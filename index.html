<!DOCTYPE html>
<html>
<head>
<meta charset="utf-8">
<title>Gists Archive</title>
<meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" type="text/css" href="assets/css/styles.css">
</head>
<body>
<div class="container">
<h1>Gists Archive</h1>
<input type="text" id="filterInput" placeholder="Search gists...">
<ul id="gistList">
<li class="gist-entry" id="gist-9fc9853ca099ff9164ab63388d461784"><a href="gists/9fc9853ca099ff9164ab63388d461784.html">Go Fuzz Testing</a><br><small class="date"><b>Created:</b> September 11, 2025</small></li>
<li class="gist-entry" id="gist-29024a8de49dcdf5ba9b24927e15cf05"><a href="gists/29024a8de49dcdf5ba9b24927e15cf05.html">Trapping Shell Signals </a><br><small class="date"><b>Created:</b> September 10, 2025</small><small class="date"><b>Tags:</b> #shell</small></li>
<li class="gist-entry" id="gist-8baf2fa15d7dfdf04b8a3e5818eda71e"><a href="gists/8baf2fa15d7dfdf04b8a3e5818eda71e.html">humanlog.io config file</a><br><small class="date"><b>Created:</b> September 3, 2025</small></li>
<li class="gist-entry" id="gist-0a714206cb2d3a7399ac7b1e6cdea69b"><a href="gists/0a714206cb2d3a7399ac7b1e6cdea69b.html">PR Reviews</a><br><small class="date"><b>Created:</b> September 1, 2025</small></li>
<li class="gist-entry" id="gist-fad3f3a20b9be166bd0b0248e8e1a665"><a href="gists/fad3f3a20b9be166bd0b0248e8e1a665.html">Search Tips </a><br><small class="date"><b>Created:</b> August 19, 2025</small><small class="date"><b>Tags:</b> #shell</small></li>
<li class="gist-entry" id="gist-a9d4c67d7c2c38d7a542306966fc5e23"><a href="gists/a9d4c67d7c2c38d7a542306966fc5e23.html">Base62 encoding and decoding </a><br><small class="date"><b>Created:</b> June 30, 2025</small><small class="date"><b>Tags:</b> #go #uuid #serialization</small></li>
<li class="gist-entry" id="gist-8061d6381b57d5316d2789feb4b829d1"><a href="gists/8061d6381b57d5316d2789feb4b829d1.html">Using ETags in your API </a><br><small class="date"><b>Created:</b> June 25, 2025</small><small class="date"><b>Tags:</b> #etag #api</small></li>
<li class="gist-entry" id="gist-e3504366d1202c7e0af8a2518422a2fc"><a href="gists/e3504366d1202c7e0af8a2518422a2fc.html">Dependabot </a><br><small class="date"><b>Created:</b> June 16, 2025</small><small class="date"><b>Tags:</b> #dependencies</small></li>
<li class="gist-entry" id="gist-0c765162e5faf3c31a6378b087684d4f"><a href="gists/0c765162e5faf3c31a6378b087684d4f.html">Simple Fastly Terraform Subscription </a><br><small class="date"><b>Created:</b> June 13, 2025</small><small class="date"><b>Tags:</b> #tls #fastly #iac</small></li>
<li class="gist-entry" id="gist-36dcf9fa921f6caa58990525e474d1a3"><a href="gists/36dcf9fa921f6caa58990525e474d1a3.html">Homebrew: custom version install </a><br><small class="date"><b>Created:</b> May 27, 2025</small><small class="date"><b>Tags:</b> #homebrew #macOS</small></li>
<li class="gist-entry" id="gist-c528f499d892cb0d74f7e037d5856358"><a href="gists/c528f499d892cb0d74f7e037d5856358.html">Go: httpx.WriteJSON </a><br><small class="date"><b>Created:</b> May 23, 2025</small><small class="date"><b>Tags:</b> #go #http #json #api</small></li>
<li class="gist-entry" id="gist-38ade4cd75f1efe01acd0738d01470cd"><a href="gists/38ade4cd75f1efe01acd0738d01470cd.html">Go: 1.23 iter.Seq/iter.Seq2 iterators </a><br><small class="date"><b>Created:</b> May 23, 2025</small><small class="date"><b>Tags:</b> #go #iterator</small></li>
<li class="gist-entry" id="gist-91d0757344d1b37ff5f40df6c2869b4e"><a href="gists/91d0757344d1b37ff5f40df6c2869b4e.html">Go: JSON omitempty vs omitzero </a><br><small class="date"><b>Created:</b> May 23, 2025</small><small class="date"><b>Tags:</b> #go #json</small></li>
<li class="gist-entry" id="gist-fc7a7bb75e2951ffe4310a2620b73e8f"><a href="gists/fc7a7bb75e2951ffe4310a2620b73e8f.html">Go: HTTP handler Write error after WriteHeader </a><br><small class="date"><b>Created:</b> May 14, 2025</small><small class="date"><b>Tags:</b> #go #http #middleware</small></li>
<li class="gist-entry" id="gist-d2a575ff3fbda36c08e31408110adbb6"><a href="gists/d2a575ff3fbda36c08e31408110adbb6.html">TLS, Certificate, and ACME Glossary </a><br><small class="date"><b>Created:</b> April 23, 2025</small><small class="date"><b>Tags:</b> #TLS #ACME</small></li>
<li class="gist-entry" id="gist-bcdd25e27bf1aed9437f8d67b14b6e9f"><a href="gists/bcdd25e27bf1aed9437f8d67b14b6e9f.html">Go: Why choose tailscale.com/util/ctxkey over Go standard context package </a><br><small class="date"><b>Created:</b> March 28, 2025</small><small class="date"><b>Tags:</b> #go #ctx</small></li>
<li class="gist-entry" id="gist-b50604c682e5ba91208f650147280596"><a href="gists/b50604c682e5ba91208f650147280596.html">DNS Delegation </a><br><small class="date"><b>Created:</b> March 26, 2025</small><small class="date"><b>Tags:</b> #dns</small></li>
<li class="gist-entry" id="gist-d61a365912576bcef88b29bd11207df3"><a href="gists/d61a365912576bcef88b29bd11207df3.html">Basic Go Project Structure </a><br><small class="date"><b>Created:</b> March 17, 2025</small><small class="date"><b>Tags:</b> #go #project</small></li>
<li class="gist-entry" id="gist-620ec233247a6eff8061e38be53ada46"><a href="gists/620ec233247a6eff8061e38be53ada46.html">Go: Serialize and Deserialize types using gob </a><br><small class="date"><b>Created:</b> March 14, 2025</small><small class="date"><b>Tags:</b> #go #serialization</small></li>
<li class="gist-entry" id="gist-49d86970ed78cfaddfffc59754ce6c4b"><a href="gists/49d86970ed78cfaddfffc59754ce6c4b.html">Improving dig output </a><br><small class="date"><b>Created:</b> March 12, 2025</small><small class="date"><b>Tags:</b> #dns #dig #bash #shell</small></li>
<li class="gist-entry" id="gist-3af3a4bfa038ed873c168709240e7213"><a href="gists/3af3a4bfa038ed873c168709240e7213.html">Well-Known URIs </a><br><small class="date"><b>Created:</b> March 11, 2025</small><small class="date"><b>Tags:</b> #IANA #Well-Known</small></li>
<li class="gist-entry" id="gist-39d50ffcf72cc9efa5874468871da722"><a href="gists/39d50ffcf72cc9efa5874468871da722.html">Go: Ring Buffers </a><br><small class="date"><b>Created:</b> March 11, 2025</small><small class="date"><b>Tags:</b> #go #ring #circular #queue</small></li>
<li class="gist-entry" id="gist-425a2a001c5bd51d06e10247739e7c13"><a href="gists/425a2a001c5bd51d06e10247739e7c13.html">Go: Generate UML </a><br><small class="date"><b>Created:</b> March 11, 2025</small><small class="date"><b>Tags:</b> #go #uml #design #architecture #diagram</small></li>
<li class="gist-entry" id="gist-df7998f8f7e5ad2aaf7d50f762a82818"><a href="gists/df7998f8f7e5ad2aaf7d50f762a82818.html">Go: Exponential Backoff </a><br><small class="date"><b>Created:</b> March 10, 2025</small><small class="date"><b>Tags:</b> #go #backoff #retry #resilience</small></li>
<li class="gist-entry" id="gist-bfcad74c66dfa1e8eb5e2c07b13811df"><a href="gists/bfcad74c66dfa1e8eb5e2c07b13811df.html">Project Planning </a><br><small class="date"><b>Created:</b> March 6, 2025</small><small class="date"><b>Tags:</b> #project #architecture #design #planning</small></li>
<li class="gist-entry" id="gist-5a89113b6c88a61b3841fc468b49b8cc"><a href="gists/5a89113b6c88a61b3841fc468b49b8cc.html">Math: How to identify a number</a><br><small class="date"><b>Created:</b> February 27, 2025</small></li>
<li class="gist-entry" id="gist-c3f14bc015191fba900da446a541f2a8"><a href="gists/c3f14bc015191fba900da446a541f2a8.html">DNS: Lookup of Host information </a><br><small class="date"><b>Created:</b> February 13, 2025</small><small class="date"><b>Tags:</b> #dns #lookup #host</small></li>
<li class="gist-entry" id="gist-52f5787154bf516628c8777dc3455a99"><a href="gists/52f5787154bf516628c8777dc3455a99.html">Bash: Update same line for progress bar reporting </a><br><small class="date"><b>Created:</b> February 7, 2025</small><small class="date"><b>Tags:</b> #bash #shell #progress</small></li>
<li class="gist-entry" id="gist-228d1c8b0d309a41de67afe09111f4eb"><a href="gists/228d1c8b0d309a41de67afe09111f4eb.html">Mermaid Diagram Examples </a><br><small class="date"><b>Created:</b> January 27, 2025</small><small class="date"><b>Tags:</b> #diagrams</small></li>
<li class="gist-entry" id="gist-cf0bc36e17d8c28b04c6e7c5d5566e10"><a href="gists/cf0bc36e17d8c28b04c6e7c5d5566e10.html">Go: go work </a><br><small class="date"><b>Created:</b> January 21, 2025</small><small class="date"><b>Tags:</b> #go #project</small></li>
<li class="gist-entry" id="gist-1391150b69eebcaac98984627ba26b7d"><a href="gists/1391150b69eebcaac98984627ba26b7d.html">xarg: parallel processing </a><br><small class="date"><b>Created:</b> January 21, 2025</small><small class="date"><b>Tags:</b> #xarg</small></li>
<li class="gist-entry" id="gist-0320ea5b1fccd4b1ad6aa6c369b011e7"><a href="gists/0320ea5b1fccd4b1ad6aa6c369b011e7.html">Make: Makefile syntax </a><br><small class="date"><b>Created:</b> January 14, 2025</small><small class="date"><b>Tags:</b> #make #makefile #shell</small></li>
<li class="gist-entry" id="gist-12a6f901da071120d3a45e41b3eb0f12"><a href="gists/12a6f901da071120d3a45e41b3eb0f12.html">OpenAPI: feature flags use different schemas </a><br><small class="date"><b>Created:</b> January 13, 2025</small><small class="date"><b>Tags:</b> #schemas #openapi #api #design</small></li>
<li class="gist-entry" id="gist-5010e113ce19285698cfe5d941b9884b"><a href="gists/5010e113ce19285698cfe5d941b9884b.html">1Password CLI </a><br><small class="date"><b>Created:</b> January 7, 2025</small><small class="date"><b>Tags:</b> #shell</small></li>
<li class="gist-entry" id="gist-5685562cd874cce18d5d00714fe0a2c7"><a href="gists/5685562cd874cce18d5d00714fe0a2c7.html">Go: errgroup </a><br><small class="date"><b>Created:</b> January 7, 2025</small><small class="date"><b>Tags:</b> #go #concurrency #errors</small></li>
<li class="gist-entry" id="gist-1b5ee79a9d128407c7daabd72a1abf27"><a href="gists/1b5ee79a9d128407c7daabd72a1abf27.html">macOS: automation with Hammerspoon </a><br><small class="date"><b>Created:</b> January 5, 2025</small><small class="date"><b>Tags:</b> #hammer #hammerspoon #os #automation #macos #shell #lua</small></li>
<li class="gist-entry" id="gist-a459a4951b5e9bca7d767d6d4f39dda2"><a href="gists/a459a4951b5e9bca7d767d6d4f39dda2.html">Image resize with ImageMagick </a><br><small class="date"><b>Created:</b> January 2, 2025</small><small class="date"><b>Tags:</b> #bash #shell #imagemagick #resize #image</small></li>
<li class="gist-entry" id="gist-bd107aa44b01e6f2077861bf746e4664"><a href="gists/bd107aa44b01e6f2077861bf746e4664.html">Go: Single-Flight </a><br><small class="date"><b>Created:</b> December 20, 2024</small><small class="date"><b>Tags:</b> #go #performance #concurrency</small></li>
<li class="gist-entry" id="gist-4c4983e9da327cb83a0e9c8b90396ac0"><a href="gists/4c4983e9da327cb83a0e9c8b90396ac0.html">Code: Programming Terminology </a><br><small class="date"><b>Created:</b> December 20, 2024</small><small class="date"><b>Tags:</b> #programming #terminology</small></li>
<li class="gist-entry" id="gist-3b1b8dcba080c980208a8bdd546966fd"><a href="gists/3b1b8dcba080c980208a8bdd546966fd.html">Go: Custom Error Handling </a><br><small class="date"><b>Created:</b> December 19, 2024</small><small class="date"><b>Tags:</b> #go #errors</small></li>
<li class="gist-entry" id="gist-49b7bdafaee71adcd5aef282f47509d2"><a href="gists/49b7bdafaee71adcd5aef282f47509d2.html">Shell: Shell Scripting Best Practices </a><br><small class="date"><b>Created:</b> December 18, 2024</small><small class="date"><b>Tags:</b> #shell #bash</small></li>
<li class="gist-entry" id="gist-dcabda9b762ad23781af76fd1971e0f7"><a href="gists/dcabda9b762ad23781af76fd1971e0f7.html">YAML: anchors </a><br><small class="date"><b>Created:</b> December 9, 2024</small><small class="date"><b>Tags:</b> #yaml #anchors</small></li>
<li class="gist-entry" id="gist-4ac5854116d0ccae632b42ba2ed2c2e4"><a href="gists/4ac5854116d0ccae632b42ba2ed2c2e4.html">Go: Generic Slice Map function </a><br><small class="date"><b>Created:</b> December 3, 2024</small><small class="date"><b>Tags:</b> #go #computation #generics</small></li>
<li class="gist-entry" id="gist-d21ee193a83fdf68bc3fa506f25782fe"><a href="gists/d21ee193a83fdf68bc3fa506f25782fe.html">Go: Delete a slice entry in Go </a><br><small class="date"><b>Created:</b> December 3, 2024</small><small class="date"><b>Tags:</b> #go #computation</small></li>
<li class="gist-entry" id="gist-dbf264af81bd51e4519357e11742699f"><a href="gists/dbf264af81bd51e4519357e11742699f.html">Go: Simple line-by-line diff in Go </a><br><small class="date"><b>Created:</b> December 2, 2024</small><small class="date"><b>Tags:</b> #go #utility</small></li>
<li class="gist-entry" id="gist-09ff73d309af7852864dfe709c53f12d"><a href="gists/09ff73d309af7852864dfe709c53f12d.html">Go: Structured Logging </a><br><small class="date"><b>Created:</b> November 26, 2024</small><small class="date"><b>Tags:</b> #go #logs</small></li>
<li class="gist-entry" id="gist-3d88940495b81a4639fc74c1bfdf266a"><a href="gists/3d88940495b81a4639fc74c1bfdf266a.html">Go: Bitwise Operations in Go </a><br><small class="date"><b>Created:</b> November 8, 2024</small><small class="date"><b>Tags:</b> #go #computation</small></li>
<li class="gist-entry" id="gist-1b1d446b84957967ce579c6278f524db"><a href="gists/1b1d446b84957967ce579c6278f524db.html">Fastly Code Test Asset</a><br><small class="date"><b>Created:</b> November 4, 2024</small></li>
<li class="gist-entry" id="gist-05fb91c42021195b727be5afb28122ec"><a href="gists/05fb91c42021195b727be5afb28122ec.html">Go: concurrency </a><br><small class="date"><b>Created:</b> October 29, 2024</small><small class="date"><b>Tags:</b> #go #concurrency</small></li>
<li class="gist-entry" id="gist-c2b21a36260d8066da28b5f397f1d7c1"><a href="gists/c2b21a36260d8066da28b5f397f1d7c1.html">macOS: Custom wireless battery alerts for mouse and keyboard </a><br><small class="date"><b>Created:</b> October 22, 2024</small><small class="date"><b>Tags:</b> #macos #automator #notifications #battery</small></li>
<li class="gist-entry" id="gist-089e4e2da20090c3a91f0991ab2dac78"><a href="gists/089e4e2da20090c3a91f0991ab2dac78.html">Go: Custom DNS resolution in Golang </a><br><small class="date"><b>Created:</b> October 18, 2024</small><small class="date"><b>Tags:</b> #go #dns</small></li>
<li class="gist-entry" id="gist-85e4cd0d0f227a84be3068ec12f9bf72"><a href="gists/85e4cd0d0f227a84be3068ec12f9bf72.html">Go: Codesign a Go test binary that listens on network and needs to accept incoming network connections </a><br><small class="date"><b>Created:</b> October 17, 2024</small><small class="date"><b>Tags:</b> #go #macos #network #security</small></li>
<li class="gist-entry" id="gist-7006aa7d67b45fcae667125921fdd362"><a href="gists/7006aa7d67b45fcae667125921fdd362.html">OpenSSL: Working with SSL Certificates, Private Keys and CSRs </a><br><small class="date"><b>Created:</b> October 1, 2024</small><small class="date"><b>Tags:</b> #openssl #ssl #tls #certs #csr</small></li>
<li class="gist-entry" id="gist-f86efc7940dbe27d0703c831ecf01b71"><a href="gists/f86efc7940dbe27d0703c831ecf01b71.html">Go: local SSH tunnel using google cloud </a><br><small class="date"><b>Created:</b> September 20, 2024</small><small class="date"><b>Tags:</b> #go #ssh</small></li>
<li class="gist-entry" id="gist-8a6401fb294964984a27d73c2bd97664"><a href="gists/8a6401fb294964984a27d73c2bd97664.html">Go: GitHub Actions update app dependencies daily with private repo access </a><br><small class="date"><b>Created:</b> September 12, 2024</small><small class="date"><b>Tags:</b> #ci #cron #go</small></li>
<li class="gist-entry" id="gist-439bb57fcba114ea7500bbc21951112c"><a href="gists/439bb57fcba114ea7500bbc21951112c.html">What is a SKU </a><br><small class="date"><b>Created:</b> September 4, 2024</small><small class="date"><b>Tags:</b> #sku</small></li>
<li class="gist-entry" id="gist-c7a1bd810e1ab30b83e99308d11191cb"><a href="gists/c7a1bd810e1ab30b83e99308d11191cb.html">Pagination: offset vs cursor </a><br><small class="date"><b>Created:</b> August 6, 2024</small><small class="date"><b>Tags:</b> #pagination #design</small></li>
<li class="gist-entry" id="gist-e056ae364b2f10cc01d26d5525ec269b"><a href="gists/e056ae364b2f10cc01d26d5525ec269b.html">Go: the goto statement </a><br><small class="date"><b>Created:</b> August 6, 2024</small><small class="date"><b>Tags:</b> #go</small></li>
<li class="gist-entry" id="gist-62a37111624853397982ac7c6369be19"><a href="gists/62a37111624853397982ac7c6369be19.html">Go: f-tests replace table-driven tests </a><br><small class="date"><b>Created:</b> July 17, 2024</small><small class="date"><b>Tags:</b> #go #tests</small></li>
<li class="gist-entry" id="gist-d076e8108f216c109d14a349e65ce490"><a href="gists/d076e8108f216c109d14a349e65ce490.html">Music: Separate the musical instruments from a song and make an instrumental</a><br><small class="date"><b>Created:</b> June 26, 2024</small></li>
<li class="gist-entry" id="gist-95661bd8dad0b66909d3cd1823f0b8d4"><a href="gists/95661bd8dad0b66909d3cd1823f0b8d4.html">Vim: beginner notes </a><br><small class="date"><b>Created:</b> June 5, 2024</small><small class="date"><b>Tags:</b> #vim #beginner</small></li>
<li class="gist-entry" id="gist-1d11348ef687d6de453f2f9b7a223e61"><a href="gists/1d11348ef687d6de453f2f9b7a223e61.html">Shell: rename files matching specific pattern </a><br><small class="date"><b>Created:</b> May 22, 2024</small><small class="date"><b>Tags:</b> #shell #bash #macos #files #rename</small></li>
<li class="gist-entry" id="gist-9302d54e6f1ecb5e8245204315dd9436"><a href="gists/9302d54e6f1ecb5e8245204315dd9436.html">SSH: Proxy HTTP requests through a SSH connection via SOCKS5 proxy </a><br><small class="date"><b>Created:</b> May 15, 2024</small><small class="date"><b>Tags:</b> #ssh #proxy #tunnel</small></li>
<li class="gist-entry" id="gist-5fa84ffa216e2c3b412ee6b090cabe57"><a href="gists/5fa84ffa216e2c3b412ee6b090cabe57.html">Markdown: Highligh notes and warnings in Markdown </a><br><small class="date"><b>Created:</b> May 13, 2024</small><small class="date"><b>Tags:</b> #gist #github #notes</small></li>
<li class="gist-entry" id="gist-92df54bfeb725d3d27943ef533eff922"><a href="gists/92df54bfeb725d3d27943ef533eff922.html">Editor: Example Editor Config </a><br><small class="date"><b>Created:</b> May 8, 2024</small><small class="date"><b>Tags:</b> #editorconfig</small></li>
<li class="gist-entry" id="gist-fafb59064e96097f5483d3775181c541"><a href="gists/fafb59064e96097f5483d3775181c541.html">Testing: Different Testing Styles </a><br><small class="date"><b>Created:</b> April 29, 2024</small><small class="date"><b>Tags:</b> #tests #terminology #system</small></li>
<li class="gist-entry" id="gist-927f91c34be67499a6a1a430ddaebe92"><a href="gists/927f91c34be67499a6a1a430ddaebe92.html">Go: basic middleware abstraction </a><br><small class="date"><b>Created:</b> March 26, 2024</small><small class="date"><b>Tags:</b> #go #middleware</small></li>
<li class="gist-entry" id="gist-d7def72bd3c20e0e076b90b2e90233b7"><a href="gists/d7def72bd3c20e0e076b90b2e90233b7.html">Go: Docker Go Image with mounted files </a><br><small class="date"><b>Created:</b> March 14, 2024</small><small class="date"><b>Tags:</b> #docker #go</small></li>
<li class="gist-entry" id="gist-ff0a0152fdb0cad90e392c19645bb5ac"><a href="gists/ff0a0152fdb0cad90e392c19645bb5ac.html">Go: convert JSON types when unmarshalling </a><br><small class="date"><b>Created:</b> March 7, 2024</small><small class="date"><b>Tags:</b> #go #json #serialization</small></li>
<li class="gist-entry" id="gist-a4418dc1fc7940e2ee77183461e6ed9d"><a href="gists/a4418dc1fc7940e2ee77183461e6ed9d.html">Make: Check if Makefile target is called with a required input arg </a><br><small class="date"><b>Created:</b> March 1, 2024</small><small class="date"><b>Tags:</b> #Makefile #make</small></li>
<li class="gist-entry" id="gist-20358d358840cb749bb4249a463af932"><a href="gists/20358d358840cb749bb4249a463af932.html">macOS: Install Windows on macOS with VirtualBox </a><br><small class="date"><b>Created:</b> February 29, 2024</small><small class="date"><b>Tags:</b> #virtualbox #vm #windows</small></li>
<li class="gist-entry" id="gist-87118a8f79d47aaf640c21149bf9d687"><a href="gists/87118a8f79d47aaf640c21149bf9d687.html">Fastly: create, validate, and destroy service </a><br><small class="date"><b>Created:</b> February 28, 2024</small><small class="date"><b>Tags:</b> #CLI #Fastly</small></li>
<li class="gist-entry" id="gist-0a685f3128597a18107ced7367b8a5bd"><a href="gists/0a685f3128597a18107ced7367b8a5bd.html">GitHub: Download latest GitHub Asset Release </a><br><small class="date"><b>Created:</b> February 23, 2024</small><small class="date"><b>Tags:</b> #github #asset #release</small></li>
<li class="gist-entry" id="gist-dba19204e096bf43d0e6274d118d8da3"><a href="gists/dba19204e096bf43d0e6274d118d8da3.html">Go: type cast </a><br><small class="date"><b>Created:</b> February 9, 2024</small><small class="date"><b>Tags:</b> #go</small></li>
<li class="gist-entry" id="gist-bcbfa8e5ea7921978031b4285a61b9a2"><a href="gists/bcbfa8e5ea7921978031b4285a61b9a2.html">Go: structure logging </a><br><small class="date"><b>Created:</b> January 24, 2024</small><small class="date"><b>Tags:</b> #go #logs</small></li>
<li class="gist-entry" id="gist-5862dd87fedf8b6cac96c8307bbdb755"><a href="gists/5862dd87fedf8b6cac96c8307bbdb755.html">Go: copy struct from pointer </a><br><small class="date"><b>Created:</b> January 19, 2024</small><small class="date"><b>Tags:</b> #go</small></li>
<li class="gist-entry" id="gist-4fcf0a313ffdbda99c59931b1142e8bb"><a href="gists/4fcf0a313ffdbda99c59931b1142e8bb.html">Go: understanding init functions </a><br><small class="date"><b>Created:</b> January 18, 2024</small><small class="date"><b>Tags:</b> #go</small></li>
<li class="gist-entry" id="gist-fad304fd5f435b8f400d6adad693a8a2"><a href="gists/fad304fd5f435b8f400d6adad693a8a2.html">Go: pointer receiver method avoids runtime panic </a><br><small class="date"><b>Created:</b> January 12, 2024</small><small class="date"><b>Tags:</b> #go</small></li>
<li class="gist-entry" id="gist-e00bb3c9e3a1210d3cfae4ee3800a1b7"><a href="gists/e00bb3c9e3a1210d3cfae4ee3800a1b7.html">OpenAPI: generate schema dynamically </a><br><small class="date"><b>Created:</b> December 15, 2023</small><small class="date"><b>Tags:</b> #openapi #template #bash #shell</small></li>
<li class="gist-entry" id="gist-7c6c9418ca6b328d6a721ccf34df050a"><a href="gists/7c6c9418ca6b328d6a721ccf34df050a.html">Go: range bug </a><br><small class="date"><b>Created:</b> November 17, 2023</small><small class="date"><b>Tags:</b> #go #bug</small></li>
<li class="gist-entry" id="gist-66b93fcfde73b7ef3a0f885dae7ce570"><a href="gists/66b93fcfde73b7ef3a0f885dae7ce570.html">Go: filter secrets </a><br><small class="date"><b>Created:</b> October 9, 2023</small><small class="date"><b>Tags:</b> #go #security</small></li>
<li class="gist-entry" id="gist-764dec7fb5e0ad4351b5fbc99e798838"><a href="gists/764dec7fb5e0ad4351b5fbc99e798838.html">Go: recursively walk tree looking for go files and analysing their imports </a><br><small class="date"><b>Created:</b> September 22, 2023</small><small class="date"><b>Tags:</b> #go #ast #recursive</small></li>
<li class="gist-entry" id="gist-f2cb72380a7e3c3e8363dba698ab9926"><a href="gists/f2cb72380a7e3c3e8363dba698ab9926.html">Go: call method directly via method expressions </a><br><small class="date"><b>Created:</b> June 16, 2023</small><small class="date"><b>Tags:</b> #go #expressions</small></li>
<li class="gist-entry" id="gist-ceede527325efbfd320944677b30197b"><a href="gists/ceede527325efbfd320944677b30197b.html">macOS: find files asynchronously </a><br><small class="date"><b>Created:</b> June 5, 2023</small><small class="date"><b>Tags:</b> #xargs #async #find</small></li>
<li class="gist-entry" id="gist-235f8156a9f20533fbc4ecd36bcc4724"><a href="gists/235f8156a9f20533fbc4ecd36bcc4724.html">Go: stream new-line delimited JSON to Server </a><br><small class="date"><b>Created:</b> May 18, 2023</small><small class="date"><b>Tags:</b> #go #api #stream #json #ndjson</small></li>
<li class="gist-entry" id="gist-4447885192c7e84e01ca7c9f2e08ef17"><a href="gists/4447885192c7e84e01ca7c9f2e08ef17.html">Make: Makefile help output </a><br><small class="date"><b>Created:</b> April 25, 2023</small><small class="date"><b>Tags:</b> #make #makefile #help #docs</small></li>
<li class="gist-entry" id="gist-d8566501ff70f0f09f7262e440c02868"><a href="gists/d8566501ff70f0f09f7262e440c02868.html">API: Versioning Strategies </a><br><small class="date"><b>Created:</b> April 25, 2023</small><small class="date"><b>Tags:</b> #api #versioning</small></li>
<li class="gist-entry" id="gist-94be4633641bc644ef3b9cb50d8926fb"><a href="gists/94be4633641bc644ef3b9cb50d8926fb.html">OpenSSL: Generate Certificate for Code Signing </a><br><small class="date"><b>Created:</b> March 24, 2023</small><small class="date"><b>Tags:</b> #openssl #cert #codesign #AI</small></li>
<li class="gist-entry" id="gist-e27f16821806aa8037c442d805fc2e44"><a href="gists/e27f16821806aa8037c442d805fc2e44.html">Git: Generate change log between two tags </a><br><small class="date"><b>Created:</b> March 23, 2023</small><small class="date"><b>Tags:</b> #changelog #git</small></li>
<li class="gist-entry" id="gist-57accaf446cf3e7974cd01d57158532c"><a href="gists/57accaf446cf3e7974cd01d57158532c.html">AWK: extract first changelog entry </a><br><small class="date"><b>Created:</b> March 22, 2023</small><small class="date"><b>Tags:</b> #awk #changelog</small></li>
<li class="gist-entry" id="gist-bdc3a6391682d351516ebcf766229e5b"><a href="gists/bdc3a6391682d351516ebcf766229e5b.html">Go: spinner </a><br><small class="date"><b>Created:</b> February 13, 2023</small><small class="date"><b>Tags:</b> #go #spinner</small></li>
<li class="gist-entry" id="gist-1e9df4944e366e46471953864858ff7e"><a href="gists/1e9df4944e366e46471953864858ff7e.html">Go: recursively search for a file until reaching user's home directory </a><br><small class="date"><b>Created:</b> January 31, 2023</small><small class="date"><b>Tags:</b> #go #search #recursive</small></li>
<li class="gist-entry" id="gist-d6c1001c252c84a9c128fa3e8c477be2"><a href="gists/d6c1001c252c84a9c128fa3e8c477be2.html">Go: Playground multiple files </a><br><small class="date"><b>Created:</b> January 16, 2023</small><small class="date"><b>Tags:</b> #go #playground</small></li>
<li class="gist-entry" id="gist-f9d739957cdec30a6a55b87862175c06"><a href="gists/f9d739957cdec30a6a55b87862175c06.html">API Clients: Publishing packages for multiple languages </a><br><small class="date"><b>Created:</b> December 9, 2022</small><small class="date"><b>Tags:</b> #publish #package #ruby #php #python #go #js #javascript #rust #api #clients</small></li>
<li class="gist-entry" id="gist-86a7d94a832b432b5139ad28c074df32"><a href="gists/86a7d94a832b432b5139ad28c074df32.html">JS: Getting JS module published </a><br><small class="date"><b>Created:</b> December 9, 2022</small><small class="date"><b>Tags:</b> #js #javascript #npm #module</small></li>
<li class="gist-entry" id="gist-9136adf9891c3e93480b02aa32de3b8a"><a href="gists/9136adf9891c3e93480b02aa32de3b8a.html">Go: Getting package documentation published </a><br><small class="date"><b>Created:</b> December 9, 2022</small><small class="date"><b>Tags:</b> #go #pkg #docs</small></li>
<li class="gist-entry" id="gist-d9ba0028ce7c6b90280f73c71cb27cf5"><a href="gists/d9ba0028ce7c6b90280f73c71cb27cf5.html">Shell: Write to a variable multiple times before writing to disk </a><br><small class="date"><b>Created:</b> December 1, 2022</small><small class="date"><b>Tags:</b> #bash #shell #performance</small></li>
<li class="gist-entry" id="gist-89ad7fe05f72941b87c6e3512c30d940"><a href="gists/89ad7fe05f72941b87c6e3512c30d940.html">RipGrep: inline file replacements </a><br><small class="date"><b>Created:</b> November 29, 2022</small><small class="date"><b>Tags:</b> #riggrep #rg #sed #replacement #bash #shell</small></li>
<li class="gist-entry" id="gist-91ebbc27690439687a804fa6860fd355"><a href="gists/91ebbc27690439687a804fa6860fd355.html">Auth: CLI Device Authorization Flow with Auth0 </a><br><small class="date"><b>Created:</b> November 24, 2022</small><small class="date"><b>Tags:</b> #auth #auth0 #device #cli</small></li>
<li class="gist-entry" id="gist-76f8be7cd5bb6e75587d58146daf0ab5"><a href="gists/76f8be7cd5bb6e75587d58146daf0ab5.html">Auth: CLI PKCE with Auth0 or KeyCloak (inc code examples + sequence diagram) </a><br><small class="date"><b>Created:</b> November 23, 2022</small><small class="date"><b>Tags:</b> #auth #auth0 #pkce #cli #keycloak</small></li>
<li class="gist-entry" id="gist-d50a2e06dbb8f1b2e510eac2f28b3e1d"><a href="gists/d50a2e06dbb8f1b2e510eac2f28b3e1d.html">Auth: OAuth2 and OIDC (OpenID Connect) </a><br><small class="date"><b>Created:</b> November 9, 2022</small><small class="date"><b>Tags:</b> #OAuth #OIDC</small></li>
<li class="gist-entry" id="gist-fdf8374a593eeef8db8fed0fb868d5eb"><a href="gists/fdf8374a593eeef8db8fed0fb868d5eb.html">Make: Makefile prompt for user input </a><br><small class="date"><b>Created:</b> October 4, 2022</small><small class="date"><b>Tags:</b> #make #shell</small></li>
<li class="gist-entry" id="gist-f55a601cf3ccdb7fc8a671c854383e3a"><a href="gists/f55a601cf3ccdb7fc8a671c854383e3a.html">Vim: increment numbers across blocks </a><br><small class="date"><b>Created:</b> September 29, 2022</small><small class="date"><b>Tags:</b> #vim #increment</small></li>
<li class="gist-entry" id="gist-ad42a27c7b0eaa2a56f6c9c5ed555e1e"><a href="gists/ad42a27c7b0eaa2a56f6c9c5ed555e1e.html">Terraform: Debugging with Delve </a><br><small class="date"><b>Created:</b> September 23, 2022</small><small class="date"><b>Tags:</b> #terraform #debug #delve</small></li>
<li class="gist-entry" id="gist-2f502863c079c5537bc7d5577c61cb98"><a href="gists/2f502863c079c5537bc7d5577c61cb98.html">Git: How to ignore root file but not a sub directory of the same name </a><br><small class="date"><b>Created:</b> July 15, 2022</small><small class="date"><b>Tags:</b> #git #ignore</small></li>
<li class="gist-entry" id="gist-2417151b6b94ffd2f8f7ca8be69337d4"><a href="gists/2417151b6b94ffd2f8f7ca8be69337d4.html">Go: file lock </a><br><small class="date"><b>Created:</b> June 30, 2022</small><small class="date"><b>Tags:</b> #go #network</small></li>
<li class="gist-entry" id="gist-c906c76a2af918e5fb8c575a0dd53ebf"><a href="gists/c906c76a2af918e5fb8c575a0dd53ebf.html">Go: retry logic </a><br><small class="date"><b>Created:</b> June 30, 2022</small><small class="date"><b>Tags:</b> #go #resilience</small></li>
<li class="gist-entry" id="gist-6b3925a677b0cfe9ef7242cc5d519a12"><a href="gists/6b3925a677b0cfe9ef7242cc5d519a12.html">JS: Simple partial application function</a><br><small class="date"><b>Created:</b> June 28, 2022</small></li>
<li class="gist-entry" id="gist-62b7ba713197ee331d80cb3479903ff3"><a href="gists/62b7ba713197ee331d80cb3479903ff3.html">Go: remove cookie from http.Request </a><br><small class="date"><b>Created:</b> June 23, 2022</small><small class="date"><b>Tags:</b> #go #http</small></li>
<li class="gist-entry" id="gist-bc358eb37de04fa536e34fcc4a7e8cba"><a href="gists/bc358eb37de04fa536e34fcc4a7e8cba.html">Perl: add language to markdown code block </a><br><small class="date"><b>Created:</b> June 21, 2022</small><small class="date"><b>Tags:</b> #perl #regex #codeblock #markdown</small></li>
<li class="gist-entry" id="gist-0f0a549adc4af44167a7222725767eb6"><a href="gists/0f0a549adc4af44167a7222725767eb6.html">Rust: flatten vector of Results </a><br><small class="date"><b>Created:</b> June 20, 2022</small><small class="date"><b>Tags:</b> #rust</small></li>
<li class="gist-entry" id="gist-be72bd063606fd36c38403791a638d0e"><a href="gists/be72bd063606fd36c38403791a638d0e.html">Rust: Smart Pointers </a><br><small class="date"><b>Created:</b> June 16, 2022</small><small class="date"><b>Tags:</b> #rust</small></li>
<li class="gist-entry" id="gist-dd65c727ea3aabe3333d7995eb9665c9"><a href="gists/dd65c727ea3aabe3333d7995eb9665c9.html">Rust: Tokio Spawn and Retry </a><br><small class="date"><b>Created:</b> June 15, 2022</small><small class="date"><b>Tags:</b> #rust #async #retry</small></li>
<li class="gist-entry" id="gist-a265f0d352379a8d484e65b71f7ac511"><a href="gists/a265f0d352379a8d484e65b71f7ac511.html">Terraform: Debugging Variables </a><br><small class="date"><b>Created:</b> June 14, 2022</small><small class="date"><b>Tags:</b> #terraform #debug #log</small></li>
<li class="gist-entry" id="gist-b065aea92c072d5b9ce7d6a829204155"><a href="gists/b065aea92c072d5b9ce7d6a829204155.html">JS: sort two-dimensional Array </a><br><small class="date"><b>Created:</b> June 9, 2022</small><small class="date"><b>Tags:</b> #js #javascript #sort</small></li>
<li class="gist-entry" id="gist-a7a84316dd7fd210b06e813fc799246f"><a href="gists/a7a84316dd7fd210b06e813fc799246f.html">Rust: Basic parsing of go.mod with Rust </a><br><small class="date"><b>Created:</b> May 23, 2022</small><small class="date"><b>Tags:</b> #rust #go #serialization</small></li>
<li class="gist-entry" id="gist-a124e35573a74496b16fa746742231a4"><a href="gists/a124e35573a74496b16fa746742231a4.html">Rust: Measure the elapsed time between two code sections in Rust </a><br><small class="date"><b>Created:</b> May 19, 2022</small><small class="date"><b>Tags:</b> #rust #debug</small></li>
<li class="gist-entry" id="gist-abbffe4c06712f46db1bcffdd82ef652"><a href="gists/abbffe4c06712f46db1bcffdd82ef652.html">Shell: single line Ruby script in shell </a><br><small class="date"><b>Created:</b> May 18, 2022</small><small class="date"><b>Tags:</b> #ruby #shell #script</small></li>
<li class="gist-entry" id="gist-091de4e072fbd84442afd6668bdc657d"><a href="gists/091de4e072fbd84442afd6668bdc657d.html">Go: REDACT tokens via regex pattern </a><br><small class="date"><b>Created:</b> May 16, 2022</small><small class="date"><b>Tags:</b> #go #regex</small></li>
<li class="gist-entry" id="gist-f9f54403afe6400d8278ff4a2462b3e5"><a href="gists/f9f54403afe6400d8278ff4a2462b3e5.html">Network: Debug Wifi Issues </a><br><small class="date"><b>Created:</b> May 16, 2022</small><small class="date"><b>Tags:</b> #wifi #network #debug</small></li>
<li class="gist-entry" id="gist-cbb09aef4897d2a6a2c03499f8e03064"><a href="gists/cbb09aef4897d2a6a2c03499f8e03064.html">Go: Docker Go/TinyGo Application </a><br><small class="date"><b>Created:</b> May 3, 2022</small><small class="date"><b>Tags:</b> #docker #go</small></li>
<li class="gist-entry" id="gist-93e6874fe1a2ed0a5a27e244293dd7c5"><a href="gists/93e6874fe1a2ed0a5a27e244293dd7c5.html">Go: Version <1.16 Embed Data </a><br><small class="date"><b>Created:</b> April 28, 2022</small><small class="date"><b>Tags:</b> #go</small></li>
<li class="gist-entry" id="gist-4a2137c733156fbfd7656d72afb5b8d8"><a href="gists/4a2137c733156fbfd7656d72afb5b8d8.html">macOS: view shutdown logs </a><br><small class="date"><b>Created:</b> April 28, 2022</small><small class="date"><b>Tags:</b> #macOS #logs</small></li>
<li class="gist-entry" id="gist-80fa38b86e9f93e6721d0c9452bc3b9f"><a href="gists/80fa38b86e9f93e6721d0c9452bc3b9f.html">Shell: Track list of open files </a><br><small class="date"><b>Created:</b> April 26, 2022</small><small class="date"><b>Tags:</b> #bash #tmux #lsof #unix #shell #monitor #zsh</small></li>
<li class="gist-entry" id="gist-82676169a06231d0e71badbde9fdd55a"><a href="gists/82676169a06231d0e71badbde9fdd55a.html">Laptop: New Laptop Software Installation </a><br><small class="date"><b>Created:</b> March 29, 2022</small><small class="date"><b>Tags:</b> #laptop</small></li>
<li class="gist-entry" id="gist-777a9d9f554f916fb30e911754c2eb54"><a href="gists/777a9d9f554f916fb30e911754c2eb54.html">Rust: parse string to custom type </a><br><small class="date"><b>Created:</b> March 29, 2022</small><small class="date"><b>Tags:</b> #rust #trait</small></li>
<li class="gist-entry" id="gist-5d597e6069299ddb6698e637b13471c1"><a href="gists/5d597e6069299ddb6698e637b13471c1.html">Rust: Parse program releases </a><br><small class="date"><b>Created:</b> March 29, 2022</small><small class="date"><b>Tags:</b> #rust #exercise #io #file #semver #trait</small></li>
<li class="gist-entry" id="gist-8f6fb17056f64ffe79f5d50529aed74d"><a href="gists/8f6fb17056f64ffe79f5d50529aed74d.html">Go: random number generator </a><br><small class="date"><b>Created:</b> March 9, 2022</small><small class="date"><b>Tags:</b> #go #rng</small></li>
<li class="gist-entry" id="gist-c1cedc3f45264d7ee78f33915a2e2b58"><a href="gists/c1cedc3f45264d7ee78f33915a2e2b58.html">Go: documentation generate example </a><br><small class="date"><b>Created:</b> March 8, 2022</small><small class="date"><b>Tags:</b> #go</small></li>
<li class="gist-entry" id="gist-2f03f0f2333b872e3ab543477355892d"><a href="gists/2f03f0f2333b872e3ab543477355892d.html">Go: generate range between two numbers </a><br><small class="date"><b>Created:</b> March 4, 2022</small><small class="date"><b>Tags:</b> #go</small></li>
<li class="gist-entry" id="gist-fe0761860384b67797f78112aa83e733"><a href="gists/fe0761860384b67797f78112aa83e733.html">Go: r.Host vs r.URL.Host </a><br><small class="date"><b>Created:</b> March 3, 2022</small><small class="date"><b>Tags:</b> #go #http</small></li>
<li class="gist-entry" id="gist-be89a373655fc00f50adcfea04dc9525"><a href="gists/be89a373655fc00f50adcfea04dc9525.html">Shell: Authenticated curl of the GitHub API </a><br><small class="date"><b>Created:</b> February 23, 2022</small><small class="date"><b>Tags:</b> #curl #bash #auth #github #api</small></li>
<li class="gist-entry" id="gist-8df24d51ae2ad99f3abbc8df156faaef"><a href="gists/8df24d51ae2ad99f3abbc8df156faaef.html">Go: GitHub API Client </a><br><small class="date"><b>Created:</b> February 22, 2022</small><small class="date"><b>Tags:</b> #go #api</small></li>
<li class="gist-entry" id="gist-2a4f935f186379d6f638807fec4af9a7"><a href="gists/2a4f935f186379d6f638807fec4af9a7.html">Rust: anyhow vs thiserror </a><br><small class="date"><b>Created:</b> February 21, 2022</small><small class="date"><b>Tags:</b> #rust #errorhandling</small></li>
<li class="gist-entry" id="gist-2a466d1d6298453796e84bb155debf53"><a href="gists/2a466d1d6298453796e84bb155debf53.html">macOS: Force eject DVD from external drive </a><br><small class="date"><b>Created:</b> February 9, 2022</small><small class="date"><b>Tags:</b> #macOS #disk #drive #dvd</small></li>
<li class="gist-entry" id="gist-9ea80fda8f332baf87844afa7ee63139"><a href="gists/9ea80fda8f332baf87844afa7ee63139.html">Go: simplicity of mitchellh/cli </a><br><small class="date"><b>Created:</b> February 8, 2022</small><small class="date"><b>Tags:</b> #go</small></li>
<li class="gist-entry" id="gist-c123665c4e4153fdfef58b658e51f879"><a href="gists/c123665c4e4153fdfef58b658e51f879.html">Shell: Generate Go documentation </a><br><small class="date"><b>Created:</b> February 3, 2022</small><small class="date"><b>Tags:</b> #go #shell</small></li>
<li class="gist-entry" id="gist-040909cecc68ee0e2f1dd5b91e5cafb6"><a href="gists/040909cecc68ee0e2f1dd5b91e5cafb6.html">Go: handle unknown json data structure </a><br><small class="date"><b>Created:</b> January 31, 2022</small><small class="date"><b>Tags:</b> #go #json #serialization</small></li>
<li class="gist-entry" id="gist-42ac0bbe464a0378fb9bb0eaf42e8312"><a href="gists/42ac0bbe464a0378fb9bb0eaf42e8312.html">Go: combine two structs with json.Marshal </a><br><small class="date"><b>Created:</b> January 31, 2022</small><small class="date"><b>Tags:</b> #go #json #serialization</small></li>
<li class="gist-entry" id="gist-b4c3231f0c95d59cf977c2911125a0a4"><a href="gists/b4c3231f0c95d59cf977c2911125a0a4.html">Fastly: Terraform 1.0.0 Migration Guide </a><br><small class="date"><b>Created:</b> January 28, 2022</small><small class="date"><b>Tags:</b> #delete #fastly #work</small></li>
<li class="gist-entry" id="gist-8660015f338619c7ab9f78e53272ea67"><a href="gists/8660015f338619c7ab9f78e53272ea67.html">Rust: ANSI Escape Code Clear Line </a><br><small class="date"><b>Created:</b> January 27, 2022</small><small class="date"><b>Tags:</b> #rust #ansi</small></li>
<li class="gist-entry" id="gist-3443beeb64e19a62b879739e854ef885"><a href="gists/3443beeb64e19a62b879739e854ef885.html">Terraform: The problem with Terraform's schema.TypeSet </a><br><small class="date"><b>Created:</b> January 27, 2022</small><small class="date"><b>Tags:</b> #terraform</small></li>
<li class="gist-entry" id="gist-3735994921455c0b5f89d5e6899b7052"><a href="gists/3735994921455c0b5f89d5e6899b7052.html">Rust: Packages, Crates, Modules </a><br><small class="date"><b>Created:</b> January 18, 2022</small><small class="date"><b>Tags:</b> #rust #rustlang #learn</small></li>
<li class="gist-entry" id="gist-719c37b2cd00e10554f643787de72d84"><a href="gists/719c37b2cd00e10554f643787de72d84.html">Go: updating a pointer field value </a><br><small class="date"><b>Created:</b> January 11, 2022</small><small class="date"><b>Tags:</b> #go</small></li>
<li class="gist-entry" id="gist-8dd5fee7c884aa2a1bf709de37108e19"><a href="gists/8dd5fee7c884aa2a1bf709de37108e19.html">Go: loop over struct fields </a><br><small class="date"><b>Created:</b> January 7, 2022</small><small class="date"><b>Tags:</b> #go #reflection</small></li>
<li class="gist-entry" id="gist-d203513edc2ef3d5dd28ea6a74bdf0f2"><a href="gists/d203513edc2ef3d5dd28ea6a74bdf0f2.html">Go: Kingpin CLI IsGlobalFlagsOnly </a><br><small class="date"><b>Created:</b> January 6, 2022</small><small class="date"><b>Tags:</b> #go</small></li>
<li class="gist-entry" id="gist-f408726ed8cbe0d29aab3f6704f91ad6"><a href="gists/f408726ed8cbe0d29aab3f6704f91ad6.html">Go: Compile go program for Windows </a><br><small class="date"><b>Created:</b> January 6, 2022</small><small class="date"><b>Tags:</b> #go #compiler #windows</small></li>
<li class="gist-entry" id="gist-889ab6d1d9052f05de06a6b1ecd1c5a1"><a href="gists/889ab6d1d9052f05de06a6b1ecd1c5a1.html">Go: godoc example code generation </a><br><small class="date"><b>Created:</b> January 6, 2022</small><small class="date"><b>Tags:</b> #go</small></li>
<li class="gist-entry" id="gist-eb2b71ea654c1e79ff73b404aff18325"><a href="gists/eb2b71ea654c1e79ff73b404aff18325.html">Go: macOS bug </a><br><small class="date"><b>Created:</b> December 20, 2021</small><small class="date"><b>Tags:</b> #macOS #go #bug</small></li>
<li class="gist-entry" id="gist-47d704a93108414efc522c1a73ddd735"><a href="gists/47d704a93108414efc522c1a73ddd735.html">Rust: Command line utilities written in Rust </a><br><small class="date"><b>Created:</b> December 20, 2021</small><small class="date"><b>Tags:</b> #cli #rust #utilities</small></li>
<li class="gist-entry" id="gist-9f4279bc4b98deebd4a1c27c022d56c1"><a href="gists/9f4279bc4b98deebd4a1c27c022d56c1.html">Terminal: Colour Support </a><br><small class="date"><b>Created:</b> December 20, 2021</small><small class="date"><b>Tags:</b> #perl #terminal #colours</small></li>
<li class="gist-entry" id="gist-fce85a72a28f5a5313002f8c972e883b"><a href="gists/fce85a72a28f5a5313002f8c972e883b.html">Go: thread-safe bytes.Buffer </a><br><small class="date"><b>Created:</b> December 17, 2021</small><small class="date"><b>Tags:</b> #go #concurrency</small></li>
<li class="gist-entry" id="gist-c112bf8c131b4cc4d52e4e237c880383"><a href="gists/c112bf8c131b4cc4d52e4e237c880383.html">Windows: Terminal Development </a><br><small class="date"><b>Created:</b> December 16, 2021</small><small class="date"><b>Tags:</b> #terminals #windows #os #dev #nvim</small></li>
<li class="gist-entry" id="gist-1d13805ac04cd10afaa2252dd144ae8e"><a href="gists/1d13805ac04cd10afaa2252dd144ae8e.html">Writing: Article Notes and Asides </a><br><small class="date"><b>Created:</b> December 15, 2021</small><small class="date"><b>Tags:</b> #writing #notes #asides</small></li>
<li class="gist-entry" id="gist-7de01a8ae89a9b035a22d61535e21230"><a href="gists/7de01a8ae89a9b035a22d61535e21230.html">Go: Generics </a><br><small class="date"><b>Created:</b> December 15, 2021</small><small class="date"><b>Tags:</b> #go #generics</small></li>
<li class="gist-entry" id="gist-c9c14aea7f6aed97840eaea2b5c14fdd"><a href="gists/c9c14aea7f6aed97840eaea2b5c14fdd.html">Shell: Short one line Bash if else statement </a><br><small class="date"><b>Created:</b> December 14, 2021</small><small class="date"><b>Tags:</b> #bash #shell #if #conditional</small></li>
<li class="gist-entry" id="gist-01aed051251476c4bd6daa4b076eb23a"><a href="gists/01aed051251476c4bd6daa4b076eb23a.html">Python: progress bar </a><br><small class="date"><b>Created:</b> December 8, 2021</small><small class="date"><b>Tags:</b> #python #python3 #ansi #escape #progress</small></li>
<li class="gist-entry" id="gist-0a6472a5b08f468c2d7697a4ef5b807d"><a href="gists/0a6472a5b08f468c2d7697a4ef5b807d.html">Git: stage hunks for untracked files in git </a><br><small class="date"><b>Created:</b> December 8, 2021</small><small class="date"><b>Tags:</b> #git #patch #staged #untracked</small></li>
<li class="gist-entry" id="gist-53303137d6dbb4ecc80a0384f29eb051"><a href="gists/53303137d6dbb4ecc80a0384f29eb051.html">Python: download YouTube Videos </a><br><small class="date"><b>Created:</b> December 8, 2021</small><small class="date"><b>Tags:</b> #python #python3 #pytube #youtube #download</small></li>
<li class="gist-entry" id="gist-2489824d4d9c59444c2478683034a141"><a href="gists/2489824d4d9c59444c2478683034a141.html">Go: cross platform subprocess </a><br><small class="date"><b>Created:</b> November 25, 2021</small><small class="date"><b>Tags:</b> #go #windows #macos</small></li>
<li class="gist-entry" id="gist-30ce5612ba4883f2de9ba69cfa51cc3d"><a href="gists/30ce5612ba4883f2de9ba69cfa51cc3d.html">Bash: moreutils examples </a><br><small class="date"><b>Created:</b> November 18, 2021</small><small class="date"><b>Tags:</b> #bash #moreutils #shell</small></li>
<li class="gist-entry" id="gist-b78bcff09166a8dea9cabfcd7af96383"><a href="gists/b78bcff09166a8dea9cabfcd7af96383.html">Go: sharing behaviours between individual structs and a base struct </a><br><small class="date"><b>Created:</b> November 18, 2021</small><small class="date"><b>Tags:</b> #go #principles</small></li>
<li class="gist-entry" id="gist-6a33445b768888f6b9869b1516428bb3"><a href="gists/6a33445b768888f6b9869b1516428bb3.html">Shell: jq and yq examples </a><br><small class="date"><b>Created:</b> November 15, 2021</small><small class="date"><b>Tags:</b> #jq #yq #shell #bash #json</small></li>
<li class="gist-entry" id="gist-deb63f56bb6178493b0b378d89030cb9"><a href="gists/deb63f56bb6178493b0b378d89030cb9.html">Go: recursive function </a><br><small class="date"><b>Created:</b> November 15, 2021</small><small class="date"><b>Tags:</b> #go #recursive</small></li>
<li class="gist-entry" id="gist-858a88f5925a10aa71c4db78863958a3"><a href="gists/858a88f5925a10aa71c4db78863958a3.html">Go: form encoding with various packages </a><br><small class="date"><b>Created:</b> November 2, 2021</small><small class="date"><b>Tags:</b> #go #serialization</small></li>
<li class="gist-entry" id="gist-06d2d5f896a3939ce208f37f2c2c2d05"><a href="gists/06d2d5f896a3939ce208f37f2c2c2d05.html">Go: Replace Makefile with Taskfile </a><br><small class="date"><b>Created:</b> November 1, 2021</small><small class="date"><b>Tags:</b> #go #build</small></li>
<li class="gist-entry" id="gist-f21d57a8fcada8d4c2ac79bece4337b4"><a href="gists/f21d57a8fcada8d4c2ac79bece4337b4.html">Go: Cross Compile Binary </a><br><small class="date"><b>Created:</b> October 22, 2021</small><small class="date"><b>Tags:</b> #go #compiler #build</small></li>
<li class="gist-entry" id="gist-bfa2372133bf8297072eeb6621ffd290"><a href="gists/bfa2372133bf8297072eeb6621ffd290.html">Go: Understanding AST parser </a><br><small class="date"><b>Created:</b> October 18, 2021</small><small class="date"><b>Tags:</b> #AST</small></li>
<li class="gist-entry" id="gist-0500e6b5aabf95034cd83eff8c9e2ead"><a href="gists/0500e6b5aabf95034cd83eff8c9e2ead.html">Shell: autocomplete for your custom programs </a><br><small class="date"><b>Created:</b> October 14, 2021</small><small class="date"><b>Tags:</b> #bash #shell #autocomplete</small></li>
<li class="gist-entry" id="gist-9b02493b0b2d54eeea0183c28edab2d1"><a href="gists/9b02493b0b2d54eeea0183c28edab2d1.html">Network: BGP Debugging Tools </a><br><small class="date"><b>Created:</b> October 13, 2021</small><small class="date"><b>Tags:</b> #bgp #network</small></li>
<li class="gist-entry" id="gist-685d23c8e8ced3afb1a4e4546f2933d6"><a href="gists/685d23c8e8ced3afb1a4e4546f2933d6.html">Go: CLI progress spinner </a><br><small class="date"><b>Created:</b> October 7, 2021</small><small class="date"><b>Tags:</b> #go #tty</small></li>
<li class="gist-entry" id="gist-20060a9be3eafcdfd3c13c1d120bee97"><a href="gists/20060a9be3eafcdfd3c13c1d120bee97.html">Go: Enums </a><br><small class="date"><b>Created:</b> October 7, 2021</small><small class="date"><b>Tags:</b> #go</small></li>
<li class="gist-entry" id="gist-157a91212e785d7d78544314622c5c24"><a href="gists/157a91212e785d7d78544314622c5c24.html">git: --theirs and --ours </a><br><small class="date"><b>Created:</b> October 7, 2021</small><small class="date"><b>Tags:</b> #git #rebase #merge</small></li>
<li class="gist-entry" id="gist-7ea8e0f8bf5d958f67e4915d68f6b153"><a href="gists/7ea8e0f8bf5d958f67e4915d68f6b153.html">Design: nice fonts </a><br><small class="date"><b>Created:</b> October 6, 2021</small><small class="date"><b>Tags:</b> #fonts</small></li>
<li class="gist-entry" id="gist-639f8418c2bec1721dd55723c3344e04"><a href="gists/639f8418c2bec1721dd55723c3344e04.html">JS: streaming server response </a><br><small class="date"><b>Created:</b> October 6, 2021</small><small class="date"><b>Tags:</b> #js #javascript #stream</small></li>
<li class="gist-entry" id="gist-845c4cbb4badfd43fe11dc1b1bba2eb4"><a href="gists/845c4cbb4badfd43fe11dc1b1bba2eb4.html">Go: unzip(.zip) and untar(.tar.gz) contents of archive to specified destination </a><br><small class="date"><b>Created:</b> October 6, 2021</small><small class="date"><b>Tags:</b> #go</small></li>
<li class="gist-entry" id="gist-6f8aab46f67b5dcff33e1974c8127c52"><a href="gists/6f8aab46f67b5dcff33e1974c8127c52.html">Go: Custom Error Log Abstraction </a><br><small class="date"><b>Created:</b> October 6, 2021</small><small class="date"><b>Tags:</b> #go #errors #logs</small></li>
<li class="gist-entry" id="gist-148f6285e74786dcbdc208b83f047aee"><a href="gists/148f6285e74786dcbdc208b83f047aee.html">Zig: Install LSP </a><br><small class="date"><b>Created:</b> October 5, 2021</small><small class="date"><b>Tags:</b> #lsp #zig #zls</small></li>
<li class="gist-entry" id="gist-a9ea0a57f95639a8e18c5bc78586888d"><a href="gists/a9ea0a57f95639a8e18c5bc78586888d.html">Compiler: Understanding linker files </a><br><small class="date"><b>Created:</b> October 5, 2021</small><small class="date"><b>Tags:</b> #system #c #compiler #linker</small></li>
<li class="gist-entry" id="gist-06be2e6f79e2120284c2613b4eeb260d"><a href="gists/06be2e6f79e2120284c2613b4eeb260d.html">GPG: Fixing GPG and Agent Errors </a><br><small class="date"><b>Created:</b> October 1, 2021</small><small class="date"><b>Tags:</b> #gpg #gpgagent #agent #pass</small></li>
<li class="gist-entry" id="gist-cc610e9cf70c6a52042cc3ae9a7ba97e"><a href="gists/cc610e9cf70c6a52042cc3ae9a7ba97e.html">Go: text indenting </a><br><small class="date"><b>Created:</b> September 24, 2021</small><small class="date"><b>Tags:</b> #go #tty</small></li>
<li class="gist-entry" id="gist-fab775b0e7071281a206673356f80530"><a href="gists/fab775b0e7071281a206673356f80530.html">Go: Complex mapstructure example </a><br><small class="date"><b>Created:</b> September 22, 2021</small><small class="date"><b>Tags:</b> #go #serialization</small></li>
<li class="gist-entry" id="gist-2d59134acebbc909ec7eb56ff93310c3"><a href="gists/2d59134acebbc909ec7eb56ff93310c3.html">Security: Confidentiality, Integrity, Availability, and the Factors of Authentication </a><br><small class="date"><b>Created:</b> September 21, 2021</small><small class="date"><b>Tags:</b> #security #confidentiality #integrity #availability</small></li>
<li class="gist-entry" id="gist-38c5c64704649231515129743b1e4033"><a href="gists/38c5c64704649231515129743b1e4033.html">Git: restore and switch to replace git checkout </a><br><small class="date"><b>Created:</b> September 3, 2021</small><small class="date"><b>Tags:</b> #git</small></li>
<li class="gist-entry" id="gist-57f24924f7100ee06e0032240f0cb70c"><a href="gists/57f24924f7100ee06e0032240f0cb70c.html">Vim: search multiple lines with line breaks using PCRE_DOTALL mode </a><br><small class="date"><b>Created:</b> September 2, 2021</small><small class="date"><b>Tags:</b> #silversearcher #ag #ack #grep #PCRE #regex #vim #lookahead #ripgrep</small></li>
<li class="gist-entry" id="gist-a959a200de07caffbc826b2cd415e6df"><a href="gists/a959a200de07caffbc826b2cd415e6df.html">Vim: Tips </a><br><small class="date"><b>Created:</b> September 2, 2021</small><small class="date"><b>Tags:</b> #vim #tips #tricks</small></li>
<li class="gist-entry" id="gist-2d04049c8d13189f0893e5b295d30daa"><a href="gists/2d04049c8d13189f0893e5b295d30daa.html">Rust: setup toolchain environment </a><br><small class="date"><b>Created:</b> August 17, 2021</small><small class="date"><b>Tags:</b> #rust #rustlang #environment #overrides #toolchain</small></li>
<li class="gist-entry" id="gist-190c817aa46200e13e4b4b88391e5479"><a href="gists/190c817aa46200e13e4b4b88391e5479.html">Go: mocking multiple stdin prompts </a><br><small class="date"><b>Created:</b> August 6, 2021</small><small class="date"><b>Tags:</b> #go #tty</small></li>
<li class="gist-entry" id="gist-d2542276df2302d2e7a0475e6d58e816"><a href="gists/d2542276df2302d2e7a0475e6d58e816.html">Shell: xarg examples </a><br><small class="date"><b>Created:</b> August 4, 2021</small><small class="date"><b>Tags:</b> #xargs #bash #shell</small></li>
<li class="gist-entry" id="gist-8c0140da58fd6575373f6f1d98367170"><a href="gists/8c0140da58fd6575373f6f1d98367170.html">Go: difference between URL host and Request Header Host </a><br><small class="date"><b>Created:</b> July 29, 2021</small><small class="date"><b>Tags:</b> #go #http</small></li>
<li class="gist-entry" id="gist-87742ba01bb58be8b0e293b5ba3fbfd3"><a href="gists/87742ba01bb58be8b0e293b5ba3fbfd3.html">Vim: word motion to be camelcase sensitive </a><br><small class="date"><b>Created:</b> July 27, 2021</small><small class="date"><b>Tags:</b> #vim #viml</small></li>
<li class="gist-entry" id="gist-6772c8861b1fb7dadc2a816e14e1fdf9"><a href="gists/6772c8861b1fb7dadc2a816e14e1fdf9.html">Go: API JSON with empy vs null fields issues </a><br><small class="date"><b>Created:</b> June 23, 2021</small><small class="date"><b>Tags:</b> #go #json #api</small></li>
<li class="gist-entry" id="gist-6d63e271c9301627d560b4786f629cac"><a href="gists/6d63e271c9301627d560b4786f629cac.html">Writing: kbd vs code vs pre vs samp </a><br><small class="date"><b>Created:</b> June 22, 2021</small><small class="date"><b>Tags:</b> #kbd #markup #render #code</small></li>
<li class="gist-entry" id="gist-ec8ec475cc168620355bdca28d928e56"><a href="gists/ec8ec475cc168620355bdca28d928e56.html">PHP: setup Composer with local code </a><br><small class="date"><b>Created:</b> June 10, 2021</small><small class="date"><b>Tags:</b> #php #composer #local</small></li>
<li class="gist-entry" id="gist-3097838786e069c33afe668ae767a367"><a href="gists/3097838786e069c33afe668ae767a367.html">Go: type asserting/coercing </a><br><small class="date"><b>Created:</b> June 8, 2021</small><small class="date"><b>Tags:</b> #go </small></li>
<li class="gist-entry" id="gist-ef5eb39ec34f5b8734bd81958be3a5e1"><a href="gists/ef5eb39ec34f5b8734bd81958be3a5e1.html">Go: embed static file inside of compiled binary </a><br><small class="date"><b>Created:</b> June 2, 2021</small><small class="date"><b>Tags:</b> #go</small></li>
<li class="gist-entry" id="gist-8a9cb8924f75ae42487fd877b03360e2"><a href="gists/8a9cb8924f75ae42487fd877b03360e2.html">Go: timeouts and custom http client </a><br><small class="date"><b>Created:</b> June 2, 2021</small><small class="date"><b>Tags:</b> #go #http #dns</small></li>
<li class="gist-entry" id="gist-baa244ccb85f1e67044136f6e2f71001"><a href="gists/baa244ccb85f1e67044136f6e2f71001.html">Git: multiple branches </a><br><small class="date"><b>Created:</b> June 2, 2021</small><small class="date"><b>Tags:</b> #git</small></li>
<li class="gist-entry" id="gist-0058659d37c2bf0691cc7bde8c9579c3"><a href="gists/0058659d37c2bf0691cc7bde8c9579c3.html">Go: nested struct embedding </a><br><small class="date"><b>Created:</b> May 25, 2021</small><small class="date"><b>Tags:</b> #go</small></li>
<li class="gist-entry" id="gist-525f7cf4683e67fc90f1e2b7a917cbfe"><a href="gists/525f7cf4683e67fc90f1e2b7a917cbfe.html">Go: reverse slice loop </a><br><small class="date"><b>Created:</b> May 25, 2021</small><small class="date"><b>Tags:</b> #go</small></li>
<li class="gist-entry" id="gist-129d30f3fff68667bb1a1f778f90ab7a"><a href="gists/129d30f3fff68667bb1a1f778f90ab7a.html">Python: Run Python tests using -m</a><br><small class="date"><b>Created:</b> May 24, 2021</small></li>
<li class="gist-entry" id="gist-74652e4486141a802c4e65803649cfe0"><a href="gists/74652e4486141a802c4e65803649cfe0.html">Vim: filter quickfix/location list results </a><br><small class="date"><b>Created:</b> May 20, 2021</small><small class="date"><b>Tags:</b> #vim #filter #quickfix #locationlist</small></li>
<li class="gist-entry" id="gist-32a615581c9d0af1b5f53f4f9ba64607"><a href="gists/32a615581c9d0af1b5f53f4f9ba64607.html">Vim: programming autocomplete with no plugins </a><br><small class="date"><b>Created:</b> May 19, 2021</small><small class="date"><b>Tags:</b> #vim #autocomplete</small></li>
<li class="gist-entry" id="gist-c6a3d8f06d1da7af9706b3c741edd544"><a href="gists/c6a3d8f06d1da7af9706b3c741edd544.html">Go: Useful tools to run over your project </a><br><small class="date"><b>Created:</b> May 17, 2021</small><small class="date"><b>Tags:</b> #go #linting</small></li>
<li class="gist-entry" id="gist-58784fe99234f095bfbae7ea509bd8f2"><a href="gists/58784fe99234f095bfbae7ea509bd8f2.html">API vs ABI </a><br><small class="date"><b>Created:</b> May 11, 2021</small><small class="date"><b>Tags:</b> #API #ABI</small></li>
<li class="gist-entry" id="gist-e319a258695531ef683077e677904156"><a href="gists/e319a258695531ef683077e677904156.html">Fastly: Terraform CLI with Terraform </a><br><small class="date"><b>Created:</b> May 7, 2021</small><small class="date"><b>Tags:</b> #fastly #cli #terraform #wasm</small></li>
<li class="gist-entry" id="gist-27e6c7a74957186916d9a0fa0adc697f"><a href="gists/27e6c7a74957186916d9a0fa0adc697f.html">Organizational Values </a><br><small class="date"><b>Created:</b> May 7, 2021</small><small class="date"><b>Tags:</b> #values</small></li>
<li class="gist-entry" id="gist-5df830bae2bc2883b998625af743e041"><a href="gists/5df830bae2bc2883b998625af743e041.html">The Benefits of Diversity </a><br><small class="date"><b>Created:</b> May 6, 2021</small><small class="date"><b>Tags:</b> #diversity</small></li>
<li class="gist-entry" id="gist-7c694e98c7da5ae1bd034e9c23ae9ea0"><a href="gists/7c694e98c7da5ae1bd034e9c23ae9ea0.html">Go: Style Guide </a><br><small class="date"><b>Created:</b> April 28, 2021</small><small class="date"><b>Tags:</b> #go #guides</small></li>
<li class="gist-entry" id="gist-bd980df3edc046a3a461db670f1d2989"><a href="gists/bd980df3edc046a3a461db670f1d2989.html">Docker: Dockerised Fastly CLI </a><br><small class="date"><b>Created:</b> April 23, 2021</small><small class="date"><b>Tags:</b> #docker #fastly #cli #shasum #awk #regex #rust</small></li>
<li class="gist-entry" id="gist-5438adc0f4862c809264e1d151560563"><a href="gists/5438adc0f4862c809264e1d151560563.html">Yaml: merge key and reference pointer </a><br><small class="date"><b>Created:</b> April 20, 2021</small><small class="date"><b>Tags:</b> #yaml #syntax #dereference #pointer #merge</small></li>
<li class="gist-entry" id="gist-39338a06a94dfea93c652cb664f5148a"><a href="gists/39338a06a94dfea93c652cb664f5148a.html">Go: TOML Examples with custom Marshaller </a><br><small class="date"><b>Created:</b> April 20, 2021</small><small class="date"><b>Tags:</b> #go #serialization</small></li>
<li class="gist-entry" id="gist-cbf2814b2565b540fdf986d4975a007a"><a href="gists/cbf2814b2565b540fdf986d4975a007a.html">Go: panic vs os.Exit </a><br><small class="date"><b>Created:</b> April 19, 2021</small><small class="date"><b>Tags:</b> #go #guides</small></li>
<li class="gist-entry" id="gist-c78c6b991fdde95919721927d6995872"><a href="gists/c78c6b991fdde95919721927d6995872.html">Terraform: ignore_changes </a><br><small class="date"><b>Created:</b> April 15, 2021</small><small class="date"><b>Tags:</b> #terraform #tf</small></li>
<li class="gist-entry" id="gist-68501b147bfea6060043b380f749c073"><a href="gists/68501b147bfea6060043b380f749c073.html">Go: Install the Go programming language (with multiple versions + installing binaries) </a><br><small class="date"><b>Created:</b> April 14, 2021</small><small class="date"><b>Tags:</b> #go #install</small></li>
<li class="gist-entry" id="gist-8b603ac63dd84f4f2efc16d671e5db22"><a href="gists/8b603ac63dd84f4f2efc16d671e5db22.html">Go: signal handling SIGINT/SIGTERM of a subprocess </a><br><small class="date"><b>Created:</b> April 13, 2021</small><small class="date"><b>Tags:</b> #go</small></li>
<li class="gist-entry" id="gist-e47ac6d674c246d77e69d55e03c6b121"><a href="gists/e47ac6d674c246d77e69d55e03c6b121.html">Go: handle long running process </a><br><small class="date"><b>Created:</b> April 13, 2021</small><small class="date"><b>Tags:</b> #go</small></li>
<li class="gist-entry" id="gist-17a7cb39505d8949bea14cd30fec5738"><a href="gists/17a7cb39505d8949bea14cd30fec5738.html">Go: new vs make </a><br><small class="date"><b>Created:</b> April 8, 2021</small><small class="date"><b>Tags:</b> #go #performance</small></li>
<li class="gist-entry" id="gist-3aa30eea6ec1fdd3874e130b84bfb6a9"><a href="gists/3aa30eea6ec1fdd3874e130b84bfb6a9.html">Go: prepend line to stop of a file that uses toml marshal </a><br><small class="date"><b>Created:</b> April 8, 2021</small><small class="date"><b>Tags:</b> #go #serialization</small></li>
<li class="gist-entry" id="gist-e23fe5cd55e87cf3043c1c32322640fa"><a href="gists/e23fe5cd55e87cf3043c1c32322640fa.html">Go: Application Design </a><br><small class="date"><b>Created:</b> April 7, 2021</small><small class="date"><b>Tags:</b> #go #guide</small></li>
<li class="gist-entry" id="gist-ac32f8f42244171183c5142a624c741d"><a href="gists/ac32f8f42244171183c5142a624c741d.html">Go: syntax differences with Rust </a><br><small class="date"><b>Created:</b> March 31, 2021</small><small class="date"><b>Tags:</b> #go #rust</small></li>
<li class="gist-entry" id="gist-41e6946a23a73022a84d5b383949faf9"><a href="gists/41e6946a23a73022a84d5b383949faf9.html">S3: backend for Terraform </a><br><small class="date"><b>Created:</b> March 31, 2021</small><small class="date"><b>Tags:</b> #terraform #s3</small></li>
<li class="gist-entry" id="gist-d9c2aae82f3442d35ebc16b7ac372ce6"><a href="gists/d9c2aae82f3442d35ebc16b7ac372ce6.html">Vim: replace document quotations with monospace equivalent </a><br><small class="date"><b>Created:</b> March 30, 2021</small><small class="date"><b>Tags:</b> #vim #quotes #monospace #substitution</small></li>
<li class="gist-entry" id="gist-f28a60096c46b59226e60bc590126516"><a href="gists/f28a60096c46b59226e60bc590126516.html">Fastly: Terraform Workspace example </a><br><small class="date"><b>Created:</b> March 30, 2021</small><small class="date"><b>Tags:</b> #fastly #terraform #hcl #workspace</small></li>
<li class="gist-entry" id="gist-864f134dfdcd8715b3a03addefdc3b13"><a href="gists/864f134dfdcd8715b3a03addefdc3b13.html">Fastly: Terraform Multiple Environments using Modules </a><br><small class="date"><b>Created:</b> March 30, 2021</small><small class="date"><b>Tags:</b> #terraform #environments #hcl #fastly</small></li>
<li class="gist-entry" id="gist-248aa0436d281e3cd44debaf7d83441d"><a href="gists/248aa0436d281e3cd44debaf7d83441d.html">Go: compile Rust program via shell to Cargo </a><br><small class="date"><b>Created:</b> March 30, 2021</small><small class="date"><b>Tags:</b> #go #rust #compiler</small></li>
<li class="gist-entry" id="gist-08fc2d98b3906fcd24ba4fd56473103d"><a href="gists/08fc2d98b3906fcd24ba4fd56473103d.html">Rust: Print the type of a reference </a><br><small class="date"><b>Created:</b> March 28, 2021</small><small class="date"><b>Tags:</b> #rust #type #reflection</small></li>
<li class="gist-entry" id="gist-dee6daacb1972b97d56aa170e518c160"><a href="gists/dee6daacb1972b97d56aa170e518c160.html">Terraform: Modules for structuring your resources </a><br><small class="date"><b>Created:</b> March 26, 2021</small><small class="date"><b>Tags:</b> #terraform #modules #fastly</small></li>
<li class="gist-entry" id="gist-b6ab05389128723d004c339b2769a485"><a href="gists/b6ab05389128723d004c339b2769a485.html">Shell: Repeat a single character N times </a><br><small class="date"><b>Created:</b> March 25, 2021</small><small class="date"><b>Tags:</b> #bash #shell #repeat</small></li>
<li class="gist-entry" id="gist-24767b93df2f368c333ca0ba54ce0e13"><a href="gists/24767b93df2f368c333ca0ba54ce0e13.html">Terraform: Fastly C@E Service </a><br><small class="date"><b>Created:</b> March 24, 2021</small><small class="date"><b>Tags:</b> #terraform #fastly #compute #serverless #edge</small></li>
<li class="gist-entry" id="gist-d927ec1a82d4e4594279dcedebff78d2"><a href="gists/d927ec1a82d4e4594279dcedebff78d2.html">Rust: Ownership, Borrowing, Lifetimes </a><br><small class="date"><b>Created:</b> March 23, 2021</small><small class="date"><b>Tags:</b> #rust #rustlang #ownership #memory</small></li>
<li class="gist-entry" id="gist-3427d0defce6e1ed8f09aaa2f2ab7f6a"><a href="gists/3427d0defce6e1ed8f09aaa2f2ab7f6a.html">Memory: The Stack and the Heap </a><br><small class="date"><b>Created:</b> March 22, 2021</small><small class="date"><b>Tags:</b> #stack #heap #memory</small></li>
<li class="gist-entry" id="gist-d47c2e8c6064ec065108ad59df6e1fb9"><a href="gists/d47c2e8c6064ec065108ad59df6e1fb9.html">Go: custom Unmarshal using json.RawMessage </a><br><small class="date"><b>Created:</b> March 19, 2021</small><small class="date"><b>Tags:</b> #go #json #serialization</small></li>
<li class="gist-entry" id="gist-c29ff647e5fb2f5c5001aa50a9288d8f"><a href="gists/c29ff647e5fb2f5c5001aa50a9288d8f.html">Go: remove line from file </a><br><small class="date"><b>Created:</b> March 19, 2021</small><small class="date"><b>Tags:</b> #go</small></li>
<li class="gist-entry" id="gist-d2f688fbb20879daa130c0a9b9517a21"><a href="gists/d2f688fbb20879daa130c0a9b9517a21.html">Go: custom toml unmarshal wrapper for string to int </a><br><small class="date"><b>Created:</b> March 10, 2021</small><small class="date"><b>Tags:</b> #go #serialization</small></li>
<li class="gist-entry" id="gist-916a82907c7a14c64df41f32c5c45a2a"><a href="gists/916a82907c7a14c64df41f32c5c45a2a.html">Network: Quick Fastly Logging Endpoint in Terminal </a><br><small class="date"><b>Created:</b> March 9, 2021</small><small class="date"><b>Tags:</b> #fastly #logging #terminal #shell #ngrok #netcat</small></li>
<li class="gist-entry" id="gist-b94c8945ac6f8c9a9ef888efed6c8cb4"><a href="gists/b94c8945ac6f8c9a9ef888efed6c8cb4.html">Terraform: Modules </a><br><small class="date"><b>Created:</b> March 3, 2021</small><small class="date"><b>Tags:</b> #terraform #tf #modules</small></li>
<li class="gist-entry" id="gist-982fe71b4f8aedebed83bed8474f1876"><a href="gists/982fe71b4f8aedebed83bed8474f1876.html">Terraform: Fastly Service] </a><br><small class="date"><b>Created:</b> March 3, 2021</small><small class="date"><b>Tags:</b> #fastly #terraform</small></li>
<li class="gist-entry" id="gist-8f39eb897316e1cbeaf9eff8326cfa59"><a href="gists/8f39eb897316e1cbeaf9eff8326cfa59.html">Go: Code Generation </a><br><small class="date"><b>Created:</b> February 25, 2021</small><small class="date"><b>Tags:</b> #go</small></li>
<li class="gist-entry" id="gist-b7e8b3529871b18c1adb69ae40ccb118"><a href="gists/b7e8b3529871b18c1adb69ae40ccb118.html">Go: Debugging with Delve </a><br><small class="date"><b>Created:</b> February 23, 2021</small><small class="date"><b>Tags:</b> #go #debugging</small></li>
<li class="gist-entry" id="gist-f2e55ede1b6dcb772cf572cba6f52745"><a href="gists/f2e55ede1b6dcb772cf572cba6f52745.html">Vim: Display number of windows, buffers, tabs </a><br><small class="date"><b>Created:</b> February 16, 2021</small><small class="date"><b>Tags:</b> #vim #display #count #windows #buffers #tabs</small></li>
<li class="gist-entry" id="gist-28ea658092a78306071c46aebd56c607"><a href="gists/28ea658092a78306071c46aebd56c607.html">API: OpenAPI Generator </a><br><small class="date"><b>Created:</b> February 9, 2021</small><small class="date"><b>Tags:</b> #openapi #api #generator</small></li>
<li class="gist-entry" id="gist-5268eb6a9ea56aeb9bea1b362e1b7036"><a href="gists/5268eb6a9ea56aeb9bea1b362e1b7036.html">Vim: pretty print json </a><br><small class="date"><b>Created:</b> February 5, 2021</small><small class="date"><b>Tags:</b> #vim #json #pretty #print</small></li>
<li class="gist-entry" id="gist-a510abba8319923bca889c8c22f73f9a"><a href="gists/a510abba8319923bca889c8c22f73f9a.html">Terraform: Provider Local Dev Environment </a><br><small class="date"><b>Created:</b> February 4, 2021</small><small class="date"><b>Tags:</b> #terraform #tf #local #dev #environment</small></li>
<li class="gist-entry" id="gist-6aacefc40dbde3d39a17c4813721f063"><a href="gists/6aacefc40dbde3d39a17c4813721f063.html">Go: manage external tools via go modules </a><br><small class="date"><b>Created:</b> February 2, 2021</small><small class="date"><b>Tags:</b> #go #dependencies</small></li>
<li class="gist-entry" id="gist-9434e6fa5977f9626b470b46a0d02149"><a href="gists/9434e6fa5977f9626b470b46a0d02149.html">CI: Github Action Workflow Example </a><br><small class="date"><b>Created:</b> February 1, 2021</small><small class="date"><b>Tags:</b> #github #git #actions #workflows</small></li>
<li class="gist-entry" id="gist-aa651c6fdaf812b6ba7e3d04193b6434"><a href="gists/aa651c6fdaf812b6ba7e3d04193b6434.html">Go: defer with os.Exit(N) </a><br><small class="date"><b>Created:</b> January 29, 2021</small><small class="date"><b>Tags:</b> #go</small></li>
<li class="gist-entry" id="gist-10491f2601ffdd6bec306554470c6b0e"><a href="gists/10491f2601ffdd6bec306554470c6b0e.html">Go: Make directory if it does not exist </a><br><small class="date"><b>Created:</b> January 28, 2021</small><small class="date"><b>Tags:</b> #go</small></li>
<li class="gist-entry" id="gist-6c57675906fd4c0e8895092e8ea1ea1c"><a href="gists/6c57675906fd4c0e8895092e8ea1ea1c.html">Shell: rename multiple files extension </a><br><small class="date"><b>Created:</b> January 25, 2021</small><small class="date"><b>Tags:</b> #bash #rename #extension</small></li>
<li class="gist-entry" id="gist-e19c9faee86e797125e6d95fe1188912"><a href="gists/e19c9faee86e797125e6d95fe1188912.html">Go: development tools as dependencies </a><br><small class="date"><b>Created:</b> January 25, 2021</small><small class="date"><b>Tags:</b> #go #dependencies</small></li>
<li class="gist-entry" id="gist-f6ec67152756d7d40476159a9094e4ee"><a href="gists/f6ec67152756d7d40476159a9094e4ee.html">Terraform: what should and shouldn't be there </a><br><small class="date"><b>Created:</b> January 13, 2021</small><small class="date"><b>Tags:</b> #tf #terraform #fastly</small></li>
<li class="gist-entry" id="gist-8d01300efcd2006c69e8b9492c0eada8"><a href="gists/8d01300efcd2006c69e8b9492c0eada8.html">Vim: search and replace content using native vim cdo and cfdo commands </a><br><small class="date"><b>Created:</b> January 5, 2021</small><small class="date"><b>Tags:</b> #vim #replace #macro #quickfix</small></li>
<li class="gist-entry" id="gist-a694cd1c562debbe1521dfadfc8be428"><a href="gists/a694cd1c562debbe1521dfadfc8be428.html">Go: Deleting go package tagged versions from pkg.go.dev </a><br><small class="date"><b>Created:</b> January 4, 2021</small><small class="date"><b>Tags:</b> #go</small></li>
<li class="gist-entry" id="gist-ff4d3d93d2ff71ea5ab33a091713c053"><a href="gists/ff4d3d93d2ff71ea5ab33a091713c053.html">Go: Developing local golang module </a><br><small class="date"><b>Created:</b> December 30, 2020</small><small class="date"><b>Tags:</b> #go #dependencies</small></li>
<li class="gist-entry" id="gist-ed24ece9ee958b873b5cedb28ce8aa84"><a href="gists/ed24ece9ee958b873b5cedb28ce8aa84.html">Terminal: Colors </a><br><small class="date"><b>Created:</b> December 16, 2020</small><small class="date"><b>Tags:</b> #terminal #colors</small></li>
<li class="gist-entry" id="gist-9a3027470353be5e89c385f4d6954680"><a href="gists/9a3027470353be5e89c385f4d6954680.html">Make: environment variables and passing values to make target </a><br><small class="date"><b>Created:</b> December 11, 2020</small><small class="date"><b>Tags:</b> #make #makefile #args #env #vars</small></li>
<li class="gist-entry" id="gist-7e6342f53056257d375a8f525120802b"><a href="gists/7e6342f53056257d375a8f525120802b.html">Shell: Google Doc Code Syntax Highlighting </a><br><small class="date"><b>Created:</b> November 20, 2020</small><small class="date"><b>Tags:</b> #google #doc #code #syntax #brew #highlight</small></li>
<li class="gist-entry" id="gist-c0933883cc79aa0d84162d839cfc6253"><a href="gists/c0933883cc79aa0d84162d839cfc6253.html">Go: Populate or update pkg.go.dev with new package </a><br><small class="date"><b>Created:</b> November 18, 2020</small><small class="date"><b>Tags:</b> #go #dependencies</small></li>
<li class="gist-entry" id="gist-06bd3469e3958b9b4481d197b0fc93f1"><a href="gists/06bd3469e3958b9b4481d197b0fc93f1.html">Security: Encryption, Hashing, Signatures </a><br><small class="date"><b>Created:</b> November 12, 2020</small><small class="date"><b>Tags:</b> #security #sec #encryption #hash #signatures #hmac</small></li>
<li class="gist-entry" id="gist-a6e36f6b32573242f0b21918a4c56a27"><a href="gists/a6e36f6b32573242f0b21918a4c56a27.html">Ruby: RVM </a><br><small class="date"><b>Created:</b> November 11, 2020</small><small class="date"><b>Tags:</b> #ruby #rvm</small></li>
<li class="gist-entry" id="gist-5e0bd295c7db33c7900876fa934949e2"><a href="gists/5e0bd295c7db33c7900876fa934949e2.html">CLI: terminology and design guidelines </a><br><small class="date"><b>Created:</b> November 11, 2020</small><small class="date"><b>Tags:</b> #cli #terminology #flags #arguments #args #options #design #guidelines #clap</small></li>
<li class="gist-entry" id="gist-0040b2e6d80765b956c5b1e12613e58e"><a href="gists/0040b2e6d80765b956c5b1e12613e58e.html">GPG: Github Commit Signing Key </a><br><small class="date"><b>Created:</b> November 3, 2020</small><small class="date"><b>Tags:</b> #gpg #github #commit #sign #key</small></li>
<li class="gist-entry" id="gist-61c77417bc253aac77e853ecbf206cb1"><a href="gists/61c77417bc253aac77e853ecbf206cb1.html">Rust: Book Examples </a><br><small class="date"><b>Created:</b> November 2, 2020</small><small class="date"><b>Tags:</b> #rust #rng</small></li>
<li class="gist-entry" id="gist-975d099da6aad2373b225b7713d20a7c"><a href="gists/975d099da6aad2373b225b7713d20a7c.html">Export Private GPG Key </a><br><small class="date"><b>Created:</b> October 27, 2020</small><small class="date"><b>Tags:</b> #gpg #keys #backup</small></li>
<li class="gist-entry" id="gist-05e5415de6743e66b112574a1a5c1970"><a href="gists/05e5415de6743e66b112574a1a5c1970.html">Laptop: Configuration Summary </a><br><small class="date"><b>Created:</b> October 11, 2020</small><small class="date"><b>Tags:</b> #new #laptop #configuration #macos</small></li>
<li class="gist-entry" id="gist-711796e832db34e19c93e4fd106c6383"><a href="gists/711796e832db34e19c93e4fd106c6383.html">CRDT: conflict-free replicated data type </a><br><small class="date"><b>Created:</b> October 2, 2020</small><small class="date"><b>Tags:</b> #crdt #distributed</small></li>
<li class="gist-entry" id="gist-9975d87f2aef9bd1f3e6fcfdf23f75dd"><a href="gists/9975d87f2aef9bd1f3e6fcfdf23f75dd.html">Python: install package directly for the interpreter Vim is using </a><br><small class="date"><b>Created:</b> October 2, 2020</small><small class="date"><b>Tags:</b> #vim #python</small></li>
<li class="gist-entry" id="gist-d6e750eb89d4a3e97bed37b80abe6e4d"><a href="gists/d6e750eb89d4a3e97bed37b80abe6e4d.html">Shell: Curl to JSON </a><br><small class="date"><b>Created:</b> October 2, 2020</small><small class="date"><b>Tags:</b> #curl #bash #shell #json</small></li>
<li class="gist-entry" id="gist-428cb45b94290c72adc5c9e5af27a58f"><a href="gists/428cb45b94290c72adc5c9e5af27a58f.html">Python: tornado logging when request has completed </a><br><small class="date"><b>Created:</b> September 25, 2020</small><small class="date"><b>Tags:</b> #python #logs</small></li>
<li class="gist-entry" id="gist-752e8620783d7507af9130e1954cf6f7"><a href="gists/752e8620783d7507af9130e1954cf6f7.html">Python: Asyncio built-in Socket Server </a><br><small class="date"><b>Created:</b> September 25, 2020</small><small class="date"><b>Tags:</b> #python #python3 #asyncio #server #socket #web #http</small></li>
<li class="gist-entry" id="gist-4e2f323f29ceb624f7fd540687d8e74f"><a href="gists/4e2f323f29ceb624f7fd540687d8e74f.html">Python: Context and ContextVars </a><br><small class="date"><b>Created:</b> September 25, 2020</small><small class="date"><b>Tags:</b> #python #python3 #context #contextvars</small></li>
<li class="gist-entry" id="gist-47e0f8f848ea67f93fc29b754f02cca7"><a href="gists/47e0f8f848ea67f93fc29b754f02cca7.html">Go: Named Return Zero Value </a><br><small class="date"><b>Created:</b> September 23, 2020</small><small class="date"><b>Tags:</b> #go</small></li>
<li class="gist-entry" id="gist-68e71bd4f8374ecf839a7500f9656d36"><a href="gists/68e71bd4f8374ecf839a7500f9656d36.html">Videos: YouTube 'Watch' Channels </a><br><small class="date"><b>Created:</b> September 21, 2020</small><small class="date"><b>Tags:</b> #youtube #watches</small></li>
<li class="gist-entry" id="gist-0f11d3d94bcf564dcd7ad414a2611d83"><a href="gists/0f11d3d94bcf564dcd7ad414a2611d83.html">Go: Module Versioning </a><br><small class="date"><b>Created:</b> September 21, 2020</small><small class="date"><b>Tags:</b> #go #dependencies</small></li>
<li class="gist-entry" id="gist-143faf7ca6b8090e112ec0752ff7e1ca"><a href="gists/143faf7ca6b8090e112ec0752ff7e1ca.html">macOS: System Information </a><br><small class="date"><b>Created:</b> September 18, 2020</small><small class="date"><b>Tags:</b> #macos #system #information #shell #bash</small></li>
<li class="gist-entry" id="gist-510068111c4e2ac933c8d7a3710e732e"><a href="gists/510068111c4e2ac933c8d7a3710e732e.html">Git: Revision Range </a><br><small class="date"><b>Created:</b> September 16, 2020</small><small class="date"><b>Tags:</b> #git #revision #range</small></li>
<li class="gist-entry" id="gist-33db869da23d0729d1e332e21803f891"><a href="gists/33db869da23d0729d1e332e21803f891.html">Go: Running Benchmarks </a><br><small class="date"><b>Created:</b> September 16, 2020</small><small class="date"><b>Tags:</b> #go #performance</small></li>
<li class="gist-entry" id="gist-1c11e1caeae96045c8aab003015d455a"><a href="gists/1c11e1caeae96045c8aab003015d455a.html">Reviews: Self Review Bullet List </a><br><small class="date"><b>Created:</b> September 10, 2020</small><small class="date"><b>Tags:</b> #work #buzzfeed #process #reviews</small></li>
<li class="gist-entry" id="gist-2166bc061a4046ea0de978f771bbee04"><a href="gists/2166bc061a4046ea0de978f771bbee04.html">Go: Pointers - Guidelines </a><br><small class="date"><b>Created:</b> September 9, 2020</small><small class="date"><b>Tags:</b> #go #guide</small></li>
<li class="gist-entry" id="gist-ddab5cf44b223a681e099a1ce107ba85"><a href="gists/ddab5cf44b223a681e099a1ce107ba85.html">Shell: Multiple searches via abstraction and grep </a><br><small class="date"><b>Created:</b> September 8, 2020</small><small class="date"><b>Tags:</b> #bash #shell #grep #search #ag #silversearcher</small></li>
<li class="gist-entry" id="gist-605cbf83fe856bac13eed76b251484c8"><a href="gists/605cbf83fe856bac13eed76b251484c8.html">Docker: jump into running container </a><br><small class="date"><b>Created:</b> September 7, 2020</small><small class="date"><b>Tags:</b> #docker #container #running #interactive #debugging</small></li>
<li class="gist-entry" id="gist-596aa6ddd65130402145fe5f2843471e"><a href="gists/596aa6ddd65130402145fe5f2843471e.html">Go: Sorting </a><br><small class="date"><b>Created:</b> September 4, 2020</small><small class="date"><b>Tags:</b> #go</small></li>
<li class="gist-entry" id="gist-08ee3edb38514b4c68c05ae42fface89"><a href="gists/08ee3edb38514b4c68c05ae42fface89.html">Go: test command usage </a><br><small class="date"><b>Created:</b> September 4, 2020</small><small class="date"><b>Tags:</b> #go #tests</small></li>
<li class="gist-entry" id="gist-206e546da66cf1a0dba6583f87b9e1ed"><a href="gists/206e546da66cf1a0dba6583f87b9e1ed.html">Go: 'Application' and 'Workspace' Directory Structure </a><br><small class="date"><b>Created:</b> September 4, 2020</small><small class="date"><b>Tags:</b> #go #project</small></li>
<li class="gist-entry" id="gist-198c5a8cc7581c6dcf59374ef6948fc2"><a href="gists/198c5a8cc7581c6dcf59374ef6948fc2.html">Go: Custom Vegeta Attack </a><br><small class="date"><b>Created:</b> September 3, 2020</small><small class="date"><b>Tags:</b> #go #performance</small></li>
<li class="gist-entry" id="gist-6bc0f9cb5a6d614ba3297e2c4a3a8050"><a href="gists/6bc0f9cb5a6d614ba3297e2c4a3a8050.html">Work: Onboarding Best Practices </a><br><small class="date"><b>Created:</b> September 3, 2020</small><small class="date"><b>Tags:</b> #onboarding #work #interviews</small></li>
<li class="gist-entry" id="gist-ed6f0b6948d8557abe2c80a192125f0e"><a href="gists/ed6f0b6948d8557abe2c80a192125f0e.html">Security: Path Traversal </a><br><small class="date"><b>Created:</b> September 2, 2020</small><small class="date"><b>Tags:</b> #security #hack #pentesting #traversal #path #encoding</small></li>
<li class="gist-entry" id="gist-1ef7f2da72e4a520a8fca1aeb7b45074"><a href="gists/1ef7f2da72e4a520a8fca1aeb7b45074.html">CLI Diff Tools </a><br><small class="date"><b>Created:</b> September 2, 2020</small><small class="date"><b>Tags:</b> #shell</small></li>
<li class="gist-entry" id="gist-f043af7c820246215b2a2524585b3270"><a href="gists/f043af7c820246215b2a2524585b3270.html">Better Terraform Diff </a><br><small class="date"><b>Created:</b> September 2, 2020</small><small class="date"><b>Tags:</b> #shell #iac</small></li>
<li class="gist-entry" id="gist-d9c1e5680ac4574f9f5b120087a925bb"><a href="gists/d9c1e5680ac4574f9f5b120087a925bb.html">Datadog Terraform - Import Existing Resource </a><br><small class="date"><b>Created:</b> September 1, 2020</small><small class="date"><b>Tags:</b> #iac</small></li>
<li class="gist-entry" id="gist-4bdf64d8c4d36dcc204cd6e44233bf22"><a href="gists/4bdf64d8c4d36dcc204cd6e44233bf22.html">Mock HTTP Response via RoundTripper interface </a><br><small class="date"><b>Created:</b> August 30, 2020</small><small class="date"><b>Tags:</b> #go #http</small></li>
<li class="gist-entry" id="gist-d92513dc93e019e7337d9bfa7790fee3"><a href="gists/d92513dc93e019e7337d9bfa7790fee3.html">Convert a Map to a Struct </a><br><small class="date"><b>Created:</b> August 28, 2020</small><small class="date"><b>Tags:</b> #go #serialization</small></li>
<li class="gist-entry" id="gist-bb73c04c2764cdf40cdcb0eabe845eba"><a href="gists/bb73c04c2764cdf40cdcb0eabe845eba.html">Ex-mode Automation </a><br><small class="date"><b>Created:</b> August 25, 2020</small><small class="date"><b>Tags:</b> #shell #vim</small></li>
<li class="gist-entry" id="gist-d7766801960dfe275bfd3bfe30359966"><a href="gists/d7766801960dfe275bfd3bfe30359966.html">HTTP routing in Go </a><br><small class="date"><b>Created:</b> August 21, 2020</small><small class="date"><b>Tags:</b> #go #http</small></li>
<li class="gist-entry" id="gist-116263155d901190aece7b67d3d2852c"><a href="gists/116263155d901190aece7b67d3d2852c.html">Walk different types via reflection </a><br><small class="date"><b>Created:</b> August 21, 2020</small><small class="date"><b>Tags:</b> #go</small></li>
<li class="gist-entry" id="gist-c48d34af47e8fa39afba6caa42b69877"><a href="gists/c48d34af47e8fa39afba6caa42b69877.html">Functional Programming Map </a><br><small class="date"><b>Created:</b> August 20, 2020</small><small class="date"><b>Tags:</b> #go</small></li>
<li class="gist-entry" id="gist-2b4298d4d287376b8a939c4e9eadd693"><a href="gists/2b4298d4d287376b8a939c4e9eadd693.html">Fastly Terraform Import </a><br><small class="date"><b>Created:</b> August 20, 2020</small><small class="date"><b>Tags:</b> #iac</small></li>
<li class="gist-entry" id="gist-e4580cf4eb8d92e587511c66fc496f02"><a href="gists/e4580cf4eb8d92e587511c66fc496f02.html">Extract mp4 from m3u8 </a><br><small class="date"><b>Created:</b> August 18, 2020</small><small class="date"><b>Tags:</b> #ffmpeg #shell</small></li>
<li class="gist-entry" id="gist-bd46b6673376ceee7f029cfb576438b5"><a href="gists/bd46b6673376ceee7f029cfb576438b5.html">Generic Status Handler Abstraction </a><br><small class="date"><b>Created:</b> August 17, 2020</small><small class="date"><b>Tags:</b> #go #http</small></li>
<li class="gist-entry" id="gist-636314c080a3b88ada95a68a03068a52"><a href="gists/636314c080a3b88ada95a68a03068a52.html">Interface Value vs Interface Type </a><br><small class="date"><b>Created:</b> August 13, 2020</small><small class="date"><b>Tags:</b> #go</small></li>
<li class="gist-entry" id="gist-e9e2b3c27a9556d92ba5782bcc9e316f"><a href="gists/e9e2b3c27a9556d92ba5782bcc9e316f.html">Pointer Dereferencing </a><br><small class="date"><b>Created:</b> August 13, 2020</small><small class="date"><b>Tags:</b> #go</small></li>
<li class="gist-entry" id="gist-d0d2e08152858944249ce8bbfd646851"><a href="gists/d0d2e08152858944249ce8bbfd646851.html">Stack and Queue Implementation </a><br><small class="date"><b>Created:</b> August 12, 2020</small><small class="date"><b>Tags:</b> #go</small></li>
<li class="gist-entry" id="gist-0c9feb43f65d3abfa5e64be4e118440d"><a href="gists/0c9feb43f65d3abfa5e64be4e118440d.html">Dynamically Create Struct </a><br><small class="date"><b>Created:</b> August 6, 2020</small><small class="date"><b>Tags:</b> #go</small></li>
<li class="gist-entry" id="gist-bf1e155f13102e254f6b541c410fbb74"><a href="gists/bf1e155f13102e254f6b541c410fbb74.html">Datadog Structured Logging Abstraction with Logrus </a><br><small class="date"><b>Created:</b> August 4, 2020</small><small class="date"><b>Tags:</b> #go #logs</small></li>
<li class="gist-entry" id="gist-3dd0e5c9e9dca246025462035db2868d"><a href="gists/3dd0e5c9e9dca246025462035db2868d.html">json.Decoder vs json.Unmarshal </a><br><small class="date"><b>Created:</b> July 30, 2020</small><small class="date"><b>Tags:</b> #go #json #serialization</small></li>
<li class="gist-entry" id="gist-af502e7a592fbf07a10433111cefd10f"><a href="gists/af502e7a592fbf07a10433111cefd10f.html">Writing a HTTP Response </a><br><small class="date"><b>Created:</b> July 30, 2020</small><small class="date"><b>Tags:</b> #go #http</small></li>
<li class="gist-entry" id="gist-2ad28a16f303b13dd58e41b3831961e3"><a href="gists/2ad28a16f303b13dd58e41b3831961e3.html">Module Error: malformed module path ... missing dot in first path element </a><br><small class="date"><b>Created:</b> July 29, 2020</small><small class="date"><b>Tags:</b> #go</small></li>
<li class="gist-entry" id="gist-0bfa1c1ab84ef06a657cd6aa6b2ce25e"><a href="gists/0bfa1c1ab84ef06a657cd6aa6b2ce25e.html">Embed empty interface{} into explicit struct and then reflect the containing struct </a><br><small class="date"><b>Created:</b> July 28, 2020</small><small class="date"><b>Tags:</b> #go</small></li>
<li class="gist-entry" id="gist-b4d7c15ef7501d863d146530ff1ff22f"><a href="gists/b4d7c15ef7501d863d146530ff1ff22f.html">Merge two structs </a><br><small class="date"><b>Created:</b> July 27, 2020</small><small class="date"><b>Tags:</b> #go</small></li>
<li class="gist-entry" id="gist-c92a7e1e47477650ed528726fa1a0c73"><a href="gists/c92a7e1e47477650ed528726fa1a0c73.html">Comparison Matrix Table Properties </a><br><small class="date"><b>Created:</b> July 17, 2020</small><small class="date"><b>Tags:</b> #project</small></li>
<li class="gist-entry" id="gist-7ae8445d3179926be127c11dfe962f95"><a href="gists/7ae8445d3179926be127c11dfe962f95.html">Closure Example </a><br><small class="date"><b>Created:</b> July 17, 2020</small><small class="date"><b>Tags:</b> #go</small></li>
<li class="gist-entry" id="gist-106c2f1b806f80f04e00cd9d43e1c971"><a href="gists/106c2f1b806f80f04e00cd9d43e1c971.html">IP Transit </a><br><small class="date"><b>Created:</b> July 17, 2020</small><small class="date"><b>Tags:</b> #network</small></li>
<li class="gist-entry" id="gist-fb0f263c624280eb3bca291ee8f0ed6b"><a href="gists/fb0f263c624280eb3bca291ee8f0ed6b.html">Simple Log Example with Configuration Overrides </a><br><small class="date"><b>Created:</b> July 15, 2020</small><small class="date"><b>Tags:</b> #go #logs</small></li>
<li class="gist-entry" id="gist-9537a46eea1b731dfa331f850ff8b8b0"><a href="gists/9537a46eea1b731dfa331f850ff8b8b0.html">Valid URL Paths </a><br><small class="date"><b>Created:</b> July 14, 2020</small><small class="date"><b>Tags:</b> #http #rfc</small></li>
<li class="gist-entry" id="gist-a66a29561f6544297a5ad41a8208193c"><a href="gists/a66a29561f6544297a5ad41a8208193c.html">Simple XHR function </a><br><small class="date"><b>Created:</b> July 10, 2020</small><small class="date"><b>Tags:</b> #js</small></li>
<li class="gist-entry" id="gist-2ecc27597cc609fcb7e4c13c8b9a1dae"><a href="gists/2ecc27597cc609fcb7e4c13c8b9a1dae.html">Fuzz Testing</a><br><small class="date"><b>Created:</b> June 22, 2020</small></li>
<li class="gist-entry" id="gist-1048649a5c00fae8d7f9841d07c728db"><a href="gists/1048649a5c00fae8d7f9841d07c728db.html">Compile Curl </a><br><small class="date"><b>Created:</b> June 18, 2020</small><small class="date"><b>Tags:</b> #shell</small></li>
<li class="gist-entry" id="gist-c88f6dca57f3bc327403c9e042e11ff2"><a href="gists/c88f6dca57f3bc327403c9e042e11ff2.html">NSQ Questions </a><br><small class="date"><b>Created:</b> June 17, 2020</small><small class="date"><b>Tags:</b> #queues</small></li>
<li class="gist-entry" id="gist-b097d008e86699ec990bd5f5dfd2e672"><a href="gists/b097d008e86699ec990bd5f5dfd2e672.html">Copying Files and Directories </a><br><small class="date"><b>Created:</b> June 15, 2020</small><small class="date"><b>Tags:</b> #shell</small></li>
<li class="gist-entry" id="gist-4d3e41b2bd9b69b5732494da1dda2fe3"><a href="gists/4d3e41b2bd9b69b5732494da1dda2fe3.html">Go: return a sample (random bool) based on percentage </a><br><small class="date"><b>Created:</b> June 11, 2020</small><small class="date"><b>Tags:</b> #go</small></li>
<li class="gist-entry" id="gist-e70714efb70cb2a19ee494c1f252e977"><a href="gists/e70714efb70cb2a19ee494c1f252e977.html">Virtual Environment with venv </a><br><small class="date"><b>Created:</b> June 4, 2020</small><small class="date"><b>Tags:</b> #python</small></li>
<li class="gist-entry" id="gist-7571b0da0ca3da25f1cd170b1030f4a0"><a href="gists/7571b0da0ca3da25f1cd170b1030f4a0.html">Enum Example </a><br><small class="date"><b>Created:</b> June 3, 2020</small><small class="date"><b>Tags:</b> #python</small></li>
<li class="gist-entry" id="gist-38ab8030b353a93105eeb46672cfdf87"><a href="gists/38ab8030b353a93105eeb46672cfdf87.html">Logging Message Format </a><br><small class="date"><b>Created:</b> May 13, 2020</small><small class="date"><b>Tags:</b> #logs</small></li>
<li class="gist-entry" id="gist-ee66b956869784137e54e6e865cfe4ef"><a href="gists/ee66b956869784137e54e6e865cfe4ef.html">Searching files and contents </a><br><small class="date"><b>Created:</b> May 7, 2020</small><small class="date"><b>Tags:</b> #vim</small></li>
<li class="gist-entry" id="gist-97f8b86ebde43a33b27289d7b87ffc0d"><a href="gists/97f8b86ebde43a33b27289d7b87ffc0d.html">Integer precision accuracy vs float </a><br><small class="date"><b>Created:</b> April 27, 2020</small><small class="date"><b>Tags:</b> #go</small></li>
<li class="gist-entry" id="gist-4db9ec39ff22ec823ce51eef9dcd2460"><a href="gists/4db9ec39ff22ec823ce51eef9dcd2460.html">gnu sed alternation </a><br><small class="date"><b>Created:</b> April 22, 2020</small><small class="date"><b>Tags:</b> #shell</small></li>
<li class="gist-entry" id="gist-bc211ad7f831ecc5e6aee532d7306340"><a href="gists/bc211ad7f831ecc5e6aee532d7306340.html">argparse cli flag examples </a><br><small class="date"><b>Created:</b> April 19, 2020</small><small class="date"><b>Tags:</b> #python</small></li>
<li class="gist-entry" id="gist-12610900a78d0880580bb96ac8fb0170"><a href="gists/12610900a78d0880580bb96ac8fb0170.html">Datadog Python API </a><br><small class="date"><b>Created:</b> April 8, 2020</small><small class="date"><b>Tags:</b> #python</small></li>
<li class="gist-entry" id="gist-1efc8dcfc0b1e9e8e8b89a4b2019f3af"><a href="gists/1efc8dcfc0b1e9e8e8b89a4b2019f3af.html">Coroutine comparison functions </a><br><small class="date"><b>Created:</b> April 3, 2020</small><small class="date"><b>Tags:</b> #python</small></li>
<li class="gist-entry" id="gist-296bbce573c9dbaed943048f7441154e"><a href="gists/296bbce573c9dbaed943048f7441154e.html">Function Timer Decorator </a><br><small class="date"><b>Created:</b> April 3, 2020</small><small class="date"><b>Tags:</b> #python</small></li>
<li class="gist-entry" id="gist-aa43fe5318318f77a3ae1c4b81c4cf6a"><a href="gists/aa43fe5318318f77a3ae1c4b81c4cf6a.html">run a macro multiple times </a><br><small class="date"><b>Created:</b> April 2, 2020</small><small class="date"><b>Tags:</b> #vim</small></li>
<li class="gist-entry" id="gist-0647b5947005d1faeb2d78f79e5b688d"><a href="gists/0647b5947005d1faeb2d78f79e5b688d.html">use control key in norm Ex command </a><br><small class="date"><b>Created:</b> April 2, 2020</small><small class="date"><b>Tags:</b> #vim</small></li>
<li class="gist-entry" id="gist-69dc115cc31d253961645c8139f25269"><a href="gists/69dc115cc31d253961645c8139f25269.html">Search, filter, cut, sort and get uniques + tee contents </a><br><small class="date"><b>Created:</b> April 2, 2020</small><small class="date"><b>Tags:</b> #shell</small></li>
<li class="gist-entry" id="gist-354e1267bef43961dd678679f5823669"><a href="gists/354e1267bef43961dd678679f5823669.html">find and replace content across multiple files </a><br><small class="date"><b>Created:</b> March 31, 2020</small><small class="date"><b>Tags:</b> #shell #tools</small></li>
<li class="gist-entry" id="gist-4493c6f895c6771b13d0324949c08977"><a href="gists/4493c6f895c6771b13d0324949c08977.html">Pretty Print Dictionary </a><br><small class="date"><b>Created:</b> March 25, 2020</small><small class="date"><b>Tags:</b> #python</small></li>
<li class="gist-entry" id="gist-9822f59cbb60f5de0f79a6cbd79ad9ab"><a href="gists/9822f59cbb60f5de0f79a6cbd79ad9ab.html">GitHub Open-Source Pull Request Flow </a><br><small class="date"><b>Created:</b> March 23, 2020</small><small class="date"><b>Tags:</b> #git #github</small></li>
<li class="gist-entry" id="gist-3b6aa81b784b37cf90d177933b5791f7"><a href="gists/3b6aa81b784b37cf90d177933b5791f7.html">IO Packages </a><br><small class="date"><b>Created:</b> March 18, 2020</small><small class="date"><b>Tags:</b> #go</small></li>
<li class="gist-entry" id="gist-e2be6c6cc8a2e23219e07682fc038bca"><a href="gists/e2be6c6cc8a2e23219e07682fc038bca.html">Simple retry logic for HTTP request </a><br><small class="date"><b>Created:</b> March 13, 2020</small><small class="date"><b>Tags:</b> #go #http</small></li>
<li class="gist-entry" id="gist-124d0de60213742030999e98527ae47c"><a href="gists/124d0de60213742030999e98527ae47c.html">Don't follow 301 redirect </a><br><small class="date"><b>Created:</b> March 13, 2020</small><small class="date"><b>Tags:</b> #go #http</small></li>
<li class="gist-entry" id="gist-009340829a377fbe350931400d2a82bc"><a href="gists/009340829a377fbe350931400d2a82bc.html">CPU Speed</a><br><small class="date"><b>Created:</b> March 6, 2020</small></li>
<li class="gist-entry" id="gist-8a2aaf1d8b1706a10049c52c15d305f0"><a href="gists/8a2aaf1d8b1706a10049c52c15d305f0.html">linefeed and carriage return </a><br><small class="date"><b>Created:</b> March 6, 2020</small><small class="date"><b>Tags:</b> #vim</small></li>
<li class="gist-entry" id="gist-4a7b9efe971c416ee56b4e0025174e9c"><a href="gists/4a7b9efe971c416ee56b4e0025174e9c.html">Redis Install and Examples </a><br><small class="date"><b>Created:</b> March 5, 2020</small><small class="date"><b>Tags:</b> #shell</small></li>
<li class="gist-entry" id="gist-50833024cf073e804e1243baa0c690e8"><a href="gists/50833024cf073e804e1243baa0c690e8.html">Simple Fastly CDN Rate Limiting Logic using Vary behaviour for cacheable GET requests </a><br><small class="date"><b>Created:</b> March 5, 2020</small><small class="date"><b>Tags:</b> #fastly #cdn</small></li>
<li class="gist-entry" id="gist-a2e407afe89be6039001535c09f782fc"><a href="gists/a2e407afe89be6039001535c09f782fc.html">Type check object is an instance of a specific struct </a><br><small class="date"><b>Created:</b> February 28, 2020</small><small class="date"><b>Tags:</b> #go</small></li>
<li class="gist-entry" id="gist-04a3895be2c428219a28c3b3dd77bfed"><a href="gists/04a3895be2c428219a28c3b3dd77bfed.html">Context package </a><br><small class="date"><b>Created:</b> February 27, 2020</small><small class="date"><b>Tags:</b> #go</small></li>
<li class="gist-entry" id="gist-1191d4fa185f43d67f03500100bae5c3"><a href="gists/1191d4fa185f43d67f03500100bae5c3.html">Runtime Profiler </a><br><small class="date"><b>Created:</b> February 27, 2020</small><small class="date"><b>Tags:</b> #go #performance</small></li>
<li class="gist-entry" id="gist-939c894e7e888fce66968eb5b1a807de"><a href="gists/939c894e7e888fce66968eb5b1a807de.html">Go: Logrus JSON Example </a><br><small class="date"><b>Created:</b> February 21, 2020</small><small class="date"><b>Tags:</b> #go #json #logs</small></li>
<li class="gist-entry" id="gist-348c70ab1d1dafc9f455d715d93ba3dd"><a href="gists/348c70ab1d1dafc9f455d715d93ba3dd.html">[AWS Active-Active Patterns Presentation (link to PDF)] </a><br><small class="date"><b>Created:</b> February 14, 2020</small><small class="date"><b>Tags:</b> #aws #pdf #presentation #resilience #multiregion #activeactive #pattern #ha #availability</small></li>
<li class="gist-entry" id="gist-de9773dc041b2dc3997096817a827d71"><a href="gists/de9773dc041b2dc3997096817a827d71.html">[Golang Struct and Interface Embedding Examples] </a><br><small class="date"><b>Created:</b> February 13, 2020</small><small class="date"><b>Tags:</b> #go #golang #struct #embedding #embed</small></li>
<li class="gist-entry" id="gist-c13c30dcad137e93b38f7f8e0581945a"><a href="gists/c13c30dcad137e93b38f7f8e0581945a.html">[nginx rate limiting is weird] </a><br><small class="date"><b>Created:</b> February 12, 2020</small><small class="date"><b>Tags:</b> #nginx #ratelimit</small></li>
<li class="gist-entry" id="gist-f0ab51316127c7d118e87bc62f5008af"><a href="gists/f0ab51316127c7d118e87bc62f5008af.html">[Golang io.Pipe and io.TeeReader combined] </a><br><small class="date"><b>Created:</b> February 12, 2020</small><small class="date"><b>Tags:</b> #go #golang #io #pipe #tee #reader #writer</small></li>
<li class="gist-entry" id="gist-1ed04781e04cef5d12354b1761b4a580"><a href="gists/1ed04781e04cef5d12354b1761b4a580.html">[Golang Gzip] </a><br><small class="date"><b>Created:</b> February 11, 2020</small><small class="date"><b>Tags:</b> #golang #go #gzip #proxy</small></li>
<li class="gist-entry" id="gist-5d9c79a740d744744b026616421708df"><a href="gists/5d9c79a740d744744b026616421708df.html">[Python Boto3 S3 Example] </a><br><small class="date"><b>Created:</b> February 5, 2020</small><small class="date"><b>Tags:</b> #python3 #boto3 #aws #s3</small></li>
<li class="gist-entry" id="gist-94474b1d73deeb832f1f22f080f50c8a"><a href="gists/94474b1d73deeb832f1f22f080f50c8a.html">[ADR Architecture Decision Record] </a><br><small class="date"><b>Created:</b> February 5, 2020</small><small class="date"><b>Tags:</b> #architecture #decision #record #adr</small></li>
<li class="gist-entry" id="gist-c61346248e1f6c5c494fec98cb7be75c"><a href="gists/c61346248e1f6c5c494fec98cb7be75c.html">[File Permissions with Octal Notation Explanation] </a><br><small class="date"><b>Created:</b> February 5, 2020</small><small class="date"><b>Tags:</b> #file #permissions #octal</small></li>
<li class="gist-entry" id="gist-81055fee04f5953d84cd4c0800e098e9"><a href="gists/81055fee04f5953d84cd4c0800e098e9.html">[Markdown syntax for links in bottom of document] </a><br><small class="date"><b>Created:</b> February 4, 2020</small><small class="date"><b>Tags:</b> #markdown #links #reference</small></li>
<li class="gist-entry" id="gist-339893af379763cf96bc73eb08376759"><a href="gists/339893af379763cf96bc73eb08376759.html">[Python Atomic Counter] </a><br><small class="date"><b>Created:</b> January 31, 2020</small><small class="date"><b>Tags:</b> #python3 #concurrency #threadsafe #lock #atomic #counter</small></li>
<li class="gist-entry" id="gist-cda12bf32cb622859512f4c666e0cbb0"><a href="gists/cda12bf32cb622859512f4c666e0cbb0.html">[Tornado configure AsyncHTTPClient to use Curl] </a><br><small class="date"><b>Created:</b> January 29, 2020</small><small class="date"><b>Tags:</b> #python3 #tornado #configure #async #httpclient #curl #libcurl</small></li>
<li class="gist-entry" id="gist-c03ddba75fec77d06f0d4eb34651f679"><a href="gists/c03ddba75fec77d06f0d4eb34651f679.html">[Parsing HTML with Python standard library] </a><br><small class="date"><b>Created:</b> January 28, 2020</small><small class="date"><b>Tags:</b> #python3 #html #parse #ast</small></li>
<li class="gist-entry" id="gist-6ccedba3b2e13b10a1afb66ced0891ff"><a href="gists/6ccedba3b2e13b10a1afb66ced0891ff.html">[Check Python Tornado version] </a><br><small class="date"><b>Created:</b> January 27, 2020</small><small class="date"><b>Tags:</b> #python3 #tornado #version</small></li>
<li class="gist-entry" id="gist-c88a09dbe96af8715cf954e040e1a4f2"><a href="gists/c88a09dbe96af8715cf954e040e1a4f2.html">[Create a simple Pip Python Repository] </a><br><small class="date"><b>Created:</b> January 27, 2020</small><small class="date"><b>Tags:</b> #python3 #pip #repository #pypi</small></li>
<li class="gist-entry" id="gist-cca9599decab873373aad6d8ebff61ac"><a href="gists/cca9599decab873373aad6d8ebff61ac.html">[Vim arg list and Search Replacement] </a><br><small class="date"><b>Created:</b> January 17, 2020</small><small class="date"><b>Tags:</b> #vim #search #replace #args #case #lower #upper</small></li>
<li class="gist-entry" id="gist-b45518d16a7bc075e9c0c5a225027ad6"><a href="gists/b45518d16a7bc075e9c0c5a225027ad6.html">[High Availability Content and Resilient Systems with Redundancy] </a><br><small class="date"><b>Created:</b> January 13, 2020</small><small class="date"><b>Tags:</b> #availability #resilience #tolerance #redundancy</small></li>
<li class="gist-entry" id="gist-a6afdbaf8a3801171e7429a6fefb1c53"><a href="gists/a6afdbaf8a3801171e7429a6fefb1c53.html">[CHANGELOG] </a><br><small class="date"><b>Created:</b> January 9, 2020</small><small class="date"><b>Tags:</b> #changelog</small></li>
<li class="gist-entry" id="gist-78677b6179f0ce46fd3fe62b1694f349"><a href="gists/78677b6179f0ce46fd3fe62b1694f349.html">[Vim highlighting words] </a><br><small class="date"><b>Created:</b> January 9, 2020</small><small class="date"><b>Tags:</b> #vim #highlight #code #comments</small></li>
<li class="gist-entry" id="gist-71142e37f4f24ad1a37e1fb94e4e6d90"><a href="gists/71142e37f4f24ad1a37e1fb94e4e6d90.html">[Go channel closing] </a><br><small class="date"><b>Created:</b> January 9, 2020</small><small class="date"><b>Tags:</b> #go #golang #channel #close</small></li>
<li class="gist-entry" id="gist-977efa8e748623ded3b164f8180e66f8"><a href="gists/977efa8e748623ded3b164f8180e66f8.html">[Golang change function signature without breaking existing consumers] </a><br><small class="date"><b>Created:</b> January 7, 2020</small><small class="date"><b>Tags:</b> #go #golang #default #variadic #interface #api</small></li>
<li class="gist-entry" id="gist-b42349c1f20782484d837118f9fb7ad8"><a href="gists/b42349c1f20782484d837118f9fb7ad8.html">[Python Print Parent Class] </a><br><small class="date"><b>Created:</b> January 7, 2020</small><small class="date"><b>Tags:</b> #python #class #hierarchy</small></li>
<li class="gist-entry" id="gist-0ce27db1d7294f3af9896c0807ccfeed"><a href="gists/0ce27db1d7294f3af9896c0807ccfeed.html">[Flake8 Import Order] </a><br><small class="date"><b>Created:</b> January 6, 2020</small><small class="date"><b>Tags:</b> #python #flake8 #import #order</small></li>
<li class="gist-entry" id="gist-e5310d1082b0ff8307e39b71a6f9bae5"><a href="gists/e5310d1082b0ff8307e39b71a6f9bae5.html">[Python Comprehensions] </a><br><small class="date"><b>Created:</b> December 28, 2019</small><small class="date"><b>Tags:</b> #python3 #comprehensions</small></li>
<li class="gist-entry" id="gist-898d40f51024c46d9660b92f5191f5e5"><a href="gists/898d40f51024c46d9660b92f5191f5e5.html">[CPU bound vs I/O bound] </a><br><small class="date"><b>Created:</b> December 24, 2019</small><small class="date"><b>Tags:</b> #cpu #io #bound</small></li>
<li class="gist-entry" id="gist-45d979cacde4d65e2c6c3298211f2719"><a href="gists/45d979cacde4d65e2c6c3298211f2719.html">[Golang Reduce Function Signature with Struct] </a><br><small class="date"><b>Created:</b> December 18, 2019</small><small class="date"><b>Tags:</b> #go #golang #struct #options #arguments #parameters #function #signature</small></li>
<li class="gist-entry" id="gist-2cc935fc5eb571cf937c17755ecc0952"><a href="gists/2cc935fc5eb571cf937c17755ecc0952.html">[Good Naming Strategy] </a><br><small class="date"><b>Created:</b> December 18, 2019</small><small class="date"><b>Tags:</b> #documentation #docs #guides #tutorials #reference #explanation #writing #naming #go #golang</small></li>
<li class="gist-entry" id="gist-e538e3831c6a0f228eee8545b6f5dc95"><a href="gists/e538e3831c6a0f228eee8545b6f5dc95.html">[How to write an introduction well Inbox] </a><br><small class="date"><b>Created:</b> December 18, 2019</small><small class="date"><b>Tags:</b> #documentation #docs #guides #tutorials #reference #explanation #writing</small></li>
<li class="gist-entry" id="gist-2a316428696daccd66e5df8df02abb3f"><a href="gists/2a316428696daccd66e5df8df02abb3f.html">[Golang Custom Error Abstraction] </a><br><small class="date"><b>Created:</b> December 18, 2019</small><small class="date"><b>Tags:</b> #go #golang #error #errorhandling #abstraction</small></li>
<li class="gist-entry" id="gist-06bddcd3a5506e46e98c2dfa9a3f5167"><a href="gists/06bddcd3a5506e46e98c2dfa9a3f5167.html">[Types of Documentation] </a><br><small class="date"><b>Created:</b> December 18, 2019</small><small class="date"><b>Tags:</b> #documentation #docs #guides #tutorials #reference #explanation</small></li>
<li class="gist-entry" id="gist-16f406bcbb3e591901b88a81438ee704"><a href="gists/16f406bcbb3e591901b88a81438ee704.html">[Python Tox Explanation] </a><br><small class="date"><b>Created:</b> December 18, 2019</small><small class="date"><b>Tags:</b> #python #tox #testing</small></li>
<li class="gist-entry" id="gist-8a1c597fe18e703282b33020adb71507"><a href="gists/8a1c597fe18e703282b33020adb71507.html">[Python3 pass vs ...]</a><br><small class="date"><b>Created:</b> December 13, 2019</small></li>
<li class="gist-entry" id="gist-f59ecde0baf7083c6fb047f24bd35f64"><a href="gists/f59ecde0baf7083c6fb047f24bd35f64.html">[Python Fastly API Edge Dictionary Example] </a><br><small class="date"><b>Created:</b> December 6, 2019</small><small class="date"><b>Tags:</b> #python3 #fastly #api #edge #dictionary #example #cdn</small></li>
<li class="gist-entry" id="gist-50f13472cfd1bc044f1364cc3517cecf"><a href="gists/50f13472cfd1bc044f1364cc3517cecf.html">[Python CLI Example Boilerplate with dependency validation] </a><br><small class="date"><b>Created:</b> December 6, 2019</small><small class="date"><b>Tags:</b> #python3 #cli #flags #example #boilerplate #validation #dependencies</small></li>
<li class="gist-entry" id="gist-6085917235753cad79388cad1ee73d0c"><a href="gists/6085917235753cad79388cad1ee73d0c.html">[git edit hunk] </a><br><small class="date"><b>Created:</b> December 3, 2019</small><small class="date"><b>Tags:</b> #git #edit #hunk #patch #diff</small></li>
<li class="gist-entry" id="gist-340306f1938606a84667c9cc56af13f7"><a href="gists/340306f1938606a84667c9cc56af13f7.html">[Bash find git repo root] </a><br><small class="date"><b>Created:</b> December 2, 2019</small><small class="date"><b>Tags:</b> #bash #git #repo #root</small></li>
<li class="gist-entry" id="gist-7cb06ccb8a06b774f0f65ae2dfe8cb65"><a href="gists/7cb06ccb8a06b774f0f65ae2dfe8cb65.html">[Python standard library HTTP request example] </a><br><small class="date"><b>Created:</b> November 26, 2019</small><small class="date"><b>Tags:</b> #python3 #standard #library #stdlib #http #client #request</small></li>
<li class="gist-entry" id="gist-1f07858ef4c827a50c7edb164e0107c8"><a href="gists/1f07858ef4c827a50c7edb164e0107c8.html">[Python3 Virtual Environment with Pyenv] </a><br><small class="date"><b>Created:</b> November 21, 2019</small><small class="date"><b>Tags:</b> #python3 #pip #deps #dependencies #venv #virtualenvironment #env #tfswitch #tf #terraform</small></li>
<li class="gist-entry" id="gist-f7a6abdd946ad5b3b06907069f79cc48"><a href="gists/f7a6abdd946ad5b3b06907069f79cc48.html">[Fastly Varnish Serve Stale Testing] </a><br><small class="date"><b>Created:</b> November 20, 2019</small><small class="date"><b>Tags:</b> #fastly #varnish #vcl #cdn #cache #stale #stale-while-revalidate #stale-if-error</small></li>
<li class="gist-entry" id="gist-ec0b1f17d7b0b8f365293048d0d79197"><a href="gists/ec0b1f17d7b0b8f365293048d0d79197.html">[Python copy file with permissions + add additional perms] </a><br><small class="date"><b>Created:</b> November 20, 2019</small><small class="date"><b>Tags:</b> #python3 #permissions #chmod</small></li>
<li class="gist-entry" id="gist-89e39ecdd3fb2afc26ea898814689da7"><a href="gists/89e39ecdd3fb2afc26ea898814689da7.html">[Python print python version information] </a><br><small class="date"><b>Created:</b> November 19, 2019</small><small class="date"><b>Tags:</b> #python #script #shell #version</small></li>
<li class="gist-entry" id="gist-f5bd41c0bfeaf9d4e37e434d3a6af5c4"><a href="gists/f5bd41c0bfeaf9d4e37e434d3a6af5c4.html">[Continuous Integration vs Delivery] </a><br><small class="date"><b>Created:</b> November 19, 2019</small><small class="date"><b>Tags:</b> #ci #cd #continous #integration #delivery</small></li>
<li class="gist-entry" id="gist-df411140a5596abefa05f27647a4f25f"><a href="gists/df411140a5596abefa05f27647a4f25f.html">[Bash default variable value for script arguments] </a><br><small class="date"><b>Created:</b> November 18, 2019</small><small class="date"><b>Tags:</b> #bash #shell #scripting #cli #terminal #defaults</small></li>
<li class="gist-entry" id="gist-d1c839f78041a64acd0113fdbaa2a3f1"><a href="gists/d1c839f78041a64acd0113fdbaa2a3f1.html">[Python Tornado Initialization and Multi-Process Mode] </a><br><small class="date"><b>Created:</b> November 18, 2019</small><small class="date"><b>Tags:</b> #python #tornado #parallelization #multi-process #processes #cpu</small></li>
<li class="gist-entry" id="gist-53e926c454e34cb76445c228ded41e95"><a href="gists/53e926c454e34cb76445c228ded41e95.html">[Python Tornado Graceful Shutdown] </a><br><small class="date"><b>Created:</b> November 13, 2019</small><small class="date"><b>Tags:</b> #python #python3 #tornado #graceful #shutdown #signals #sigterm #sigint</small></li>
<li class="gist-entry" id="gist-b81f2dd872f4dc3176ba1ce63dd68ce6"><a href="gists/b81f2dd872f4dc3176ba1ce63dd68ce6.html">[Golang Fastly Purge by URL and by Key] </a><br><small class="date"><b>Created:</b> November 6, 2019</small><small class="date"><b>Tags:</b> #fastly #go #golang #purge #cdn #cache</small></li>
<li class="gist-entry" id="gist-1ac45cfeab44d917d28c062346363684"><a href="gists/1ac45cfeab44d917d28c062346363684.html">[Golang convert code into Assembly] </a><br><small class="date"><b>Created:</b> November 6, 2019</small><small class="date"><b>Tags:</b> #assembly #go #golang</small></li>
<li class="gist-entry" id="gist-96ef2d239c1743cf8cc7f9baec93404d"><a href="gists/96ef2d239c1743cf8cc7f9baec93404d.html">[Security: Zero Trust Platform] </a><br><small class="date"><b>Created:</b> November 6, 2019</small><small class="date"><b>Tags:</b> #security #zerotrust #zero #trust #platform</small></li>
<li class="gist-entry" id="gist-b39b53e7f33970223eca5fb814c6add6"><a href="gists/b39b53e7f33970223eca5fb814c6add6.html">[Golang HTTP Web Server Parallel Tee Goroutine per Request] </a><br><small class="date"><b>Created:</b> November 4, 2019</small><small class="date"><b>Tags:</b> #go #golang #tee #parallel #http #web #server #request #pool #concurrency</small></li>
<li class="gist-entry" id="gist-88d9a8ba3f33ce801ead28f04bbb65d3"><a href="gists/88d9a8ba3f33ce801ead28f04bbb65d3.html">[Fakes vs Stubs vs Mocks] </a><br><small class="date"><b>Created:</b> October 24, 2019</small><small class="date"><b>Tags:</b> #fakes #stubs #mocks #testing</small></li>
<li class="gist-entry" id="gist-d16924d70b14502cbe5bb443ac62a09b"><a href="gists/d16924d70b14502cbe5bb443ac62a09b.html">[Bash string wildcard glob conains example] </a><br><small class="date"><b>Created:</b> October 16, 2019</small><small class="date"><b>Tags:</b> #bash #wildcard #glob #contains</small></li>
<li class="gist-entry" id="gist-66a3723e5a69fe355f2cade31a1070e8"><a href="gists/66a3723e5a69fe355f2cade31a1070e8.html">[Bash Hash Bang] </a><br><small class="date"><b>Created:</b> October 16, 2019</small><small class="date"><b>Tags:</b> #bash #hash #bang</small></li>
<li class="gist-entry" id="gist-c08b1ab3e9dd508b1ccc5fe768d1a9b0"><a href="gists/c08b1ab3e9dd508b1ccc5fe768d1a9b0.html">[Fastly Clustering and Shielding Example] </a><br><small class="date"><b>Created:</b> October 15, 2019</small><small class="date"><b>Tags:</b> #fastly #varnish #vcl #clustering #shielding #cluster #shield</small></li>
<li class="gist-entry" id="gist-831298624d7171b155dd58b45341c576"><a href="gists/831298624d7171b155dd58b45341c576.html">[Develop Streamlink Locally] </a><br><small class="date"><b>Created:</b> October 5, 2019</small><small class="date"><b>Tags:</b> #streamlink #video #download #stream</small></li>
<li class="gist-entry" id="gist-41a1e77cd7e55439ca66d2591d772beb"><a href="gists/41a1e77cd7e55439ca66d2591d772beb.html">[SQL get unique values using BigQuery] </a><br><small class="date"><b>Created:</b> October 2, 2019</small><small class="date"><b>Tags:</b> #bigquery #google #data #sql #unique</small></li>
<li class="gist-entry" id="gist-c662fe35041e9a66facce222cba32643"><a href="gists/c662fe35041e9a66facce222cba32643.html">[Golang http.Request.Context] </a><br><small class="date"><b>Created:</b> September 9, 2019</small><small class="date"><b>Tags:</b> #go #golang #http #request #context</small></li>
<li class="gist-entry" id="gist-8719fed37c7e1ac27d5f739926bac584"><a href="gists/8719fed37c7e1ac27d5f739926bac584.html">[Curl Redirect Output and Grep] </a><br><small class="date"><b>Created:</b> September 9, 2019</small><small class="date"><b>Tags:</b> #curl #redirect #stdout #grep</small></li>
<li class="gist-entry" id="gist-1ca0b1acb0d65af19df9d38618b5058f"><a href="gists/1ca0b1acb0d65af19df9d38618b5058f.html">[Safe Tech Terminology] </a><br><small class="date"><b>Created:</b> September 9, 2019</small><small class="date"><b>Tags:</b> #safe #terminology #tech</small></li>
<li class="gist-entry" id="gist-524be67b0b33e8087dd67a5a6af9b3c5"><a href="gists/524be67b0b33e8087dd67a5a6af9b3c5.html">[Example System Contract for Caching Behaviours] </a><br><small class="date"><b>Created:</b> August 16, 2019</small><small class="date"><b>Tags:</b> #system #contract #architecture #design #interface #SLA #fastly #cdn</small></li>
<li class="gist-entry" id="gist-b2e87acad7fdf354ade3250dcb31c168"><a href="gists/b2e87acad7fdf354ade3250dcb31c168.html">[Go embedding interface types] </a><br><small class="date"><b>Created:</b> August 15, 2019</small><small class="date"><b>Tags:</b> #go #golang #interface #struct #field #type #assertion #embed #override #template #pattern</small></li>
<li class="gist-entry" id="gist-0068812f12b4c72ee8e9d10ce38a1ed9"><a href="gists/0068812f12b4c72ee8e9d10ce38a1ed9.html">[Golang Read HTTP Response Body TWICE!] </a><br><small class="date"><b>Created:</b> August 13, 2019</small><small class="date"><b>Tags:</b> #go #golang #http #response #body #read</small></li>
<li class="gist-entry" id="gist-b123e4a98bcf232d09216577c29f34a3"><a href="gists/b123e4a98bcf232d09216577c29f34a3.html">[golang avoid promoted field in literal struct error] </a><br><small class="date"><b>Created:</b> August 13, 2019</small><small class="date"><b>Tags:</b> #go #golang #struct #promoted #field #error</small></li>
<li class="gist-entry" id="gist-2e4a78fe92ec70d2e2709ff7be660669"><a href="gists/2e4a78fe92ec70d2e2709ff7be660669.html">[fastly default vcl, no custom vcl] </a><br><small class="date"><b>Created:</b> August 6, 2019</small><small class="date"><b>Tags:</b> #fastly #varnish #vcl</small></li>
<li class="gist-entry" id="gist-dc05d8b18c8d793ad347f92623075535"><a href="gists/dc05d8b18c8d793ad347f92623075535.html">[ffmpeg examples] </a><br><small class="date"><b>Created:</b> August 5, 2019</small><small class="date"><b>Tags:</b> #ffmpeg #crop #video #concat #split #resize</small></li>
<li class="gist-entry" id="gist-d84389ff35687f7c9d89d5246338fa38"><a href="gists/d84389ff35687f7c9d89d5246338fa38.html">[Go Access Underlying Slice Array] </a><br><small class="date"><b>Created:</b> July 30, 2019</small><small class="date"><b>Tags:</b> #go #golang #slice #array #unsafe #reflect #header</small></li>
<li class="gist-entry" id="gist-632892f6ee2556e5a2f44789f93ddbd8"><a href="gists/632892f6ee2556e5a2f44789f93ddbd8.html">[Go Array Element Removal] </a><br><small class="date"><b>Created:</b> July 30, 2019</small><small class="date"><b>Tags:</b> #go #golang #array #slice #splice #remove #element #item</small></li>
<li class="gist-entry" id="gist-644f8794ff272734d12ffaa77e05f51a"><a href="gists/644f8794ff272734d12ffaa77e05f51a.html">[Go Time Formating + Conversions and Comparisons + Stale] </a><br><small class="date"><b>Created:</b> July 29, 2019</small><small class="date"><b>Tags:</b> #go #golang #time #formatting #layout #comparison #conversion #stale</small></li>
<li class="gist-entry" id="gist-6ca9251adf682be55d387474b46998b6"><a href="gists/6ca9251adf682be55d387474b46998b6.html">[vim open multiple files from a grep/sift search] </a><br><small class="date"><b>Created:</b> July 24, 2019</small><small class="date"><b>Tags:</b> #vim #open #files #multiple #sift #grep #replace #search</small></li>
<li class="gist-entry" id="gist-256c445d1d56369632e43d49056b60cf"><a href="gists/256c445d1d56369632e43d49056b60cf.html">[Golang Array and Slices] </a><br><small class="date"><b>Created:</b> July 19, 2019</small><small class="date"><b>Tags:</b> #go #golang #slice #slices #array #internal #pointers</small></li>
<li class="gist-entry" id="gist-7816083906903bf4c24140e7228c7ad2"><a href="gists/7816083906903bf4c24140e7228c7ad2.html">[Git Commit Frequency] </a><br><small class="date"><b>Created:</b> July 18, 2019</small><small class="date"><b>Tags:</b> #git #commit #frequency #bash #perl</small></li>
<li class="gist-entry" id="gist-1ceb9258b03ee4bc3a610582ea989412"><a href="gists/1ceb9258b03ee4bc3a610582ea989412.html">[BGP IP Hijack] </a><br><small class="date"><b>Created:</b> July 17, 2019</small><small class="date"><b>Tags:</b> #bgp #route #routing #as #autonomous #systems #network #networking #internet</small></li>
<li class="gist-entry" id="gist-3fb9a8d8e52d1f0725bf4026491e6f49"><a href="gists/3fb9a8d8e52d1f0725bf4026491e6f49.html">[golang cidr ip inspection] </a><br><small class="date"><b>Created:</b> July 16, 2019</small><small class="date"><b>Tags:</b> #cidr #ip #network #go #golang</small></li>
<li class="gist-entry" id="gist-568a866aa64c6c6df092601e75b98def"><a href="gists/568a866aa64c6c6df092601e75b98def.html">[transmission torrent alias] </a><br><small class="date"><b>Created:</b> July 15, 2019</small><small class="date"><b>Tags:</b> #transmission #torrent</small></li>
<li class="gist-entry" id="gist-92e09f273c42ded3d3c2521972eb092e"><a href="gists/92e09f273c42ded3d3c2521972eb092e.html">[dev deployment workflow process] </a><br><small class="date"><b>Created:</b> July 14, 2019</small><small class="date"><b>Tags:</b> #workflow #process #deployment #ci #cd</small></li>
<li class="gist-entry" id="gist-fcc7c1705f9210bf58b9391b842c8450"><a href="gists/fcc7c1705f9210bf58b9391b842c8450.html">[transmission torrent tracker add script] </a><br><small class="date"><b>Created:</b> July 6, 2019</small><small class="date"><b>Tags:</b> #tracker #torrent #client #transmission #bash #cli</small></li>
<li class="gist-entry" id="gist-48d35050d5342bb7568f04183b81ca29"><a href="gists/48d35050d5342bb7568f04183b81ca29.html">[go struct with mutex to encapsulate data from users and help hide required lock implementation] </a><br><small class="date"><b>Created:</b> June 27, 2019</small><small class="date"><b>Tags:</b> #go #golang #struct #mutex #concurrency #encapsulation</small></li>
<li class="gist-entry" id="gist-09d8caa41656d8e8447c4c6d315cb99d"><a href="gists/09d8caa41656d8e8447c4c6d315cb99d.html">[Go Test Mocking Package Function] </a><br><small class="date"><b>Created:</b> June 27, 2019</small><small class="date"><b>Tags:</b> #go #golang #mock #stub #testing #unittests #test</small></li>
<li class="gist-entry" id="gist-414fc20834cf953ee725f930e74d8acf"><a href="gists/414fc20834cf953ee725f930e74d8acf.html">[Deployment Types] </a><br><small class="date"><b>Created:</b> June 20, 2019</small><small class="date"><b>Tags:</b> #deploy #rollout #types #deployment #bluegreen #canary</small></li>
<li class="gist-entry" id="gist-ef14e3f674ad2265dbebdfa8bd015f19"><a href="gists/ef14e3f674ad2265dbebdfa8bd015f19.html">[Python Auto-Formatter] </a><br><small class="date"><b>Created:</b> June 14, 2019</small><small class="date"><b>Tags:</b> #autopep8 #black #python #format</small></li>
<li class="gist-entry" id="gist-57a5dc349137990a01d6947b359c80fc"><a href="gists/57a5dc349137990a01d6947b359c80fc.html">[Go Range List and Goroutine Async Processing with Errors] </a><br><small class="date"><b>Created:</b> June 11, 2019</small><small class="date"><b>Tags:</b> #go #golang #concurrency #goroutines #thread #map</small></li>
<li class="gist-entry" id="gist-94136fe04af40f5e9c53f0f746d4fb6e"><a href="gists/94136fe04af40f5e9c53f0f746d4fb6e.html">[Golang Range and Binary Search] </a><br><small class="date"><b>Created:</b> June 5, 2019</small><small class="date"><b>Tags:</b> #binarysearch #search #sort #go #golang #range</small></li>
<li class="gist-entry" id="gist-4b5c0cb47657e0a80d25ab6369174c72"><a href="gists/4b5c0cb47657e0a80d25ab6369174c72.html">[Golang ReverseProxy] </a><br><small class="date"><b>Created:</b> May 21, 2019</small><small class="date"><b>Tags:</b> #go #golang #reverseproxy</small></li>
<li class="gist-entry" id="gist-84d319238f95f28c680a789204fb57b4"><a href="gists/84d319238f95f28c680a789204fb57b4.html">[How Vary HTTP header works] </a><br><small class="date"><b>Created:</b> May 14, 2019</small><small class="date"><b>Tags:</b> #fastly #vcl #cdn #vary</small></li>
<li class="gist-entry" id="gist-8a2e256c20708f6fcb0d1e3a5eda799a"><a href="gists/8a2e256c20708f6fcb0d1e3a5eda799a.html">[Go Unit Table Test Example] </a><br><small class="date"><b>Created:</b> May 9, 2019</small><small class="date"><b>Tags:</b> #go #golang #tests #testing #unittest #parallel #async #table #matrix</small></li>
<li class="gist-entry" id="gist-050debbb72e596c882ce609187fd3d52"><a href="gists/050debbb72e596c882ce609187fd3d52.html">[AWS Security Group Rule - Ingress vs Egress] </a><br><small class="date"><b>Created:</b> May 9, 2019</small><small class="date"><b>Tags:</b> #aws #security #sg #sgr #rule</small></li>
<li class="gist-entry" id="gist-98b5f2822e17ba97b58639ba91335527"><a href="gists/98b5f2822e17ba97b58639ba91335527.html">[Python Poetry] </a><br><small class="date"><b>Created:</b> May 7, 2019</small><small class="date"><b>Tags:</b> #python3 #poetry</small></li>
<li class="gist-entry" id="gist-583e9ebf461fe23d1718288a73aac484"><a href="gists/583e9ebf461fe23d1718288a73aac484.html">[Python3 Stream Server] </a><br><small class="date"><b>Created:</b> May 7, 2019</small><small class="date"><b>Tags:</b> #python3 #asyncio #stream #server</small></li>
<li class="gist-entry" id="gist-68d208605633e3167df4d78f8371f3bf"><a href="gists/68d208605633e3167df4d78f8371f3bf.html">CDN Logs Sampling Rates </a><br><small class="date"><b>Created:</b> April 26, 2019</small><small class="date"><b>Tags:</b> #cdn #logs #maths #performance #costs</small></li>
<li class="gist-entry" id="gist-321700af51f3735766efe05756a88bec"><a href="gists/321700af51f3735766efe05756a88bec.html">[Symlinking] </a><br><small class="date"><b>Created:</b> April 23, 2019</small><small class="date"><b>Tags:</b> #terminal #command #symlink</small></li>
<li class="gist-entry" id="gist-769d16edbc7791ab4e6a61983162b964"><a href="gists/769d16edbc7791ab4e6a61983162b964.html">[Fastly Create Users + API tokens for Auditing purposes] </a><br><small class="date"><b>Created:</b> April 16, 2019</small><small class="date"><b>Tags:</b> #fastly #cli #auth #api</small></li>
<li class="gist-entry" id="gist-b904c5b29f050fd4936a7f04dba043ae"><a href="gists/b904c5b29f050fd4936a7f04dba043ae.html">[Fastly VCL Multiplication] </a><br><small class="date"><b>Created:</b> April 16, 2019</small><small class="date"><b>Tags:</b> #fastly #vcl #cdn #multiplication</small></li>
<li class="gist-entry" id="gist-3e835b07842cfab4dfd11d2047ffd7dd"><a href="gists/3e835b07842cfab4dfd11d2047ffd7dd.html">[Bash script with dynamic values for inputs using Expect] </a><br><small class="date"><b>Created:</b> April 11, 2019</small><small class="date"><b>Tags:</b> #bash #shell #expect #dynamic #script #input #password</small></li>
<li class="gist-entry" id="gist-a368e3e3d4693652b67ea6199cb42c2b"><a href="gists/a368e3e3d4693652b67ea6199cb42c2b.html">Python: AWS Lambda sending S3 Fastly streamed logs to Datadog </a><br><small class="date"><b>Created:</b> April 11, 2019</small><small class="date"><b>Tags:</b> #aws #python #logs</small></li>
<li class="gist-entry" id="gist-5106e8af59c780826faf5ad04a116184"><a href="gists/5106e8af59c780826faf5ad04a116184.html">[Backup Private GPG Key] </a><br><small class="date"><b>Created:</b> April 9, 2019</small><small class="date"><b>Tags:</b> #gpg #backup #private #key</small></li>
<li class="gist-entry" id="gist-00387caeb4d68bb0c0ef862c3de3459d"><a href="gists/00387caeb4d68bb0c0ef862c3de3459d.html">[Lightline Status Line Tweaks] </a><br><small class="date"><b>Created:</b> April 8, 2019</small><small class="date"><b>Tags:</b> #vim #lightline #powerline #statusline</small></li>
<li class="gist-entry" id="gist-67b3cff501cbeef421113c39bd86b5c5"><a href="gists/67b3cff501cbeef421113c39bd86b5c5.html">[Vim Highlight Current Line] </a><br><small class="date"><b>Created:</b> April 8, 2019</small><small class="date"><b>Tags:</b> #vim #highlight #line</small></li>
<li class="gist-entry" id="gist-4eb10817e06a69bd511f14d2370e2d45"><a href="gists/4eb10817e06a69bd511f14d2370e2d45.html">[Vim open current line in GitHub UI] </a><br><small class="date"><b>Created:</b> April 8, 2019</small><small class="date"><b>Tags:</b> #github #git #vim</small></li>
<li class="gist-entry" id="gist-27d19b9f1fd50699264e40bc1be89247"><a href="gists/27d19b9f1fd50699264e40bc1be89247.html">[Lazy Load NVM] </a><br><small class="date"><b>Created:</b> April 8, 2019</small><small class="date"><b>Tags:</b> #lazy #load #nvm #node</small></li>
<li class="gist-entry" id="gist-024582e886a039a022cc7359dfc6f8e3"><a href="gists/024582e886a039a022cc7359dfc6f8e3.html">Generate UUID (Universally Unique Identifier) </a><br><small class="date"><b>Created:</b> April 8, 2019</small><small class="date"><b>Tags:</b> #uuid</small></li>
<li class="gist-entry" id="gist-edda7d0af6a26f2413433003a10fceb5"><a href="gists/edda7d0af6a26f2413433003a10fceb5.html">[Generate SSH Key] </a><br><small class="date"><b>Created:</b> April 8, 2019</small><small class="date"><b>Tags:</b> #generate #ssh #key</small></li>
<li class="gist-entry" id="gist-63d0318b9f9b38ccd1afea947a76a9a2"><a href="gists/63d0318b9f9b38ccd1afea947a76a9a2.html">[Docker Cleanup Remove Prune] </a><br><small class="date"><b>Created:</b> April 8, 2019</small><small class="date"><b>Tags:</b> #docker #remove #cleanup #prune</small></li>
<li class="gist-entry" id="gist-df829fd78bda3d593fa00e67e10f8436"><a href="gists/df829fd78bda3d593fa00e67e10f8436.html">[Simple Vim TODO list] </a><br><small class="date"><b>Created:</b> April 8, 2019</small><small class="date"><b>Tags:</b> #vim #gtd #todo</small></li>
<li class="gist-entry" id="gist-b0f4c62d38761babfd8616694a852024"><a href="gists/b0f4c62d38761babfd8616694a852024.html">[Bash Print All Alias'] </a><br><small class="date"><b>Created:</b> April 8, 2019</small><small class="date"><b>Tags:</b> #bash #alias #list</small></li>
<li class="gist-entry" id="gist-1d3030ef6ef539de9d873d19b98cc38f"><a href="gists/1d3030ef6ef539de9d873d19b98cc38f.html">[Python -m cli flag] </a><br><small class="date"><b>Created:</b> April 3, 2019</small><small class="date"><b>Tags:</b> #python #cli #flag</small></li>
<li class="gist-entry" id="gist-e73a5f698058493e25eb301c4bcbf972"><a href="gists/e73a5f698058493e25eb301c4bcbf972.html">[AWS Athena SQL] </a><br><small class="date"><b>Created:</b> April 2, 2019</small><small class="date"><b>Tags:</b> #aws #athena #s3 #sql</small></li>
<li class="gist-entry" id="gist-35c2190befc0229771367397be20c98e"><a href="gists/35c2190befc0229771367397be20c98e.html">Fastly JSON Logging </a><br><small class="date"><b>Created:</b> April 2, 2019</small><small class="date"><b>Tags:</b> #fastly #cdn #logs #json</small></li>
<li class="gist-entry" id="gist-4500e029ee24d160da944039274f7003"><a href="gists/4500e029ee24d160da944039274f7003.html">[Python VirtualEnv Dockerized] </a><br><small class="date"><b>Created:</b> April 1, 2019</small><small class="date"><b>Tags:</b> #python #virtualenv #docker #venv</small></li>
<li class="gist-entry" id="gist-8d0e9896b31a7145dd84f3093974404c"><a href="gists/8d0e9896b31a7145dd84f3093974404c.html">[Fastly Purge with Python] </a><br><small class="date"><b>Created:</b> March 26, 2019</small><small class="date"><b>Tags:</b> #python #tornado #cli #purge #cache #fastly #cdn</small></li>
<li class="gist-entry" id="gist-4396c5b9d3466800da85405c4b57866a"><a href="gists/4396c5b9d3466800da85405c4b57866a.html">[Golang Line Counter Alternative] </a><br><small class="date"><b>Created:</b> March 8, 2019</small><small class="date"><b>Tags:</b> #go #golang #line #counter</small></li>
<li class="gist-entry" id="gist-5e2cfb0b3f7dcd9ff0eda4ee974e6fb1"><a href="gists/5e2cfb0b3f7dcd9ff0eda4ee974e6fb1.html">[Python Security Hashing] </a><br><small class="date"><b>Created:</b> March 6, 2019</small><small class="date"><b>Tags:</b> #python #security #hashing #hash</small></li>
<li class="gist-entry" id="gist-b2dded9dfa43e7858ec6ccea33ea3dc4"><a href="gists/b2dded9dfa43e7858ec6ccea33ea3dc4.html">[Business Success] </a><br><small class="date"><b>Created:</b> March 1, 2019</small><small class="date"><b>Tags:</b> #business #product #focus #priority #success</small></li>
<li class="gist-entry" id="gist-fb0f19802a7021fbdefae39c6de9fc3b"><a href="gists/fb0f19802a7021fbdefae39c6de9fc3b.html">[Calculating BigO] </a><br><small class="date"><b>Created:</b> February 27, 2019</small><small class="date"><b>Tags:</b> #bigo #algorithms #analysis</small></li>
<li class="gist-entry" id="gist-bb12b7c70da37501c62014789c3c0827"><a href="gists/bb12b7c70da37501c62014789c3c0827.html">[Partial Application in Golang] </a><br><small class="date"><b>Created:</b> February 26, 2019</small><small class="date"><b>Tags:</b> #go #golang #fp #partialapplication</small></li>
<li class="gist-entry" id="gist-c6ca97498a25911d17ca93a39d723dcc"><a href="gists/c6ca97498a25911d17ca93a39d723dcc.html">[Simple Tornado] </a><br><small class="date"><b>Created:</b> February 26, 2019</small><small class="date"><b>Tags:</b> #python #python3 #tornado #example #basic #simple</small></li>
<li class="gist-entry" id="gist-c86d2fba3cceddb3afb7b51ebe6a95d5"><a href="gists/c86d2fba3cceddb3afb7b51ebe6a95d5.html">[Single Sign-On SSO] </a><br><small class="date"><b>Created:</b> February 22, 2019</small><small class="date"><b>Tags:</b> #sso #singlesignon #auth #multipledomains #aws</small></li>
<li class="gist-entry" id="gist-5e0008a16da806cac32c7db0e0f6b251"><a href="gists/5e0008a16da806cac32c7db0e0f6b251.html">[Golang Design Patterns] </a><br><small class="date"><b>Created:</b> February 22, 2019</small><small class="date"><b>Tags:</b> #go #golang #design</small></li>
<li class="gist-entry" id="gist-fee3c008296cb3e0a16ec8fdfcdc371b"><a href="gists/fee3c008296cb3e0a16ec8fdfcdc371b.html">[Python Exception Handling Guidelines] </a><br><small class="date"><b>Created:</b> February 20, 2019</small><small class="date"><b>Tags:</b> #python #exceptions #design #guidelines</small></li>
<li class="gist-entry" id="gist-5b4c9489bf307da542d5f087adbbff42"><a href="gists/5b4c9489bf307da542d5f087adbbff42.html">[Golang Print over last line - like a counter] </a><br><small class="date"><b>Created:</b> February 20, 2019</small><small class="date"><b>Tags:</b> #go #golang #counter #inplace #print</small></li>
<li class="gist-entry" id="gist-a51d5f876f1ee2259915548ad6d1f963"><a href="gists/a51d5f876f1ee2259915548ad6d1f963.html">[Set same cookie on multiple domains] </a><br><small class="date"><b>Created:</b> February 18, 2019</small><small class="date"><b>Tags:</b> #cookie #multiple #domains</small></li>
<li class="gist-entry" id="gist-e5316d6b9e4046e07180c821f391de22"><a href="gists/e5316d6b9e4046e07180c821f391de22.html">[Golang Pretty Print] </a><br><small class="date"><b>Created:</b> February 6, 2019</small><small class="date"><b>Tags:</b> #go #golang #prettyprint</small></li>
<li class="gist-entry" id="gist-1d119f758edb2d8fa3e074fdc209b742"><a href="gists/1d119f758edb2d8fa3e074fdc209b742.html">[Python Internals] </a><br><small class="date"><b>Created:</b> January 29, 2019</small><small class="date"><b>Tags:</b> #python #internals</small></li>
<li class="gist-entry" id="gist-0feb183ff45964403b2722f2f37c40cb"><a href="gists/0feb183ff45964403b2722f2f37c40cb.html">[Rollout strategies for large code changes] </a><br><small class="date"><b>Created:</b> January 7, 2019</small><small class="date"><b>Tags:</b> #rollout #strategy #plans #strangler #pattern</small></li>
<li class="gist-entry" id="gist-ff7065a6c74b7cf8bfd58fcd32dfd9f1"><a href="gists/ff7065a6c74b7cf8bfd58fcd32dfd9f1.html">[Sed Replace Pattern with File Contents] </a><br><small class="date"><b>Created:</b> December 25, 2018</small><small class="date"><b>Tags:</b> #sed #bash #replace</small></li>
<li class="gist-entry" id="gist-2b01cfdaf9c85efb0de6e2b2085896c3"><a href="gists/2b01cfdaf9c85efb0de6e2b2085896c3.html">[Vim handling stdin] </a><br><small class="date"><b>Created:</b> December 22, 2018</small><small class="date"><b>Tags:</b> #vim #stdin</small></li>
<li class="gist-entry" id="gist-7aa06d40c58e5d47f25780fda887d142"><a href="gists/7aa06d40c58e5d47f25780fda887d142.html">[Vim Directory Structure, Start-up and Debugging] </a><br><small class="date"><b>Created:</b> December 22, 2018</small><small class="date"><b>Tags:</b> #vim #directory #structure #startup #debugging #debug</small></li>
<li class="gist-entry" id="gist-095fbd52f488ca295ae9fd408973587a"><a href="gists/095fbd52f488ca295ae9fd408973587a.html">[Vim Arg List and Searching] </a><br><small class="date"><b>Created:</b> December 19, 2018</small><small class="date"><b>Tags:</b> #vim #vimgrep #arglist #search #regex</small></li>
<li class="gist-entry" id="gist-4f7d9498070f530c50d005d16bb019c5"><a href="gists/4f7d9498070f530c50d005d16bb019c5.html">[Python TTL Cache Decorator] </a><br><small class="date"><b>Created:</b> November 25, 2018</small><small class="date"><b>Tags:</b> #python #decorator #async #ttl #cache</small></li>
<li class="gist-entry" id="gist-31bd757258a956d49c0504b36903e2d7"><a href="gists/31bd757258a956d49c0504b36903e2d7.html">[Python String Formatting] </a><br><small class="date"><b>Created:</b> November 22, 2018</small><small class="date"><b>Tags:</b> #python #string #formatting</small></li>
<li class="gist-entry" id="gist-0548b4c9189653854cf4f06d0469c86f"><a href="gists/0548b4c9189653854cf4f06d0469c86f.html">[Python Tornado UVLoop] </a><br><small class="date"><b>Created:</b> November 16, 2018</small><small class="date"><b>Tags:</b> #python #tornado #uvloop</small></li>
<li class="gist-entry" id="gist-9817c8654a92df0cc887c21549b49356"><a href="gists/9817c8654a92df0cc887c21549b49356.html">[Python pytest] </a><br><small class="date"><b>Created:</b> November 16, 2018</small><small class="date"><b>Tags:</b> #pytest</small></li>
<li class="gist-entry" id="gist-ca30ae8a609f715aadf4f5a2b63ed239"><a href="gists/ca30ae8a609f715aadf4f5a2b63ed239.html">[Go Modules] </a><br><small class="date"><b>Created:</b> November 16, 2018</small><small class="date"><b>Tags:</b> #go #golang #modules #dependencies #vendoring</small></li>
<li class="gist-entry" id="gist-cc04c2c34a988be26e56fe2f3ea95aff"><a href="gists/cc04c2c34a988be26e56fe2f3ea95aff.html">[Python Interfaces via Protocols and Abstract Base Classes (with Metaclasses)] </a><br><small class="date"><b>Created:</b> November 13, 2018</small><small class="date"><b>Tags:</b> #python #interfaces #protocols #design #collections #abc #iterator #sized #metaclasses #abstract</small></li>
<li class="gist-entry" id="gist-bee893792f152e1d5e68fdecffb7e289"><a href="gists/bee893792f152e1d5e68fdecffb7e289.html">[Avoid Negative Language] </a><br><small class="date"><b>Created:</b> November 13, 2018</small><small class="date"><b>Tags:</b> #language #negative #avoid</small></li>
<li class="gist-entry" id="gist-ee8e14571d9781cd74f1b1e8052f3c65"><a href="gists/ee8e14571d9781cd74f1b1e8052f3c65.html">[Python API Design] </a><br><small class="date"><b>Created:</b> November 12, 2018</small><small class="date"><b>Tags:</b> #api #design #python</small></li>
<li class="gist-entry" id="gist-cdb39290c32826b40cd50b59ba7afc22"><a href="gists/cdb39290c32826b40cd50b59ba7afc22.html">[Python algorithm to generate single list] </a><br><small class="date"><b>Created:</b> November 7, 2018</small><small class="date"><b>Tags:</b> #algorithm #python</small></li>
<li class="gist-entry" id="gist-822089746ef730a7adfb98c1e230955b"><a href="gists/822089746ef730a7adfb98c1e230955b.html">[Python Named Tuples Default Values] </a><br><small class="date"><b>Created:</b> November 1, 2018</small><small class="date"><b>Tags:</b> #python #defaults #namedtuple</small></li>
<li class="gist-entry" id="gist-52b2f7a9fe0c230d310c8a65a7bbf3d6"><a href="gists/52b2f7a9fe0c230d310c8a65a7bbf3d6.html">[Python Mocking] </a><br><small class="date"><b>Created:</b> October 30, 2018</small><small class="date"><b>Tags:</b> #python #mocking #mocks #tornado</small></li>
<li class="gist-entry" id="gist-75df27f55c1fac0cb52838bffa7638b9"><a href="gists/75df27f55c1fac0cb52838bffa7638b9.html">[Python Tornado Queue] </a><br><small class="date"><b>Created:</b> October 29, 2018</small><small class="date"><b>Tags:</b> #python #tornado #queue</small></li>
<li class="gist-entry" id="gist-dbdd2fc992a934ea3986a8959a10fbb6"><a href="gists/dbdd2fc992a934ea3986a8959a10fbb6.html">[Python Custom Iterator] </a><br><small class="date"><b>Created:</b> October 25, 2018</small><small class="date"><b>Tags:</b> #python #iterator</small></li>
<li class="gist-entry" id="gist-20ff7427d3df5cc02d5a619ca0cd9695"><a href="gists/20ff7427d3df5cc02d5a619ca0cd9695.html">[Go Guru and Vim-Go] </a><br><small class="date"><b>Created:</b> October 16, 2018</small><small class="date"><b>Tags:</b> #go #golang #guru #interfaces #vim #vim-go</small></li>
<li class="gist-entry" id="gist-f6ba7569f055103ca8b602422eb4f994"><a href="gists/f6ba7569f055103ca8b602422eb4f994.html">[Vim Regex] </a><br><small class="date"><b>Created:</b> October 15, 2018</small><small class="date"><b>Tags:</b> #vim #regex #lookaround #assertions</small></li>
<li class="gist-entry" id="gist-6d9444532e5b500942ebc8759c278d2f"><a href="gists/6d9444532e5b500942ebc8759c278d2f.html">[Bash loop files in a directory and check their types] </a><br><small class="date"><b>Created:</b> October 14, 2018</small><small class="date"><b>Tags:</b> #bash #directory #file #search</small></li>
<li class="gist-entry" id="gist-74f55c0587238536f24644715e0f3325"><a href="gists/74f55c0587238536f24644715e0f3325.html">[Golang Long and Short Flags] </a><br><small class="date"><b>Created:</b> October 3, 2018</small><small class="date"><b>Tags:</b> #go #golang #flags</small></li>
<li class="gist-entry" id="gist-1140bcd773616ecdae9bb4d2e9e55b34"><a href="gists/1140bcd773616ecdae9bb4d2e9e55b34.html">Python: Dynamic Log Levels via Abstraction </a><br><small class="date"><b>Created:</b> September 27, 2018</small><small class="date"><b>Tags:</b> #python #logs</small></li>
<li class="gist-entry" id="gist-120a791c8a8e8170d60cc72d197b5b67"><a href="gists/120a791c8a8e8170d60cc72d197b5b67.html">GitHub: Collapsible Drop Down Menus </a><br><small class="date"><b>Created:</b> September 25, 2018</small><small class="date"><b>Tags:</b> #GitHub #Collapsible #DropDown #Menus</small></li>
<li class="gist-entry" id="gist-ff7930457efc34134cc982b486f2b4c5"><a href="gists/ff7930457efc34134cc982b486f2b4c5.html">[Python Tornado Generic Exception Handling] </a><br><small class="date"><b>Created:</b> September 24, 2018</small><small class="date"><b>Tags:</b> #python #tornado #exceptions #handling</small></li>
<li class="gist-entry" id="gist-848b13a9be823090e7dfc230d5bcce41"><a href="gists/848b13a9be823090e7dfc230d5bcce41.html">[Python Decorator Order] </a><br><small class="date"><b>Created:</b> September 24, 2018</small><small class="date"><b>Tags:</b> #python #decorator #order</small></li>
<li class="gist-entry" id="gist-8d2744cf001c689425568e75c3b75ffa"><a href="gists/8d2744cf001c689425568e75c3b75ffa.html">[Modern JS] </a><br><small class="date"><b>Created:</b> September 24, 2018</small><small class="date"><b>Tags:</b> #javascript #js #modern #tools #transpilers #babel #webpack</small></li>
<li class="gist-entry" id="gist-4f0318075092b6d2c3d2624b3f57ebec"><a href="gists/4f0318075092b6d2c3d2624b3f57ebec.html">[Fastly Edge Dictionaries API Examples] </a><br><small class="date"><b>Created:</b> September 14, 2018</small><small class="date"><b>Tags:</b> #fastly #api #cdn #edge #dictionaries #bash #shell</small></li>
<li class="gist-entry" id="gist-18ef92e020b6dcb074f49d799f4cc67f"><a href="gists/18ef92e020b6dcb074f49d799f4cc67f.html">[Python Tornado Header Authorization Check] </a><br><small class="date"><b>Created:</b> September 6, 2018</small><small class="date"><b>Tags:</b> #python #tornado #authorization #access</small></li>
<li class="gist-entry" id="gist-93a64b36c0c029b1d851f70000a551fa"><a href="gists/93a64b36c0c029b1d851f70000a551fa.html">[Python Generic Exception Logging] </a><br><small class="date"><b>Created:</b> September 4, 2018</small><small class="date"><b>Tags:</b> #python #exceptions #error #logging</small></li>
<li class="gist-entry" id="gist-b7d50026b01e3a2f613a4c263a913ef9"><a href="gists/b7d50026b01e3a2f613a4c263a913ef9.html">[Python Get Function Name Dynamically At Runtime] </a><br><small class="date"><b>Created:</b> September 4, 2018</small><small class="date"><b>Tags:</b> #python #inspect #stack</small></li>
<li class="gist-entry" id="gist-364ee91f21df42fc0673749966600775"><a href="gists/364ee91f21df42fc0673749966600775.html">[API Documentation Example] </a><br><small class="date"><b>Created:</b> September 4, 2018</small><small class="date"><b>Tags:</b> #API #documentation</small></li>
<li class="gist-entry" id="gist-16707fd0b9f1869f479325ea8dab90e6"><a href="gists/16707fd0b9f1869f479325ea8dab90e6.html">[Python Exception Handling Attributes] </a><br><small class="date"><b>Created:</b> August 31, 2018</small><small class="date"><b>Tags:</b> #python #exceptions</small></li>
<li class="gist-entry" id="gist-b9aa8e225ade0f78fcb57e1852627785"><a href="gists/b9aa8e225ade0f78fcb57e1852627785.html">[SLI, SLO, SLA] </a><br><small class="date"><b>Created:</b> August 6, 2018</small><small class="date"><b>Tags:</b> #SLI #SLO #SLA #Process #Service</small></li>
<li class="gist-entry" id="gist-af300f602fa4da8cc14863f36a24bd1e"><a href="gists/af300f602fa4da8cc14863f36a24bd1e.html">[Build Go from source] </a><br><small class="date"><b>Created:</b> August 3, 2018</small><small class="date"><b>Tags:</b> #go #golang #compile #source</small></li>
<li class="gist-entry" id="gist-a096c0fae0fc8061eefb17eb79e13717"><a href="gists/a096c0fae0fc8061eefb17eb79e13717.html">[APT Search for Packages using Cache command] </a><br><small class="date"><b>Created:</b> July 31, 2018</small><small class="date"><b>Tags:</b> #apt #cache #packages #search</small></li>
<li class="gist-entry" id="gist-8da2dfefd8b41c0d8e4f39be5251ad3d"><a href="gists/8da2dfefd8b41c0d8e4f39be5251ad3d.html">[Compile NGINX from source, including its dependencies] </a><br><small class="date"><b>Created:</b> July 30, 2018</small><small class="date"><b>Tags:</b> #nginx #open-source #compile #build</small></li>
<li class="gist-entry" id="gist-cfd543d2fb68eb2f14c3f02d14f64226"><a href="gists/cfd543d2fb68eb2f14c3f02d14f64226.html">[Sed Ignore Lines] </a><br><small class="date"><b>Created:</b> July 30, 2018</small><small class="date"><b>Tags:</b> #sed #ignore #regex #patterns</small></li>
<li class="gist-entry" id="gist-7dfb75e058f584761948169a93dd1838"><a href="gists/7dfb75e058f584761948169a93dd1838.html">[Python Tornado Decorator with arguments] </a><br><small class="date"><b>Created:</b> July 20, 2018</small><small class="date"><b>Tags:</b> #python #decorator #tornado #dict #compare</small></li>
<li class="gist-entry" id="gist-66f50ed461f12157419a13152436b5e4"><a href="gists/66f50ed461f12157419a13152436b5e4.html">[Distributed Tracing] </a><br><small class="date"><b>Created:</b> July 19, 2018</small><small class="date"><b>Tags:</b> #distributed #tracing</small></li>
<li class="gist-entry" id="gist-6d0ee04eb68ecfdaab8509b1eccadc98"><a href="gists/6d0ee04eb68ecfdaab8509b1eccadc98.html">[Memory Sharing] </a><br><small class="date"><b>Created:</b> July 19, 2018</small><small class="date"><b>Tags:</b> #python #rss #resident #virtual #memory</small></li>
<li class="gist-entry" id="gist-242cb31de57b33066c26ab366de5aacc"><a href="gists/242cb31de57b33066c26ab366de5aacc.html">[Mature Engineers] </a><br><small class="date"><b>Created:</b> July 18, 2018</small><small class="date"><b>Tags:</b> #mature #senior #developer #qualities #engineer</small></li>
<li class="gist-entry" id="gist-ede3fe461213844bb8b8685f1fee44af"><a href="gists/ede3fe461213844bb8b8685f1fee44af.html">[Convert synchronous external Python code into asynchronous code] </a><br><small class="date"><b>Created:</b> July 13, 2018</small><small class="date"><b>Tags:</b> #python #tornado #sync #async #requests #urllib</small></li>
<li class="gist-entry" id="gist-887fd2c395e8096c4030ac056552131d"><a href="gists/887fd2c395e8096c4030ac056552131d.html">[Calculate cost of electrical appliances] </a><br><small class="date"><b>Created:</b> July 7, 2018</small><small class="date"><b>Tags:</b> #electrics #cost #money #calculate #home</small></li>
<li class="gist-entry" id="gist-7c4cbd811acb2d9719b5288198a1882b"><a href="gists/7c4cbd811acb2d9719b5288198a1882b.html">[Tornado AsyncHTTPClient POST form params example] </a><br><small class="date"><b>Created:</b> July 3, 2018</small><small class="date"><b>Tags:</b> #python #tornado #post #httpclient #asynchttpclient</small></li>
<li class="gist-entry" id="gist-11bf6bfb16a9b5fccef2764f8b4d2b67"><a href="gists/11bf6bfb16a9b5fccef2764f8b4d2b67.html">[URI Regex] </a><br><small class="date"><b>Created:</b> July 2, 2018</small><small class="date"><b>Tags:</b> #regex</small></li>
<li class="gist-entry" id="gist-15e50d705424e41e1f4f035dc43fa7fc"><a href="gists/15e50d705424e41e1f4f035dc43fa7fc.html">[Python Boto Exception Handling] </a><br><small class="date"><b>Created:</b> June 21, 2018</small><small class="date"><b>Tags:</b> #boto #boto3 #python #cognito #aws</small></li>
<li class="gist-entry" id="gist-d82ed806ce634c30329fae88427f18f8"><a href="gists/d82ed806ce634c30329fae88427f18f8.html">Homebrew: Formula Example </a><br><small class="date"><b>Created:</b> June 18, 2018</small><small class="date"><b>Tags:</b> #homebrew #package</small></li>
<li class="gist-entry" id="gist-252aa731f5aee6933f4bbc96bdceb921"><a href="gists/252aa731f5aee6933f4bbc96bdceb921.html">[Basic `tree` command written in Go] </a><br><small class="date"><b>Created:</b> June 15, 2018</small><small class="date"><b>Tags:</b> #go #golang #tree</small></li>
<li class="gist-entry" id="gist-a7dda88c5959e3684fc9cd467464813d"><a href="gists/a7dda88c5959e3684fc9cd467464813d.html">[Memorize Days in the Month] </a><br><small class="date"><b>Created:</b> June 14, 2018</small><small class="date"><b>Tags:</b> #month #day #calendar</small></li>
<li class="gist-entry" id="gist-865863da8fa5312e75b6a6787578086f"><a href="gists/865863da8fa5312e75b6a6787578086f.html">[Bash remove whitelist] </a><br><small class="date"><b>Created:</b> June 12, 2018</small><small class="date"><b>Tags:</b> #bash #remove #whitelist</small></li>
<li class="gist-entry" id="gist-07d62f6a55ba42481b23458c15c00e27"><a href="gists/07d62f6a55ba42481b23458c15c00e27.html">[Python Lambda] </a><br><small class="date"><b>Created:</b> June 12, 2018</small><small class="date"><b>Tags:</b> #aws #lambda #makefile #python #cognito</small></li>
<li class="gist-entry" id="gist-042d1d6c93efa390b15b19e2f3f3827a"><a href="gists/042d1d6c93efa390b15b19e2f3f3827a.html">[Vim substitution examples] </a><br><small class="date"><b>Created:</b> June 7, 2018</small><small class="date"><b>Tags:</b> #vim #substitution #replace #global #viml #forloop #vimscript</small></li>
<li class="gist-entry" id="gist-8f7e646ffa87f0e16ea6ec05974bc5db"><a href="gists/8f7e646ffa87f0e16ea6ec05974bc5db.html">[Python Multiple Characters String Replacement] </a><br><small class="date"><b>Created:</b> June 7, 2018</small><small class="date"><b>Tags:</b> #python #replacement #string #translate</small></li>
<li class="gist-entry" id="gist-fd603239cacbb3d3d317950905b76096"><a href="gists/fd603239cacbb3d3d317950905b76096.html">[Tornado AsyncHTTPClient - No Web Server] </a><br><small class="date"><b>Created:</b> June 7, 2018</small><small class="date"><b>Tags:</b> #python #pipenv #tornado #async #concurrency #httpclient #asynchttpclient #tox #ini #basicauth #auth</small></li>
<li class="gist-entry" id="gist-a654cfef4d2e7713d89a5d1624f6453f"><a href="gists/a654cfef4d2e7713d89a5d1624f6453f.html">[Tiny Docker Builds] </a><br><small class="date"><b>Created:</b> May 24, 2018</small><small class="date"><b>Tags:</b> #go #golang #docker #build</small></li>
<li class="gist-entry" id="gist-7d9b10e7f691605792cc182910eb070f"><a href="gists/7d9b10e7f691605792cc182910eb070f.html">Go: Server Boilerplate </a><br><small class="date"><b>Created:</b> May 24, 2018</small><small class="date"><b>Tags:</b> #go #http #project</small></li>
<li class="gist-entry" id="gist-0fd4f4b627ce3aef0278862bd16e4b71"><a href="gists/0fd4f4b627ce3aef0278862bd16e4b71.html">[Project Management] </a><br><small class="date"><b>Created:</b> May 24, 2018</small><small class="date"><b>Tags:</b> #management #process #project #pm</small></li>
<li class="gist-entry" id="gist-9e0c5ee9c2cc2568dd1961bf370716c9"><a href="gists/9e0c5ee9c2cc2568dd1961bf370716c9.html">[Python's Pipenv] </a><br><small class="date"><b>Created:</b> May 23, 2018</small><small class="date"><b>Tags:</b> #python #pip #pipenv #virtualenv</small></li>
<li class="gist-entry" id="gist-1f07d02d411958f024eddd387b37fc19"><a href="gists/1f07d02d411958f024eddd387b37fc19.html">[Python Warrant Cognito] </a><br><small class="date"><b>Created:</b> May 10, 2018</small><small class="date"><b>Tags:</b> #python #cognito</small></li>
<li class="gist-entry" id="gist-264293f57bd07c302f683aeda4bbe598"><a href="gists/264293f57bd07c302f683aeda4bbe598.html">[Python Cookies] </a><br><small class="date"><b>Created:</b> May 10, 2018</small><small class="date"><b>Tags:</b> #python #cookies</small></li>
<li class="gist-entry" id="gist-979098ebd90a0820456c246c4224f770"><a href="gists/979098ebd90a0820456c246c4224f770.html">[Fastly VCL Boilerplate for handling mutliple subdomains] </a><br><small class="date"><b>Created:</b> May 4, 2018</small><small class="date"><b>Tags:</b> #fastly #vcl #boilerplate</small></li>
<li class="gist-entry" id="gist-f04b2ac395bd6ded45efcfb4fceec5a4"><a href="gists/f04b2ac395bd6ded45efcfb4fceec5a4.html">[AWS Amplify Tips] </a><br><small class="date"><b>Created:</b> May 1, 2018</small><small class="date"><b>Tags:</b> #aws #amplify #cognito #js #javascript</small></li>
<li class="gist-entry" id="gist-ddaab0ae0ee43b8c7c3e88b8cf6b88cd"><a href="gists/ddaab0ae0ee43b8c7c3e88b8cf6b88cd.html">[React JS] </a><br><small class="date"><b>Created:</b> May 1, 2018</small><small class="date"><b>Tags:</b> #js #javascript #react</small></li>
<li class="gist-entry" id="gist-a29f00053771789914baa652c104cac8"><a href="gists/a29f00053771789914baa652c104cac8.html">[ElasticSearch] </a><br><small class="date"><b>Created:</b> April 30, 2018</small><small class="date"><b>Tags:</b> #elasticsearch</small></li>
<li class="gist-entry" id="gist-e2f3ff5522d20605874e1ce18258bc02"><a href="gists/e2f3ff5522d20605874e1ce18258bc02.html">[Dockerize Node] </a><br><small class="date"><b>Created:</b> April 30, 2018</small><small class="date"><b>Tags:</b> #docker #node</small></li>
<li class="gist-entry" id="gist-916c150d64ccafb4bf7ad74650b4a6a9"><a href="gists/916c150d64ccafb4bf7ad74650b4a6a9.html">[Python Type Hinting MyPy] </a><br><small class="date"><b>Created:</b> April 25, 2018</small><small class="date"><b>Tags:</b> #mypy #python #types #hinting</small></li>
<li class="gist-entry" id="gist-32d2d7a30c1efe14316d28d74a821600"><a href="gists/32d2d7a30c1efe14316d28d74a821600.html">[Simple Math and Notation] </a><br><small class="date"><b>Created:</b> April 9, 2018</small><small class="date"><b>Tags:</b> #math #number #notation #decimal #point #metric #prefix</small></li>
<li class="gist-entry" id="gist-faffc17e27185cd8271e942f69a811b2"><a href="gists/faffc17e27185cd8271e942f69a811b2.html">[Golang Prevent Directory Listing with Static FileServer] </a><br><small class="date"><b>Created:</b> April 3, 2018</small><small class="date"><b>Tags:</b> #static #fileserver #go #golang</small></li>
<li class="gist-entry" id="gist-430fec07b713e2480f718d78550cc32a"><a href="gists/430fec07b713e2480f718d78550cc32a.html">[Python timestamp to epoch and back, inc. UTC timezone] </a><br><small class="date"><b>Created:</b> April 3, 2018</small><small class="date"><b>Tags:</b> #python #timezone #timestamp #epoch #utc</small></li>
<li class="gist-entry" id="gist-21819f5dd4ded1ebdf48ea01e882dd01"><a href="gists/21819f5dd4ded1ebdf48ea01e882dd01.html">[Topics to discuss with a new employer] </a><br><small class="date"><b>Created:</b> April 3, 2018</small><small class="date"><b>Tags:</b> #jobs #culture #questions</small></li>
<li class="gist-entry" id="gist-4cd6aed3c58ae99b58e62cf2c76ea836"><a href="gists/4cd6aed3c58ae99b58e62cf2c76ea836.html">[Go Standard Lib HTTP Routing] </a><br><small class="date"><b>Created:</b> March 28, 2018</small><small class="date"><b>Tags:</b> #go #golang #http #routing #mux #http</small></li>
<li class="gist-entry" id="gist-60267c6185518a8ed8b4dcaff47891a2"><a href="gists/60267c6185518a8ed8b4dcaff47891a2.html">[Go Middleware] </a><br><small class="date"><b>Created:</b> March 27, 2018</small><small class="date"><b>Tags:</b> #golang #go #middleware</small></li>
<li class="gist-entry" id="gist-8a3cce24fe7a5794eafd445a33b0e03f"><a href="gists/8a3cce24fe7a5794eafd445a33b0e03f.html">[Security Tools] </a><br><small class="date"><b>Created:</b> March 26, 2018</small><small class="date"><b>Tags:</b> #security #pentesting</small></li>
<li class="gist-entry" id="gist-9d7d82d9f702ffd4b17d909d3458015e"><a href="gists/9d7d82d9f702ffd4b17d909d3458015e.html">[Grammar] </a><br><small class="date"><b>Created:</b> March 26, 2018</small><small class="date"><b>Tags:</b> #grammar #english #language</small></li>
<li class="gist-entry" id="gist-6e45b59b45884eddb2e4f4cf955d653e"><a href="gists/6e45b59b45884eddb2e4f4cf955d653e.html">[Maths: variations/possible combinations] </a><br><small class="date"><b>Created:</b> March 20, 2018</small><small class="date"><b>Tags:</b> #math #factorials #exponents #power #raise</small></li>
<li class="gist-entry" id="gist-92ad26edc5ff8d4e52b768e85c8ef346"><a href="gists/92ad26edc5ff8d4e52b768e85c8ef346.html">[SDK and API] </a><br><small class="date"><b>Created:</b> March 19, 2018</small><small class="date"><b>Tags:</b> #sdk #api</small></li>
<li class="gist-entry" id="gist-7153194c9183fd54b97a1d5af71947ae"><a href="gists/7153194c9183fd54b97a1d5af71947ae.html">[GPN: Ganners Pipe Notation] </a><br><small class="date"><b>Created:</b> March 19, 2018</small><small class="date"><b>Tags:</b> #GPN #design #architecture #systems</small></li>
<li class="gist-entry" id="gist-e428e20a636b3a9ace3238d8412c7670"><a href="gists/e428e20a636b3a9ace3238d8412c7670.html">[Varnish VCL Basic Authentication] </a><br><small class="date"><b>Created:</b> March 16, 2018</small><small class="date"><b>Tags:</b> #security #basicauth #authentication #vcl #varnish #fastly #cdn</small></li>
<li class="gist-entry" id="gist-5d5aa78b13576b98358d019d32bbfe2a"><a href="gists/5d5aa78b13576b98358d019d32bbfe2a.html">[Process Substitution] </a><br><small class="date"><b>Created:</b> March 14, 2018</small><small class="date"><b>Tags:</b> #bash #process #substitution</small></li>
<li class="gist-entry" id="gist-4d550544a3194ebe6bb536fe86e18fd8"><a href="gists/4d550544a3194ebe6bb536fe86e18fd8.html">[Python Class Implementation of a Decorator] </a><br><small class="date"><b>Created:</b> February 27, 2018</small><small class="date"><b>Tags:</b> #python #decorator #class</small></li>
<li class="gist-entry" id="gist-24df00f9d954aec96e9de27d4032a2d0"><a href="gists/24df00f9d954aec96e9de27d4032a2d0.html">[gpg agent connection refused] </a><br><small class="date"><b>Created:</b> February 20, 2018</small><small class="date"><b>Tags:</b> #gpg</small></li>
<li class="gist-entry" id="gist-c22b1266f9df01bff6671f30ef7bf4a2"><a href="gists/c22b1266f9df01bff6671f30ef7bf4a2.html">[Sync Pool Golang] </a><br><small class="date"><b>Created:</b> February 14, 2018</small><small class="date"><b>Tags:</b> #pool #concurrency #go #golang</small></li>
<li class="gist-entry" id="gist-fb1b5dbb6271632298f44d62a2221905"><a href="gists/fb1b5dbb6271632298f44d62a2221905.html">[Python Async Decorator] </a><br><small class="date"><b>Created:</b> February 14, 2018</small><small class="date"><b>Tags:</b> #python #asyncio #decorator</small></li>
<li class="gist-entry" id="gist-5f056192ae527a7c7598cab248d73c04"><a href="gists/5f056192ae527a7c7598cab248d73c04.html">[Pip Python Workflow] </a><br><small class="date"><b>Created:</b> February 12, 2018</small><small class="date"><b>Tags:</b> #pip #python #workflow</small></li>
<li class="gist-entry" id="gist-911252f81830ff0ed650145c4d52f58e"><a href="gists/911252f81830ff0ed650145c4d52f58e.html">[Python Tornado Basic Auth Middleware] </a><br><small class="date"><b>Created:</b> February 9, 2018</small><small class="date"><b>Tags:</b> #auth #authentication #basicauth #python #tornado #POST</small></li>
<li class="gist-entry" id="gist-2af63c57242e1183c37cc0ce1cdc9e1a"><a href="gists/2af63c57242e1183c37cc0ce1cdc9e1a.html">[Replace macOS Terminal Emulator with GPU accelerated Alacritty] </a><br><small class="date"><b>Created:</b> February 8, 2018</small><small class="date"><b>Tags:</b> #macOS #terminal #shell #alacritty</small></li>
<li class="gist-entry" id="gist-f9e9c4dcf621945acfe38bd13734c537"><a href="gists/f9e9c4dcf621945acfe38bd13734c537.html">[Monitor TCP traffic from NGINX] </a><br><small class="date"><b>Created:</b> February 1, 2018</small><small class="date"><b>Tags:</b> #nginx #tcp #tcpdump</small></li>
<li class="gist-entry" id="gist-1debaf8bbb27fda5009888d9ff6f59a7"><a href="gists/1debaf8bbb27fda5009888d9ff6f59a7.html">[Jack The Ripper] </a><br><small class="date"><b>Created:</b> January 28, 2018</small><small class="date"><b>Tags:</b> #quotes</small></li>
<li class="gist-entry" id="gist-fe90c05c26037a83ce47ae859b783ce9"><a href="gists/fe90c05c26037a83ce47ae859b783ce9.html">[encrypt file using a keyring] </a><br><small class="date"><b>Created:</b> January 25, 2018</small><small class="date"><b>Tags:</b> #gpg #keyring</small></li>
<li class="gist-entry" id="gist-44f6e2acb3a4e97c96305ed7584f6514"><a href="gists/44f6e2acb3a4e97c96305ed7584f6514.html">[image quality reduction] </a><br><small class="date"><b>Created:</b> January 25, 2018</small><small class="date"><b>Tags:</b> #bash #image #quality</small></li>
<li class="gist-entry" id="gist-db14b7d8a336176022b49a9e550780e5"><a href="gists/db14b7d8a336176022b49a9e550780e5.html">[Vim Automatic Bootstrap] </a><br><small class="date"><b>Created:</b> January 14, 2018</small><small class="date"><b>Tags:</b> #vim #bootstrap #install</small></li>
<li class="gist-entry" id="gist-b919f3a4f499501b0f0545204b48f953"><a href="gists/b919f3a4f499501b0f0545204b48f953.html">[Sorting a Dictionary by Key] </a><br><small class="date"><b>Created:</b> January 12, 2018</small><small class="date"><b>Tags:</b> #python #sort</small></li>
<li class="gist-entry" id="gist-a0b1d9e31c9b2cdd25e9795b82dbcd37"><a href="gists/a0b1d9e31c9b2cdd25e9795b82dbcd37.html">[Handling CSV files in Python] </a><br><small class="date"><b>Created:</b> January 11, 2018</small><small class="date"><b>Tags:</b> #csv #python</small></li>
<li class="gist-entry" id="gist-18106b28d4d4d66708da09d652f83cc5"><a href="gists/18106b28d4d4d66708da09d652f83cc5.html">[Bracket Terminology] </a><br><small class="date"><b>Created:</b> January 11, 2018</small><small class="date"><b>Tags:</b> #bracket #terminology #parentheses #braces</small></li>
<li class="gist-entry" id="gist-08266927214e0b5f12636a6b46900fb0"><a href="gists/08266927214e0b5f12636a6b46900fb0.html">[Calculate Percentages] </a><br><small class="date"><b>Created:</b> January 5, 2018</small><small class="date"><b>Tags:</b> #math #percentage</small></li>
<li class="gist-entry" id="gist-70409dd264eebf5ec6a93f733d66038a"><a href="gists/70409dd264eebf5ec6a93f733d66038a.html">[Python Semaphore] </a><br><small class="date"><b>Created:</b> January 5, 2018</small><small class="date"><b>Tags:</b> #python #concurrency #semaphore</small></li>
<li class="gist-entry" id="gist-a9171ca1cce786d7dbf7a61df2685e8a"><a href="gists/a9171ca1cce786d7dbf7a61df2685e8a.html">[Rollout Strategies with A/B logic via Varnish and VCL] </a><br><small class="date"><b>Created:</b> January 5, 2018</small><small class="date"><b>Tags:</b> #rollout #vcl #cdn #varnish #fastly #ab</small></li>
<li class="gist-entry" id="gist-5681fd7e4259edb972771a830d074b4a"><a href="gists/5681fd7e4259edb972771a830d074b4a.html">[Multi Torrent Site Search] </a><br><small class="date"><b>Created:</b> December 31, 2017</small><small class="date"><b>Tags:</b> #torrents #cli #shell #bash #python</small></li>
<li class="gist-entry" id="gist-24c8a9ce570d78d37ed0cf9967594e0e"><a href="gists/24c8a9ce570d78d37ed0cf9967594e0e.html">[SBI Framework] </a><br><small class="date"><b>Created:</b> December 31, 2017</small><small class="date"><b>Tags:</b> #framework #reviews</small></li>
<li class="gist-entry" id="gist-aa4c0d3c98f6bbef40de03d072ff2419"><a href="gists/aa4c0d3c98f6bbef40de03d072ff2419.html">[DNS Change Best Practice] </a><br><small class="date"><b>Created:</b> December 31, 2017</small><small class="date"><b>Tags:</b> #dns #ttl</small></li>
<li class="gist-entry" id="gist-f7e17034800b65b51eb7e9807720025a"><a href="gists/f7e17034800b65b51eb7e9807720025a.html">[GPG Security Best Practice] </a><br><small class="date"><b>Created:</b> December 26, 2017</small><small class="date"><b>Tags:</b> #gpg #security #encryption</small></li>
<li class="gist-entry" id="gist-94a73bb9f3b15ccb824881d3ddb7ec6f"><a href="gists/94a73bb9f3b15ccb824881d3ddb7ec6f.html">Extend expired GPG key </a><br><small class="date"><b>Created:</b> December 26, 2017</small><small class="date"><b>Tags:</b> #gpg #keys #encryption</small></li>
<li class="gist-entry" id="gist-57ae3bb90883e603f3851bab496682b9"><a href="gists/57ae3bb90883e603f3851bab496682b9.html">[website day/night theme switcher with cookies] </a><br><small class="date"><b>Created:</b> December 19, 2017</small><small class="date"><b>Tags:</b> #js #javascript #cookies</small></li>
<li class="gist-entry" id="gist-e2e2599fff9eb5ee54d939ae51334de2"><a href="gists/e2e2599fff9eb5ee54d939ae51334de2.html">[Using Vim to format nginx file] </a><br><small class="date"><b>Created:</b> December 13, 2017</small><small class="date"><b>Tags:</b> #vim #nginx</small></li>
<li class="gist-entry" id="gist-92a6e96aa4757365e1f4b7460ffd1bd8"><a href="gists/92a6e96aa4757365e1f4b7460ffd1bd8.html">[Dynamically import modules from a package in Python] </a><br><small class="date"><b>Created:</b> December 8, 2017</small><small class="date"><b>Tags:</b> #python</small></li>
<li class="gist-entry" id="gist-dcee6630903658a6b84b5bcb11ac4d5b"><a href="gists/dcee6630903658a6b84b5bcb11ac4d5b.html">[nginx redirect request to separate server block with different server_name] </a><br><small class="date"><b>Created:</b> December 7, 2017</small><small class="date"><b>Tags:</b> #nginx #rewrite #server</small></li>
<li class="gist-entry" id="gist-3fef386bd3beefac93f71e2a074803fb"><a href="gists/3fef386bd3beefac93f71e2a074803fb.html">[Set Operations] </a><br><small class="date"><b>Created:</b> December 5, 2017</small><small class="date"><b>Tags:</b> #set #theory #operations #go #golang</small></li>
<li class="gist-entry" id="gist-00ee13f2c2ede5e2200e6ea129d3c43d"><a href="gists/00ee13f2c2ede5e2200e6ea129d3c43d.html">[Limit Concurrency] </a><br><small class="date"><b>Created:</b> December 5, 2017</small><small class="date"><b>Tags:</b> #go #golang #concurrency #semaphore</small></li>
<li class="gist-entry" id="gist-730b6f33dc5b0763b152caaff81d397f"><a href="gists/730b6f33dc5b0763b152caaff81d397f.html">[Upstream vs Downstream] </a><br><small class="date"><b>Created:</b> November 30, 2017</small><small class="date"><b>Tags:</b> #upstream #downstream</small></li>
<li class="gist-entry" id="gist-a1b252f8da926043d67ab90ee47818b2"><a href="gists/a1b252f8da926043d67ab90ee47818b2.html">[UTC, GMT, BST, DST] </a><br><small class="date"><b>Created:</b> November 29, 2017</small><small class="date"><b>Tags:</b> #time #timezones</small></li>
<li class="gist-entry" id="gist-76829e05ec57cc908d30fc6a7731688d"><a href="gists/76829e05ec57cc908d30fc6a7731688d.html">Python: Analyse Logs and report top N common matches </a><br><small class="date"><b>Created:</b> November 13, 2017</small><small class="date"><b>Tags:</b> #python #logs</small></li>
<li class="gist-entry" id="gist-1f8efb4fdedd69d4a4387ce95e743f0d"><a href="gists/1f8efb4fdedd69d4a4387ce95e743f0d.html">[Python Boolean Argument Flag] </a><br><small class="date"><b>Created:</b> November 9, 2017</small><small class="date"><b>Tags:</b> #python #cli #flags</small></li>
<li class="gist-entry" id="gist-56cf991ae97551583d5a2f0d69f37788"><a href="gists/56cf991ae97551583d5a2f0d69f37788.html">[Fastly's Custom VCL] </a><br><small class="date"><b>Created:</b> November 1, 2017</small><small class="date"><b>Tags:</b> #fastly #cdn #varnish #vcl</small></li>
<li class="gist-entry" id="gist-9b496994a22d2c7d8aa24bf495ac355f"><a href="gists/9b496994a22d2c7d8aa24bf495ac355f.html">[vim-plug load specific plugin] </a><br><small class="date"><b>Created:</b> October 30, 2017</small><small class="date"><b>Tags:</b> #vim #plugin</small></li>
<li class="gist-entry" id="gist-8a03b201d5de15fac8845414859b4f04"><a href="gists/8a03b201d5de15fac8845414859b4f04.html">[varnish hit-for-pass explanation] </a><br><small class="date"><b>Created:</b> October 27, 2017</small><small class="date"><b>Tags:</b> #varnish #vcl</small></li>
<li class="gist-entry" id="gist-a7b496f4af3b83eead289af7ba8b0261"><a href="gists/a7b496f4af3b83eead289af7ba8b0261.html">[Python CLI Flags for CDN purge] </a><br><small class="date"><b>Created:</b> October 26, 2017</small><small class="date"><b>Tags:</b> #python #cli #flags #cdn #purge</small></li>
<li class="gist-entry" id="gist-70856b480ecb343b85b796d4dd2f9f32"><a href="gists/70856b480ecb343b85b796d4dd2f9f32.html">[Python mutate list content and return new list as they're immutable] </a><br><small class="date"><b>Created:</b> October 24, 2017</small><small class="date"><b>Tags:</b> #python</small></li>
<li class="gist-entry" id="gist-9cf6f2376aa25520a80e191e8925263f"><a href="gists/9cf6f2376aa25520a80e191e8925263f.html">[Golang AWS S3 Examples] </a><br><small class="date"><b>Created:</b> October 20, 2017</small><small class="date"><b>Tags:</b> #go #golang #aws #s3</small></li>
<li class="gist-entry" id="gist-d387c16f9f7b06400e4d22581ccbc338"><a href="gists/d387c16f9f7b06400e4d22581ccbc338.html">[Fastly to S3 with Query Params] </a><br><small class="date"><b>Created:</b> October 19, 2017</small><small class="date"><b>Tags:</b> #fastly #vcl #varnish</small></li>
<li class="gist-entry" id="gist-03279be86a356119b1f820da6ebb8740"><a href="gists/03279be86a356119b1f820da6ebb8740.html">[Validate README format with Python] </a><br><small class="date"><b>Created:</b> October 18, 2017</small><small class="date"><b>Tags:</b> #python</small></li>
<li class="gist-entry" id="gist-a02ff1e208218442e04f2160dae6d2c6"><a href="gists/a02ff1e208218442e04f2160dae6d2c6.html">[Golang Generator (Yield) like Python] </a><br><small class="date"><b>Created:</b> October 16, 2017</small><small class="date"><b>Tags:</b> #go #golang #generator #yield</small></li>
<li class="gist-entry" id="gist-def6f72d6651c4bd86c610da1d04dc48"><a href="gists/def6f72d6651c4bd86c610da1d04dc48.html">[GitHub DNS Reverse Lookup] </a><br><small class="date"><b>Created:</b> October 16, 2017</small><small class="date"><b>Tags:</b> #dns #domain #ip #lookup</small></li>
<li class="gist-entry" id="gist-4dcf314dffecb366dee081e0e1081d50"><a href="gists/4dcf314dffecb366dee081e0e1081d50.html">[Python Flame Graph with pyflame] </a><br><small class="date"><b>Created:</b> October 15, 2017</small><small class="date"><b>Tags:</b> #pyflame #flame #graph #python</small></li>
<li class="gist-entry" id="gist-8f6a3aeb721ec00affbc5c42590343b0"><a href="gists/8f6a3aeb721ec00affbc5c42590343b0.html">[Go Loop Alphabet via Code Points] </a><br><small class="date"><b>Created:</b> October 13, 2017</small><small class="date"><b>Tags:</b> #go #golang</small></li>
<li class="gist-entry" id="gist-73753be0eb5c35bd3ae1e234f3f77dde"><a href="gists/73753be0eb5c35bd3ae1e234f3f77dde.html">[awk search and sum columns] </a><br><small class="date"><b>Created:</b> October 12, 2017</small><small class="date"><b>Tags:</b> #awk #search #sum</small></li>
<li class="gist-entry" id="gist-12806fcbea259edcbc438746b58156af"><a href="gists/12806fcbea259edcbc438746b58156af.html">[list and store every key in a bucket] </a><br><small class="date"><b>Created:</b> October 5, 2017</small><small class="date"><b>Tags:</b> #aws #cli #s3 #bash #python</small></li>
<li class="gist-entry" id="gist-e4b4e53dd09745b645e10e89fc133f63"><a href="gists/e4b4e53dd09745b645e10e89fc133f63.html">[Vegeta + pdsh wrapper for distributed load testing] </a><br><small class="date"><b>Created:</b> October 3, 2017</small><small class="date"><b>Tags:</b> #distributed #loadtest #performance #vegeta #golang #python</small></li>
<li class="gist-entry" id="gist-22ced4b4700df1e6cbec88c1074c8b2d"><a href="gists/22ced4b4700df1e6cbec88c1074c8b2d.html">[Golang Memory Allocation] </a><br><small class="date"><b>Created:</b> September 21, 2017</small><small class="date"><b>Tags:</b> #go #golang #memory #allocation</small></li>
<li class="gist-entry" id="gist-f94955d51daabd4fe874c8d6491924ec"><a href="gists/f94955d51daabd4fe874c8d6491924ec.html">[Git Search logs via Grep] </a><br><small class="date"><b>Created:</b> September 18, 2017</small><small class="date"><b>Tags:</b> #git #grep #search</small></li>
<li class="gist-entry" id="gist-f03ade30c36887b9de68dd4635ae981c"><a href="gists/f03ade30c36887b9de68dd4635ae981c.html">[Bash basic syntax checker] </a><br><small class="date"><b>Created:</b> September 4, 2017</small><small class="date"><b>Tags:</b> #bash #shell</small></li>
<li class="gist-entry" id="gist-fb8782908abe5fcd47f4ef8e39d2f56d"><a href="gists/fb8782908abe5fcd47f4ef8e39d2f56d.html">[Bash Show All Builtin Commands.sh] </a><br><small class="date"><b>Created:</b> September 4, 2017</small><small class="date"><b>Tags:</b> #bash #shell</small></li>
<li class="gist-entry" id="gist-2718a4eb51b00a7a4138fd182566c53b"><a href="gists/2718a4eb51b00a7a4138fd182566c53b.html">[Check TLS version using by Python] </a><br><small class="date"><b>Created:</b> September 4, 2017</small><small class="date"><b>Tags:</b> #python #tls #ssl</small></li>
<li class="gist-entry" id="gist-7a13c09791ceba62b9bd70f954552f3f"><a href="gists/7a13c09791ceba62b9bd70f954552f3f.html">[Sed Date Insertion] </a><br><small class="date"><b>Created:</b> September 4, 2017</small><small class="date"><b>Tags:</b> #sed #bash #date</small></li>
<li class="gist-entry" id="gist-82539776c218e590d64126d58edc5e38"><a href="gists/82539776c218e590d64126d58edc5e38.html">[Bash Date Formatting] </a><br><small class="date"><b>Created:</b> September 4, 2017</small><small class="date"><b>Tags:</b> #bash #date #gnu #posix</small></li>
<li class="gist-entry" id="gist-70e455bb56bd5d780c7b01704fc368ed"><a href="gists/70e455bb56bd5d780c7b01704fc368ed.html">[AWS CloudFront Signed-Cookie Access] </a><br><small class="date"><b>Created:</b> September 2, 2017</small><small class="date"><b>Tags:</b> #aws #cloudfront #cookie #planz</small></li>
<li class="gist-entry" id="gist-993863467f978c9a42ef787a56bafcee"><a href="gists/993863467f978c9a42ef787a56bafcee.html">[Perl Regex Bash Example] </a><br><small class="date"><b>Created:</b> September 1, 2017</small><small class="date"><b>Tags:</b> #perl #regex #pcre</small></li>
<li class="gist-entry" id="gist-edcfb88c925658a13fc3e51f581fe4bc"><a href="gists/edcfb88c925658a13fc3e51f581fe4bc.html">[Python URL Validation] </a><br><small class="date"><b>Created:</b> August 31, 2017</small><small class="date"><b>Tags:</b> #python #urls #validation</small></li>
<li class="gist-entry" id="gist-8b58308965b9b1839f3c76eb610d43ab"><a href="gists/8b58308965b9b1839f3c76eb610d43ab.html">Shell: list, download and extract S3 log files </a><br><small class="date"><b>Created:</b> August 29, 2017</small><small class="date"><b>Tags:</b> #aws #logs #shell</small></li>
<li class="gist-entry" id="gist-d29b157e104fda2e6589063d2c5c6803"><a href="gists/d29b157e104fda2e6589063d2c5c6803.html">[Requests per hour, per docker container] </a><br><small class="date"><b>Created:</b> August 29, 2017</small><small class="date"><b>Tags:</b> #docker #rps #performance</small></li>
<li class="gist-entry" id="gist-548e1d149e15003b5c799da2520ed46c"><a href="gists/548e1d149e15003b5c799da2520ed46c.html">[Hugo build script for User page] </a><br><small class="date"><b>Created:</b> August 28, 2017</small><small class="date"><b>Tags:</b> #github #hugo #build</small></li>
<li class="gist-entry" id="gist-8683880c5a5d0f36802c4a02522710fa"><a href="gists/8683880c5a5d0f36802c4a02522710fa.html">[Bash search find and filter, then execute] </a><br><small class="date"><b>Created:</b> August 23, 2017</small><small class="date"><b>Tags:</b> #bash #find #filter #execute #grep #uniq #sort #search</small></li>
<li class="gist-entry" id="gist-3c64fc7b72039be9770db8a6eed346b4"><a href="gists/3c64fc7b72039be9770db8a6eed346b4.html">[Python Garbage Collection Circular References] </a><br><small class="date"><b>Created:</b> August 19, 2017</small><small class="date"><b>Tags:</b> #python #gc #memory</small></li>
<li class="gist-entry" id="gist-e824971e3f917d23e5315253f98ece92"><a href="gists/e824971e3f917d23e5315253f98ece92.html">[RFC Example Structure] </a><br><small class="date"><b>Created:</b> August 19, 2017</small><small class="date"><b>Tags:</b> #rfc #example</small></li>
<li class="gist-entry" id="gist-65205295a2026c0f12fdb51630ec085b"><a href="gists/65205295a2026c0f12fdb51630ec085b.html">[Bash Column Sort and Sum] </a><br><small class="date"><b>Created:</b> August 10, 2017</small><small class="date"><b>Tags:</b> #bash #sort #sum #column</small></li>
<li class="gist-entry" id="gist-3829b02d798a7668d662cdf54ec74d2a"><a href="gists/3829b02d798a7668d662cdf54ec74d2a.html">[curl via US proxy] </a><br><small class="date"><b>Created:</b> August 2, 2017</small><small class="date"><b>Tags:</b> #curl #proxy</small></li>
<li class="gist-entry" id="gist-b0baf6b4b0397e975083491d32927368"><a href="gists/b0baf6b4b0397e975083491d32927368.html">Shell: AWS S3 CLI - Logs </a><br><small class="date"><b>Created:</b> August 2, 2017</small><small class="date"><b>Tags:</b> #aws #shell #logs</small></li>
<li class="gist-entry" id="gist-772c7a32b313930dbb4493253d80e893"><a href="gists/772c7a32b313930dbb4493253d80e893.html">[Large Number of JavaScript Cookies] </a><br><small class="date"><b>Created:</b> August 1, 2017</small><small class="date"><b>Tags:</b> #cookie #js</small></li>
<li class="gist-entry" id="gist-0f46fe9c24015fb0e9a1e51e69e2cb4e"><a href="gists/0f46fe9c24015fb0e9a1e51e69e2cb4e.html">[Refresh OAuth Token] For non-UI apps </a><br><small class="date"><b>Created:</b> July 13, 2017</small><small class="date"><b>Tags:</b> #golang #oauth</small></li>
<li class="gist-entry" id="gist-4ca9ff94ea82b0e407f540540f1d8c6c"><a href="gists/4ca9ff94ea82b0e407f540540f1d8c6c.html">[Calculate Aspect Ratio] </a><br><small class="date"><b>Created:</b> June 29, 2017</small><small class="date"><b>Tags:</b> #aspect #ratio #python</small></li>
<li class="gist-entry" id="gist-05247b9a12bad8a93c84c74e4784b8a7"><a href="gists/05247b9a12bad8a93c84c74e4784b8a7.html">[Python regex replace with capture group] </a><br><small class="date"><b>Created:</b> June 13, 2017</small><small class="date"><b>Tags:</b> #python #regex #replace #substring</small></li>
<li class="gist-entry" id="gist-dbbc25b6f851670f5f03585a75d784ce"><a href="gists/dbbc25b6f851670f5f03585a75d784ce.html">[Base64 JS Object] Allow for passing complex object to an iframe via Query String </a><br><small class="date"><b>Created:</b> June 13, 2017</small><small class="date"><b>Tags:</b> #js #pickle #base64</small></li>
<li class="gist-entry" id="gist-124f65630d23bc9834081b8551e4421d"><a href="gists/124f65630d23bc9834081b8551e4421d.html">[Python timestamp handling] </a><br><small class="date"><b>Created:</b> May 31, 2017</small><small class="date"><b>Tags:</b> #python #date #time</small></li>
<li class="gist-entry" id="gist-2700697b316637e2a1f57b9cd802914c"><a href="gists/2700697b316637e2a1f57b9cd802914c.html">[Search for package versions] </a><br><small class="date"><b>Created:</b> May 11, 2017</small><small class="date"><b>Tags:</b> #tags: bash, apt, versions</small></li>
<li class="gist-entry" id="gist-7fd120f523e82e352163302544c9f6b6"><a href="gists/7fd120f523e82e352163302544c9f6b6.html">[Python VCR] </a><br><small class="date"><b>Created:</b> May 5, 2017</small><small class="date"><b>Tags:</b> #tags: python, vcr, testing</small></li>
<li class="gist-entry" id="gist-344837ede1d85739fdfa05410db9ffee"><a href="gists/344837ede1d85739fdfa05410db9ffee.html">[Golang Reflection with Struct] </a><br><small class="date"><b>Created:</b> April 29, 2017</small><small class="date"><b>Tags:</b> #go #golang #pointer #struct #reflection #iterate #fields</small></li>
<li class="gist-entry" id="gist-90499f2bb24073ec5eb487020078a582"><a href="gists/90499f2bb24073ec5eb487020078a582.html">[Golang CLI Flags and Subcommands] </a><br><small class="date"><b>Created:</b> April 28, 2017</small><small class="date"><b>Tags:</b> #tags: golang, go, cli, flags, subcommands, logs, logging</small></li>
<li class="gist-entry" id="gist-16c24949a076ea5554a45a7c2001e9a4"><a href="gists/16c24949a076ea5554a45a7c2001e9a4.html">[Simple Bash File Watcher] </a><br><small class="date"><b>Created:</b> April 27, 2017</small><small class="date"><b>Tags:</b> #tags: bash, watcher, polling</small></li>
<li class="gist-entry" id="gist-dfae68eccb8c4cdbd0e405fe6bc808cf"><a href="gists/dfae68eccb8c4cdbd0e405fe6bc808cf.html">[Python CPU and Memory Profiling Tools] </a><br><small class="date"><b>Created:</b> April 26, 2017</small><small class="date"><b>Tags:</b> #tags: python, profiling, perf</small></li>
<li class="gist-entry" id="gist-0c3f6434d4b953a603d3d54b613f5572"><a href="gists/0c3f6434d4b953a603d3d54b613f5572.html">[Python method signature syntax] Along with functools.partial interaction </a><br><small class="date"><b>Created:</b> April 25, 2017</small><small class="date"><b>Tags:</b> #tags: python, args, kwargs, partial</small></li>
<li class="gist-entry" id="gist-958e5ae15640100fa1752f6112184601"><a href="gists/958e5ae15640100fa1752f6112184601.html">[Go defer cleanup exit pattern] </a><br><small class="date"><b>Created:</b> April 19, 2017</small><small class="date"><b>Tags:</b> #tags: go, golang, pattern, cleanup</small></li>
<li class="gist-entry" id="gist-abe4a3e377b4114d08564164e9e8b192"><a href="gists/abe4a3e377b4114d08564164e9e8b192.html">[Python Tornado Example Application] </a><br><small class="date"><b>Created:</b> April 16, 2017</small><small class="date"><b>Tags:</b> #python #python3 #tornado #example #basic #simple</small></li>
<li class="gist-entry" id="gist-4ad4574f66339ccefa74260bfa39e5f2"><a href="gists/4ad4574f66339ccefa74260bfa39e5f2.html">[Python Decorator with optional arguments] </a><br><small class="date"><b>Created:</b> April 16, 2017</small><small class="date"><b>Tags:</b> #tags: python, decorator</small></li>
<li class="gist-entry" id="gist-c0f1e3fe02d8d03fc3a49e806d102f4b"><a href="gists/c0f1e3fe02d8d03fc3a49e806d102f4b.html">[Go Interface Design] </a><br><small class="date"><b>Created:</b> April 16, 2017</small><small class="date"><b>Tags:</b> #tags: go, interface</small></li>
<li class="gist-entry" id="gist-ebc452a46e411cf432b01c7812ddb07f"><a href="gists/ebc452a46e411cf432b01c7812ddb07f.html">[Python and Go Structured Logging] </a><br><small class="date"><b>Created:</b> April 6, 2017</small><small class="date"><b>Tags:</b> #go #golang #python #logging #structured #logrus #structlog</small></li>
<li class="gist-entry" id="gist-56f304c94c42fb60c04cc7b60aa48732"><a href="gists/56f304c94c42fb60c04cc7b60aa48732.html">[vim debugging] </a><br><small class="date"><b>Created:</b> April 6, 2017</small><small class="date"><b>Tags:</b> #vim #debugging</small></li>
<li class="gist-entry" id="gist-12caf8067bbafbfb9113d752e299f2cd"><a href="gists/12caf8067bbafbfb9113d752e299f2cd.html">[Increment parsed number within a pipeline sub shell] When you need the next available port number </a><br><small class="date"><b>Created:</b> March 29, 2017</small><small class="date"><b>Tags:</b> #buzzfeed #bash</small></li>
<li class="gist-entry" id="gist-e1743503f18904e3af99dac27134de91"><a href="gists/e1743503f18904e3af99dac27134de91.html">[Python Auto Generate API Documentation] Python Auto Generate API Documentation </a><br><small class="date"><b>Created:</b> March 23, 2017</small><small class="date"><b>Tags:</b> #tags: python, git, bash, make</small></li>
<li class="gist-entry" id="gist-0f088983d522de5c0c81ea148823eef1"><a href="gists/0f088983d522de5c0c81ea148823eef1.html">[Python3 Logging] Simple Python3 Logging Configuration </a><br><small class="date"><b>Created:</b> March 17, 2017</small><small class="date"><b>Tags:</b> #logs #python</small></li>
<li class="gist-entry" id="gist-17f9ffb8178ec9b543025ab3116ef2ed"><a href="gists/17f9ffb8178ec9b543025ab3116ef2ed.html">[Python Auto Documentation Generation] Use pycco for generating documentation using docstrings from code files </a><br><small class="date"><b>Created:</b> March 13, 2017</small><small class="date"><b>Tags:</b> #python #docs</small></li>
<li class="gist-entry" id="gist-23e8b8e732fa6c033e090dde3547ec82"><a href="gists/23e8b8e732fa6c033e090dde3547ec82.html">[Python State Machine] simple state machine for replacing quotations in a string </a><br><small class="date"><b>Created:</b> February 21, 2017</small><small class="date"><b>Tags:</b> #tags: python3, state-machine</small></li>
<li class="gist-entry" id="gist-99a20bc40fee08e8ec8d63d06c7788f0"><a href="gists/99a20bc40fee08e8ec8d63d06c7788f0.html">[HTTP Headers Shell Script Abstraction] </a><br><small class="date"><b>Created:</b> February 15, 2017</small><small class="date"><b>Tags:</b> #tags: bash, http-headers</small></li>
<li class="gist-entry" id="gist-ecb0890a7ea36d0010bf1cc47306d13f"><a href="gists/ecb0890a7ea36d0010bf1cc47306d13f.html">[VCL Logging Abstraction] vcl abstraction around logging to make calls cleaner </a><br><small class="date"><b>Created:</b> February 15, 2017</small><small class="date"><b>Tags:</b> #tags: vcl, varnish, logging</small></li>
<li class="gist-entry" id="gist-025dd8456b459ae823f3795969cf1e28"><a href="gists/025dd8456b459ae823f3795969cf1e28.html">Pylint Detect Similarities</a><br><small class="date"><b>Created:</b> February 1, 2017</small></li>
<li class="gist-entry" id="gist-835e6ce181584bec9ba6391d29ebaf12"><a href="gists/835e6ce181584bec9ba6391d29ebaf12.html">[Varnish VCL] use vcl to store provided query string and path into HTTP response headers </a><br><small class="date"><b>Created:</b> January 24, 2017</small><small class="date"><b>Tags:</b> #tags: vcl, varnish</small></li>
<li class="gist-entry" id="gist-d9b00fc9deafc80f845193deb43f1edf"><a href="gists/d9b00fc9deafc80f845193deb43f1edf.html">Python Class Decorator (AOP)</a><br><small class="date"><b>Created:</b> January 18, 2017</small></li>
<li class="gist-entry" id="gist-240275c63598f69a83d1678644824063"><a href="gists/240275c63598f69a83d1678644824063.html">Example NGINX global "rollout" strategy</a><br><small class="date"><b>Created:</b> January 17, 2017</small></li>
<li class="gist-entry" id="gist-11e10dd3acf972dd97f5c122db531162"><a href="gists/11e10dd3acf972dd97f5c122db531162.html">Install more recent version of Siege (https://github.com/JoeDog/siege) inside of a Docker container</a><br><small class="date"><b>Created:</b> January 9, 2017</small></li>
<li class="gist-entry" id="gist-1017c8df0c3be2e0fd979fffa3fb80ff"><a href="gists/1017c8df0c3be2e0fd979fffa3fb80ff.html">Configure Wrk https://github.com/wg/wrk (brew install wrk) with Lua to execute against multiple URLs</a><br><small class="date"><b>Created:</b> January 9, 2017</small></li>
<li class="gist-entry" id="gist-8fdd949bc049c5169f2311ed2e5263f5"><a href="gists/8fdd949bc049c5169f2311ed2e5263f5.html">Stylish Chrome Extension: github.com - stylised to be black as the white is a bit intense on my eyes</a><br><small class="date"><b>Created:</b> January 9, 2017</small></li>
<li class="gist-entry" id="gist-88cb5699ccd9324efb91fee600c79a39"><a href="gists/88cb5699ccd9324efb91fee600c79a39.html">Stylish Chrome Extension: doc.rust-lang.org - stylised to be black as the white is a bit intense on my eyes</a><br><small class="date"><b>Created:</b> January 9, 2017</small></li>
<li class="gist-entry" id="gist-402d7ebc44fefdac9779dd4be2791b0e"><a href="gists/402d7ebc44fefdac9779dd4be2791b0e.html">[Python Tornado Request Performance] </a><br><small class="date"><b>Created:</b> January 6, 2017</small><small class="date"><b>Tags:</b> #tornado #performance #async #requests</small></li>
<li class="gist-entry" id="gist-f5c713a63db3679ee60d1c739b0aa226"><a href="gists/f5c713a63db3679ee60d1c739b0aa226.html">Storing Passwords (salt + pepper)</a><br><small class="date"><b>Created:</b> January 3, 2017</small></li>
<li class="gist-entry" id="gist-e35cf61b857829bbf340260ac4f46210"><a href="gists/e35cf61b857829bbf340260ac4f46210.html">:w ~/.vim/colors/vim-integralist.vim - doesn't work though with macOS terminal :-( although it could be modified to use terminal equivalent like 'ctermbg=233' but refer to this palette... https://upload.wikimedia.org/wikipedia/en/1/15/Xterm_256color_chart.svg</a><br><small class="date"><b>Created:</b> December 24, 2016</small></li>
<li class="gist-entry" id="gist-d615647810c9f3961b29b9e84e252c8b"><a href="gists/d615647810c9f3961b29b9e84e252c8b.html">Go test with interface</a><br><small class="date"><b>Created:</b> December 20, 2016</small></li>
<li class="gist-entry" id="gist-06afe9a193413593f630b357a898d1c5"><a href="gists/06afe9a193413593f630b357a898d1c5.html">Python Format Date String</a><br><small class="date"><b>Created:</b> December 15, 2016</small></li>
<li class="gist-entry" id="gist-1670fa65ad8f685d35a5235b3fba7af0"><a href="gists/1670fa65ad8f685d35a5235b3fba7af0.html">Python aiohttp example using mustache (also consider https://github.com/saghul/aiodns)</a><br><small class="date"><b>Created:</b> December 9, 2016</small></li>
<li class="gist-entry" id="gist-1a256fc6e9112a084cddd94a49bb5fba"><a href="gists/1a256fc6e9112a084cddd94a49bb5fba.html">Python if/else list comprehension (generator expression)</a><br><small class="date"><b>Created:</b> November 30, 2016</small></li>
<li class="gist-entry" id="gist-f790b21acc5fa178830f060f649a04c4"><a href="gists/f790b21acc5fa178830f060f649a04c4.html">Python subclass dictionary</a><br><small class="date"><b>Created:</b> November 24, 2016</small></li>
<li class="gist-entry" id="gist-06bb03a150c7fb54a783c13dddf6b720"><a href="gists/06bb03a150c7fb54a783c13dddf6b720.html">netcat web server</a><br><small class="date"><b>Created:</b> November 22, 2016</small></li>
<li class="gist-entry" id="gist-06866d9c6faba66517d05b9278766376"><a href="gists/06866d9c6faba66517d05b9278766376.html">Compile Mozilla's Servo web browser (built with their new Rust language)</a><br><small class="date"><b>Created:</b> November 22, 2016</small></li>
<li class="gist-entry" id="gist-06f026435f47062562c4280b77399919"><a href="gists/06f026435f47062562c4280b77399919.html">Basic Shell Logger</a><br><small class="date"><b>Created:</b> November 19, 2016</small></li>
<li class="gist-entry" id="gist-5fbfe778d38fcf2e77dc0928ec0d6bce"><a href="gists/5fbfe778d38fcf2e77dc0928ec0d6bce.html">Log to SysLog on the command line (terminal)</a><br><small class="date"><b>Created:</b> November 19, 2016</small></li>
<li class="gist-entry" id="gist-89db69ec07e3ca34495259d4feacb2ae"><a href="gists/89db69ec07e3ca34495259d4feacb2ae.html">What's the difference between a router and a modem?</a><br><small class="date"><b>Created:</b> November 19, 2016</small></li>
<li class="gist-entry" id="gist-f93386e9f7559e2c38a7a0fbb3e8e498"><a href="gists/f93386e9f7559e2c38a7a0fbb3e8e498.html">C vs System Calls and where to find documentation?</a><br><small class="date"><b>Created:</b> November 18, 2016</small></li>
<li class="gist-entry" id="gist-07f0df8dd810e64d5803720380a852c3"><a href="gists/07f0df8dd810e64d5803720380a852c3.html">CSS representation of long hand division</a><br><small class="date"><b>Created:</b> November 16, 2016</small></li>
<li class="gist-entry" id="gist-aced055890fa13a82fbae51b23693102"><a href="gists/aced055890fa13a82fbae51b23693102.html">Bits Explained (inc. IPs, CIDR, RAM etc)</a><br><small class="date"><b>Created:</b> November 11, 2016</small></li>
<li class="gist-entry" id="gist-6c35d4f26c0c7bf5bdce7b95cfa906b3"><a href="gists/6c35d4f26c0c7bf5bdce7b95cfa906b3.html">C Concepts</a><br><small class="date"><b>Created:</b> November 10, 2016</small></li>
<li class="gist-entry" id="gist-f046375b675f13a44e2aff0a75816bc2"><a href="gists/f046375b675f13a44e2aff0a75816bc2.html">DNS update strategy</a><br><small class="date"><b>Created:</b> November 9, 2016</small></li>
<li class="gist-entry" id="gist-c125817c5409b5a4a5a5bc0a1d448da9"><a href="gists/c125817c5409b5a4a5a5bc0a1d448da9.html">Python extract query string params in order they are specified</a><br><small class="date"><b>Created:</b> November 8, 2016</small></li>
<li class="gist-entry" id="gist-51d18f1625cc9cfd524fabd8cb957152"><a href="gists/51d18f1625cc9cfd524fabd8cb957152.html">Website Crawler</a><br><small class="date"><b>Created:</b> November 8, 2016</small></li>
<li class="gist-entry" id="gist-cc2616ece918fdd8239d16cca62e37de"><a href="gists/cc2616ece918fdd8239d16cca62e37de.html">Mutt View Attachments Script</a><br><small class="date"><b>Created:</b> November 7, 2016</small></li>
<li class="gist-entry" id="gist-aee36a7e54a4593084157e333ea40a28"><a href="gists/aee36a7e54a4593084157e333ea40a28.html">Mutt configuration and usage</a><br><small class="date"><b>Created:</b> November 4, 2016</small></li>
<li class="gist-entry" id="gist-59d6a84a7a083a60ebdeceacf6f63cd9"><a href="gists/59d6a84a7a083a60ebdeceacf6f63cd9.html">Python Singleton</a><br><small class="date"><b>Created:</b> November 1, 2016</small></li>
<li class="gist-entry" id="gist-229eaa0a688773e1cb5f5ea03facee6f"><a href="gists/229eaa0a688773e1cb5f5ea03facee6f.html">Multiple asynchronous HTTP GET requests with Python's aiohttp and asyncio</a><br><small class="date"><b>Created:</b> November 1, 2016</small></li>
<li class="gist-entry" id="gist-d0732065f2d230d5e715bc186546bf90"><a href="gists/d0732065f2d230d5e715bc186546bf90.html">[Wait for multiple Python futures to finish using asyncio.wait()] </a><br><small class="date"><b>Created:</b> November 1, 2016</small><small class="date"><b>Tags:</b> #asyncio #wait #concurrency #multiple #requests #httpclient</small></li>
<li class="gist-entry" id="gist-0d2f7f156aea02fce362523dd4fc185c"><a href="gists/0d2f7f156aea02fce362523dd4fc185c.html">Kali Linux Vim + Bash setup</a><br><small class="date"><b>Created:</b> October 30, 2016</small></li>
<li class="gist-entry" id="gist-2f03b8b13d8c0b5515bfd32ba15a2864"><a href="gists/2f03b8b13d8c0b5515bfd32ba15a2864.html">VirtualBox: Kali Linux Linux Headers</a><br><small class="date"><b>Created:</b> October 30, 2016</small></li>
<li class="gist-entry" id="gist-09770231e6b8bab267973c01918b5ea4"><a href="gists/09770231e6b8bab267973c01918b5ea4.html">Bash shortcut syntax for redirecting stderr to stdout</a><br><small class="date"><b>Created:</b> October 28, 2016</small></li>
<li class="gist-entry" id="gist-f06b7740d0d70f920439ef9595302d1a"><a href="gists/f06b7740d0d70f920439ef9595302d1a.html">Taken from "Python for Programmers" https://leanpub.com/pythonforprogrammers</a><br><small class="date"><b>Created:</b> October 27, 2016</small></li>
<li class="gist-entry" id="gist-7a66effc75e8dbe6875f7019d118d170"><a href="gists/7a66effc75e8dbe6875f7019d118d170.html">Vim filtering with global command, sorting and then filtering out duplicate lines for unique results</a><br><small class="date"><b>Created:</b> October 21, 2016</small></li>
<li class="gist-entry" id="gist-2b272db0bd81124073164d7252743c34"><a href="gists/2b272db0bd81124073164d7252743c34.html">Complex log filtering in Vim</a><br><small class="date"><b>Created:</b> October 21, 2016</small></li>
<li class="gist-entry" id="gist-01fdb84efbcb0bd656783cc96dad74c2"><a href="gists/01fdb84efbcb0bd656783cc96dad74c2.html">Python Sort List by Dictionary Key</a><br><small class="date"><b>Created:</b> October 18, 2016</small></li>
<li class="gist-entry" id="gist-eacba980ad679b342457ad5698e6cc0d"><a href="gists/eacba980ad679b342457ad5698e6cc0d.html">MapReduce in Python (copied verbatim for posterity from https://www.reddit.com/r/Python/comments/572xtj/i_decided_to_teach_myself_how_mapreduce_works_and/)</a><br><small class="date"><b>Created:</b> October 12, 2016</small></li>
<li class="gist-entry" id="gist-c8f3bb0bca3ed23ae4b4a2780b05dc7a"><a href="gists/c8f3bb0bca3ed23ae4b4a2780b05dc7a.html">Setup DNSMASQ</a><br><small class="date"><b>Created:</b> October 11, 2016</small></li>
<li class="gist-entry" id="gist-ea1b8c52414579302c817606d3fe338d"><a href="gists/ea1b8c52414579302c817606d3fe338d.html">Can't replace or mv a file (e.g. like when using sed -i) when a file is bind mounted with Docker. So Vim to the rescue...</a><br><small class="date"><b>Created:</b> October 10, 2016</small></li>
<li class="gist-entry" id="gist-ce5ebb37390ab0ae56c9e6e80128fdc2"><a href="gists/ce5ebb37390ab0ae56c9e6e80128fdc2.html">Python3 HTTP Server.py</a><br><small class="date"><b>Created:</b> October 5, 2016</small></li>
<li class="gist-entry" id="gist-10a8dca7bf3c6dbd6faf8609a43905fd"><a href="gists/10a8dca7bf3c6dbd6faf8609a43905fd.html">Python Jinja Example</a><br><small class="date"><b>Created:</b> October 4, 2016</small></li>
<li class="gist-entry" id="gist-a3db511b7800f5b5a0bef3aba3c63ea1"><a href="gists/a3db511b7800f5b5a0bef3aba3c63ea1.html">Domain Structure</a><br><small class="date"><b>Created:</b> October 3, 2016</small></li>
<li class="gist-entry" id="gist-7ec3f86d4929471151aba5f376b91187"><a href="gists/7ec3f86d4929471151aba5f376b91187.html">[Docker NGINX Plus] </a><br><small class="date"><b>Created:</b> September 29, 2016</small><small class="date"><b>Tags:</b> #nginx-plus #nginx #docker</small></li>
<li class="gist-entry" id="gist-89aa62c98bd60403fefe3ab1b6eb993e"><a href="gists/89aa62c98bd60403fefe3ab1b6eb993e.html">[Compiling Python] </a><br><small class="date"><b>Created:</b> September 29, 2016</small><small class="date"><b>Tags:</b> #python #compile #manual #install</small></li>
<li class="gist-entry" id="gist-f6ff300dd586d40bf3584183f419b09e"><a href="gists/f6ff300dd586d40bf3584183f419b09e.html">Python2: YAML convert to OrderedDict (http://stackoverflow.com/questions/5121931/in-python-how-can-you-load-yaml-mappings-as-ordereddicts/21912744</a><br><small class="date"><b>Created:</b> September 26, 2016</small><small class="date"><b>Tags:</b> #21912744)</small></li>
<li class="gist-entry" id="gist-703869f00ee1ac9267803264f5bb81d0"><a href="gists/703869f00ee1ac9267803264f5bb81d0.html">Papertrail Log Aggregator: Filter 5xx errors</a><br><small class="date"><b>Created:</b> September 21, 2016</small></li>
<li class="gist-entry" id="gist-36621860135c2a265cf7b6eb0f661db5"><a href="gists/36621860135c2a265cf7b6eb0f661db5.html">Netcat in Python</a><br><small class="date"><b>Created:</b> September 18, 2016</small></li>
<li class="gist-entry" id="gist-3f004c3594bbf8431c15ed6db15809ae"><a href="gists/3f004c3594bbf8431c15ed6db15809ae.html">Python TCP Client Server Example</a><br><small class="date"><b>Created:</b> September 18, 2016</small></li>
<li class="gist-entry" id="gist-9d56525978e03ea2fcc73bebd9fa983d"><a href="gists/9d56525978e03ea2fcc73bebd9fa983d.html">Python coloured logs</a><br><small class="date"><b>Created:</b> September 17, 2016</small></li>
<li class="gist-entry" id="gist-f48288f7133fc6d1769707e5c96d5569"><a href="gists/f48288f7133fc6d1769707e5c96d5569.html">Python stdlib scheduler</a><br><small class="date"><b>Created:</b> September 17, 2016</small></li>
<li class="gist-entry" id="gist-310fa87e707a0d54962545b1d2aeb6ea"><a href="gists/310fa87e707a0d54962545b1d2aeb6ea.html">Netcat web server</a><br><small class="date"><b>Created:</b> September 15, 2016</small></li>
<li class="gist-entry" id="gist-b7cc23bbe544428758339b6b8bdbd5b4"><a href="gists/b7cc23bbe544428758339b6b8bdbd5b4.html">Export code into formatted file</a><br><small class="date"><b>Created:</b> September 15, 2016</small></li>
<li class="gist-entry" id="gist-335cb5bb402bcc7fd0c4c6a88776f08a"><a href="gists/335cb5bb402bcc7fd0c4c6a88776f08a.html">Terminal Resize Images with ImageMagick</a><br><small class="date"><b>Created:</b> September 11, 2016</small></li>
<li class="gist-entry" id="gist-e81902245636115169456956244e31a8"><a href="gists/e81902245636115169456956244e31a8.html">Run foreground process in background (odd I know)</a><br><small class="date"><b>Created:</b> August 24, 2016</small></li>
<li class="gist-entry" id="gist-9bd233b776c9d5d6a3bc5710981d61e8"><a href="gists/9bd233b776c9d5d6a3bc5710981d61e8.html">Coding Best Practices: High Level Principles</a><br><small class="date"><b>Created:</b> August 22, 2016</small></li>
<li class="gist-entry" id="gist-1e2616dc0b165f0edead9bf819d23c1e"><a href="gists/1e2616dc0b165f0edead9bf819d23c1e.html">Bash rename function</a><br><small class="date"><b>Created:</b> August 17, 2016</small></li>
<li class="gist-entry" id="gist-a15252e33c2bab27c811bc9da7484423"><a href="gists/a15252e33c2bab27c811bc9da7484423.html">Python 3: Reduce Array/List into Dict</a><br><small class="date"><b>Created:</b> August 17, 2016</small></li>
<li class="gist-entry" id="gist-2bd6ea43e7f617b8b4eb81b45554bd49"><a href="gists/2bd6ea43e7f617b8b4eb81b45554bd49.html">Python 2: execute multiple shell cmds and print result</a><br><small class="date"><b>Created:</b> August 17, 2016</small></li>
<li class="gist-entry" id="gist-a93f6dfe7e1b948666272fd2e64db466"><a href="gists/a93f6dfe7e1b948666272fd2e64db466.html">[Python ignore pylint and flake8 linter errors] </a><br><small class="date"><b>Created:</b> August 16, 2016</small><small class="date"><b>Tags:</b> #tags: python, linter, ignore, pylint, flake8</small></li>
<li class="gist-entry" id="gist-1bc8397c9f0d363de15966027ded3dcb"><a href="gists/1bc8397c9f0d363de15966027ded3dcb.html">Bash split string by delimiter</a><br><small class="date"><b>Created:</b> August 15, 2016</small></li>
<li class="gist-entry" id="gist-0d108466742b952398383f331a7a3784"><a href="gists/0d108466742b952398383f331a7a3784.html">Awk insert before and after regex match</a><br><small class="date"><b>Created:</b> August 15, 2016</small></li>
<li class="gist-entry" id="gist-defcfaed6d59cc27b6e3d951e93e8a54"><a href="gists/defcfaed6d59cc27b6e3d951e93e8a54.html">Bold text in bash output</a><br><small class="date"><b>Created:</b> August 15, 2016</small></li>
<li class="gist-entry" id="gist-f382f8573900bd1821769be478b81323"><a href="gists/f382f8573900bd1821769be478b81323.html">Python programmatically check installed module version</a><br><small class="date"><b>Created:</b> August 15, 2016</small></li>
<li class="gist-entry" id="gist-ab995319d287314a45c74d5f49d90c5d"><a href="gists/ab995319d287314a45c74d5f49d90c5d.html">[First Time Flyers] Help for those new to flying </a><br><small class="date"><b>Created:</b> August 13, 2016</small><small class="date"><b>Tags:</b> #tags: flight, flying</small></li>
<li class="gist-entry" id="gist-6776715c2e5f468a303f36dbb52bfec4"><a href="gists/6776715c2e5f468a303f36dbb52bfec4.html">Bash Associative Arrays</a><br><small class="date"><b>Created:</b> August 11, 2016</small></li>
<li class="gist-entry" id="gist-30f5a0eb07f93c90c8ec7e223a040902"><a href="gists/30f5a0eb07f93c90c8ec7e223a040902.html">Bash join Array values</a><br><small class="date"><b>Created:</b> August 8, 2016</small></li>
<li class="gist-entry" id="gist-3edda4adb44ed6e2177034740936ece6"><a href="gists/3edda4adb44ed6e2177034740936ece6.html">[Bash function passed an Array] </a><br><small class="date"><b>Created:</b> August 8, 2016</small><small class="date"><b>Tags:</b> #bash #array</small></li>
<li class="gist-entry" id="gist-ce3783da8cd0b178be7b8ef6121ee47f"><a href="gists/ce3783da8cd0b178be7b8ef6121ee47f.html">Python EasyDict</a><br><small class="date"><b>Created:</b> August 8, 2016</small></li>
<li class="gist-entry" id="gist-81031cc1d99d007afe9cf544dd6595c0"><a href="gists/81031cc1d99d007afe9cf544dd6595c0.html">Debugging nginx with custom headers</a><br><small class="date"><b>Created:</b> August 4, 2016</small></li>
<li class="gist-entry" id="gist-09fec74608b3b0a8b2c3cc8202ea19f5"><a href="gists/09fec74608b3b0a8b2c3cc8202ea19f5.html">gpg-agent across vm ssh sessions</a><br><small class="date"><b>Created:</b> August 2, 2016</small></li>
<li class="gist-entry" id="gist-7f0efad70f8e65b69f463bac4cf5cf56"><a href="gists/7f0efad70f8e65b69f463bac4cf5cf56.html">Managing resources with Python Context Managers</a><br><small class="date"><b>Created:</b> July 28, 2016</small></li>
<li class="gist-entry" id="gist-77d73b2380e4645b564c28c53fae71fb"><a href="gists/77d73b2380e4645b564c28c53fae71fb.html">Python Asyncio Timing Decorator</a><br><small class="date"><b>Created:</b> July 27, 2016</small></li>
<li class="gist-entry" id="gist-9c7e32a2126ca28722693675f99f2ad9"><a href="gists/9c7e32a2126ca28722693675f99f2ad9.html">[Python Custom Exception Handling] </a><br><small class="date"><b>Created:</b> July 26, 2016</small><small class="date"><b>Tags:</b> #python #custom #exceptions #error #handling</small></li>
<li class="gist-entry" id="gist-b25185f91ebc8a56fe070d499111b447"><a href="gists/b25185f91ebc8a56fe070d499111b447.html">Python 3: Convert namedtuple into dict so we can convert it to json</a><br><small class="date"><b>Created:</b> July 22, 2016</small></li>
<li class="gist-entry" id="gist-0b469a51b83eb905b2d202407cffa8b7"><a href="gists/0b469a51b83eb905b2d202407cffa8b7.html">Docker Alpine</a><br><small class="date"><b>Created:</b> July 18, 2016</small></li>
<li class="gist-entry" id="gist-868693b4fdaf62ac68df4e6b4370322d"><a href="gists/868693b4fdaf62ac68df4e6b4370322d.html">Python Generator Expressions</a><br><small class="date"><b>Created:</b> July 15, 2016</small></li>
<li class="gist-entry" id="gist-55d091fad91c2b4c7e9a36b3c798f01a"><a href="gists/55d091fad91c2b4c7e9a36b3c798f01a.html">nginx health check via docker</a><br><small class="date"><b>Created:</b> July 13, 2016</small></li>
<li class="gist-entry" id="gist-dcf09ce0bdd58c527bc6fa63737dbd4e"><a href="gists/dcf09ce0bdd58c527bc6fa63737dbd4e.html">Python access the stack trace failed functions</a><br><small class="date"><b>Created:</b> July 6, 2016</small></li>
<li class="gist-entry" id="gist-5f92f748a3c73a98b1e51dd3dc9ac0ea"><a href="gists/5f92f748a3c73a98b1e51dd3dc9ac0ea.html">Python calculate difference in dates</a><br><small class="date"><b>Created:</b> July 6, 2016</small></li>
<li class="gist-entry" id="gist-84622bbfbb64a5a2b315a5a35fc3945b"><a href="gists/84622bbfbb64a5a2b315a5a35fc3945b.html">Python Exception Stack Trace Debugging</a><br><small class="date"><b>Created:</b> July 4, 2016</small></li>
<li class="gist-entry" id="gist-6f34e23f71340a1a23e846cd2f64cf32"><a href="gists/6f34e23f71340a1a23e846cd2f64cf32.html">Python Asyncio Loop Forever</a><br><small class="date"><b>Created:</b> July 4, 2016</small></li>
<li class="gist-entry" id="gist-f832aac00ec710a08049cd070323a3fe"><a href="gists/f832aac00ec710a08049cd070323a3fe.html">[Python Tornado Yield Multiple Async Requests] </a><br><small class="date"><b>Created:</b> July 1, 2016</small><small class="date"><b>Tags:</b> #python #tornado #yield #splat #async #asynchttpclient #locals #vars #variables</small></li>
<li class="gist-entry" id="gist-9763bded76e7d826535a3caeafc3bdff"><a href="gists/9763bded76e7d826535a3caeafc3bdff.html">Algorithms in Python (modified from the excellent: Grokking Algorithms) - see also http://www.integralist.co.uk/posts/bigo.html for details on understanding Big O notation</a><br><small class="date"><b>Created:</b> June 23, 2016</small></li>
<li class="gist-entry" id="gist-115d083348cbd6521607eb1bfc03b39a"><a href="gists/115d083348cbd6521607eb1bfc03b39a.html">Python Exception Logging Decorator</a><br><small class="date"><b>Created:</b> June 14, 2016</small></li>
<li class="gist-entry" id="gist-e521a0a4eda8f5bfe130283e0f6a60c6"><a href="gists/e521a0a4eda8f5bfe130283e0f6a60c6.html">URL Shortener</a><br><small class="date"><b>Created:</b> June 8, 2016</small></li>
<li class="gist-entry" id="gist-af15ae73da17ec1d8a299aa2ced203e8"><a href="gists/af15ae73da17ec1d8a299aa2ced203e8.html">Service Orchestration vs Choreography (http://developers.redhat.com/blog/2016/05/26/scalable-microservices-through-messaging/)</a><br><small class="date"><b>Created:</b> June 3, 2016</small></li>
<li class="gist-entry" id="gist-ca3e89497f57eb47a2df2e4cece3f5ac"><a href="gists/ca3e89497f57eb47a2df2e4cece3f5ac.html">Sort an Array according to another Array</a><br><small class="date"><b>Created:</b> June 2, 2016</small></li>
<li class="gist-entry" id="gist-3f8089345a1236b374a7a5b8a13591a1"><a href="gists/3f8089345a1236b374a7a5b8a13591a1.html">The Perfect Developer Qualities</a><br><small class="date"><b>Created:</b> May 27, 2016</small></li>
<li class="gist-entry" id="gist-2938b1bee56ab5bcf690c717d42731e9"><a href="gists/2938b1bee56ab5bcf690c717d42731e9.html">Ruby WebMock Example</a><br><small class="date"><b>Created:</b> May 25, 2016</small></li>
<li class="gist-entry" id="gist-cc5b63b4a999cde93f353801d50e5e87"><a href="gists/cc5b63b4a999cde93f353801d50e5e87.html">Find and execute using `find` and `-exec` flag</a><br><small class="date"><b>Created:</b> May 25, 2016</small></li>
<li class="gist-entry" id="gist-01e2ffd00a599069bda33ab64ab37c20"><a href="gists/01e2ffd00a599069bda33ab64ab37c20.html">Vim Grep</a><br><small class="date"><b>Created:</b> May 25, 2016</small></li>
<li class="gist-entry" id="gist-090fb5d3b55694c7b92d32798845eded"><a href="gists/090fb5d3b55694c7b92d32798845eded.html">Backup all your GitHub Gists (inc. private gists)</a><br><small class="date"><b>Created:</b> May 24, 2016</small></li>
<li class="gist-entry" id="gist-e217429a5da1edcd5d220ed2ccb61f59"><a href="gists/e217429a5da1edcd5d220ed2ccb61f59.html">Cryptographic Hash Functions</a><br><small class="date"><b>Created:</b> May 23, 2016</small></li>
<li class="gist-entry" id="gist-38c72374cd37cff9f62c3484aaa58ba2"><a href="gists/38c72374cd37cff9f62c3484aaa58ba2.html">Docker and StatsD</a><br><small class="date"><b>Created:</b> May 23, 2016</small></li>
<li class="gist-entry" id="gist-957d1a940a582042152194dd9dde0095"><a href="gists/957d1a940a582042152194dd9dde0095.html">keybase.md</a><br><small class="date"><b>Created:</b> May 22, 2016</small></li>
<li class="gist-entry" id="gist-cf76668bc46d75058ab5f566d96ce74a"><a href="gists/cf76668bc46d75058ab5f566d96ce74a.html">Testing Go Web Applications http://www.meetspaceapp.com/2016/05/16/acceptance-testing-go-webapps-with-cookies.html</a><br><small class="date"><b>Created:</b> May 22, 2016</small></li>
<li class="gist-entry" id="gist-5480428f4edcb49ba0fba6dde2c3e9ff"><a href="gists/5480428f4edcb49ba0fba6dde2c3e9ff.html">Local Memcache and ElastiCache</a><br><small class="date"><b>Created:</b> May 10, 2016</small></li>
<li class="gist-entry" id="gist-52d07564bcae1937a76d28377746e0fd"><a href="gists/52d07564bcae1937a76d28377746e0fd.html">AWS KMS</a><br><small class="date"><b>Created:</b> May 5, 2016</small></li>
<li class="gist-entry" id="gist-5224a227dccd5007a8081a270029c58c"><a href="gists/5224a227dccd5007a8081a270029c58c.html">git commit template example file</a><br><small class="date"><b>Created:</b> May 3, 2016</small></li>
<li class="gist-entry" id="gist-7db3ea36a575d1bbec223bee208734f5"><a href="gists/7db3ea36a575d1bbec223bee208734f5.html">[Python asyncio] </a><br><small class="date"><b>Created:</b> May 3, 2016</small><small class="date"><b>Tags:</b> #python #asyncio #helloworld</small></li>
<li class="gist-entry" id="gist-efe0e673ecd02f9a96e9cbc071c5b1b3"><a href="gists/efe0e673ecd02f9a96e9cbc071c5b1b3.html">SSH port binding</a><br><small class="date"><b>Created:</b> May 3, 2016</small></li>
<li class="gist-entry" id="gist-c6e4f7f6f27ed996e9a9a777c85fd746"><a href="gists/c6e4f7f6f27ed996e9a9a777c85fd746.html">Python Binary Search Tree</a><br><small class="date"><b>Created:</b> April 26, 2016</small></li>
<li class="gist-entry" id="gist-b416501ca4ab98c966e872ba23662e05"><a href="gists/b416501ca4ab98c966e872ba23662e05.html">Functional Ruby with Lambda/Procs</a><br><small class="date"><b>Created:</b> April 26, 2016</small></li>
<li class="gist-entry" id="gist-592042384d547d0621613f719205b7a2"><a href="gists/592042384d547d0621613f719205b7a2.html">[Python3 Virtual Environment with virtualenv] </a><br><small class="date"><b>Created:</b> April 26, 2016</small><small class="date"><b>Tags:</b> #python3</small></li>
<li class="gist-entry" id="gist-c972802f1601540d59dbc9a3d9c38fb2"><a href="gists/c972802f1601540d59dbc9a3d9c38fb2.html">ls command behave like tree command</a><br><small class="date"><b>Created:</b> April 25, 2016</small></li>
<li class="gist-entry" id="gist-aa62485464d512d6c79a92b6d2bb9b2a"><a href="gists/aa62485464d512d6c79a92b6d2bb9b2a.html">Programming Languages - Word Association</a><br><small class="date"><b>Created:</b> April 24, 2016</small></li>
<li class="gist-entry" id="gist-a2f01ab4aabb786268d5006da5013c9e"><a href="gists/a2f01ab4aabb786268d5006da5013c9e.html">Python equivalent to Ruby's Pry (update: use https://docs.python.org/3/library/pdb.html - see also https://pythonconquerstheuniverse.wordpress.com/2009/09/10/debugging-in-python/)</a><br><small class="date"><b>Created:</b> April 18, 2016</small></li>
<li class="gist-entry" id="gist-3d8e407cbba5bd3539393dfbe7774fe2"><a href="gists/3d8e407cbba5bd3539393dfbe7774fe2.html">Update Homebrew Apache Bench</a><br><small class="date"><b>Created:</b> April 18, 2016</small></li>
<li class="gist-entry" id="gist-20e773f92466fc7508143bfafb55b9d3"><a href="gists/20e773f92466fc7508143bfafb55b9d3.html">Python setup for NeoVim</a><br><small class="date"><b>Created:</b> April 17, 2016</small></li>
<li class="gist-entry" id="gist-e7577572c0e8f59cbf34b91173d67dd4"><a href="gists/e7577572c0e8f59cbf34b91173d67dd4.html">Bash read the user input and react to it</a><br><small class="date"><b>Created:</b> April 17, 2016</small></li>
<li class="gist-entry" id="gist-481b72ab2db5d913a864958f4379ed42"><a href="gists/481b72ab2db5d913a864958f4379ed42.html">Redirect stdout and stderr</a><br><small class="date"><b>Created:</b> April 14, 2016</small></li>
<li class="gist-entry" id="gist-ce71e93f07f9f24030d0420a1969b3cc"><a href="gists/ce71e93f07f9f24030d0420a1969b3cc.html">Git Workflow</a><br><small class="date"><b>Created:</b> April 11, 2016</small></li>
<li class="gist-entry" id="gist-e70e1556656f92b9cb985b939e366973"><a href="gists/e70e1556656f92b9cb985b939e366973.html">Git Request Pull</a><br><small class="date"><b>Created:</b> April 11, 2016</small></li>
<li class="gist-entry" id="gist-daed0185d0a26c94417e13d54c189262"><a href="gists/daed0185d0a26c94417e13d54c189262.html">Ruby Socket Wrapper (one connection, multiple messages)</a><br><small class="date"><b>Created:</b> April 11, 2016</small></li>
<li class="gist-entry" id="gist-e26339e4d4469471a256317a9bacb8bb"><a href="gists/e26339e4d4469471a256317a9bacb8bb.html">gRPC: a REAL beginners guide</a><br><small class="date"><b>Created:</b> April 10, 2016</small></li>
<li class="gist-entry" id="gist-45732badab5a807e1d133dc9ceed315b"><a href="gists/45732badab5a807e1d133dc9ceed315b.html">Sinatra errors</a><br><small class="date"><b>Created:</b> April 7, 2016</small></li>
<li class="gist-entry" id="gist-a777d580dbf1c21e6dc27e7668c6f677"><a href="gists/a777d580dbf1c21e6dc27e7668c6f677.html">Test Rubocop against inline code</a><br><small class="date"><b>Created:</b> April 1, 2016</small></li>
<li class="gist-entry" id="gist-12999021c58e7b4911e3"><a href="gists/12999021c58e7b4911e3.html">Install dotfiles and give users options</a><br><small class="date"><b>Created:</b> March 27, 2016</small></li>
<li class="gist-entry" id="gist-edd6ab7279fc037d23d2"><a href="gists/edd6ab7279fc037d23d2.html">Bootstrap Mac OS X Configuration</a><br><small class="date"><b>Created:</b> March 27, 2016</small></li>
<li class="gist-entry" id="gist-c485a9d3a998edc413ac"><a href="gists/c485a9d3a998edc413ac.html">Ruby Dynamic JSON Logger session via Lambda</a><br><small class="date"><b>Created:</b> March 23, 2016</small></li>
<li class="gist-entry" id="gist-71e45214734c76652f02"><a href="gists/71e45214734c76652f02.html">Bash update current line when `echo`ing updating output</a><br><small class="date"><b>Created:</b> March 23, 2016</small></li>
<li class="gist-entry" id="gist-ae6ec15da52edf9efb50"><a href="gists/ae6ec15da52edf9efb50.html">SCP Remote Logs to Local Machine</a><br><small class="date"><b>Created:</b> March 22, 2016</small></li>
<li class="gist-entry" id="gist-b9e11ac5819137ff7a86"><a href="gists/b9e11ac5819137ff7a86.html">Apple Curl Issues</a><br><small class="date"><b>Created:</b> March 22, 2016</small></li>
<li class="gist-entry" id="gist-5658cb218bb50494a1fa"><a href="gists/5658cb218bb50494a1fa.html">Ruby stdlib debugger</a><br><small class="date"><b>Created:</b> March 21, 2016</small></li>
<li class="gist-entry" id="gist-bc08de0c739dbc1f5b68"><a href="gists/bc08de0c739dbc1f5b68.html">Bash ask user a question</a><br><small class="date"><b>Created:</b> March 21, 2016</small></li>
<li class="gist-entry" id="gist-e76b869dd1bc922b658e"><a href="gists/e76b869dd1bc922b658e.html">Ruby Sinatra Sessions</a><br><small class="date"><b>Created:</b> March 21, 2016</small></li>
<li class="gist-entry" id="gist-0fc25edb5d9ceeae74cc"><a href="gists/0fc25edb5d9ceeae74cc.html">Bash Strict Mode (http://redsymbol.net/articles/unofficial-bash-strict-mode/)</a><br><small class="date"><b>Created:</b> March 20, 2016</small></li>
<li class="gist-entry" id="gist-a49df746e2bd30bff047"><a href="gists/a49df746e2bd30bff047.html">Different Linux utility commands (e.g. top, ps, strace, lsof, netstat, ifconfig, iftop, iptraf, tcpdump, wireshark)</a><br><small class="date"><b>Created:</b> March 18, 2016</small></li>
<li class="gist-entry" id="gist-72d1f0ab5155c1a27d3f"><a href="gists/72d1f0ab5155c1a27d3f.html">Ruby Mock Redis</a><br><small class="date"><b>Created:</b> March 17, 2016</small></li>
<li class="gist-entry" id="gist-22520358fced54b3fed5"><a href="gists/22520358fced54b3fed5.html">Microservices</a><br><small class="date"><b>Created:</b> March 9, 2016</small></li>
<li class="gist-entry" id="gist-584f6a4cf0a607a9da52"><a href="gists/584f6a4cf0a607a9da52.html">[Vegeta load test examples https://github.com/tsenart/vegeta] </a><br><small class="date"><b>Created:</b> March 4, 2016</small><small class="date"><b>Tags:</b> #go #golang #vegeta #examples #loadtest #benchmark #report</small></li>
<li class="gist-entry" id="gist-45e295b305511005d22e"><a href="gists/45e295b305511005d22e.html">[Bash Watchtower] </a><br><small class="date"><b>Created:</b> March 1, 2016</small><small class="date"><b>Tags:</b> #bash #shell #watchtower</small></li>
<li class="gist-entry" id="gist-05bbbfd6130d16730fcc"><a href="gists/05bbbfd6130d16730fcc.html">Nice Ruby Rack Tests</a><br><small class="date"><b>Created:</b> February 29, 2016</small></li>
<li class="gist-entry" id="gist-e6fa5e03254a9309fe27"><a href="gists/e6fa5e03254a9309fe27.html">Ruby Load Path</a><br><small class="date"><b>Created:</b> February 29, 2016</small></li>
<li class="gist-entry" id="gist-bceec14f23672bf3174c"><a href="gists/bceec14f23672bf3174c.html">Print the next line AFTER your pattern has matched with AWK</a><br><small class="date"><b>Created:</b> February 28, 2016</small></li>
<li class="gist-entry" id="gist-cc6d9574ae6598cf78c5"><a href="gists/cc6d9574ae6598cf78c5.html">Ruby Google Calendar API</a><br><small class="date"><b>Created:</b> February 28, 2016</small></li>
<li class="gist-entry" id="gist-9f37c7f929b616aa9fdd"><a href="gists/9f37c7f929b616aa9fdd.html">chmod and chown explained</a><br><small class="date"><b>Created:</b> February 26, 2016</small></li>
<li class="gist-entry" id="gist-00e077ff960d4e15315b"><a href="gists/00e077ff960d4e15315b.html">Ruby Bundler Nokogiri Bug</a><br><small class="date"><b>Created:</b> February 25, 2016</small></li>
<li class="gist-entry" id="gist-87852ced09d7918322c0"><a href="gists/87852ced09d7918322c0.html">Git Patch and Apply (see alternative patch generation and applying in reverse: https://gist.github.com/Integralist/13d9f5e8ec197e5e53c6)</a><br><small class="date"><b>Created:</b> February 25, 2016</small></li>
<li class="gist-entry" id="gist-df21ee2b5597aa0437e5"><a href="gists/df21ee2b5597aa0437e5.html">Ruby Threads: failing fast</a><br><small class="date"><b>Created:</b> February 23, 2016</small></li>
<li class="gist-entry" id="gist-6217f7b942fb056837e0"><a href="gists/6217f7b942fb056837e0.html">Ruby Thread speed and fail fast</a><br><small class="date"><b>Created:</b> February 23, 2016</small></li>
<li class="gist-entry" id="gist-c167accb81374c134331"><a href="gists/c167accb81374c134331.html">WebSockets with Vanilla JS and Ruby Faye</a><br><small class="date"><b>Created:</b> February 18, 2016</small></li>
<li class="gist-entry" id="gist-5611d411cffe72e39161"><a href="gists/5611d411cffe72e39161.html">Ruby client communicating with Go RPC over a TCP socket</a><br><small class="date"><b>Created:</b> February 18, 2016</small></li>
<li class="gist-entry" id="gist-74fffc52bb68e2bcd738"><a href="gists/74fffc52bb68e2bcd738.html">[Trap exit and error (defer cleanup execution when bash script fails)] </a><br><small class="date"><b>Created:</b> February 11, 2016</small><small class="date"><b>Tags:</b> #bash #trap #catch #errorhandling</small></li>
<li class="gist-entry" id="gist-1a069f995b3de3836a6c"><a href="gists/1a069f995b3de3836a6c.html">Apache LogFormat Example</a><br><small class="date"><b>Created:</b> February 10, 2016</small></li>
<li class="gist-entry" id="gist-8ae1882966237fb5e98c"><a href="gists/8ae1882966237fb5e98c.html">Avoid SSH connection timeout & freezing of terminal tab</a><br><small class="date"><b>Created:</b> February 10, 2016</small></li>
<li class="gist-entry" id="gist-57ff3b8c17e918c4e9fe"><a href="gists/57ff3b8c17e918c4e9fe.html">Redis testing on EC2 instance with CentOS</a><br><small class="date"><b>Created:</b> February 10, 2016</small></li>
<li class="gist-entry" id="gist-68f45e3aebccc2f5068e"><a href="gists/68f45e3aebccc2f5068e.html">Restrict Access to pushing updates to an API in the Live environment (except via Jenkins CI) via Apache</a><br><small class="date"><b>Created:</b> February 10, 2016</small></li>
<li class="gist-entry" id="gist-970b8e4a595b118acdd3"><a href="gists/970b8e4a595b118acdd3.html">Bash Template (an older version with different variations can be found here: https://gist.github.com/Integralist/c16c4cc7698cebb8d606)</a><br><small class="date"><b>Created:</b> February 4, 2016</small></li>
<li class="gist-entry" id="gist-a625dd7d7c0d07bf1ad6"><a href="gists/a625dd7d7c0d07bf1ad6.html">Simple check for git repo in Bash</a><br><small class="date"><b>Created:</b> February 4, 2016</small></li>
<li class="gist-entry" id="gist-c16c4cc7698cebb8d606"><a href="gists/c16c4cc7698cebb8d606.html">Basic Bash Configuration (superseded by https://gist.github.com/Integralist/970b8e4a595b118acdd3)</a><br><small class="date"><b>Created:</b> February 1, 2016</small></li>
<li class="gist-entry" id="gist-59cfb4f4e6185a9c7107"><a href="gists/59cfb4f4e6185a9c7107.html">Access Instance and Class level methods (one example using `new`)</a><br><small class="date"><b>Created:</b> January 29, 2016</small></li>
<li class="gist-entry" id="gist-8079e79c5eb4e7b88183"><a href="gists/8079e79c5eb4e7b88183.html">Example script that uses the `&` trick (typically used to convert an object to a proc; e.g. https://gist.github.com/Integralist/11206577) to convert a method (retrieved using `method()`) to a proc so it can be utilised by another method</a><br><small class="date"><b>Created:</b> January 29, 2016</small></li>
<li class="gist-entry" id="gist-2bd037f7450bbf7b9f10"><a href="gists/2bd037f7450bbf7b9f10.html">Basic Vim config for when ssh'ed onto an EC2 instance (yum install vim -y)</a><br><small class="date"><b>Created:</b> January 27, 2016</small></li>
<li class="gist-entry" id="gist-cff468ba808fbca09602"><a href="gists/cff468ba808fbca09602.html">Networking CIDR explained</a><br><small class="date"><b>Created:</b> January 25, 2016</small></li>
<li class="gist-entry" id="gist-23fe68c35bb2907bdc44"><a href="gists/23fe68c35bb2907bdc44.html">Ruby: get class name and method name</a><br><small class="date"><b>Created:</b> January 19, 2016</small></li>
<li class="gist-entry" id="gist-a4c88da0e30d7053d1b6"><a href="gists/a4c88da0e30d7053d1b6.html">Best Practice Code Design and Architecture</a><br><small class="date"><b>Created:</b> January 15, 2016</small></li>
<li class="gist-entry" id="gist-4e84af31c483d0f5a182"><a href="gists/4e84af31c483d0f5a182.html">Code of Conduct (Template)</a><br><small class="date"><b>Created:</b> January 15, 2016</small></li>
<li class="gist-entry" id="gist-c7e23300cf1e95c9c750"><a href="gists/c7e23300cf1e95c9c750.html">List remote NPM dependencies</a><br><small class="date"><b>Created:</b> January 13, 2016</small></li>
<li class="gist-entry" id="gist-ad19a062fde8991e4373"><a href="gists/ad19a062fde8991e4373.html">HTTP Status Codes</a><br><small class="date"><b>Created:</b> January 12, 2016</small></li>
<li class="gist-entry" id="gist-35479416b54f2ee51b31"><a href="gists/35479416b54f2ee51b31.html">Search for files and pipe into Vim</a><br><small class="date"><b>Created:</b> January 5, 2016</small></li>
<li class="gist-entry" id="gist-9c87172cb418e539dae0"><a href="gists/9c87172cb418e539dae0.html">Redis vs Memcache</a><br><small class="date"><b>Created:</b> January 5, 2016</small></li>
<li class="gist-entry" id="gist-aeb52af738eef575b718"><a href="gists/aeb52af738eef575b718.html">[Update all submodules for a repo with a single command] </a><br><small class="date"><b>Created:</b> January 4, 2016</small><small class="date"><b>Tags:</b> #git #submodules</small></li>
<li class="gist-entry" id="gist-b3621d6ed0f46901f200"><a href="gists/b3621d6ed0f46901f200.html">Guitar Music Theory</a><br><small class="date"><b>Created:</b> December 28, 2015</small></li>
<li class="gist-entry" id="gist-0e277a517fee68153f93"><a href="gists/0e277a517fee68153f93.html">OAuth</a><br><small class="date"><b>Created:</b> December 22, 2015</small></li>
<li class="gist-entry" id="gist-00450ac1debb0d243a5c"><a href="gists/00450ac1debb0d243a5c.html">[Datadog Monitoring and Metrics] </a><br><small class="date"><b>Created:</b> December 22, 2015</small><small class="date"><b>Tags:</b> #datadog #metrics #monitoring #cost</small></li>
<li class="gist-entry" id="gist-95bc6060fbf40d00265e"><a href="gists/95bc6060fbf40d00265e.html">Flawed Golang concurrency logic: diff below shows the fixed code</a><br><small class="date"><b>Created:</b> December 21, 2015</small></li>
<li class="gist-entry" id="gist-b80617d2a70288bacd97"><a href="gists/b80617d2a70288bacd97.html">DB migrations</a><br><small class="date"><b>Created:</b> December 19, 2015</small></li>
<li class="gist-entry" id="gist-e8c418156d2330d53fab"><a href="gists/e8c418156d2330d53fab.html">Year in Review 2015</a><br><small class="date"><b>Created:</b> December 19, 2015</small></li>
<li class="gist-entry" id="gist-2225a8b2c3e12c92757f"><a href="gists/2225a8b2c3e12c92757f.html">Ruby Alephant JSON Logger</a><br><small class="date"><b>Created:</b> December 18, 2015</small></li>
<li class="gist-entry" id="gist-c5f3bfa368cb1dc7ce51"><a href="gists/c5f3bfa368cb1dc7ce51.html">Semantic Versioning Explanation</a><br><small class="date"><b>Created:</b> December 11, 2015</small></li>
<li class="gist-entry" id="gist-f3ce36ed840eda63f8e8"><a href="gists/f3ce36ed840eda63f8e8.html">Docker Compose: Example Ruby Application</a><br><small class="date"><b>Created:</b> December 11, 2015</small></li>
<li class="gist-entry" id="gist-f5856b94e002bcfd4ce7"><a href="gists/f5856b94e002bcfd4ce7.html">RPC: Remote Procedure Call</a><br><small class="date"><b>Created:</b> December 4, 2015</small></li>
<li class="gist-entry" id="gist-e785c93566f96e1fcaf4"><a href="gists/e785c93566f96e1fcaf4.html">Ruby Decorator Design Pattern for BBC: with a little imagination you can see how we could store data in S3 instead of "printing" it to the screen AND also how we could have some models extend based on a whitelist (as some components you'll want to extend ALL formatters, and other components you'll only want to extend from one or two formatters)</a><br><small class="date"><b>Created:</b> December 2, 2015</small></li>
<li class="gist-entry" id="gist-8058ac54088408d9aadc"><a href="gists/8058ac54088408d9aadc.html">Ruby Fail vs Raise</a><br><small class="date"><b>Created:</b> November 30, 2015</small></li>
<li class="gist-entry" id="gist-72161a96641fa4a0033d"><a href="gists/72161a96641fa4a0033d.html">Install Redis CLI on AWS Instance</a><br><small class="date"><b>Created:</b> November 27, 2015</small></li>
<li class="gist-entry" id="gist-0f773d286e0e3692a0aa"><a href="gists/0f773d286e0e3692a0aa.html">[Programming types: imperative vs declarative vs structured] </a><br><small class="date"><b>Created:</b> November 27, 2015</small><small class="date"><b>Tags:</b> #types #procedural #imperative #declarative #structured</small></li>
<li class="gist-entry" id="gist-633482ec3d2e75ac2d05"><a href="gists/633482ec3d2e75ac2d05.html">Bash pipestatus</a><br><small class="date"><b>Created:</b> November 25, 2015</small></li>
<li class="gist-entry" id="gist-16b2354277bd8dac01d8"><a href="gists/16b2354277bd8dac01d8.html">Jenkins CI -> GitHub API</a><br><small class="date"><b>Created:</b> November 25, 2015</small></li>
<li class="gist-entry" id="gist-63d1491144aa80cd6fb1"><a href="gists/63d1491144aa80cd6fb1.html">HTTP Security Headers</a><br><small class="date"><b>Created:</b> November 19, 2015</small></li>
<li class="gist-entry" id="gist-d7543ea8624750e80f9a"><a href="gists/d7543ea8624750e80f9a.html">Senior Ruby Programmer: Job Spec</a><br><small class="date"><b>Created:</b> November 19, 2015</small></li>
<li class="gist-entry" id="gist-7ddef5afaeeff601fc72"><a href="gists/7ddef5afaeeff601fc72.html">[REST design: PUT vs POST] </a><br><small class="date"><b>Created:</b> November 19, 2015</small><small class="date"><b>Tags:</b> #REST #API #PUT #POST #DELETE #GET #methods #http</small></li>
<li class="gist-entry" id="gist-e69c50d02f0edf086dbd"><a href="gists/e69c50d02f0edf086dbd.html">[Caching strategies and headers] (see also http://fideloper.com/api-etag-conditional-get) </a><br><small class="date"><b>Created:</b> November 18, 2015</small><small class="date"><b>Tags:</b> #cache #caching #headers #stale #revalidate #memcache #redis #varnish #nginx #fastly #cdn #if-none-match #conditional #http</small></li>
<li class="gist-entry" id="gist-e2a129d5f4fa04bf4c8b"><a href="gists/e2a129d5f4fa04bf4c8b.html">Ruby parsing of complex nested data structures from the Query String</a><br><small class="date"><b>Created:</b> November 18, 2015</small></li>
<li class="gist-entry" id="gist-0c12b8233666b443b29e"><a href="gists/0c12b8233666b443b29e.html">Convert a P12 into a PEM and vice versa</a><br><small class="date"><b>Created:</b> November 17, 2015</small></li>
<li class="gist-entry" id="gist-acda6e7647e0e23a001c"><a href="gists/acda6e7647e0e23a001c.html">Use Docker to setup a Ruby application to use a private gem server. The reason I'm documenting this is because Ruby's Bundler gem is notoriously problematic using SSL</a><br><small class="date"><b>Created:</b> November 16, 2015</small></li>
<li class="gist-entry" id="gist-69ef5e1465744364843c"><a href="gists/69ef5e1465744364843c.html">SCP examples (local to remote and remote to local)</a><br><small class="date"><b>Created:</b> November 11, 2015</small></li>
<li class="gist-entry" id="gist-a0acc2b0b0fe2c2860a9"><a href="gists/a0acc2b0b0fe2c2860a9.html">tree exclude directories</a><br><small class="date"><b>Created:</b> November 10, 2015</small></li>
<li class="gist-entry" id="gist-121a664d6f93b82dcd53"><a href="gists/121a664d6f93b82dcd53.html">Kubernetes Essentials</a><br><small class="date"><b>Created:</b> November 8, 2015</small></li>
<li class="gist-entry" id="gist-43574477639b327e1d8a"><a href="gists/43574477639b327e1d8a.html">Demonstrating the set-up of CoreOS and how to utilise Etcd along with Systemd and Fleet</a><br><small class="date"><b>Created:</b> October 29, 2015</small></li>
<li class="gist-entry" id="gist-1e0b704fd3c008399cae"><a href="gists/1e0b704fd3c008399cae.html">Faraday TLS Connection</a><br><small class="date"><b>Created:</b> October 26, 2015</small></li>
<li class="gist-entry" id="gist-f4eabcda00379fc7c0de"><a href="gists/f4eabcda00379fc7c0de.html">Sift example that demonstrates how to ignore a directory and also display the line numbers whilst using a regex pattern with a word boundary</a><br><small class="date"><b>Created:</b> October 21, 2015</small></li>
<li class="gist-entry" id="gist-644095f06ec4eb8651a8"><a href="gists/644095f06ec4eb8651a8.html">irssi irc connecting to network and joining a channel (and identify yourself if you seen an error about joining a channel)</a><br><small class="date"><b>Created:</b> October 19, 2015</small></li>
<li class="gist-entry" id="gist-d16db70821e2a4c57bb0"><a href="gists/d16db70821e2a4c57bb0.html">HTTP/2 notes (taken from https://www.nginx.com/wp-content/uploads/2015/09/NGINX_HTTP2_White_Paper_v4.pdf)</a><br><small class="date"><b>Created:</b> October 19, 2015</small></li>
<li class="gist-entry" id="gist-25ed16d02e1d60b7d0dc"><a href="gists/25ed16d02e1d60b7d0dc.html">Go running in Lambda: https://gist.github.com/miksago/d1c456d4e235e025791d and http://blog.0x82.com/2014/11/24/aws-lambda-functions-in-go/ and https://github.com/jasonmoo/lambda_proc for more details</a><br><small class="date"><b>Created:</b> October 14, 2015</small></li>
<li class="gist-entry" id="gist-e36796c130b4bf6b356c"><a href="gists/e36796c130b4bf6b356c.html">`curl -s -L bit.ly/<your_bitly>  | bash` <- bit.ly should point to a private gist that pulls content from a public S3 bucket</a><br><small class="date"><b>Created:</b> September 16, 2015</small></li>
<li class="gist-entry" id="gist-8236c15562389b10b576"><a href="gists/8236c15562389b10b576.html">Demonstrates how to use Sumo Logic query language</a><br><small class="date"><b>Created:</b> September 16, 2015</small></li>
<li class="gist-entry" id="gist-147104c868f171f7604e"><a href="gists/147104c868f171f7604e.html">AWS Assume Role</a><br><small class="date"><b>Created:</b> September 9, 2015</small></li>
<li class="gist-entry" id="gist-6a39f1181b02edf4fdd6"><a href="gists/6a39f1181b02edf4fdd6.html">Dockerfile that demonstrates how to use Supervisord.org</a><br><small class="date"><b>Created:</b> September 1, 2015</small></li>
<li class="gist-entry" id="gist-e5906e3dd84b1088decf"><a href="gists/e5906e3dd84b1088decf.html">Building a Go program via Docker</a><br><small class="date"><b>Created:</b> August 27, 2015</small></li>
<li class="gist-entry" id="gist-70f17466b7056403b05d"><a href="gists/70f17466b7056403b05d.html">[curl performance timing] </a><br><small class="date"><b>Created:</b> August 22, 2015</small><small class="date"><b>Tags:</b> #curl #performance #monitoring</small></li>
<li class="gist-entry" id="gist-4d465b2f0e0c3a03db38"><a href="gists/4d465b2f0e0c3a03db38.html">Regular Expression that matches Camel Cased words</a><br><small class="date"><b>Created:</b> August 17, 2015</small></li>
<li class="gist-entry" id="gist-eb7bf0d8f3b7d9958f13"><a href="gists/eb7bf0d8f3b7d9958f13.html">Zsh and Bash Array Shift (remove first item from the Array)</a><br><small class="date"><b>Created:</b> August 17, 2015</small></li>
<li class="gist-entry" id="gist-354984f84b5dfec8a7c6"><a href="gists/354984f84b5dfec8a7c6.html">Docker Machine on Mac OS X</a><br><small class="date"><b>Created:</b> August 15, 2015</small></li>
<li class="gist-entry" id="gist-e4f2fd44affa4bf901e5"><a href="gists/e4f2fd44affa4bf901e5.html">If a shell command returns an exit status then you'll find that in a CI environment that the job will immediately fail. To resolve this you should capture the error and then pipe the result and then use PIPESTATUS instead</a><br><small class="date"><b>Created:</b> August 13, 2015</small></li>
<li class="gist-entry" id="gist-8247ac875ed6d556198b"><a href="gists/8247ac875ed6d556198b.html">Test Files for Composition Example</a><br><small class="date"><b>Created:</b> August 11, 2015</small></li>
<li class="gist-entry" id="gist-2e381839f67447a178f9"><a href="gists/2e381839f67447a178f9.html">git merge --squash brings in your changes but doesn't create a commit. Instead it will stage your changes so you can create a fresh commit for it (avoiding ugly merge commits showing in GitHub when using a standard git merge)</a><br><small class="date"><b>Created:</b> August 7, 2015</small></li>
<li class="gist-entry" id="gist-8ee681ac96a9c28fcb71"><a href="gists/8ee681ac96a9c28fcb71.html">Super basic concurrency based HTTP requester</a><br><small class="date"><b>Created:</b> August 4, 2015</small></li>
<li class="gist-entry" id="gist-403d7985d22d58080722"><a href="gists/403d7985d22d58080722.html">[Bash Array Looping] </a><br><small class="date"><b>Created:</b> July 28, 2015</small><small class="date"><b>Tags:</b> #bash #shell #loop #code #gen</small></li>
<li class="gist-entry" id="gist-e9ea91ef026ed698c5f9"><a href="gists/e9ea91ef026ed698c5f9.html">Modify Boot2Docker to default specific arguments when executing the docker command</a><br><small class="date"><b>Created:</b> July 27, 2015</small></li>
<li class="gist-entry" id="gist-bb1b1623e5229455fd7f"><a href="gists/bb1b1623e5229455fd7f.html">Multiline Curl PUT'ing of data with no extra processing (thanks to --data-binary flag). We also use @ with a hyphen, so @- (the hyphen indicates input from stdin)</a><br><small class="date"><b>Created:</b> July 21, 2015</small></li>
<li class="gist-entry" id="gist-b4169a24ec0c55f00fde"><a href="gists/b4169a24ec0c55f00fde.html">Benchmark MRI vs JRuby</a><br><small class="date"><b>Created:</b> July 17, 2015</small></li>
<li class="gist-entry" id="gist-d8f9ff562bc9d2454543"><a href="gists/d8f9ff562bc9d2454543.html">Basic Ruby exception and error handling</a><br><small class="date"><b>Created:</b> June 11, 2015</small></li>
<li class="gist-entry" id="gist-749153aa53fea7168e7e"><a href="gists/749153aa53fea7168e7e.html">Array flatten function written in ES6 syntax</a><br><small class="date"><b>Created:</b> May 20, 2015</small></li>
<li class="gist-entry" id="gist-53f6dc643fd0227c6606"><a href="gists/53f6dc643fd0227c6606.html">Golang Essentials</a><br><small class="date"><b>Created:</b> May 11, 2015</small></li>
<li class="gist-entry" id="gist-0cad5acc795175e53393"><a href="gists/0cad5acc795175e53393.html">Building an RPM https://github.com/integralist/simple-rpm</a><br><small class="date"><b>Created:</b> May 11, 2015</small></li>
<li class="gist-entry" id="gist-8b9e15be0a3dd175ab19"><a href="gists/8b9e15be0a3dd175ab19.html">Sinatra and Docker</a><br><small class="date"><b>Created:</b> May 8, 2015</small></li>
<li class="gist-entry" id="gist-160dbf75898bcf9cc4a6"><a href="gists/160dbf75898bcf9cc4a6.html">Siege load/stress testing utility (https://www.joedog.org/siege-manual/)</a><br><small class="date"><b>Created:</b> May 8, 2015</small></li>
<li class="gist-entry" id="gist-5cfd5c884b0f2c0c5d11"><a href="gists/5cfd5c884b0f2c0c5d11.html">nginx and ruby</a><br><small class="date"><b>Created:</b> May 4, 2015</small></li>
<li class="gist-entry" id="gist-9e9be437bf4ef6f79e4d"><a href="gists/9e9be437bf4ef6f79e4d.html">Docker container for a better curl than found natively on Mac OSX</a><br><small class="date"><b>Created:</b> April 20, 2015</small></li>
<li class="gist-entry" id="gist-1f905931c7aa6d760489"><a href="gists/1f905931c7aa6d760489.html">AWS Lambda using Ruby (via uploaded compiled binary of MRI)</a><br><small class="date"><b>Created:</b> April 17, 2015</small></li>
<li class="gist-entry" id="gist-1745beb7b1607caf36f1"><a href="gists/1745beb7b1607caf36f1.html">[Sed Insert Append + Prefix and Suffix] </a><br><small class="date"><b>Created:</b> April 15, 2015</small><small class="date"><b>Tags:</b> #sed #bash #insert #append #prefix #suffix</small></li>
<li class="gist-entry" id="gist-f701ff1065a751387cb1"><a href="gists/f701ff1065a751387cb1.html">Example of a slightly complex search/filter query for Elasticsearch (the - before message means NOT)</a><br><small class="date"><b>Created:</b> April 15, 2015</small></li>
<li class="gist-entry" id="gist-2e3c083cb4d16bfb5779"><a href="gists/2e3c083cb4d16bfb5779.html">This is a nice concise where to extract the successful match within a capture group using Ruby: http://ruby-doc.org/core-2.2.0/String.html</a><br><small class="date"><b>Created:</b> April 10, 2015</small><small class="date"><b>Tags:</b> #method-i-5B-5D</small></li>
<li class="gist-entry" id="gist-db10e8e8a6ec2ca8515d"><a href="gists/db10e8e8a6ec2ca8515d.html">Optimise image size using Ruby</a><br><small class="date"><b>Created:</b> April 10, 2015</small></li>
<li class="gist-entry" id="gist-77877126a0b13766f0de"><a href="gists/77877126a0b13766f0de.html">[Tech Books: Recommended Reading] </a><br><small class="date"><b>Created:</b> March 22, 2015</small><small class="date"><b>Tags:</b> #reading #books #list</small></li>
<li class="gist-entry" id="gist-4fe392b768bf94d23abc"><a href="gists/4fe392b768bf94d23abc.html">Clojure Macros cheat sheet</a><br><small class="date"><b>Created:</b> February 16, 2015</small></li>
<li class="gist-entry" id="gist-bdb68d0b499bc502be11"><a href="gists/bdb68d0b499bc502be11.html">Clojure talking to Spurious</a><br><small class="date"><b>Created:</b> February 8, 2015</small></li>
<li class="gist-entry" id="gist-3822807d3c91281af22d"><a href="gists/3822807d3c91281af22d.html">Rubocop: ignore/disable features + example configuration yaml</a><br><small class="date"><b>Created:</b> February 4, 2015</small></li>
<li class="gist-entry" id="gist-9d9a28e7c0e07fa8fd52"><a href="gists/9d9a28e7c0e07fa8fd52.html">POST data via curl command using CERT and password</a><br><small class="date"><b>Created:</b> January 26, 2015</small></li>
<li class="gist-entry" id="gist-6ba8b3effc03aa47ab93"><a href="gists/6ba8b3effc03aa47ab93.html">Clojure deftype, defrecord, defprotocol</a><br><small class="date"><b>Created:</b> January 24, 2015</small></li>
<li class="gist-entry" id="gist-e4cc5e0816fbb6b64142"><a href="gists/e4cc5e0816fbb6b64142.html">Server-Sent Events in Ruby</a><br><small class="date"><b>Created:</b> January 13, 2015</small></li>
<li class="gist-entry" id="gist-4537e399bf987b4635f1"><a href="gists/4537e399bf987b4635f1.html">Executing the Clojure STM within JRuby (code modified from "Programming Concurrency on the JVM")</a><br><small class="date"><b>Created:</b> January 10, 2015</small></li>
<li class="gist-entry" id="gist-c3d0c9dd88629d2835f4"><a href="gists/c3d0c9dd88629d2835f4.html">Ruby Array subset methods (intersection, difference, union)</a><br><small class="date"><b>Created:</b> January 5, 2015</small></li>
<li class="gist-entry" id="gist-c0a412d184fbf01f41e6"><a href="gists/c0a412d184fbf01f41e6.html">How encryption with certificates and public/private keys work</a><br><small class="date"><b>Created:</b> January 5, 2015</small></li>
<li class="gist-entry" id="gist-12b3f1370dbc1530ad0b"><a href="gists/12b3f1370dbc1530ad0b.html">Rust Cargo Guardfile</a><br><small class="date"><b>Created:</b> January 4, 2015</small></li>
<li class="gist-entry" id="gist-6843e2cb448d879aa5a6"><a href="gists/6843e2cb448d879aa5a6.html">Rust Guardfile</a><br><small class="date"><b>Created:</b> January 4, 2015</small></li>
<li class="gist-entry" id="gist-62a2b3e41c27ec680cbf"><a href="gists/62a2b3e41c27ec680cbf.html">Spawning Actors in Celluloid</a><br><small class="date"><b>Created:</b> January 3, 2015</small></li>
<li class="gist-entry" id="gist-e24848ee273fe4adab2c"><a href="gists/e24848ee273fe4adab2c.html">VimScript custom function that triggers tmux pane to open specified gem contents within Vim</a><br><small class="date"><b>Created:</b> January 1, 2015</small></li>
<li class="gist-entry" id="gist-1fbbe4dafc77200c0bed"><a href="gists/1fbbe4dafc77200c0bed.html">Ruby: override `new` constructor method using meta programming</a><br><small class="date"><b>Created:</b> December 31, 2014</small></li>
<li class="gist-entry" id="gist-741c2577e97fd8e466a4"><a href="gists/741c2577e97fd8e466a4.html">Clojure Thread State</a><br><small class="date"><b>Created:</b> December 29, 2014</small></li>
<li class="gist-entry" id="gist-6d8c6e44d79e0ca17579"><a href="gists/6d8c6e44d79e0ca17579.html">Ruby DI Container Example (Dim)</a><br><small class="date"><b>Created:</b> December 28, 2014</small></li>
<li class="gist-entry" id="gist-8437127809c10ca964ca"><a href="gists/8437127809c10ca964ca.html">Ruby Meta Programming: Dynamically create Class methods with values populated from YAML config</a><br><small class="date"><b>Created:</b> December 28, 2014</small></li>
<li class="gist-entry" id="gist-708fe5cda56a7bc958ad"><a href="gists/708fe5cda56a7bc958ad.html">Year in Review 2014</a><br><small class="date"><b>Created:</b> December 24, 2014</small></li>
<li class="gist-entry" id="gist-21cc5b702beb276054b0"><a href="gists/21cc5b702beb276054b0.html">Concurrency: JRuby vs MRI</a><br><small class="date"><b>Created:</b> December 23, 2014</small></li>
<li class="gist-entry" id="gist-bb8760d11a03c88da151"><a href="gists/bb8760d11a03c88da151.html">Ruby: private class level methods</a><br><small class="date"><b>Created:</b> December 18, 2014</small></li>
<li class="gist-entry" id="gist-e9a7c7fdc7244f7854ad"><a href="gists/e9a7c7fdc7244f7854ad.html">Trello API</a><br><small class="date"><b>Created:</b> December 17, 2014</small></li>
<li class="gist-entry" id="gist-24da7316dee1ba00bd66"><a href="gists/24da7316dee1ba00bd66.html">JIRA API creating a ticket/issue</a><br><small class="date"><b>Created:</b> December 16, 2014</small></li>
<li class="gist-entry" id="gist-3db095cb29dc6ae7625c"><a href="gists/3db095cb29dc6ae7625c.html">Reading "Programming Concurrency on the JVM" I found an example (which I've modified below) using Clojure to solve a classic concurrency dilemma by using the STM to help keep things sane.</a><br><small class="date"><b>Created:</b> December 15, 2014</small></li>
<li class="gist-entry" id="gist-6912a6ad05754dc0e9dc"><a href="gists/6912a6ad05754dc0e9dc.html">RSpec described_class</a><br><small class="date"><b>Created:</b> December 12, 2014</small></li>
<li class="gist-entry" id="gist-9f9f2215e001b15ac492"><a href="gists/9f9f2215e001b15ac492.html">DynamoDB (using Spurious)</a><br><small class="date"><b>Created:</b> November 24, 2014</small></li>
<li class="gist-entry" id="gist-e10f8e1370f977fd6573"><a href="gists/e10f8e1370f977fd6573.html">DynamoDB Update Document</a><br><small class="date"><b>Created:</b> November 24, 2014</small></li>
<li class="gist-entry" id="gist-6c8bfed1550ec8b9933e"><a href="gists/6c8bfed1550ec8b9933e.html">Netcat</a><br><small class="date"><b>Created:</b> November 24, 2014</small></li>
<li class="gist-entry" id="gist-40f9f61537b2f7d471a6"><a href="gists/40f9f61537b2f7d471a6.html">Terminal go back up one line</a><br><small class="date"><b>Created:</b> November 24, 2014</small></li>
<li class="gist-entry" id="gist-ad1a9536d19b142f11d3"><a href="gists/ad1a9536d19b142f11d3.html">Rack Middleware</a><br><small class="date"><b>Created:</b> November 15, 2014</small></li>
<li class="gist-entry" id="gist-7b9034a9a961bcf76b0d"><a href="gists/7b9034a9a961bcf76b0d.html">Fix EC2 Timezone issues</a><br><small class="date"><b>Created:</b> November 7, 2014</small></li>
<li class="gist-entry" id="gist-52156c512704dd7bc5c2"><a href="gists/52156c512704dd7bc5c2.html">[Manually compile Vim] </a><br><small class="date"><b>Created:</b> November 2, 2014</small><small class="date"><b>Tags:</b> #tags: vim, compile</small></li>
<li class="gist-entry" id="gist-b675a263897680e02fbd"><a href="gists/b675a263897680e02fbd.html">Go Guardfile: `bundle exec guard`</a><br><small class="date"><b>Created:</b> October 31, 2014</small></li>
<li class="gist-entry" id="gist-a6f9e207314a91da13f5"><a href="gists/a6f9e207314a91da13f5.html">Ruby Gems Docker</a><br><small class="date"><b>Created:</b> October 31, 2014</small></li>
<li class="gist-entry" id="gist-29580a0cf6d17ef2f446"><a href="gists/29580a0cf6d17ef2f446.html">JS "pass by"</a><br><small class="date"><b>Created:</b> October 28, 2014</small></li>
<li class="gist-entry" id="gist-66aa5635fb388934822c"><a href="gists/66aa5635fb388934822c.html">Ruby JSON Schema Generator and Validator</a><br><small class="date"><b>Created:</b> October 24, 2014</small></li>
<li class="gist-entry" id="gist-a83752c51a4736230d85"><a href="gists/a83752c51a4736230d85.html">Ruby Faraday SSL</a><br><small class="date"><b>Created:</b> October 24, 2014</small></li>
<li class="gist-entry" id="gist-c94349404471165b8f8a"><a href="gists/c94349404471165b8f8a.html">Get HTTP Status Code</a><br><small class="date"><b>Created:</b> October 20, 2014</small></li>
<li class="gist-entry" id="gist-4708a79785466a800b90"><a href="gists/4708a79785466a800b90.html">Sinatra Reloader</a><br><small class="date"><b>Created:</b> October 15, 2014</small></li>
<li class="gist-entry" id="gist-151e15da5f74c9b4ea0e"><a href="gists/151e15da5f74c9b4ea0e.html">Bankers Dilemma</a><br><small class="date"><b>Created:</b> October 12, 2014</small></li>
<li class="gist-entry" id="gist-7968aefac0f35f914484"><a href="gists/7968aefac0f35f914484.html">Ruby Namespace Concern</a><br><small class="date"><b>Created:</b> October 9, 2014</small></li>
<li class="gist-entry" id="gist-39e4c5ee5a226d5dc0e2"><a href="gists/39e4c5ee5a226d5dc0e2.html">Designing Systems and Applications</a><br><small class="date"><b>Created:</b> October 3, 2014</small></li>
<li class="gist-entry" id="gist-06004b0fccc2bed05460"><a href="gists/06004b0fccc2bed05460.html">Docker tagging and ONBUILD</a><br><small class="date"><b>Created:</b> October 3, 2014</small></li>
<li class="gist-entry" id="gist-4691a91dae0d7e1bb3d4"><a href="gists/4691a91dae0d7e1bb3d4.html">Node Dockerfile with PhantomJS</a><br><small class="date"><b>Created:</b> October 2, 2014</small></li>
<li class="gist-entry" id="gist-8015efed6bfb59ee93af"><a href="gists/8015efed6bfb59ee93af.html">Ruby: Check Balanced Params</a><br><small class="date"><b>Created:</b> October 1, 2014</small></li>
<li class="gist-entry" id="gist-d67f0f913d795f703b89"><a href="gists/d67f0f913d795f703b89.html">Design Patterns: Adapter vs Facade vs Bridge</a><br><small class="date"><b>Created:</b> September 26, 2014</small></li>
<li class="gist-entry" id="gist-9d02e37ee65746cdafdb"><a href="gists/9d02e37ee65746cdafdb.html">Ruby Threads</a><br><small class="date"><b>Created:</b> September 25, 2014</small></li>
<li class="gist-entry" id="gist-9a56468ba84d82c7ae6d"><a href="gists/9a56468ba84d82c7ae6d.html">Manually SSH into Vagrant</a><br><small class="date"><b>Created:</b> September 18, 2014</small></li>
<li class="gist-entry" id="gist-f82dcb34a431e8fabf56"><a href="gists/f82dcb34a431e8fabf56.html">Clojure Homework</a><br><small class="date"><b>Created:</b> September 13, 2014</small></li>
<li class="gist-entry" id="gist-0bc61ef9827232605b55"><a href="gists/0bc61ef9827232605b55.html">Testing a Ruby Gem</a><br><small class="date"><b>Created:</b> September 10, 2014</small></li>
<li class="gist-entry" id="gist-145efaf22f17d8a5cc73"><a href="gists/145efaf22f17d8a5cc73.html">EC2 Roles applied by InstanceProfiles.md</a><br><small class="date"><b>Created:</b> September 4, 2014</small></li>
<li class="gist-entry" id="gist-4646ab0381d45402bfdd"><a href="gists/4646ab0381d45402bfdd.html">Create JSON from Yaml</a><br><small class="date"><b>Created:</b> September 1, 2014</small></li>
<li class="gist-entry" id="gist-cbbbb95b571bd08bb5aa"><a href="gists/cbbbb95b571bd08bb5aa.html">Homebrew: switch to custom versions of software </a><br><small class="date"><b>Created:</b> August 29, 2014</small><small class="date"><b>Tags:</b> #homebrew #brew #install #versions #switch</small></li>
<li class="gist-entry" id="gist-c7277cbacd53487b3bb0"><a href="gists/c7277cbacd53487b3bb0.html">Software Simplicity</a><br><small class="date"><b>Created:</b> August 23, 2014</small></li>
<li class="gist-entry" id="gist-a9b12a7a3db9f9ca11ba"><a href="gists/a9b12a7a3db9f9ca11ba.html">Ruby string formatting functionality (like PHP's sprintf)</a><br><small class="date"><b>Created:</b> August 22, 2014</small></li>
<li class="gist-entry" id="gist-43b6da80a91827671e55"><a href="gists/43b6da80a91827671e55.html">Process for rebasing Pull Request</a><br><small class="date"><b>Created:</b> August 19, 2014</small></li>
<li class="gist-entry" id="gist-971b4192aa5c8ef7bae4"><a href="gists/971b4192aa5c8ef7bae4.html">Download and Install htop command</a><br><small class="date"><b>Created:</b> August 13, 2014</small></li>
<li class="gist-entry" id="gist-f7fa2a2f3794787909f5"><a href="gists/f7fa2a2f3794787909f5.html">Ruby: Command Design Pattern (can allow for "undo" history feature)</a><br><small class="date"><b>Created:</b> August 8, 2014</small></li>
<li class="gist-entry" id="gist-58220f584782964aa2ca"><a href="gists/58220f584782964aa2ca.html">Ruby: use Struct for inheritance chain</a><br><small class="date"><b>Created:</b> August 8, 2014</small></li>
<li class="gist-entry" id="gist-438898d6164daebec0c9"><a href="gists/438898d6164daebec0c9.html">AWS EC2 SSH Access and creating new AMI</a><br><small class="date"><b>Created:</b> August 4, 2014</small></li>
<li class="gist-entry" id="gist-1ac9e20330fd14db2390"><a href="gists/1ac9e20330fd14db2390.html">AWS Instance types</a><br><small class="date"><b>Created:</b> August 4, 2014</small></li>
<li class="gist-entry" id="gist-427746222345cfe81a24"><a href="gists/427746222345cfe81a24.html">Using git bisect to find where a bug was introduced</a><br><small class="date"><b>Created:</b> July 25, 2014</small></li>
<li class="gist-entry" id="gist-a2c2fcdf565047910126"><a href="gists/a2c2fcdf565047910126.html">Monads in JavaScript and the power of composability</a><br><small class="date"><b>Created:</b> July 21, 2014</small></li>
<li class="gist-entry" id="gist-13d9f5e8ec197e5e53c6"><a href="gists/13d9f5e8ec197e5e53c6.html">Get a git diff and apply git diff using gist ruby gem -> https://github.com/defunkt/gist (also see this alternative using `git format-patch`: https://gist.github.com/Integralist/87852ced09d7918322c0)</a><br><small class="date"><b>Created:</b> July 16, 2014</small></li>
<li class="gist-entry" id="gist-3e9c2ab8c1733c71a00c"><a href="gists/3e9c2ab8c1733c71a00c.html">Recursion and Trampolines in JavaScript (code copied from JS Drip Newsletter </a><br><small class="date"><b>Created:</b> July 14, 2014</small><small class="date"><b>Tags:</b> #65)</small></li>
<li class="gist-entry" id="gist-99577f14fb01101123bb"><a href="gists/99577f14fb01101123bb.html">Mori.js Calendar Application (NodeJS) -> copied from the talk http://vimeo.com/96425437</a><br><small class="date"><b>Created:</b> July 11, 2014</small></li>
<li class="gist-entry" id="gist-e8b0adc5bb96a4162aea"><a href="gists/e8b0adc5bb96a4162aea.html">Mori.js ClojureScript Data Structures in plain vanilla JavaScript -> http://swannodette.github.io/mori/ and https://github.com/swannodette/mori</a><br><small class="date"><b>Created:</b> July 11, 2014</small></li>
<li class="gist-entry" id="gist-3b6b69e1bafb30b81890"><a href="gists/3b6b69e1bafb30b81890.html">Data Structures</a><br><small class="date"><b>Created:</b> July 10, 2014</small></li>
<li class="gist-entry" id="gist-30a2c7351c028a0dda32"><a href="gists/30a2c7351c028a0dda32.html">Polling example with back pressure handling</a><br><small class="date"><b>Created:</b> July 8, 2014</small></li>
<li class="gist-entry" id="gist-a96cf6d6f01d5d0cce0a"><a href="gists/a96cf6d6f01d5d0cce0a.html">Ruby OOP vs FP (examples are from ThoughtBot's Weekly Iteration -> you should subscribe!)</a><br><small class="date"><b>Created:</b> July 7, 2014</small></li>
<li class="gist-entry" id="gist-ffe7f134a2ed1ecb62c7"><a href="gists/ffe7f134a2ed1ecb62c7.html">Auto Currying JavaScript Function</a><br><small class="date"><b>Created:</b> June 27, 2014</small></li>
<li class="gist-entry" id="gist-d84d65c909eeafe4dfca"><a href="gists/d84d65c909eeafe4dfca.html">Functional Programming: Polling XHR</a><br><small class="date"><b>Created:</b> June 23, 2014</small></li>
<li class="gist-entry" id="gist-e239380bb4e4c5b50280"><a href="gists/e239380bb4e4c5b50280.html">RoboHydra</a><br><small class="date"><b>Created:</b> June 23, 2014</small></li>
<li class="gist-entry" id="gist-fe4221f6207471b614ce"><a href="gists/fe4221f6207471b614ce.html">[Example of using cat to pass HEREDOC content into a file] </a><br><small class="date"><b>Created:</b> June 11, 2014</small><small class="date"><b>Tags:</b> #bash #heredoc #file</small></li>
<li class="gist-entry" id="gist-054e34983e8680c506c3"><a href="gists/054e34983e8680c506c3.html">Currying vs Partial Application</a><br><small class="date"><b>Created:</b> June 7, 2014</small></li>
<li class="gist-entry" id="gist-2cf1079f564a430d1313"><a href="gists/2cf1079f564a430d1313.html">Best way to modular Grunt tasks</a><br><small class="date"><b>Created:</b> June 4, 2014</small></li>
<li class="gist-entry" id="gist-57ebb1ddc040ea813b64"><a href="gists/57ebb1ddc040ea813b64.html">Run Sass within Ruby</a><br><small class="date"><b>Created:</b> June 4, 2014</small></li>
<li class="gist-entry" id="gist-b79b7a7706cc150b457c"><a href="gists/b79b7a7706cc150b457c.html">Ruby: pass a block to a function that has zero arity (i.e. don't define &block inside of our initialize method). The point of this demonstration is that you are able to pass a block through to another method whilst not initially defining an argument for the block to be passed by. This way we gain better performance (calling a proc is very slow compared to yielding), and regardless we're not able to pass a yield through to another method.</a><br><small class="date"><b>Created:</b> May 26, 2014</small></li>
<li class="gist-entry" id="gist-b7ed2e337a0b5cbbecce"><a href="gists/b7ed2e337a0b5cbbecce.html">JavaScript Function Programming (scratch pad) -> Most of the code here is modified from the excellent O'Reilly book "Functional JavaScript".</a><br><small class="date"><b>Created:</b> May 18, 2014</small></li>
<li class="gist-entry" id="gist-a29212a8eb10bc8154b7"><a href="gists/a29212a8eb10bc8154b7.html">Ruby Meta Programming</a><br><small class="date"><b>Created:</b> May 15, 2014</small></li>
<li class="gist-entry" id="gist-9bdbb99b83bd1613f062"><a href="gists/9bdbb99b83bd1613f062.html">Why does this fail in MRI 2.0 but pass in JRuby (which is API compat with MRI 1.9.3)?</a><br><small class="date"><b>Created:</b> May 15, 2014</small></li>
<li class="gist-entry" id="gist-a0faa55488af1b4b358e"><a href="gists/a0faa55488af1b4b358e.html">Pro Vim `.zshrc` configuration file</a><br><small class="date"><b>Created:</b> May 13, 2014</small></li>
<li class="gist-entry" id="gist-ac3eb133663d20a9fce1"><a href="gists/ac3eb133663d20a9fce1.html">Ruby Array Guarding</a><br><small class="date"><b>Created:</b> May 9, 2014</small></li>
<li class="gist-entry" id="gist-67360cd42b64329e7448"><a href="gists/67360cd42b64329e7448.html">Ruby's "Around Alias" pattern</a><br><small class="date"><b>Created:</b> May 9, 2014</small></li>
<li class="gist-entry" id="gist-11471364"><a href="gists/11471364.html">Expanding scratch pad of Clojure code</a><br><small class="date"><b>Created:</b> May 2, 2014</small></li>
<li class="gist-entry" id="gist-11394651"><a href="gists/11394651.html">Clojure's "Thread First" and "Thread Last" macros</a><br><small class="date"><b>Created:</b> April 29, 2014</small></li>
<li class="gist-entry" id="gist-11376734"><a href="gists/11376734.html">Clojure destructuring using `let` (which allows local storage inside of a function, we would say a local "variable" but that would be misleading because all data is immutable in Clojure)</a><br><small class="date"><b>Created:</b> April 28, 2014</small></li>
<li class="gist-entry" id="gist-11282503"><a href="gists/11282503.html">Loop recursively through a multi-level array using the SPL (Standard PHP Library) RecursiveArrayIterator</a><br><small class="date"><b>Created:</b> April 25, 2014</small></li>
<li class="gist-entry" id="gist-11246383"><a href="gists/11246383.html">JS Tail Call Optimisation</a><br><small class="date"><b>Created:</b> April 24, 2014</small></li>
<li class="gist-entry" id="gist-11207262"><a href="gists/11207262.html">Ruby Splat (single and double)</a><br><small class="date"><b>Created:</b> April 23, 2014</small></li>
<li class="gist-entry" id="gist-11206577"><a href="gists/11206577.html">Ruby: Symbol class to_proc and custom class object to_proc (see also https://gist.github.com/Integralist/8079e79c5eb4e7b88183 to see how to use `&` with `method()`)</a><br><small class="date"><b>Created:</b> April 23, 2014</small></li>
<li class="gist-entry" id="gist-11206399"><a href="gists/11206399.html">Ruby Data Structures: Set</a><br><small class="date"><b>Created:</b> April 23, 2014</small></li>
<li class="gist-entry" id="gist-11206349"><a href="gists/11206349.html">Ruby Data Structures: Queue</a><br><small class="date"><b>Created:</b> April 23, 2014</small></li>
<li class="gist-entry" id="gist-10357392"><a href="gists/10357392.html">Public-key infrastructure (PKI)</a><br><small class="date"><b>Created:</b> April 10, 2014</small></li>
<li class="gist-entry" id="gist-10135411"><a href="gists/10135411.html">Custom Ruby Error Handling</a><br><small class="date"><b>Created:</b> April 8, 2014</small></li>
<li class="gist-entry" id="gist-10008871"><a href="gists/10008871.html">For up to date list of plugins please see my Fresh Install repository: https://github.com/Integralist/Fresh-Install/</a><br><small class="date"><b>Created:</b> April 6, 2014</small></li>
<li class="gist-entry" id="gist-9994331"><a href="gists/9994331.html">Ruby lambdas</a><br><small class="date"><b>Created:</b> April 5, 2014</small></li>
<li class="gist-entry" id="gist-9910271"><a href="gists/9910271.html">Refactoring Ruby -> not all conditionals can be removed, and those that can can't necessarily use the standard refactoring methods such as "Replace Type Code with Module Extension", "Replace Type Code with Polymorphism" or "Replace Type Code with State/Strategy". The below examples demonstrate this.</a><br><small class="date"><b>Created:</b> April 1, 2014</small></li>
<li class="gist-entry" id="gist-9893111"><a href="gists/9893111.html">Messing around with AWS and DynamoDB</a><br><small class="date"><b>Created:</b> March 31, 2014</small></li>
<li class="gist-entry" id="gist-9888759"><a href="gists/9888759.html">git reset --soft/--mixed/--hard</a><br><small class="date"><b>Created:</b> March 31, 2014</small></li>
<li class="gist-entry" id="gist-9887248"><a href="gists/9887248.html">AOP (Aspect-Oriented Programming)</a><br><small class="date"><b>Created:</b> March 31, 2014</small></li>
<li class="gist-entry" id="gist-9791615"><a href="gists/9791615.html">Ruby: reducing context</a><br><small class="date"><b>Created:</b> March 26, 2014</small></li>
<li class="gist-entry" id="gist-9780188"><a href="gists/9780188.html">Object-Oriented Design Principles (Code Design)</a><br><small class="date"><b>Created:</b> March 26, 2014</small></li>
<li class="gist-entry" id="gist-9779256"><a href="gists/9779256.html">Concurrency vs Parallelism</a><br><small class="date"><b>Created:</b> March 26, 2014</small></li>
<li class="gist-entry" id="gist-9544962"><a href="gists/9544962.html">Polymorphism using `if` condition in JavaScript</a><br><small class="date"><b>Created:</b> March 14, 2014</small></li>
<li class="gist-entry" id="gist-9503099"><a href="gists/9503099.html">Convert Ruby Hash keys into symbols </a><br><small class="date"><b>Created:</b> March 12, 2014</small></li>
<li class="gist-entry" id="gist-9482527"><a href="gists/9482527.html">S.O.L.I.D principles in Ruby</a><br><small class="date"><b>Created:</b> March 11, 2014</small></li>
<li class="gist-entry" id="gist-9346221"><a href="gists/9346221.html">[Example of POST'ing data via Curl command] </a><br><small class="date"><b>Created:</b> March 4, 2014</small><small class="date"><b>Tags:</b> #curl #post #body</small></li>
<li class="gist-entry" id="gist-9251386"><a href="gists/9251386.html">Passing through key and value to a reduce method block rather than just the item</a><br><small class="date"><b>Created:</b> February 27, 2014</small></li>
<li class="gist-entry" id="gist-9251201"><a href="gists/9251201.html">In Ruby using the `<<` operator as a method identifier has special meaning. It allows us to call the method without using a period (so we can do `foo << "abc"` and not have to do `foo.<< "abc"`)</a><br><small class="date"><b>Created:</b> February 27, 2014</small></li>
<li class="gist-entry" id="gist-9041051"><a href="gists/9041051.html">How to clone a Hash (in Ruby) and modify the cloned hash without affecting the original object</a><br><small class="date"><b>Created:</b> February 16, 2014</small></li>
<li class="gist-entry" id="gist-9001836"><a href="gists/9001836.html">Demonstrate how to handle bubbling errors by consolidating them (modified from: http://blog.ponyfoo.com/2013/07/12/teach-yourself-nodejs-in-10-steps)</a><br><small class="date"><b>Created:</b> February 14, 2014</small></li>
<li class="gist-entry" id="gist-9001300"><a href="gists/9001300.html">Web Scraping with NodeJS (copied from http://www.storminthecastle.com/2013/08/25/use-node-js-to-extract-data-from-the-web-for-fun-and-profit/)</a><br><small class="date"><b>Created:</b> February 14, 2014</small></li>
<li class="gist-entry" id="gist-8999306"><a href="gists/8999306.html">Variety of different Capybara configurations, tips and tricks</a><br><small class="date"><b>Created:</b> February 14, 2014</small></li>
<li class="gist-entry" id="gist-8954316"><a href="gists/8954316.html">Ruby HEREDOC but not worrying about the crappy spacing</a><br><small class="date"><b>Created:</b> February 12, 2014</small></li>
<li class="gist-entry" id="gist-8685823"><a href="gists/8685823.html">npm in-house registry cache using nginx</a><br><small class="date"><b>Created:</b> January 29, 2014</small></li>
<li class="gist-entry" id="gist-8566704"><a href="gists/8566704.html">Looking at the Thread API in Ruby</a><br><small class="date"><b>Created:</b> January 22, 2014</small></li>
<li class="gist-entry" id="gist-8560960"><a href="gists/8560960.html">Refactor this Ruby code...</a><br><small class="date"><b>Created:</b> January 22, 2014</small></li>
<li class="gist-entry" id="gist-8433187"><a href="gists/8433187.html">Example of importing Java libraries into JRuby</a><br><small class="date"><b>Created:</b> January 15, 2014</small></li>
<li class="gist-entry" id="gist-8419151"><a href="gists/8419151.html">Private and Privileged methods using the Constructor pattern in JavaScript</a><br><small class="date"><b>Created:</b> January 14, 2014</small></li>
<li class="gist-entry" id="gist-8400550"><a href="gists/8400550.html">Better Mocking using RequireJS' `undef` method to unset redefined modules</a><br><small class="date"><b>Created:</b> January 13, 2014</small></li>
<li class="gist-entry" id="gist-8341704"><a href="gists/8341704.html">Rack Server Example</a><br><small class="date"><b>Created:</b> January 9, 2014</small></li>
<li class="gist-entry" id="gist-8115457"><a href="gists/8115457.html">Shortcut Vim mappings for running RSpec and Cucumber tests</a><br><small class="date"><b>Created:</b> December 24, 2013</small></li>
<li class="gist-entry" id="gist-8114940"><a href="gists/8114940.html">Trying to run RSpec and Cucumber tests via Vim but found executing commands in different contexts means scope changes between what's available in the $PATH to the installed Ruby version and it's available gemsets.</a><br><small class="date"><b>Created:</b> December 24, 2013</small></li>
<li class="gist-entry" id="gist-8098172"><a href="gists/8098172.html">Playing around with http://gulpjs.com/</a><br><small class="date"><b>Created:</b> December 23, 2013</small></li>
<li class="gist-entry" id="gist-8057721"><a href="gists/8057721.html">2013 review: looking back at what I achieved this year...</a><br><small class="date"><b>Created:</b> December 20, 2013</small></li>
<li class="gist-entry" id="gist-8035585"><a href="gists/8035585.html">Is there a more elegant way in Ruby to filter data from an object and store it in another object. We're searching for a key (which can appear multiple times) and I only want to store the key once, but to also increment that key's value every time the key is found.</a><br><small class="date"><b>Created:</b> December 19, 2013</small></li>
<li class="gist-entry" id="gist-8002000"><a href="gists/8002000.html">Mocking the `window` object in JavaScript unit tests</a><br><small class="date"><b>Created:</b> December 17, 2013</small></li>
<li class="gist-entry" id="gist-7978893"><a href="gists/7978893.html">RSpec Template</a><br><small class="date"><b>Created:</b> December 15, 2013</small></li>
<li class="gist-entry" id="gist-7974887"><a href="gists/7974887.html">S.O.L.I.D principles</a><br><small class="date"><b>Created:</b> December 15, 2013</small></li>
<li class="gist-entry" id="gist-7944948"><a href="gists/7944948.html">Sandi Metz advice for writing tests</a><br><small class="date"><b>Created:</b> December 13, 2013</small></li>
<li class="gist-entry" id="gist-7927745"><a href="gists/7927745.html">JavaScript: mocking the Window and Document objects</a><br><small class="date"><b>Created:</b> December 12, 2013</small></li>
<li class="gist-entry" id="gist-7910295"><a href="gists/7910295.html">Node debugger API</a><br><small class="date"><b>Created:</b> December 11, 2013</small></li>
<li class="gist-entry" id="gist-7750250"><a href="gists/7750250.html">[Cucumber Gherkin Template Feature File] </a><br><small class="date"><b>Created:</b> December 2, 2013</small><small class="date"><b>Tags:</b> #gherkin #cucumber #userstory #story #feature #scenario</small></li>
<li class="gist-entry" id="gist-7702823"><a href="gists/7702823.html">The importance of refactoring...</a><br><small class="date"><b>Created:</b> November 29, 2013</small></li>
<li class="gist-entry" id="gist-7694814"><a href="gists/7694814.html">[The distinction between "arguments" and "parameters"] </a><br><small class="date"><b>Created:</b> November 28, 2013</small><small class="date"><b>Tags:</b> #args #params #vs</small></li>
<li class="gist-entry" id="gist-7605146"><a href="gists/7605146.html">Sass REM</a><br><small class="date"><b>Created:</b> November 22, 2013</small></li>
<li class="gist-entry" id="gist-7604932"><a href="gists/7604932.html">Clamps a block of text to a certain number of lines followed by an ellipsis in Webkit and Blink based browsers</a><br><small class="date"><b>Created:</b> November 22, 2013</small></li>
<li class="gist-entry" id="gist-7560051"><a href="gists/7560051.html">Complex Sass example found in the wild...</a><br><small class="date"><b>Created:</b> November 20, 2013</small></li>
<li class="gist-entry" id="gist-7464000"><a href="gists/7464000.html">Example of how to structure your Grunt files</a><br><small class="date"><b>Created:</b> November 14, 2013</small></li>
<li class="gist-entry" id="gist-7463783"><a href="gists/7463783.html">How to extract JSHint details into its own config file</a><br><small class="date"><b>Created:</b> November 14, 2013</small></li>
<li class="gist-entry" id="gist-7378674"><a href="gists/7378674.html">JavaScript grid overlay</a><br><small class="date"><b>Created:</b> November 8, 2013</small></li>
<li class="gist-entry" id="gist-7352055"><a href="gists/7352055.html">JavaScript: function to determine object's type</a><br><small class="date"><b>Created:</b> November 7, 2013</small></li>
<li class="gist-entry" id="gist-7269907"><a href="gists/7269907.html">BBC News' RTL (right to left) solution</a><br><small class="date"><b>Created:</b> November 1, 2013</small></li>
<li class="gist-entry" id="gist-7264753"><a href="gists/7264753.html">How should we handle sub elements within an existing element? Should it be converted into a block?</a><br><small class="date"><b>Created:</b> November 1, 2013</small></li>
<li class="gist-entry" id="gist-7100367"><a href="gists/7100367.html">CabinJS static generator example</a><br><small class="date"><b>Created:</b> October 22, 2013</small></li>
<li class="gist-entry" id="gist-6711354"><a href="gists/6711354.html">PhantomJS network tests</a><br><small class="date"><b>Created:</b> September 26, 2013</small></li>
<li class="gist-entry" id="gist-6573026"><a href="gists/6573026.html">MongoDB: when using the `find()` method on a Collection you'll need to `toArray()` on results as it doesn't run your query but instead returns new Cursor instance</a><br><small class="date"><b>Created:</b> September 15, 2013</small></li>
<li class="gist-entry" id="gist-6571371"><a href="gists/6571371.html">Thoughts re: UnCSS (a way to parse CSS files to see if all of the rules/selectors apply to a HTML page)</a><br><small class="date"><b>Created:</b> September 15, 2013</small></li>
<li class="gist-entry" id="gist-6229170"><a href="gists/6229170.html">Imager.js (as of 14th August 2013)</a><br><small class="date"><b>Created:</b> August 14, 2013</small></li>
<li class="gist-entry" id="gist-6222299"><a href="gists/6222299.html">Sass mixin that handles span'ing content based off of a 12 column grid (could be updated to accept dynamic content)</a><br><small class="date"><b>Created:</b> August 13, 2013</small></li>
<li class="gist-entry" id="gist-6157139"><a href="gists/6157139.html">This is how BBC News currently implements it's Image Enhancer for responsive images. Note: this is a completely rebuilt version of the code so the BBC's original source code doesn't actually look anything like the below example.</a><br><small class="date"><b>Created:</b> August 5, 2013</small></li>
<li class="gist-entry" id="gist-6105162"><a href="gists/6105162.html">Firefox chokes on this code without the `setTimeout`...</a><br><small class="date"><b>Created:</b> July 29, 2013</small></li>
<li class="gist-entry" id="gist-6088405"><a href="gists/6088405.html">Is this good flow control? Or would Promises (or Generators) make this much simpler and easier to read? I write my code in such a way that I try to be as 'functional' as possible, and that the code reads in a linear fashion (as if telling a story, there is a start, middle and an end).</a><br><small class="date"><b>Created:</b> July 26, 2013</small></li>
<li class="gist-entry" id="gist-5985455"><a href="gists/5985455.html">Strategy pattern to remove the need for conditionals. If you find yourself writing conditionals then that's really just an object waiting to be made. Yes there are more lines of code, but this enforces the 'open/closed principle' which means the code is open for extension but closed for modification and means our code can scale a lot more easily than the conditional style.</a><br><small class="date"><b>Created:</b> July 12, 2013</small></li>
<li class="gist-entry" id="gist-5896921"><a href="gists/5896921.html">The power of r.js is incredible. `insertRequire` and `onBuildRead` are insanely useful in the right situation (not to mention other useful features such as `fileExclusionRegExp`, `removeCombined` and literally a ton more)...</a><br><small class="date"><b>Created:</b> June 30, 2013</small></li>
<li class="gist-entry" id="gist-5798071"><a href="gists/5798071.html">Example of how Sass mixins when used excessively and without thought can actually be more of a code smell than a helper.</a><br><small class="date"><b>Created:</b> June 17, 2013</small></li>
<li class="gist-entry" id="gist-5774273"><a href="gists/5774273.html">Over engineered Sass...</a><br><small class="date"><b>Created:</b> June 13, 2013</small></li>
<li class="gist-entry" id="gist-5772010"><a href="gists/5772010.html">Mocking a Window object for unit-testing purposes</a><br><small class="date"><b>Created:</b> June 13, 2013</small></li>
<li class="gist-entry" id="gist-5763792"><a href="gists/5763792.html">S.O.L.I.D - (L)iskov Substitution. </a><br><small class="date"><b>Created:</b> June 12, 2013</small></li>
<li class="gist-entry" id="gist-5763515"><a href="gists/5763515.html">S.O.L.I.D - (D)ependency Inversion. In the bad example, yes we're injecting our dependency but the Button class is now no longer reusable as it is too tightly coupled to the Lamp class. In the better example, we're still injecting our dependency but we now inverse the control via the use of an Interface. So now any `SwitchableDevice` can be used with the Button class.</a><br><small class="date"><b>Created:</b> June 12, 2013</small></li>
<li class="gist-entry" id="gist-5759057"><a href="gists/5759057.html">Avoid direct access to complex data structures, transform them to avoid problems when the structure changes</a><br><small class="date"><b>Created:</b> June 11, 2013</small></li>
<li class="gist-entry" id="gist-5755677"><a href="gists/5755677.html">Need help watching/compiling multiple Sass files in a project with a awkward folder structure...</a><br><small class="date"><b>Created:</b> June 11, 2013</small></li>
<li class="gist-entry" id="gist-5755078"><a href="gists/5755078.html">S.O.L.I.D - (O)pen/Closed Principle</a><br><small class="date"><b>Created:</b> June 11, 2013</small></li>
<li class="gist-entry" id="gist-5755008"><a href="gists/5755008.html">S.O.L.I.D - (S)ingle Responsibility Principle</a><br><small class="date"><b>Created:</b> June 11, 2013</small></li>
<li class="gist-entry" id="gist-5736427"><a href="gists/5736427.html">Strategy Design Pattern in JavaScript</a><br><small class="date"><b>Created:</b> June 8, 2013</small></li>
<li class="gist-entry" id="gist-5575743"><a href="gists/5575743.html">Example of a r.js build script for AMD formatted modules loaded using RequireJS</a><br><small class="date"><b>Created:</b> May 14, 2013</small></li>
<li class="gist-entry" id="gist-5541500"><a href="gists/5541500.html">There are a couple of different ways to `require` a module using RequireJS</a><br><small class="date"><b>Created:</b> May 8, 2013</small></li>
<li class="gist-entry" id="gist-5458681"><a href="gists/5458681.html">Using RequireJS, switch from jQuery 2.0 down to 1.9.1</a><br><small class="date"><b>Created:</b> April 25, 2013</small></li>
<li class="gist-entry" id="gist-5442770"><a href="gists/5442770.html">Ruby 1.8.7 doesn't support regular expression lookbehind assertions -> so this example mimicks it using lookaheads and some trickery. Basically the solution is to reverse your content and lookahead for the items you want to avoid or include.</a><br><small class="date"><b>Created:</b> April 23, 2013</small></li>
<li class="gist-entry" id="gist-5433330"><a href="gists/5433330.html">PHP Reflection Example</a><br><small class="date"><b>Created:</b> April 22, 2013</small></li>
<li class="gist-entry" id="gist-5433171"><a href="gists/5433171.html">CSS touch delay</a><br><small class="date"><b>Created:</b> April 22, 2013</small></li>
<li class="gist-entry" id="gist-5396881"><a href="gists/5396881.html">PubSub in JavaScript</a><br><small class="date"><b>Created:</b> April 16, 2013</small></li>
<li class="gist-entry" id="gist-5361793"><a href="gists/5361793.html">[Sass: avoiding @if conditionals] </a><br><small class="date"><b>Created:</b> April 11, 2013</small><small class="date"><b>Tags:</b> #sass #if #conditions</small></li>
<li class="gist-entry" id="gist-5355802"><a href="gists/5355802.html">[Sass: right-to-left CSS] </a><br><small class="date"><b>Created:</b> April 10, 2013</small><small class="date"><b>Tags:</b> #sass #css #rtl</small></li>
<li class="gist-entry" id="gist-5244199"><a href="gists/5244199.html">Basic Closure example in PHP</a><br><small class="date"><b>Created:</b> March 26, 2013</small></li>
<li class="gist-entry" id="gist-5235882"><a href="gists/5235882.html">The responsive GEL grid system</a><br><small class="date"><b>Created:</b> March 25, 2013</small></li>
<li class="gist-entry" id="gist-5206872"><a href="gists/5206872.html">Basic script loader example that works for all browsers</a><br><small class="date"><b>Created:</b> March 20, 2013</small></li>
<li class="gist-entry" id="gist-5194807"><a href="gists/5194807.html">A few (of the many) different ways to create a Singleton in JavaScript. Be warned some of these examples require a lot more code to make them true Singletons. As is the case with most problems: simplicity is the key.</a><br><small class="date"><b>Created:</b> March 19, 2013</small></li>
<li class="gist-entry" id="gist-5145242"><a href="gists/5145242.html">Boilerplate for AMD, Node and browser global</a><br><small class="date"><b>Created:</b> March 12, 2013</small></li>
<li class="gist-entry" id="gist-5134943"><a href="gists/5134943.html">The difference between JavaScript's `exec` and `match` methods is subtle but important, and I always forget...</a><br><small class="date"><b>Created:</b> March 11, 2013</small></li>
<li class="gist-entry" id="gist-5109219"><a href="gists/5109219.html">Add properties to PHP object dynamically</a><br><small class="date"><b>Created:</b> March 7, 2013</small></li>
<li class="gist-entry" id="gist-5098437"><a href="gists/5098437.html">Comments on Analytics code...</a><br><small class="date"><b>Created:</b> March 6, 2013</small></li>
<li class="gist-entry" id="gist-5094034"><a href="gists/5094034.html">Example of prototypal inheritance but done in a 'classical inheritance' style...</a><br><small class="date"><b>Created:</b> March 5, 2013</small></li>
<li class="gist-entry" id="gist-5078336"><a href="gists/5078336.html">Example code using RubyInline which lets you run foreign code (such as C or C++) within Ruby which has much greater performance over Ruby itself.</a><br><small class="date"><b>Created:</b> March 3, 2013</small></li>
<li class="gist-entry" id="gist-5073030"><a href="gists/5073030.html">The difference between `prototype` and `__proto__`</a><br><small class="date"><b>Created:</b> March 2, 2013</small></li>
<li class="gist-entry" id="gist-4966463"><a href="gists/4966463.html">Was reading http://jspro.com/raw-javascript/intelligent-string-abbreviation/ and decided to try and clean up the example.

I then made another version which separated specific functionality into individual functions.

Finally I made a third variation which made dependencies external.</a><br><small class="date"><b>Created:</b> February 16, 2013</small></li>
<li class="gist-entry" id="gist-4960210"><a href="gists/4960210.html">In CSS/BEM: how do we name a sub-block that is related to its parent block?</a><br><small class="date"><b>Created:</b> February 15, 2013</small></li>
<li class="gist-entry" id="gist-4713288"><a href="gists/4713288.html">Made a super quick bookmarklet for displaying the current screen dimensions for Chrome</a><br><small class="date"><b>Created:</b> February 5, 2013</small></li>
<li class="gist-entry" id="gist-4642970"><a href="gists/4642970.html">I'm trying to get the cleanest, most basic export from r.js</a><br><small class="date"><b>Created:</b> January 26, 2013</small></li>
<li class="gist-entry" id="gist-4327823"><a href="gists/4327823.html">Refreshing my memory on PHP inheritance and general OOP</a><br><small class="date"><b>Created:</b> December 18, 2012</small></li>
<li class="gist-entry" id="gist-4319778"><a href="gists/4319778.html">The last time I wrote any real PHP (of any production worth) was back in 2006 (it's now December 2012). I thought I would share some potentially terrible PHP code I wrote today whilst trying to refresh my memory. Definitely feel free to have a good laugh, but what would be even better would be some constructive criticism. This isn't supposed to be anything remotely near finished code. The purpose was to get me back into the feel for writing PHP. If there are suggestions about what I've written (things I should avoid for example) then I'd love to hear them. Thanks!</a><br><small class="date"><b>Created:</b> December 17, 2012</small></li>
<li class="gist-entry" id="gist-4117173"><a href="gists/4117173.html">Ensure two columns match heights (rather than tweaking CSS for multiple browser's rendering differences)</a><br><small class="date"><b>Created:</b> November 20, 2012</small></li>
<li class="gist-entry" id="gist-4116778"><a href="gists/4116778.html">The Checkbox CSS Hack (doesn't work in IE <= 8, but all other browsers fine)</a><br><small class="date"><b>Created:</b> November 20, 2012</small></li>
<li class="gist-entry" id="gist-3947056"><a href="gists/3947056.html">Doesn't work: preload images so we can check when background images are loaded via CSS</a><br><small class="date"><b>Created:</b> October 24, 2012</small></li>
<li class="gist-entry" id="gist-3938408"><a href="gists/3938408.html">Detect CSS Animation support and provide object of normalised properties</a><br><small class="date"><b>Created:</b> October 23, 2012</small></li>
<li class="gist-entry" id="gist-3931680"><a href="gists/3931680.html">Sass Mixin for CSS3 Animations</a><br><small class="date"><b>Created:</b> October 22, 2012</small></li>
<li class="gist-entry" id="gist-3926924"><a href="gists/3926924.html">Data warehouse module</a><br><small class="date"><b>Created:</b> October 21, 2012</small></li>
<li class="gist-entry" id="gist-3918798"><a href="gists/3918798.html">Backbone example</a><br><small class="date"><b>Created:</b> October 19, 2012</small></li>
<li class="gist-entry" id="gist-3912086"><a href="gists/3912086.html">Example of passing a code block to a Mixin to make it more flexible (especially for displaying retina content)</a><br><small class="date"><b>Created:</b> October 18, 2012</small></li>
<li class="gist-entry" id="gist-3898612"><a href="gists/3898612.html">Updated truncation script/module</a><br><small class="date"><b>Created:</b> October 16, 2012</small></li>
<li class="gist-entry" id="gist-3807247"><a href="gists/3807247.html">Basic Sass Grid</a><br><small class="date"><b>Created:</b> September 30, 2012</small></li>
<li class="gist-entry" id="gist-3788967"><a href="gists/3788967.html">My mammoth View file (this needs refactoring for sure - maybe into sub views?)</a><br><small class="date"><b>Created:</b> September 26, 2012</small></li>
<li class="gist-entry" id="gist-3761608"><a href="gists/3761608.html">The model only triggers the change event when the value being set is unique (i.e. not set before)</a><br><small class="date"><b>Created:</b> September 21, 2012</small></li>
<li class="gist-entry" id="gist-3743933"><a href="gists/3743933.html">Backbone.js example script (?)</a><br><small class="date"><b>Created:</b> September 18, 2012</small></li>
<li class="gist-entry" id="gist-3675078"><a href="gists/3675078.html">Toast Grid Code</a><br><small class="date"><b>Created:</b> September 8, 2012</small></li>
<li class="gist-entry" id="gist-3447189"><a href="gists/3447189.html">Basic Page Layout </a><br><small class="date"><b>Created:</b> August 24, 2012</small><small class="date"><b>Tags:</b> #basic #html</small></li>
<li class="gist-entry" id="gist-3414140"><a href="gists/3414140.html">Example font-face code</a><br><small class="date"><b>Created:</b> August 21, 2012</small></li>
<li class="gist-entry" id="gist-3226822"><a href="gists/3226822.html">Sass: referencing parent selector</a><br><small class="date"><b>Created:</b> August 1, 2012</small></li>
<li class="gist-entry" id="gist-3186740"><a href="gists/3186740.html">JavaScript pass by value/reference example</a><br><small class="date"><b>Created:</b> July 27, 2012</small></li>
<li class="gist-entry" id="gist-3169769"><a href="gists/3169769.html">I'm glad ES4 never happened. Couldn't imagine writing bullshit JavaScript like this ActionScript code...</a><br><small class="date"><b>Created:</b> July 24, 2012</small></li>
<li class="gist-entry" id="gist-3046619"><a href="gists/3046619.html">WinXP IE8 doesn't work, but Win7 IE8 Browser/Document Mode does work?</a><br><small class="date"><b>Created:</b> July 4, 2012</small></li>
<li class="gist-entry" id="gist-3004787"><a href="gists/3004787.html">Chunky script</a><br><small class="date"><b>Created:</b> June 27, 2012</small></li>
<li class="gist-entry" id="gist-2996941"><a href="gists/2996941.html">How to access a specific :after pseudo-element's styles via JavaScript</a><br><small class="date"><b>Created:</b> June 26, 2012</small></li>
<li class="gist-entry" id="gist-2994844"><a href="gists/2994844.html">How to target close button</a><br><small class="date"><b>Created:</b> June 26, 2012</small></li>
<li class="gist-entry" id="gist-2964977"><a href="gists/2964977.html">Mega Validation Form</a><br><small class="date"><b>Created:</b> June 21, 2012</small></li>
<li class="gist-entry" id="gist-2947867"><a href="gists/2947867.html">More ActionScript, how I hate dealing with Flash</a><br><small class="date"><b>Created:</b> June 18, 2012</small></li>
<li class="gist-entry" id="gist-2937109"><a href="gists/2937109.html">Animating image slides in ActionScript</a><br><small class="date"><b>Created:</b> June 15, 2012</small></li>
<li class="gist-entry" id="gist-2864041"><a href="gists/2864041.html">Create basic site using Ruby and Sinatra (and external templates)</a><br><small class="date"><b>Created:</b> June 3, 2012</small></li>
<li class="gist-entry" id="gist-2862917"><a href="gists/2862917.html">Create basic Web Server in Ruby (using WEBrick)</a><br><small class="date"><b>Created:</b> June 3, 2012</small></li>
<li class="gist-entry" id="gist-2782758"><a href="gists/2782758.html">Basic Form Validator</a><br><small class="date"><b>Created:</b> May 24, 2012</small></li>
<li class="gist-entry" id="gist-2700684"><a href="gists/2700684.html">Ordered Lists</a><br><small class="date"><b>Created:</b> May 15, 2012</small></li>
<li class="gist-entry" id="gist-2665277"><a href="gists/2665277.html">CSS alignment test</a><br><small class="date"><b>Created:</b> May 12, 2012</small></li>
<li class="gist-entry" id="gist-2651826"><a href="gists/2651826.html">Custom Scrollbars (WebKit only because no other browser has similar feature)</a><br><small class="date"><b>Created:</b> May 10, 2012</small></li>
<li class="gist-entry" id="gist-2510274"><a href="gists/2510274.html">HTML5 Placeholder Polyfill</a><br><small class="date"><b>Created:</b> April 27, 2012</small></li>
<li class="gist-entry" id="gist-2509586"><a href="gists/2509586.html">Recruitment Questions for front-end developer (modified from https://github.com/darcyclarke/Front-end-Developer-Interview-Questions)</a><br><small class="date"><b>Created:</b> April 27, 2012</small></li>
<li class="gist-entry" id="gist-2391459"><a href="gists/2391459.html">Relative Sizing</a><br><small class="date"><b>Created:</b> April 15, 2012</small></li>
<li class="gist-entry" id="gist-2385187"><a href="gists/2385187.html">[JS before AMD] </a><br><small class="date"><b>Created:</b> April 14, 2012</small><small class="date"><b>Tags:</b> #amd #lab #js #html</small></li>
<li class="gist-entry" id="gist-2214136"><a href="gists/2214136.html">Git Workflow using an organisation account with Private repositories</a><br><small class="date"><b>Created:</b> March 27, 2012</small></li>
<li class="gist-entry" id="gist-2035643"><a href="gists/2035643.html">Aspect Ratio Calculator</a><br><small class="date"><b>Created:</b> March 14, 2012</small></li>
<li class="gist-entry" id="gist-2030311"><a href="gists/2030311.html">Unit Testing with BusterJS</a><br><small class="date"><b>Created:</b> March 13, 2012</small></li>
<li class="gist-entry" id="gist-1973726"><a href="gists/1973726.html">Automatically generated images via JavaScript Canvas API</a><br><small class="date"><b>Created:</b> March 4, 2012</small></li>
<li class="gist-entry" id="gist-1973283"><a href="gists/1973283.html">Canvas example</a><br><small class="date"><b>Created:</b> March 4, 2012</small></li>
<li class="gist-entry" id="gist-1899675"><a href="gists/1899675.html">IE Box Model in other browsers </a><br><small class="date"><b>Created:</b> February 24, 2012</small><small class="date"><b>Tags:</b> #js</small></li>
<li class="gist-entry" id="gist-1875544"><a href="gists/1875544.html">set-up remote git repository </a><br><small class="date"><b>Created:</b> February 21, 2012</small><small class="date"><b>Tags:</b> #git</small></li>
<li class="gist-entry" id="gist-1834760"><a href="gists/1834760.html">Star ratings </a><br><small class="date"><b>Created:</b> February 15, 2012</small><small class="date"><b>Tags:</b> #css</small></li>
<li class="gist-entry" id="gist-1710256"><a href="gists/1710256.html">Google Maps with native HTML5 geolocation + audio </a><br><small class="date"><b>Created:</b> January 31, 2012</small><small class="date"><b>Tags:</b> #js</small></li>
<li class="gist-entry" id="gist-1663422"><a href="gists/1663422.html">Beware of setting 'require' as a dependancy </a><br><small class="date"><b>Created:</b> January 23, 2012</small><small class="date"><b>Tags:</b> #js</small></li>
<li class="gist-entry" id="gist-1625810"><a href="gists/1625810.html">Sinon.js Fake XHR </a><br><small class="date"><b>Created:</b> January 17, 2012</small><small class="date"><b>Tags:</b> #js</small></li>
<li class="gist-entry" id="gist-1599740"><a href="gists/1599740.html">Detect `onhashchange` support </a><br><small class="date"><b>Created:</b> January 12, 2012</small><small class="date"><b>Tags:</b> #js</small></li>
<li class="gist-entry" id="gist-1599546"><a href="gists/1599546.html">Error Handling with RequireJs </a><br><small class="date"><b>Created:</b> January 12, 2012</small><small class="date"><b>Tags:</b> #js</small></li>
<li class="gist-entry" id="gist-1593770"><a href="gists/1593770.html">Host Objects </a><br><small class="date"><b>Created:</b> January 11, 2012</small><small class="date"><b>Tags:</b> #js</small></li>
<li class="gist-entry" id="gist-1530417"><a href="gists/1530417.html">Element dimensions </a><br><small class="date"><b>Created:</b> December 28, 2011</small><small class="date"><b>Tags:</b> #js</small></li>
<li class="gist-entry" id="gist-1525419"><a href="gists/1525419.html">Execution context (Variable/Activation Object) from @kangax's </a><br><small class="date"><b>Created:</b> December 27, 2011</small><small class="date"><b>Tags:</b> #js</small></li>
<li class="gist-entry" id="gist-1525378"><a href="gists/1525378.html">Feature Testing a Host Method </a><br><small class="date"><b>Created:</b> December 27, 2011</small><small class="date"><b>Tags:</b> #js</small></li>
<li class="gist-entry" id="gist-1513947"><a href="gists/1513947.html">Calculate distance between two co-ordinates on a Map (Lat/Lng) </a><br><small class="date"><b>Created:</b> December 23, 2011</small><small class="date"><b>Tags:</b> #js</small></li>
<li class="gist-entry" id="gist-1446641"><a href="gists/1446641.html">How to use @testling </a><br><small class="date"><b>Created:</b> December 8, 2011</small><small class="date"><b>Tags:</b> #js</small></li>
<li class="gist-entry" id="gist-1442875"><a href="gists/1442875.html">browser cache prevents image onload event </a><br><small class="date"><b>Created:</b> December 7, 2011</small><small class="date"><b>Tags:</b> #js</small></li>
<li class="gist-entry" id="gist-1430271"><a href="gists/1430271.html">JSON-P </a><br><small class="date"><b>Created:</b> December 4, 2011</small><small class="date"><b>Tags:</b> #php</small></li>
<li class="gist-entry" id="gist-1393418"><a href="gists/1393418.html">Detect previousElementSibling/nextElementSibling </a><br><small class="date"><b>Created:</b> November 25, 2011</small><small class="date"><b>Tags:</b> #js</small></li>
<li class="gist-entry" id="gist-1393248"><a href="gists/1393248.html">News Ticker </a><br><small class="date"><b>Created:</b> November 25, 2011</small><small class="date"><b>Tags:</b> #js</small></li>
<li class="gist-entry" id="gist-1391785"><a href="gists/1391785.html">mixins > inheritance </a><br><small class="date"><b>Created:</b> November 24, 2011</small><small class="date"><b>Tags:</b> #js</small></li>
<li class="gist-entry" id="gist-1391440"><a href="gists/1391440.html">List of Twitter Bootstrap CSS classes </a><br><small class="date"><b>Created:</b> November 24, 2011</small><small class="date"><b>Tags:</b> #css</small></li>
<li class="gist-entry" id="gist-1370735"><a href="gists/1370735.html">JSONP Async Loading via RequireJs </a><br><small class="date"><b>Created:</b> November 16, 2011</small><small class="date"><b>Tags:</b> #js #php</small></li>
<li class="gist-entry" id="gist-1370134"><a href="gists/1370134.html">Examples of jsonp loading via RequireJs </a><br><small class="date"><b>Created:</b> November 16, 2011</small><small class="date"><b>Tags:</b> #js</small></li>
<li class="gist-entry" id="gist-1363964"><a href="gists/1363964.html">Attempt at polyfilling addEventListener in IE7 via .htc hack </a><br><small class="date"><b>Created:</b> November 14, 2011</small><small class="date"><b>Tags:</b> #js</small></li>
<li class="gist-entry" id="gist-1363933"><a href="gists/1363933.html">Curl Google Plugin Example </a><br><small class="date"><b>Created:</b> November 14, 2011</small><small class="date"><b>Tags:</b> #js</small></li>
<li class="gist-entry" id="gist-1357584"><a href="gists/1357584.html">Curl Example </a><br><small class="date"><b>Created:</b> November 11, 2011</small><small class="date"><b>Tags:</b> #js</small></li>
<li class="gist-entry" id="gist-1336327"><a href="gists/1336327.html">jQuery Mobile application event list </a><br><small class="date"><b>Created:</b> November 3, 2011</small><small class="date"><b>Tags:</b> #js</small></li>
<li class="gist-entry" id="gist-1336279"><a href="gists/1336279.html">cancel all jQuery AJAX requests </a><br><small class="date"><b>Created:</b> November 3, 2011</small><small class="date"><b>Tags:</b> #js</small></li>
<li class="gist-entry" id="gist-1303396"><a href="gists/1303396.html">jQuery Ajax Test (using Deferred/Promises) </a><br><small class="date"><b>Created:</b> October 21, 2011</small><small class="date"><b>Tags:</b> #js</small></li>
<li class="gist-entry" id="gist-1303355"><a href="gists/1303355.html">Analyze the viewport size </a><br><small class="date"><b>Created:</b> October 21, 2011</small><small class="date"><b>Tags:</b> #js</small></li>
<li class="gist-entry" id="gist-1258903"><a href="gists/1258903.html">RequireJs Build Script </a><br><small class="date"><b>Created:</b> October 3, 2011</small><small class="date"><b>Tags:</b> #js </small></li>
<li class="gist-entry" id="gist-1247263"><a href="gists/1247263.html">Create Elements using memoization technique (modified to @GarrettS' points) </a><br><small class="date"><b>Created:</b> September 28, 2011</small><small class="date"><b>Tags:</b> #js</small></li>
<li class="gist-entry" id="gist-1225181"><a href="gists/1225181.html">@madrobby's 140 bytes template engine </a><br><small class="date"><b>Created:</b> September 18, 2011</small><small class="date"><b>Tags:</b> #js</small></li>
<li class="gist-entry" id="gist-1213445"><a href="gists/1213445.html">Better CSS Grid System </a><br><small class="date"><b>Created:</b> September 13, 2011</small><small class="date"><b>Tags:</b> #css</small></li>
<li class="gist-entry" id="gist-1186328"><a href="gists/1186328.html">Access original value of property that has been over-written /via @jdalton and modified by @dperini </a><br><small class="date"><b>Created:</b> September 1, 2011</small><small class="date"><b>Tags:</b> #js</small></li>
<li class="gist-entry" id="gist-1186292"><a href="gists/1186292.html">displays CSS properties that support URL as value via @LeaVerou </a><br><small class="date"><b>Created:</b> September 1, 2011</small><small class="date"><b>Tags:</b> #js</small></li>
<li class="gist-entry" id="gist-1186135"><a href="gists/1186135.html">server-sent events </a><br><small class="date"><b>Created:</b> September 1, 2011</small><small class="date"><b>Tags:</b> #php</small></li>
<li class="gist-entry" id="gist-1148650"><a href="gists/1148650.html">better CSS pseudo-element selector detector </a><br><small class="date"><b>Created:</b> August 16, 2011</small><small class="date"><b>Tags:</b> #js</small></li>
<li class="gist-entry" id="gist-1148624"><a href="gists/1148624.html">detect CSS pseudo-element selector support </a><br><small class="date"><b>Created:</b> August 16, 2011</small><small class="date"><b>Tags:</b> #js</small></li>
<li class="gist-entry" id="gist-1123058"><a href="gists/1123058.html">lookbehind implementations </a><br><small class="date"><b>Created:</b> August 3, 2011</small><small class="date"><b>Tags:</b> #regex</small></li>
<li class="gist-entry" id="gist-1106383"><a href="gists/1106383.html">CSS Syntax Terminology </a><br><small class="date"><b>Created:</b> July 26, 2011</small><small class="date"><b>Tags:</b> #css</small></li>
<li class="gist-entry" id="gist-1080410"><a href="gists/1080410.html">input placeholder polyfill </a><br><small class="date"><b>Created:</b> July 13, 2011</small><small class="date"><b>Tags:</b> #js</small></li>
<li class="gist-entry" id="gist-1077593"><a href="gists/1077593.html">Cheap 'inArray' trick by @ded </a><br><small class="date"><b>Created:</b> July 12, 2011</small><small class="date"><b>Tags:</b> #js</small></li>
<li class="gist-entry" id="gist-890700"><a href="gists/890700.html">Generic JavaScript library </a><br><small class="date"><b>Created:</b> March 28, 2011</small><small class="date"><b>Tags:</b> #js</small></li>
<li class="gist-entry" id="gist-884830"><a href="gists/884830.html">Mobile Selector Engine </a><br><small class="date"><b>Created:</b> March 24, 2011</small><small class="date"><b>Tags:</b> #js</small></li>
<li class="gist-entry" id="gist-803331"><a href="gists/803331.html">JavaScript CSS animation </a><br><small class="date"><b>Created:</b> January 30, 2011</small><small class="date"><b>Tags:</b> #js</small></li>
<li class="gist-entry" id="gist-763762"><a href="gists/763762.html">Observer Design Pattern </a><br><small class="date"><b>Created:</b> January 3, 2011</small><small class="date"><b>Tags:</b> #patterns</small></li>
</ul>
<script>window.SEARCH_DATA = [{"id":"29024a8de49dcdf5ba9b24927e15cf05","title":"Trapping Shell Signals ","content":"#!/usr/bin/env bash\n\ncleanup() {\n  echo \"\u003e\u003e\u003e cleanup called (reason: $1)\"\n}\n\n# Trap EXIT, INT, TERM\n# In the following code we're passing the 'signal' as an argument to the cleanup function.\n#\n# trap 'cleanup EXIT' EXIT\n# trap 'cleanup INT' INT\n# trap 'cleanup TERM' TERM\n\n# INT/TERM would normally stop the script immediately.\n# But when you trap them, you replace the default action with whatever you tell the shell to do.\n# You need to explicitly tell the shell to exit after cleanup, e.g.:\ntrap 'cleanup INT; exit 130' INT    # 130 is the conventional exit code for SIGINT\ntrap 'cleanup TERM; exit 143' TERM  # 143 = 128 + 15 (SIGTERM)\ntrap 'cleanup EXIT' EXIT\n\necho \"PID $$ running. Try:\"\necho \"  1) Let it finish normally\"\necho \"  2) Press Ctrl+C\"\necho \"  3) Run: kill -TERM $$\"\necho\n\n# Simulate doing some work\nfor i in {1..10}; do\n  echo \"Working... $i\"\n  sleep 1\ndone\n\necho \"Script finished normally.\"\n","tags":"#shell"},{"id":"8baf2fa15d7dfdf04b8a3e5818eda71e","title":"humanlog.io config file","content":"The config file is stored here:\n\n```\n~/.config/humanlog/config.json\n```\n\nThe only thing I really configure is `formatter.themes.dark.levels.debug.foreground.html_hex_color`, which I set to `#8CBBFF`:\n\n\u003e [!TIP]\n\u003e You can view via `humanlog config show`.\n\n```json\n{\n\t\"version\": 2,\n\t\"formatter\": {\n\t\t\"themes\": {\n\t\t\t\"light\": {\n\t\t\t\t\"key\": {\n\t\t\t\t\t\"foreground\": {\n\t\t\t\t\t\t\"html_hex_color\": \"#146e23\"\n\t\t\t\t\t}\n\t\t\t\t},\n\t\t\t\t\"value\": {\n\t\t\t\t\t\"foreground\": {\n\t\t\t\t\t\t\"html_hex_color\": \"#878376\"\n\t\t\t\t\t}\n\t\t\t\t},\n\t\t\t\t\"time\": {\n\t\t\t\t\t\"foreground\": {\n\t\t\t\t\t\t\"html_hex_color\": \"#565454\"\n\t\t\t\t\t}\n\t\t\t\t},\n\t\t\t\t\"msg\": {\n\t\t\t\t\t\"foreground\": {\n\t\t\t\t\t\t\"html_hex_color\": \"#000000\"\n\t\t\t\t\t}\n\t\t\t\t},\n\t\t\t\t\"levels\": {\n\t\t\t\t\t\"debug\": {\n\t\t\t\t\t\t\"foreground\": {\n\t\t\t\t\t\t\t\"html_hex_color\": \"#d33682\"\n\t\t\t\t\t\t}\n\t\t\t\t\t},\n\t\t\t\t\t\"info\": {\n\t\t\t\t\t\t\"foreground\": {\n\t\t\t\t\t\t\t\"html_hex_color\": \"#2aa198\"\n\t\t\t\t\t\t}\n\t\t\t\t\t},\n\t\t\t\t\t\"warn\": {\n\t\t\t\t\t\t\"foreground\": {\n\t\t\t\t\t\t\t\"html_hex_color\": \"#ff8800\"\n\t\t\t\t\t\t}\n\t\t\t\t\t},\n\t\t\t\t\t\"error\": {\n\t\t\t\t\t\t\"foreground\": {\n\t\t\t\t\t\t\t\"html_hex_color\": \"#d82626\"\n\t\t\t\t\t\t}\n\t\t\t\t\t},\n\t\t\t\t\t\"panic\": {\n\t\t\t\t\t\t\"foreground\": {\n\t\t\t\t\t\t\t\"html_hex_color\": \"#d82626\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t\"background\": {\n\t\t\t\t\t\t\t\"html_hex_color\": \"#ffffff\"\n\t\t\t\t\t\t}\n\t\t\t\t\t},\n\t\t\t\t\t\"fatal\": {\n\t\t\t\t\t\t\"foreground\": {\n\t\t\t\t\t\t\t\"html_hex_color\": \"#d82626\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t\"background\": {\n\t\t\t\t\t\t\t\"html_hex_color\": \"#ffff00\"\n\t\t\t\t\t\t}\n\t\t\t\t\t},\n\t\t\t\t\t\"unknown\": {\n\t\t\t\t\t\t\"foreground\": {\n\t\t\t\t\t\t\t\"html_hex_color\": \"#a9a9a9\"\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t},\n\t\t\t\t\"absent_msg\": {\n\t\t\t\t\t\"foreground\": {\n\t\t\t\t\t\t\"html_hex_color\": \"#a9a9a9\"\n\t\t\t\t\t}\n\t\t\t\t},\n\t\t\t\t\"absent_time\": {\n\t\t\t\t\t\"foreground\": {\n\t\t\t\t\t\t\"html_hex_color\": \"#a9a9a9\"\n\t\t\t\t\t}\n\t\t\t\t},\n\t\t\t\t\"logs\": {\n\t\t\t\t\t\"key\": {\n\t\t\t\t\t\t\"foreground\": {\n\t\t\t\t\t\t\t\"html_hex_color\": \"#146e23\"\n\t\t\t\t\t\t}\n\t\t\t\t\t},\n\t\t\t\t\t\"value\": {\n\t\t\t\t\t\t\"foreground\": {\n\t\t\t\t\t\t\t\"html_hex_color\": \"#878376\"\n\t\t\t\t\t\t}\n\t\t\t\t\t},\n\t\t\t\t\t\"time\": {\n\t\t\t\t\t\t\"foreground\": {\n\t\t\t\t\t\t\t\"html_hex_color\": \"#565454\"\n\t\t\t\t\t\t}\n\t\t\t\t\t},\n\t\t\t\t\t\"msg\": {\n\t\t\t\t\t\t\"foreground\": {\n\t\t\t\t\t\t\t\"html_hex_color\": \"#000000\"\n\t\t\t\t\t\t}\n\t\t\t\t\t},\n\t\t\t\t\t\"levels\": {\n\t\t\t\t\t\t\"debug\": {\n\t\t\t\t\t\t\t\"foreground\": {\n\t\t\t\t\t\t\t\t\"html_hex_color\": \"#d33682\"\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t},\n\t\t\t\t\t\t\"info\": {\n\t\t\t\t\t\t\t\"foreground\": {\n\t\t\t\t\t\t\t\t\"html_hex_color\": \"#2aa198\"\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t},\n\t\t\t\t\t\t\"warn\": {\n\t\t\t\t\t\t\t\"foreground\": {\n\t\t\t\t\t\t\t\t\"html_hex_color\": \"#ff8800\"\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t},\n\t\t\t\t\t\t\"error\": {\n\t\t\t\t\t\t\t\"foreground\": {\n\t\t\t\t\t\t\t\t\"html_hex_color\": \"#d82626\"\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t},\n\t\t\t\t\t\t\"panic\": {\n\t\t\t\t\t\t\t\"foreground\": {\n\t\t\t\t\t\t\t\t\"html_hex_color\": \"#d82626\"\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\"background\": {\n\t\t\t\t\t\t\t\t\"html_hex_color\": \"#ffffff\"\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t},\n\t\t\t\t\t\t\"fatal\": {\n\t\t\t\t\t\t\t\"foreground\": {\n\t\t\t\t\t\t\t\t\"html_hex_color\": \"#d82626\"\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\"background\": {\n\t\t\t\t\t\t\t\t\"html_hex_color\": \"#ffff00\"\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t},\n\t\t\t\t\t\t\"unknown\": {\n\t\t\t\t\t\t\t\"foreground\": {\n\t\t\t\t\t\t\t\t\"html_hex_color\": \"#a9a9a9\"\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t},\n\t\t\t\t\t\"absent_msg\": {\n\t\t\t\t\t\t\"foreground\": {\n\t\t\t\t\t\t\t\"html_hex_color\": \"#a9a9a9\"\n\t\t\t\t\t\t}\n\t\t\t\t\t},\n\t\t\t\t\t\"absent_time\": {\n\t\t\t\t\t\t\"foreground\": {\n\t\t\t\t\t\t\t\"html_hex_color\": \"#a9a9a9\"\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t},\n\t\t\t\t\"spans\": {\n\t\t\t\t\t\"trace_id\": {\n\t\t\t\t\t\t\"foreground\": {\n\t\t\t\t\t\t\t\"html_hex_color\": \"#1b645e\"\n\t\t\t\t\t\t}\n\t\t\t\t\t},\n\t\t\t\t\t\"span_id\": {\n\t\t\t\t\t\t\"foreground\": {\n\t\t\t\t\t\t\t\"html_hex_color\": \"#1b645e\"\n\t\t\t\t\t\t}\n\t\t\t\t\t},\n\t\t\t\t\t\"trace_state\": {\n\t\t\t\t\t\t\"foreground\": {\n\t\t\t\t\t\t\t\"html_hex_color\": \"#1b645e\"\n\t\t\t\t\t\t}\n\t\t\t\t\t},\n\t\t\t\t\t\"parent_span_id\": {\n\t\t\t\t\t\t\"foreground\": {\n\t\t\t\t\t\t\t\"html_hex_color\": \"#1b645e\"\n\t\t\t\t\t\t}\n\t\t\t\t\t},\n\t\t\t\t\t\"name\": {\n\t\t\t\t\t\t\"foreground\": {\n\t\t\t\t\t\t\t\"html_hex_color\": \"#000000\"\n\t\t\t\t\t\t}\n\t\t\t\t\t},\n\t\t\t\t\t\"kind\": {\n\t\t\t\t\t\t\"foreground\": {\n\t\t\t\t\t\t\t\"html_hex_color\": \"#1b645e\"\n\t\t\t\t\t\t}\n\t\t\t\t\t},\n\t\t\t\t\t\"service_name\": {\n\t\t\t\t\t\t\"foreground\": {\n\t\t\t\t\t\t\t\"html_hex_color\": \"#1b645e\"\n\t\t\t\t\t\t}\n\t\t\t\t\t},\n\t\t\t\t\t\"scope_name\": {\n\t\t\t\t\t\t\"foreground\": {\n\t\t\t\t\t\t\t\"html_hex_color\": \"#1b645e\"\n\t\t\t\t\t\t}\n\t\t\t\t\t},\n\t\t\t\t\t\"scope_version\": {\n\t\t\t\t\t\t\"foreground\": {\n\t\t\t\t\t\t\t\"html_hex_color\": \"#1b645e\"\n\t\t\t\t\t\t}\n\t\t\t\t\t},\n\t\t\t\t\t\"time\": {\n\t\t\t\t\t\t\"foreground\": {\n\t\t\t\t\t\t\t\"html_hex_color\": \"#565454\"\n\t\t\t\t\t\t}\n\t\t\t\t\t},\n\t\t\t\t\t\"duration\": {\n\t\t\t\t\t\t\"foreground\": {\n\t\t\t\t\t\t\t\"html_hex_color\": \"#1b645e\"\n\t\t\t\t\t\t}\n\t\t\t\t\t},\n\t\t\t\t\t\"resource_key\": {\n\t\t\t\t\t\t\"foreground\": {\n\t\t\t\t\t\t\t\"html_hex_color\": \"#146e23\"\n\t\t\t\t\t\t}\n\t\t\t\t\t},\n\t\t\t\t\t\"resource_val\": {\n\t\t\t\t\t\t\"foreground\": {\n\t\t\t\t\t\t\t\"html_hex_color\": \"#878376\"\n\t\t\t\t\t\t}\n\t\t\t\t\t},\n\t\t\t\t\t\"attribute_key\": {\n\t\t\t\t\t\t\"foreground\": {\n\t\t\t\t\t\t\t\"html_hex_color\": \"#146e23\"\n\t\t\t\t\t\t}\n\t\t\t\t\t},\n\t\t\t\t\t\"attribute_val\": {\n\t\t\t\t\t\t\"foreground\": {\n\t\t\t\t\t\t\t\"html_hex_color\": \"#878376\"\n\t\t\t\t\t\t}\n\t\t\t\t\t},\n\t\t\t\t\t\"status_message\": {\n\t\t\t\t\t\t\"foreground\": {\n\t\t\t\t\t\t\t\"html_hex_color\": \"#1b645e\"\n\t\t\t\t\t\t}\n\t\t\t\t\t},\n\t\t\t\t\t\"status_code\": {\n\t\t\t\t\t\t\"foreground\": {\n\t\t\t\t\t\t\t\"html_hex_color\": \"#1b645e\"\n\t\t\t\t\t\t}\n\t\t\t\t\t},\n\t\t\t\t\t\"event_time\": {\n\t\t\t\t\t\t\"foreground\": {\n\t\t\t\t\t\t\t\"html_hex_color\": \"#1b645e\"\n\t\t\t\t\t\t}\n\t\t\t\t\t},\n\t\t\t\t\t\"event_name\": {\n\t\t\t\t\t\t\"foreground\": {\n\t\t\t\t\t\t\t\"html_hex_color\": \"#1b645e\"\n\t\t\t\t\t\t}\n\t\t\t\t\t},\n\t\t\t\t\t\"event_key\": {\n\t\t\t\t\t\t\"foreground\": {\n\t\t\t\t\t\t\t\"html_hex_color\": \"#1b645e\"\n\t\t\t\t\t\t}\n\t\t\t\t\t},\n\t\t\t\t\t\"event_val\": {\n\t\t\t\t\t\t\"foreground\": {\n\t\t\t\t\t\t\t\"html_hex_color\": \"#1b645e\"\n\t\t\t\t\t\t}\n\t\t\t\t\t},\n\t\t\t\t\t\"link_trace_id\": {\n\t\t\t\t\t\t\"foreground\": {\n\t\t\t\t\t\t\t\"html_hex_color\": \"#1b645e\"\n\t\t\t\t\t\t}\n\t\t\t\t\t},\n\t\t\t\t\t\"link_span_id\": {\n\t\t\t\t\t\t\"foreground\": {\n\t\t\t\t\t\t\t\"html_hex_color\": \"#1b645e\"\n\t\t\t\t\t\t}\n\t\t\t\t\t},\n\t\t\t\t\t\"link_trace_state\": {\n\t\t\t\t\t\t\"foreground\": {\n\t\t\t\t\t\t\t\"html_hex_color\": \"#1b645e\"\n\t\t\t\t\t\t}\n\t\t\t\t\t},\n\t\t\t\t\t\"link_key\": {\n\t\t\t\t\t\t\"foreground\": {\n\t\t\t\t\t\t\t\"html_hex_color\": \"#1b645e\"\n\t\t\t\t\t\t}\n\t\t\t\t\t},\n\t\t\t\t\t\"link_val\": {\n\t\t\t\t\t\t\"foreground\": {\n\t\t\t\t\t\t\t\"html_hex_color\": \"#1b645e\"\n\t\t\t\t\t\t}\n\t\t\t\t\t},\n\t\t\t\t\t\"absent_parent_span_id\": {\n\t\t\t\t\t\t\"foreground\": {\n\t\t\t\t\t\t\t\"html_hex_color\": \"#a9a9a9\"\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t},\n\t\t\t\t\"tables\": {\n\t\t\t\t\t\"column_name\": {\n\t\t\t\t\t\t\"foreground\": {\n\t\t\t\t\t\t\t\"html_hex_color\": \"#1b645e\"\n\t\t\t\t\t\t}\n\t\t\t\t\t},\n\t\t\t\t\t\"column_type\": {\n\t\t\t\t\t\t\"foreground\": {\n\t\t\t\t\t\t\t\"html_hex_color\": \"#1b645e\"\n\t\t\t\t\t\t}\n\t\t\t\t\t},\n\t\t\t\t\t\"value\": {\n\t\t\t\t\t\t\"foreground\": {\n\t\t\t\t\t\t\t\"html_hex_color\": \"#1b645e\"\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t},\n\t\t\t\"dark\": {\n\t\t\t\t\"key\": {\n\t\t\t\t\t\"foreground\": {\n\t\t\t\t\t\t\"html_hex_color\": \"#48df61\"\n\t\t\t\t\t}\n\t\t\t\t},\n\t\t\t\t\"value\": {\n\t\t\t\t\t\"foreground\": {\n\t\t\t\t\t\t\"html_hex_color\": \"#8c887c\"\n\t\t\t\t\t}\n\t\t\t\t},\n\t\t\t\t\"time\": {\n\t\t\t\t\t\"foreground\": {\n\t\t\t\t\t\t\"html_hex_color\": \"#9e9e9e\"\n\t\t\t\t\t}\n\t\t\t\t},\n\t\t\t\t\"msg\": {\n\t\t\t\t\t\"foreground\": {\n\t\t\t\t\t\t\"html_hex_color\": \"#ffffff\"\n\t\t\t\t\t}\n\t\t\t\t},\n\t\t\t\t\"levels\": {\n\t\t\t\t\t\"debug\": {\n\t\t\t\t\t\t\"foreground\": {\n\t\t\t\t\t\t\t\"html_hex_color\": \"#8CBBFF\"\n\t\t\t\t\t\t}\n\t\t\t\t\t},\n\t\t\t\t\t\"info\": {\n\t\t\t\t\t\t\"foreground\": {\n\t\t\t\t\t\t\t\"html_hex_color\": \"#2aa198\"\n\t\t\t\t\t\t}\n\t\t\t\t\t},\n\t\t\t\t\t\"warn\": {\n\t\t\t\t\t\t\"foreground\": {\n\t\t\t\t\t\t\t\"html_hex_color\": \"#ff8800\"\n\t\t\t\t\t\t}\n\t\t\t\t\t},\n\t\t\t\t\t\"error\": {\n\t\t\t\t\t\t\"foreground\": {\n\t\t\t\t\t\t\t\"html_hex_color\": \"#ff6a6a\"\n\t\t\t\t\t\t}\n\t\t\t\t\t},\n\t\t\t\t\t\"panic\": {\n\t\t\t\t\t\t\"foreground\": {\n\t\t\t\t\t\t\t\"html_hex_color\": \"#ff6a6a\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t\"background\": {\n\t\t\t\t\t\t\t\"html_hex_color\": \"#ffffff\"\n\t\t\t\t\t\t}\n\t\t\t\t\t},\n\t\t\t\t\t\"fatal\": {\n\t\t\t\t\t\t\"foreground\": {\n\t\t\t\t\t\t\t\"html_hex_color\": \"#ff6a6a\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t\"background\": {\n\t\t\t\t\t\t\t\"html_hex_color\": \"#ffff00\"\n\t\t\t\t\t\t}\n\t\t\t\t\t},\n\t\t\t\t\t\"unknown\": {\n\t\t\t\t\t\t\"foreground\": {\n\t\t\t\t\t\t\t\"html_hex_color\": \"#a9a9a9\"\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t},\n\t\t\t\t\"absent_msg\": {\n\t\t\t\t\t\"foreground\": {\n\t\t\t\t\t\t\"html_hex_color\": \"#a9a9a9\"\n\t\t\t\t\t}\n\t\t\t\t},\n\t\t\t\t\"absent_time\": {\n\t\t\t\t\t\"foreground\": {\n\t\t\t\t\t\t\"html_hex_color\": \"#a9a9a9\"\n\t\t\t\t\t}\n\t\t\t\t},\n\t\t\t\t\"logs\": {\n\t\t\t\t\t\"key\": {\n\t\t\t\t\t\t\"foreground\": {\n\t\t\t\t\t\t\t\"html_hex_color\": \"#48df61\"\n\t\t\t\t\t\t}\n\t\t\t\t\t},\n\t\t\t\t\t\"value\": {\n\t\t\t\t\t\t\"foreground\": {\n\t\t\t\t\t\t\t\"html_hex_color\": \"#8c887c\"\n\t\t\t\t\t\t}\n\t\t\t\t\t},\n\t\t\t\t\t\"time\": {\n\t\t\t\t\t\t\"foreground\": {\n\t\t\t\t\t\t\t\"html_hex_color\": \"#9e9e9e\"\n\t\t\t\t\t\t}\n\t\t\t\t\t},\n\t\t\t\t\t\"msg\": {\n\t\t\t\t\t\t\"foreground\": {\n\t\t\t\t\t\t\t\"html_hex_color\": \"#ffffff\"\n\t\t\t\t\t\t}\n\t\t\t\t\t},\n\t\t\t\t\t\"levels\": {\n\t\t\t\t\t\t\"debug\": {\n\t\t\t\t\t\t\t\"foreground\": {\n\t\t\t\t\t\t\t\t\"html_hex_color\": \"#d33682\"\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t},\n\t\t\t\t\t\t\"info\": {\n\t\t\t\t\t\t\t\"foreground\": {\n\t\t\t\t\t\t\t\t\"html_hex_color\": \"#2aa198\"\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t},\n\t\t\t\t\t\t\"warn\": {\n\t\t\t\t\t\t\t\"foreground\": {\n\t\t\t\t\t\t\t\t\"html_hex_color\": \"#ff8800\"\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t},\n\t\t\t\t\t\t\"error\": {\n\t\t\t\t\t\t\t\"foreground\": {\n\t\t\t\t\t\t\t\t\"html_hex_color\": \"#ff6a6a\"\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t},\n\t\t\t\t\t\t\"panic\": {\n\t\t\t\t\t\t\t\"foreground\": {\n\t\t\t\t\t\t\t\t\"html_hex_color\": \"#ff6a6a\"\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\"background\": {\n\t\t\t\t\t\t\t\t\"html_hex_color\": \"#ffffff\"\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t},\n\t\t\t\t\t\t\"fatal\": {\n\t\t\t\t\t\t\t\"foreground\": {\n\t\t\t\t\t\t\t\t\"html_hex_color\": \"#ff6a6a\"\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\"background\": {\n\t\t\t\t\t\t\t\t\"html_hex_color\": \"#ffff00\"\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t},\n\t\t\t\t\t\t\"unknown\": {\n\t\t\t\t\t\t\t\"foreground\": {\n\t\t\t\t\t\t\t\t\"html_hex_color\": \"#a9a9a9\"\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t},\n\t\t\t\t\t\"absent_msg\": {\n\t\t\t\t\t\t\"foreground\": {\n\t\t\t\t\t\t\t\"html_hex_color\": \"#a9a9a9\"\n\t\t\t\t\t\t}\n\t\t\t\t\t},\n\t\t\t\t\t\"absent_time\": {\n\t\t\t\t\t\t\"foreground\": {\n\t\t\t\t\t\t\t\"html_hex_color\": \"#a9a9a9\"\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t},\n\t\t\t\t\"spans\": {\n\t\t\t\t\t\"trace_id\": {\n\t\t\t\t\t\t\"foreground\": {\n\t\t\t\t\t\t\t\"html_hex_color\": \"#2aa198\"\n\t\t\t\t\t\t}\n\t\t\t\t\t},\n\t\t\t\t\t\"span_id\": {\n\t\t\t\t\t\t\"foreground\": {\n\t\t\t\t\t\t\t\"html_hex_color\": \"#2aa198\"\n\t\t\t\t\t\t}\n\t\t\t\t\t},\n\t\t\t\t\t\"trace_state\": {\n\t\t\t\t\t\t\"foreground\": {\n\t\t\t\t\t\t\t\"html_hex_color\": \"#2aa198\"\n\t\t\t\t\t\t}\n\t\t\t\t\t},\n\t\t\t\t\t\"parent_span_id\": {\n\t\t\t\t\t\t\"foreground\": {\n\t\t\t\t\t\t\t\"html_hex_color\": \"#2aa198\"\n\t\t\t\t\t\t}\n\t\t\t\t\t},\n\t\t\t\t\t\"name\": {\n\t\t\t\t\t\t\"foreground\": {\n\t\t\t\t\t\t\t\"html_hex_color\": \"#2aa198\"\n\t\t\t\t\t\t}\n\t\t\t\t\t},\n\t\t\t\t\t\"kind\": {\n\t\t\t\t\t\t\"foreground\": {\n\t\t\t\t\t\t\t\"html_hex_color\": \"#2aa198\"\n\t\t\t\t\t\t}\n\t\t\t\t\t},\n\t\t\t\t\t\"service_name\": {\n\t\t\t\t\t\t\"foreground\": {\n\t\t\t\t\t\t\t\"html_hex_color\": \"#2aa198\"\n\t\t\t\t\t\t}\n\t\t\t\t\t},\n\t\t\t\t\t\"scope_name\": {\n\t\t\t\t\t\t\"foreground\": {\n\t\t\t\t\t\t\t\"html_hex_color\": \"#2aa198\"\n\t\t\t\t\t\t}\n\t\t\t\t\t},\n\t\t\t\t\t\"scope_version\": {\n\t\t\t\t\t\t\"foreground\": {\n\t\t\t\t\t\t\t\"html_hex_color\": \"#2aa198\"\n\t\t\t\t\t\t}\n\t\t\t\t\t},\n\t\t\t\t\t\"time\": {\n\t\t\t\t\t\t\"foreground\": {\n\t\t\t\t\t\t\t\"html_hex_color\": \"#2aa198\"\n\t\t\t\t\t\t}\n\t\t\t\t\t},\n\t\t\t\t\t\"duration\": {\n\t\t\t\t\t\t\"foreground\": {\n\t\t\t\t\t\t\t\"html_hex_color\": \"#2aa198\"\n\t\t\t\t\t\t}\n\t\t\t\t\t},\n\t\t\t\t\t\"resource_key\": {\n\t\t\t\t\t\t\"foreground\": {\n\t\t\t\t\t\t\t\"html_hex_color\": \"#2aa198\"\n\t\t\t\t\t\t}\n\t\t\t\t\t},\n\t\t\t\t\t\"resource_val\": {\n\t\t\t\t\t\t\"foreground\": {\n\t\t\t\t\t\t\t\"html_hex_color\": \"#2aa198\"\n\t\t\t\t\t\t}\n\t\t\t\t\t},\n\t\t\t\t\t\"attribute_key\": {\n\t\t\t\t\t\t\"foreground\": {\n\t\t\t\t\t\t\t\"html_hex_color\": \"#2aa198\"\n\t\t\t\t\t\t}\n\t\t\t\t\t},\n\t\t\t\t\t\"attribute_val\": {\n\t\t\t\t\t\t\"foreground\": {\n\t\t\t\t\t\t\t\"html_hex_color\": \"#2aa198\"\n\t\t\t\t\t\t}\n\t\t\t\t\t},\n\t\t\t\t\t\"status_message\": {\n\t\t\t\t\t\t\"foreground\": {\n\t\t\t\t\t\t\t\"html_hex_color\": \"#2aa198\"\n\t\t\t\t\t\t}\n\t\t\t\t\t},\n\t\t\t\t\t\"status_code\": {\n\t\t\t\t\t\t\"foreground\": {\n\t\t\t\t\t\t\t\"html_hex_color\": \"#2aa198\"\n\t\t\t\t\t\t}\n\t\t\t\t\t},\n\t\t\t\t\t\"event_time\": {\n\t\t\t\t\t\t\"foreground\": {\n\t\t\t\t\t\t\t\"html_hex_color\": \"#2aa198\"\n\t\t\t\t\t\t}\n\t\t\t\t\t},\n\t\t\t\t\t\"event_name\": {\n\t\t\t\t\t\t\"foreground\": {\n\t\t\t\t\t\t\t\"html_hex_color\": \"#2aa198\"\n\t\t\t\t\t\t}\n\t\t\t\t\t},\n\t\t\t\t\t\"event_key\": {\n\t\t\t\t\t\t\"foreground\": {\n\t\t\t\t\t\t\t\"html_hex_color\": \"#2aa198\"\n\t\t\t\t\t\t}\n\t\t\t\t\t},\n\t\t\t\t\t\"event_val\": {\n\t\t\t\t\t\t\"foreground\": {\n\t\t\t\t\t\t\t\"html_hex_color\": \"#2aa198\"\n\t\t\t\t\t\t}\n\t\t\t\t\t},\n\t\t\t\t\t\"link_trace_id\": {\n\t\t\t\t\t\t\"foreground\": {\n\t\t\t\t\t\t\t\"html_hex_color\": \"#2aa198\"\n\t\t\t\t\t\t}\n\t\t\t\t\t},\n\t\t\t\t\t\"link_span_id\": {\n\t\t\t\t\t\t\"foreground\": {\n\t\t\t\t\t\t\t\"html_hex_color\": \"#2aa198\"\n\t\t\t\t\t\t}\n\t\t\t\t\t},\n\t\t\t\t\t\"link_trace_state\": {\n\t\t\t\t\t\t\"foreground\": {\n\t\t\t\t\t\t\t\"html_hex_color\": \"#2aa198\"\n\t\t\t\t\t\t}\n\t\t\t\t\t},\n\t\t\t\t\t\"link_key\": {\n\t\t\t\t\t\t\"foreground\": {\n\t\t\t\t\t\t\t\"html_hex_color\": \"#2aa198\"\n\t\t\t\t\t\t}\n\t\t\t\t\t},\n\t\t\t\t\t\"link_val\": {\n\t\t\t\t\t\t\"foreground\": {\n\t\t\t\t\t\t\t\"html_hex_color\": \"#2aa198\"\n\t\t\t\t\t\t}\n\t\t\t\t\t},\n\t\t\t\t\t\"absent_parent_span_id\": {\n\t\t\t\t\t\t\"foreground\": {\n\t\t\t\t\t\t\t\"html_hex_color\": \"#888888\"\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t},\n\t\t\t\t\"tables\": {\n\t\t\t\t\t\"column_name\": {\n\t\t\t\t\t\t\"foreground\": {\n\t\t\t\t\t\t\t\"html_hex_color\": \"#2aa198\"\n\t\t\t\t\t\t}\n\t\t\t\t\t},\n\t\t\t\t\t\"column_type\": {\n\t\t\t\t\t\t\"foreground\": {\n\t\t\t\t\t\t\t\"html_hex_color\": \"#2aa198\"\n\t\t\t\t\t\t}\n\t\t\t\t\t},\n\t\t\t\t\t\"value\": {\n\t\t\t\t\t\t\"foreground\": {\n\t\t\t\t\t\t\t\"html_hex_color\": \"#2aa198\"\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t},\n\t\t\"sort_longest\": true,\n\t\t\"skip_unchanged\": true,\n\t\t\"time\": {\n\t\t\t\"format\": \"Jan _2 15:04:05.000\"\n\t\t},\n\t\t\"terminal_color_mode\": 0\n\t},\n\t\"parser\": {\n\t\t\"timestamp\": {\n\t\t\t\"field_names\": [\n\t\t\t\t\"time\",\n\t\t\t\t\"ts\",\n\t\t\t\t\"@timestamp\",\n\t\t\t\t\"timestamp\",\n\t\t\t\t\"Timestamp\"\n\t\t\t]\n\t\t},\n\t\t\"message\": {\n\t\t\t\"field_names\": [\n\t\t\t\t\"message\",\n\t\t\t\t\"msg\",\n\t\t\t\t\"Body\"\n\t\t\t]\n\t\t},\n\t\t\"level\": {\n\t\t\t\"field_names\": [\n\t\t\t\t\"level\",\n\t\t\t\t\"lvl\",\n\t\t\t\t\"loglevel\",\n\t\t\t\t\"severity\",\n\t\t\t\t\"SeverityText\"\n\t\t\t]\n\t\t}\n\t},\n\t\"runtime\": {\n\t\t\"interrupt\": false,\n\t\t\"skip_check_for_updates\": false,\n\t\t\"features\": {},\n\t\t\"experimental_features\": {\n\t\t\t\"release_channel\": \"main\",\n\t\t\t\"serve_localhost\": {\n\t\t\t\t\"port\": 32764,\n\t\t\t\t\"engine\": \"advanced\",\n\t\t\t\t\"engine_config\": {\n\t\t\t\t\t\"path\": \"~/.state/humanlog/data/db.humanlog\"\n\t\t\t\t},\n\t\t\t\t\"show_in_systray\": true,\n\t\t\t\t\"log_dir\": \"~/.state/humanlog/logs\",\n\t\t\t\t\"otlp\": {\n\t\t\t\t\t\"grpc_port\": 4317,\n\t\t\t\t\t\"http_port\": 4318\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n}\n```\n","tags":""},{"id":"5fa84ffa216e2c3b412ee6b090cabe57","title":"Markdown: Highligh notes and warnings in Markdown ","content":"https://github.com/orgs/community/discussions/16925\n\n```\n\u003e [!NOTE]\n\u003e Highlights information that users should take into account, even when skimming.\n\n\u003e [!TIP]\n\u003e Optional information to help a user be more successful.\n\n\u003e [!IMPORTANT]\n\u003e Crucial information necessary for users to succeed.\n\n\u003e [!WARNING]\n\u003e Critical content demanding immediate user attention due to potential risks.\n\n\u003e [!CAUTION]\n\u003e Negative potential consequences of an action.\n```\n\n\u003e [!NOTE]\n\u003e Highlights information that users should take into account, even when skimming.\n\n\u003e [!TIP]\n\u003e Optional information to help a user be more successful.\n\n\u003e [!IMPORTANT]\n\u003e Crucial information necessary for users to succeed.\n\n\u003e [!WARNING]\n\u003e Critical content demanding immediate user attention due to potential risks.\n\n\u003e [!CAUTION]\n\u003e Negative potential consequences of an action.\n","tags":"#gist #github #notes"},{"id":"fad3f3a20b9be166bd0b0248e8e1a665","title":"Search Tips ","content":"## Check if file was modified more than N time ago\n\nThe following commands will indicate if the specified file (`/tmp/cache-lazy-op`) was modified more than 60 minutes ago:\n\n```shell\nfind \"/tmp/cache-lazy-op\" -mmin +60\nfd cache-lazy-op /tmp --type f --changed-before 60m\n```\n\nThe `find` command is more readily available and simpler to remember, but some people prefer more modern tools like `fd`.\n\n\u003e [!NOTE]\n\u003e This isn't checking how old the file is, but _specifically_ whether it was last modified over an hour ago.\n","tags":"#shell"},{"id":"0a714206cb2d3a7399ac7b1e6cdea69b","title":"PR Reviews","content":"\u003e [!TIP]\n\u003e \"I think many people misunderstand the purpose of code review.  The purpose of code review is not for the reviewer to find bugs, and certainly not for them to ensure that the code is bug-free.  Anyone who depends on code review to find bugs is living in a fool's paradise.  As everyone should know by now, it is not in general possible to find bugs by examining the code.\n\u003e \n\u003e The primary purpose of code review is to find code that will be _hard to maintain_.  The reviewer looks at the code and tries to understand what it is doing and how. If they can't, that means it will be hard to maintain in the future, and should be fixed now, while the original author is still familiar with it.\" -- https://infosec.exchange/@mjd@mathstodon.xyz/115096720467521263\n","tags":""},{"id":"8061d6381b57d5316d2789feb4b829d1","title":"Using ETags in your API ","content":"I like to include ETags ([RFC 7232](https://datatracker.ietf.org/doc/html/rfc7232#section-2.3)) in an API as a way to distinguish between “_Which resource am I targeting?_” (e.g. `id`) and “_Which version of the resource am I changing?_” (e.g. `etag`). \n\nThe `id` never changes while the `etag` changes every time the resource is modified. \n\nThe problem I'm trying to solve is both \"race conditions\" and \"lost updates\". \n\nFor example, a customer has two employees (or automated systems) both looking to make modifications to API-based data. They get the same data at the same time, then attempt to update that data, but the changes they each attempt to make overlaps with each other (maybe user A changes the `name` field in the data, while user B deletes the `name` field). This is a problem because the outcome is non-deterministic and user A's changes might be applied last which means the `name` field is put back instead of deleted. \n\nSupporting ETags requires the API user to provide an `If-Match` request header with the relevant ETag value and if the tag doesn’t match what is currently stored in the database (which the API communicates with to get the data), then the request is rejected with a `412 Precondition Failed` ([RFC 9110](https://datatracker.ietf.org/doc/html/rfc9110#name-412-precondition-failed)).\n","tags":"#etag #api"},{"id":"9fc9853ca099ff9164ab63388d461784","title":"Go Fuzz Testing","content":".PHONY: test-fuzz\ntest-fuzz: ## Run fuzz tests\nifeq ($(strip $(GO_FUZZARGS)),)\n\t@status=0; \\\n\tfor pkg in $$(go list ./...); do \\\n\t\tfor test in $$(go test -list=^Fuzz $$pkg | grep '^Fuzz'); do \\\n\t\t\techo \"\u003e\u003e\u003e Fuzzing $$pkg $$test\"; \\\n\t\t\tif ! go test -fuzz=$$test -fuzztime=10s $$pkg; then \\\n\t\t\t\techo \"❌ FAIL: $$pkg $$test\"; \\\n\t\t\t\tstatus=1; \\\n\t\t\tfi; \\\n\t\tdone; \\\n\tdone; \\\n\texit $$status\nelse\n\t@# Running tests with fuzz arguments\n\tgo test -v -run='^$$' $(GO_FUZZARGS)\nendif\n","tags":""},{"id":"0c765162e5faf3c31a6378b087684d4f","title":"Simple Fastly Terraform Subscription ","content":"terraform {\n  required_providers {\n    fastly = {\n      source  = \"fastly/fastly\"\n      version = \"7.0.0\"\n    }\n  }\n  required_version = \"\u003e= 1.0\"\n}\n\n# data \"fastly_tls_configuration\" \"http3_tls13\" {\n# \tid = \"QqO0FM8CvrMCSr94yODlTw\"\n# }\n#\n# output \"tls_config\" {\n# \tvalue = data.fastly_tls_configuration.http3_tls13\n# }\n\nresource \"fastly_tls_subscription\" \"fastly_dev\" {\n  domains               = [\"www.fastly-dev.com\"]\n  certificate_authority = \"certainly\"\n  configuration_id      = \"QqO0FM8CvrMCSr94yODlTw\"\n}\n\nresource \"fastly_service_vcl\" \"fastly_dev\" {\n  name = \"fastly_dev\"\n\n  domain {\n    name = \"www.fastly-dev.com\"\n  }\n\n  backend {\n    address           = \"www.fastly-debug.com\"\n    name              = \"fastly_debug\"\n    override_host     = \"www.fastly-debug.com\"\n    port              = 443\n    ssl_cert_hostname = \"fastly-debug.com\"\n    ssl_sni_hostname  = \"fastly-debug.com\"\n    use_ssl           = true\n  }\n\n  force_destroy = true\n}\n","tags":"#tls #fastly #iac"},{"id":"a9d4c67d7c2c38d7a542306966fc5e23","title":"Base62 encoding and decoding ","content":"// https://go.dev/play/p/IwFfNFlIq_x\npackage main\n\nimport (\n\t\"fmt\"\n\t\"log\"\n\n\t\"github.com/dromara/dongle\"\n\t\"github.com/google/uuid\"\n)\n\nfunc main() {\n\tid, err := uuid.NewV7()\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\tfmt.Println(\"UUID:\", id)\n\n\t// Convert UUID to string from its raw bytes\n\tencoded := dongle.Encode.\n\t\tFromBytes(id[:]).\n\t\tByBase62().\n\t\tToString()\n\tfmt.Println(\"Base62:\", encoded)\n\n\t// Decode Base62 string back to bytes\n\tdecoded := dongle.Decode.\n\t\tFromString(encoded).\n\t\tByBase62().\n\t\tToBytes()\n\n\t// Reconstruct UUID from bytes\n\trecovered, err := uuid.FromBytes(decoded)\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\tfmt.Println(\"Decoded UUID:\", recovered)\n}\n// https://go.dev/play/p/9gbyOrXVUGt\npackage main\n\nimport (\n\t\"errors\"\n\t\"fmt\"\n\t\"log\"\n\t\"strings\"\n\n\t\"github.com/jxskiss/base62\"\n)\n\nfunc main() {\n\tencoded := EncodeCursor(\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\")\n\tfmt.Println(encoded)\n\tdecoded, err := DecodeCursor(encoded)\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\tfmt.Println(decoded)\n}\n\nfunc EncodeCursor(values ...string) string {\n\tif len(values) == 0 {\n\t\treturn \"\"\n\t}\n\tcursorStr := strings.Join(values, \",\")\n\treturn base62.EncodeToString([]byte(cursorStr))\n}\n\nfunc DecodeCursor(encodedCursor string) ([]string, error) {\n\tif encodedCursor == \"\" {\n\t\treturn nil, nil\n\t}\n\n\tdecoded, err := base62.DecodeString(encodedCursor)\n\tif err != nil {\n\t\treturn nil, errors.New(\"invalid cursor format\")\n\t}\n\n\treturn strings.Split(string(decoded), \",\"), nil\n}\n\n","tags":"#go #uuid #serialization"},{"id":"e3504366d1202c7e0af8a2518422a2fc","title":"Dependabot ","content":"# Example configuration that's quite detailed in its approach.\n# .github/dependabot.yaml\n\nversion: 2\nupdates:\n  - package-ecosystem: github-actions\n    directory: \"/\"\n    schedule:\n      day: monday\n      interval: weekly\n      time: \"13:00\"\n    open-pull-requests-limit: 10\n    groups:\n      version-bumps:\n        applies-to: version-updates\n        update-types: [\"minor\", \"patch\"]\n\n  - package-ecosystem: gomod\n    directory: \"/\"\n    schedule:\n      interval: weekly\n      time: \"12:00\"\n    open-pull-requests-limit: 10\n    groups:\n      # Always create a separate PR for zonedb updates\n      zonedb-only:\n        patterns:\n          - \"github.com/zonedb/zonedb\"\n      # Create a grouped PR specifically for fastly dependencies.\n      fastly-modules:\n        applies-to: version-updates\n        patterns:\n          - \"github.com/fastly\"\n      # Create a grouped PR for all go.mod dependencies that have a minor or\n      # patch version updates. All major updates will be separate PRs.\n      external-modules:\n        applies-to: version-updates\n        update-types: [\"minor\", \"patch\"]\n        exclude-patterns:\n          - \"github.com/zonedb/zonedb\"\n          - \"github.com/fastly\"\n\n  - package-ecosystem: terraform\n    # specify directories for dependabot to monitor for updating\n    # directories allows the use wildcard and globbing, which is needed because infrastructure contains many layers of subdirectories\n    # https://docs.github.com/en/code-security/dependabot/working-with-dependabot/dependabot-options-reference#directories-or-directory--\n    directories:\n      - \"/infrastructure\" # files within the directory\n      - \"/infrastructure/**/*\" # subdirectories\n    schedule:\n      day: monday\n      interval: weekly\n      time: \"13:00\" # 5am Pacific\n    open-pull-requests-limit: 10\n    groups:\n      version-bumps:\n        applies-to: version-updates\n        update-types: [\"minor\", \"patch\"]\n","tags":"#dependencies"},{"id":"36dcf9fa921f6caa58990525e474d1a3","title":"Homebrew: custom version install ","content":"You can't install specific package versions using [Homebrew](https://brew.sh/).\n\nIf you have a version installed you can _pin_ it:\n\n```\nbrew pin \u003cpackage\u003e\n```\n\nThat will prevent a `brew upgrade` from updating the package.\n\nBut this doesn't help if you've already upgraded a package and then discovered that you need an older version.\n\nTo do that:\n\n1. Download the older Brew script, e.g. `helm` version `3.17.3`: https://github.com/Homebrew/homebrew-core/blob/14e5c24f9bb081fe3cd5ad595f518edc28955473/Formula/h/helm.rb\n2. `HOMEBREW_NO_AUTO_UPDATE=1 brew install /tmp/helm.rb`\n","tags":"#homebrew #macOS"},{"id":"1b5ee79a9d128407c7daabd72a1abf27","title":"macOS: automation with Hammerspoon ","content":"You need to install [Hammerspoon](https://www.hammerspoon.org/) and setup a `~/.hammerspoon/init.lua`.\n\nExamples can be found here: https://www.hammerspoon.org/go/#helloworld\nhs.hotkey.bind({\"cmd\"}, \"escape\", function()\n  local ghostty = hs.application.find(\"Ghostty\")\n  if ghostty and ghostty:isFrontmost() then\n    ghostty:hide()\n  else\n    hs.application.launchOrFocus(\"Ghostty\")\n  end\nend)\n","tags":"#hammer #hammerspoon #os #automation #macos #shell #lua"},{"id":"38ade4cd75f1efe01acd0738d01470cd","title":"Go: 1.23 iter.Seq/iter.Seq2 iterators ","content":"// This code demonstrates how iterators work in Go.\n// This particular example is contrived, but I wanted something simple enough to demonstrate the point.\n\npackage main\n\nimport (\n\t\"fmt\"\n\t\"iter\"\n\t\"strings\"\n)\n\n// stringlines returns an iterator over lines in a string.\nfunc stringlines(s string) iter.Seq[string] {\n\treturn func(yield func(string) bool) {\n\t\tlines := strings.Split(s, \"\\n\")\n\t\tfor _, line := range lines {\n\t\t\tif !yield(line) { // Call yield with the current line\n\t\t\t\treturn // Stop if yield returns false\n\t\t\t}\n\t\t}\n\t\tfmt.Println(\"yield() never returned false so the internal for loop kept going\")\n\t}\n}\n\nfunc main() {\n\tdata := \"line one\\nline two\\nline three\"\n\n\t// function stringlines() returns an iterator:\n\tfor line := range stringlines(data) {\n\t\tfmt.Println(line)\n\t}\n\n\t// Iterating with early exit:\n\t// If the range 'block' returns/breaks, then that == false\n\t// If the range 'block' completes, then that == true\n\tfor line := range stringlines(data) {\n\t\tfmt.Println(line)\n\t\tif line == \"line two\" {\n\t\t\tbreak // exits the loop, signifying to yield() it should stop the loop inside of stringlines()\n\t\t}\n\t}\n}\n","tags":"#go #iterator"},{"id":"b50604c682e5ba91208f650147280596","title":"DNS Delegation ","content":"## DNS Management and Delegation\n\nIf a domain owner wants to use another company for handling DNS management over its domain, then they can update the \"Name Servers\" for their domain wherever DNS is currently managed, and set the Name Servers to a different DNS provider. \n\nThis is known as DNS _delegation_.\n\nOnce that Name Server change has propagated, the new DNS provider will be responsible for managing DNS records for the domain.\n\n## CNAME redirection magic\n\nThrough a CNAME, a domain owner can delegate the DNS resolution for a specific hostname to another service, enabling that service to provide the necessary records (like TXT) for that name.\n\n## Example\n\nSo as an example, let's say I'm onboarding my domain `integralist.co.uk` with Fastly and Fastly is going to manage a TLS certificate for me using a popular Certificate Authority (CA) such as Let's Encrypt.\n\nThe CA (as part of `dns-01` ACME validation) needs to prove that I own the domain before it will issue a certificate. So it asks that the domain owner create a TXT record like `_acme-challenge.integralist.co.uk` with a specific value. It'll then check if that has been done, and if so, it'll issue a TLS certificate.\n\nNow I (as the domain owner) am not communicating with the CA. Fastly is. So Fastly is the one being given the information from the CA as to the TXT record that needs to be created. But Fastly doesn't show me that information. That's because Fastly wants to be responsible for managing TLS certificate _renewals_. It would be annoying if Fastly had to keep coming back to me (as the domain owner) every time the TLS certificate was going to expire and ask me to update my DNS each time with whatever new TXT challenge record the CA is asking to be created to verify domain ownership.\n\nSo, Fastly instead asks me to create a CNAME record called `_acme-challenge.integralist.co.uk`. This record name is the same as the TXT record name the CA is expecting, but importantly, it's a CNAME record, not a TXT record. \n\nFastly will ask me to create this CNAME record with a value like `\u003cunique-id\u003e.fastly-validations.com`.\n\nNow remember, the CA itself is expecting a TXT record called `_acme-challenge.integralist.co.uk` to be created.\n\nStandard DNS resolver behavior dictates that when looking for a specific record type (like TXT) and encountering a CNAME, the resolver should restart the query for the original record type but using the target of the CNAME.\n\n\u003e [!NOTE]\n\u003e To be clear, the DNS resolver doesn't _choose_ to look at the CNAME instead of the TXT; rather, when it asks for the TXT record, the authoritative server responds with the CNAME because:\n\u003e\n\u003e a) The CNAME exists for that name.\\\n\u003e b) The DNS rules forbid a TXT record (or most other types) from existing at the same name as the CNAME.\n\u003e\n\u003e Receiving the CNAME record triggers the standard resolver behavior to follow the alias and re-query for the original record type (TXT) at the target name. It \"automatically sees the CNAME\" because that's the data the authoritative server provides in response to its TXT query, due to the CNAME's exclusive nature.\n\nThis means, it'll restart the query for the TXT record but will look for `\u003cunique-id\u003e.fastly-validations.com` as the value.\n\nThe DNS will naturally follow the `\u003cunique-id\u003e.fastly-validations.com` to where Fastly controls the DNS, and Fastly has set-up that TXT record with the secret TXT value that the CA originally asked for.\n\n## Diagram\n\nThe following is a very rough proximation of steps...\n\n```mermaid\nsequenceDiagram\n    participant User\n    participant Fastly as Fastly Platform\n    participant UserDNS as User's DNS Provider\n    participant FastlyDNS as Fastly's DNS Provider\n    participant AcmeCA as ACME CA Server\n    participant AcmeResolver as ACME CA's DNS Resolver\n\n    Note over User, FastlyDNS: Pre-requisite: User Configures DNS\n    User-\u003e\u003eUserDNS: Create CNAME record: _acme-challenge.integralist.co.uk -\u003e \u003cunique-id\u003e.fastly-validations.com\n\n    Note over User, Fastly: User Initiates Certificate Process\n    User-\u003e\u003eFastly: Request TLS Certificate for integralist.co.uk\n\n    Note over Fastly, AcmeCA: Fastly Starts ACME Order\n    Fastly-\u003e\u003eAcmeCA: Initiate certificate order (DNS-01 challenge)\n    AcmeCA--\u003e\u003eFastly: Respond with Challenge (Domain: _acme-challenge.integralist.co.uk, Token: TOKEN_VALUE)\n\n    Note over Fastly, FastlyDNS: Fastly Prepares Validation Record\n    Fastly-\u003e\u003eFastlyDNS: Create TXT record for \u003cunique-id\u003e.fastly-validations.com with value \"TOKEN_VALUE\"\n    FastlyDNS--\u003e\u003eFastly: TXT record created/updated\n\n    Note over Fastly, AcmeCA: Fastly Signals Readiness\n    Fastly-\u003e\u003eAcmeCA: Ready for challenge validation\n\n    Note over AcmeCA, AcmeResolver: ACME CA Initiates Verification\n    AcmeCA-\u003e\u003eAcmeResolver: Verify domain control for integralist.co.uk (check TXT at _acme-challenge...)\n\n    Note over AcmeResolver, UserDNS: Resolver Query 1 (Original Domain)\n    AcmeResolver-\u003e\u003eUserDNS: Query: TXT record for _acme-challenge.integralist.co.uk?\n    UserDNS--\u003e\u003eAcmeResolver: Response: CNAME \u003cunique-id\u003e.fastly-validations.com\n\n    Note over AcmeResolver, FastlyDNS: Resolver Query 2 (Following CNAME)\n    AcmeResolver-\u003e\u003eFastlyDNS: Query: TXT record for \u003cunique-id\u003e.fastly-validations.com?\n    FastlyDNS--\u003e\u003eAcmeResolver: Response: TXT \"TOKEN_VALUE\"\n\n    Note over AcmeResolver, AcmeCA: Resolver Reports Result\n    AcmeResolver--\u003e\u003eAcmeCA: Found TXT record with value \"TOKEN_VALUE\"\n\n    Note over AcmeCA, Fastly: ACME CA Validates and Issues\n    AcmeCA-\u003e\u003eAcmeCA: Compare found TOKEN_VALUE with expected TOKEN_VALUE\n    alt Validation Successful\n        AcmeCA--\u003e\u003eFastly: Challenge successful, issuing certificate\n        Fastly-\u003e\u003eFastly: Receive and deploy certificate\n    else Validation Failed\n        AcmeCA--\u003e\u003eFastly: Challenge failed\n    end\n```\n","tags":"#dns"},{"id":"91d0757344d1b37ff5f40df6c2869b4e","title":"Go: JSON omitempty vs omitzero ","content":"**Guidelines:**\n\n\u003e [!TIP]\n\u003e The super quick summary is: use `omitzero`\\\n\u003e _Unless_ you need to identify an empty map/slice/interface, then use `omitempty`.\\\n\u003e If you need to identify if value was deliberately set to the zero type, use a pointer.\\\n\u003e If you have specific zero requirements define custom type with `IsZero` method.\n\n- to filter out a nil map, use `omitzero`\n- to filter out a nil map _and_ an empty map, use `omitempty`\n- to filter out a nil slice, use `omitzero`\n- to filter out a nil slice _and_ an empty slice, use `omitempty`\n- to filter out an empty struct, use `omitzero`(see NOTE)\n- to filter out a zero time, use `omitzero`\n- to filter out a bool, use `omitzero`\n\n\u003e [!NOTE]\n\u003e Go checks if all the struct's fields are their respective zero values _or_ if it has a custom `IsZero()` bool method that returns true. \n\nHere is a contrived example of a custom int type that implements `IsZero` to trick 0 to be shown (but really, the implementation can be whatever makes sense for your application):\n\n```go\npackage main\n\nimport (\n\t\"encoding/json\"\n\t\"fmt\"\n)\n\ntype Data struct {\n\tField CustomInt `json:\"field,omitzero\"`\n}\n\ntype CustomInt int\n\nfunc (i CustomInt) IsZero() bool {\n\treturn i == -1\n}\n\nfunc main() {\n\td1 := Data{}\n\tj1, _ := json.Marshal(d1)\n\tfmt.Println(string(j1)) // {\"field\":0}\n\n\td2 := Data{Field: 0}\n\tj2, _ := json.Marshal(d2)\n\tfmt.Println(string(j2)) // {\"field\":0}\n\n\td3 := Data{Field: 1}\n\tj3, _ := json.Marshal(d3)\n\tfmt.Println(string(j3)) // {\"field\":1}\n}\n```\n","tags":"#go #json"},{"id":"c528f499d892cb0d74f7e037d5856358","title":"Go: httpx.WriteJSON ","content":"Here is some problematic code...\n\n```go\nfunc WriteJSON(l *slog.Logger, w http.ResponseWriter, r *http.Request, code int, v any) {\n\tctx := r.Context()\n\tw.Header().Set(\"Content-Type\", \"application/json\")\n        w.WriteHeader(code)\n\n\tif err := json.NewEncoder(w).Encode(v); err != nil {\n\t\tl.LogAttrs(ctx, slog.LevelError, \"encode_json_response\", slog.Any(\"err\", err))\n\t\tw.WriteHeader(http.StatusInternalServerError)\n\t\t// w.Write([]byte(\"some response data\"))\n\t\tfmt.Fprintf(w, `{\"error\": %q}`, err)\n\t\treturn\n\t}\n}\n```\n\nIt's problematic because an error encoding the JSON response will result in a 2xx status code but an error JSON message.\n\nThis is because of how `http.ResponseWriter.Write` works:\n\n- If `w.WriteHeader` hasn't been called, then call it with `http.StatusOK`.\n- If `w.WriteHeader` has been called, then the status has already been sent to the client and it can't now be changed.\n- This means repeated calls to `w.WriteHeader` have no effect. Whatever was first set, is what will be seen by the client.\n// EXAMPLES\n//\n// ERROR RESPONSE:\n//    response := ErrorResponse{Message: \"error reading request body\", Details: err.Error()}\n//    httpx.WriteJSON(l, w, r, http.StatusBadRequest, response)\n//\n// SUCCESS RESPONSE:\n//    response := map[string]string{\"message\": \"updated order status to trigger certificate issuance\"}\n//    httpx.WriteJSON(l, w, r, http.StatusOK, response)\n\npackage httpx\n\nimport (\n\t\"bytes\"\n\t\"encoding/json\"\n\t\"fmt\"\n\t\"log/slog\"\n\t\"net/http\"\n)\n\n// WriteJSON encodes v as JSON and writes to w.\n// It ensures the correct status code is written even if JSON encoding fails.\n// Will write a [http.StatusInternalServerError] if there is an error.\n// Otherwise, it'll write the JSON response with specified code status.\n//\n// WARNING: The response status code is explicitly sent before the body.\n//\n// We have to do this because we don't want the first call to\n// [http.ResponseWriter.Write] to call `WriteHeader(http.StatusOK)`.\n//\n// This means there is the potential for the incorrect status code to be sent.\n// If, the call to [bytes.Buffer.WriteTo] fails, then we've already set the\n// response status code. We now can't change the status, as Go ignores\n// subsequent calls to [http.ResponseWriter.WriteHeader]. The best we can do is\n// catch and log the error.\nfunc WriteJSON(l *slog.Logger, w http.ResponseWriter, r *http.Request, code int, v any) {\n\tctx := r.Context()\n\tw.Header().Set(\"Content-Type\", \"application/json\")\n\n\tvar buf bytes.Buffer\n\tif err := json.NewEncoder(\u0026buf).Encode(v); err != nil {\n\t\tl.LogAttrs(ctx, slog.LevelError, \"encode_json_response\", slog.Any(\"err\", err))\n\t\tw.WriteHeader(http.StatusInternalServerError)\n\t\tfmt.Fprintf(w, `{\"error\": %q}`, err)\n\t\treturn\n\t}\n\n\tw.WriteHeader(code)\n\n\tif _, err := buf.WriteTo(w); err != nil {\n\t\tl.LogAttrs(ctx, slog.LevelError, \"write_buffered_response\", slog.Any(\"err\", err))\n\t\tfmt.Fprintf(w, `{\"error\": %q}`, err)\n\t\treturn\n\t\t// Alternatively, instead of writing the error and returning...\n\t\t// panic(http.ErrAbortHandler)\n\t\t// ...but you should probably have some Panic Recovery middleware in your stack.\n\t}\n}\n// PanicRecovery recovers from panics in an HTTP handler.\n// It records a log line and reports a metric, then re-raises the panic so\n// [http.Server] can handle the default recovery behaviour.\nfunc PanicRecovery(l *slog.Logger, m *metrics.Metrics) func(next http.Handler) http.Handler {\n\treturn func(next http.Handler) http.Handler {\n\t\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\t\t// IMPORTANT: Create a scoped logger to avoid memory leaks.\n\t\t\tsl := l.With(\n\t\t\t\tslog.Group(\"request\",\n\t\t\t\t\tslog.String(\"method\", r.Method),\n\t\t\t\t\tslog.String(\"path\", r.URL.Path),\n\t\t\t\t),\n\t\t\t)\n\t\t\tctx := r.Context()\n\n\t\t\tdefer func() {\n\t\t\t\tif rec := recover(); rec != nil {\n\t\t\t\t\t// [http.ErrAbortHandler] is a sentinel panic value to abort\n\t\t\t\t\t// a handler. While any panic from ServeHTTP aborts the\n\t\t\t\t\t// response to the client, panicking with ErrAbortHandler\n\t\t\t\t\t// also suppresses logging of a stack trace to the server's\n\t\t\t\t\t// error log. We catch the panic early so we can issue a\n\t\t\t\t\t// custom log and metric call, then re-raise the panic.\n\t\t\t\t\tpanicType := \"Unknown\"\n\t\t\t\t\tif rec == http.ErrAbortHandler {\n\t\t\t\t\t\tpanicType = \"ErrAbortHandler\"\n\t\t\t\t\t}\n\n\t\t\t\t\tsl.LogAttrs(ctx, slog.LevelInfo, \"panic_recovered\",\n\t\t\t\t\t\tslog.Any(\"panic\", panicType),\n\t\t\t\t\t\tslog.String(\"stack_trace\", string(debug.Stack())),\n\t\t\t\t\t)\n\t\t\t\t\tm.Count(\"api_panic_countervecs_total\", \"panic=\"+panicType)\n\n\t\t\t\t\t// We re-raise the panic so that the net/http server's\n\t\t\t\t\t// default panic handler can take over. This ensures the\n\t\t\t\t\t// server terminates the request gracefully.\n\t\t\t\t\tpanic(rec)\n\t\t\t\t}\n\t\t\t}()\n\t\t\tnext.ServeHTTP(w, r)\n\t\t})\n\t}\n}\n","tags":"#go #http #json #api"},{"id":"d2a575ff3fbda36c08e31408110adbb6","title":"TLS, Certificate, and ACME Glossary ","content":"# TLS, Certificate, and ACME Glossary\n\nThis glossary defines common terms related to Transport Layer Security (TLS),\ndigital certificates, Certificate Authorities (CAs), and the Automatic\nCertificate Management Environment (ACME) protocol. It's intended to help users\nunderstand the concepts involved in securing services and using APIs that manage\ncertificate issuance, particularly focusing on Subject Alternative Names (SANs).\n\n- [Core Concepts](#core-concepts)\n- [Certificate Details](#certificate-details)\n- [ACME Protocol](#acme-protocol)\n- [Authorities \u0026 Trust](#authorities--trust)\n\n## Core Concepts\n\n**TLS (Transport Layer Security):** The successor to SSL (Secure Sockets Layer).\nA cryptographic protocol designed to provide secure communication over a\ncomputer network. TLS ensures privacy and data integrity between two\ncommunicating applications, most commonly seen securing HTTPS web traffic.\n\n**SSL (Secure Sockets Layer):** The predecessor protocol to TLS. While the term\n\"SSL\" is still sometimes used colloquially, modern secure connections use TLS.\nSSL versions are deprecated due to known vulnerabilities.\n\n**HTTPS (Hypertext Transfer Protocol Secure):** The secure version of HTTP,\nwhere communications are encrypted using TLS. It ensures that data exchanged\nbetween a user's browser and a web server is confidential and integral.\n\n**Encryption:** The process of converting information or data into a code,\nespecially to prevent unauthorized access.\n\n- **Asymmetric Encryption (Public-Key Cryptography):** Uses a pair of keys: a\n  public key (shared freely) for encryption and a private key (kept secret) for\n  decryption. Used during the TLS handshake to establish a shared secret.\n- **Symmetric Encryption:** Uses the same secret key for both encryption and\n  decryption. Used for the bulk data transfer during a TLS session because it's\n  faster than asymmetric encryption.\n\n**Handshake (TLS Handshake):** The process at the beginning of a TLS session\nwhere the client and server agree on the protocol version, select cipher suites,\nauthenticate each other (optionally, server authentication is most common), and\nestablish shared secret keys for the session.\n\n**Cipher Suite:** A named combination of cryptographic algorithms used during a\nTLS session. It typically includes algorithms for key exchange, bulk encryption,\nand message authentication (MAC). Example: `TLS_AES_128_GCM_SHA256`.\n\n## Certificate Details\n\n**Certificate (Digital Certificate / TLS Certificate / X.509 Certificate):** An\nelectronic document used to prove the ownership of a public key. It binds a\npublic key to an identity (like a hostname or organization) and is signed by a\ntrusted Certificate Authority (CA). It follows the X.509 standard format.\n\n**X.509:** The standard defining the format of public key certificates. Most TLS\ncertificates are X.509 certificates.\n\n**Key Pair:** The combination of a public key and its corresponding private key\nused in asymmetric cryptography.\n\n**Public Key:** The key in an asymmetric key pair that can be shared publicly\nwithout compromising security. It's typically used to encrypt data intended for\nthe private key holder or to verify a digital signature made with the private\nkey.\n\n**Private Key:** The key in an asymmetric key pair that *must* be kept secret by\nthe owner. It's used to decrypt data encrypted with the corresponding public key\nor to create digital signatures. Compromise of the private key compromises the\nsecurity of the certificate.\n\n**Subject:** The field in a certificate that identifies the entity (e.g., domain\nname, organization) the certificate belongs to. It contains several components,\nincluding the Common Name (CN).\n\n**Common Name (CN):** A component within the Subject field of a certificate.\nHistorically, it was the primary field used to identify the hostname the\ncertificate was issued for. *Note: Modern browsers and clients primarily rely on\nthe Subject Alternative Name (SAN) field instead.*\n\n**Subject Alternative Name (SAN):** An extension field in an X.509 certificate\n(since X.509v3) that allows multiple identifiers (like DNS names, IP addresses,\nemail addresses) to be bound to the same certificate. **This is the standard and\nrequired way to specify the hostnames a certificate should be valid for.** A\nsingle certificate can secure multiple domains (e.g., `example.com`,\n`www.example.com`, `api.example.com`) using SAN entries.\n\n**Issuer:** The field in a certificate that identifies the entity (usually a CA)\nthat signed and issued the certificate.\n\n**Signature (Digital Signature):** Data appended to a message (or certificate)\ncreated using the signer's private key. It allows anyone with the corresponding\npublic key to verify the authenticity and integrity of the message (or\ncertificate) and confirm the signer's identity. CAs sign the certificates they\nissue.\n\n**Validity Period:** The time frame during which a certificate is considered\nvalid. Defined by a 'Not Before' date/time and a 'Not After' (Expiration)\ndate/time.\n\n**Certificate Chain (Chain of Trust):** An ordered list of certificates,\nstarting with an end-entity certificate, followed by one or more intermediate\ncertificates, and ending with a trusted root certificate. It allows a client to\nverify that an end-entity certificate is trustworthy by tracing it back to a\nroot CA certificate stored in the client's trust store.\n\n- **End-entity Certificate (or Leaf Certificate):** The certificate issued for a\n  specific server/domain.\n- **Intermediate Certificate:** A certificate issued by a Root CA or another\n  Intermediate CA, used to sign end-entity certificates. Using intermediates\n  avoids exposing the root private key frequently.\n- **Root Certificate:** A self-signed certificate from a Root CA that forms the\n  basis of trust. These are pre-installed in operating systems and browsers in a\n  'Trust Store'.\n\n**Certificate Signing Request (CSR):** A message sent from an applicant to a CA\nto apply for a digital identity certificate. It contains the public key and\nsubject information (like CN and SANs) and is usually signed with the\napplicant's corresponding private key.\n\n**Wildcard Certificate:** A certificate that can secure multiple subdomains of a\nsingle base domain (e.g., `*.example.com` would cover `www.example.com`,\n`api.example.com`, etc., but not `example.com` itself or `sub.sub.example.com`).\nUsually specified using a SAN entry like `*.example.com`.\n\n**Self-Signed Certificate:** A certificate signed with its own private key\ninstead of by a trusted CA. Browsers and clients will typically issue warnings\nfor these certificates as they cannot be automatically trusted. Useful for\ntesting or internal systems where trust is established manually.\n\n**Certificate Revocation List (CRL):** A list published by a CA containing\nserial numbers of certificates that have been revoked (invalidated before their\nexpiration date). Clients may check CRLs to ensure a certificate is still valid.\n\n**Online Certificate Status Protocol (OCSP):** A protocol used to check the\nrevocation status of a certificate in real-time without needing to download\nlarge CRLs. Clients query an OCSP responder (run by the CA) with the\ncertificate's serial number.\n\n**OCSP Stapling:** A performance enhancement for OCSP where the web server\nperiodically obtains a signed OCSP response from the CA and sends (\"staples\") it\nto the client during the TLS handshake, saving the client from making a separate\nOCSP query.\n\n## ACME Protocol\n\n**ACME (Automatic Certificate Management Environment):** A protocol for\nautomating the interactions between CAs and users' web servers or clients,\nenabling the automatic issuance, renewal, and revocation of TLS certificates.\nLet's Encrypt is the most prominent user of ACME.\n\n**ACME Client:** Software that runs on a user's server or device and\ncommunicates with an ACME server (CA) to request, renew, and manage certificates\naccording to the ACME protocol. Examples include Certbot, acme.sh, lego, etc.\n\n**ACME Server:** The endpoint provided by a CA that implements the ACME\nprotocol, allowing ACME clients to interact with it.\n\n**Let's Encrypt:** A non-profit Certificate Authority that provides free X.509\ncertificates through the automated ACME protocol.\n\n**Account Key:** A cryptographic key pair used by an ACME client to sign its\nrequests to the ACME server, authenticating the client to its account with the\nCA.\n\n**Order:** An ACME object representing a client's request for a certificate for\na set of identifiers (domain names).\n\n**Authorization:** An ACME object representing the CA's confirmation that an\naccount holder is authorized to manage a specific identifier (domain name). An\nOrder requires a valid Authorization for each identifier it contains.\n\n**Challenge:** A task given by the ACME server to the ACME client to prove\ncontrol over an identifier (domain name). Successfully completing a challenge is\nnecessary to get an Authorization. Common challenge types include:\n\n- **HTTP-01:** Prove control by provisioning a specific file with specific\n  content at a designated URL on the domain\n  (`http://\u003cdomain\u003e/.well-known/acme-challenge/\u003ctoken\u003e`). Requires port 80 access.\n- **DNS-01:** Prove control by provisioning a specific DNS TXT record under the\n  domain name being validated (`_acme-challenge.\u003cdomain\u003e`). Requires API access to\n  DNS zone. Can be used for wildcard certificates.\n- **TLS-ALPN-01:** Prove control using a special TLS certificate presented\n  during a TLS handshake using the Application-Layer Protocol Negotiation (ALPN)\n  extension. Requires control over the TLS server on port 443.\n\n**Identifier:** A name (typically a DNS domain name) that a certificate request\npertains to. In ACME, these are the subjects for which authorization is sought.\nCorresponds to SAN entries in the final certificate.\n\n**Finalize Request:** An ACME request sent by the client after fulfilling\nauthorizations. The client provides a CSR, and if valid, the ACME server issues\nthe certificate.\n\n**Certificate Issuance:** The final step where the ACME server, after successful\nfinalization, provides the issued certificate (and often the intermediate chain)\nto the ACME client.\n\n## Authorities \u0026 Trust\n\n**Certificate Authority (CA):** An entity trusted to issue, sign, and manage\ndigital certificates. CAs verify the identity of certificate applicants before\nissuing certificates.\n\n**Root CA:** The top-level Certificate Authority in a trust hierarchy. Root CAs\nissue certificates for Intermediate CAs. Their root certificates are self-signed\nand embedded in trust stores.\n\n**Intermediate CA:** A CA whose certificate is signed by a Root CA or another\nIntermediate CA. They issue end-entity certificates, protecting the Root CA's\nprivate key from frequent use.\n\n**Public CA:** A CA whose root certificates are included in the default trust\nstores of major operating systems and browsers (e.g., Let's Encrypt, DigiCert,\nGlobalSign). Certificates issued by Public CAs are generally trusted\nautomatically by clients.\n\n**Private CA:** A CA operated internally by an organization for issuing\ncertificates for internal use cases. Root certificates from Private CAs need to\nbe manually installed or distributed to client trust stores within the\norganization.\n\n**Trust Store:** A collection of trusted Root CA certificates maintained by an\noperating system, browser, or application. Certificates presented during a TLS\nhandshake are validated against this store via the certificate chain.\n\n**Certificate Policy (CP):** A document outlining the policies and procedures a\nCA uses when issuing and managing certificates.\n\n**Certification Practice Statement (CPS):** A detailed document describing the\npractices and procedures a CA employs to implement its Certificate Policy,\nincluding identity verification, issuance, revocation, and key management.\n\n","tags":"#TLS #ACME"},{"id":"fc7a7bb75e2951ffe4310a2620b73e8f","title":"Go: HTTP handler Write error after WriteHeader ","content":"func exampleHandler(w http.ResponseWriter, r *http.Request) {\n\tdefer func() {\n\t\tif rec := recover(); rec != nil {\n\t\t\t// The net/http server itself has a recovery mechanism that specifically looks for http.ErrAbortHandler. \n\t\t\t// When it catches this particular panic, it knows to abort the current request handler and close the connection.\n\t\t\tif rec == http.ErrAbortHandler {\n\t\t\t\tlog.Println(\"Handler aborted with http.ErrAbortHandler. Connection will be closed by server.\")\n\t\t\t} else {\n\t\t\t\tlog.Printf(\"Unhandled panic: %v.\", rec)\n\t\t\t}\n\t\t\t// Now that we've implemented our own custom logging for this panic,\n\t\t\t// we re-raise the panic so that the net/http server's default panic handler can take over.\n\t\t\tpanic(rec)\n\t\t}\n\t}()\n\n    w.WriteHeader(http.StatusOK)\n\n    _, err := w.Write([]byte(\"This is a successful response.\\n\"))\n    if err != nil {\n\t// The client has already received the 200 OK header but will now get an incomplete response body.\n        log.Printf(\"Error writing successful response body: %v. Panicking with ErrAbortHandler.\", err)\n\t    \n        // ErrAbortHandler is a sentinel panic value to abort a handler. \n\t// While any panic from ServeHTTP aborts the response to the client, \n\t// panicking with ErrAbortHandler also suppresses logging of a stack trace to the server's error log.\n        panic(http.ErrAbortHandler)\n    }\n    log.Println(\"Successfully wrote response body.\")\n}\n","tags":"#go #http #middleware"},{"id":"bcdd25e27bf1aed9437f8d67b14b6e9f","title":"Go: Why choose tailscale.com/util/ctxkey over Go standard context package ","content":"https://pkg.go.dev/tailscale.com/util/ctxkey\n\nExample Playground: https://play.golang.com/p/aZ0joNec3Xl\n\n```go\npackage main\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"time\"\n\n\t\"tailscale.com/util/ctxkey\"\n)\n\nvar TimeoutKey = ctxkey.New(\"mapreduce.Timeout\", 5*time.Second)\n\nfunc main() {\n\tctx := context.Background()\n\tfmt.Println(TimeoutKey.Value(ctx))\n\n\t// Have to overwrite the ctx with the returned value.\n\t// Otherwise the default value will still be associated with ctx.\n\tctx = TimeoutKey.WithValue(ctx, 10*time.Second)\n\tfmt.Println(TimeoutKey.Value(ctx))\n}\n```\n\n## Why choose `ctxkey` over standard Go `context`?\n\nThe core difference lies in **type safety**.\n\n1.  **Standard `context` Package (`context.WithValue`, `ctx.Value`)**\n\n    -   **How it works:** You associate a value with a key using `context.WithValue(parentCtx, key, value)`. The `key` is typically an unexported custom type (like `type myKey struct{}`) to prevent collisions. You retrieve the value using `val := ctx.Value(key)`.\n    -   **The Drawback:** `ctx.Value(key)` returns a value of type `interface{}`. This means you *must* perform a type assertion to get the value back in its original type: `realVal, ok := val.(ExpectedType)`.\n    -   **The Problem:** This check happens at **runtime**. ^1^ If you make a mistake (e.g., assert the wrong type, forget to check the `ok` boolean), your program might panic or behave unexpectedly *only when that specific code path is executed*. There's no compile-time guarantee that the value associated with a key is of the type you expect. This can lead to subtle bugs that are harder to catch during development.\n\n2.  **`tailscale.com/util/ctxkey`**\n\n    -   **How it works:** This package leverages Go generics (introduced in Go 1.18). You define a key specifically for a certain *type* of value, e.g. `uniqueCtxKey = ctxkey.New(\"\"unique-key-name\"\", uint32(1))` (and you can assign a DEFAULT value, 1 in this case).\n    -   **Setting Values:** You use `uniqueCtxKey.WithValue(ctx, 2)`.\n    -   **Getting Values:** You use `uniqueCtxKey.Value(ctx)`.\n    -   **The Advantage:** Notice there's **no type assertion needed** when retrieving the value. The `Value` function returns the specific type associated with the key (`uint32` in the example above). The Go compiler checks this at **compile time**.\n    -   **The Benefit:** If you try to retrieve a value using a key that expects a different type, or if you try to use the retrieved value as the wrong type, the compiler will flag it as an error *before you even run the program*. This significantly reduces the risk of runtime type errors related to context values. It makes your code safer and easier to refactor.\n\n## In Summary: Why Choose `tailscale.com/util/ctxkey`?\n\n-   **Compile-Time Type Safety:** This is the primary reason. It catches type mismatches related to context values during compilation, preventing a class of runtime errors.\n-   **Reduced Boilerplate:** You don't need the `val.(ExpectedType)` type assertion when retrieving values.\n-   **Improved Readability/Intent:** The key definition `ctxkey.NewKey[ValueType]` explicitly states the type of value the key is intended for.\n\n## Why Stick with Standard `context`?\n\n-   **No External Dependencies:** The `context` package is part of the Go standard library. Using `ctxkey` introduces a dependency on `tailscale.com/util/ctxkey`.\n-   **Simplicity (for basic cases):** If you only have one or two context values and are diligent about type assertions, the standard library might feel sufficient.\n-   **Universality:** Every Go developer knows the standard `context` package.\n\n## Conclusion\n\nYou would want to use `tailscale.com/util/ctxkey` primarily when you want **stronger, compile-time guarantees** about the types of values stored in your context. This is particularly beneficial in larger projects or teams where maintaining type consistency across different parts of the codebase is crucial for preventing runtime errors and improving maintainability. The trade-off is adding an external dependency.\n","tags":"#go #ctx"},{"id":"d61a365912576bcef88b29bd11207df3","title":"Basic Go Project Structure ","content":"github.com/BurntSushi/toml v1.4.0 h1:kuoIxZQy2WRRk1pttg9asf+WVv6tWQuBNVmK8+nqPr0=\ngithub.com/BurntSushi/toml v1.4.0/go.mod h1:ukJfTF/6rtPPRCnwkur4qwRxa8vTRFBF0uk2lLoLwho=\ngithub.com/BurntSushi/toml v1.4.1-0.20240526193622-a339e1f7089c h1:pxW6RcqyfI9/kWtOwnv/G+AzdKuy2ZrqINhenH4HyNs=\ngithub.com/BurntSushi/toml v1.4.1-0.20240526193622-a339e1f7089c/go.mod h1:ukJfTF/6rtPPRCnwkur4qwRxa8vTRFBF0uk2lLoLwho=\ngithub.com/chavacava/garif v0.1.0 h1:2JHa3hbYf5D9dsgseMKAmc/MZ109otzgNFk5s87H9Pc=\ngithub.com/chavacava/garif v0.1.0/go.mod h1:XMyYCkEL58DF0oyW4qDjjnPWONs2HBqYKI+UIPD+Gww=\ngithub.com/davecgh/go-spew v1.1.0/go.mod h1:J7Y8YcW2NihsgmVo/mv3lAwl/skON4iLHjSsI+c5H38=\ngithub.com/davecgh/go-spew v1.1.1/go.mod h1:J7Y8YcW2NihsgmVo/mv3lAwl/skON4iLHjSsI+c5H38=\ngithub.com/fatih/color v1.18.0 h1:S8gINlzdQ840/4pfAwic/ZE0djQEH3wM94VfqLTZcOM=\ngithub.com/fatih/color v1.18.0/go.mod h1:4FelSpRwEGDpQ12mAdzqdOukCy4u8WUtOY6lkT/6HfU=\ngithub.com/fatih/structtag v1.2.0 h1:/OdNE99OxoI/PqaW/SuSK9uxxT3f/tcSZgon/ssNSx4=\ngithub.com/fatih/structtag v1.2.0/go.mod h1:mBJUNpUnHmRKrKlQQlmCrh5PuhftFbNv8Ys4/aAZl94=\ngithub.com/google/go-cmp v0.6.0 h1:ofyhxvXcZhMsU5ulbFiLKl/XBFqE1GSq7atu8tAmTRI=\ngithub.com/google/go-cmp v0.6.0/go.mod h1:17dUlkBOakJ0+DkrSSNjCkIjxS6bF9zb3elmeNGIjoY=\ngithub.com/google/go-cmp v0.7.0 h1:wk8382ETsv4JYUZwIsn6YpYiWiBsYLSJiTsyBybVuN8=\ngithub.com/google/go-cmp v0.7.0/go.mod h1:pXiqmnSA92OHEEa9HXL2W4E7lf9JzCmGVUdgjX3N/iU=\ngithub.com/hashicorp/go-version v1.7.0 h1:5tqGy27NaOTB8yJKUZELlFAS/LTKJkrmONwQKeRZfjY=\ngithub.com/hashicorp/go-version v1.7.0/go.mod h1:fltr4n8CU8Ke44wwGCBoEymUuxUHl09ZGVZPK5anwXA=\ngithub.com/mattn/go-colorable v0.1.14 h1:9A9LHSqF/7dyVVX6g0U9cwm9pG3kP9gSzcuIPHPsaIE=\ngithub.com/mattn/go-colorable v0.1.14/go.mod h1:6LmQG8QLFO4G5z1gPvYEzlUgJ2wF+stgPZH1UqBm1s8=\ngithub.com/mattn/go-isatty v0.0.20 h1:xfD0iDuEKnDkl03q4limB+vH+GxLEtL/jb4xVJSWWEY=\ngithub.com/mattn/go-isatty v0.0.20/go.mod h1:W+V8PltTTMOvKvAeJH7IuucS94S2C6jfK/D7dTCTo3Y=\ngithub.com/mattn/go-runewidth v0.0.9/go.mod h1:H031xJmbD/WCDINGzjvQ9THkh0rPKHF+m2gUSrubnMI=\ngithub.com/mattn/go-runewidth v0.0.16 h1:E5ScNMtiwvlvB5paMFdw9p4kSQzbXFikJ5SQO6TULQc=\ngithub.com/mattn/go-runewidth v0.0.16/go.mod h1:Jdepj2loyihRzMpdS35Xk/zdY8IAYHsh153qUoGf23w=\ngithub.com/mgechev/dots v0.0.0-20210922191527-e955255bf517 h1:zpIH83+oKzcpryru8ceC6BxnoG8TBrhgAvRg8obzup0=\ngithub.com/mgechev/dots v0.0.0-20210922191527-e955255bf517/go.mod h1:KQ7+USdGKfpPjXk4Ga+5XxQM4Lm4e3gAogrreFAYpOg=\ngithub.com/mgechev/revive v1.7.0 h1:JyeQ4yO5K8aZhIKf5rec56u0376h8AlKNQEmjfkjKlY=\ngithub.com/mgechev/revive v1.7.0/go.mod h1:qZnwcNhoguE58dfi96IJeSTPeZQejNeoMQLUZGi4SW4=\ngithub.com/olekukonko/tablewriter v0.0.5 h1:P2Ga83D34wi1o9J6Wh1mRuqd4mF/x/lgBS7N7AbDhec=\ngithub.com/olekukonko/tablewriter v0.0.5/go.mod h1:hPp6KlRPjbx+hW8ykQs1w3UBbZlj6HuIJcUGPhkA7kY=\ngithub.com/pmezard/go-difflib v1.0.0/go.mod h1:iKH77koFhYxTK1pcRnkKkqfTogsbg7gZNVY4sRDYZ/4=\ngithub.com/rivo/uniseg v0.2.0/go.mod h1:J6wj4VEh+S6ZtnVlnTBMWIodfgj8LQOQFoIToxlJtxc=\ngithub.com/rivo/uniseg v0.4.7 h1:WUdvkW8uEhrYfLC4ZzdpI2ztxP1I582+49Oc5Mq64VQ=\ngithub.com/rivo/uniseg v0.4.7/go.mod h1:FN3SvrM+Zdj16jyLfmOkMNblXMcoc8DfTHruCPUcx88=\ngithub.com/spf13/afero v1.12.0 h1:UcOPyRBYczmFn6yvphxkn9ZEOY65cpwGKb5mL36mrqs=\ngithub.com/spf13/afero v1.12.0/go.mod h1:ZTlWwG4/ahT8W7T0WQ5uYmjI9duaLQGy3Q2OAl4sk/4=\ngithub.com/spf13/afero v1.14.0 h1:9tH6MapGnn/j0eb0yIXiLjERO8RB6xIVZRDCX7PtqWA=\ngithub.com/spf13/afero v1.14.0/go.mod h1:acJQ8t0ohCGuMN3O+Pv0V0hgMxNYDlvdk+VTfyZmbYo=\ngithub.com/stretchr/objx v0.1.0/go.mod h1:HFkY916IF+rwdDfMAkV7OtwuqBVzrE8GR6GFx+wExME=\ngithub.com/stretchr/objx v0.4.0/go.mod h1:YvHI0jy2hoMjB+UWwv71VJQ9isScKT/TqJzVSSt89Yw=\ngithub.com/stretchr/objx v0.5.0/go.mod h1:Yh+to48EsGEfYuaHDzXPcE3xhTkx73EhmCGUpEOglKo=\ngithub.com/stretchr/testify v1.7.1/go.mod h1:6Fq8oRcR53rry900zMqJjRRixrwX3KX962/h/Wwjteg=\ngithub.com/stretchr/testify v1.8.0/go.mod h1:yNjHg4UonilssWZ8iaSj1OCr/vHnekPRkoO+kdMU+MU=\ngithub.com/stretchr/testify v1.8.4/go.mod h1:sz/lmYIOXD/1dqDmKjjqLyZ2RngseejIcXlSw2iwfAo=\ngolang.org/x/crypto v0.0.0-20190308221718-c2843e01d9a2/go.mod h1:djNgcEr1/C05ACkg1iLfiJU5Ep61QUkGW8qpdssI0+w=\ngolang.org/x/crypto v0.0.0-20191011191535-87dc89f01550/go.mod h1:yigFU9vqHzYiE8UmvKecakEJjdnWj3jj499lnFckfCI=\ngolang.org/x/exp v0.0.0-20231110203233-9a3e6036ecaa h1:FRnLl4eNAQl8hwxVVC17teOw8kdjVDVAiFMtgUdTSRQ=\ngolang.org/x/exp/typeparams v0.0.0-20231108232855-2478ac86f678 h1:1P7xPZEwZMoBoz0Yze5Nx2/4pxj6nw9ZqHWXqP0iRgQ=\ngolang.org/x/exp/typeparams v0.0.0-20231108232855-2478ac86f678/go.mod h1:AbB0pIl9nAr9wVwH+Z2ZpaocVmF5I4GyWCDIsVjR0bk=\ngolang.org/x/exp/typeparams v0.0.0-20250305212735-054e65f0b394 h1:VI4qDpTkfFaCXEPrbojidLgVQhj2x4nzTccG0hjaLlU=\ngolang.org/x/exp/typeparams v0.0.0-20250305212735-054e65f0b394/go.mod h1:LKZHyeOpPuZcMgxeHjJp4p5yvxrCX1xDvH10zYHhjjQ=\ngolang.org/x/lint v0.0.0-20241112194109-818c5a804067 h1:adDmSQyFTCiv19j015EGKJBoaa7ElV0Q1Wovb/4G7NA=\ngolang.org/x/lint v0.0.0-20241112194109-818c5a804067/go.mod h1:3xt1FjdF8hUf6vQPIChWIBhFzV8gjjsPE/fR3IyQdNY=\ngolang.org/x/mod v0.1.1-0.20191105210325-c90efee705ee/go.mod h1:QqPTAvyqsEbceGzBzNggFXnrqF1CaUcvgkdR5Ot7KZg=\ngolang.org/x/mod v0.23.0 h1:Zb7khfcRGKk+kqfxFaP5tZqCnDZMjC5VtUBs87Hr6QM=\ngolang.org/x/mod v0.23.0/go.mod h1:6SkKJ3Xj0I0BrPOZoBy3bdMptDDU9oJrpohJ3eWZ1fY=\ngolang.org/x/mod v0.24.0 h1:ZfthKaKaT4NrhGVZHO1/WDTwGES4De8KtWO0SIbNJMU=\ngolang.org/x/mod v0.24.0/go.mod h1:IXM97Txy2VM4PJ3gI61r1YEk/gAj6zAHN3AdZt6S9Ww=\ngolang.org/x/net v0.0.0-20190404232315-eb5bcb51f2a3/go.mod h1:t9HGtf8HONx5eT2rtn7q6eTqICYqUVnKs3thJo3Qplg=\ngolang.org/x/net v0.0.0-20190620200207-3b0461eec859/go.mod h1:z5CRVTTTmAJ677TzLLGU+0bjPO0LkuOLi4/5GtJWs/s=\ngolang.org/x/sync v0.0.0-20190423024810-112230192c58/go.mod h1:RxMgew5VJxzue5/jJTE5uejpjVlOe/izrB70Jof72aM=\ngolang.org/x/sync v0.11.0 h1:GGz8+XQP4FvTTrjZPzNKTMFtSXH80RAzG+5ghFPgK9w=\ngolang.org/x/sync v0.11.0/go.mod h1:Czt+wKu1gCyEFDUtn0jG5QVvpJ6rzVqr5aXyt9drQfk=\ngolang.org/x/sync v0.12.0 h1:MHc5BpPuC30uJk597Ri8TV3CNZcTLu6B6z4lJy+g6Jw=\ngolang.org/x/sync v0.12.0/go.mod h1:1dzgHSNfp02xaA81J2MS99Qcpr2w7fw1gpm99rleRqA=\ngolang.org/x/sys v0.0.0-20190215142949-d0b11bdaac8a/go.mod h1:STP8DvDyc/dI5b8T5hshtkjS+E42TnysNCUPdjciGhY=\ngolang.org/x/sys v0.0.0-20190412213103-97732733099d/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.6.0/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=\ngolang.org/x/sys v0.30.0 h1:QjkSwP/36a20jFYWkSue1YwXzLmsV5Gfq7Eiy72C1uc=\ngolang.org/x/sys v0.30.0/go.mod h1:/VUhepiaJMQUp4+oa/7Zr1D23ma6VTLIYjOOTFZPUcA=\ngolang.org/x/sys v0.31.0 h1:ioabZlmFYtWhL+TRYpcnNlLwhyxaM9kWTDEmfnprqik=\ngolang.org/x/sys v0.31.0/go.mod h1:BJP2sWEmIv4KK5OTEluFJCKSidICx8ciO85XgH3Ak8k=\ngolang.org/x/telemetry v0.0.0-20240522233618-39ace7a40ae7 h1:FemxDzfMUcK2f3YY4H+05K9CDzbSVr2+q/JKN45pey0=\ngolang.org/x/telemetry v0.0.0-20240522233618-39ace7a40ae7/go.mod h1:pRgIJT+bRLFKnoM1ldnzKoxTIn14Yxz928LQRYYgIN0=\ngolang.org/x/telemetry v0.0.0-20250310203348-fdfaad844314 h1:UY+gQAskx5vohcvUlJDKkJPt9lALCgtZs3rs8msRatU=\ngolang.org/x/telemetry v0.0.0-20250310203348-fdfaad844314/go.mod h1:16eI1RtbPZAEm3u7hpIh7JM/w5AbmlDtnrdKYaREic8=\ngolang.org/x/text v0.3.0/go.mod h1:NqM8EUOU14njkJ3fqMW+pc6Ldnwhi/IjpwHt7yyuwOQ=\ngolang.org/x/text v0.22.0 h1:bofq7m3/HAFvbF51jz3Q9wLg3jkvSPuiZu/pD1XwgtM=\ngolang.org/x/text v0.22.0/go.mod h1:YRoo4H8PVmsu+E3Ou7cqLVH8oXWIHVoX0jqUWALQhfY=\ngolang.org/x/text v0.23.0 h1:D71I7dUrlY+VX0gQShAThNGHFxZ13dGLBHQLVl1mJlY=\ngolang.org/x/text v0.23.0/go.mod h1:/BLNzu4aZCJ1+kcD0DNRotWKage4q2rGVAg4o22unh4=\ngolang.org/x/tools v0.0.0-20200130002326-2f3ba24bd6e7/go.mod h1:TB2adYChydJhpapKDTa4BR/hXlZSLoq2Wpct/0txZ28=\ngolang.org/x/tools v0.30.0 h1:BgcpHewrV5AUp2G9MebG4XPFI1E2W41zU1SaqVA9vJY=\ngolang.org/x/tools v0.30.0/go.mod h1:c347cR/OJfw5TI+GfX7RUPNMdDRRbjvYTS0jPyvsVtY=\ngolang.org/x/tools v0.31.0 h1:0EedkvKDbh+qistFTd0Bcwe/YLh4vHwWEkiI0toFIBU=\ngolang.org/x/tools v0.31.0/go.mod h1:naFTU+Cev749tSJRXJlna0T3WxKvb1kWEx15xA4SdmQ=\ngolang.org/x/vuln v1.1.4 h1:Ju8QsuyhX3Hk8ma3CesTbO8vfJD9EvUBgHvkxHBzj0I=\ngolang.org/x/vuln v1.1.4/go.mod h1:F+45wmU18ym/ca5PLTPLsSzr2KppzswxPP603ldA67s=\ngolang.org/x/xerrors v0.0.0-20191011141410-1b5146add898/go.mod h1:I/5z698sn9Ka8TeJc9MKroUUfqBBauWjQqLJ2OPfmY0=\ngopkg.in/check.v1 v0.0.0-20161208181325-20d25e280405/go.mod h1:Co6ibVJAznAaIkqp8huTwlJQCZ016jof/cbN4VW5Yz0=\ngopkg.in/yaml.v3 v3.0.0-20200313102051-9f266ea9e77c/go.mod h1:K4uyk7z7BCEPqu6E+C64Yfv1cQ7kz7rIZviUmN+EgEM=\ngopkg.in/yaml.v3 v3.0.1/go.mod h1:K4uyk7z7BCEPqu6E+C64Yfv1cQ7kz7rIZviUmN+EgEM=\nhonnef.co/go/tools v0.6.1 h1:R094WgE8K4JirYjBaOpz/AvTyUu/3wbmAoskKN/pxTI=\nhonnef.co/go/tools v0.6.1/go.mod h1:3puzxxljPCe8RGJX7BIy1plGbxEOZni5mR2aXe3/uk4=\nmvdan.cc/gofumpt v0.7.0 h1:bg91ttqXmi9y2xawvkuMXyvAA/1ZGJqYAEGjXuP0JXU=\nmvdan.cc/gofumpt v0.7.0/go.mod h1:txVFJy/Sc/mvaycET54pV8SW8gWxTlUuGHVEcncmNUo=\n// Package main is the starting point for the Ascerta API.\npackage main\n\nimport (\n\t\"context\"\n\t\"log/slog\"\n\t\"os\"\n\n\t\"github.com/fastly/ascerta/internal/api\"\n\t\"github.com/fastly/ascerta/internal/log\"\n)\n\nfunc main() {\n\tl := log.New()\n\tif err := api.Run(l); err != nil {\n\t\tctx := context.Background()\n\t\tl.LogAttrs(ctx, slog.LevelError, \"api_run\", slog.Any(\"err\", err))\n\t\tos.Exit(1)\n\t}\n}\nmodule github.com/fastly/ascerta\n\ngo 1.24\n\nrequire github.com/fastly/fst-go v1.13.0\n\nrequire (\n\tgithub.com/beorn7/perks v1.0.1 // indirect\n\tgithub.com/cespare/xxhash/v2 v2.3.0 // indirect\n\tgithub.com/munnerz/goautoneg v0.0.0-20191010083416-a7dc8b61c822 // indirect\n\tgithub.com/prometheus/client_golang v1.21.1 // indirect\n\tgithub.com/prometheus/client_model v0.6.1 // indirect\n\tgithub.com/prometheus/common v0.63.0 // indirect\n\tgithub.com/prometheus/procfs v0.15.1 // indirect\n\tgolang.org/x/sys v0.31.0 // indirect\n\tgoogle.golang.org/protobuf v1.36.5 // indirect\n)\ngithub.com/beorn7/perks v1.0.1 h1:VlbKKnNfV8bJzeqoa4cOKqO6bYr3WgKZxO8Z16+hsOM=\ngithub.com/beorn7/perks v1.0.1/go.mod h1:G2ZrVWU2WbWT9wwq4/hrbKbnv/1ERSJQ0ibhJ6rlkpw=\ngithub.com/cespare/xxhash/v2 v2.3.0 h1:UL815xU9SqsFlibzuggzjXhog7bL6oX9BbNZnL2UFvs=\ngithub.com/cespare/xxhash/v2 v2.3.0/go.mod h1:VGX0DQ3Q6kWi7AoAeZDth3/j3BFtOZR5XLFGgcrjCOs=\ngithub.com/davecgh/go-spew v1.1.1 h1:vj9j/u1bqnvCEfJOwUhtlOARqs3+rkHYY13jYWTU97c=\ngithub.com/davecgh/go-spew v1.1.1/go.mod h1:J7Y8YcW2NihsgmVo/mv3lAwl/skON4iLHjSsI+c5H38=\ngithub.com/fastly/fst-go v1.13.0 h1:rtRF6RZUjOBMGzaNWD9M87b6yEJn8yPWHZ2dcQjR1TA=\ngithub.com/fastly/fst-go v1.13.0/go.mod h1:95Gbykg+NKlc2JPo9SfZp5W6wWILlLqdc6HUIWEySsc=\ngithub.com/google/go-cmp v0.7.0 h1:wk8382ETsv4JYUZwIsn6YpYiWiBsYLSJiTsyBybVuN8=\ngithub.com/google/go-cmp v0.7.0/go.mod h1:pXiqmnSA92OHEEa9HXL2W4E7lf9JzCmGVUdgjX3N/iU=\ngithub.com/klauspost/compress v1.17.11 h1:In6xLpyWOi1+C7tXUUWv2ot1QvBjxevKAaI6IXrJmUc=\ngithub.com/klauspost/compress v1.17.11/go.mod h1:pMDklpSncoRMuLFrf1W9Ss9KT+0rH90U12bZKk7uwG0=\ngithub.com/kylelemons/godebug v1.1.0 h1:RPNrshWIDI6G2gRW9EHilWtl7Z6Sb1BR0xunSBf0SNc=\ngithub.com/kylelemons/godebug v1.1.0/go.mod h1:9/0rRGxNHcop5bhtWyNeEfOS8JIWk580+fNqagV/RAw=\ngithub.com/munnerz/goautoneg v0.0.0-20191010083416-a7dc8b61c822 h1:C3w9PqII01/Oq1c1nUAm88MOHcQC9l5mIlSMApZMrHA=\ngithub.com/munnerz/goautoneg v0.0.0-20191010083416-a7dc8b61c822/go.mod h1:+n7T8mK8HuQTcFwEeznm/DIxMOiR9yIdICNftLE1DvQ=\ngithub.com/pmezard/go-difflib v1.0.0 h1:4DBwDE0NGyQoBHbLQYPwSUPoCMWR5BEzIk/f1lZbAQM=\ngithub.com/pmezard/go-difflib v1.0.0/go.mod h1:iKH77koFhYxTK1pcRnkKkqfTogsbg7gZNVY4sRDYZ/4=\ngithub.com/prometheus/client_golang v1.21.1 h1:DOvXXTqVzvkIewV/CDPFdejpMCGeMcbGCQ8YOmu+Ibk=\ngithub.com/prometheus/client_golang v1.21.1/go.mod h1:U9NM32ykUErtVBxdvD3zfi+EuFkkaBvMb09mIfe0Zgg=\ngithub.com/prometheus/client_model v0.6.1 h1:ZKSh/rekM+n3CeS952MLRAdFwIKqeY8b62p8ais2e9E=\ngithub.com/prometheus/client_model v0.6.1/go.mod h1:OrxVMOVHjw3lKMa8+x6HeMGkHMQyHDk9E3jmP2AmGiY=\ngithub.com/prometheus/common v0.63.0 h1:YR/EIY1o3mEFP/kZCD7iDMnLPlGyuU2Gb3HIcXnA98k=\ngithub.com/prometheus/common v0.63.0/go.mod h1:VVFF/fBIoToEnWRVkYoXEkq3R3paCoxG9PXP74SnV18=\ngithub.com/prometheus/procfs v0.15.1 h1:YagwOFzUgYfKKHX6Dr+sHT7km/hxC76UB0learggepc=\ngithub.com/prometheus/procfs v0.15.1/go.mod h1:fB45yRUv8NstnjriLhBQLuOUt+WW4BsoGhij/e3PBqk=\ngithub.com/stretchr/testify v1.10.0 h1:Xv5erBjTwe/5IxqUQTdXv5kgmIvbHo3QQyRwhJsOfJA=\ngithub.com/stretchr/testify v1.10.0/go.mod h1:r2ic/lqez/lEtzL7wO/rwa5dbSLXVDPFyf8C91i36aY=\ngolang.org/x/sys v0.31.0 h1:ioabZlmFYtWhL+TRYpcnNlLwhyxaM9kWTDEmfnprqik=\ngolang.org/x/sys v0.31.0/go.mod h1:BJP2sWEmIv4KK5OTEluFJCKSidICx8ciO85XgH3Ak8k=\ngoogle.golang.org/protobuf v1.36.5 h1:tPhr+woSbjfYvY6/GPufUoYizxw1cF/yFoxJ2fmpwlM=\ngoogle.golang.org/protobuf v1.36.5/go.mod h1:9fA7Ob0pmnwhb644+1+CVWFRbNajQ6iRojtC/QF5bRE=\ngopkg.in/yaml.v3 v3.0.1 h1:fxVm/GzAzEWqLHuvctI91KS9hhNmmWOoWu0XTYJS7CA=\ngopkg.in/yaml.v3 v3.0.1/go.mod h1:K4uyk7z7BCEPqu6E+C64Yfv1cQ7kz7rIZviUmN+EgEM=\n// Package log contains code for creating a structured logger.\npackage log\n\nimport (\n\t\"context\"\n\t\"io\"\n\t\"log\"\n\t\"log/slog\"\n\t\"os\"\n\t\"path/filepath\"\n\t\"strings\"\n\n\t\"github.com/fastly/fst-go/build\"\n)\n\n// contextKey is used to store a logger in a context.\ntype contextKey struct{}\n\nvar (\n\t// ContextKey is used to store a logger in a context.\n\t// Only to be used in places where a logger can't be passed in as an argument.\n\tContextKey = contextKey{}\n\n\t// Level allows dynamically changing the output level via .Set() method.\n\t// Defaults to [slog.LevelInfo].\n\t// EXAMPLE: log.Level.Set(slog.LevelDebug)\n\tLevel = new(slog.LevelVar)\n)\n\n// New returns a log.Logger configured for stdout.\nfunc New() *slog.Logger {\n\treturn NewWithOutputLevel(os.Stdout, Level)\n}\n\n// NewWithOutput returns a [*slog.Logger] configured with an output writer.\nfunc NewWithOutput(w io.Writer) *slog.Logger {\n\treturn slog.New(slog.NewJSONHandler(w, defaultOptions()).WithAttrs(defaultAttrs()))\n}\n\n// NewWithOutputLevel returns a [*slog.Logger] configured with an output writer and Level.\nfunc NewWithOutputLevel(w io.Writer, l slog.Leveler) *slog.Logger {\n\topts := defaultOptions()\n\topts.Level = l\n\treturn slog.New(slog.NewJSONHandler(w, opts).WithAttrs(defaultAttrs()))\n}\n\n// Adapt returns a [log.Logger] for use with packages that are not yet compatible with\n// [log/slog].\nfunc Adapt(l *slog.Logger, level slog.Level) *log.Logger {\n\treturn slog.NewLogLogger(l.Handler(), level)\n}\n\n// FromContext returns the logger attached to a context.\nfunc FromContext(ctx context.Context) *slog.Logger {\n\tlogger, ok := ctx.Value(ContextKey).(*slog.Logger)\n\tif !ok {\n\t\tlogger = New()\n\t}\n\treturn logger\n}\n\n// defaultOptions defines default logger options.\nfunc defaultOptions() *slog.HandlerOptions {\n\treturn \u0026slog.HandlerOptions{\n\t\tAddSource:   true,\n\t\tReplaceAttr: slogReplaceAttr,\n\t\tLevel:       Level,\n\t}\n}\n\n// defaultAttrs defines default logger attributes.\nfunc defaultAttrs() []slog.Attr {\n\treturn []slog.Attr{\n\t\tslog.Group(\"app\",\n\t\t\tslog.String(\"name\", build.Info.Project),\n\t\t\tslog.String(\"repo\", build.Info.Repository),\n\t\t\tslog.String(\"version\", build.Info.Version),\n\t\t),\n\t}\n}\n\n// slogReplaceAttr adjusts the log output.\n//\n// - Restricts these changes to top-level keys (not keys within groups)\n//   - Changes default time field value to UTC time zone\n//   - Replaces msg key with event\n//   - Omits event field if empty\n//   - Omits error field if when nil\n//   - Truncates source's filename to project directory\n//\n// See https://pkg.go.dev/log/slog#HandlerOptions.ReplaceAttr\n// N.B: TextHandler manages quoting attribute values as necessary.\nfunc slogReplaceAttr(groups []string, a slog.Attr) slog.Attr {\n\t// Limit application of these rules only to top-level keys\n\tif len(groups) == 0 {\n\t\t// Set time zone to UTC\n\t\tif a.Key == slog.TimeKey {\n\t\t\ta.Value = slog.TimeValue(a.Value.Time().UTC())\n\t\t\treturn a\n\t\t}\n\t\t// Use event as the default MessageKey, remove if empty\n\t\tif a.Key == slog.MessageKey {\n\t\t\ta.Key = \"event\"\n\t\t\tif a.Value.String() == \"\" {\n\t\t\t\treturn slog.Attr{}\n\t\t\t}\n\t\t\treturn a\n\t\t}\n\t\t// Display a 'partial' path.\n\t\t// Avoids ambiguity when multiple files have the same name across packages.\n\t\tif a.Key == slog.SourceKey {\n\t\t\tif source, ok := a.Value.Any().(*slog.Source); ok {\n\t\t\t\ta.Key = \"caller\"\n\t\t\t\tif _, after, ok := strings.Cut(source.File, \"ascerta\"+string(filepath.Separator)); ok {\n\t\t\t\t\tsource.File = after\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\t// Remove error key=value when error is nil\n\tif a.Equal(slog.Any(\"error\", error(nil))) {\n\t\treturn slog.Attr{}\n\t}\n\n\t// Present durations and delays etc as milliseconds\n\tswitch a.Key {\n\tcase \"dur\", \"delay\", \"p95\", \"previous_p95\", \"remaining\", \"max_wait\":\n\t\ta.Value = slog.Float64Value(a.Value.Duration().Seconds() * 1000) //nolint:mnd\n\t}\n\n\treturn a\n}\npackage log\n\nimport (\n\t\"bytes\"\n\t\"context\"\n\t\"encoding/json\"\n\t\"log/slog\"\n\t\"path/filepath\"\n\t\"strings\"\n\t\"testing\"\n\t\"time\"\n)\n\nfunc TestLogger(t *testing.T) {\n\tbuf := new(bytes.Buffer)\n\tl := NewWithOutput(buf)\n\n\ttype App struct {\n\t\tName    string `json:\"name\"`\n\t\tVersion string `json:\"version\"`\n\t}\n\n\ttype Caller struct {\n\t\tFunction string `json:\"function\"`\n\t\tFile     string `json:\"file\"`\n\t\tLine     int    `json:\"line\"`\n\t}\n\n\ttype log struct {\n\t\tTime      string  `json:\"time\"`\n\t\tLevel     string  `json:\"level\"`\n\t\tCaller    Caller  `json:\"caller\"`\n\t\tEvent     string  `json:\"event\"`\n\t\tApp       App     `json:\"app\"`\n\t\tError     string  `json:\"error\"`\n\t\tDur       float64 `json:\"dur\"`\n\t\tDelay     float64 `json:\"delay\"`\n\t\tP95       float64 `json:\"p95\"`\n\t\tPrevP95   float64 `json:\"previous_p95\"`\n\t\tRemaining float64 `json:\"remaining\"`\n\t\tMaxWait   float64 `json:\"max_wait\"`\n\t}\n\n\tt.Run(\"has expected fields\", func(t *testing.T) {\n\t\tdumpLogs(t, buf)\n\t\tl.LogAttrs(context.Background(), slog.LevelInfo, \"testing\")\n\t\tvar data log\n\t\t_ = json.Unmarshal(buf.Bytes(), \u0026data)\n\t\tif data.Time == \"\" {\n\t\t\tt.Error(\"missing field: time\")\n\t\t}\n\t})\n\n\tt.Run(\"outputs debug at LevelDebug\", func(t *testing.T) {\n\t\tLevel.Set(slog.LevelDebug)                                   // change for test\n\t\tdefer func(lvl slog.Level) { Level.Set(lvl) }(Level.Level()) // ensure reset to default\n\n\t\tdumpLogs(t, buf)\n\t\tctx := context.Background()\n\t\tl.LogAttrs(ctx, slog.LevelDebug, \"\")\n\n\t\tvar data log\n\t\t_ = json.Unmarshal(buf.Bytes(), \u0026data)\n\t\tif data.Level != \"DEBUG\" {\n\t\t\tt.Error(\"missing level=DEBUG\")\n\t\t}\n\t})\n\n\tt.Run(\"elides empty event message\", func(t *testing.T) {\n\t\tdumpLogs(t, buf)\n\t\tl.LogAttrs(context.Background(), slog.LevelInfo, \"\")\n\t\tvar data log\n\t\t_ = json.Unmarshal(buf.Bytes(), \u0026data)\n\t\tif data.Event != \"\" {\n\t\t\tt.Error(\"log should not contain an event\")\n\t\t}\n\t})\n\n\tt.Run(\"elides empty error\", func(t *testing.T) {\n\t\tdumpLogs(t, buf)\n\t\tl.LogAttrs(context.Background(), slog.LevelInfo, \"test message\", slog.Any(\"error\", nil))\n\t\tvar data log\n\t\t_ = json.Unmarshal(buf.Bytes(), \u0026data)\n\t\tif data.Error != \"\" {\n\t\t\tt.Error(\"log should not contain an empty error\")\n\t\t}\n\t})\n\n\tt.Run(\"uses UTC time zone\", func(t *testing.T) {\n\t\tdumpLogs(t, buf)\n\t\tl.LogAttrs(context.Background(), slog.LevelInfo, \"UTC\")\n\n\t\tvar data log\n\t\t_ = json.Unmarshal(buf.Bytes(), \u0026data)\n\n\t\tp, err := time.Parse(time.RFC3339, data.Time)\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"time field failed to parse: %s\", err)\n\t\t}\n\t\tif z, _ := p.Zone(); z != time.UTC.String() {\n\t\t\tt.Errorf(\"expected time in UTC zone, got %s\", z)\n\t\t}\n\t})\n\n\tt.Run(\"uses shorter source location\", func(t *testing.T) {\n\t\tdumpLogs(t, buf)\n\t\tl.LogAttrs(context.Background(), slog.LevelInfo, \"source -\u003e caller test\")\n\n\t\tvar data log\n\t\t_ = json.Unmarshal(buf.Bytes(), \u0026data)\n\n\t\t// slogReplaceAttr replaces the top-level key \"source\" with \"caller\"\n\t\t// IMPORTANT: the name of the repo is hard-coded into the slogReplaceAttr logic\n\t\tif data.Caller.File == \"\" {\n\t\t\tt.Error(\"field not found\")\n\t\t}\n\t\tif strings.HasPrefix(data.Caller.File, string(filepath.Separator)) {\n\t\t\tt.Errorf(\"caller includes full path: %s\", data.Caller.File)\n\t\t}\n\t})\n\n\tt.Run(\"displays milliseconds\", func(t *testing.T) {\n\t\tdumpLogs(t, buf)\n\t\tconst ts = 1234567890\n\t\tl.LogAttrs(context.Background(), slog.LevelInfo, \"\",\n\t\t\tslog.Duration(\"dur\", ts),\n\t\t\tslog.Duration(\"delay\", ts),\n\t\t\tslog.Duration(\"p95\", ts),\n\t\t\tslog.Duration(\"previous_p95\", ts),\n\t\t\tslog.Duration(\"remaining\", ts),\n\t\t\tslog.Duration(\"max_wait\", ts),\n\t\t)\n\n\t\tvar data log\n\t\t_ = json.Unmarshal(buf.Bytes(), \u0026data)\n\n\t\twant := 1234.56789\n\t\tif data.Dur != want || data.Delay != want || data.P95 != want || data.PrevP95 != want || data.Remaining != want || data.MaxWait != want {\n\t\t\tt.Errorf(\"log should contain: %f\", want)\n\t\t}\n\t})\n}\n\nfunc dumpLogs(t *testing.T, buf *bytes.Buffer) {\n\tt.Helper()\n\tt.Cleanup(func() {\n\t\tt.Helper()\n\t\tif t.Failed() || testing.Verbose() {\n\t\t\tt.Log(\"Logs:\\n\", buf.String())\n\t\t}\n\t\tbuf.Reset()\n\t})\n}\nenableAllRules = true\n\n# DISABLED RULES\n\n[rule.add-constant]\ndisabled = true\n\n[rule.cognitive-complexity]\ndisabled = true\n\n[rule.cyclomatic]\ndisabled = true\n\n[rule.line-length-limit]\ndisabled = true\n\n[rule.max-public-structs]\ndisabled = true\n\n[rule.unused-receiver]\ndisabled = true\n\n# ACTIVE RULES\n\n[rule.argument-limit]\nseverity = \"warning\"\narguments = [6]\n\n[rule.atomic]\nseverity = \"warning\"\n\n[rule.bare-return]\nseverity = \"warning\"\n\n[rule.bool-literal-in-expr]\nseverity = \"warning\"\n\n[rule.comment-spacings]\narguments = [\"nolint:\", \"lint:ignore\", \"exhaustive:ignore\", \"codespell:ignore\"]\n\n[rule.confusing-naming]\nseverity = \"warning\"\n\n[rule.confusing-results]\nseverity = \"warning\"\n\n[rule.constant-logical-expr]\nseverity = \"error\"\n\n[rule.context-as-argument]\nseverity = \"error\"\n\n[rule.context-keys-type]\nseverity = \"error\"\n\n[rule.deep-exit]\nseverity = \"warning\"\n\n[rule.defer]\nseverity = \"warning\"\n\n[rule.early-return]\nseverity = \"warning\"\n\n[rule.empty-block]\nseverity = \"error\"\n\n[rule.empty-lines]\nseverity = \"warning\"\n\n[rule.error-naming]\nseverity = \"error\"\n\n[rule.error-return]\nseverity = \"error\"\n\n[rule.error-strings]\nseverity = \"error\"\n\n[rule.errorf]\nseverity = \"warning\"\n\n[rule.exported]\nseverity = \"error\"\n\n[rule.flag-parameter]\nseverity = \"warning\"\n\n[rule.function-result-limit]\nseverity = \"warning\"\narguments = [4]\n\n[rule.function-length]\nseverity = \"warning\"\narguments = [50, 0]\n\n[rule.get-return]\nseverity = \"error\"\n\n[rule.identical-branches]\nseverity = \"error\"\n\n[rule.if-return]\nseverity = \"warning\"\n\n[rule.increment-decrement]\nseverity = \"error\"\n\n[rule.indent-error-flow]\nseverity = \"warning\"\n\n[rule.import-shadowing]\nseverity = \"warning\"\n\n[rule.modifies-parameter]\nseverity = \"warning\"\n\n[rule.modifies-value-receiver]\nseverity = \"warning\"\n\n[rule.nested-structs]\nseverity = \"warning\"\n\n[rule.optimize-operands-order]\nseverity = \"warning\"\n\n[rule.package-comments]\nseverity = \"warning\"\n\n[rule.range]\nseverity = \"warning\"\n\n[rule.range-val-in-closure]\nseverity = \"warning\"\n\n[rule.range-val-address]\nseverity = \"warning\"\n\n[rule.receiver-naming]\nseverity = \"warning\"\n\n[rule.redefines-builtin-id]\nseverity = \"error\"\n\n[rule.string-of-int]\nseverity = \"warning\"\n\n[rule.struct-tag]\nseverity = \"warning\"\n\n[rule.superfluous-else]\nseverity = \"warning\"\n\n[rule.time-equal]\nseverity = \"warning\"\n\n[rule.time-naming]\nseverity = \"warning\"\n\n[rule.var-declaration]\nseverity = \"warning\"\n\n[rule.var-naming]\nseverity = \"warning\"\n\n[rule.unconditional-recursion]\nseverity = \"error\"\n\n[rule.unexported-naming]\nseverity = \"warning\"\n\n[rule.unexported-return]\nseverity = \"error\"\n\n[rule.unhandled-error]\nseverity = \"warning\"\narguments = [\n  \"fmt.Print\",\n  \"fmt.Printf\",\n  \"fmt.Println\",\n  \"fmt.Fprint\",\n  \"fmt.Fprintf\",\n  \"fmt.Fprintln\",\n]\n\n[rule.unnecessary-stmt]\nseverity = \"warning\"\n\n[rule.unreachable-code]\nseverity = \"warning\"\n\n[rule.unused-parameter]\nseverity = \"warning\"\n\n[rule.use-any]\nseverity = \"warning\"\n\n[rule.useless-break]\nseverity = \"warning\"\n\n[rule.waitgroup-by-value]\nseverity = \"warning\"\nmodule github.com/fastly/ascerta/tools\n\ngo 1.24.1\n\ntool (\n\tgithub.com/mgechev/revive\n\tgolang.org/x/lint/golint\n\tgolang.org/x/tools/go/analysis/passes/nilness/cmd/nilness\n\tgolang.org/x/vuln/cmd/govulncheck\n\thonnef.co/go/tools/cmd/staticcheck\n\tmvdan.cc/gofumpt\n)\n\nrequire (\n\tgithub.com/BurntSushi/toml v1.4.1-0.20240526193622-a339e1f7089c // indirect\n\tgithub.com/chavacava/garif v0.1.0 // indirect\n\tgithub.com/fatih/color v1.18.0 // indirect\n\tgithub.com/fatih/structtag v1.2.0 // indirect\n\tgithub.com/google/go-cmp v0.7.0 // indirect\n\tgithub.com/hashicorp/go-version v1.7.0 // indirect\n\tgithub.com/mattn/go-colorable v0.1.14 // indirect\n\tgithub.com/mattn/go-isatty v0.0.20 // indirect\n\tgithub.com/mattn/go-runewidth v0.0.16 // indirect\n\tgithub.com/mgechev/dots v0.0.0-20210922191527-e955255bf517 // indirect\n\tgithub.com/mgechev/revive v1.7.0 // indirect\n\tgithub.com/olekukonko/tablewriter v0.0.5 // indirect\n\tgithub.com/rivo/uniseg v0.4.7 // indirect\n\tgithub.com/spf13/afero v1.14.0 // indirect\n\tgolang.org/x/exp/typeparams v0.0.0-20250305212735-054e65f0b394 // indirect\n\tgolang.org/x/lint v0.0.0-20241112194109-818c5a804067 // indirect\n\tgolang.org/x/mod v0.24.0 // indirect\n\tgolang.org/x/sync v0.12.0 // indirect\n\tgolang.org/x/sys v0.31.0 // indirect\n\tgolang.org/x/telemetry v0.0.0-20250310203348-fdfaad844314 // indirect\n\tgolang.org/x/text v0.23.0 // indirect\n\tgolang.org/x/tools v0.31.0 // indirect\n\tgolang.org/x/vuln v1.1.4 // indirect\n\thonnef.co/go/tools v0.6.1 // indirect\n\tmvdan.cc/gofumpt v0.7.0 // indirect\n)\n```\n.\n├── Makefile\n├── cmd\n│   └── api\n│       └── main.go\n├── go.mod\n├── go.sum\n├── internal\n│   ├── api\n│   │   └── api.go\n│   └── log\n│       ├── log.go\n│       └── log_test.go\n├── revive.toml\n├── tools.mod\n└── tools.sum\n```\n.DEFAULT_GOAL := run  ## Default make target\nTOOLS = \"\"            ## List of dev tools\nTOOLS = \\\n\tgithub.com/mgechev/revive \\\n\tgolang.org/x/lint/golint \\\n\tgolang.org/x/tools/go/analysis/passes/nilness/cmd/nilness \\\n\tgolang.org/x/vuln/cmd/govulncheck \\\n\thonnef.co/go/tools/cmd/staticcheck \\\n\tmvdan.cc/gofumpt\n\n.PHONY: help\nhelp: ## Displays list of Makefile targets and documented variables\n\t@echo \"Targets:\"\n\t@grep -h -E '^[0-9a-zA-Z_.-]+:.*?## .*$$' $(MAKEFILE_LIST) | sort | awk 'BEGIN {FS = \":.*?## \"}; {printf \"  \\033[36m%-20s\\033[0m %s\\n\", $$1, $$2}'\n\t@echo \"\"\n\t@echo \"Variables:\"\n\t@grep -h -E '^[0-9a-zA-Z_.-]+\\s[?:]?=.*?## .*$$' $(MAKEFILE_LIST) | sort | awk 'BEGIN {FS = \"[?:]?=.*?## \"}; {printf \"  \\033[36m%-20s\\033[0m %s\\n\", $$1, $$2}'\n\t@echo \"\"\n\t@echo \"Default target:\"\n\t@printf \"  \\033[36m%s\\033[0m\\n\" $(.DEFAULT_GOAL)\n\n.PHONY: api-update\napi-update: ## Update all API application dependencies\n\tgo get -u -t ./...\n\tgo mod tidy\n\tif [ -d \"vendor\" ]; then go mod vendor; fi\n\n.PHONY: fmt\nfmt: ## Format all Go files using gofumpt\n\tgo tool -modfile=tools.mod gofumpt -w .\n\n.PHONY: lint-all\nlint-all: lint-golint lint-govet lint-govul lint-nilness lint-revive lint-staticcheck ## Lint project using all linters\n\n.PHONY: lint-golint\nlint-golint: ## Lint project using golint\n\tgo tool -modfile=tools.mod golint -set_exit_status $(shell go list -f '{{.Dir}}' ./... )\n\n.PHONY: lint-govet\nlint-govet: ## Lint project using go vet\n\tgo vet ./...\n\n.PHONY: lint-govul\nlint-govul: ## Lint project using govulncheck\n\tgo tool -modfile=tools.mod govulncheck ./...\n\n.PHONY: lint-nilness\nlint-nilness: ## Lint project using nilness\n\tgo tool -modfile=tools.mod nilness ./...\n\n.PHONY: lint-revive\nlint-revive: ## Lint project using revive\n\tgo tool -modfile=tools.mod revive -config revive.toml ./...\n\n.PHONY: lint-staticcheck\nlint-staticcheck: ## Lint project using staticcheck\n\tgo tool -modfile=tools.mod staticcheck ./...\n\n.PHONY: run\nrun: ## Run the API server (opts: HUMANLOG=true)\n\t@# humanlog doesn't sort keys lexicographically.\n\t@# to do that we must set `--sort-longest=false`\n\t@# this causes the key sorting we want (as a side effect)\n\t@# while at the same time avoiding humanlog from trying to sort by key length\n\tgo run ./cmd/api/main.go $(if \\\n\t\t$(filter true,$(HUMANLOG)),| \\\n\t\t\thumanlog \\\n\t\t\t\t--message-fields=event \\\n\t\t\t\t--sort-longest=false \\\n\t\t\t\t--truncate=false, \\\n\t)\n\n.PHONY: test\ntest: ## Run the Go test suite\n\tgo test ./...\n\n.PHONY: tools-install\ntools-install: ## Install dev tools\n\t@if [ ! -f tools.mod ]; then \\\n\t\techo \"Initializing tools.mod\"; \\\n\t\tgo mod init -modfile=tools.mod github.com/fastly/ascerta/tools; \\\n\tfi\n\t@$(foreach tool,$(TOOLS), \\\n\t\tif ! go tool -modfile=tools.mod | grep \"$(tool)\" \u003e/dev/null; then \\\n\t\t\techo \"installing $(tool)\"; \\\n\t\t\tgo get -modfile=tools.mod -tool \"$(tool)\"@latest; \\\n\t\tfi; \\\n\t)\n\t@[ -x \"$(shell which humanlog)\" ] || curl -sSL \"https://humanlog.io/install.sh\" | NONINTERACTIVE=true bash\n\n.PHONY: tools-update\ntools-update: ## Update dev tools\n\tgo get -u -modfile=tools.mod tool\n\tgo mod tidy\n\n# checkmake (https://github.com/mrtazz/checkmake) requires these targets be set\n.PHONY: all clean test\n// Package api contains code for running an API server.\npackage api\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"log/slog\"\n\t\"net/http\"\n\t\"os\"\n\t\"os/signal\"\n\t\"syscall\"\n\t\"time\"\n)\n\nconst (\n\tapiPort         = \":8080\"\n\tapiReadTimeout  = time.Duration(5) * time.Second\n\tapiWriteTimeout = time.Duration(5) * time.Second\n)\n\n// Run starts the API.\nfunc Run(l *slog.Logger) error {\n\tctx := context.Background()\n\n\ts := http.Server{\n\t\tAddr:         apiPort,\n\t\tReadTimeout:  apiReadTimeout,\n\t\tWriteTimeout: apiWriteTimeout,\n\t}\n\n\tquit := make(chan os.Signal, 1)\n\tsignal.Notify(quit, syscall.SIGINT, syscall.SIGTERM)\n\n\tgo func() {\n\t\tsignalType := \u003c-quit\n\t\tl.LogAttrs(ctx, slog.LevelWarn, \"api_shutdown\", slog.String(\"signal\", signalType.String()))\n\n\t\tif err := s.Shutdown(context.Background()); err != nil { // nolint:contextcheck // we use a separate context to avoid cancellation\n\t\t\terr := fmt.Errorf(\"unable to gracefully stop API server: %w\", err)\n\t\t\tl.LogAttrs(ctx, slog.LevelError, \"api_shutdown\", slog.Any(\"error\", err))\n\t\t}\n\t}()\n\n\tif err := s.ListenAndServe(); err != nil {\n\t\terr := fmt.Errorf(\"api server failed to listen and serve requests: %w\", err)\n\t\tl.LogAttrs(ctx, slog.LevelError, \"api_serve\", slog.Any(\"error\", err))\n\t\treturn err\n\t}\n\n\treturn nil\n}\n","tags":"#go #project"},{"id":"620ec233247a6eff8061e38be53ada46","title":"Go: Serialize and Deserialize types using gob ","content":"// Package gob manages streams of gobs - binary values exchanged between an Encoder\n// (transmitter) and a Decoder (receiver).\npackage main\n\nimport (\n\t\"bytes\"\n\t\"encoding/gob\"\n\t\"fmt\"\n\t\"log\"\n)\n\ntype Person struct {\n\tName    string\n\tAge     int\n\tAddress Address\n}\n\ntype Address struct {\n\tStreet string\n\tCity   string\n}\n\nfunc main() {\n\t// Original Person object\n\toriginalPerson := Person{\n\t\tName: \"Alice\",\n\t\tAge:  30,\n\t\tAddress: Address{\n\t\t\tStreet: \"123 Main St\",\n\t\t\tCity:   \"Anytown\",\n\t\t},\n\t}\n\n\t// 1. Serialization (Gob Encoding)\n\tvar buf bytes.Buffer\n\tenc := gob.NewEncoder(\u0026buf)\n\terr := enc.Encode(originalPerson)\n\tif err != nil {\n\t\tlog.Fatalf(\"Gob encode error: %v\", err)\n\t}\n\n\t// 2. Deserialization (Gob Decoding)\n\tvar decodedPerson Person\n\tdec := gob.NewDecoder(\u0026buf)\n\terr = dec.Decode(\u0026decodedPerson)\n\tif err != nil {\n\t\tlog.Fatalf(\"Gob decode error: %v\", err)\n\t}\n\n\t// Verify the decoded object\n\tfmt.Printf(\"Original Person: %+v\\n\", originalPerson)\n\tfmt.Printf(\"Decoded Person:  %+v\\n\", decodedPerson)\n\n\t//Check that the two objects are identical\n\tif originalPerson == decodedPerson {\n\t\tfmt.Println(\"The objects are identical.\")\n\t} else {\n\t\tfmt.Println(\"The objects are different.\")\n\t}\n}\n","tags":"#go #serialization"},{"id":"3af3a4bfa038ed873c168709240e7213","title":"Well-Known URIs ","content":"`.well-known` is a standardized path on a website's root domain that allows services to access metadata and configurations related to that domain. It's defined by [RFC 5785].\n\nThe IANA (Internet Assigned Numbers Authority) maintains a registry of [well-known URIs][wellknown], ensuring that these paths are standardized and avoid conflicts.\n\n[rfc 5785]: https://datatracker.ietf.org/doc/html/rfc5785\n[wellknown]: https://www.iana.org/assignments/well-known-uris/well-known-uris.xhtml\n","tags":"#IANA #Well-Known"},{"id":"df7998f8f7e5ad2aaf7d50f762a82818","title":"Go: Exponential Backoff ","content":"package main\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"fmt\"\n\t\"math\"\n\t\"time\"\n)\n\nfunc main() {\n\tif err := doSomething(); err != nil {\n\t\tfmt.Println(\"there was an error:\", err)\n\t}\n}\n\nfunc doSomething() error {\n\tctx, cancel := context.WithTimeout(context.Background(), 3*time.Second)\n\tdefer cancel()\n\tvar (\n\t\t// initialBackoff is the initial backoff used for exponential backoff\n\t\tinitialBackoff = 100 * time.Millisecond\n\t\t// is the maximum value to use for exponential backoff\n\t\tmaxBackoff = 500 * time.Millisecond\n\t\t// maxRetries is the number of retries\n\t\tmaxRetries = 3\n\t)\n\tfor attempt := range maxRetries {\n\t\t// exponential backoff\n\t\tbackoff := time.Duration(math.Pow(2, float64(attempt+1))) * initialBackoff\n\t\tif backoff \u003e maxBackoff {\n\t\t\tbackoff = maxBackoff\n\t\t}\n\t\tfmt.Println(backoff)\n\n\t\tselect {\n\t\tcase \u003c-ctx.Done():\n\t\t\treturn errors.New(\"whoops: timeout\")\n\t\tcase \u003c-time.After(backoff):\n\t\t\t// continue\n\t\t}\n\t}\n\treturn errors.New(\"unable to perform the task, max retries exceeded\")\n}\n\n// Alternative implementation\n\nfunc (s *service) CreateVersion(ctx context.Context, customerID, configID string, cloneVersion *int, comment string) (*ConfigVersion, error) {\n      const maxRetries = 3\n\n      for attempt := 0; attempt \u003c maxRetries; attempt++ {\n          version, err := s.createVersionAttempt(ctx, customerID, configID, cloneVersion, comment)\n          if err == nil {\n              return version, nil\n          }\n\n          // Retry only on duplicate errors (race condition)\n          if !errors.Is(err, errorsx.ErrDuplicate) {\n              return nil, err\n          }\n\n          // Exponential backoff: 10ms, 20ms, 40ms\n          backoff := time.Duration(10 * (1 \u003c\u003c attempt)) * time.Millisecond\n          time.Sleep(backoff)\n      }\n\n      return nil, fmt.Errorf(\"failed to create version after %d attempts: %w\", maxRetries, errorsx.ErrDuplicate)\n}\n","tags":"#go #backoff #retry #resilience"},{"id":"bfcad74c66dfa1e8eb5e2c07b13811df","title":"Project Planning ","content":"There are three types of documents you should write, in this specific order:\n\n1. **Project** document\n2. **Discovery** document (inc. matrix** for possible solutions)\n3. **Design** document\n\n\u003e [!TIP] \n\u003e ** Have \"use cases\" down the left side, and \"approaches\" across the top row.\\\n\u003e Then each cell describes how the approach affects the use case.\\\n\u003e Use cases should include how users want to work (UI, CLI, TF).\\\n\u003e Once you've had time refining the data, reorder the use cases and approaches.\\\n\u003e This is so the most relevant data is closest to the start/top.\n\nA \"project\" document is for planning the overarching/broader project work.\\\nIt's responsible for breaking down the project into smaller milestones.\n\nA \"discovery\" document is for _discovering_ how we'll solve ONE of the milestones defined in the project document.\n\nA \"design\" document describes our design plan for what we're going to build from the discovery document.\\\nIt will be presented to lead engineers (and architects) to review and approve.\n\n\u003e [!TIP]\n\u003e Also read:\\\n\u003e https://www.integralist.co.uk/posts/project-management/\n\n## Project Document\n\n- **Preliminary Milestones:** This describes significant ‘stages’ in the project's timeline and serves as markers of progress.\n- **Key Objectives:** This describes the high-level outcomes that are desired.\n- **Current Architecture:** Visualise the architecture at a high-level.\n- **Proposed Architecture:** Visualise the new architecture at a high-level.\n- **Design Benefits:** \n- **Functional Requirements:** This defines the specific _behaviors_, _actions_, or _functions_ that the software must perform.\n- **Non-functional Requirements:** This describes the _characteristics_ of the system (e.g. performance, security, reliability etc).\n- **Miscellaneous:** This section includes miscellaneous documents and links relevant to the overall discussion.\n\n## Discovery Document\n\nThis document presents an objective assessment of the existing system's requirements and deficiencies (for a specific milestone that was defined in the project document), and proposes a high-level approach that will inform the creation of a more detailed design document.\n\n\u003e [!IMPORTANT]\n\u003e No implementation details at this point!\n\n- **Glossary:** Make sure everyone is on the same page as to what certain words mean.\n- **Customer Abstraction:** What the customer perceives is happening. It’s what they buy/use/derive value from.\n- **Description:** What is the current situation and what are the concerns?\n- **Problem:** What are the underlying problems contributing to this situation?\n- **Approach:** What will be our approach to resolve these issues?\n- **Business Outcomes:** The desired, measurable results of this project that directly benefit the business.\n\n## Design Document\n\n- **Goals:** What specifically are we trying to accomplish? By when? Are there guiding principles to follow?\n- **Requirements:** Include any technical (storage, accessibility, latency/speed, monitoring \u0026 alerting), security, compliance or Product-requested deliverables.\n- **Out of Scope (Non-Goals):** What are we thoughtfully and purposefully excluding from this project?\n- **Success metrics:** How will we know when the project is done? Include any timelines to meet.\n- **Proposed Design:** How are we proposing to solve the problems: what are we doing, what systems will change?\n- **Rationale:** Why did we choose this approach? This should include a link to [a matrix spreadsheet](https://docs.google.com/spreadsheets/d/1ZnxIY4BCnsUaY65Cc2GCmzmq18XBJvG2iErSWfMjW10/edit?usp=sharing).\n- **Interactions with existing systems:** What systems/components are available to build from or interact with? Are there relationships to common Fastly architecture principles?\n- **Resources:** What resources do we need for this proposed design? Are there licenses, versions, hardware, specific expertise and training,etc to include?\n- **Development Stages:** Identify the implementation stages of the project, so people understand what roll out looks like and how it will be approached.\n- **Alternatives considered:** Describe other options considered and trade off/decisions for not doing.\n- **Considerations, Risks or Constraints:** Add any special considerations, risks, or constraints. \n- **Open Questions:** Note anything for further investigation or future problems to solve (create action items and assign for follow-up if needed).\n- **Stakeholders \u0026 Approval:** Primary stakeholders listed check the box to indicate sign-off or add comments with questions/concerns.\n- **References:** Include any links to related documents: Problem Statement, PRD, POC proposals, boards or architecture documentation for additional context.\n","tags":"#project #architecture #design #planning"},{"id":"49d86970ed78cfaddfffc59754ce6c4b","title":"Improving dig output ","content":"## Outcome\n\n\u003cimg width=\"691\" alt=\"Screenshot 2025-03-12 at 16 31 37\" src=\"https://gist.github.com/user-attachments/assets/7f884893-160d-4cb9-bab3-d871e8e131b1\" /\u003e\n\n## Implementation\n\n```shell\n# digg adds colors to the standard dig output to improve readability while not losing contextual information.\n#\nDIG_COMMENT_COLOR_SINGLE=\"\\e[38;5;8m\"  # Dark grey text, no background, no bold\nDIG_COMMENT_COLOR_DOUBLE=\"\\e[48;5;88m\\e[1;37m\" # Dark red background, bold white text\nDIG_RESET_COLOR=\"\\e[0m\"\ndigg() {\n\tlocal domain=\"$1\"\n\tlocal record=\"${2:-A}\"\n\tlocal dig_output=$(dig \"$domain\" \"$record\")\n\tlocal question_section_found=0\n\n\twhile IFS= read -r line; do\n\t\tif [[ \"$line\" == \";\"* ]]; then\n\t\t\tif [[ \"$line\" == \";;\"* ]]; then\n\t\t\t\tif [[ \"$line\" == *' SECTION:'* ]]; then\n\t\t\t\t\tif [[ \"$line\" == *'QUESTION SECTION:'* ]]; then\n\t\t\t\t\t\tquestion_section_found=1;\n\t\t\t\t\t\techo \"\"\n\t\t\t\t\tfi\n\t\t\t\t\techo -e \"${DIG_COMMENT_COLOR_DOUBLE}${line#';;'} ${DIG_RESET_COLOR}\"\n\t\t\t\telse\n\t\t\t\t\techo -e \"${DIG_COMMENT_COLOR_SINGLE}${line#';;'} ${DIG_RESET_COLOR}\"\n\t\t\t\tfi\n\t\t\telse\n\t\t\t\tif [[ \"$question_section_found\" -eq 1 ]]; then\n\t\t\t\t\techo \"${line#';'}\";\n\t\t\t\t\tquestion_section_found=0;\n\t\t\t\telse\n\t\t\t\t\techo -e \"${DIG_COMMENT_COLOR_SINGLE}${line#';'}${DIG_RESET_COLOR}\"\n\t\t\t\tfi\n\t\t\tfi\n\t\telse\n\t\t\techo \"$line\";\n\t\tfi\n\tdone \u003c\u003c\u003c \"$dig_output\"\n}\n```\n","tags":"#dns #dig #bash #shell"},{"id":"c3f14bc015191fba900da446a541f2a8","title":"DNS: Lookup of Host information ","content":"$ dig www.integralist.co.uk +noall +answer\n\n; \u003c\u003c\u003e\u003e DiG 9.10.6 \u003c\u003c\u003e\u003e www.integralist.co.uk +noall +answer\n;; global options: +cmd\nwww.integralist.co.uk.  14400   IN      CNAME   dreamy-wing-b0b998.netlify.com.\ndreamy-wing-b0b998.netlify.com. 120 IN  A       3.75.10.80\ndreamy-wing-b0b998.netlify.com. 120 IN  A       3.125.36.175\n\n$ curl -so /dev/null -D - https://dreamy-wing-b0b998.netlify.com\n\nHTTP/2 404\ncache-control: private, max-age=0\ncontent-type: text/plain; charset=utf-8\ndate: Thu, 13 Feb 2025 11:36:28 GMT\nserver: Netlify\nstrict-transport-security: max-age=31536000; includeSubDomains; preload\nx-nf-request-id: 01JKZHH4RJB03HFXC1XGH9AKKM\ncontent-length: 50\n\n$ curl -so /dev/null -H Host:www.integralist.co.uk -D - https://dreamy-wing-b0b998.netlify.com\n\nHTTP/2 200\naccept-ranges: bytes\nage: 0\ncache-control: public,max-age=0,must-revalidate\ncache-status: \"Netlify Edge\"; fwd=miss\ncontent-type: text/html; charset=UTF-8\ndate: Thu, 13 Feb 2025 11:40:56 GMT\netag: \"73dd185071271fad04cb81c48e5155ef-ssl\"\nserver: Netlify\nstrict-transport-security: max-age=31536000\nx-nf-request-id: 01JKZHSAV7X773C1W8BJ2WENTH\ncontent-length: 36094\n\n$ curl -so /dev/null -H Host:www.integralist.co.uk -D - 3.75.10.80\n\nHTTP/1.1 301 Moved Permanently\nContent-Type: text/plain; charset=utf-8\nDate: Thu, 13 Feb 2025 11:36:58 GMT\nLocation: https://www.integralist.co.uk/\nServer: Netlify\nX-Nf-Request-Id: 01JKZHJ2ADYPWA1K54BDRMHZBN\nContent-Length: 45\n\n$ curl -so /dev/null -D - https://dreamy-wing-b0b998.netlify.app\n\nHTTP/2 200\naccept-ranges: bytes\nage: 26\ncache-control: public,max-age=0,must-revalidate\ncache-status: \"Netlify Edge\"; hit\ncontent-type: text/html; charset=UTF-8\ndate: Thu, 13 Feb 2025 11:36:33 GMT\netag: \"73dd185071271fad04cb81c48e5155ef-ssl\"\nlink: \u003chttps://www.integralist.co.uk/\u003e; rel=\"canonical\"\nserver: Netlify\nstrict-transport-security: max-age=31536000; includeSubDomains; preload\nx-nf-request-id: 01JKZHHA268JB2H2TC47AAND8E\ncontent-length: 36094\n","tags":"#dns #lookup #host"},{"id":"425a2a001c5bd51d06e10247739e7c13","title":"Go: Generate UML ","content":"# install dependencies\nbrew install graphviz plantuml librsvg\n\n# generate puml file for entire project\ngo run github.com/jfeliu007/goplantuml/cmd/goplantuml@latest -recursive ./ \u003e Example.puml\n\n# generate SVG from entire project\nplantuml Example.puml -o \"$pwd\" -tsvg\n\n# convert SVG into a PDF\nrsvg-convert Example.svg -f pdf -o Example.pdf\n","tags":"#go #uml #design #architecture #diagram"},{"id":"39d50ffcf72cc9efa5874468871da722","title":"Go: Ring Buffers ","content":"## What's a ring buffer?\n\nRing buffers are known by a few names, such as circular queues and circular buffers.\n\nA ring buffer is a fixed-size, circular data structure that overwrites the oldest data when the buffer is full. It’s particularly useful for scenarios where you want to store and retrieve data in a FIFO (First-In-First-Out) manner but with limited memory. When the buffer reaches its size limit, new data will overwrite the oldest data.\n\nInstead of adding on the end and popping from the end, like a stack, you can add to one end and remove from the start, like a queue. And as you add or remove things, the _start_ and _end_ pointers move around. By managing these pointers, a ring buffer naturally enforces the FIFO order.\n\n## What's the benefit?\n\nA ring buffer lets us keep a fixed number of elements in the buffer without running into reallocation. \n\nIn a regular old buffer, if you use it as a queue—add to the end, remove from the front—then you'll eventually need to either reallocate the entire thing or shift all the elements over. \n\nInstead, a ring buffer lets you just keep adding from either end and removing from either end and you never have to reallocate!\n\n## Algorithm\n\n- We start with an empty buffer. \n- The `start` and `end` markers both point at the first element. \n\n\n```\n  START\n  ▿\n| _ | _ | _ | _ | _ |\n  ▵\n  END\n```\n\n- When `start == end`, we know the buffer is empty.\n- If we insert an element, we move `end` forward.\n\n```\n  START\n  ▿\n| A | _ | _ | _ | _ |\n      ▵\n      END\n      \n\n  START\n  ▿\n| A | B | C | _ | _ |\n              ▵\n              END\n```\n\n- If we remove an element (`\u003cX\u003e`), we move `start` forward.\n\n```\n        START\n        ▿\n| \u003cX\u003e | B | C | _ | _ |\n                ▵\n                END\n```\n\n- We can also have `start` point at any part of the buffer, and it crosses over the `end` gracefully.\n\n\n```\n              START\n              ▿\n| A | B | C | D | E |\n      ▵\n      END\n```\n\n## Implementations\n\nHere are some Go packages that implement a ring buffer:\\\nhttps://github.com/search?q=lang%3AGo+ring+buffer\u0026type=repositories\u0026s=stars\u0026o=desc\n\nWhen I last checked https://github.com/smallnest/ringbuffer seemed like a good option.\n\nHere's a custom option written by:\\\nhttps://medium.com/checker-engineering/a-practical-guide-to-implementing-a-generic-ring-buffer-in-go-866d27ec1a05\n\n```go\npackage main\n\nimport (\n\t\"fmt\"\n\t\"log\"\n\t\"reflect\"\n\t\"sync\"\n)\n\nfunc main() {\n\tringBuffer := NewRingBuffer[int](5)\n\tringBuffer.Add(1)\n\tringBuffer.Add(2)\n\tringBuffer.Add(3)\n\n\texpected := []int{1, 2, 3}\n\tactual := ringBuffer.Get()\n\tif !reflect.DeepEqual(actual, expected) {\n\t\tlog.Fatalf(\"Expected %v, but got %v\", expected, actual)\n\t}\n\n\tringBuffer.Add(4)\n\tringBuffer.Add(5)\n\tringBuffer.Add(6)\n\n\texpected = []int{2, 3, 4, 5, 6}\n\tactual = ringBuffer.Get()\n\tif !reflect.DeepEqual(actual, expected) {\n\t\tlog.Fatalf(\"Expected %v, but got %v\", expected, actual)\n\t}\n\n\tringBuffer.Add(7)\n\tringBuffer.Add(8)\n\n\texpected = []int{4, 5, 6, 7, 8}\n\tactual = ringBuffer.Get()\n\tif !reflect.DeepEqual(actual, expected) {\n\t\tlog.Fatalf(\"Expected %v, but got %v\", expected, actual)\n\t}\n\n\tfmt.Printf(\"ring buffer: %#v\\n\", ringBuffer)\n}\n\ntype RingBuffer[T any] struct {\n\tbuffer []T\n\tsize   int\n\tmu     sync.Mutex\n\twrite  int\n\tcount  int\n}\n\n// NewRingBuffer creates a new ring buffer with a fixed size.\nfunc NewRingBuffer[T any](size int) *RingBuffer[T] {\n\treturn \u0026RingBuffer[T]{\n\t\tbuffer: make([]T, size),\n\t\tsize:   size,\n\t}\n}\n\n// Add inserts a new element into the buffer, overwriting the oldest if full.\nfunc (rb *RingBuffer[T]) Add(value T) {\n\trb.mu.Lock()\n\tdefer rb.mu.Unlock()\n\n\trb.buffer[rb.write] = value\n\trb.write = (rb.write + 1) % rb.size\n\n\tif rb.count \u003c rb.size {\n\t\trb.count++\n\t}\n}\n\n// Get returns the contents of the buffer in FIFO order.\nfunc (rb *RingBuffer[T]) Get() []T {\n\trb.mu.Lock()\n\tdefer rb.mu.Unlock()\n\n\tresult := make([]T, 0, rb.count)\n\n\tfor i := 0; i \u003c rb.count; i++ {\n\t\tindex := (rb.write + rb.size - rb.count + i) % rb.size\n\t\tresult = append(result, rb.buffer[index])\n\t}\n\n\treturn result\n}\n\n// Len returns the current number of elements in the buffer.\nfunc (rb *RingBuffer[T]) Len() int {\n\trb.mu.Lock()\n\tdefer rb.mu.Unlock()\n\treturn rb.count\n}\n```\n","tags":"#go #ring #circular #queue"},{"id":"52f5787154bf516628c8777dc3455a99","title":"Bash: Update same line for progress bar reporting ","content":"echo -ne \"Getting the TLS entries from 1Password... ⌛\\r\"\nsleep 2  # Simulate some processing\necho -ne \"Getting the TLS entries from 1Password... ✅\\n\"\n\n# -n prevents echo from automatically adding a newline.\n# -e enables interpretation of escape sequences like \\r (carriage return).\n# \\r moves the cursor back to the start of the line, so the next echo overwrites it.\n# The final \\n ensures the cursor moves to a new line after displaying the ✅.\n","tags":"#bash #shell #progress"},{"id":"5a89113b6c88a61b3841fc468b49b8cc","title":"Math: How to identify a number","content":"Here is how a number is divided up...\n\n![](https://www.integralist.co.uk/assets/images/base-10-system.png)\n\nSo how do we identify large numbers?\n\nThe \"trick\" is to always group the digits in threes from right to left, starting with the smallest unit (ones). \n\n**Here's how it works:**\n\n- If the number has more than three digits, you add commas every three digits as you move left.\n- If the number has three digits or fewer, there’s no need for commas since it’s already easy to read.\n\n**Examples:**\n\n- 123 → No comma needed, already 3 digits\n  - i.e. one hundred and twenty three.\n  - The 1 is 'hundreds', 2 is 'tens', 3 is 'ones'.\n\n- 1,234 → Four digits, so we group into 1,234.\n  - i.e. one thousand, two hundred and thirty four.\n  - The 1 is 'thousands', 2 is 'hundreds', 3 is 'tens', 4 is 'ones'.\n  \n- 12,345 → Five digits, so we group into 12,345.\n  - i.e. twelve thousand, three hundred and fourty five.\n  - The 12 is 'thousands', 3 is 'hundreds', 4 is 'tens', 5 is 'ones'.\n\n- 123,456 → Six digits, grouped as 123,456.\n  - i.e. one hound and twenty three thousand, four hundred and fifty six.\n  - The 123 is 'thousands', 4 is 'hundreds', 5 is 'tens', 6 is 'ones'.\n\n- 1,234,567 → Seven digits, grouped as 1,234,567.\n  - i.e. one million, two hundred and thirty four thousand, five hundred and sixty seven.\n  - The 1 is 'millions', 234 is 'thousands', 5 is 'hundreds', 6 is 'tens', 7 is 'ones'.\n","tags":""},{"id":"cf0bc36e17d8c28b04c6e7c5d5566e10","title":"Go: go work ","content":"Create a new directory for your project.\n\nInside the directory `git clone` your projects.\n\nNext, from within the project directory (where the individual projects are cloned _within_), create your `go.work` file.\n\nYou can do this in one of two ways:\n\n```shell\ngo work init ./cli ./go-fastly\n```\n\nor\n\n```shell\ngo work init \ngo work use ./cli ./go-fastly\n```\n\nThe latter is useful for changing the work file after you've started working.\n\nYou should end up with a file tree that looks something like this:\n\n```\n.\n├── cli\n│   ├── go.mod\n├── go-fastly\n│   ├── go.mod\n├── go.work\n├── go.work.sum\n```\n\nNow when you `cd` into one of the project directories (e.g. `cd ./cli`), and `go run` the code, you'll find it auto-magically identifies the dependency (e.g. `./go-fastly`) and uses that instead of trying to pull the remote/real dependency.\n\n\u003e [!WARNING]\n\u003e This causes gopls in Neovim to report an error (although the LSP still works).\\\n\u003e `LSP[gopls]: Error SERVER_REQUEST_HANDLER_ERROR \"... ENOENT: no such file or directory\"`\n","tags":"#go #project"},{"id":"1391150b69eebcaac98984627ba26b7d","title":"xarg: parallel processing ","content":"# update --cursor value to acquire all the relevant domain data (see batch-identify-domains.sh)\nfastly domain-v1 list --fqdn=test-tf --cursor=\u003cREDACTED\u003e --limit=100 --json | jq -r .data[].id \u003e\u003e /tmp/delete-domains\n\n# now delete all those items\ncat /tmp/delete-domains | xargs -P \"$(sysctl -n hw.ncpu)\" -I % fastly domain-v1 delete --domain-id=%\n#!/bin/bash\n\n# Initial cursor value\ncursor=\"\u003cSTARTING CURSOR\u003e\"\noutput_file=\"/tmp/delete-domains\"\n\n# Clear the output file before appending data\n\u003e \"$output_file\"\n\nwhile true; do\n  # Run the command and capture the output\n  response=$(go run ./cmd/fastly/main.go domain-v1 list --fqdn=tf-test --limit=100 --json --cursor=\"$cursor\")\n\n  # Extract IDs and append to the output file\n  echo \"$response\" | jq -r .data[].id \u003e\u003e \"$output_file\"\n\n  # Extract the next cursor value from the JSON response\n  next_cursor=$(echo \"$response\" | jq -r .meta.next_cursor)\n\n  # Check if there is no next cursor (end of pagination)\n  if [[ -z \"$next_cursor\" || \"$next_cursor\" == \"null\" ]]; then\n    echo \"No more data to fetch. Exiting loop.\"\n    break\n  fi\n\n  # Update the cursor for the next iteration\n  cursor=\"$next_cursor\"\n\n  echo \"Fetched batch. Next cursor: $cursor\"\ndone\n\necho \"All data fetched and saved to $output_file.\"\n","tags":"#xarg"},{"id":"228d1c8b0d309a41de67afe09111f4eb","title":"Mermaid Diagram Examples ","content":"https://mermaid.js.org/  \nhttps://mermaid.live/\n\n```mermaid\n---\ntitle: Sequence Diagram example\n---\nsequenceDiagram\n    autonumber\n    participant cl AS Client\n    participant avs AS API VCL Service (Edge)\n    participant dag AS MyApp API Gateway (Edge)\n    participant ag AS Auth Gateway (Control Plane)\n    participant er AS Entity Registry (Control Plane)\n    participant da AS MyApp API (Control Plane)\n    \n    %% below we put a note across MULTIPLE actors\n    note over ag,da: here is my note\n\n    cl-\u003e\u003e+avs: Initial Request\n    avs-\u003e\u003e+dag: Proxy Request\n    alt JWT Expired\n        dag\u003c\u003c--\u003e\u003eag: Exchange API Key for JWT \n    end\n    alt EntityID Not Found\n        dag\u003c\u003c--\u003e\u003eer: Look up EntityId associated with CustomerId\n    end\n    dag-\u003e\u003e+da: Proxy request to Origin\n    da-\u003e\u003e-dag: Origin response\n    dag-\u003e\u003e-avs: Respond to API VCL Service\n    avs-\u003e\u003e-cl: Respond to client\n```\n\n\u003e [!NOTE]\n\u003e The yellow box is rendered by use of `+` and `-` before the target names.\\\n\u003e e.g. `cl-\u003e\u003e+avs: Initial Request` finishes with `avs-\u003e\u003e-cl: Respond to client`\n\n\u003e [!TIP]\n\u003e Use `autonumber` to automatically number lines!\n\n\u003e [!TIP]\n\u003e You can comment out lines using `%%`.\n\n```mermaid\n---\ntitle: Instant Onboarding - API Integration\n---\nsequenceDiagram\n    participant ui AS MyApp UI\n    participant dag AS MyApp API Gateway (Edge)\n    participant da AS MyApp API (Control Plane)\n    participant rd AS Redis (Cache)\n    participant dns AS DNS (Resolution)\n\n    ui-\u003e\u003edag: Initial request\n    note right of ui: GET /internal/domains/v1/tools/lookup/{fqdn}\n    dag-\u003e\u003e+da: Proxy request to the API\n    da-\u003e\u003erd: Lookup domain in cache\n    alt No cache record Found\n        note right of da: Query CNAME and SOA records\n        da\u003c\u003c--\u003e\u003edns: DNS lookup\n    end\n    da-\u003e\u003e-ui: JSON response\n```\n\n\n```mermaid\n---\ntitle: Flowchart example\n---\nflowchart TD\n    A[Christmas] --\u003e|Get money| B(Go shopping)\n    B --\u003e C{Let me think}\n    C --\u003e|One| D[Laptop]\n    C --\u003e|Two| E[iPhone]\n    C --\u003e|Three| F[fa:fa-car Car]\n```\n\n\u003e [!NOTE]\n\u003e `TB` - Top to bottom\\\n\u003e `TD` - Top-down/ same as top to bottom\\\n\u003e `BT` - Bottom to top\\\n\u003e `RL` - Right to left\\\n\u003e `LR` - Left to right\n\n\u003e [!TIP]\n\u003e For a flowchart, you can use either `flowchart` or `graph` (see below for example).\n\n```mermaid\n---\ntitle: DNS CNAME/SOA Lookup Flow\n---\ngraph TD\n    A[Check for CNAME] --\u003e B{CNAME Exists?};\n    B -- Yes --\u003e C[Check SOA of CNAME];\n    B -- No --\u003e D[Check SOA of APEX];\n    C --\u003e E{RNAME and MNAME match?};\n    E -- Yes --\u003e F[Return Hostname];\n    E -- No --\u003e G{Known RNAME match?};\n    G -- Yes --\u003e H[Return RNAME Hostname];\n    G -- No --\u003e I{Known MNAME match?};\n    I -- Yes --\u003e J[Return MNAME Hostname];\n    I -- No --\u003e D;\n    D --\u003e K{RNAME and MNAME match?};\n    K -- Yes --\u003e L[Return Hostname];\n    K -- No --\u003e M{Known RNAME match?};\n    M -- Yes --\u003e N[Return RNAME Hostname];\n    M -- No --\u003e O{Known MNAME match?};\n    O -- Yes --\u003e P[Return MNAME Hostname];\n    O -- No --\u003e Q[Return empty string];\n```\n\n```mermaid\n---\ntitle: Current TLS API Overview\n---\ngraph LR\n    A@{ shape: circle, label: \"Customer\" } --\u003e B(TLS API);\n    B --\u003e C[[Spotless]];\n    C --\u003e D{API Routing};\n    D --\u003e E@{ shape: braces, label: \"Activations\" };\n    D --\u003e F@{ shape: braces, label: \"Bulk\" };\n    D --\u003e G@{ shape: braces, label: \"Certificates\" };\n    D --\u003e H@{ shape: braces, label: \"Configuration\" };\n    D --\u003e I@{ shape: braces, label: \"Domains\" };\n    D --\u003e J@{ shape: braces, label: \"Mutual Authentication\" };\n    D --\u003e K@{ shape: braces, label: \"Private Keys\" };\n    D --\u003e L@{ shape: braces, label: \"Subscriptions\" };\n    L --\u003e M{Certificate Authority CA};\n    M --\u003e N[[Let's Encrypt]]\n    M --\u003e O[[Certainly]]\n    M --\u003e P[[GlobalSign]]\n```\n\n```mermaid\n---\ntitle: Class Diagram example\n---\nclassDiagram\n    note \"From Duck till Zebra\"\n    Animal \u003c|-- Duck\n    note for Duck \"can fly\\ncan swim\\ncan dive\\ncan help in debugging\"\n    Animal \u003c|-- Fish\n    Animal \u003c|-- Zebra\n    Animal : +int age\n    Animal : +String gender\n    Animal: +isMammal()\n    Animal: +mate()\n    class Duck{\n        +String beakColor\n        +swim()\n        +quack()\n    }\n    class Fish{\n        -int sizeInFeet\n        -canEat()\n    }\n    class Zebra{\n        +bool is_wild\n        +run()\n    }\n```\n\n```mermaid\n---\ntitle: State Diagram example\n---\nstateDiagram-v2\n    [*] --\u003e Still\n    Still --\u003e [*]\n\n    Still --\u003e Moving\n    Moving --\u003e Still\n    Moving --\u003e Crash\n    Crash --\u003e [*]\n```\n\n```mermaid\npie title Pie Chart example\n    \"Dogs\" : 386\n    \"Cats\" : 85\n    \"Rats\" : 15\n```\n\n```mermaid\n---\ntitle: API Request Flow\n---\nerDiagram\n    Customer ||--o{ TLSAPI : makes-requests-to\n    TLSAPI ||--o{ SpotlessBackendAPI : communicates-with\n    SpotlessBackendAPI {\n        string API_Routing\n    }\n    SpotlessBackendAPI ||--o{ Activations : routes-to\n    SpotlessBackendAPI ||--o{ Bulk : routes-to\n    SpotlessBackendAPI ||--o{ Certificates : routes-to\n    SpotlessBackendAPI ||--o{ Configurations : routes-to\n    SpotlessBackendAPI ||--o{ Domains : routes-to\n    SpotlessBackendAPI ||--o{ MutualAuthentication : routes-to\n    SpotlessBackendAPI ||--o{ PrivateKeys : routes-to\n    SpotlessBackendAPI ||--o{ Subscriptions : routes-to\n    Subscriptions ||--o{ CertificateAuthority : communicates-with\n```\n\n```mermaid\nsequenceDiagram\n    participant Customer\n    participant Spotless\n    participant Ascerta\n    participant Queue\n    participant Worker\n\n    Customer-\u003e\u003eSpotless: POST /tls/subscriptions\n    Spotless-\u003e\u003e+Ascerta: https://\u003chostname\u003e/internal/tls/v2/certs/...\n    Note right of Spotless: include callback url\n    par\n        Ascerta--\u003e\u003eQueue: send request\n    end\n    Note right of Ascerta: include callback url\n    Ascerta-\u003e\u003e-Spotless: response\n    Spotless-\u003e\u003eCustomer: 201 Created\n    par\n        Worker\u003c\u003c-\u003e\u003eQueue: get item\n        Worker-\u003e\u003eWorker: do work\n        Worker-\u003e\u003eSpotless: https://\u003chostname\u003e/internal/tls/v2/certs/...\n        Note right of Spotless: the callback url\n    end\n```\n\n```mermaid\n---\ntitle: NSQ Infrastructure\n---\ngraph LR\n    subgraph \"Producer\"\n        A[API] -- push to topic --\u003e CP((topic: priority))\n        A -- push to topic --\u003e CS((topic: standard))\n        A -- push to topic --\u003e CSP((topic: special))\n\n        %% nsqd is the daemon that receives, queues, and distributes messages. \n        %% It acts as the message queue server.\n        CP \u0026 CS \u0026 CSP -- send message --\u003e N[nsqd]\n    end\n\n    subgraph \" \"\n        %% nsqlookupd provides a directory service, \n        %% allowing consumers to find the nsqd instances that are producing messages \n        %%for a specific topic.\n        N -- register topic --\u003e L[nsqlookupd]\n    end\n\n    subgraph \"Consumers\"\n        %% The consumers are trying to discover the nsqd instances \n        %% that are handling the specific topic they're interested in. \n        L \u003c-- discover producers --\u003e WP@{ shape: procs, label: \"priority workers\"}\n        L \u003c-- discover producers --\u003e WS@{ shape: procs, label: \"standard workers\"}\n        L \u003c-- discover producers --\u003e WSP@{ shape: procs, label: \"special workers\"}\n\n        WP \u0026 WS \u0026 WSP \u003c-- retrieve message --\u003e N\n    end\n```\n\nBelow is an example of drawing boxes around specific parts of a system...\n\n```mermaid\nsequenceDiagram\n    participant EU as End User\n    participant RR as Recursive Resolver\n    participant Root as Root Servers\n    participant TLD as .com TLD Servers\n    participant DS as DNSimple Servers \u003cbr/\u003e (IPs via Glue Records for nsX.example.com)\n    participant Cust as Customer\n    participant UI as Example UI\n    participant BE as Example Facade API Service\n    participant API as DNSimple API\n    participant DB as DNSimple Database\n\n    box LightBlue DNS Resolution Process (Query for www.customerdomain.com)\n        participant EU\n        participant RR\n        participant Root\n        participant TLD\n    end\n\n    box Pink Record Management Process (Customer updates DNS)\n        participant Cust\n        participant UI\n        participant BE\n        participant API\n    end\n\n    Note over EU, DS: Initial Setup Prerequisite (Not Shown):\u003cbr/\u003e1. Vanity NS (nsX.example.com) configured in DNSimple.\u003cbr/\u003e2. Glue Records created at example.com's registrar mapping nsX.example.com to DNSimple IPs.\u003cbr/\u003e3. customerdomain.com's NS records point to nsX.example.com.\n\n    %% === DNS Resolution Flow ===\n    EU-\u003e\u003e+RR: Resolve www.customerdomain.com?\n    RR-\u003e\u003e+Root: Who handles .com?\n    Root--\u003e\u003e-RR: TLD Server IPs\n    RR-\u003e\u003e+TLD: Who handles customerdomain.com?\n    TLD--\u003e\u003e-RR: NS: ns1.example.com @ DNSimple_IP1\u003cbr/\u003eNS: ns2.example.com @ DNSimple_IP2\u003cbr/\u003e(Info via Glue Records)\n    RR-\u003e\u003e+DS: (Query sent to DNSimple_IP1) A record for www.customerdomain.com?\n    DS--\u003e\u003e-RR: A record is 192.0.2.100\n    RR--\u003e\u003e-EU: www.customerdomain.com is 192.0.2.100\n    EU-\u003e\u003e(Web Server): Connect to 192.0.2.100\n\n    %% === Record Management Flow ===\n    Cust-\u003e\u003e+UI: Login \u0026 Navigate to manage.example.com\n    Cust-\u003e\u003eUI: Request Add/Update Record (e.g., TXT _foo=\"bar\")\n    UI-\u003e\u003e+BE: Submit Record Change Request (domain, type, name, content)\n    BE-\u003e\u003e+API: Create/Update Record via DNSimple API\u003cbr/\u003e(Zone: customerdomain.com, Record Details)\n    API-\u003e\u003e+DB: Store/Update record data in DNSimple's database\n    Note over DB, DS: DNSimple internal propagation\u003cbr/\u003eupdates authoritative servers (DS).\n    DB--\u003e\u003e-API: Confirmation of data update\n    API--\u003e\u003e-BE: Success Response (e.g., Record ID)\n    BE--\u003e\u003e-UI: Operation Successful\n    UI--\u003e\u003e-Cust: Display success message / updated record list\n\n    Note right of DS: DNSimple Servers (DS)\u003cbr/\u003enow serve the\u003cbr/\u003enew/updated record\u003cbr/\u003efor future queries.\n```\n\nExample of complex architecture with `\u003cbr\u003e` for line breaks:\n\n```mermaid\ngraph TD\n    subgraph \"User Interaction\"\n        User[User/Customer]\n    end\n\n    subgraph \"Example DNS Platform\"\n        ManagementService[Example DNS Management Service API/UI]\n        CentralDB[(\"Central Database: stores zones with 'account' column for partition_id\")]\n        \n        subgraph \"DNS Partition ..N\"\n            PDNSN[PowerDNS Instance for PN \u003cbr\u003e\u003cbr\u003e config: SELECT ... WHERE account='PN_id']\n            NS_PN_Set[NS Servers for P..N: \u003cbr\u003e\u003cbr\u003e nsn1.your-dns.com nsn2.your-dns.com]\n        end\n        subgraph \"DNS Partition 2\"\n            PDNS2[PowerDNS Instance for P2 \u003cbr\u003e\u003cbr\u003e config: SELECT ... WHERE account='P2_id']\n            NS_P2_Set[NS Servers for P2: \u003cbr\u003e\u003cbr\u003e nsb1.your-dns.com nsb2.your-dns.com]\n        end\n        subgraph \"DNS Partition 1\"\n            PDNS1[PowerDNS Instance for P1 \u003cbr\u003e\u003cbr\u003e config: SELECT ... WHERE account='P1_id']\n            NS_P1_Set[NS Servers for P1: \u003cbr\u003e\u003cbr\u003e nsa1.your-dns.com nsa2.your-dns.com]\n        end\n    end\n\n    subgraph \"External DNS Infrastructure\"\n        Registrar[Domain Registrar]\n        UserCurrentDNS[User's Current/External DNS; for verification if needed]\n    end\n\n    User -- Manages Zones via --\u003e ManagementService\n    ManagementService -- Reads/Writes Zone Config --\u003e CentralDB\n    \n    PDNS1 -- Reads Zone Data \u003cbr\u003e (filtered for P1) --\u003e CentralDB\n    PDNS2 -- Reads Zone Data \u003cbr\u003e (filtered for P2) --\u003e CentralDB\n    PDNSN -- Reads Zone Data \u003cbr\u003e (filtered for PN) --\u003e CentralDB\n    \n    NS_P1_Set -- Served by --\u003e PDNS1\n    NS_P2_Set -- Served by --\u003e PDNS2\n    NS_PN_Set -- Served by --\u003e PDNSN\n\n    User -- Creates Verification Record --\u003e UserCurrentDNS\n    User -- Updates NS Records --\u003e Registrar\n\n    ManagementService -- Verification Check --\u003e UserCurrentDNS\n\n    style User fill:#aliceblue,stroke:#333,stroke-width:2px\n    style ManagementService fill:#lightcyan,stroke:#333,stroke-width:2px\n    style CentralDB fill:#honeydew,stroke:#333,stroke-width:2px\n    style PDNS1 fill:#mistyrose,stroke:#333,stroke-width:2px\n    style PDNS2 fill:#mistyrose,stroke:#333,stroke-width:2px\n    style PDNSN fill:#mistyrose,stroke:#333,stroke-width:2px\n    style NS_P1_Set fill:#lemonchiffon,stroke:#333,stroke-width:2px\n    style NS_P2_Set fill:#lemonchiffon,stroke:#333,stroke-width:2px\n    style NS_PN_Set fill:#lemonchiffon,stroke:#333,stroke-width:2px\n    style Registrar fill:#thistle,stroke:#333,stroke-width:2px\n    style UserCurrentDNS fill:#whitesmoke,stroke:#333,stroke-width:2px\n```\n\nExample of complex architecture using line colours _and_ `~~~` to force a vertical rendering of the boxes within the \"DNS Data Plan\" subgraph:\n\n```mermaid\nflowchart TD\n    subgraph user[\"User Interaction\"]\n        APIUser[\"User/Customer\"]\n        DNSUser[\"User/Customer\"]\n    end\n\n    subgraph DNSControl[\"DNS Control Plane\"]\n        APIService[\"DNS API Service\"]\n        controlPlaneDB[(\"Control Plane Database: stores zone mappings, entityID information, partition mapping\")]\n    end\n\n    subgraph pdnsInstance [\"PowerDNS instance\"]\n        pdnsAPIN[\"PowerDNS Primary/Secondary\"]\n        pdnsDBN[(\"PowerDNS Partition N MySQL Database: stores zones, records, etc\")]\n        pdnsAPIN --\u003e pdnsDBN\n        pdnsDBNReplica[(\"PowerDNS Partition N MySQL Replica DB: stores zones, records, etc\")]\n        pdnsDBN -- Replication --\u003e pdnsDBNReplica\n        Note[\"Note: PowerDNS will act as a primary/secondary for a given zone, depending on the configuration\"]\n    end\n    \n    subgraph DNSDataPlane [\"DNS Data Plane\"]\n        subgraph pdnsN[\"PDNS Partition..N\"]\n            origin_refN[\"origin instance\"]\n            control_refN[\"control instance\"]\n            transfer_refN[\"transfer instance\"]\n        end\n        subgraph pdns2[\"PDNS Partition 2\"]\n            origin_ref2[\"origin instance\"]\n            control_ref2[\"control instance\"]\n            transfer_ref2[\"transfer instance\"]\n        end\n        subgraph pdns1[\"PDNS Partition 1\"]\n            origin_ref1[\"origin instance\"]\n            control_ref1[\"control instance\"]\n            transfer_ref1[\"transfer instance\"]\n        end\n        \n        %% Vertical Layout Hint (i.e. force a vertical rendering of the boxes)\n        pdns1 ~~~ pdns2\n        pdns2 ~~~ pdnsN\n    end\n\n    subgraph externalDNSProvider[\"External DNS Platform\"]\n    end\n\n    subgraph EdgeDNS[\"DNS Edge\"]\n        subgraph cacheN[\"Cache Node ..N\"]\n            xdnsN[\"xdns (dns proxy): \u003cbr\u003e Filters invalid packets\"]\n            dnsdistN[\"dnsdist: authoritative DNS cache/proxy\"]\n        end\n        subgraph cache2[\"Cache Node 2\"]\n            xdns2[\"xdns (dns proxy): \u003cbr\u003e Filters invalid packets\"]\n            dnsdist2[\"dnsdist: authoritative DNS cache/proxy\"]\n        end\n        subgraph cache1[\"Cache Node 1\"]\n            xdns1[\"xdns (dns proxy): \u003cbr\u003e Filters invalid packets\"]\n            dnsdist1[\"dnsdist: authoritative DNS cache/proxy\"]\n        end\n        xdns1 \u003c-- valid query --\u003e dnsdist1\n        dnsdist1 -- Cache misses \u003cbr\u003e Xproxy encoded --\u003e origin_ref1\n        xdns2 \u003c-- valid query --\u003e dnsdist2\n        dnsdist2 \u003c-- Cache misses \u003cbr\u003e Xproxy encoded ---\u003e origin_ref2\n        xdnsN \u003c-- valid query --\u003e dnsdistN\n        dnsdistN \u003c-- Cache misses \u003cbr\u003e Xproxy encoded ---\u003e origin_refN\n    end\n    \n    %% Connections\n    APIUser -- Manages Zones via API --\u003e APIService\n    APIUser -- Manages Zones on External DNS Provider --\u003e externalDNSProvider\n    DNSUser -- Incoming DNS Queries --\u003e EdgeDNS\n    \n    APIService -- Route DNS request to PowerDNS control instance ---\u003e control_refN\n    APIService -- Route DNS request to PowerDNS control instance ---\u003e control_ref2\n    APIService -- Route DNS request to PowerDNS control instance ---\u003e control_ref1\n    APIService -- Check DB for customer information and mapping--\u003e controlPlaneDB\n    \n    externalDNSProvider -- Replicates records via XFR --\u003e transfer_ref1\n    externalDNSProvider -- Replicates records via XFR --\u003e transfer_ref2\n    externalDNSProvider -- Replicates records via XFR --\u003e transfer_refN\n    \n    %% Links to PowerDNS Instance\n    origin_refN -- \"is a\" --\u003e pdnsInstance\n    control_refN -- \"is a\" --\u003e pdnsInstance\n    transfer_refN -- \"is a\" --\u003e pdnsInstance\n    origin_ref1 -- \"is a\" --\u003e pdnsInstance\n    control_ref1 -- \"is a\" --\u003e pdnsInstance\n    transfer_ref1 -- \"is a\" --\u003e pdnsInstance\n    origin_ref2 -- \"is a\" --\u003e pdnsInstance\n    control_ref2 -- \"is a\" --\u003e pdnsInstance\n    transfer_ref2 -- \"is a\" --\u003e pdnsInstance\n\n    %% Links for origin instances\n    linkStyle 4 stroke:red,stroke-width:2px,color:grey;\n    linkStyle 5 stroke:red,stroke-width:2px,color:grey;\n    linkStyle 6 stroke:red,stroke-width:2px,color:grey;\n    linkStyle 7 stroke:red,stroke-width:2px,color:grey;\n    linkStyle 8 stroke:red,stroke-width:2px,color:grey;\n    linkStyle 9 stroke:red,stroke-width:2px,color:grey;\n    linkStyle 12 stroke:red,stroke-width:2px,color:grey;\n    linkStyle 20 stroke:red,stroke-width:2px,color:grey;\n    linkStyle 23 stroke:red,stroke-width:2px,color:grey;\n    linkStyle 26 stroke:red,stroke-width:2px,color:grey;\n\n    %% Links for control instances\n    linkStyle 10 stroke:blue,stroke-width:2px,color:grey;\n    linkStyle 13 stroke:blue,stroke-width:2px,color:grey;\n    linkStyle 14 stroke:blue,stroke-width:2px,color:grey;\n    linkStyle 15 stroke:blue,stroke-width:2px,color:grey;\n    linkStyle 16 stroke:blue,stroke-width:2px,color:grey;\n    linkStyle 21 stroke:blue,stroke-width:2px,color:grey;\n    linkStyle 24 stroke:blue,stroke-width:2px,color:grey;\n    linkStyle 27 stroke:blue,stroke-width:2px,color:grey;\n\n    %% Links for transfer instances\n    linkStyle 11 stroke:orange,stroke-width:2px,color:grey;\n    linkStyle 17 stroke:orange,stroke-width:2px,color:grey;\n    linkStyle 18 stroke:orange,stroke-width:2px,color:grey;\n    linkStyle 19 stroke:orange,stroke-width:2px,color:grey;\n    linkStyle 22 stroke:orange,stroke-width:2px,color:grey;\n    linkStyle 25 stroke:orange,stroke-width:2px,color:grey;\n    linkStyle 28 stroke:orange,stroke-width:2px,color:grey;\n```\n\nHere's a simplified version of the above:\n\n```mermaid\nflowchart TD\n    subgraph user[\"Customer Interaction\"]\n        APIUser[\"API User\"]\n        DNSUser[\"DNS User\"]\n        ExternalUser[\"External User\"]\n    end\n\n    subgraph DNSControl[\"DNS Control Plane\"]\n        APIService[\"DNS API Service\"]\n        controlPlaneDB[(\"Control Plane Database: stores zone mappings, entityID information, partition mapping\")]\n    end\n    \n    subgraph DNSDataPlane [\"DNS Data Plane\"]\n        subgraph pdnsN[\"Partitions ..N\"]\n            origin[\"PowerDNS:\u003cbr\u003eorigin instance\"]\n            control[\"PowerDNS:\u003cbr\u003econtrol instance\"]\n            transfer[\"PowerDNS:\u003cbr\u003etransfer instance\"]\n\n            pdnsDBOrigin[(\"PowerDNS:\u003cbr\u003eDatabase\")]\n            pdnsDBControl[(\"PowerDNS:\u003cbr\u003eDatabase\")]\n            pdnsDBTransfer[(\"PowerDNS:\u003cbr\u003eDatabase\")]\n\n            origin --\u003e pdnsDBOrigin\n            control --\u003e pdnsDBControl\n            transfer --\u003e pdnsDBTransfer\n        end\n    end\n\n    DNSDataPlane --\u003e pdnsInstance\n\n    subgraph pdnsInstance [\"PowerDNS instance\"]\n        pdnsAPIN[\"PowerDNS Primary/Secondary\"]\n        pdnsDBN[(\"PowerDNS Partition N MySQL Database: stores zones, records, etc\")]\n        pdnsAPIN --\u003e pdnsDBN\n        pdnsDBNReplica[(\"PowerDNS Partition N MySQL Replica DB: stores zones, records, etc\")]\n        pdnsDBN -- Replication --\u003e pdnsDBNReplica\n        Note[\"Note: PowerDNS will act as a primary/secondary for a given zone, depending on the configuration\"]\n    end\n\n    subgraph externalDNSProvider[\"External DNS Platform\"]\n    end\n\n    subgraph EdgeDNS[\"DNS Edge\"]\n        subgraph cacheN[\"Cache Node ..N\"]\n            xdnsN[\"xdns (dns proxy):\u003cbr\u003efilters invalid packets\"]\n            dnsdistN[\"dnsdist:\u003cbr\u003eauthoritative DNS cache/proxy\"]\n        end\n        xdnsN \u003c-- valid query --\u003e dnsdistN\n        dnsdistN \u003c-- cache miss\u003cbr\u003e(xproxy encoded) ---\u003e pdnsN\n    end\n    \n    %% Connections\n    APIUser -- Manages Zones via API --\u003e APIService\n    ExternalUser -- Manages Zones on External DNS Provider --\u003e externalDNSProvider\n    DNSUser -- Incoming DNS Queries --\u003e EdgeDNS\n    \n    APIService -- Route DNS request to PowerDNS control instance ---\u003e control\n    APIService -- Route DNS request to PowerDNS control instance ---\u003e control\n    APIService -- Route DNS request to PowerDNS control instance ---\u003e control\n    APIService -- Check DB for customer information and mapping--\u003e controlPlaneDB\n    \n    externalDNSProvider -- Replicates records via XFR --\u003e transfer\n    externalDNSProvider -- Replicates records via XFR --\u003e transfer\n    externalDNSProvider -- Replicates records via XFR --\u003e transfer\n```\n\nExample of a Entity Relationship diagram (e.g. MySQL database visualisation)\n\n```mermaid\nerDiagram\n    %% https://mermaid.js.org/syntax/entityRelationshipDiagram.html\n    %% PK == Primary Key\n    %% UK == Unique Key\n    %% ||--o{ : One-to-Zero-or-More relationship\n\n    LEGEND {\n        _PK_ Primary_Key\n        _UK_ Unique_Key\n        _FK_ Foreign_Key\n    }\n\n    routing_configs {\n        BIGINT internal_id PK \"Internal Primary Key\"\n        VARCHAR(36) id UK \"Public Unique ID\"\n        VARCHAR(255) name UK \"Human-readable Name\"\n    }\n\n    rules {\n        BIGINT internal_id PK \"Internal Primary Key\"\n        VARCHAR(36) id UK \"Public Unique ID\"\n        VARCHAR(36) config_id \"Parent Config ID (Logical FK)\"\n        VARCHAR(255) sort_key \"Fractional Index for Ordering\"\n    }\n\n    conditions {\n        BIGINT internal_id PK \"Internal Primary Key\"\n        VARCHAR(36) id UK \"Public Unique ID\"\n        VARCHAR(36) rule_id \"Parent Rule ID (Logical FK)\"\n        INT sort_order \"Integer for Ordering\"\n    }\n\n    routing_configs ||--o{ rules : \"has\"\n    rules ||--o{ conditions : \"has\"\n```\n\nExample of CDN Edge configuration loading (demonstrates how a file box looks different):\n\n```mermaid\nflowchart LR\n    client[Client of Customer] -- example.com/foo --\u003e h2o\n    customer[CDN Customer] -- routing config API requests --\u003e gateway\n    customer -- associate routing configuration with domain --\u003e ui\n\n    subgraph edge[Edge Node]\n        fetchly[Fetchly Daemon]\n        h2o[H2O Server]\n        file[/etc/cdn/h2o/route-config-ID.json/]\n        tlsconfig[/etc/cdn/h2o/tls-config.json/]\n        minerva[Minerva]\n\n        fetchly -- 2\\. store config to disk --\u003e file\n        h2o \u003c-- 1\\. read tls config data\u003cbr\u003eand extract route config id --\u003e tlsconfig\n        h2o \u003c-- 2\\. read route info from disk\u003cbr\u003eusing route config id --\u003e file\n    end\n\n    subgraph control_plane[Control Plane]\n        gateway[CDN API Gateway]\n\n    end\n\n    subgraph manage_ui[Manage UI]\n        ui[CDN UI]\n    end\n\n    subgraph elevation[Elevation]\n        route_controller_api[Route Controller API]\n        spotless[Spotless]\n        neptune[Neptune]\n    end\n\n    subgraph origin[Origin]\n        backend[Heroku]\n    end\n\n    subgraph async_pipeline[Asynchronous Pipeline]\n        nsq[Queue]\n        consumer[Consumer]\n    end\n\n    subgraph f[Data Plane]\n        db[MySQL]\n    end\n\n    fetchly \u003c-- 1\\. fetch route info (periodically 🚨) --\u003e route_controller_api\n    h2o -- 3\\. proxy request --\u003e backend\n    gateway -- proxy routing config API request --\u003e route_controller_api\n    route_controller_api -- if batch --\u003e nsq\n    route_controller_api -- store data --\u003e db\n    spotless -- associate routing config with CHO --\u003e neptune\n    consumer \u003c-- take message and process the operation --\u003e nsq\n    consumer -- store data --\u003e db\n    ui -- domain API requests (POST/PATCH domains, activations w/ routing config) --\u003e gateway\n    ui -- routing config API requests (GET list of routing configs) --\u003e gateway\n    gateway -- proxy domain API requests --\u003e spotless\n    minerva \u003c-- 1\\. acquire TLS config data\u003cbr\u003eevery 30 seconds --\u003e neptune\n    minerva -- 2\\. store data to disk --\u003e tlsconfig\n```\n\nFastly production decision:\n\n```mermaid\nflowchart TD\n\n    A{\"Does the data have a TTL?\"} --\u003e|Yes| B[Ephemeral]\n    A --\u003e|No| C[Durable]\n\n    %% Ephemeral branch\n    B --\u003e D{\"What type of cached content is it?\"}\n    D --\u003e |HTTP responses| Q{Which platform product} \n    Q --\u003e|Delivery| E[Varnish]\n    Q --\u003e|Compute| F[\"HTTP Cache API (*)\"]\n    D --\u003e |Everything else| G{\"What caching features are required?\"}\n\n    G --\u003e|Insert, retrieve, purge| H[\"Simple Cache API (*)\"]\n    G --\u003e|\"Cache revalidations, request collapsing, streaming miss etc.\"| I[\"Core Cache API (*)\"]\n\n    %% Durable branch\n    C --\u003e J{\"What type of data is it?\"}\n\n    J --\u003e|Sensitive customer data| K[\"Secret Store (+)\"]\n    J --\u003e|Customer config data| L[\"Config Store (+)\"]\n    J --\u003e|Everything else| S{What size restrictions are there?}\n    S --\u003e|\u003c 100MB| M[\"KV Store (+)\"]\n    S --\u003e|\u003e 100MB| N[\"Object Storage (+)\"]\n\n    %% Notes\n    subgraph Legend\n      O[\"(*) Included with Compute\"]\n      P[\"(+) Has to be purchased separately\"]\n    end\n```\n","tags":"#diagrams"},{"id":"5685562cd874cce18d5d00714fe0a2c7","title":"Go: errgroup ","content":"\u003e [!TIP]\n\u003e For a real-world example see [this gist][real-world].\n\n`errgroup.Group` in Go is a great way to manage concurrent goroutines that return errors. It simplifies error handling and ensures that all goroutines finish or exit if any one of them fails. However, there are specific scenarios where it shines and others where it might not be the best fit.\n\n## When to use `errgroup.Group`\n\n1. **Multiple Independent Goroutines:**  \n  If you need to launch several goroutines concurrently, and each one performs an independent task (like querying different services), `errgroup` helps manage their lifecycle.\n2. **Error-First Cancellation:**  \n  When any goroutine's error should cancel all other goroutines, `errgroup` simplifies this with context cancellation. It ensures that if one task fails, the others stop as soon as possible.\n3. **Resource Cleanup:**  \n  If goroutines hold resources (e.g., database connections or files), `errgroup` ensures that when one fails, the others can clean up or abort gracefully.\n4. **Waiting for All Goroutines:**  \n  `errgroup` provides a simple way to wait for all goroutines to finish without manually tracking them. It reduces boilerplate code by calling `g.Wait()`.\n5. **Hierarchical Task Execution:**  \n  If tasks spawn subtasks, `errgroup` can manage goroutines at multiple levels with different cancellation contexts.\n\n## When NOT to use `errgroup.Group`\n\n1. **Fire-and-Forget Goroutines:**  \n  If the goroutines don’t return errors and don’t need to be canceled on failure, using `errgroup` adds unnecessary complexity. Just use `sync.WaitGroup` instead.\n2. **Tight Loops with Many Goroutines:**  \n  For creating a large number of goroutines (like in a loop), `errgroup` may not be ideal because it cancels all goroutines on the first error, potentially leaving work unfinished.\n3. **Performance-Critical Sections:**  \n  `errgroup` uses `context.WithCancel` internally, which introduces a slight overhead. In extremely performance-sensitive scenarios, using `sync.WaitGroup` might be more efficient.\n4. **Tasks Without Shared Context:**  \n  If the tasks do not depend on a shared context or don't need coordinated cancellation, `errgroup` is overkill.\n5. **Partial Completion is Acceptable:**  \n  If some goroutines can fail without affecting the outcome of the program, you might prefer `sync.WaitGroup` or custom error aggregation rather than stopping all work at the first failure.\n\n[real-world]: https://gist.github.com/Integralist/927f91c34be67499a6a1a430ddaebe92#file-2-main-go\n","tags":"#go #concurrency #errors"},{"id":"12a6f901da071120d3a45e41b3eb0f12","title":"OpenAPI: feature flags use different schemas ","content":"I don't know if this actually works but apparently you can use a [discriminator](https://swagger.io/docs/specification/v3_0/data-models/inheritance-and-polymorphism/#discriminator) like this...\n\n\u003e [!NOTE]\n\u003e In this example, your API has to return a `type` property that might have a value like `\"base\"` or `\"feature_x\"`.\n\nIf the API response contains `\"type\": \"base\"`, then the OpenAPI schema will use the `BaseResponse` schema. \nOtherwise, if it's `\"type\": \"feature_x\"`, the OpenAPI schema will use the `eatureXResponse` schema.\n\n```yaml\nopenapi: 3.1.0\ninfo:\n  title: Discriminator Example API\n  version: 1.0.0\npaths:\n  /example:\n    get:\n      summary: Example endpoint with feature-flagged responses\n      description: Returns different responses based on whether FeatureX is enabled.\n      responses:\n        '200':\n          description: Successful response\n          content:\n            application/json:\n              schema:\n                $ref: '#/components/schemas/ApiResponse'\n\ncomponents:\n  schemas:\n    ApiResponse:\n      type: object\n      required:\n        - type\n      properties:\n        type:\n          type: string\n          description: \"Indicates the type of the response.\"\n      discriminator:\n        propertyName: type\n        mapping:\n          base: '#/components/schemas/BaseResponse'\n          feature_x: '#/components/schemas/FeatureXResponse'\n      oneOf:\n        - $ref: '#/components/schemas/BaseResponse'\n        - $ref: '#/components/schemas/FeatureXResponse'\n\n    BaseResponse:\n      type: object\n      properties:\n        type:\n          type: string\n          enum:\n            - base\n          description: \"Base response type\"\n        message:\n          type: string\n          description: \"A generic message.\"\n\n    FeatureXResponse:\n      type: object\n      allOf:\n        - $ref: '#/components/schemas/BaseResponse'\n        - type: object\n          properties:\n            type:\n              type: string\n              enum:\n                - feature_x\n              description: \"Indicates FeatureX response.\"\n            feature_x_data:\n              type: string\n              description: \"Additional data when FeatureX is enabled.\"\n```\n","tags":"#schemas #openapi #api #design"},{"id":"a459a4951b5e9bca7d767d6d4f39dda2","title":"Image resize with ImageMagick ","content":"brew install imagemagick\nmagick example.png -quality 70 optimised.jpg\n","tags":"#bash #shell #imagemagick #resize #image"},{"id":"5010e113ce19285698cfe5d941b9884b","title":"1Password CLI ","content":"## list all accounts\n\n```shell\nop account list\n```\n\n## check which account we're using\n\n```shell\nop whoami\n```\n\n## switch account\n\n```shell\nop signin\nop signin --account my # account flag must be passed subset of the URL from `op account list` (e.g. `my` matches `my.1password.com`)\n```\n\n## list all vaults\n\n```shell\nop vault list --format json\n```\n\n## list all items within the \"Private\" vault\n\n```shell\nop item list --vault \"Private\" --format json\n```\n\n## get a specific item from the \"Private\" vault\n\n```shell\nop item get \"Your Item Title\" --vault \"Private\" --format json\n```\n\n## get the password from a specific item from the \"Private\" vault\n\n```shell\nop item get \"Your Item Title\" --vault \"Private\" --fields password --reveal\n```\n\n## use 1Password \"secret reference\" wherever you need a secret to be used. \n\ne.g. an application config file or even an environment variable exported as part of a shell script.\n\nformat:\n```\nop://\u003cVAULT_NAME\u003e/\u003cITEM_NAME\u003e/\u003cFIELD\u003e\n```\n\nyou can easily get the reference to any field using the 1Password GUI.\n\n```shell\nop read \"op://Private/Fastly API Tokens/Integralist-PersonalAllServices/Token\"\nop inject -i some_input_file.tpl -o the_output_file_with_secret\n\nexport FASTLY_API_TOKEN=$(op read \"op://Private/Fastly API Tokens/Integralist-PersonalAllServices/Token\")\nexport FASTLY_API_TOKEN=$(echo \"op://Private/Fastly API Tokens/Integralist-PersonalAllServices/Token\" | op inject)\n\ncurl -sX GET \"https://api.cloudflare.com/client/v4/user/tokens/verify\" -H \"Authorization: Bearer $(op read 'op://Private/6bky6ykumav2wfpguwn4dokcku/API Token')\" -H \"Content-Type:application/json\" | jq\ncurl -sX GET \"https://api.cloudflare.com/client/v4/user/tokens/verify\" -H \"Authorization: Bearer $(echo 'op://Private/6bky6ykumav2wfpguwn4dokcku/API Token' | op inject)\" -H \"Content-Type:application/json\" | jq\n```\n\n\u003e [!NOTE]\n\u003e When entering a title for a 1Password entry, the use of a `:` will cause the \"Copy Secret Reference\" feature to use a cryptic hash instead of a descriptive name.\n\u003e If you want to find the entry this secret reference is related to, then you can search in 1Password using the hash, but from a documentation perspective I much prefer the \"descriptive\" version.\n","tags":"#shell"},{"id":"bd107aa44b01e6f2077861bf746e4664","title":"Go: Single-Flight ","content":"// https://play.golang.com/p/GoyqwZ5jW_L\n// https://pkg.go.dev/golang.org/x/sync/singleflight\n// https://victoriametrics.com/blog/go-singleflight/index.html\n\npackage main\n\nimport (\n\t\"fmt\"\n\t\"math/rand\"\n\t\"sync\"\n\t\"sync/atomic\"\n\t\"time\"\n\n\t\"golang.org/x/sync/singleflight\"\n)\n\nvar callCount atomic.Int32\nvar wg sync.WaitGroup\n\n// Simulate a function that fetches data from a database\nfunc fetchData() (interface{}, error) {\n\tcallCount.Add(1)\n\ttime.Sleep(100 * time.Millisecond)\n\treturn rand.Intn(100), nil\n}\n\n// Wrap the fetchData function with singleflight\nfunc fetchDataWrapper(g *singleflight.Group, id int) error {\n\tdefer wg.Done()\n\n\ttime.Sleep(time.Duration(id) * 40 * time.Millisecond)\n\tv, err, shared := g.Do(\"key-fetch-data\", fetchData)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tfmt.Printf(\"Goroutine %d: result: %v, shared: %v\\n\", id, v, shared)\n\treturn nil\n}\n\nfunc main() {\n\tvar g singleflight.Group\n\n\t// 5 goroutines to fetch the same data\n\tconst numGoroutines = 5\n\twg.Add(numGoroutines)\n\n\tfor i := 0; i \u003c numGoroutines; i++ {\n\t\tgo fetchDataWrapper(\u0026g, i)\n\t}\n\n\twg.Wait()\n\tfmt.Printf(\"Function was called %d times\\n\", callCount.Load())\n}\n\n// Output:\n// Goroutine 0: result: 90, shared: true\n// Goroutine 2: result: 90, shared: true\n// Goroutine 1: result: 90, shared: true\n// Goroutine 3: result: 13, shared: true\n// Goroutine 4: result: 13, shared: true\n// Function was called 2 times\n\n","tags":"#go #performance #concurrency"},{"id":"c2b21a36260d8066da28b5f397f1d7c1","title":"macOS: Custom wireless battery alerts for mouse and keyboard ","content":"\u003e [!NOTE]\n\u003e The whole reason I bothered doing this is because I hate it when macOS notifies me that my mouse is \"critically\" low on charge, as it forces me to have to stop work for charging my mouse. I'd prefer to know at around 50% charge so I can continue working but stick my mouse on charge when I go for lunch or finish my day.\n\nStart by writing an AppleScript file that is essentially just a wrapper around a bash script...\n\n```applescript\ndo shell script \"\n# Get the battery percentage for the Magic Mouse\nmouseBattery=$(ioreg -c AppleDeviceManagementHIDEventService -r | grep -i '\\\"Product\\\" = \\\"Magic Mouse\\\"' -A 20 | grep '\\\"BatteryPercent\\\" =' | awk '{print $NF}')\n\n# Get the battery percentage for the Magic Keyboard\nkeyboardBattery=$(ioreg -c AppleDeviceManagementHIDEventService -r | grep -i '\\\"Product\\\" = \\\"Magic Keyboard\\\"' -A 20 | grep '\\\"BatteryPercent\\\" =' | awk '{print $NF}')\n\n# Check if mouse battery is found and notify if it's below 50%\nif [[ -n \\\"$mouseBattery\\\" \u0026\u0026 \\\"$mouseBattery\\\" -lt 50 ]]; then\n    osascript -e \\\"display notification \\\\\\\"Mouse battery is at $mouseBattery%\\\\\\\" with title \\\\\\\"Battery Alert\\\\\\\"\\\"\nfi\n\n# Check if keyboard battery is found and notify if it's below 50%\nif [[ -n \\\"$keyboardBattery\\\" \u0026\u0026 \\\"$keyboardBattery\\\" -lt 50 ]]; then\n    osascript -e \\\"display notification \\\\\\\"Keyboard battery is at $keyboardBattery%\\\\\\\" with title \\\\\\\"Battery Alert\\\\\\\"\\\"\nfi\n\"\n```\n\n...in the above I'm checking if my mouse and keyboard charge is less than 50%. If so, display a notification to let me know.\n\nNow open up the `Automator.app` application and type \"Run AppleScript\" into the \"Actions\" box to find that action.\n\nPaste the above AppleScript into the input and then `%S` to save the application as `BatteryAlert.app`.\n\nNow to automate running the application...\n\n```shell\ncd ~/Library/LaunchAgents/\ntouch com.integralist.batteryalert.plist\nvim com.integralist.batteryalert.plist # HERE IS WHERE YOU PASTE IN THE BELOW FILE CONTENTS\nlaunchctl load ~/Library/LaunchAgents/com.integralist.batteryalert.plist # SCHEDULE THE APP TO BE RUN\nlaunchctl list | grep batteryalert # SHOW THAT THE APP IS RUNNING\nlog show --predicate 'eventMessage contains \"com.integralist.batteryalert\"' --info # SHOW ANY APP LOGS\n```\n\nHere's the plist file:\n\n```xml\n\u003c?xml version=\"1.0\" encoding=\"UTF-8\"?\u003e\n\u003c!DOCTYPE plist PUBLIC \"-//Apple//DTD PLIST 1.0//EN\" \"http://www.apple.com/DTDs/PropertyList-1.0.dtd\"\u003e\n\u003cplist version=\"1.0\"\u003e\n\u003cdict\u003e\n    \u003ckey\u003eLabel\u003c/key\u003e\n    \u003cstring\u003ecom.integralist.batteryalert\u003c/string\u003e\n\n    \u003ckey\u003eProgramArguments\u003c/key\u003e\n    \u003carray\u003e\n        \u003cstring\u003e/Applications/BatteryAlert.app/Contents/MacOS/applet\u003c/string\u003e\n    \u003c/array\u003e\n\n    \u003ckey\u003eStartInterval\u003c/key\u003e\n    \u003cinteger\u003e3600\u003c/integer\u003e \u003c!-- Run every 3600 seconds = 60 minutes --\u003e\n\n    \u003ckey\u003eRunAtLoad\u003c/key\u003e\n    \u003ctrue/\u003e\n\u003c/dict\u003e\n\u003c/plist\u003e\n```\n","tags":"#macos #automator #notifications #battery"},{"id":"0320ea5b1fccd4b1ad6aa6c369b011e7","title":"Make: Makefile syntax ","content":"# Make\n\nMake is a build automation tool that uses a file called a Makefile to define how\nto build, test, or manage dependencies in a project.\n\nIt's commonly used to:\n\n- Compile and link code.\n- Automate repetitive tasks (e.g., testing, deploying).\n- Track changes in files and only rebuild what’s necessary.\n\n## Terminology\n\n```Makefile\ntarget: prerequisites\n  recipe\n```\n\n- target: is expected to be a filename.\n- prerequisites: is a list of files the target depends on\n- recipe: is the command(s) you run to create the target\n\nThe entire block of code (target, prerequisite, recipe) is called a 'rule'.\n\n\u003e \\[!NOTE\\]\n\u003e Not all 'targets' will be a filename because you don't always want to use Make\n\u003e to create files. You often want to use Make to just run some code without the\n\u003e side-effect of creating a new file. In these cases you annotate your rule with\n\u003e `.PHONY: target`.\n\n\u003c!----\u003e\n\n\u003e \\[!NOTE\\]\n\u003e You can have multiple prerequisites, and they can either be a filename or they\n\u003e can be the name of another target.\n\n## Automatic Variables\n\nMake's [Automatic Variables] are special variables that represent parts of a\nrule, making Makefiles more concise and flexible. They get their values\nautomatically based on the target, prerequisites, or commands.\n\nYou'll see a few different automatic variables used:\n\n- `%`: pattern rule\n- `$@`: target name\n- `$\u003c`: first prerequisite\n- `$^`: list of prerequisites\n- `$?`: list of prerequisites that have changed\n- `$*`: the stem of a target\n\n\u003e \\[!IMPORTANT\\]\n\u003e Any time you need to use a shell variable (i.e. `$foo`) it must be prefixed\n\u003e with `$`.\\\n\u003e This is because `$` already has a special meaning in Make.\\\n\u003e So, the variable would be referenced like `$$foo` (see also Make's [shell\n\u003e function][shell function]).\n\n## Example\n\nLet's look at an example rule:\n\n```Makefile\n%.mock.pid: %.mock\n  ./%.mock -addr=127.0.0.1:8446 \u003e .$\u003c.log \u0026 echo $$! \u003e $@\n```\n\nThen it could be invoked (as an example) like so:\n\n```shell\nmake mustang.mock.pid\n```\n\nThe `%` wildcard would match the above Makefile _target_ `%.mock.pid`.\n\nNext it would ensure the _prerequisite_ `mustang.mock` existed (i.e. `%.mock`).\n\nNext it would run the `./mustang.mock` binary (i.e. `./%.mock`).\n\nThe stdout (`\u003e`) would be written to `.mustang.mock.log` (i.e. `.$\u003c.log`).\n\nFinally, the process ID (`$$!`) is written to `mustang.mock.pid` (i.e. `$@`).\n\n[automatic variables]: https://www.gnu.org/software/make/manual/html_node/Automatic-Variables.html\n[shell function]: https://www.gnu.org/software/make/manual/html_node/Shell-Function.html\n\n## Performance\n\nMake has built-in rules (e.g., for compiling .c to .o) called implicit rules.\\\nhttps://www.gnu.org/software/make/manual/html_node/Implicit-Rules.html\n\nThe following example disables default implicit rule searches:\n\n```Makefile\n# These empty rules tell Make *not* to search for implicit rules for .go, .mk, .json \u0026 the Makefile itself.\n# Searching for them can be slow. This speeds up dependency checking.\nMakefile : ;\n\n# The double-colon `::` fully disables the implicit search.\n%.go %.mk %.json :: ;\n```\n\n## Functions\n\nThere are many [built-in functions](https://www.gnu.org/software/make/manual/html_node/Functions.html) you can use.\n\nHere are some useful documentation pages:\n\n- [Text Functions](https://www.gnu.org/software/make/manual/html_node/Text-Functions.html)\n- [File Name Functions](https://www.gnu.org/software/make/manual/html_node/File-Name-Functions.html)\n- [Error Handling Functions](https://www.gnu.org/software/make/manual/html_node/Make-Control-Functions.html)\n\n## Generating Help Output\n\nhttps://gist.github.com/Integralist/4447885192c7e84e01ca7c9f2e08ef17\n","tags":"#make #makefile #shell"},{"id":"4c4983e9da327cb83a0e9c8b90396ac0","title":"Code: Programming Terminology ","content":"# Programming Terminology in Go\n\n## 1. Expression\n- **Definition**: A combination of values, variables, operators, and function calls that **evaluates to a single value**.\n- **Examples**:\n  - `2 + 2` (evaluates to `4`)\n  - `x * y` (evaluates to the product of `x` and `y`)\n  - `time.Second * 10` (evaluates to a `time.Duration` value of 10 seconds)\n- **Usage**: Expressions are used to compute values. They can appear within statements, assignments, or function arguments.\n\n---\n\n## 2. Statement\n- **Definition**: A **complete unit of execution** that performs an action, like assigning a value, calling a function, or controlling the flow of a program.\n- **Examples**:\n  - Assignment: `x := 5`\n  - Function call: `fmt.Println(\"Hello, World!\")`\n  - Control flow: `if x \u003e 10 { fmt.Println(\"x is large\") }`\n- **Types of Statements**:\n  - **Expression Statement**: An expression used as a standalone statement (e.g., `x + y` is an expression; `x + y;` on its own would be invalid in Go, but `fmt.Println(x + y)` is a valid statement).\n  - **Control Statement**: Includes `if`, `for`, `switch`, etc.\n  - **Declaration Statement**: Declares variables or constants, e.g., `var a int`.\n\n---\n\n## 3. Directive\n- **Definition**: A **special instruction to the compiler or tooling**, modifying behavior at compile time or runtime.\n- **Examples**:\n  - `//go:generate`: Tells the Go toolchain to generate code during build processes.\n  - Build constraints: `// +build linux` ensures code is only compiled on Linux systems.\n- **Usage**: Directives are typically comments prefixed with `//`, interpreted by Go tools.\n\n---\n\n## 4. Declaration\n- **Definition**: Introduces new identifiers (variables, constants, types, or functions) into the program.\n- **Examples**:\n  - Variable declaration: `var x int`\n  - Constant declaration: `const Pi = 3.14`\n  - Type declaration: `type Point struct { X, Y int }`\n  - Function declaration: `func Add(a, b int) int { return a + b }`\n\n---\n\n## 5. Keyword\n- **Definition**: Reserved words in a language with predefined meanings that cannot be used as identifiers.\n- **Examples**:\n  - `if`, `else`, `func`, `return`, `var`, `const`, etc.\n- **Usage**: Keywords form the syntax and structure of the language.\n\n---\n\n## 6. Block\n- **Definition**: A sequence of statements enclosed in curly braces `{}`.\n- **Examples**:\n  ```go\n  func main() {\n      fmt.Println(\"Hello, World!\") // This is a block\n  }\n  ```\n- **Usage**: Blocks are used to group statements together in functions, loops, or conditionals.\n  \n---\n  \n## 7. Literal\n- **Definition**: A fixed value written directly in the code.\n- **Examples**:\n  - Numbers: `42`, `3.14`\n  - Strings: `\"hello\"`\n  - Booleans: `true`, `false`\n- **Usage**: Literals are used to represent constant values in a program.\n\n---\n\n## 8. Operator\n- **Definition**: A symbol that performs operations on variables or values.\n- **Examples**:\n  - Arithmetic: `+`, `-`, `*`, `/`\n  - Logical: `\u0026\u0026`, `||`, `!`\n  - Relational: `==`, `!=`, `\u003c`, `\u003e`\n- **Usage**: Operators are used within expressions to compute values or make comparisons.\n\n---\n\n## 9. Type\n- **Definition**: A classification that defines the kind of data a variable or value can hold.\n- **Examples**:\n  - Primitive types: `int`, `float64`, `string`\n  - Composite types: `struct`, `array`, `slice`, `map`\n- **Usage**: Types ensure variables are used consistently and define the operations applicable to them.\n\n---\n\n## 10. Function\n- **Definition**: A block of code that performs a specific task and can be reused.\n- **Examples**:\n  ```go\n  func Add(a, b int) int {\n      return a + b\n  }\n  ```\n- **Usage**: Functions encapsulate logic and make the code reusable and modular.\n\n---\n\n## 11. Package\n- **Definition**: A collection of related Go files grouped together to provide reusable functionality.\n- **Examples**:\n  - Standard packages: `fmt`, `time`, `strings`\n  - Custom packages: `mypackage`\n- **Usage**: Packages allow modular programming and reuse of code across projects.\n\n---\n\n## 12. Import\n- **Definition**: Brings a package into the current file for use.\n- **Examples**:\n  ```go\n  import \"fmt\"\n  ```\n- **Usage**: Imports allow access to external or standard library functionality.\n\n---\n\n## 13. Comment\n- **Definition**: A human-readable note in the code that is ignored by the compiler.\n- **Examples**:\n  - Single-line: `// This is a comment`\n  - Multi-line: `/* This is a multi-line comment */`\n- **Usage**: Used for documentation or explanations.\n\n---\n\n## Example Code with All Terms\n\n```go\n// This is a package declaration (declaration)\npackage main\n\nimport \"fmt\" // Import statement\n\n// Function declaration\nfunc main() {\n    var x int = 10 // Declaration statement\n    const y = 20   // Constant declaration\n\n    // Expression within an assignment statement\n    result := x + y\n\n    // Control flow statement\n    if result \u003e 15 {\n        fmt.Println(\"Result is greater than 15\") // Expression statement\n    }\n\n    // Function call within a block\n    fmt.Println(\"End of program\") // Directive example: //go:generate could appear here\n}\n```\n","tags":"#programming #terminology"},{"id":"089e4e2da20090c3a91f0991ab2dac78","title":"Go: Custom DNS resolution in Golang ","content":"```shell\n$ go run main.go\n\nQuerying root server 198.41.0.4 for TLD com...\nSelected TLD server: g.gtld-servers.net.\nResolved TLD server IP: 192.42.93.30\nQuerying TLD server 192.42.93.30 for domain coca-cola.com...\nSelected authoritative server: ns4-09.azure-dns.info.\nResolved authoritative server IP: 208.84.5.9\nQuerying authoritative server 208.84.5.9 for domain coca-cola.com...\nresolved A record: coca-cola.com.\t3000\tIN\tA\t52.14.144.171\n```\npackage main\n\nimport (\n\t\"crypto/rand\"\n\t\"errors\"\n\t\"fmt\"\n\t\"log\"\n\t\"math/big\"\n\t\"net\"\n\t\"strings\"\n\n\t\"github.com/miekg/dns\"\n)\n\nfunc main() {\n\tdomain := \"coca-cola.com\"\n\tif err := traceDNS(domain); err != nil {\n\t\tlog.Fatal(err)\n\t}\n}\n\nfunc traceDNS(domain string) error {\n\tips, err := net.LookupIP(\"a.root-servers.net\")\n\tif err != nil {\n\t\treturn fmt.Errorf(\"failed to lookup root DNS server: %w\", err)\n\t}\n\n\t// Step 1: Query a root DNS server for the TLD (e.g., com)\n\t// We use `a.root-servers.net` IP address (`dig +short a.root-servers.net`).\n\trootServer := ips[0].String()\n\ttld := domain[strings.LastIndex(domain, \".\")+1:]\n\n\tfmt.Printf(\"Querying root server %s for TLD %s...\\n\", rootServer, tld)\n\tresp, err := queryDNS(rootServer, tld, dns.TypeNS)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"failed to query root server: %w\", err)\n\t}\n\n\t// // Print root server response\n\t// for _, ns := range resp.Ns {\n\t// \tfmt.Printf(\"Root NS: %v\\n\", ns)\n\t// }\n\n\t// Step 2: Select a random TLD server from the root server response\n\ttldServers := []string{}\n\tfor _, ns := range resp.Ns {\n\t\tif tldNs, ok := ns.(*dns.NS); ok {\n\t\t\ttldServers = append(tldServers, tldNs.Ns)\n\t\t}\n\t}\n\n\tif len(tldServers) == 0 {\n\t\treturn errors.New(\"no TLD servers found in root server response\")\n\t}\n\n\t// Randomly pick a TLD server\n\tnBig, err := rand.Int(rand.Reader, big.NewInt(int64(len(tldServers))))\n\tif err != nil {\n\t\treturn fmt.Errorf(\"failed to create random int: %w\", err)\n\t}\n\tselectedTLDServer := tldServers[nBig.Int64()]\n\tfmt.Printf(\"Selected TLD server: %s\\n\", selectedTLDServer)\n\n\t// Step 3: Get the IP address of the selected TLD server (need to query its A record)\n\ttldServerIP, err := resolveNameToIP(selectedTLDServer)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"failed to resolve TLD server %s: %w\", selectedTLDServer, err)\n\t}\n\n\tfmt.Printf(\"Resolved TLD server IP: %s\\n\", tldServerIP)\n\n\t// Step 4: Query the TLD server for the domain's NS records\n\tfmt.Printf(\"Querying TLD server %s for domain %s...\\n\", tldServerIP, domain)\n\tresp, err = queryDNS(tldServerIP, domain, dns.TypeNS)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"failed to query TLD server: %w\", err)\n\t}\n\n\t// Step 5: Print the authoritative name servers for the domain\n\t// fmt.Printf(\"Authoritative name servers for %s:\\n\", domain)\n\t// for _, ns := range resp.Ns {\n\t// \tif authNs, ok := ns.(*dns.NS); ok {\n\t// \t\tfmt.Printf(\"NS: %v\\n\", authNs.Ns)\n\t// \t}\n\t// }\n\n\t// Randomly pick an authoritative server\n\tnBig, err = rand.Int(rand.Reader, big.NewInt(int64(len(resp.Ns))))\n\tif err != nil {\n\t\treturn fmt.Errorf(\"failed to create random int: %w\", err)\n\t}\n\tselectedAuthoritativeServer := resp.Ns[nBig.Int64()]\n\n\t// Step 6: Get the IP address of the selected authoritative server\n\tif authNs, ok := selectedAuthoritativeServer.(*dns.NS); ok {\n\t\tfmt.Printf(\"Selected authoritative server: %s\\n\", authNs.Ns)\n\t\tauthoritativeServerIP, err := resolveNameToIP(authNs.Ns)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"failed to resolve authoritative server %s: %w\", selectedAuthoritativeServer, err)\n\t\t}\n\t\tfmt.Printf(\"Resolved authoritative server IP: %s\\n\", authoritativeServerIP)\n\n\t\t// Step 7: Query the authoritative server for the domain's A records\n\t\tfmt.Printf(\"Querying authoritative server %s for domain %s...\\n\", authoritativeServerIP, domain)\n\t\tresp, err := queryDNS(authoritativeServerIP, domain, dns.TypeA)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"failed to query TLD server: %w\", err)\n\t\t}\n\t\tfor _, rr := range resp.Answer {\n\t\t\tfmt.Printf(\"resolved A record: %s\\n\", rr.String())\n\t\t}\n\t}\n\n\treturn nil\n}\n\n// Resolve a domain name (e.g., TLD server) to its IP address by querying for its A record\nfunc resolveNameToIP(name string) (string, error) {\n\t// Use a public DNS server to resolve the name\n\tpublicDNSServer := \"8.8.8.8\" // Google DNS\n\n\tresp, err := queryDNS(publicDNSServer, name, dns.TypeA)\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\n\tfor _, ans := range resp.Answer {\n\t\tif aRecord, ok := ans.(*dns.A); ok {\n\t\t\treturn aRecord.A.String(), nil\n\t\t}\n\t}\n\n\treturn \"\", fmt.Errorf(\"no A record found for %s\", name)\n}\n\n// Query the specified DNS server for the given domain and record type\nfunc queryDNS(server, domain string, qtype uint16) (*dns.Msg, error) {\n\t// Create a DNS client\n\tclient := new(dns.Client)\n\n\t// Create a DNS message\n\tmsg := new(dns.Msg)\n\tmsg.SetQuestion(dns.Fqdn(domain), qtype)\n\tmsg.RecursionDesired = false\n\n\t// Send the query to the specified server\n\tresponse, _, err := client.Exchange(msg, server+\":53\")\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"failed to query dns server: %w\", err)\n\t}\n\n\treturn response, nil\n}\n","tags":"#go #dns"},{"id":"7006aa7d67b45fcae667125921fdd362","title":"OpenSSL: Working with SSL Certificates, Private Keys and CSRs ","content":"https://www.digitalocean.com/community/tutorials/openssl-essentials-working-with-ssl-certificates-private-keys-and-csrs\n\n# OpenSSL Essentials: Working with SSL Certificates, Private Keys and CSRs\n\nOpenSSL is a versatile command line tool that can be used for a large variety of tasks related to Public Key Infrastructure (PKI) and HTTPS (HTTP over TLS).\n\n## Certificate Signing Requests (CSRs)\n\nIf you would like to obtain an SSL certificate from a commercial certificate authority (CA), you must generate a certificate signing request (CSR). A CSR consists mainly of the public key of a key pair, and some additional information. Both of these components are inserted into the certificate when it is signed.\n\nWhenever you generate a CSR, you will be prompted to provide information regarding the certificate. This information is known as a Distinguished Name (DN). An important field in the DN is the Common Name (CN), which should be the exact Fully Qualified Domain Name (FQDN) of the host that you intend to use the certificate with. It is also possible to skip the interactive prompts when creating a CSR by passing the information via command line or from a file.\n\nThe other items in a DN provide additional information about your business or organization. If you are purchasing an SSL certificate from a certificate authority, it is often required that these additional fields, such as “Organization”, accurately reflect your organization’s details.\n\nIf you want to non-interactively answer the CSR information prompt, you can do so by adding the -subj option to any OpenSSL commands that request CSR information. Here is an example of the option, using the same information displayed in the code block above:\n\n```shell\n-subj \"/C=US/ST=New York/L=Brooklyn/O=Example Brooklyn Company/CN=examplebrooklyn.com\"\n```\n\n## Generate a Private Key and a CSR\n\nUse this method if you want to use HTTPS (HTTP over TLS) to secure your Apache HTTP or Nginx web server, and you want to use a Certificate Authority (CA) to issue the SSL certificate. The CSR that is generated can be sent to a CA to request the issuance of a CA-signed SSL certificate. If your CA supports SHA-2, add the -sha256 option to sign the CSR with SHA-2.\n\nThis command creates a 2048-bit private key (domain.key) and a CSR (domain.csr) from scratch:\n\n```shell\nopenssl req \\\n       -newkey rsa:2048 -nodes -keyout domain.key \\\n       -out domain.csr\n```\n\nAnswer the CSR information prompt to complete the process.\n\nThe -newkey rsa:2048 option specifies that the key should be 2048-bit, generated using the RSA algorithm. The -nodes option specifies that the private key should not be encrypted with a pass phrase. The -new option, which is not included here but implied, indicates that a CSR is being generated.\n\n## Generate a CSR from an Existing Private Key\n\nUse this method if you already have a private key that you would like to use to request a certificate from a CA.\n\nThis command creates a new CSR (domain.csr) based on an existing private key (domain.key):\n\n```shell\nopenssl req \\\n       -key domain.key \\\n       -new -out domain.csr\n```\n\nAnswer the CSR information prompt to complete the process.\n\nThe -key option specifies an existing private key (domain.key) that will be used to generate a new CSR. The -new option indicates that a CSR is being generated.\n\n## Generate a CSR from an Existing Certificate and Private Key\n\nUse this method if you want to renew an existing certificate but you or your CA do not have the original CSR for some reason. It basically saves you the trouble of re-entering the CSR information, as it extracts that information from the existing certificate.\n\nThis command creates a new CSR (domain.csr) based on an existing certificate (domain.crt) and private key (domain.key):\n\n```shell\nopenssl x509 \\\n       -in domain.crt \\\n       -signkey domain.key \\\n       -x509toreq -out domain.csr\n```\n\nThe -x509toreq option specifies that you are using an X509 certificate to make a CSR.\n\n## Generating SSL Certificates\n\nIf you would like to use an SSL certificate to secure a service but you do not require a CA-signed certificate, a valid (and free) solution is to sign your own certificates.\n\nA common type of certificate that you can issue yourself is a self-signed certificate. A self-signed certificate is a certificate that is signed with its own private key. Self-signed certificates can be used to encrypt data just as well as CA-signed certificates, but your users will be displayed a warning that says that the certificate is not trusted by their computer or browser. Therefore, self-signed certificates should only be used if you do not need to prove your service’s identity to its users (e.g. non-production or non-public servers).\n\nThis section covers OpenSSL commands that are related to generating self-signed certificates.\n\n### Generate a Self-Signed Certificate\n\nUse this method if you want to use HTTPS (HTTP over TLS) to secure your Apache HTTP or Nginx web server, and you do not require that your certificate is signed by a CA.\n\nThis command creates a 2048-bit private key (domain.key) and a self-signed certificate (domain.crt) from scratch:\n\n```shell\nopenssl req \\\n       -newkey rsa:2048 -nodes -keyout domain.key \\\n       -x509 -days 365 -out domain.crt\n```\n\nAnswer the CSR information prompt to complete the process.\n\nThe -x509 option tells req to create a self-signed certificate. The -days 365 option specifies that the certificate will be valid for 365 days. A temporary CSR is generated to gather information to associate with the certificate.\n\n### Generate a Self-Signed Certificate from an Existing Private Key\n\nUse this method if you already have a private key that you would like to generate a self-signed certificate with it.\n\nThis command creates a self-signed certificate (domain.crt) from an existing private key (domain.key):\n\n```shell\nopenssl req \\\n       -key domain.key \\\n       -new \\\n       -x509 -days 365 -out domain.crt\n```\n\nAnswer the CSR information prompt to complete the process.\n\nThe -x509 option tells req to create a self-signed certificate. The -days 365 option specifies that the certificate will be valid for 365 days. The -new option enables the CSR information prompt.\n\n### Generate a Self-Signed Certificate from an Existing Private Key and CSR\n\nUse this method if you already have a private key and CSR, and you want to generate a self-signed certificate with them.\n\nThis command creates a self-signed certificate (domain.crt) from an existing private key (domain.key) and (domain.csr):\n\n```shell\nopenssl x509 \\\n       -signkey domain.key \\\n       -in domain.csr \\\n       -req -days 365 -out domain.crt\n```\n\nThe -days 365 option specifies that the certificate will be valid for 365 days.\n\n## View Certificates\n\nCertificate and CSR files are encoded in PEM format, which is not readily human-readable.\n\nThis section covers OpenSSL commands that will output the actual entries of PEM-encoded files.\n\n### View CSR Entries\n\nThis command allows you to view and verify the contents of a CSR (domain.csr) in plain text:\n\n```shell\nopenssl req -text -noout -verify -in domain.csr\n```\n\n### View Certificate Entries\n\nThis command allows you to view the contents of a certificate (domain.crt) in plain text:\n\n```shell\nopenssl x509 -text -noout -in domain.crt\n```\n\n### Verify a Certificate was Signed by a CA\n\nUse this command to verify that a certificate (domain.crt) was signed by a specific CA certificate (ca.crt):\n\n```shell\nopenssl verify -verbose -CAFile ca.crt domain.crt\n```\n\n## Validate Connections\n\n### Show Certificates\n\nIf you want to see what certificates a domain is using, especially when the domain automatically redirects to another domain (making it impossible to check via your web browser):\n\n```shell\nopenssl s_client -connect fastly.dev:443 -showcerts\n```\n\n### Force a specific TLS version\n\n```shell\nopenssl s_client -connect fastly.dev:443 -tls1   # 1.0\nopenssl s_client -connect fastly.dev:443 -tls1_1 # 1.1\nopenssl s_client -connect fastly.dev:443 -tls1_2 # 1.2\nopenssl s_client -connect fastly.dev:443 -tls1_3 # 1.3\n```\n\n## Private Keys\n\nThis section covers OpenSSL commands that are specific to creating and verifying private keys.\n\n### Create a Private Key\n\nUse this command to create a password-protected, 2048-bit private key (domain.key):\n\n```shell\nopenssl genrsa -des3 -out domain.key 2048\n```\n\nEnter a password when prompted to complete the process.\n\n### Verify a Private Key\n\nUse this command to check that a private key (domain.key) is a valid key:\n\n```shell\nopenssl rsa -check -in domain.key\n```\n\nIf your private key is encrypted, you will be prompted for its pass phrase. Upon success, the unencrypted key will be output on the terminal.\n\n### Verify a Private Key Matches a Certificate and CSR\n\nUse these commands to verify if a private key (domain.key) matches a certificate (domain.crt) and CSR (domain.csr):\n\n```shell\nopenssl rsa -noout -modulus -in domain.key | openssl md5\nopenssl x509 -noout -modulus -in domain.crt | openssl md5\nopenssl req -noout -modulus -in domain.csr | openssl md5\n```\n\nIf the output of each command is identical there is an extremely high probability that the private key, certificate, and CSR are related.\n\n### Encrypt a Private Key\n\nThis takes an unencrypted private key (unencrypted.key) and outputs an encrypted version of it (encrypted.key):\n\n```shell\nopenssl rsa -des3 \\\n       -in unencrypted.key \\\n       -out encrypted.key\n```\n\nEnter your desired pass phrase, to encrypt the private key with.\n\n### Decrypt a Private Key\n\nThis takes an encrypted private key (encrypted.key) and outputs a decrypted version of it (decrypted.key):\n\n```shell\nopenssl rsa \\\n       -in encrypted.key \\\n       -out decrypted.key\n```\n\nEnter the pass phrase for the encrypted key when prompted.\n\n## Convert Certificate Formats\n\nAll of the certificates that we have been working with have been X.509 certificates that are ASCII PEM encoded. There are a variety of other certificate encoding and container types; some applications prefer certain formats over others. Also, many of these formats can contain multiple items, such as a private key, certificate, and CA certificate, in a single file.\n\nOpenSSL can be used to convert certificates to and from a large variety of these formats. This section will cover a some of the possible conversions.\n\n### Convert PEM to DER\n\nUse this command if you want to convert a PEM-encoded certificate (domain.crt) to a DER-encoded certificate (domain.der), a binary format:\n\n```shell\nopenssl x509 \\\n       -in domain.crt \\\n       -outform der -out domain.der\n```\n\nThe DER format is typically used with Java.\n\n### Convert DER to PEM\n\nUse this command if you want to convert a DER-encoded certificate (domain.der) to a PEM-encoded certificate (domain.crt):\n\n```shell\nopenssl x509 \\\n       -inform der -in domain.der \\\n       -out domain.crt\n```\n\n### Convert PEM to PKCS7\n\nUse this command if you want to add PEM certificates (domain.crt and ca-chain.crt) to a PKCS7 file (domain.p7b):\n\n```shell\nopenssl crl2pkcs7 -nocrl \\\n       -certfile domain.crt \\\n       -certfile ca-chain.crt \\\n       -out domain.p7b\n```\n\nNote that you can use one or more -certfile options to specify which certificates to add to the PKCS7 file.\n\nPKCS7 files, also known as P7B, are typically used in Java Keystores and Microsoft IIS (Windows). They are ASCII files which can contain certificates and CA certificates.\n\n### Convert PKCS7 to PEM\n\nUse this command if you want to convert a PKCS7 file (domain.p7b) to a PEM file:\n\n```shell\nopenssl pkcs7 \\\n       -in domain.p7b \\\n       -print_certs -out domain.crt\n```\n\nNote that if your PKCS7 file has multiple items in it (e.g. a certificate and a CA intermediate certificate), the PEM file that is created will contain all of the items in it.\n\n### Convert PEM to PKCS12\n\nUse this command if you want to take a private key (domain.key) and a certificate (domain.crt), and combine them into a PKCS12 file (domain.pfx):\n\n```shell\nopenssl pkcs12 \\\n       -inkey domain.key \\\n       -in domain.crt \\\n       -export -out domain.pfx\n```\n\nYou will be prompted for export passwords, which you may leave blank. Note that you may add a chain of certificates to the PKCS12 file by concatenating the certificates together in a single PEM file (domain.crt) in this case.\n\nPKCS12 files, also known as PFX files, are typically used for importing and exporting certificate chains in Microsoft IIS (Windows).\n\n### Convert PKCS12 to PEM\n\nUse this command if you want to convert a PKCS12 file (domain.pfx) and convert it to PEM format (domain.combined.crt):\n\n```shell\nopenssl pkcs12 \\\n       -in domain.pfx \\\n       -nodes -out domain.combined.crt\n```\n\nNote that if your PKCS12 file has multiple items in it (e.g. a certificate and private key), the PEM file that is created will contain all of the items in it.\n","tags":"#openssl #ssl #tls #certs #csr"},{"id":"c7a1bd810e1ab30b83e99308d11191cb","title":"Pagination: offset vs cursor ","content":"## What is pagination?\n\nWe use pagination to request specific segments of a dataset from an API (and a database) instead of everything at once.\n\n## Offset-based pagination\n\nThe use of offset-based pagination requires passing:\n\n- A limit: the number of records per page\n- An offset: the position of the first item of a page\n\nOffsets allow page-specific features, and are simple to implement and use.\n\n\u003e [!WARNING]\n\u003e Offsets create database performances issues:\n\u003e\n\u003e  - Page 1: offset = 0, limit = 100, reads and returns 100 records\n\u003e  - Page 2: offset = 100, limit = 100, reads **_200_** records, returns 100 records\n\n```\n/* First request */\n\n/services?filter[customer_id]=123\u0026page[number]=1\u0026page[size]=500\n\n/* Response */\n\n“data” : [,...],\n“meta”: {\n  \"current_page\": 1,\n  \"per_page\": 500,\n  \"record_count\": 1133,\n  \"total_pages\": 3\n}\n\n/* Next request */\n\n/services?filter[customer_id]=123\u0026page[number]=2\u0026page[size]=500\n```\n\n## Cursor-based pagination\n\nThe use of cursor-based pagination requires passing:\n\n- A limit: the number of records per page\n\nThe response will include:\n\n- A cursor: the identifier of the last item in a page\n\nAnd subsequent request will pass such cursor:\n\n- Page 1: limit = 100, reads and returns 100 records, with a cursor pointing to item 100 (cursor = ABC*)\n- Page 2: limit = 100, cursor = ABC, reads and returns 100 records starting with the next item after ABC, with a cursor pointing to item 200 (cursor = DEF*)\n\n\u003e [!NOTE]\n\u003e *example identifiers\n\n```\n/* First request */\n/services?filter[customer_id]=123\u0026limit=500\n\n/* Response */\n“data” : [,…],\n“meta”: {\n  \"next_cursor\": “1tkSVoL9b7VAvdIhad9aH8”,\n  \"limit\": 500\n}\n\n/* Next request */\n/services?filter[customer_id]=123\u0026limit=500\u0026cursor=1tkSVoL9b7VAvdIhad9aH8\n```\n\n\u003e [!IMPORTANT]\n\u003e Cursor-based pagination provides a consistent query time, ideal for vast and changing datasets, and excluding total count and number of pages makes the performance optimization even more significative.\n\n## Issues with cursor-based pagination\n\n- The lack of total number of items in cursor-based responses makes it difficult to provide that information with certainty for clients in one request\n- In the case of some UI clients, this removes the ability to provide numbered pages for large datasets, but traversing to previous and next “pages” is still possible.\n- It is recommended that you remove page counts as a feature provided in the API responses.\n- The total number of items remains a needed feature, for what we recommend a secondary request to obtain that number.\n- Lack of page numbers make a strong argument for record discoverability in the UI, an issue we can address with better dataset search capabilities.\n\n```\n/* Count request */\n/services?filter[customer_id]=123\u0026total=true\n\n/* Response */\n“data” : [],\n“meta”: {\n  \"total\": 1113\n}\n```\n","tags":"#pagination #design"},{"id":"8a6401fb294964984a27d73c2bd97664","title":"Go: GitHub Actions update app dependencies daily with private repo access ","content":"name: Update Dependencies and Run Tests\n\non:\n  # Schedule to run at 9am UTC every day\n  schedule:\n    - cron: '0 9 * * *'\n\n  # Allow manual trigger via GitHub UI\n  workflow_dispatch:\n\njobs:\n  update-deps-and-test:\n    runs-on: ubuntu-latest\n\n    steps:\n    - name: Check out repository\n      uses: actions/checkout@v3\n\n    - name: Set up Go\n      uses: actions/setup-go@v4\n      with:\n        go-version-file: 'go.mod'\n\n    - name: Set up private Go modules\n      run: |\n        echo \"Setting up GOPRIVATE and GitHub token\"\n        echo \"machine github.com login ${{ secrets.GH_PAT_CI }}\" \u003e ~/.netrc\n      env:\n        GOPRIVATE: \"github.com/some_private_repo\" # \u003c\u003c\u003c\u003c\u003c\u003c\u003c\u003c\u003c\u003c\u003c\u003c\u003c\u003c\u003c\u003c\u003c\u003c UPDATE THIS\n\n    - name: Update dependencies\n      run: |\n        go get -u -t ./...\n        go mod tidy\n\n    - name: Run tests\n      env:\n        GO_TESTARGS: \"-count=1 -v -run=Test ./...\"\n      run: go test -race  -count=1 -v -run=Test ./...\n\n    - name: Commit changes\n      if: success()\n      run: |\n        git config --global user.name \"github-actions[bot]\"\n        git config --global user.email \"github-actions[bot]@users.noreply.github.com\"\n        git add .\n        git commit -m \"build: update dependencies [skip ci]\"\n        git push\n","tags":"#ci #cron #go"},{"id":"439bb57fcba114ea7500bbc21951112c","title":"What is a SKU ","content":"SKU stands for stock-keeping unit. \n\nIt is mostly the unit used by Salesforce, and all other business systems to 'sell' and invoice for products/features we sell\n\nIt can take up to a quarter or more to get a SKU.\n\nYou can't sell something for $$ without a SKU.\n\nMonetization engineering often won't get started on any work without a SKU/product description in Salesforce.\n","tags":"#sku"},{"id":"85e4cd0d0f227a84be3068ec12f9bf72","title":"Go: Codesign a Go test binary that listens on network and needs to accept incoming network connections ","content":"# 0. Have a binary to codesign.\n# NOTE: I use `if os.Getenv(\"SKIP_FTP\") != \"\" { t.Skip(\"...\") }` to allow skipping the test when running the full test suite.\n\ngo test -c -o ./path/to/package/test_binary ./path/to/package\n\n# 1. Create self-signed private key and certificate\n# IMPORTANT: The `-addext` flags are essential for codesigning purposes.\n\nopenssl req -new -x509 -days 365 -nodes \\\n    -keyout ExampleTestBinaryCodeSigning.key -out ExampleTestBinaryCodeSigning.crt \\\n    -subj \"/CN=ExampleTestBinaryCodeSigning\" \\\n    -addext \"keyUsage=digitalSignature,keyEncipherment\" \\\n    -addext \"extendedKeyUsage=codeSigning\"\n\n# 2. Export private key and certificate as p12.\n# IMPORTANT: The `-legacy` flag is essential if using OpenSSL 3.x on macOS.\n# OpenSSL 3.x changed its default algorithm in pkcs12. \n# Which is not compatible with embedded Security frameworks in macOS/iOS. \n# So you either downgrade to OpenSSL 1.1 or use -legacy flag.\n\nopenssl pkcs12 -export \\\n  -out ExampleTestBinaryCodeSigning.p12 \\\n  -inkey ExampleTestBinaryCodeSigning.key \\\n  -in ExampleTestBinaryCodeSigning.crt \\\n  -legacy \\\n  -passout pass:whatever\n\n# 3. Validate the password has been set on your p12 (-nokeys vs -noout == just different output)\n\nopenssl pkcs12 -info -nokeys -in ExampleTestBinaryCodeSigning.p12 -legacy -password pass:whatever\nopenssl pkcs12 -info -noout  -in ExampleTestBinaryCodeSigning.p12 -legacy -password pass:whatever\n\n# 4. List your keychains so you know which one you're going to reference and where it is located.\n# It can be extracted automatically using `security list | awk '/login.keychain/ { print $1 }'`\n\nsecurity list\n\n# 5. Import your p12 into your keychain.\n\nsecurity import ExampleTestBinaryCodeSigning.p12 -k ~/Library/Keychains/login.keychain-db -P whatever -T /usr/bin/codesign\n\n# 6. Find the certificate in your keychain.\n\nsecurity find-certificate -a -c \"ExampleTestBinaryCodeSigning\" -p\n\n# 7. Check the details of the certificate in the keychain.\n\nsecurity find-certificate -c \"ExampleTestBinaryCodeSigning\"\n\n# 8. Set the certificate to be trusted.\n# Only possible if you still have the cert.\n# Otherwise you have to manually trust it via the \"Keychain Access\" GUI.\n\nsecurity add-trusted-cert -d -r trustRoot -k ~/Library/Keychains/login.keychain-db ./ExampleTestBinaryCodeSigning.crt\n\n# 9. Validate you have 'valid' identities.\n\nsecurity find-identity -v\nsecurity find-identity -p codesigning -v\n\n# 10. Now you may codesign your binary.\n\ncodesign -f -s \"ExampleTestBinaryCodeSigning\" ./path/to/package/test_binary\n.PHONY: codesigning\ncodesigning: ID=ExampleTestBinaryCodeSigningIdentity\ncodesigning: CERT_PSW=whatever\ncodesigning:\n\t@if [ $$(uname) == \"Darwin\" ] \u0026\u0026 [ \"$$(security find-certificate -a -c \"$(ID)\" -p)\" == \"\" ]; then \\\n\t\techo \"\"; \\\n\t\techo \"⚠️  no code-signing certificate found in your keychain (so we'll try to generate that for you)\"; \\\n\t\techo \"\"; \\\n\t\topenssl req -new -x509 -days 365 -nodes \\\n\t\t\t-keyout $(ID).key -out $(ID).crt \\\n\t\t\t-subj \"/CN=$(ID)\" \\\n\t\t\t-addext \"keyUsage=digitalSignature,keyEncipherment\" \\\n\t\t\t-addext \"extendedKeyUsage=codeSigning\"; \\\n\t\topenssl pkcs12 -export \\\n\t\t  -out $(ID).p12 \\\n\t\t  -inkey $(ID).key \\\n\t\t  -in $(ID).crt \\\n\t\t  -legacy \\\n\t\t  -passout pass:$(CERT_PSW); \\\n\t\ttrap \"rm -f $(ID)*\" EXIT; \\\n\t\tkc=$$(security list | awk '/login.keychain/ { gsub(/^ *| *$$/, \"\"); print $$1 }' | sed 's/\"//g'); \\\n\t\tsecurity import $(ID).p12 \\\n\t\t\t-k \"$$kc\" \\\n\t\t\t-P $(CERT_PSW) \\\n\t\t\t-T /usr/bin/codesign; \\\n\t\tsecurity add-trusted-cert -d -r trustRoot -k $$kc $(ID).crt; \\\n\t\tif security find-identity -p codesigning -v | grep '0 valid identities found'; then \\\n\t\t\techo \"🚨 failed to find a valid code-signing identity\"; \\\n\t\t\texit 1; \\\n\t\tfi \\\n\tfi\n\n.PHONY: test\ntest: codesigning ## Run project's test suite with race detection\n\t@if [ $$(uname) == \"Darwin\" ]; then \\\n\t\tgo test -c -o ./path/to/package/test_binary ./path/to/package; \\\n\t\tcodesign -f -s \"ExampleTestBinaryCodeSigningIdentity\" ./path/to/package/test_binary; \\\n\t\ttrap \"rm -f ./path/to/package/test_binary\" EXIT; \\\n\t\tcd ./path/to/package/ \u0026\u0026 { ./test_binary; cd -; } || cd -; \\\n\t\t# SKIP_FTP forces the go toolchain to skip the problematic test that uses the network; \\\n\t\tSKIP_FTP=true go test -race -v -count=1 $(GO_BUILDARGS) $(GO_TESTARGS) $(APP_TESTARGS); \\\n\telse \\\n\t\tgo test -race -v -count=1 $(GO_BUILDARGS) $(GO_TESTARGS) $(APP_TESTARGS); \\\n\tfi\n","tags":"#go #macos #network #security"},{"id":"e056ae364b2f10cc01d26d5525ec269b","title":"Go: the goto statement ","content":"// https://play.golang.com/p/EAtzwpDeb30\n// https://go.dev/ref/spec#Goto_statements\n\npackage main\n\nimport (\n\t\"fmt\"\n)\n\nfunc main() {\n\tgoTo(\"beep\")\n\tgoTo(\"boop\")\n\tgoTo(\"xxxx\")\n}\n\nfunc goTo(location string) {\n\tswitch location {\n\tcase \"beep\":\n\t\tgoto beep\n\tcase \"boop\":\n\t\tgoto boop\n\tdefault:\n\t\tfmt.Println(\"unrecognised location\")\n\t\treturn\n\t}\n\nbeep:\n\tfmt.Println(\"beep was reached\")\n\treturn // IMPORTANT: Go will continue to execute the following code, so return to avoid accidentally printing \"boop was reached\"\nboop:\n\tfmt.Println(\"boop was reached\")\n\treturn\n}\n","tags":"#go"},{"id":"f86efc7940dbe27d0703c831ecf01b71","title":"Go: local SSH tunnel using google cloud ","content":"// Package main is the entrypoint to the proxy CLI program.\npackage main\n\nimport (\n\t\"bytes\"\n\t\"context\"\n\t\"errors\"\n\t\"flag\"\n\t\"fmt\"\n\t\"io\"\n\t\"log\"\n\t\"os\"\n\t\"os/exec\"\n\t\"os/signal\"\n\t\"syscall\"\n\n\t\"golang.org/x/sys/unix\"\n)\n\n// Open an SSH tunnel on a local port to the given proxy address.\nfunc main() {\n\tif err := run(); err != nil {\n\t\tlog.Fatalf(\"failed to run: %s\", err)\n\t}\n}\n\nfunc run() error {\n\tproxyAddr := flag.String(\"connect\", \"\", \"open SSH tunnel to `IP address` (omit port)\")\n\tlogin := flag.Bool(\"login\", false, \"log in instead of opening tunnel\")\n\tport := flag.String(\"port\", \"1080\", \"local `port` number of tunnel\")\n\tflag.Parse()\n\n\tgcpURL, err := getGCPURL(*proxyAddr)\n\tif gcpURL == \"\" || err != nil {\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"failed to get GCP URL: %w\", err)\n\t\t}\n\t\tmsg := \"no GCP proxy with IP address %v found; make sure you’ve run 'gcloud components install beta' first; check gcloud auth list and the IP address\"\n\t\treturn fmt.Errorf(msg, *proxyAddr)\n\t}\n\n\tif *login {\n\t\tloginReplaceProc(gcpURL)\n\t\treturn nil\n\t}\n\n\tctx, cancel := context.WithCancel(context.Background())\n\tdefer cancel()\n\tcmd, err := connect(ctx, gcpURL, *port, os.Stderr)\n\tif err != nil {\n\t\treturn nil\n\t}\n\tif cmd == nil {\n\t\treturn fmt.Errorf(\"no proxy with address: %#v\", *proxyAddr)\n\t}\n\n\tgo func() {\n\t\tc := make(chan os.Signal, 1)\n\t\tsignal.Notify(c, syscall.SIGINT, syscall.SIGTERM)\n\t\t\u003c-c\n\t\tcancel()\n\t}()\n\n\tfmt.Fprintf(os.Stdout, \"forwarding localhost:%s to proxy: %s\\n\", *port, *proxyAddr)\n\terr = cmd.Wait()\n\tif err != nil {\n\t\tvar exitErr *exec.ExitError\n\t\tif errors.As(err, \u0026exitErr) {\n\t\t\terr = fmt.Errorf(\"exit error: %s: %w\", exitErr.Stderr, err)\n\t\t}\n\t\treturn err\n\t}\n\n\treturn nil\n}\n\nfunc connect(ctx context.Context, url, port string, out io.Writer) (*exec.Cmd, error) {\n\tcmd := exec.CommandContext(ctx, \"gcloud\", \"compute\", \"ssh\", \"--ssh-flag=-nNTC -D localhost:\"+port, \"--project=\u003cREDACTED\u003e\", url) // #nosec: G204\n\tif out != nil {\n\t\tcmd.Stdout = out\n\t\tcmd.Stderr = out\n\t}\n\terr := cmd.Start()\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"failed to start gcloud command: %w\", err)\n\t}\n\treturn cmd, nil\n}\n\nfunc loginReplaceProc(url string) {\n\tcmd := exec.Command(\"gcloud\", \"beta\", \"compute\", \"ssh\", \"--project=\u003cREDACTED\u003e\", url)\n\terr := unix.Exec(cmd.Path, cmd.Args, os.Environ())\n\tfmt.Fprintln(os.Stderr, err)\n}\n\nfunc getGCPURL(addr string) (string, error) {\n\tcmd := exec.Command(\"gcloud\", \"beta\", \"compute\", \"addresses\", \"list\", \"--format=value(users[0].flatten())\", \"--project=\u003cREDACTED\u003e\", \"--filter=labels.production=ssh-proxy AND address=\"+addr) // #nosec: G204\n\tout, err := cmd.Output()\n\tout = bytes.TrimSpace(out)\n\treturn string(out), err\n}\n","tags":"#go #ssh"},{"id":"62a37111624853397982ac7c6369be19","title":"Go: f-tests replace table-driven tests ","content":"https://itnext.io/f-tests-as-a-replacement-for-table-driven-tests-in-go-8814a8b19e9e\n\nThe following shows how to use sub-tests, which are nice because they give a visible name to each test and allow you to run each sub test in isolation:\n\n```go\nfunc TestSomeFuncWithSubtests(t *testing.T) {\n  f := func(t *testing.T, input, outputExpected string) {\n    t.Helper()\n    \n    output := SomeFunc(input)\n    if output != outputExpected {\n      t.Fatalf(\"unexpected output; got %q; want %q\", output, outputExpected)\n    }\n  }\n\n  t.Run(\"first_subtest\", func(t *testing.T) {\n    f(t, \"foo\", \"bar\")\n  })\n\n  t.Run(\"second_subtest\", func(t *testing.T) {\n    f(t, \"baz\", \"abc\")\n  })\n}\n```\n\nThe following is a combination of f-test style with table-driven style...\n\n```go\nfunc TestThing_Success(t *testing.T) {\n    f := func(t *testing.T, input1, input2 string, expected int) {\n        // hoist the test code with assertions and clear args...\n    }\n\n    testcases := []struct{name, input1, input2 string, expected int}{\n        {},\n        // etc...\n    }\n\n    for _, tc := range testcases {\n        t.Run(tc.name, func(t *testing.T) {\n            f(t, tc.input1, tc.input2, tc.expected)\n        })\n    }\n}\n```\n","tags":"#go #tests"},{"id":"d076e8108f216c109d14a349e65ce490","title":"Music: Separate the musical instruments from a song and make an instrumental","content":"Download the demucs app:  \nhttps://github.com/CarlGao4/Demucs-Gui/releases\n\nOpen the app and press \"Load\".\n\nClick on the \"File queue\" tab.\n\nDrag and drop your mp3 file into the app window.\n\nClick on \"Start separation\".\n\nOnce finished, you'll find a folder in the same directory as your mp3 file.\n\nThis folder will contain separate `.flac` music files for the vocals, drums, guitar, bass etc.\n\nYou can then recombine the song, omitting the vocals, using the following terminal command:\n\n```\nbrew install ffmpeg\nffmpeg -i other.flac -i bass.flac -i drums.flac -filter_complex \"[0:a][1:a][2:a]amerge=inputs=3[aout]\" -map \"[aout]\" -ac 2 -c:a libmp3lame instrumental.mp3\n```\n\n\u003e [!NOTE]\n\u003e Replace/update the `-i other.flac`, `-i bass.flac` etc, depending on what parts you want put back together.\n\nThe `ffmpeg` command will generate an `instrumental.mp3` file.\n","tags":""},{"id":"95661bd8dad0b66909d3cd1823f0b8d4","title":"Vim: beginner notes ","content":"There are many 'motions' and things you can do but I would probably say there are some essential motions you'll use a lot...\n\n- `:\u003cLINE_NUMBER\u003e` to jump to a specific line number (e.g. `:10`)\n- `gg` to go to the top of the file (`G` to go to the bottom)\n- `Ctrl+d` to go down half a page (`Ctrl+u` to go up half a page)\n- `{` and `}` to jump back and forth between paragraphs\n- `f\u003cCHARACTER\u003e` to jump forward on the current line to a specific character (use `F` to search backwards in the line).\n- `^` to go to the start of the line (`0` if you want to specifically go back to the zero column)\n- `$` to go to the end of the line\n- `/\u003cPATTERN\u003e` to search for text in the current buffer (see https://www.vimregex.com/ or use `\\v` flag to make regexes a bit more sane, e.g. `/\\v\u003cPATTERN`)\n\nThe typical structure for doing something like \"delete the text inside parentheses\" is... \"operation, placement, pattern\" (not sure if that's the correct terminology to use, I've not had to think about that sort of stuff in a long time 😅) but an example would be `di(` where `d` is the operation (i.e. delete), `i` is the placement (i.e. inside), `(` is the pattern (i.e. the parenthesis).\n\nFor the \"operation\": you have `d` for delete, `v` for select, `c` for change.\n\nFor the \"placement\": you have `i` for inside, `a` for around.\n\n**Example:** if I have the text `myFunction(something)` and my cursor is inside the parentheses then I can do...\n\n- `ci(` to remove the text inside the parentheses and put me into `INSERT` mode so I can type new text \n- `vi(` to select the text inside the parentheses, where I can then `y` to \"yank\" the text into my clipboard\n- `di(` to get `myFunction()` \n- `da(` to get `myFunction`\n\nOf course there's a lifetime of motions/movement/modal stuff you can learn but I'd definitely say the above is my \"bread and butter\" of things I use a lot (outside of features from plugins).\n\nGood luck!\n\n\u003e **EDIT:** the following Neovim plugins can help you https://github.com/jinh0/eyeliner.nvim + https://github.com/folke/which-key.nvim\n","tags":"#vim #beginner"},{"id":"49b7bdafaee71adcd5aef282f47509d2","title":"Shell: Shell Scripting Best Practices ","content":"# Shell Script Best Practices\n\n\u003e [!NOTE]\n\u003e Source https://sharats.me/posts/shell-script-best-practices/\n\nThis article is about a few quick thumb rules I use when writing shell scripts that I’ve come to appreciate over the years. Very opinionated.\n\n## Things\n\n1.  Use `bash`. Using `zsh` or `fish` or any other, will make it hard for others to understand / collaborate. Among all shells, `bash` strikes a good balance between portability and DX.\n    \n2.  Just make the first line be `#!/usr/bin/env bash`, even if you don’t give executable permission to the script file.\n    \n3.  Use the `.sh` (or `.bash`) extension for your file. It may be fancy to not have an extension for your script, but unless your case explicitly depends on it, you’re probably just trying to do clever stuff. Clever stuff are hard to understand.\n    \n4.  Use `set -o errexit` at the start of your script.\n    \n    *   So that when a command fails, `bash` exits instead of continuing with the rest of the script.\n5.  Prefer to use `set -o nounset`. You _may_ have a good excuse to not do this, but, my opinion, it’s best to always set it.\n    \n    *   This will make the script fail, when accessing an unset variable. Saves from horrible unintended consequences, with typos in variable names.\n    *   When you want to access a variable that may or may not have been set, use `\"${VARNAME-}\"` instead of `\"$VARNAME\"`, and you’re good.\n6.  Use `set -o pipefail`. Again, you may have good reasons to not do this, but I’d recommend to always set it.\n    \n    *   This will ensure that a pipeline command is treated as failed, even if one command in the pipeline fails.\n7.  Use `set -o xtrace`, with a check on `$TRACE` env variable.\n    \n    *   For copy-paste: `if [[ \"${TRACE-0}\" == \"1\" ]]; then set -o xtrace; fi`.\n    *   This helps in debugging your scripts, a lot. Like, really lot.\n    *   People can now _enable_ debug mode, by running your script as `TRACE=1 ./script.sh` instead of `./script.sh`.\n8.  Use `[[ ]]` for conditions in `if` / `while` statements, instead of `[ ]` or `test`.\n    \n    *   `[[ ]]` is a bash builtin keyword, and is more powerful than `[ ]` or `test`.\n9.  Always quote variable accesses with double-quotes.\n    \n    *   One place where it’s _okay_ not to is on the _left-hand-side_ of an `[[ ]]` condition. But even there I’d recommend quoting.\n    *   When you need the unquoted behaviour, using `bash` arrays will likely serve you much better.\n10.  Use `local` variables in functions.\n    \n11.  Accept multiple ways that users can ask for help and respond in kind.\n    \n    *   Check if the first arg is `-h` or `--help` or `help` or just `h` or even `-help`, and in all these cases, print help text and exit.\n    *   Please. For the sake of your future-self.\n12.  When printing error messages, please redirect to stderr.\n    \n    *   Use `echo 'Something unexpected happened' \u003e\u00262` for this.\n13.  Use long options, where possible (like `--silent` instead of `-s`). These serve to document your commands explicitly.\n    \n    *   Note though, that commands shipped on some systems like macOS don’t always have long options.\n14.  If appropriate, change to the script’s directory close to the start of the script.\n    \n    *   And it’s usually always appropriate.\n    *   Use `cd \"$(dirname \"$0\")\"`, which works in _most_ cases.\n15.  Use `shellcheck`. Heed its warnings.\n    \n\n## Template\n\n```shel\n#!/usr/bin/env bash\n\nset -o errexit\nset -o nounset\nset -o pipefail\nif [[ \"${TRACE-0}\" == \"1\" ]]; then\n    set -o xtrace\nfi\n\nif [[ \"${1-}\" =~ ^-*h(elp)?$ ]]; then\n    echo 'Usage: ./script.sh arg-one arg-two\n\nThis is an awesome bash script to make your life better.\n\n'\n    exit\nfi\n\ncd \"$(dirname \"$0\")\"\n\nmain() {\n    echo do awesome stuff\n}\n\nmain \"$@\"\n\n```\n\n\n## Conclusion\n\nI try to follow these rules in my scripts, and they’re known to have made at least my own life better. I’m still not consistent though, unfortunately, in following my own rules. So perhaps writing them down this way will help me improve there as well.\n\nDo you have anything you think I should add to this? Please share in the comments!\n\nEdit 1: Included fixes from HN comments at [https://news.ycombinator.com/item?id=33355407](https://news.ycombinator.com/item?id=33355407) and [https://news.ycombinator.com/item?id=33355077](https://news.ycombinator.com/item?id=33355077).\n\nEdit 2: Fix from [https://news.ycombinator.com/item?id=33354759](https://news.ycombinator.com/item?id=33354759).\n","tags":"#shell #bash"},{"id":"9302d54e6f1ecb5e8245204315dd9436","title":"SSH: Proxy HTTP requests through a SSH connection via SOCKS5 proxy ","content":"https://www.linkedin.com/pulse/proxying-web-traffic-via-ssh-mark-el-khoury\n\nEssentially your local machines creates a SOCK5 proxy which connects to a remote server via SSH (using either username/password or SSH PKI Cert/Key combination).\n\nThe SOCK5 proxy handles sending the HTTP request via the SSH tunnel.\n\nThe remote server will automatically process the HTTP request and handle sending it to its intended destination.\n\nThe upstream (i.e. the endpoint being requested) will see the request coming from the SSH server and presume that's where it originated.\n\n## Go Example\n\n```go\npackage main\n\nimport (\n\t\"golang.org/x/crypto/ssh\"\n\t\"golang.org/x/net/proxy\"\n\t\"net/http\"\n\t\"net/url\"\n\t\"io/ioutil\"\n\t\"log\"\n\t\"time\"\n)\n\nfunc main() {\n\thttp.HandleFunc(\"/\", handleRequestAndRedirect)\n\tlog.Fatal(http.ListenAndServe(\":8080\", nil))\n}\n\nfunc handleRequestAndRedirect(w http.ResponseWriter, r *http.Request) {\n\t// SSH connection details\n\tsshHost := \"ssh.example.com:22\"\n\tsshUser := \"your_ssh_user\"\n\tsshPassword := \"your_ssh_password\"\n\n\t// Upstream service URL\n\tupstreamURL := \"http://upstream-service.example.com\"\n\n\t// Create the SSH client configuration\n\tsshConfig := \u0026ssh.ClientConfig{\n\t\tUser: sshUser,\n\t\tAuth: []ssh.AuthMethod{\n\t\t\tssh.Password(sshPassword),\n\t\t},\n\t\tHostKeyCallback: ssh.InsecureIgnoreHostKey(),\n\t\tTimeout:         5 * time.Second,\n\t}\n\n\t// Establish the SSH connection\n\tsshConn, err := ssh.Dial(\"tcp\", sshHost, sshConfig)\n\tif err != nil {\n\t\thttp.Error(w, \"Failed to dial SSH: \"+err.Error(), http.StatusInternalServerError)\n\t\treturn\n\t}\n\tdefer sshConn.Close()\n\n\t// Create a SOCKS5 proxy client over the SSH connection\n\tsocks5Client, err := proxy.SOCKS5(\"tcp\", \"localhost:0\", nil, \u0026sshDialer{sshConn})\n\tif err != nil {\n\t\thttp.Error(w, \"Failed to create SOCKS5 proxy: \"+err.Error(), http.StatusInternalServerError)\n\t\treturn\n\t}\n\n\t// Create an HTTP client that uses the SOCKS5 proxy\n\thttpClient := \u0026http.Client{\n\t\tTransport: \u0026http.Transport{\n\t\t\tDial: socks5Client.Dial,\n\t\t},\n\t}\n\n\t// Create the request to the upstream service\n\treq, err := http.NewRequest(r.Method, upstreamURL, r.Body)\n\tif err != nil {\n\t\thttp.Error(w, \"Failed to create request: \"+err.Error(), http.StatusInternalServerError)\n\t\treturn\n\t}\n\n\t// Copy the headers from the original request to the new request\n\tfor key, values := range r.Header {\n\t\tfor _, value := range values {\n\t\t\treq.Header.Add(key, value)\n\t\t}\n\t}\n\n\t// Perform the request\n\tresp, err := httpClient.Do(req)\n\tif err != nil {\n\t\thttp.Error(w, \"Failed to perform request: \"+err.Error(), http.StatusInternalServerError)\n\t\treturn\n\t}\n\tdefer resp.Body.Close()\n\n\t// Copy the response from the upstream service to the original response\n\tbody, err := ioutil.ReadAll(resp.Body)\n\tif err != nil {\n\t\thttp.Error(w, \"Failed to read response: \"+err.Error(), http.StatusInternalServerError)\n\t\treturn\n\t}\n\n\tfor key, values := range resp.Header {\n\t\tfor _, value := range values {\n\t\t\tw.Header().Add(key, value)\n\t\t}\n\t}\n\tw.WriteHeader(resp.StatusCode)\n\tw.Write(body)\n}\n\n// sshDialer is a custom Dialer implementation that uses an SSH connection\ntype sshDialer struct {\n\tclient *ssh.Client\n}\n\n// Dial connects to the address on the named network using the SSH client.\nfunc (d *sshDialer) Dial(network, addr string) (net.Conn, error) {\n\treturn d.client.Dial(network, addr)\n}\n```\n","tags":"#ssh #proxy #tunnel"},{"id":"1d11348ef687d6de453f2f9b7a223e61","title":"Shell: rename files matching specific pattern ","content":"#!/bin/bash\n\n# Iterate over each MP4 file in the current directory\nfor file in *.mp4; do\n  # Check if the file matches the pattern: MMDDYYYY \u003cNAME\u003e.mp4\n  if [[ \"$file\" =~ ^([0-9]{2})([0-9]{2})([0-9]{4})\\ (.*)\\.mp4$ ]]; then\n    # Extract the parts of the filename\n    MM=\"${BASH_REMATCH[1]}\"\n    DD=\"${BASH_REMATCH[2]}\"\n    YYYY=\"${BASH_REMATCH[3]}\"\n\n    # Construct the new filename (YYYY.MM.DD.mp4)\n    new_filename=\"${YYYY}.${MM}.${DD}.mp4\"\n\n    # Rename the file\n    mv \"$file\" \"$new_filename\"\n\n    # Print a message indicating the rename\n    echo \"Renamed '$file' to '$new_filename'\"\n  else\n    echo \"File '$file' does not match the expected pattern.\"\n  fi\ndone\n","tags":"#shell #bash #macos #files #rename"},{"id":"dcabda9b762ad23781af76fd1971e0f7","title":"YAML: anchors ","content":"If you've not used YAML before you might be wondering what `\u0026\u003cname\u003e` means. \n\nWhat this will do is create an 'anchor'. \n\nAnchors allow you to inject the associated block of data any where else within your YAML configuration file. \n\nThis allows you to avoid duplicating those particular settings.\n\nThe way to do that injection is to 'dereference' the anchor with an asterisk. \n\ne.g. `log_format: *log_format` or inject it _inside_ another block using a double chevron (e.g. `\u003c\u003c: *upstreams`). \n\nI recommend having a read through the YAML documentation to get a better feel for how these YAML features work.\n\nhttps://onlineyamltools.com/convert-yaml-to-json is a good site to test this out on as it can convert your YAML to JSON and you can see if it works how you expect.\n\nBelow demonstrates a problem with this feature, which is it works best with objects, not arrays... \n\nIn the below example I want to inject the same `args:` array into the array entry that follows...\n\n```yaml\n- containers:\n    - args: \u0026args\n        - -cfg\n        - /vault/secrets/datasync.conf\n        - -backup\n      name: datasync\n- containers:\n    - args: *args\n      name: datasync\n```\n\nThis products:\n\n```json\n[\n  {\n    \"containers\": [\n      {\n        \"args\": [\n          \"-cfg\",\n          \"/vault/secrets/datasync.conf\",\n          \"-backup\"\n        ],\n        \"name\": \"datasync\"\n      }\n    ]\n  },\n  {\n    \"containers\": [\n      {\n        \"args\": [\n          \"-cfg\",\n          \"/vault/secrets/datasync.conf\",\n          \"-backup\"\n        ],\n        \"name\": \"datasync\"\n      }\n    ]\n  }\n]\n```\n\nThis is fine. But what if I want to extend `args` in the second case to have an extra argument?\n\nThe problem with that is I can't _extend_ the args list. This is the problem with the array data type. When working with an object you can use `\u003c\u003c: *whatever` and then extend an object's key/value but not with an array :-( \n\nWhere as if it was an object instead of an array:\n\n```yaml\n- containers:\n    - args: \u0026args\n        foo: bar\n      name: datasync\n- containers:\n    - args: \n        \u003c\u003c: *args\n        beep: boop\n      name: datasync\n```\n\nThen this would work fine...\n\n```json\n[\n  {\n    \"containers\": [\n      {\n        \"args\": {\n          \"foo\": \"bar\"\n        },\n        \"name\": \"datasync\"\n      }\n    ]\n  },\n  {\n    \"containers\": [\n      {\n        \"args\": {\n          \"foo\": \"bar\",\n          \"beep\": \"boop\"\n        },\n        \"name\": \"datasync\"\n      }\n    ]\n  }\n]\n```\n","tags":"#yaml #anchors"},{"id":"4ac5854116d0ccae632b42ba2ed2c2e4","title":"Go: Generic Slice Map function ","content":"// https://play.golang.com/p/TbawROSRv8X\n\npackage main\n\nimport (\n\t\"fmt\"\n\n\t\"golang.org/x/net/idna\"\n)\n\nfunc main() {\n\ts := []string{\"xn--6frz82g\", \"xn--9dbq2a\", \"xn--vhquv\"}\n\tfmt.Printf(\"%#v\\n\", s)\n\tMap[string](s, func(zone string) string {\n\t\tu, err := idna.ToUnicode(zone)\n\t\tif err != nil {\n\t\t\treturn zone\n\t\t}\n\t\treturn u\n\t})\n\tfmt.Printf(\"%#v\\n\", s)\n}\n\n// Map takes a slice and a map function,\n// then applies it to each element of the slice.\nfunc Map[T any](s []T, m func(T) T) {\n\tfor i, e := range s {\n\t\ts[i] = m(e)\n\t}\n}\n","tags":"#go #computation #generics"},{"id":"dbf264af81bd51e4519357e11742699f","title":"Go: Simple line-by-line diff in Go ","content":"// Probably should just use https://github.com/sergi/go-diff\n\n// printDiff prints the differences between two files line by line.\nfunc printDiff(file1, file2 string) error {\n\tf1, err := os.Open(file1)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"failed to open file1: %w\", err)\n\t}\n\tdefer f1.Close()\n\n\tf2, err := os.Open(file2)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"failed to open file2: %w\", err)\n\t}\n\tdefer f2.Close()\n\n\tscanner1 := bufio.NewScanner(f1)\n\tscanner2 := bufio.NewScanner(f2)\n\n\tlineNumber := 1\n\tfor scanner1.Scan() || scanner2.Scan() {\n\t\tvar line1, line2 string\n\t\tif scanner1.Scan() {\n\t\t\tline1 = scanner1.Text()\n\t\t}\n\t\tif scanner2.Scan() {\n\t\t\tline2 = scanner2.Text()\n\t\t}\n\n\t\tif line1 != line2 {\n\t\t\tfmt.Printf(\"Line %d:\\n\", lineNumber)\n\t\t\tfmt.Printf(\"- %s\\n\", line1)\n\t\t\tfmt.Printf(\"+ %s\\n\", line2)\n\t\t}\n\t\tlineNumber++\n\t}\n\n\tif err := scanner1.Err(); err != nil {\n\t\treturn fmt.Errorf(\"error reading file1: %w\", err)\n\t}\n\tif err := scanner2.Err(); err != nil {\n\t\treturn fmt.Errorf(\"error reading file2: %w\", err)\n\t}\n\n\treturn nil\n}\n\n// printDiff prints the differences between two files using the standard diff\n// CLI installed on the host machine.\nfunc printDiff(file1, file2 string, logger *slog.Logger) error {\n\tcmd := exec.Command(\"diff\", file1, file2)\n\toutput, err := cmd.CombinedOutput()\n\tif err != nil {\n\t\t// NOTE: See `EXIT STATUS` in `man diff`.\n\t\t// 0:  No differences were found.\n\t\t// 1:  Differences were found.\n\t\t// \u003e1: An error occurred.\n\t\tvar exitErr *exec.ExitError\n\t\tif errors.As(err, \u0026exitErr) \u0026\u0026 exitErr.ExitCode() == 1 {\n\t\t\tfmt.Printf(\"%s\\n\", output)\n\t\t\treturn nil\n\t\t}\n\t\t// Actual error occurred.\n\t\terr = fmt.Errorf(\"failed to run diff command: %w\", err)\n\t\tlogger.LogAttrs(context.Background(), slog.LevelError, \"diff_files\", slog.Any(\"error\", err))\n\t\treturn err\n\t}\n\treturn nil\n}\n","tags":"#go #utility"},{"id":"d21ee193a83fdf68bc3fa506f25782fe","title":"Go: Delete a slice entry in Go ","content":"// zones    == complete list of dns zones\n// denyList == list of zones to remove\nfor _, deniedZone := range denyList {\n\tfor i := 0; i \u003c len(zones); i++ {\n\t\tif zones[i] == deniedZone {\n\t\t\tzones = append(zones[:i], zones[i+1:]...)\n\t\t\ti-- // Adjust index to stay at the correct position after removal\n\t\t}\n\t}\n}\n","tags":"#go #computation"},{"id":"3d88940495b81a4639fc74c1bfdf266a","title":"Go: Bitwise Operations in Go ","content":"# Bitwise Operations in Go\n\nIn the below Go file we use bitwise operators to manipulate individual flags (on/off switches) in a single integer, where each bit position represents a different status.\n\n## Visualising Bits\n\nIn case you need a reminder of a what bit alignment and shifting look like:\n\n![example of bits in a byte](https://www.integralist.co.uk/images/bits-visualised.png)\n\n## Defining Bit Flags\n\nEach status is assigned a unique power of 2 using bit shifting (`1 \u003c\u003c iota`). \n\nThis ensures each flag only affects a single bit:\n\n- `StatusActive` has the binary value `0001` (`1 \u003c\u003c 0` == 1 in decimal).\n- `StatusAdmin` has the binary value `0010` (`1 \u003c\u003c 1` == 2 in decimal).\n- `StatusBanned` has the binary value `0100` (`1 \u003c\u003c 2` == 4 in decimal).\n- `StatusVerified` has the binary value `1000` (`1 \u003c\u003c 3` == 8 in decimal).\n\n## Setting Statuses\n\nThe following example combines two separate status flags:\n\n```\nuserStatus |= StatusActive | StatusVerified\n```\n\nIn binary, this results in `1001` (or 9 in decimal), which means both the \"active\" and \"verified\" flags are set.\n\n## Adding and Removing Flags\n\nThe following example sets the \"admin\" bit without affecting the other bits, resulting in `1011` (11 in decimal):\n\n```\nuserStatus |= StatusAdmin\n```\n\n## Comparing Statuses\n\nOnce `userStatus` has combined flags we can use the `\u0026` operator to perform a bitwise `AND` operation, which means it compares each bit of two integers. For each bit position, if both bits are 1, the result at that position will be 1; otherwise, it will be 0.\n\nSo what happens when we compare `userStatus\u0026StatusAdmin != 0`?\n\nWell, `StatusAdmin` is a bit flag defined as `1 \u003c\u003c 1`, which results in `0010` in binary. This means that `StatusAdmin` occupies the second bit position in the binary representation of an integer. When we do `userStatus\u0026StatusAdmin`, we're effectively \"masking\" all bits except for the one represented by StatusAdmin (this is known as **bit masking**).\n\nWhen we perform `userStatus\u0026StatusAdmin`, we get a result where only the bit corresponding to `StatusAdmin` remains (and is set to `1` if that bit was already set in `userStatus`). If this result is non-zero (`!= 0`), it means the `StatusAdmin` bit is set in `userStatus`. If it's zero, then `StatusAdmin` is not set in `userStatus`.\n\nIf we look at the code in `bitwise.go` we'll see `userStatus` is initially set to include `StatusActive` and `StatusVerified`, so `userStatus` is `1001` in binary (which is `9` in decimal). Remember `StatusActive` occupied the first bit position (`0001`), while `StatusVerified` occupied the fourth bit position (`1000`) so if setting both flags we get the combined `1001`.\n\nNext, we add the `StatusAdmin` flag with `userStatus |= StatusAdmin`, making `userStatus` now `1011` in binary (which is 11 in decimal). When we check if `StatusAdmin` is set using `userStatus\u0026StatusAdmin != 0` we get back `2` from `userStatus\u0026StatusAdmin` (which is `0010` in binary) because we've bit masked the other bits that might have been turned on (if you recall, using `\u0026` turns each bit to zero except for those bits that were 1 in both numbers being compared), in order to _reveal_ whether the `StatusAdmin` bit was set on or not (i.e. `0` != `2` so we know this person is an admin).\npackage main\n\nimport (\n\t\"fmt\"\n\t\"strings\"\n)\n\n// Define bit flags as constants, where each status is represented by a unique bit position\nconst (\n\tStatusActive   = 1 \u003c\u003c iota // 1 \u003c\u003c 0 which is 0001 (binary)\n\tStatusAdmin                // 1 \u003c\u003c 1 which is 0010\n\tStatusBanned               // 1 \u003c\u003c 2 which is 0100\n\tStatusVerified             // 1 \u003c\u003c 3 which is 1000\n)\n\n// Stringify statuses for easier output\nfunc stringifyStatus(status int) string {\n\tstatuses := []string{}\n\n\tif status\u0026StatusActive != 0 {\n\t\tstatuses = append(statuses, \"Active\")\n\t}\n\tif status\u0026StatusAdmin != 0 {\n\t\tstatuses = append(statuses, \"Admin\")\n\t}\n\tif status\u0026StatusBanned != 0 {\n\t\tstatuses = append(statuses, \"Banned\")\n\t}\n\tif status\u0026StatusVerified != 0 {\n\t\tstatuses = append(statuses, \"Verified\")\n\t}\n\n\treturn strings.Join(statuses, \", \")\n}\n\nfunc main() {\n\t// Let's create a user status and use bitwise OR to combine different flags\n\n\tvar userStatus int\n\n\t// Set the user as active and verified\n\tuserStatus |= StatusActive | StatusVerified\n\tfmt.Println(\"Initial Status:\", stringifyStatus(userStatus))\n\n\t// Add \"Admin\" status\n\tuserStatus |= StatusAdmin\n\tfmt.Println(\"After adding Admin:\", stringifyStatus(userStatus))\n\n\t// Remove \"Verified\" status using bitwise AND with NOT\n\tuserStatus \u0026^= StatusVerified\n\tfmt.Println(\"After removing Verified:\", stringifyStatus(userStatus))\n\n\t// Add \"Banned\" status\n\tuserStatus |= StatusBanned\n\tfmt.Println(\"After adding Banned:\", stringifyStatus(userStatus))\n\n\t// Check if the user is an admin\n\tif userStatus\u0026StatusAdmin != 0 {\n\t\tfmt.Println(\"User is an admin.\")\n\t} else {\n\t\tfmt.Println(\"User is NOT an admin.\")\n\t}\n\n\t// Remove \"Admin\" status using bitwise AND with NOT\n\tuserStatus \u0026^= StatusAdmin\n\tfmt.Println(\"After removing Admin:\", stringifyStatus(userStatus))\n\n\t// Check if the user is banned\n\tif userStatus\u0026StatusBanned != 0 {\n\t\tfmt.Println(\"User is banned.\")\n\t} else {\n\t\tfmt.Println(\"User is NOT banned.\")\n\t}\n\n\t// Check if the user is an admin\n\tif userStatus\u0026StatusAdmin != 0 {\n\t\tfmt.Println(\"User is an admin.\")\n\t} else {\n\t\tfmt.Println(\"User is NOT an admin.\")\n\t}\n}\n","tags":"#go #computation"},{"id":"09ff73d309af7852864dfe709c53f12d","title":"Go: Structured Logging ","content":"// https://play.golang.com/p/tfop7CgoGF5\n// https://goplay.tools/snippet/aZatTtNaElZ\n\npackage main\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"log/slog\"\n\t\"os\"\n)\n\ntype foo struct {\n\tbeep string\n\tboop int\n\tblah bool\n}\n\nfunc (f foo) LogValue() slog.Value {\n\treturn slog.GroupValue(\n\t\tslog.String(\"beep\", f.beep),\n\t\tslog.Int(\"boop\", f.boop),\n\t\tslog.Bool(\"blah\", f.blah),\n\t)\n}\n\n// IMPORTANT: [(slog.HandlerOptions).ReplaceAttr] docs say not to mutate `groups` slice.\n// This means, you can't solve the problem of multiple groups with the same name.\n// Ultimately, you will end up with invalid JSON (two keys with the same name == invalid).\n// So it's your responsibility to avoid that situation.\n// Which means storing your attributes in a slice and waiting for a single log event to add a group.\n// You can't add a group and then later append to it (as demonstrated below).\n\nfunc main() {\n\tctx := context.Background()\n\tattrs := []any{slog.String(\"foo\", \"a\"), slog.String(\"bar\", \"b\")}\n\t\n\t// The replacer function is resolved once per logger instance.\n\t// i.e. it is not called on each log event trigger (e.g. LogAttrs).\n\treplacer := func(groups []string, a slog.Attr) slog.Attr {\n\t\tif len(groups) \u003e 0 {\n\t\t\tif groups[0] == \"a_struct\" {\n\t\t\t\treturn slog.Attr{} // delete the attribute from the group (will run for every attribute in the group, and ultimately will result in the group itself being removed)\n\t\t\t}\n\t\t\tfmt.Printf(\"groups: %#v\\n\", groups)\n\t\t\tfmt.Printf(\"attribute: %#v\\n\", a)\n\t\t}\n\t\treturn a\n\t}\n\thandler := \u0026slog.HandlerOptions{Level: slog.LevelInfo, ReplaceAttr: replacer}\n\tlogger := slog.New(slog.NewJSONHandler(os.Stdout, handler))\n\t\n\t// Create a new logger instance with `a_struct` group.\n\tlogger = logger.With(slog.Any(\"a_struct\", foo{\"beeping\", 123, true}))\n\n\t// Append new attribute to our `attrs` slice.\n\tattrs = append(attrs, slog.String(\"baz\", \"c\"))\n\t\n\t// Create a new logger instance with `a_group` group using our `attrs` slice.\n\tlogger = logger.With(slog.Group(\"a_group\", attrs...))\n\t\n\t// Although we append a new attribute to the `attrs` slice,\n\t// the attribute will not show up in the following log event,\n\t// as it was appended AFTER the logger instance was created.\n\tattrs = append(attrs, slog.String(\"qux\", \"d\"))\n\t\n\tlogger.LogAttrs(ctx, slog.LevelInfo, \"some_event_1\")\n\t\n\t// If I try to create a new logger instance, \n\t// I'll end up with invalid JSON (i.e. double \"a_group\" fields)\n\tlogger = logger.With(slog.Group(\"a_group\", attrs...))\n\t\n\tlogger.LogAttrs(ctx, slog.LevelInfo, \"some_event_2\")\n}\n","tags":"#go #logs"},{"id":"1b1d446b84957967ce579c6278f524db","title":"Fastly Code Test Asset","content":"11 02 08:24:01 \"GET /index.html\" 400 152\n11 02 08:24:03 \"POST /api/login\" 201 98\n11 02 08:24:05 \"GET /images/logo.png\" 404 134\n11 02 08:24:07 \"DELETE /api/resource/123\" 204 65\n11 02 08:24:09 \"PUT /api/item\" 400 189\n11 02 08:24:10 \"PATCH /api/user/profile\" 200 102\n11 02 08:24:12 \"GET /products\" 400 115\n11 02 08:24:14 \"POST /api/order\" 201 177\n11 02 08:24:16 \"GET /about\" 200 98\n11 02 08:24:18 \"DELETE /api/cart/1\" 200 145\n11 02 08:24:20 \"POST /api/search\" 500 211\n11 02 08:24:21 \"GET /contact\" 302 87\n11 02 08:24:23 \"POST /api/login\" 200 126\n11 02 08:24:25 \"GET /shop\" 200 144\n11 02 08:24:27 \"GET /api/user/123\" 200 95\n11 02 08:24:29 \"PATCH /api/order/456\" 200 109\n11 02 08:24:30 \"DELETE /api/item/789\" 404 82\n11 02 08:24:32 \"POST /api/register\" 201 164\n11 02 08:24:34 \"GET /docs\" 301 90\n11 02 08:24:36 \"PUT /api/address\" 503 120\n11 02 08:24:38 \"POST /api/upload\" 400 187\n11 02 08:24:40 \"PATCH /api/user/settings\" 200 130\n11 02 08:24:42 \"GET /home\" 200 102\n11 02 08:24:44 \"DELETE /api/item/123\" 200 142\n11 02 08:24:46 \"POST /api/order\" 201 156\n11 02 08:24:48 \"GET /blog\" 304 115\n11 02 08:24:50 \"GET /api/checkout\" 500 203\n11 02 08:24:52 \"GET /login\" 200 83\n11 02 08:24:54 \"POST /api/logout\" 200 146\n11 02 08:24:55 \"PATCH /api/item/789\" 200 97\n11 02 08:24:57 \"GET /api/user/123\" 400 107\n11 02 08:24:59 \"POST /api/user\" 201 167\n11 02 08:25:01 \"GET /news\" 301 89\n11 02 08:25:03 \"PUT /api/order/456\" 500 162\n11 02 08:25:05 \"DELETE /api/item/999\" 404 80\n11 02 08:25:07 \"POST /api/login\" 401 128\n11 02 08:25:09 \"GET /faq\" 200 136\n11 02 08:25:10 \"POST /api/product\" 503 158\n11 02 08:25:12 \"PATCH /api/settings\" 400 111\n11 02 08:25:14 \"GET /contact-us\" 403 123\n11 02 08:25:16 \"POST /api/register\" 201 93\n11 02 08:25:18 \"GET /store\" 200 105\n11 02 08:25:20 \"DELETE /api/cart/789\" 404 141\n11 02 08:25:22 \"POST /api/order\" 201 154\n11 02 08:25:24 \"GET /terms\" 302 119\n11 02 08:25:25 \"PATCH /api/order/456\" 500 178\n11 02 08:25:27 \"GET /profile\" 400 84\n11 02 08:25:29 \"POST /api/product\" 503 156\n11 02 08:25:31 \"GET /api/resource\" 403 108\n11 02 08:25:33 \"DELETE /api/resource/123\" 404 135\n11 02 08:25:35 \"POST /api/login\" 401 147\n11 02 08:25:37 \"GET /api/status\" 200 118\n11 02 08:25:39 \"POST /api/logout\" 401 140\n11 02 08:25:40 \"PUT /api/cart\" 503 169\n11 02 08:25:42 \"GET /support\" 404 95\n11 02 08:25:44 \"POST /api/upload\" 400 123\n11 02 08:25:46 \"PATCH /api/user/123\" 200 132\n11 02 08:25:48 \"GET /checkout\" 400 100\n11 02 08:25:50 \"POST /api/cart\" 503 111\n11 02 08:25:52 \"GET /resources\" 403 107\n11 02 08:25:53 \"DELETE /api/item/789\" 404 151\n11 02 08:25:55 \"POST /api/register\" 401 137\n11 02 08:25:57 \"GET /admin\" 302 92\n11 02 08:25:59 \"PATCH /api/user/profile\" 500 182\n11 02 08:26:01 \"GET /api/status\" 400 109\n11 02 08:26:03 \"POST /api/logout\" 401 150\n11 02 08:26:05 \"PUT /api/address\" 503 135\n11 02 08:26:07 \"DELETE /api/cart/999\" 404 142\n11 02 08:26:08 \"GET /login\" 400 116\n11 02 08:26:10 \"POST /api/login\" 401 129\n11 02 08:26:12 \"PATCH /api/resource\" 400 114\n11 02 08:26:14 \"GET /about-us\" 403 123\n11 02 08:26:16 \"POST /api/user\" 401 99\n11 02 08:26:18 \"GET /api/dashboard\" 200 127\n11 02 08:26:20 \"DELETE /api/item/101\" 400 130\n11 02 08:26:22 \"POST /api/login\" 401 162\n11 02 08:26:23 \"GET /images/header.png\" 200 113\n11 02 08:26:25 \"PUT /api/product\" 503 121\n11 02 08:26:27 \"POST /api/cart\" 201 150\n11 02 08:26:29 \"GET /api/help\" 402 103\n11 02 08:26:31 \"PATCH /api/user/789\" 500 134\n11 02 08:26:33 \"GET /catalog\" 400 117\n11 02 08:26:34 \"POST /api/support\" 400 146\n11 02 08:26:36 \"GET /api/resource\" 200 139\n11 02 08:26:38 \"DELETE /api/product/987\" 404 159\n11 02 08:26:40 \"POST /api/register\" 201 130\n11 02 08:26:42 \"GET /home\" 301 83\n11 02 08:26:43 \"PUT /api/order\" 200 144\n11 02 08:26:45 \"GET /profile\" 200 101\n11 02 08:26:47 \"POST /api/register\" 201 132\n11 02 08:26:49 \"DELETE /api/cart/101\" 404 149\n11 02 08:26:51 \"POST /api/login\" 200 156\n11 02 08:26:53 \"GET /privacy\" 302 97\n11 02 08:26:55 \"PATCH /api/user/101\" 500 121\n11 02 08:26:56 \"GET /api/notification\" 200 113\n11 02 08:26:57 \"POST /api/notification\" 201 99\n11 02 08:26:58 \"GET /settings\" 200 134\n11 02 08:26:59 \"DELETE /api/item/777\" 404 103\n11 02 08:27:00 \"POST /api/upload\" 500 109\n11 02 08:26:58 \"GET /settings\" 502 134\n","tags":""},{"id":"05fb91c42021195b727be5afb28122ec","title":"Go: concurrency ","content":"# Go Concurrency\n\n- [Goroutines](#goroutines)\n- [Channels](#channels)\n- [Select Statement](#select-statement)\n- [Wait Groups](#wait-groups)\n- [Mutex](#mutex)\n- [Conditions](#conditions)\n- [Atomic Operations](#atomic-operations)\n- [Once](#once)\n- [Context](#context)\n- [Map](#map)\n- [Real Examples](#real-examples)\n\n## Goroutines\n\nThe `go` keyword is used to start a goroutine.\n\nA goroutine is a lightweight, managed thread used by the Go runtime to run functions concurrently.\n\nUnlike OS threads, which have a fixed stack size (often around 1MB), goroutines start with a very small stack, around 2KB, and can grow or shrink dynamically as needed. This makes it possible to run thousands or even millions of goroutines simultaneously, depending on the available memory.\n\nGoroutines are sometimes compared to \"green threads,\" which are threads that are scheduled in user space rather than by the OS. The problem with green threads is that they may not leverage multiple CPU cores efficiently since they don't interact directly with the OS’s scheduler.\n\nGoroutines are similar to green threads in that they are scheduled by the Go runtime rather than the OS. However, they differ in a crucial way: Go uses a model called Mscheduling, where the Go runtime maps multiple goroutines (M) onto multiple OS threads (N). This allows the runtime to distribute goroutines across multiple CPU cores when possible, making Go’s concurrency model more efficient and scalable than traditional green threads.\n\n\u003e [!IMPORTANT]\n\u003e The following example uses a `time.Sleep` to wait for the goroutine to finish.\\\n\u003e This is done for simplicity. Do NOT use this approach.\\\n\u003e I'll explain alternative options afterwards.\n\n```go\npackage main\n\nimport (\n\t\"fmt\"\n\t\"time\"\n)\n\nfunc sayHello() {\n\tfmt.Println(\"Hello from a goroutine!\")\n}\n\nfunc main() {\n\tgo sayHello() // Launches sayHello in a new goroutine\n\n\tfmt.Println(\"Hello from main!\")\n\ttime.Sleep(1 * time.Second) // Wait for the goroutine to complete (only for example)\n}\n```\n\nhttps://play.golang.com/p/SdOdZ90-exI\n\n\u003e [!NOTE]\n\u003e In Go, the `main` function is effectively the \"initial\" goroutine.\\\n\u003e When a Go program starts, the Go runtime creates a goroutine to run `main`.\\\n\u003e This main goroutine can then spawn additional goroutines as needed.\n\n## Channels\n\nChannels in Go are a powerful way to communicate between goroutines and to synchronize them. They allow you to send and receive values across goroutines, and they help avoid race conditions by enabling safe data sharing.\n\n\u003e [!IMPORTANT]\n\u003e In the following example the `\u003c-ch` BLOCKS the main thread.\\\n\u003e This can cause a deadlock if we don't have a goroutine running to unblock it.\n\n```go\npackage main\n\nimport (\n\t\"fmt\"\n)\n\nfunc sendMessage(ch chan string) {\n\tch \u003c- \"Hello from a goroutine!\" // Send a message to the channel\n}\n\nfunc main() {\n\t// Create a new channel of type string\n\tch := make(chan string)\n\n\t// Start a goroutine to send a message\n\tgo sendMessage(ch)\n\n\t// Receive the message from the channel\n\tmsg := \u003c-ch\n\tfmt.Println(msg) // Output: Hello from a goroutine!\n}\n```\n\nhttps://play.golang.com/p/2Qn_NacVw-0\n\n\u003e [!IMPORTANT]\n\u003e The most crucial best practice is to close the channel from the sender side, not the receiver. The sender is the goroutine that writes data to the channel. This signals to the receiver that no more values will be sent.\n\n## Select Statement\n\nThe `select` statement is used to wait on multiple channel operations. It blocks until one of its cases can proceed, which makes it essential for handling multiple asynchronous tasks.\n\nUse `select` when you have multiple channels to listen to, and you want to respond to whichever channel receives data first.\n\n\u003e [!NOTE]\n\u003e In the following example, the first goroutine uses a `time.Sleep`.\\\n\u003e This is to simulate the operation taking a long time.\\\n\u003e It results in the `select` pulling a value from the second goroutine.\n\n```go\npackage main\n\nimport (\n\t\"fmt\"\n\t\"time\"\n)\n\nfunc main() {\n\tch1 := make(chan string)\n\tch2 := make(chan string)\n\n\tgo func() {\n\t\ttime.Sleep(1 * time.Second)\n\t\tch1 \u003c- \"result from ch1\"\n\t}()\n\n\tgo func() {\n\t\tch2 \u003c- \"result from ch2\"\n\t}()\n\n\tselect {\n\tcase msg1 := \u003c-ch1:\n\t\tfmt.Println(\"Received:\", msg1)\n\tcase msg2 := \u003c-ch2:\n\t\tfmt.Println(\"Received:\", msg2)\n\t}\n}\n```\n\nhttps://play.golang.com/p/HXe-bZ__EEy\n\nA common use case for `select` is to timeout a potential deadlock:\n\n\u003e [!NOTE]\n\u003e In the following example we use `time.After` to cause a timeout.\n\n```go\npackage main\n\nimport (\n\t\"fmt\"\n\t\"time\"\n)\n\nfunc main() {\n\t// Create an unbuffered channel\n\tch := make(chan string)\n\n\t// Start a goroutine that simulates a delayed send\n\tgo func() {\n\t\ttime.Sleep(3 * time.Second)   // Simulate a delay\n\t\tch \u003c- \"Hello from goroutine!\" // Send a message after delay\n\t}()\n\n\tselect {\n\tcase msg := \u003c-ch:\n\t\tfmt.Println(\"Received:\", msg)\n\tcase \u003c-time.After(2 * time.Second): // Timeout after 2 seconds\n\t\tfmt.Println(\"Timeout! No message received.\")\n\t}\n}\n```\n\nhttps://play.golang.com/p/6BMPeUKdqkg\n\n## Wait Groups\n\nA `sync.WaitGroup` waits for a collection of goroutines to finish. It helps coordinate a group of goroutines and ensures the program waits until all of them have completed before proceeding.\n\nUse a `WaitGroup` when you need to wait for multiple goroutines to finish before moving on.\n\nIn this example, a `sync.WaitGroup` is used to wait for three goroutines to complete. Each goroutine represents a worker, and each one calls `wg.Done()` to signal that it's finished. The `main` function calls `wg.Wait()` to block until all workers are done.\n\n```go\npackage main\n\nimport (\n\t\"fmt\"\n\t\"sync\"\n)\n\nfunc worker(id int, wg *sync.WaitGroup) {\n\tdefer wg.Done() // Decrement counter when goroutine completes\n\tfmt.Printf(\"Worker %d starting\\n\", id)\n\tfmt.Printf(\"Worker %d done\\n\", id)\n}\n\nfunc main() {\n\tvar wg sync.WaitGroup\n\n\tfor i := range 3 {\n\t\twg.Add(1) // Track each goroutine started\n\t\tgo worker(i, \u0026wg)\n\t}\n\n\t// Wait for all goroutines to finish\n\twg.Wait()\n\n\tfmt.Println(\"All workers done.\")\n}\n```\n\nhttps://play.golang.com/p/LhEdSQIPp1R\n\n## Mutex\n\nGo's `sync.Mutex` provides mutual exclusion, allowing only one goroutine at a time to access a critical section of code. While `sync.RWMutex` is a variant that allows multiple readers or a single writer but not both.\n\nUse `sync.Mutex` or `sync.RWMutex` when you need fine-grained control over data access and want to protect shared data from race conditions.\n\nIn the below example `sync.Mutex` ensures that only one goroutine modifies `counter.value` at a time, preventing race conditions:\n\n```go\npackage main\n\nimport (\n\t\"fmt\"\n\t\"sync\"\n)\n\ntype Counter struct {\n\tmu    sync.Mutex\n\tvalue int\n}\n\nfunc (c *Counter) Increment() {\n\tc.mu.Lock()\n\tdefer c.mu.Unlock()\n\tc.value++\n}\n\nfunc (c *Counter) Value() int {\n\tc.mu.Lock()\n\tdefer c.mu.Unlock()\n\treturn c.value\n}\n\nfunc main() {\n\tcounter := \u0026Counter{}\n\tvar wg sync.WaitGroup\n\n\tfor range 10 {\n\t\twg.Add(1)\n\t\tgo func() {\n\t\t\tdefer wg.Done()\n\t\t\tcounter.Increment()\n\t\t}()\n\t}\n\n\twg.Wait()\n\t\n\tfmt.Println(\"Final Counter:\", counter.Value())\n}\n```\n\nhttps://play.golang.com/p/VIbNkQaPfZI\n\n## Conditions\n\nGo's `sync.Cond` is used for signaling between goroutines. It lets goroutines wait until they are notified to continue, which is useful when one goroutine needs to wait for a certain condition to be met by another goroutine.\n\nUse `sync.Cond` when you need goroutines to wait for certain conditions, such as producer-consumer scenarios.\n\nIn the following example, `cond.Wait()` blocks until `cond.Signal()` is called. It's useful for waiting on complex conditions where other primitives like `chan` may not be ideal:\n\n\u003e [!IMPORTANT]\n\u003e The call to `cond.L.Lock()` in the main goroutine just before `for !ready` is required, otherwise you'll get the error `fatal error: sync: unlock of unlocked mutex`. This is because `cond.Wait()` expects the caller to hold the lock before calling `Wait()` (see [this video](https://youtu.be/VAV2h1GdgE0?si=cqErfqLXnWOgmcsh) for details). Once `Wait()` returns, it reacquires the lock, ensuring the main goroutine can safely check ready and exit the loop.\n\n```go\npackage main\n\nimport (\n\t\"fmt\"\n\t\"sync\"\n\t\"time\"\n)\n\nfunc main() {\n\tvar mu sync.Mutex\n\tcond := sync.NewCond(\u0026mu)\n\tready := false\n\n\tgo func() {\n\t\ttime.Sleep(1 * time.Second)\n\t\tcond.L.Lock()\n\t\tready = true\n\t\tcond.L.Unlock()\n\t\tcond.Signal() // Notify one waiting goroutine\n\t}()\n\n\tcond.L.Lock()\n\tfor !ready {\n\t\tcond.Wait() // Wait until condition is met\n\t}\n\tfmt.Println(\"Ready is true, proceeding.\")\n\tcond.L.Unlock()\n}\n```\n\nhttps://play.golang.com/p/n_txZaH7lPA\n\nIn the following example we have multiple worker goroutines waiting on a shared condition to be \"notified.\" We'll see how both `.Signal()` and `.Broadcast()` work when notifying waiting goroutines:\n\n```go\npackage main\n\nimport (\n\t\"fmt\"\n\t\"sync\"\n\t\"time\"\n)\n\nfunc worker(id int, cond *sync.Cond) {\n\tcond.L.Lock() // Lock the condition\n\tdefer cond.L.Unlock()\n\n\tfmt.Printf(\"Worker %d is waiting\\n\", id)\n\tcond.Wait() // Wait for a signal or broadcast\n\tfmt.Printf(\"Worker %d is proceeding\\n\", id)\n}\n\nfunc main() {\n\tlock := \u0026sync.Mutex{}\n\tcond := sync.NewCond(lock)\n\n\t// Start multiple worker goroutines that will wait on the condition\n\tfor i := range 3 {\n\t\tgo worker(i, cond)\n\t}\n\n\t// Allow time for all workers to start and wait\n\ttime.Sleep(1 * time.Second)\n\n\t// Use Signal to wake up one goroutine\n\tfmt.Println(\"Notifying one worker\")\n\tcond.Signal() // Notifies one waiting worker\n\ttime.Sleep(1 * time.Second)\n\n\t// Use Broadcast to wake up all remaining goroutines\n\tfmt.Println(\"Broadcasting to all remaining workers\")\n\tcond.Broadcast() // Notifies all remaining waiting workers\n\n\t// Allow time for all goroutines to complete\n\ttime.Sleep(2 * time.Second)\n\tfmt.Println(\"Main function exiting.\")\n}\n```\n\nhttps://play.golang.com/p/41ibtmUmKaN\n\nEach worker goroutine locks the condition, calls `cond.Wait()`, and then waits. This releases the lock (as we now understand from the earlier IMPORTANT note, see above if you missed it), allowing other goroutines to call `Wait()` as well.\n\nThe `cond.Signal()` call in the `main` function wakes up one of the waiting goroutines, allowing it to proceed.\n\nAfter a short delay, `cond.Broadcast()` wakes up all remaining waiting goroutines, allowing them to proceed simultaneously.\n\nThis is useful for scenarios where multiple tasks need to wait for a common event or state change to proceed.\n\n\u003e [!IMPORTANT]\n\u003e Notifications are not ordered.\\\n\u003e Any one of the waiting goroutines can be chosen to proceed first.\\\n\u003e Broadcast ensures that all waiting goroutines eventually proceed.\n\nNow you might be thinking \"hmm, it looks like I could use channels instead and they're more idiomatic\".\n\nWell, here are some reasons for why you might need to choose `sync.Cond` over channels:\n\n1. Fine-Grained Control: `sync.Cond` allows precise control over waiting and signaling, suitable for cases where specific conditions must be checked or managed.\n\n2. Broadcast Capability: Broadcasting to multiple goroutines is straightforward with `sync.Cond`, whereas channels require individual signaling, which can be inefficient.\n\n3. Reduced Complexity for State-Based Waiting: `sync.Cond` is ideal for situations where goroutines need to wait for specific conditions to be true, rather than for individual values or events passed through a channel.\n\n4. Avoiding Channel Overhead: Channels introduce buffering and management overhead, especially with many goroutines, whereas `sync.Cond` relies on a shared mutex with a direct wait/notify mechanism, which is often faster.\n\nIn summary, `sync.Cond` is best suited for use cases that involve waiting for and signaling conditions, especially when you need more control over synchronization and when goroutines are reacting to shared state changes rather than discrete message passing.\n\n## Atomic Operations\n\nThe `sync/atomic` package provides low-level atomic operations on simple types like integers and pointers, ensuring operations are performed atomically.\n\nUse atomic operations when you need lock-free synchronization for counters or flags, but only for basic integer or pointer manipulations.\n\nIn the following example, `atomic.AddInt32` safely increments `counter` without a lock, making it ideal for high-performance counters or flags:\n\n```go\npackage main\n\nimport (\n\t\"fmt\"\n\t\"sync\"\n\t\"sync/atomic\"\n)\n\nfunc main() {\n\tvar counter int32\n\tvar wg sync.WaitGroup\n\n\tfor range 10 {\n\t\twg.Add(1)\n\t\tgo func() {\n\t\t\tdefer wg.Done()\n\t\t\tatomic.AddInt32(\u0026counter, 1)\n\t\t}()\n\t}\n\n\twg.Wait()\n\t\n\tfmt.Println(\"Final Counter:\", atomic.LoadInt32(\u0026counter))\n}\n```\n\nhttps://play.golang.com/p/qsRPoC4GPNv\n\n## Once\n\nGo's `sync.Once` ensures that a function only executes once, even if multiple goroutines attempt to run it.\n\nUse `sync.Once` when you need to perform a one-time initialization, such as setting up a shared resource.\n\nIn the following example, even though multiple goroutines call `once.Do(initialize)`, `initialize` only runs once. This is especially useful for lazy initialization of global resources:\n\n```go\npackage main\n\nimport (\n\t\"fmt\"\n\t\"sync\"\n)\n\nvar once sync.Once\n\nfunc initialize() {\n\tfmt.Println(\"Initializing...\")\n}\n\nfunc main() {\n\tvar wg sync.WaitGroup\n\tfor range 3 {\n\t\twg.Add(1)\n\t\tgo func() {\n\t\t\tdefer wg.Done()\n\t\t\tonce.Do(initialize)\n\t\t}()\n\t}\n\twg.Wait()\n}\n```\n\nhttps://play.golang.com/p/5J1ApCPc1iU\n\n## Context\n\nGo's `context.Context` is not a strict concurrency primitive but is widely used to manage timeouts, cancellations, and deadlines across goroutines.\n\nUse `context.Context` to signal cancellation or control the lifespan of goroutines, particularly in networked or long-running tasks.\n\nIn the following example, `context.WithTimeout` creates a context that automatically cancels after 1 second, which is useful for controlling tasks that may hang or take too long:\n\n```go\npackage main\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"time\"\n)\n\nfunc process(ctx context.Context) {\n\tselect {\n\tcase \u003c-time.After(2 * time.Second): // use time.After to simulate slow operation\n\t\tfmt.Println(\"Completed work\")\n\tcase \u003c-ctx.Done():\n\t\tfmt.Println(\"Work cancelled\")\n\t}\n}\n\nfunc main() {\n\tctx, cancel := context.WithTimeout(context.Background(), 1*time.Second)\n\tdefer cancel()\n\n\tgo process(ctx)\n\n\ttime.Sleep(2 * time.Second)\n}\n```\n\nhttps://play.golang.com/p/diSmAp0SJkg\n\n## Map\n\nThe `sync` package has a [`Map`](https://pkg.go.dev/sync#Map) type which you will likely not need to use.\n\nThe Go authors even document it as such...\n\n\u003e The Map type is specialized. Most code should use a plain Go map instead, with separate locking or coordination, for better type safety and to make it easier to maintain other invariants along with the map content.\n\u003e\n\u003e The Map type is optimized for two common use cases: (1) when the entry for a given key is only ever written once but read many times, as in caches that only grow, or (2) when multiple goroutines read, write, and overwrite entries for disjoint sets of keys. In these two cases, use of a Map may significantly reduce lock contention compared to a Go map paired with a separate Mutex or RWMutex. \n\n## Real Examples\n\nBelow is a 'real world' example where we need to delete a bunch of keys from a data store.\n\nThe API that is provided, does not support bulk deleting of keys.\n\nThe API does provide an endpoint that lets us paginate the available keys, and we then need to stream that information as quickly as possible using a pool of goroutines coordinated with both channels and wait groups.\n\nIt's a nice example because it brings together several different concurrency primitives (goroutines, channels, select, wait groups, atomic operations).\n\n\u003e [!TIP]\n\u003e Keep reading after the code snippet for a brief breakdown of what the code does.\n\n```go\nconst (\n\t// PoolSize is the goroutine/thread-pool size.\n\t// Each pool will take a 'key' from a channel and issue a DELETE request.\n\tconst PoolSize int = 100\n\n\t// MaxErrors is the maximum number of errors we'll allow before\n\t// stopping the goroutines from executing.\n\tconst MaxErrors int = 100\n)\n\nfunc DeleteAllKeys(storeID string, out io.Writer) error {\n\t// Create a 'spinner' which helps visually update the user on the progress.\n\tspinnerMessage := \"Deleting keys\"\n\tvar spinner text.Spinner\n\n\tvar err error\n\tspinner, err = text.NewSpinner(out)\n\tif err != nil {\n\t\treturn err\n\t}\n\terr = spinner.Start()\n\tif err != nil {\n\t\treturn err\n\t}\n\tspinner.Message(spinnerMessage + \"...\")\n\n\t// Create a keys paginator.\n\tp := fastly.NewListKVStoreKeysPaginator(\u0026fastly.ListKVStoreKeysInput{\n\t\tStoreID: storeID,\n\t})\n\n\t// Channel for tracking errors when deleting keys.\n\terrorsCh := make(chan string, MaxErrors)\n\t\n\t// Channel for tracking keys to delete.\n\tkeysCh := make(chan string, 1000) // this number correlates to the pagination page size defined by the API\n\n\tvar (\n\t\t// Track the number of keys deleted.\n\t\tdeleteCount atomic.Uint64\n\t\t\n\t\t// Track which keys failed to be deleted.\n\t\tfailedKeys []string\n\t\t\n\t\t// This will help us wait for all goroutines to complete.\n\t\twg sync.WaitGroup\n\t)\n\n\t// We have two separate execution flows happening at once:\n\t//\n\t// 1. Pushing keys from pagination data into a key channel.\n\t// 2. Pulling keys from key channel and issuing API DELETE call.\n\t//\n\t// We have a limit on the number of errors. Once that limit is reached we'll\n\t// stop the second set of goroutines processing the delete operation.\n\n\twg.Add(1)\n\tgo func() {\n\t\tdefer wg.Done()\n\t\tdefer close(keysCh)\n\t\tfor p.Next() {\n\t\t\tfor _, key := range p.Keys() {\n\t\t\t\tkeysCh \u003c- key\n\t\t\t}\n\t\t}\n\t}()\n\n\t// Limit the number of goroutines spun up to the specified pool size.\n\tfor range PoolSize {\n\t\twg.Add(1)\n\t\tgo func() {\n\t\t\tdefer wg.Done()\n\t\t\tfor key := range keysCh {\n\t\t\t\terr := fastly.DeleteKVStoreKey(\u0026fastly.DeleteKVStoreKeyInput{StoreID: c.StoreID, Key: key})\n\t\t\t\tif err != nil {\n\t\t\t\t\tselect {\n\t\t\t\t\tcase errorsCh \u003c- key:\n\t\t\t\t\tdefault:\n\t\t\t\t\t\treturn // channel is full (i.e. we've reached our MaxErrors limit)\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\t// Update the TUI (Terminal UI) to reflect the current number of deleted keys.\n\t\t\t\tspinner.Message(spinnerMessage + \"...\" + strconv.FormatUint(deleteCount.Add(1), 10))\n\t\t\t}\n\t\t}()\n\t}\n\n\twg.Wait()\n\n\tclose(errorsCh)\n\tfor err := range errorsCh {\n\t\tfailedKeys = append(failedKeys, err)\n\t}\n\n\tspinnerMessage = \"Deleted keys: \" + strconv.FormatUint(deleteCount.Load(), 10)\n\n\tif len(failedKeys) \u003e 0 {\n\t\tspinner.StopFailMessage(spinnerMessage)\n\t\terr := spinner.StopFail()\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"failed to stop spinner: %w\", err)\n\t\t}\n\t\treturn fmt.Errorf(\"failed to delete %d keys\", len(failedKeys))\n\t}\n\n\tspinner.StopMessage(spinnerMessage)\n\tif err := spinner.Stop(); err != nil {\n\t\treturn fmt.Errorf(\"failed to stop spinner: %w\", err)\n\t}\n\n\ttext.Success(out, \"\\nDeleted all keys from KV Store '%s'\", c.StoreID)\n\treturn nil\n}\n```\n\nSo you can see we have multiple goroutines spun up (and we wait for them using `sync.WaitGroup`):\n\n- The first goroutine is iterating over the pagination data and pushing data into a channel.\n- The other goroutines (we have a limit of `PoolSize`) are pulling data from the channel and issuing key deletion API calls.\n\nWe also use the `select` statement to control whether we stop the goroutines processing the deletion operations. The way we do this is to define another channel (`errorsCh`) with a buffer size of `MaxErrors`, and then every time we get an error we push the error into that channel. If the channel becomes full (which it will do eventually because there's nothing pulling messages from the `errorsCh` channel), then the `select` statement will fallthrough to its `default` block and we'll return the goroutine (causing it to stop running)\n\nThe last interesting concurrency primitive we use is `atomic.Uint64` for accurately tracking the number of deleted keys. We use its `Add()` method within the goroutine to safely increment the counter, and then at the end of the function we use its `Load()` method to safely extract the final value.\n\n## Reference Material\n\n- https://www.integralist.co.uk/posts/go-style-guide/\n- https://go.dev/doc/effective_go#concurrency\n","tags":"#go #concurrency"},{"id":"3b1b8dcba080c980208a8bdd546966fd","title":"Go: Custom Error Handling ","content":"package main\n\nimport (\n\t\"errors\"\n\t\"fmt\"\n\t\"io\"\n)\n\nfunc main() {\n\terr := doSomething()\n\tfe := \u0026FooError{}\n\tif errors.As(err, fe) {\n\t\tfmt.Printf(\"it's a FooError: %#v\\n\", fe) // \u0026main.FooError{Op:\"doSomething\", Err:(*errors.errorString)(0x556720)}\n\t\tfmt.Printf(\"%#v\\n\", fe.Op)  // \"doSomething\"\n\t\tfmt.Printf(\"%#v\\n\", fe.Err) // \u0026errors.errorString{s:\"EOF\"}\n\t}\n}\n\ntype FooError struct {\n\tOp  string\n\tErr error\n}\n\nfunc (e FooError) Error() string {\n\treturn fmt.Sprintf(\"operation %s: %v\", e.Op, e.Err)\n}\n\nfunc (e FooError) Unwrap() error {\n\treturn e.Err\n}\n\nfunc doSomething() error {\n\treturn FooError{\n\t\tOp:  \"doSomething\",\n\t\tErr: io.EOF,\n\t}\n}\n","tags":"#go #errors"},{"id":"47d704a93108414efc522c1a73ddd735","title":"Rust: Command line utilities written in Rust ","content":"- https://lib.rs/command-line-utilities\n- https://crates.io/categories/command-line-utilities?sort=alpha \n- https://rustrepo.com/catalog/rust-command-line_newest_1\n- https://awesomeopensource.com/project/learn-anything/command-line-tools\n","tags":"#cli #rust #utilities"},{"id":"6b3925a677b0cfe9ef7242cc5d519a12","title":"JS: Simple partial application function","content":"export const partial = (fn, arg) =\u003e {\n  return (...rest) =\u003e {\n    return fn(arg, ...rest)\n  }\n}\n","tags":""},{"id":"92df54bfeb725d3d27943ef533eff922","title":"Editor: Example Editor Config ","content":"root = true\n\n[*]\nindent_size = 2\ncharset = utf-8\nend_of_line = lf\nindent_style = tab\ninsert_final_newline = true\ntrim_trailing_whitespace = true\n\n[{Makefile,go.mod,go.sum,*.go,.gitmodules,*.cue}]\nindent_size = 4\nindent_style = tab\n\n[*.md]\nindent_size = 4\neclint_indent_style = unset\ntrim_trailing_whitespace = false\n\n[Dockerfile*]\nindent_size = 8\nindent_style = space\n\n[*.{yml,yaml}]\nindent_size = 2\nindent_style = space\neclint_indent_style = unset\ntrim_trailing_whitespace = false\n","tags":"#editorconfig"},{"id":"2417151b6b94ffd2f8f7ca8be69337d4","title":"Go: file lock ","content":"package main\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"os\"\n\t\"time\"\n\n\t\"github.com/gofrs/flock\"\n)\n\nconst (\n\t// FileLockTimeout is the amount of time to wait trying to acquire a lock.\n\tFileLockTimeout = 30 * time.Second\n\n\t// FileLockRetryDelay is the mount of time to wait before attempting a retry.\n\tFileLockRetryDelay = 500 * time.Millisecond\n)\n\nfunc main() {\n\tfilename := \"go.mod\"\n\n\t// NOTE: We stat the file because if we didn't, and we provided a file path\n\t// that didn't exist, then flock will cause the file to exist!\n\t// That is confusing behaviour obviously.\n\tif _, err := os.Stat(filename); err != nil {\n\t\tfmt.Printf(\"error stating file '%s': %v\", filename, err)\n\t\treturn\n\t}\n\n\tfileLock := flock.New(filename)\n\tlockCtx, cancel := context.WithTimeout(context.Background(), FileLockTimeout)\n\tdefer cancel()\n\n\tlocked, err := fileLock.TryLockContext(lockCtx, FileLockRetryDelay)\n\tif err != nil {\n\t\tfmt.Printf(\"error acquiring file lock for '%s': %v\", fileLock.Path(), err)\n\t\treturn\n\t}\n\n\tif locked {\n\t\tdata, err := os.ReadFile(fileLock.Path())\n\t\tif err != nil {\n\t\t\tfmt.Printf(\"error reading file '%s': %v\", fileLock.Path(), err)\n\t\t\treturn\n\t\t}\n\t\tfmt.Printf(\"file content: %+v\\n\", string(data))\n\n\t\t// Add some friction to demonstrate how multiple instances of this app\n\t\t// cannot access the go.mod file at the same time.\n\t\ttime.Sleep(20 * time.Second)\n\n\t\tif err := fileLock.Unlock(); err != nil {\n\t\t\tfmt.Printf(\"error releasing file lock for '%s': %v\", fileLock.Path(), err)\n\t\t}\n\t}\n}\n","tags":"#go #network"},{"id":"c906c76a2af918e5fb8c575a0dd53ebf","title":"Go: retry logic ","content":"package main\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"time\"\n\n\t\"github.com/sethvargo/go-retry\"\n)\n\nfunc main() {\n\tctx := context.Background()\n\n\tb := retry.NewConstant(1 * time.Second)\n\tb = retry.WithMaxRetries(3, b)\n\n\tcount := 0\n\n\tif err := retry.Do(ctx, b, func(_ context.Context) error {\n\t\tcount++\n\t\tif count \u003c 5 {\n\t\t\tfmt.Println(\"error to retry\")\n\t\t\treturn retry.RetryableError(fmt.Errorf(\"whoops\"))\n\t\t}\n\t\treturn nil\n\t}); err != nil {\n\t\tfmt.Println(\"error happened:\", err)\n\t\treturn\n\t}\n\n\tfmt.Println(\"success\")\n}\n","tags":"#go #resilience"},{"id":"c1cedc3f45264d7ee78f33915a2e2b58","title":"Go: documentation generate example ","content":"Create a file in the same package as the code and give it the format `example_\u003cwhatever\u003e_test.go`.\n\nThe file should use the external package reference, e.g. `package \u003cyour_package\u003e_test`.\n\nThe function name should be in the format: `Example\u003cType\u003e_\u003cMethod\u003e` or just `Example\u003cFunc\u003e` if it's a global package function.\n\nAn official example is `json.Marshal` which can be found in the file `src/encoding/json/example_test.go` and uses the package `json_test` as it's part of the `json` package and the function is named `ExampleMarshal`.\n\nIf you see examples like `Decoder.Decode (Stream)` this is generated by using more than one underscore: `Example\u003cType\u003e_\u003cMethod\u003e_text_to_be_inside_parentheses` (e.g. `ExampleDecoder_Decode_stream`).\n","tags":"#go"},{"id":"8f6fb17056f64ffe79f5d50529aed74d","title":"Go: random number generator ","content":"seed := rand.NewSource(time.Now().UnixNano())\nrng := rand.New(seed)\nrn := rng.Int()\n","tags":"#go #rng"},{"id":"0a685f3128597a18107ced7367b8a5bd","title":"GitHub: Download latest GitHub Asset Release ","content":".PHONY: bin-viceroy\nbin-viceroy: # Download latest version of Viceroy to ./bin/ directory\n\t@arch=$$(uname -m | sed 's/x86_64/amd64/'); \\\n\tos=$$(uname -s | tr '[:upper:]' '[:lower:]'); \\\n\turl=$$(curl -s https://api.github.com/repos/fastly/viceroy/releases/latest | jq --arg arch $$arch --arg os $$os -r '.assets[] | select((.name | contains($$arch)) and (.name | contains($$os))) | .browser_download_url'); \\\n\tfilename=$$(basename $$url); \\\n\tcurl -sLO $$url \u0026\u0026 mkdir -p bin \u0026\u0026 tar -xzvf $$filename --directory ./bin/ \u0026\u0026 \\\n\t./bin/viceroy --version \u0026\u0026 rm $$filename \u0026\u0026 sudo cp ./bin/viceroy /usr/local/bin/viceroy # NOTE: sudo is a no-op in GitHub Actions\n","tags":"#github #asset #release"},{"id":"fafb59064e96097f5483d3775181c541","title":"Testing: Different Testing Styles ","content":"## Unit test\n\nSpecify and test one point of the contract of single method of a class. This should have a very narrow and well defined scope. Complex dependencies and interactions to the outside world are stubbed or mocked.\n\n## Integration test\n\nTest the correct inter-operation of multiple subsystems. There is whole spectrum there, from testing integration between two classes, to testing integration with the production environment.\n\n## Acceptance test\n\nTest that a feature or use case is correctly implemented. It is similar to an integration test, but with a focus on the use case to provide rather than on the components involved.\n\n## Smoke test\n\nA simple integration test where we just check that when the system under test is invoked it returns normally and does not blow up.\n\nAlso known as a \"sanity check\".\n\n## Regression test\n\nA test that was written when a bug was fixed. It ensures that this specific bug will not occur again. The full name is \"non-regression test\". It can also be a test made prior to changing an application to make sure the application provides the same outcome.\n","tags":"#tests #terminology #system"},{"id":"87118a8f79d47aaf640c21149bf9d687","title":"Fastly: create, validate, and destroy service ","content":"\u003c!-- https://github.com/get-alex/alex?tab=readme-ov-file#control --\u003e\n\n\u003c!--alex disable dad-mom uk--\u003e\n\n# Compute readthrough cache validator\n\nThis directory contains a Compute application that proxies incoming requests\nonto [https://http-me.glitch.me/](https://http-me.glitch.me/).\n\nThere is a `run.sh` script which will attempt to validate the\nresponses from the Compute service to see what cache semantics are respected.\n\n\u003e [!TIP]\n\u003e Read the official Fastly documentation: [readthrough cache](https://www.fastly.com/documentation/guides/concepts/edge-state/cache/#readthrough-cache)\n\nThe `run.sh` script does the following:\n\n- Checks if `real` is passed as an input argument.\n  - If yes, it attempts to deploy the Compute application to Fastly.\n  - Otherwise, it attempts to run the Compute application locally.\n- It makes multiple requests to the Compute application.\n- It validates that the responses are as expected.\n\n\u003e [!IMPORTANT] \n\u003e It doesn't make sense (currently) to try and run this script without `real` as the input argument, because it causes the script to run the Compute application locally using `fastly compute serve`, which itself uses https://github.com/fastly/viceroy/ and Viceroy (at the moment) has no support for cache semantics.\n\n## POPs and Retries\n\nA request that you might expect to return a cache HIT, could return a MISS. This\nis because the request can end up at a different POP to where a previous request\nfor the resource ended up.\n\nFor example, in the UK there are multiple POPs. Nearest to me are the `LHR` and\n`LCY` POPs. This means I can make a request that ends up at the `LHR` POP, and\nif I make a second request and it also ends up at the same POP, then I'll get a\ncache HIT, otherwise if the request ends up at the `LCY` POP I'll get a cache\nMISS.\n\nTo try and account for this the `run.sh` script will re-attempt the request a\nnumber of times before marking it as unsuccessful. Ultimately, we want to be\nsure a request is either cached or not cached, so depending on what the\nexpectation is, we give the script the best chance possible to validate the\nexpectation accurately.\n\n## Summary of results\n\nRefer to the `run.sh` script for the details.\n\n|Request Method|Response Code|Response Headers|Cacheable|\n|---|---|---|---|\n|GET|200|   |✅|\n|GET|200|`Cache-Control:max-age=120`|✅|\n|GET|200|`Surrogate-Control:max-age=120`|✅|\n|GET|200|`Cache-Control:max-age=120\u0026Surrogate-Control:max-age=120`|✅|\n|GET|200|`Set-Cookie:foo=bar`|❌|\n|GET|200|`Cache-Control:no-store`|❌|\n|GET|200|`Cache-Control:private`|❌|\n|GET|200|`Surrogate-Control:no-store`|❌|\n|GET|200|`Surrogate-Control:private`|❌|\n|GET|203|   |✅|\n|GET|300|   |✅|\n|GET|301|   |✅|\n|GET|302|   |❌|\n|GET|400|   |❌|\n|GET|404|   |✅|\n|GET|410|   |✅|\n|GET|500|   |❌|\n|GET|503|   |❌|\n|POST|200|   |❌|\n|POST|200|`Cache-Control:max-age=120`|❌|\n|POST|200|`Surrogate-Control:max-age=120`|❌|\n|POST|200|`Cache-Control:max-age=120\u0026Surrogate-Control:max-age=120`|❌|\n\n\u003e [!NOTE]\n\u003e The [Fastly VCL documentation](https://www.fastly.com/documentation/reference/vcl/variables/backend-response/beresp-cacheable/) suggests a 302 is cacheable, but it's not in Compute.\n#!/usr/bin/env bash\n\nreal=\"$1\"\n\ncleanup() {\n  if [ \"$real\" == \"real\" ]; then\n    echo \"\"\n    fastly service delete --force # uses service_id in fastly.toml\n  fi\n}\ntrap 'cleanup' ERR\n\nif [ \"$real\" == \"real\" ]; then\n  fastly compute publish --non-interactive # uses [setup] in fastly.toml to create backend resource\nelse\n  fastly compute serve --verbose \u0026 # run in the background\n  bg_pid=$! # store the Fastly CLI's Process ID\nfi\n\nif [ \"$real\" == \"real\" ]; then\n  service_id=$(yq eval '.service_id' fastly.toml)\n  domain=$(fastly domain list --service-id \"$service_id\" --version latest --json | jq -r '.[0].Name')\n  endpoint=\"https://$domain\"\nelse\n  endpoint=\"http://127.0.0.1:7676\"\nfi\n\nif [ \"$real\" != \"real\" ]; then\n  # wait for the `serve` command to have spun up a local server\n  server_port=7676\n  max_attempts=10\n  attempt=0\n  while ! nc -z localhost \"$server_port\"; do\n    if (( attempt == max_attempts )); then\n      echo \"\"\n      echo \"The local server did not start within the specified number of attempts.\"\n      kill \"$bg_pid\" # terminate the Fastly CLI running `serve` command in the background\n      sleep 2 # give just enough time for Viceroy to setup its listener\n      kill \"$(lsof -i :7676 | awk 'NR==2 {print $2}')\" # terminal Viceroy (CLI might not have a chance to setup signal monitoring to terminate it yet)\n      exit 1\n    fi\n    sleep 1\n    (( attempt++ ))\n  done\nfi\n\n# NOTE: \"Fastly-Debug:1\" forces the display of the `Surrogate-Control` header.\n# We don't set Fastly-Debug because we want to validate Surrogate-Control is omitted from the response.\n#\n# IMPORTANT: Compute doesn't strip Surrogate-Control for POST requests.\n# This is to support VCL service chaining where VCL needs to cache the response.\n# Meaning the VCL service requires the Surrogate-Control still.\n# The Compute team will investigate if it's possible to fix this so that a\n# Compute service will strip the header if not fronted by another Fastly\n# service. Now, although POST requests don't strip Surrogate-Control and GET\n# requests do, the Viceroy testing tool NEVER strips Surrogate-Control and this\n# appears to be related to the fact that it has no cache semantics support.\n\nfunction check_cacheable() {\n  local url=$1\n  local needle=\"x-cache: HIT\"\n  retries=5\n  while [ \"$retries\" -gt 0 ]; do\n    response=$(curl -D - -s \"$url\")\n    if [[ $url == *\"Surrogate-Control\"* ]]; then\n      if [[ $response == *\"surrogate-control\"* ]]; then\n        echo \"\"\n        echo \"❌ Surrogate-Control failed to be stripped from the response for $url\"\n        echo \"\"\n      fi\n    fi\n    if [[ $url == *\"Cache-Control\"* ]]; then\n      if [[ $response != *\"cache-control\"* ]]; then\n        echo \"\"\n        echo \"❌ Cache-Control failed to be found in the response for $url\"\n        echo \"\"\n      fi\n    fi\n    if [[ $response == *\"$needle\"* ]]; then\n      echo \"\"\n      echo \"✅ Found '$needle' in the response from $url\"\n      echo \"\"\n      success=\"true\"\n      break\n    else\n      ((retries--))\n      success=\"false\"\n      sleep 1\n    fi\n  done\n  if [ \"$success\" != \"true\" ]; then\n    echo \"\"\n    echo \"❌ Failed after 5 retries to find '$needle' in the response from $url\"\n    echo \"\"\n  fi\n}\n\necho \"\"\necho \"Validating cacheable endpoints...\"\n\ncheck_cacheable \"$endpoint/anything/status=200\"\ncheck_cacheable \"$endpoint/anything/status=203\"\ncheck_cacheable \"$endpoint/anything/status=300\"\ncheck_cacheable \"$endpoint/anything/status=301\"\ncheck_cacheable \"$endpoint/anything/status=404\"\ncheck_cacheable \"$endpoint/anything/status=410\"\ncheck_cacheable \"$endpoint/anything/status=200?header=Cache-Control:max-age=120\"\ncheck_cacheable \"$endpoint/anything/status=200?header=Surrogate-Control:max-age=120\"\ncheck_cacheable \"$endpoint/anything/status=200?header=Surrogate-Control:max-age=240\u0026header=Cache-Control:max-age=120\"\n\nfunction check_uncacheable() {\n  local url=$1\n  local method=${2:-\"GET\"}\n  local needle=\"x-cache: HIT\"\n  retries=5\n  surrogate_error_displayed=\"false\"\n  cache_error_displayed=\"false\"\n  while [ \"$retries\" -gt 0 ]; do\n    response=$(curl -X \"$method\" -D - -s \"$url\")\n    if [[ $url == *\"Surrogate-Control\"* \u0026\u0026 $surrogate_error_displayed == \"false\" \u0026\u0026 $method != \"POST\" ]]; then\n      if [[ $response == *\"surrogate-control\"* ]]; then\n        echo \"\"\n        echo \"❌ Surrogate-Control failed to be stripped from the response for $method $url\"\n        echo \"\"\n        surrogate_error_displayed=\"true\"\n      fi\n    fi\n    if [[ $url == *\"Cache-Control\"* \u0026\u0026 $cache_error_displayed == \"false\" ]]; then\n      if [[ $response != *\"cache-control\"* ]]; then\n        echo \"\"\n        echo \"❌ Cache-Control failed to be found in the response for $method $url\"\n        echo \"\"\n        cache_error_displayed=\"true\"\n      fi\n    fi\n    if [[ $response == *\"$needle\"* ]]; then\n      echo \"\"\n      echo \"❌ Found '$needle' in the response from $method $url\"\n      echo \"\"\n      success=\"false\"\n      break\n    else\n      ((retries--))\n      success=\"true\"\n      sleep 1\n    fi\n  done\n  if [ \"$success\" == \"true\" ]; then\n    echo \"\"\n    echo \"✅ After 5 retries '$needle' was NOT found in the response from $method $url\"\n    echo \"\"\n  fi\n}\n\necho \"Validating uncacheable endpoints...\"\n\ncheck_uncacheable \"$endpoint/anything/status=200?header=Set-Cookie:foo=bar\"\ncheck_uncacheable \"$endpoint/anything/status=200?header=Cache-Control:no-store\"\ncheck_uncacheable \"$endpoint/anything/status=200?header=Cache-Control:private\"\ncheck_uncacheable \"$endpoint/anything/status=200?header=Surrogate-Control:no-store\"\ncheck_uncacheable \"$endpoint/anything/status=200?header=Surrogate-Control:private\"\ncheck_uncacheable \"$endpoint/anything/status=200\" \"POST\"\ncheck_uncacheable \"$endpoint/anything/status=200?header=Cache-Control:max-age=120\" \"POST\"\ncheck_uncacheable \"$endpoint/anything/status=200?header=Surrogate-Control:max-age=120\" \"POST\"\ncheck_uncacheable \"$endpoint/anything/status=200?header=Surrogate-Control:max-age=240\u0026header=Cache-Control:max-age=120\" \"POST\"\ncheck_uncacheable \"$endpoint/anything/status=302\" # https://www.fastly.com/documentation/reference/vcl/variables/backend-response/beresp-cacheable/ suggested this was cacheable, but it's not\ncheck_uncacheable \"$endpoint/anything/status=400\"\ncheck_uncacheable \"$endpoint/anything/status=500\"\ncheck_uncacheable \"$endpoint/anything/status=503\"\n\nif [ \"$real\" != \"real\" ]; then\n  kill \"$bg_pid\" # terminate the Fastly CLI running `serve` command in the background\n  kill \"$(lsof -i :7676 | awk 'NR==2 {print $2}')\" 2\u003e/dev/null # terminal Viceroy if still running (although CLI should have signals setup at this point and would have terminated it already)\nfi\n\ncleanup\n\n# NOTE: 3600s (1hr) is XQD's default TTL (VCL services have a 2min TTL).\n\npackage main\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"time\"\n\n\t\"github.com/fastly/compute-sdk-go/fsthttp\"\n)\n\n// BackendName is the origin server incoming requests will be proxied onto.\nconst BackendName = \"httpme\"\n\nfunc main() {\n\tfsthttp.ServeFunc(func(ctx context.Context, w fsthttp.ResponseWriter, r *fsthttp.Request) {\n\t\tstart := time.Now()\n\t\tresp, err := r.Send(ctx, BackendName)\n\t\tif err != nil {\n\t\t\tw.WriteHeader(fsthttp.StatusBadGateway)\n\t\t\tfmt.Fprintln(w, err.Error())\n\t\t\treturn\n\t\t}\n\t\tw.Header().Reset(resp.Header)\n\t\tw.Header().Set(\"X-Execution-Time\", time.Since(start).String())\n\t\tw.WriteHeader(resp.StatusCode)\n\t\tif err := w.Append(resp.Body); err != nil {\n\t\t\tw.WriteHeader(fsthttp.StatusBadGateway)\n\t\t\tfmt.Fprintln(w, err.Error())\n\t\t\treturn\n\t\t}\n\t})\n}\n# This file describes a Fastly Compute package. To learn more visit:\n# https://developer.fastly.com/reference/fastly-toml/\n\nauthors = [\"integralist@fastly.com\"]\ncloned_from = \"https://github.com/fastly/compute-starter-kit-go-default\"\ndescription = \"\"\nlanguage = \"go\"\nmanifest_version = 3\nname = \"fastly-readthrough-cache\"\nservice_id = \"\"\n\n[local_server]\n\n  [local_server.backends]\n\n    [local_server.backends.httpme]\n      override_host = \"http-me.glitch.me\"\n      url = \"https://http-me.glitch.me/\"\n\n[scripts]\n  build = \"go build -o bin/main.wasm .\"\n  env_vars = [\"GOARCH=wasm\", \"GOOS=wasip1\"]\n\n[setup]\n\n  [setup.backends]\n\n    [setup.backends.httpme]\n      address = \"http-me.glitch.me\"\n      description = \"HTTP me is a tiny express app initally designed to replicate the features of HTTPBin.org\"\n      port = 443\n\nmodule github.com/domainr/fastly-readthrough-cache\n\ngo 1.22\n\nrequire github.com/fastly/compute-sdk-go v1.3.0\n\n","tags":"#CLI #Fastly"},{"id":"4fcf0a313ffdbda99c59931b1142e8bb","title":"Go: understanding init functions ","content":"// This is a file designed to be run on go.dev/play (link below).\n// It validates the behaviour of init() functions.\n// i.e. init() is only called once regardless of how many times its package is imported.\n// https://go.dev/play/p/99YpDma6mVJ\npackage main\n\nimport (\n\t\"play.ground/bar\"\n\t\"play.ground/foo\"\n)\n\nfunc main() {\n\tfoo.Message()\n\tbar.Message()\n}\n-- go.mod --\nmodule play.ground\n-- foo/foo.go --\npackage foo\n\nimport (\n\t\"fmt\"\n\n\t\"play.ground/bar\"\n)\n\nfunc Message() {\n\tfmt.Println(\"This is the foo package\")\n\tbar.Message()\n}\n-- bar/bar.go --\npackage bar\n\nimport \"fmt\"\n\nfunc init() {\n\tfmt.Println(\"This is the init() inside the bar package\")\n}\n\nfunc Message() {\n\tfmt.Println(\"This is the bar package\")\n}\n","tags":"#go"},{"id":"dba19204e096bf43d0e6274d118d8da3","title":"Go: type cast ","content":"// https://play.golang.com/p/fLovZCiAzn1\npackage main\n\nimport (\n\t\"fmt\"\n)\n\ntype myString string\n\nfunc main() {\n\tvar s myString = \"this is my string\"\n\tp := \u0026s\n\tfmt.Printf(\"%#v (%T)\\n\", p, p) // (*main.myString)(0xc000104020) (*main.myString)\n\tc := (*string)(p)\n\tfmt.Printf(\"%#v (%T) %#v\\n\", c, c, *c) // (*string)(0xc000104020) (*string) \"this is my string\"\n}\n","tags":"#go"},{"id":"5862dd87fedf8b6cac96c8307bbdb755","title":"Go: copy struct from pointer ","content":"// structs are considered a primitive type and as such are passed by value.\n// but if you have a pointer to struct you need to be careful not to assign it to a variable thinking you're getting a copy of the 'value'.\n// you're only getting a copy of the 'pointer'! which means the newly assigned variable will mutate the underlying struct.\n// so to make a copy you have to dereference the struct pointer first.\n\npackage main\n\nimport \"fmt\"\n\ntype Foo struct {\n\tBar string\n\tBaz int\n\tQux bool\n}\n\nfunc main() {\n\tf := \u0026Foo{\"BAR\", 123, true}\n\tfmt.Printf(\"f (%T): %#v\\n\", f, f)\n\n\tf.Bar = \"BAR!\"\n\tfmt.Printf(\"f (%T): %#v\\n\", f, f)\n\n\tn := f // assigning f to n is assigning the pointer address to n\n\tn.Bar = \"BAR!!\" // meaning we're still able to mutate the struct that f is pointing to\n\tfmt.Printf(\"n (%T): %#v\\n\", n, n)\n\n\tc := *f // here we deference the pointer to get the struct 'value' back, and assign the value not the pointer to `c`\n\tc.Bar = \"BAR!!!\" // now this change only affects `c` and not the original struct that f and n point to\n\tfmt.Printf(\"c (%T): %#v\\n\", c, c) // doesn't modify n or f\n\tfmt.Printf(\"n (%T): %#v\\n\", n, n)\n\tfmt.Printf(\"f (%T): %#v\\n\", f, f)\n}\n","tags":"#go"},{"id":"e00bb3c9e3a1210d3cfae4ee3800a1b7","title":"OpenAPI: generate schema dynamically ","content":"#!/bin/bash\n\nAWK_PATH=$(which awk)\nCAT_PATH=$(which cat)\n\nread -rp \"Enter API Version (e.g. 1.0.0): \" VERSION\nread -rp \"Enter API Title: \" TITLE\nread -rp \"Enter API Description: \" DESCRIPTION\nread -rp \"Enter Your Name (for contact info): \" NAME\nread -rp \"Enter Your Email (for contact info): \" EMAIL\nread -rp \"Enter Category (for DevHub URL, e.g. services, see common/categories.yaml): \" CATEGORY\nread -rp \"Enter Slug (for DevHub URL, e.g. backend): \" SLUG\nread -rp \"Enter API Path (e.g. /service/{service_id}/version/{version_id}/backend): \" PATH\nread -rp \"Enter Resource (e.g. backend): \" RESOURCE\nread -rp \"Enter output file name (e.g. 'backend' will generate a 'backend.yaml' file): \" OUTPUT_FILENAME\n\nrm \"${OUTPUT_FILENAME}.yaml\" 2\u003e/dev/null\n\n# Function to capitalize the first letter of a string\ncapitalize() {\n  echo \"$1\" | $AWK_PATH '{print toupper(substr($0,1,1)) tolower(substr($0,2))}'\n}\n\n# Replace template fields in the template content\ncontent=$( $CAT_PATH \u003c\u003cEOF\nopenapi: 3.0.3\ninfo:\n  version: '$VERSION'\n  title: $(capitalize \"$TITLE\")\n  description: $DESCRIPTION.\n  termsOfService: https://www.fastly.com/terms\n  contact:\n    name: $NAME\n    email: $EMAIL\n    url: https://www.fastly.com\n\nservers:\n  - url: https://api.fastly.com\n\nsecurity:\n  - token_engineer: []\n\nx-taxonomy:\n  category:\n    \\$ref: 'common/categories.yaml#/$CATEGORY'\n  slug: $SLUG\n\npaths:\n  $PATH:\n    get:\n      summary: List $RESOURCE\n      description: List all $RESOURCE.\n      operationId: list-${RESOURCE}s\n      responses:\n        '200':\n          \\$ref: '#/components/responses/response-$RESOURCE'\n\n    post:\n      summary: Create a $RESOURCE\n      description: Create a $RESOURCE.\n      operationId: create-$RESOURCE\n      requestBody:\n        \\$ref: '#/components/requestBodies/requestBody-$RESOURCE'\n      responses:\n        '200':\n          \\$ref: '#/components/responses/response-$RESOURCE'\n\n  '$PATH/{${RESOURCE}_id}':\n    get:\n      summary: Get a $RESOURCE\n      description: Get a $RESOURCE.\n      operationId: list-$RESOURCE-s-${RESOURCE}_id\n      parameters:\n        - \\$ref: '#/components/parameters/parameter-${RESOURCE}_id'\n      responses:\n        '200':\n          \\$ref: '#/components/responses/response-$RESOURCE'\n\n    patch:\n      summary: Update a $RESOURCE\n      description: Update a $RESOURCE.\n      operationId: update-$RESOURCE\n      parameters:\n        - \\$ref: '#/components/parameters/parameter-${RESOURCE}_id'\n      requestBody:\n        \\$ref: '#/components/requestBodies/requestBody-$RESOURCE'\n      responses:\n        '200':\n          \\$ref: '#/components/responses/response-$RESOURCE'\n\n    delete:\n      summary: Delete a $RESOURCE\n      description: Delete a $RESOURCE.\n      operationId: delete-$RESOURCE\n      parameters:\n        - name: ${RESOURCE}_id\n          in: path\n          required: true\n          schema:\n            type: string\n            description: $(capitalize \"$RESOURCE\") Identifier (UUID).\n      responses:\n        '200':\n          description: OK\n\ncomponents:\n  examples:\n    example-requestBody-$RESOURCE:\n      value:\n        example_field_name_1: '...'\n        example_field_name_2:\n          - id: '...'\n            title: '...'\n            example_of_nullable_field: null\n\n    example-response-$RESOURCE:\n      value:\n        example_field_name_1: '...'\n        example_field_name_2:\n          - id: '...'\n            title: '...'\n            example_of_nullable_field: null\n\n  parameters:\n    parameter-${RESOURCE}_id:\n      name: ${RESOURCE}_id\n      in: path\n      required: true\n      schema:\n        type: string\n        description: $(capitalize \"$RESOURCE\") Identifier (UUID).\n\n  requestBodies:\n    requestBody-$RESOURCE:\n      content:\n        application/json:\n          schema:\n            \\$ref: '#/components/schemas/schema-requestBody-$RESOURCE'\n          examples:\n            body:\n              \\$ref: '#/components/examples/example-requestBody-$RESOURCE'\n\n  responses:\n    response-$RESOURCE:\n      description: Example response.\n      content:\n        application/json:\n          schema:\n            \\$ref: '#/components/schemas/schema-response-$RESOURCE'\n          examples:\n            body:\n              \\$ref: '#/components/examples/example-response-$RESOURCE'\n\n  securitySchemes:\n    token_engineer:\n      \\$ref: 'common/security.yaml#/token_engineer'\n\n  schemas:\n    schema-requestBody-$RESOURCE:\n      title: $RESOURCE\n      description: A $RESOURCE request body.\n      allOf:\n        - \\$ref: '#/components/schemas/schema-${RESOURCE}-mulitple-schemas-example-1'\n        - \\$ref: '#/components/schemas/schema-${RESOURCE}-mulitple-schemas-example-2'\n\n    schema-response-$RESOURCE:\n      title: $RESOURCE\n      description: A $RESOURCE response.\n      allOf:\n        - \\$ref: '#/components/schemas/schema-${RESOURCE}-mulitple-schemas-example-1'\n        - \\$ref: '#/components/schemas/schema-${RESOURCE}-mulitple-schemas-example-2'\n\n    schema-${RESOURCE}-mulitple-schemas-example-1:\n      type: object\n      properties:\n        example_field_name_1:\n          type: string\n          description: Some example description.\n\n    schema-${RESOURCE}-mulitple-schemas-example-2:\n      type: object\n      properties:\n        example_field_name_2:\n          type: array\n          items:\n            \\$ref: '#/components/schemas/schema-array-items-as-object'\n\n    schema-array-items-as-object:\n      type: object\n      title: Example array item\n      description: An example array item.\n      properties:\n        id:\n          type: string\n          description: An example identifier (UUID).\n          readOnly: true\n        title:\n          type: string\n        example_of_nullable_field:\n          type: string\n          nullable: true\n          default: null\n          description: A field that can be null.\n      required:\n        - title\nEOF\n)\n\n# Write the final output to a new yaml file\necho \"$content\" \u003e \"${OUTPUT_FILENAME}.yaml\"\necho \"\"\necho \"Script executed successfully. Output saved to ${OUTPUT_FILENAME}.yaml\"\n","tags":"#openapi #template #bash #shell"},{"id":"66b93fcfde73b7ef3a0f885dae7ce570","title":"Go: filter secrets ","content":"// WARNING: There are regexes in trufflehog that try to match the VALUE.\n// So for example, setting `AWS_SECRET_ACCESS_KEY` by itself doesn't get identified.\n// Only if the VALUE assigned to it matches the expected regex pattern defined in trufflehog.\n\npackage main\n\nimport (\n\t\"fmt\"\n  \t\"log\"\n  \t\"runtime\"\n\t\"sync\"\n  \n\t// go get github.com/trufflesecurity/trufflehog/v3@latest\n  \n\t\"github.com/trufflesecurity/trufflehog/v3/pkg/context\"\n\t\"github.com/trufflesecurity/trufflehog/v3/pkg/detectors\"\n\t\"github.com/trufflesecurity/trufflehog/v3/pkg/engine\"\n\t\"github.com/trufflesecurity/trufflehog/v3/pkg/output\"\n\t\"github.com/trufflesecurity/trufflehog/v3/pkg/sources\"\n)\n\nfunc main() {\n\tctx := context.Background()\n\tprinter := new(output.JSONPrinter)\n\t// NOTE: To prevent a log output we have to explicitly set the concurrency.\n\te, err := engine.Start(ctx,\n\t\tengine.WithPrinter(printer),\n\t\tengine.WithConcurrency(uint8(runtime.NumCPU())),\n\t)\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\tcfg := sources.FilesystemConfig{\n\t\tPaths: []string{\"./fastly.toml\"},\n\t}\n\tif err = e.ScanFileSystem(ctx, cfg); err != nil {\n\t\tlog.Fatal(err)\n\t}\n\tvar (\n\t\tmu      sync.Mutex\n\t\tresults []detectors.ResultWithMetadata\n\t)\n\tgo func() {\n\t\tfor result := range e.ResultsChan() {\n\t\t\tmu.Lock()\n\t\t\tresults = append(results, result)\n\t\t\tmu.Unlock()\n\t\t}\n\t}()\n\terr = e.Finish(ctx)\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\tfmt.Println(\"HasFoundResults:\", e.HasFoundResults())\n\tfmt.Println(e.GetMetrics().BytesScanned)\n\tfmt.Println(e.GetMetrics().ChunksScanned)\n\tfmt.Println(e.GetMetrics().UnverifiedSecretsFound)\n\tfmt.Println(e.GetMetrics().VerifiedSecretsFound)\n\tfor _, r := range results {\n\t\tfmt.Printf(\"REDACT ME: %#v\\n\", r.Redacted)\n\t}\n}\n","tags":"#go #security"},{"id":"7c6c9418ca6b328d6a721ccf34df050a","title":"Go: range bug ","content":"## Problem\n\nConsider the following example:\n\n```go\npackage main\n\nimport \"fmt\"\n\nfunc main() {\n\tfor _, n := range []int{1, 2, 3, 4} {\n\t\tfmt.Printf(\"%#v | %d\\n\", \u0026n, n) // NOTE: The memory address is the same! Meaning the value could change and print 4 each time.\n\t}\n}\n```\n\nStatic analysis tools (like `gosec`) will sometimes report:\n\n\u003e G601: Implicit memory aliasing in for loop. (gosec)\n\nThis happens because in [for statements](https://golang.org/ref/spec#For_statements) the iteration variable is reused. \n\nThis means for each iteration, the _value_ of the next element in the `range` expression is assigned to the iteration variable. \n\nSo `v` doesn't change, only its _value_ changes. Hence, the expression `\u0026v` is referring to the _same location in memory_.\n\nWhen you store the address of the iteration variable, or when you use it in a closure inside the loop, by the time you dereference the pointer, its value might have changed.\n\n## Solutions\n\n\u003e **NOTE:** Go _might_ fix this in go1.22 (not guaranteed at time of writing).\n\nIndex the ranged slice/array/map. This takes the address of the actual element at i-th position, instead of the iteration variable:\n\n```go\nfor i := range versions {\n    res := createWorkerFor(\u0026versions[i])\n}\n```\n\nReassign the iteration variable inside the loop:\n\n```go\nfor _, v := range versions {\n    v := v\n    res := createWorkerFor(\u0026v) // this is now the address of the inner v\n}\n```\n\nWith closures, pass the iteration variable as argument to the closure:\n\n```go\nfor _, v := range versions { \n    go func(arg ObjectDescription) {\n        x := \u0026arg // safe\n    }(v)\n}\n```\n\n## Reference\n\nThis gist was produced after reading the answer given here: https://stackoverflow.com/a/68247837/14849316\n","tags":"#go #bug"},{"id":"fad304fd5f435b8f400d6adad693a8a2","title":"Go: pointer receiver method avoids runtime panic ","content":"// https://play.golang.com/p/NOxcQO8U-G7\n\npackage main\n\nimport (\n\t\"fmt\"\n)\n\ntype Example struct {\n\tField int\n}\n\nfunc (e *Example) PointerMethod() {\n\tfmt.Printf(\"PointerMethod: %#v (%T)\\n\", e, e)\n\tfmt.Printf(\"PointerMethod field access: %#v (%T)\\n\", e.Field, e.Field) // this is a runtime panic\n}\n\nfunc (e Example) ValueMethod() {\n\tfmt.Printf(\"ValueMethod: %#v (%T)\\n\", e, e)\n}\n\nfunc NewExample() *Example {\n\treturn nil\n}\n\nfunc main() {\n\te := NewExample()\n\tfmt.Printf(\"main: %#v (%T)\\n\", e, e) // (*main.Example)(nil) (*main.Example)\n\te.PointerMethod()                    // this is ok! :mindblown:\n\te.ValueMethod()                      // this is a runtime panic\n\tfmt.Println(e.Field)                 // this is a runtime panic\n\n\u003e [!IMPORTANT]\n\u003e Even though you can call the pointer receiver method, you still can't access a field without triggering a runtime panic. But just being able to call the method is still useful/interesting.\n\n**The explanation for this is as follows...**\n\nThere’s two things going on here. The first is calling a method. Go knows which method to call thanks to the name of the method and the type of the receiver. That’s all there is to knowing which method to call.\n\ne.g. The Go runtime evaluates the code `e.PointerMethod()` into something like `(*Example).PointerMethod(e)`.\n\nThe trick to understand the rest is to remember that having a pointer be nil is not a reason to panic just yet. You only panic when you try to do something that needs to dereference that nil pointer.\n\nNow when the method gets called, the sugared version (e.g. `(*Example).PointerMethod(e)`) shows that the first argument is the receiver. \n\nIf that receiver is a pointer, then Go gives that even if it’s nil and that’s fine since it doesn’t get dereferenced (until you dereference it yourself and that panics). \n\nIf you try to pass a nil pointer by value, Go will need to dereference it and will panic before having a chance to call your method.\n\nThis is why calling a method with a value receiver will trigger a runtime panic.\n","tags":"#go"},{"id":"764dec7fb5e0ad4351b5fbc99e798838","title":"Go: recursively walk tree looking for go files and analysing their imports ","content":"package main\n\nimport (\n\t\"fmt\"\n\t\"go/ast\"\n\t\"go/parser\"\n\t\"go/token\"\n\t\"log\"\n\t\"os\"\n\t\"path/filepath\"\n\t\"sort\"\n\t\"strings\"\n)\n\nfunc main() {\n\t// Create a new file set\n\tfs := token.NewFileSet()\n\n\t// Create a map to track imported packages\n\timportedPackages := make(map[string]bool)\n\n\t// Create a slice to store the import paths\n\tvar importPaths []string\n\n\t// Walk through the current directory and its subdirectories\n\troot := \"/Users/integralist/Code/fastly/cli\" // You can change this to the desired directory path\n\terr := filepath.Walk(root, func(path string, _ os.FileInfo, _ error) error {\n\t\t// Check if the file is a Go source file\n\t\tif strings.HasSuffix(path, \".go\") {\n\t\t\t// Read the content of the Go file\n\t\t\tgoCode, err := os.ReadFile(path)\n\t\t\tif err != nil {\n\t\t\t\tlog.Printf(\"Error reading file %s: %v\", path, err)\n\t\t\t\treturn nil\n\t\t\t}\n\n\t\t\t// Parse the Go code into an AST\n\t\t\tnode, err := parser.ParseFile(fs, path, string(goCode), parser.AllErrors)\n\t\t\tif err != nil {\n\t\t\t\tlog.Printf(\"Error parsing file %s: %v\", path, err)\n\t\t\t\treturn nil\n\t\t\t}\n\n\t\t\t// Extract and store import declarations in the slice\n\t\t\tfor _, decl := range node.Decls {\n\t\t\t\tif gd, isGenDecl := decl.(*ast.GenDecl); isGenDecl \u0026\u0026 gd.Tok == token.IMPORT {\n\t\t\t\t\tfor _, spec := range gd.Specs {\n\t\t\t\t\t\tif ispec, isImportSpec := spec.(*ast.ImportSpec); isImportSpec {\n\t\t\t\t\t\t\timportPath := strings.TrimSpace(ispec.Path.Value)\n\t\t\t\t\t\t\tif !importedPackages[importPath] {\n\t\t\t\t\t\t\t\timportPaths = append(importPaths, importPath)\n\t\t\t\t\t\t\t\timportedPackages[importPath] = true\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\treturn nil\n\t})\n\tif err != nil {\n\t\tlog.Fatalf(\"Error walking directory: %v\", err)\n\t}\n\n\t// Print the unique import paths\n\tsort.Strings(importPaths)\n\tfor _, path := range importPaths {\n\t\tfmt.Println(\"Import:\", path)\n\t}\n}\n// IMCOMPLETE (started but never finished).\n// Two formats to account for (CommonJS and ES Modules).\n//\n// CommonJS...\n//\n// const {add, subtract} = require('./util')\n// const {\n//   add, \n//   subtract\n// } = require('./util')\n// \n// ES Modules...\n//\n// import {add, subtract} from './util.mjs'\n// import {\n//   add, \n//   subtract\n// } from './util.mjs' \n// import defaultExport from \"module-name\";\n// import * as name from \"module-name\";\n// import { \n//   export1 \n// } from \"module-name\";\n// import { export1 as alias1 } from \"module-name\";\n// import { default as alias } from \"module-name\";\n// import { export1, export2 } from \"module-name\";\n// import { export1, export2 as alias2, /* … */ } from \"module-name\";\n// import { \"string name\" as alias } from \"module-name\";\n// import defaultExport, { export1, /* … */ } from \"module-name\";\n// import defaultExport, * as name from \"module-name\";\n// import \"module-name\";\n\n// Variables used as part of parsing imports from JavaScript source files.\nvar (\n\timportSingleLineBlockPattern = regexp.MustCompile(`^import (\\{ [^;]+);`)\n\timportAsPattern              = regexp.MustCompile(`as [^\\s]+\\s*`)\n)\n\n// Imports returns all source code imported packages.\nfunc (j *JavaScript) Imports() []string {\n\timportedPackages := make(map[string]bool)\n\n\tvar importPaths []string\n\n\troot := \".\"\n\t_ = filepath.Walk(root, func(path string, _ os.FileInfo, _ error) error {\n\t\tif strings.HasSuffix(path, \".js\") {\n\t\t\tif strings.Contains(path, \"node_modules\") {\n\t\t\t\treturn nil\n\t\t\t}\n\n\t\t\tf, err := os.Open(path)\n\t\t\tif err != nil {\n\t\t\t\treturn nil\n\t\t\t}\n\t\t\tdefer f.Close()\n\n\t\t\tscanner := bufio.NewScanner(f)\n\n\t\t\tfor scanner.Scan() {\n\t\t\t\tline := scanner.Text()\n\t\t\t\tmatch := importSingleLineBlockPattern.FindStringSubmatch(line)\n\t\t\t\tif len(match) \u003e= 2 {\n\t\t\t\t\titem := importAsPattern.ReplaceAllString(match[1], \"\")\n\t\t\t\t\tif !importedPackages[item] {\n\t\t\t\t\t\timportPaths = append(importPaths, item)\n\t\t\t\t\t\timportedPackages[item] = true\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\treturn nil\n\t})\n\n\tsort.Strings(importPaths)\n\treturn importPaths\n}\n/*\nWorks with...\n\nuse wasi_common::I32Exit;\nuse fastly::http::{header, Method, StatusCode}\n\nuse fastly::http::{header, Method, StatusCode};\nuse fastly::{mime, Error, Request, Response};\n\nuse {\n    fastly::http::header,\n    fastly::http::Method,\n    fastly::http::StatusCode,\n    fastly::{mime, Error, Request, Response},\n};\n\nuse {\n    fastly::http::header,\n    fastly::http::Method,\n    fastly::http::StatusCode,\n    fastly::{\n        mime, Error, Request, Response,\n    },\n};\n\nuse {\n    fastly::http::{\n      header,\n    },\n    fastly::http::Method,\n    fastly::http::StatusCode,\n    fastly::{\n        mime, Error, Request, Response,\n    },\n};\n\nuse {\n    fastly::http::*,\n    fastly::{\n        mime, Error, Request, Response,\n    },\n};\n*/\n\npackage main\n\nimport (\n\t\"bufio\"\n\t\"fmt\"\n\t\"os\"\n\t\"path/filepath\"\n\t\"regexp\"\n\t\"sort\"\n\t\"strings\"\n)\n\nvar (\n\tuseSinglePattern               = regexp.MustCompile(`^\\s*use\\s+([^;]+);`)\n\tuseMultilineStartPattern       = regexp.MustCompile(`^\\s*use\\s+\\{$`)\n\tuseMultilineEndPattern         = regexp.MustCompile(`^\\s*};$`)\n  \tuseMultilineNestedStartPattern = regexp.MustCompile(`^\\s*((\\w+::)+)\\{$`)\n\tuseMultilineNestedEndPattern   = regexp.MustCompile(`^\\s*}$`)\n\tmultilineNested                bool\n\tmultilineNestedPrefix          string\n)\n\nfunc main() {\n\timportedPackages := make(map[string]bool)\n\n\tvar importPaths []string\n\n\troot := \"/Users/integralist/Code/test-projects/testing-fastly-cli\"\n\t_ = filepath.Walk(root, func(path string, info os.FileInfo, err error) error {\n\t\tif strings.HasSuffix(path, \".rs\") {\n\t\t\tif strings.Contains(path, \"/target/\") {\n\t\t\t\treturn nil\n\t\t\t}\n\t\t\tfile, err := os.Open(path)\n\t\t\tif err != nil {\n\t\t\t\treturn nil\n\t\t\t}\n\t\t\tdefer file.Close()\n\n\t\t\tscanner := bufio.NewScanner(file)\n\n\t\t\tvar multilineUse bool\n\n\t\t\tfor scanner.Scan() {\n\t\t\t\tline := scanner.Text()\n\n\t\t\t\t// Parse single `use` declaration\n\t\t\t\tmatch := useSinglePattern.FindStringSubmatch(line)\n\t\t\t\tif len(match) \u003e= 2 {\n\t\t\t\t\tusePath := strings.TrimSpace(match[1])\n\t\t\t\t\tvar cont bool\n\t\t\t\t\timportPaths, cont = parseUseDeclarations(usePath, importPaths, importedPackages)\n\t\t\t\t\tif cont {\n\t\t\t\t\t\tcontinue\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\t// Parse multiline `use` declaration\n\t\t\t\tif useMultilineStartPattern.MatchString(line) {\n\t\t\t\t\tmultilineUse = true\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t\tif useMultilineEndPattern.MatchString(line) {\n\t\t\t\t\tmultilineUse = false\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t\tif multilineUse \u0026\u0026 !useMultilineEndPattern.MatchString(line) {\n\t\t\t\t\tusePath := strings.TrimSpace(line)\n\t\t\t\t\tusePath = strings.TrimSuffix(line, \",\")\n\t\t\t\t\tvar cont bool\n\t\t\t\t\timportPaths, cont = parseUseDeclarations(usePath, importPaths, importedPackages)\n\t\t\t\t\tif cont {\n\t\t\t\t\t\tcontinue // TODO: is this needed?\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\treturn nil\n\t})\n\n\tsort.Strings(importPaths)\n\tfor _, path := range importPaths {\n\t\tfmt.Println(path)\n\t}\n}\n\nfunc parseUseDeclarations(\n\tusePath string,\n\timportPaths []string,\n\timportedPackages map[string]bool,\n) ([]string, bool) {\n\t// Parse a nested multiline crate declaration\n\t//\n\t// e.g.\n\t// use {\n\t//     fastly::http::header,\n\t//     fastly::http::Method,\n\t//     fastly::http::StatusCode,\n\t//     fastly::{                           \u003c\u003c\u003c this\n\t//         mime, Error, Request, Response, \u003c\u003c\u003c this\n\t//     },                                  \u003c\u003c\u003c this\n\t// };\n\tmatch := useMultilineNestedStartPattern.FindStringSubmatch(usePath)\n\tif len(match) \u003e= 2 {\n\t\tmultilineNested = true\n\t\tmultilineNestedPrefix = strings.TrimSpace(match[1])\n\t\treturn importPaths, true\n\t}\n\tif useMultilineNestedEndPattern.MatchString(usePath) {\n\t\tmultilineNested = false\n\t\tmultilineNestedPrefix = \"\"\n\t\treturn importPaths, true\n\t}\n\tif multilineNested \u0026\u0026 !useMultilineNestedEndPattern.MatchString(usePath) {\n\t\tusePath := strings.TrimSpace(usePath)\n\t\tusePath = strings.TrimSuffix(usePath, \",\")\n\t\tfor _, v := range strings.Split(usePath, \",\") {\n\t\t\titem := fmt.Sprintf(\"%s%s\", multilineNestedPrefix, strings.TrimSpace(v))\n\t\t\tif !importedPackages[item] {\n\t\t\t\timportPaths = append(importPaths, item)\n\t\t\t\timportedPackages[item] = true\n\t\t\t}\n\t\t}\n\t\treturn importPaths, true\n\t}\n\n\t// Find the position of the opening and closing curly braces\n\topenBraceIndex := strings.Index(usePath, \"{\")\n\tcloseBraceIndex := strings.Index(usePath, \"}\")\n\n\t// Parse `use \u003cpath\u003e::{\u003cpath\u003e, \u003cpath\u003e, \u003cpath\u003e}`\n\tif openBraceIndex != -1 \u0026\u0026 closeBraceIndex != -1 {\n\t\t// Extract the prefix before the opening curly brace\n\t\tprefix := usePath[:openBraceIndex]\n\t\t// Extract the contents inside the curly braces\n\t\tcontents := usePath[openBraceIndex+1 : closeBraceIndex]\n\n\t\tfor _, item := range strings.Split(contents, \",\") {\n\t\t\titem = fmt.Sprintf(\"%s%s\", strings.TrimSpace(prefix), strings.TrimSpace(item))\n\t\t\tif !importedPackages[item] {\n\t\t\t\timportPaths = append(importPaths, item)\n\t\t\t\timportedPackages[item] = true\n\t\t\t}\n\t\t}\n\t\treturn importPaths, true\n\t}\n\n\t// Parse `use \u003cpath\u003e;`\n\tusePath = strings.TrimSpace(usePath)\n\tif !importedPackages[usePath] {\n\t\timportPaths = append(importPaths, usePath)\n\t\timportedPackages[usePath] = true\n\t}\n\n\treturn importPaths, false\n}\n","tags":"#go #ast #recursive"},{"id":"f2cb72380a7e3c3e8363dba698ab9926","title":"Go: call method directly via method expressions ","content":"// https://play.golang.com/p/iPOOcSzZCe7\n\npackage main\n\nimport (\n\t\"fmt\"\n)\n\ntype Foo struct {\n\tBar string\n}\n\nfunc (f Foo) String() string {\n\treturn f.Bar + \" stuff happens\"\n}\n\nfunc main() {\n\tf := Foo{Bar: \"Baz\"}\n\tfmt.Println(Foo.String(f))\n}\n","tags":"#go #expressions"},{"id":"bcbfa8e5ea7921978031b4285a61b9a2","title":"Go: structure logging ","content":"// https://go.dev/play/p/dgMult9xaao\n//\n// Code copied verbatim from https://github.com/veqryn/slog-dedup\n\npackage main\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"log/slog\"\n\t\"os\"\n\n\t\"modernc.org/b/v2\" // Package b implements the B+tree flavor of a BTree.\n)\n\nfunc main() {\n\tslogger := slog.New(NewOverwriteHandler(slog.NewJSONHandler(os.Stdout, \u0026slog.HandlerOptions{\n\t\tLevel: slog.LevelDebug,\n\t})))\n\n\tFuncA(slogger, \"foo\")\n}\n\nfunc FuncA(l *slog.Logger, someAttr string) {\n\tl = l.With(slog.String(\"foo\", someAttr))\n\tl.Debug(\"FuncA\")\n\tFuncB(l, \"foo\") // \"foo\":\"foo\"\n}\n\nfunc FuncB(l *slog.Logger, someAttr string) {\n\tl = l.With(slog.String(\"foo\", someAttr))\n\tl.Debug(\"FuncB\")\n\tFuncC(l, someAttr) // \"foo\":\"foo\",\"foo\":\"foo\"\n}\n\nfunc FuncC(l *slog.Logger, someAttr string) {\n\tl = l.With(slog.String(\"foo\", someAttr))\n\tl.Debug(\"FuncC\") // \"foo\":\"foo\",\"foo\":\"foo\",\"foo\":\"foo\"\n}\n\n// NewOverwriteHandler creates an OverwriteHandler slog.Handler middleware that will deduplicate all attributes and\n// groups by overwriting any older attributes or groups with the same string key.\n// It passes the final record and attributes off to the next handler when finished.\nfunc NewOverwriteHandler(next slog.Handler) *OverwriteHandler {\n\treturn \u0026OverwriteHandler{\n\t\tnext:       next,\n\t\tkeyCompare: CaseSensitiveCmp,\n\t\tgetKey:     getKeyClosure(IncrementIfBuiltinKeyConflict),\n\t}\n}\n\n// OverwriteHandler is a slog.Handler middleware that will deduplicate all attributes and\n// groups by overwriting any older attributes or groups with the same string key.\n// It passes the final record and attributes off to the next handler when finished.\ntype OverwriteHandler struct {\n\tnext       slog.Handler\n\tgoa        *groupOrAttrs\n\tkeyCompare func(a, b string) int\n\tgetKey     func(key string, depth int) (string, bool)\n}\n\n// Enabled reports whether the next handler handles records at the given level.\n// The handler ignores records whose level is lower.\nfunc (h *OverwriteHandler) Enabled(ctx context.Context, level slog.Level) bool {\n\treturn h.next.Enabled(ctx, level)\n}\n\n// Handle de-duplicates all attributes and groups, then passes the new set of attributes to the next handler.\nfunc (h *OverwriteHandler) Handle(ctx context.Context, r slog.Record) error {\n\t// The final set of attributes on the record, is basically the same as a final With-Attributes groupOrAttrs.\n\t// So collect all final attributes and turn them into a groupOrAttrs so that it can be handled the same.\n\tfinalAttrs := make([]slog.Attr, 0, r.NumAttrs())\n\tr.Attrs(func(a slog.Attr) bool {\n\t\tfinalAttrs = append(finalAttrs, a)\n\t\treturn true\n\t})\n\tgoas := collectGroupOrAttrs(h.goa, \u0026groupOrAttrs{attrs: finalAttrs})\n\n\t// Resolve groups and with-attributes\n\tuniq := b.TreeNew[string, any](h.keyCompare)\n\th.createAttrTree(uniq, goas, 0)\n\n\t// Add all attributes to new record (because old record has all the old attributes)\n\tnewR := \u0026slog.Record{\n\t\tTime:    r.Time,\n\t\tLevel:   r.Level,\n\t\tMessage: r.Message,\n\t\tPC:      r.PC,\n\t}\n\n\t// Add deduplicated attributes back in\n\tnewR.AddAttrs(buildAttrs(uniq)...)\n\treturn h.next.Handle(ctx, *newR)\n}\n\n// WithGroup returns a new OverwriteHandler that still has h's attributes,\n// but any future attributes added will be namespaced.\nfunc (h *OverwriteHandler) WithGroup(name string) slog.Handler {\n\th2 := *h\n\th2.goa = h2.goa.WithGroup(name)\n\treturn \u0026h2\n}\n\n// WithAttrs returns a new OverwriteHandler whose attributes consists of h's attributes followed by attrs.\nfunc (h *OverwriteHandler) WithAttrs(attrs []slog.Attr) slog.Handler {\n\th2 := *h\n\th2.goa = h2.goa.WithAttrs(attrs)\n\treturn \u0026h2\n}\n\n// createAttrTree recursively goes through all groupOrAttrs, resolving their attributes and creating subtrees as\n// necessary, adding the results to the map\nfunc (h *OverwriteHandler) createAttrTree(uniq *b.Tree[string, any], goas []*groupOrAttrs, depth int) {\n\tif len(goas) == 0 {\n\t\treturn\n\t}\n\n\t// If a group is encountered, create a subtree for that group and all groupOrAttrs after it\n\tif goas[0].group != \"\" {\n\t\tif key, ok := h.getKey(goas[0].group, depth); ok {\n\t\t\tuniqGroup := b.TreeNew[string, any](h.keyCompare)\n\t\t\th.createAttrTree(uniqGroup, goas[1:], depth+1)\n\t\t\t// Ignore empty groups, otherwise put subtree into the map\n\t\t\tif uniqGroup.Len() \u003e 0 {\n\t\t\t\tuniq.Set(key, uniqGroup)\n\t\t\t}\n\t\t\treturn\n\t\t}\n\t}\n\n\t// Otherwise, set all attributes for this groupOrAttrs, and then call again for remaining groupOrAttrs's\n\th.resolveValues(uniq, goas[0].attrs, depth)\n\th.createAttrTree(uniq, goas[1:], depth)\n}\n\n// resolveValues iterates through the attributes, resolving them and putting them into the map.\n// If a group is encountered (as an attribute), it will be separately resolved and added as a subtree.\n// Since attributes are ordered from oldest to newest, it overwrites keys as it goes.\nfunc (h *OverwriteHandler) resolveValues(uniq *b.Tree[string, any], attrs []slog.Attr, depth int) {\n\tvar ok bool\n\tfor _, a := range attrs {\n\t\ta.Value = a.Value.Resolve()\n\t\tif a.Equal(slog.Attr{}) {\n\t\t\tcontinue // Ignore empty attributes, and keep iterating\n\t\t}\n\n\t\t// Default situation: resolve the key and put it into the map\n\t\ta.Key, ok = h.getKey(a.Key, depth)\n\t\tif !ok {\n\t\t\tcontinue\n\t\t}\n\n\t\tif a.Value.Kind() != slog.KindGroup {\n\t\t\tuniq.Set(a.Key, a)\n\t\t\tcontinue\n\t\t}\n\n\t\t// Groups with empty keys are inlined\n\t\tif a.Key == \"\" {\n\t\t\th.resolveValues(uniq, a.Value.Group(), depth)\n\t\t\tcontinue\n\t\t}\n\n\t\t// Create a subtree for this group\n\t\tuniqGroup := b.TreeNew[string, any](h.keyCompare)\n\t\th.resolveValues(uniqGroup, a.Value.Group(), depth+1)\n\n\t\t// Ignore empty groups, otherwise put subtree into the map\n\t\tif uniqGroup.Len() \u003e 0 {\n\t\t\tuniq.Set(a.Key, uniqGroup)\n\t\t}\n\t}\n}\n\n// buildAttrs converts the deduplicated map back into an attribute array,\n// with any subtrees converted into slog.Group's\nfunc buildAttrs(uniq *b.Tree[string, any]) []slog.Attr {\n\ten, emptyErr := uniq.SeekFirst()\n\tif emptyErr != nil {\n\t\treturn nil // Empty (btree only returns an error when empty)\n\t}\n\tdefer en.Close()\n\n\t// Iterate through all values in the map, add to slice\n\tattrs := make([]slog.Attr, 0, uniq.Len())\n\tfor k, i, err := en.Next(); err == nil; k, i, err = en.Next() {\n\t\t// Values will either be an attribute, a subtree, or a specially appended slice of the former two\n\t\tswitch v := i.(type) {\n\t\tcase slog.Attr:\n\t\t\tattrs = append(attrs, v)\n\t\tcase *b.Tree[string, any]:\n\t\t\t// Convert subtree into a group\n\t\t\tattrs = append(attrs, slog.Attr{Key: k, Value: slog.GroupValue(buildAttrs(v)...)})\n\t\tcase appended:\n\t\t\t// This case only happens in the AppendHandler\n\t\t\tanys := make([]any, 0, len(v))\n\t\t\tfor _, sliceVal := range v {\n\t\t\t\tswitch sliceV := sliceVal.(type) {\n\t\t\t\tcase slog.Attr:\n\t\t\t\t\tanys = append(anys, sliceV.Value.Any())\n\t\t\t\tcase *b.Tree[string, any]:\n\t\t\t\t\t// Convert subtree into a map (because having a Group Attribute within a slice doesn't render)\n\t\t\t\t\tanys = append(anys, buildGroupMap(buildAttrs(sliceV)))\n\t\t\t\tdefault:\n\t\t\t\t\tpanic(\"unexpected type in attribute map\")\n\t\t\t\t}\n\t\t\t}\n\t\t\tattrs = append(attrs, slog.Any(k, anys))\n\t\tdefault:\n\t\t\tpanic(\"unexpected type in attribute map\")\n\t\t}\n\t}\n\treturn attrs\n}\n\n// appended is a type that exists to allow us to differentiate between a log attribute that is a slice or any's ([]any),\n// versus when we are appending to the key so that it becomes a slice. Only used with the AppendHandler.\ntype appended []any\n\n// buildGroupMap takes a slice of attributes (the attributes within a group), and turns them into a map of string keys\n// to a non-attribute resolved value (any).\n// This function exists solely to deal with groups that are inside appended-slices (for the AppendHandler),\n// because slog does not have a \"slice\" kind, which means that those groups and their values do not render at all.\nfunc buildGroupMap(attrs []slog.Attr) map[string]any {\n\tgroup := map[string]any{}\n\tfor _, attr := range attrs {\n\t\tif attr.Value.Kind() != slog.KindGroup {\n\t\t\tgroup[attr.Key] = attr.Value.Any()\n\t\t} else {\n\t\t\tgroup[attr.Key] = buildGroupMap(attr.Value.Group())\n\t\t}\n\t}\n\treturn group\n}\n\n// groupOrAttrs holds either a group name or a list of slog.Attrs.\n// It also holds a reference/link to its parent groupOrAttrs, forming a linked list.\ntype groupOrAttrs struct {\n\tgroup string        // group name if non-empty\n\tattrs []slog.Attr   // attrs if non-empty\n\tnext  *groupOrAttrs // parent\n}\n\n// WithGroup returns a new groupOrAttrs that includes the given group, and links to the old groupOrAttrs.\n// Safe to call on a nil groupOrAttrs.\nfunc (g *groupOrAttrs) WithGroup(name string) *groupOrAttrs {\n\t// Empty-name groups are inlined as if they didn't exist\n\tif name == \"\" {\n\t\treturn g\n\t}\n\treturn \u0026groupOrAttrs{\n\t\tgroup: name,\n\t\tnext:  g,\n\t}\n}\n\n// WithAttrs returns a new groupOrAttrs that includes the given attrs, and links to the old groupOrAttrs.\n// Safe to call on a nil groupOrAttrs.\nfunc (g *groupOrAttrs) WithAttrs(attrs []slog.Attr) *groupOrAttrs {\n\tif len(attrs) == 0 {\n\t\treturn g\n\t}\n\treturn \u0026groupOrAttrs{\n\t\tattrs: attrs,\n\t\tnext:  g,\n\t}\n}\n\n// collectGroupOrAttrs unrolls all individual groupOrAttrs and collects them into a slice, ordered from oldest to newest\nfunc collectGroupOrAttrs(gs ...*groupOrAttrs) []*groupOrAttrs {\n\t// Get a total count of all groups in the group linked-list chain\n\tn := 0\n\tfor _, g := range gs {\n\t\tfor ga := g; ga != nil; ga = ga.next {\n\t\t\tn++\n\t\t}\n\t}\n\n\t// The groupOrAttrs on the handler is a linked list starting from the newest to the oldest set of attributes/groups.\n\t// Within each groupOrAttrs, all attributes are in a slice that is ordered from oldest to newest.\n\t// To make things consistent we will reverse the order of the groupOrAttrs, so that it goes from oldest to newest,\n\t// thereby matching the order of the attributes.\n\tres := make([]*groupOrAttrs, n)\n\tj := 0\n\tfor i := len(gs) - 1; i \u003e= 0; i-- {\n\t\tfor ga := gs[i]; ga != nil; ga = ga.next {\n\t\t\tres[len(res)-j-1] = ga\n\t\t\tj++\n\t\t}\n\t}\n\treturn res\n}\n\n// CaseSensitiveCmp is a case-sensitive comparison and ordering function that orders by byte values\nfunc CaseSensitiveCmp(a, b string) int {\n\tif a == b {\n\t\treturn 0\n\t}\n\tif a \u003e b {\n\t\treturn 1\n\t}\n\treturn -1\n}\n\n// IncrementIfBuiltinKeyConflict will, if there is a conflict/duplication at the root level (not in a group) with one of\n// the built-in keys, add \"#01\" to the end of the key\nfunc IncrementIfBuiltinKeyConflict(key string) (string, bool) {\n\tif DoesBuiltinKeyConflict(key) {\n\t\treturn IncrementKeyName(key, 1), true // Don't overwrite the built-in attribute keys\n\t}\n\treturn key, true\n}\n\n// DoesBuiltinKeyConflict returns true if the key conflicts with the builtin keys.\n// This will only be called on all root level (not in a group) attribute keys.\nfunc DoesBuiltinKeyConflict(key string) bool {\n\tif key == slog.TimeKey || key == slog.LevelKey || key == slog.MessageKey || key == slog.SourceKey {\n\t\treturn true\n\t}\n\treturn false\n}\n\n// IncrementKeyName adds a count onto the key name after the first seen.\n// Example: keyname, keyname#01, keyname#02, keyname#03\nfunc IncrementKeyName(key string, index int) string {\n\tif index == 0 {\n\t\treturn key\n\t}\n\treturn fmt.Sprintf(\"%s#%02d\", key, index)\n}\n\n// getKeyClosure returns a function to be used to resolve a key at the root level, determining its behavior when it\n// would otherwise conflict/duplicate the 4 built-in attribute keys (time, level, msg, source).\nfunc getKeyClosure(resolveBuiltinKeyConflict func(k string) (string, bool)) func(key string, depth int) (string, bool) {\n\treturn func(key string, depth int) (string, bool) {\n\t\tif depth == 0 {\n\t\t\treturn resolveBuiltinKeyConflict(key)\n\t\t}\n\t\treturn key, true\n\t}\n}\npackage logging\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"io\"\n\t\"log/slog\"\n\t\"os\"\n\t\"path/filepath\"\n\t\"strings\"\n\n\t\"github.com/domainr/mustang/internal/version\"\n)\n\n// Logger describes the set of features we want to expose from log/slog.\ntype Logger interface {\n\tEnabled(ctx context.Context, level slog.Level) bool\n\tLogAttrs(ctx context.Context, level slog.Level, msg string, attrs ...slog.Attr)\n\tWith(args ...any) *slog.Logger\n}\n\n// Level allows dynamically changing the log level via .Set() method.\nvar Level = new(slog.LevelVar)\n\n// NewLogger returns a logging.Logger configured for stderr.\nfunc NewLogger() Logger {\n\treturn NewLoggerWithOutput(os.Stderr)\n}\n\n// NewLoggerWithOutput returns a logging.Logger configured with a specific\n// output location.\nfunc NewLoggerWithOutput(w io.Writer) Logger {\n\topts, attrs := loggerDefaults()\n\treturn slog.New(slog.NewTextHandler(w, opts).WithAttrs(attrs))\n}\n\n// NewLoggerWithOutputLevel returns a logging.Logger configured with a specific\n// output location and Level.\nfunc NewLoggerWithOutputLevel(w io.Writer, l slog.Leveler) Logger {\n\topts, attrs := loggerDefaults()\n\topts.Level = l\n\treturn slog.New(slog.NewTextHandler(w, opts).WithAttrs(attrs))\n}\n\nfunc loggerDefaults() (*slog.HandlerOptions, []slog.Attr) {\n\tappName := strings.Replace(os.Getenv(\"HEROKU_APP_NAME\"), \"mustang\", \"heroku\", 1)\n\tif appName == \"\" {\n\t\tappName = os.Getenv(\"USER\")\n\t}\n\topts := \u0026slog.HandlerOptions{\n\t\tAddSource:   true,\n\t\tReplaceAttr: slogReplaceAttr,\n\t\tLevel:       Level,\n\t}\n\tattrs := []slog.Attr{\n\t\tslog.Group(\"mustang\",\n\t\t\tslog.String(\"name\", appName),\n\t\t\tslog.String(\"version\", version.Version()),\n\t\t),\n\t}\n\treturn opts, attrs\n}\n\n// NullLogger discards logs.\nfunc NullLogger() Logger {\n\t// NOTE: We pass a level not currently defined to reduce operational overhead.\n\t// The intent, unlike passing nil for the opts argument, is for the logger to\n\t// not even bother generating a message that will just be discarded.\n\t// An additional gap of 4 was used as it aligns with Go's original design.\n\t// https://github.com/golang/go/blob/1e95fc7/src/log/slog/level.go#L34-L42\n\treturn slog.New(slog.NewTextHandler(io.Discard, \u0026slog.HandlerOptions{Level: slog.LevelError + 4}))\n}\n\n// slogReplaceAttr adjusts the output format of some attributes:\n// - changes timestamps to UTC time zone\n// - shortens source.File by removing path\n// - elides error=\u003cnil\u003e\n// - formats dur values in microseconds as NNNµs\n// See https://pkg.go.dev/log/slog#HandlerOptions.ReplaceAttr\n// N.B: TextHandler manages quoting attribute values as necessary.\nfunc slogReplaceAttr(groups []string, a slog.Attr) slog.Attr {\n\t// Limit application of these rules only to top-level keys\n\tif len(groups) == 0 {\n\t\t// Set time zone to UTC\n\t\tif a.Key == slog.TimeKey {\n\t\t\ta.Value = slog.TimeValue(a.Value.Time().UTC())\n\t\t\treturn a\n\t\t}\n\t\t// Remove empty msg=\"\"\n\t\tif a.Equal(slog.String(slog.MessageKey, \"\")) {\n\t\t\treturn slog.Attr{}\n\t\t}\n\t\t// Remove error key=value when error is nil\n\t\tif a.Equal(slog.Any(\"error\", error(nil))) {\n\t\t\treturn slog.Attr{}\n\t\t}\n\t\t// Display a 'partial' path.\n\t\t// Avoids ambiguity when multiple files have the same name across packages.\n\t\t// e.g. billing.go appears under 'global', 'billing' and 'server' packages.\n\t\tif a.Key == slog.SourceKey {\n\t\t\tif source, ok := a.Value.Any().(*slog.Source); ok {\n\t\t\t\ta.Key = \"caller\"\n\t\t\t\tif _, after, ok := strings.Cut(source.File, \"mustang\"+string(filepath.Separator)); ok {\n\t\t\t\t\tsource.File = after\n\t\t\t\t}\n\t\t\t\treturn a\n\t\t\t}\n\t\t}\n\t}\n\n\t// Present durations and delays as xxxxµs\n\tswitch a.Key {\n\tcase \"dur\", \"delay\", \"p95\", \"previous_p95\", \"remaining\", \"max_wait\":\n\t\ta.Value = slog.StringValue(fmt.Sprintf(\"%dµs\", a.Value.Duration().Microseconds()))\n\t}\n\n\treturn a\n}\npackage logging\n\nimport (\n\t\"bytes\"\n\t\"context\"\n\t\"fmt\"\n\t\"log/slog\"\n\t\"path/filepath\"\n\t\"strings\"\n\t\"testing\"\n\t\"time\"\n)\n\nfunc TestLogger(t *testing.T) {\n\tbuf := new(bytes.Buffer)\n\tl := NewLoggerWithOutput(buf)\n\n\tt.Run(\"has expected fields\", func(t *testing.T) {\n\t\tdumpLogs(t, buf)\n\t\tl.LogAttrs(context.Background(), slog.LevelInfo, \"test message\")\n\t\tout := buf.String()\n\t\tfor _, field := range []string{\n\t\t\t\"time\",\n\t\t\t\"level\",\n\t\t\t\"caller\",\n\t\t\t\"mustang.name\",\n\t\t\t\"mustang.version\",\n\t\t} {\n\t\t\tif !strings.Contains(out, field+\"=\") {\n\t\t\t\tt.Errorf(\"missing field %q:\", field)\n\t\t\t}\n\t\t}\n\t})\n\n\tt.Run(\"adds non-default levels\", func(t *testing.T) {\n\t\tdumpLogs(t, buf)\n\t\tctx := context.Background()\n\t\ttests := []struct {\n\t\t\tlevel   slog.Level\n\t\t\tenabled bool\n\t\t\twant    string\n\t\t}{\n\t\t\t{slog.LevelDebug, false, \"\"},\n\t\t\t{slog.LevelInfo, true, \"level=INFO\"},\n\t\t\t{slog.LevelWarn, true, \"level=WARN\"},\n\t\t\t{slog.LevelError, true, \"level=ERROR\"},\n\t\t\t{slog.Level(12), true, \"level=ERROR+4\"},\n\t\t}\n\t\tfor _, tt := range tests {\n\t\t\tl.LogAttrs(ctx, tt.level, \"\")\n\t\t\t// WARNING: strings.Contains can return true on a \"\" substr.\n\t\t\t// For example: LevelInfo with \"\" would pass, which is misleading.\n\t\t\t// Because the test would suggest that `level=INFO` shouldn't appear in the output.\n\t\t\tif tt.enabled \u0026\u0026 !strings.Contains(buf.String(), tt.want) {\n\t\t\t\tt.Errorf(\"missing level=%s\", tt.level)\n\t\t\t}\n\t\t\tif got := l.Enabled(ctx, tt.level); tt.enabled != got {\n\t\t\t\tt.Errorf(\"enabled = %t at level=%s\", got, tt.level)\n\t\t\t}\n\t\t}\n\t})\n\n\tt.Run(\"adds debug at LevelDebug\", func(t *testing.T) {\n\t\tdumpLogs(t, buf)\n\t\tctx := context.Background()\n\t\tl = NewLoggerWithOutputLevel(buf, slog.LevelDebug)\n\t\tl.LogAttrs(ctx, slog.LevelDebug, \"\")\n\t\tout := buf.String()\n\t\tif !strings.Contains(out, \"level=DEBUG\") {\n\t\t\tt.Errorf(\"missing level=DEBUG\")\n\t\t}\n\t})\n\n\tt.Run(\"elides empty message\", func(t *testing.T) {\n\t\tdumpLogs(t, buf)\n\t\tl.LogAttrs(context.Background(), slog.LevelInfo, \"\")\n\t\tout := buf.String()\n\t\tif s := \"msg=\"; strings.Contains(out, s) {\n\t\t\tt.Errorf(\"log should not contain %q:\", s)\n\t\t}\n\t})\n\n\tt.Run(\"elides empty error\", func(t *testing.T) {\n\t\tdumpLogs(t, buf)\n\t\tl.LogAttrs(context.Background(), slog.LevelInfo, \"test message\", slog.Any(\"error\", nil))\n\t\tout := buf.String()\n\t\tif s := \"error=\"; strings.Contains(out, s) {\n\t\t\tt.Errorf(\"log should not contain %q:\", s)\n\t\t}\n\t})\n\n\tt.Run(\"uses UTC time zone\", func(t *testing.T) {\n\t\tdumpLogs(t, buf)\n\t\tl.LogAttrs(context.Background(), slog.LevelInfo, \"UTC\")\n\t\tout := buf.String()\n\t\tts := logFieldValue(out, \"time\")\n\t\tp, err := time.Parse(time.RFC3339, ts)\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"time field failed to parse: %s\", err)\n\t\t}\n\t\tif z, _ := p.Zone(); z != time.UTC.String() {\n\t\t\tt.Errorf(\"expected time in UTC zone, got %s\", z)\n\t\t}\n\t})\n\n\tt.Run(\"uses short source location\", func(t *testing.T) {\n\t\tdumpLogs(t, buf)\n\t\tl.LogAttrs(context.Background(), slog.LevelInfo, \"source loc\")\n\t\tout := buf.String()\n\t\tsource := logFieldValue(out, \"source\")\n\t\tif strings.HasPrefix(source, string(filepath.Separator)) {\n\t\t\tt.Errorf(\"source includes full path: %s\", source)\n\t\t}\n\t})\n\n\tt.Run(\"displays microseconds\", func(t *testing.T) {\n\t\tdumpLogs(t, buf)\n\t\tconst ts = 1234567890\n\t\tl.LogAttrs(context.Background(), slog.LevelInfo, \"\",\n\t\t\tslog.Duration(\"dur\", ts),\n\t\t\tslog.Duration(\"delay\", ts),\n\t\t\tslog.Duration(\"p95\", ts),\n\t\t\tslog.Duration(\"previous_p95\", ts),\n\t\t\tslog.Duration(\"remaining\", ts),\n\t\t\tslog.Duration(\"max_wait\", ts),\n\t\t)\n\t\tout := buf.String()\n\t\tfor _, field := range []string{\n\t\t\t\"dur\",\n\t\t\t\"delay\",\n\t\t\t\"p95\",\n\t\t\t\"previous_p95\",\n\t\t\t\"remaining\",\n\t\t\t\"max_wait\",\n\t\t} {\n\t\t\twant := fmt.Sprintf(\"%s=%d%s\", field, 1234567, \"µs\")\n\t\t\tif !strings.Contains(out, want) {\n\t\t\t\tt.Errorf(\"log should contain: %s\", want)\n\t\t\t}\n\t\t}\n\t})\n}\n\nfunc logFieldValue(s, field string) string {\n\tprefix := field + \"=\"\n\ti := strings.Index(s, prefix)\n\tif i == -1 {\n\t\treturn s\n\t}\n\ti += len(prefix)\n\treturn s[i : i+strings.Index(s[i:], \" \")]\n}\n\nfunc dumpLogs(t *testing.T, buf *bytes.Buffer) {\n\tt.Helper()\n\tt.Cleanup(func() {\n\t\tt.Helper()\n\t\tif t.Failed() || testing.Verbose() {\n\t\t\tt.Log(\"Logs:\\n\", buf.String())\n\t\t}\n\t\tbuf.Reset()\n\t})\n}\n// Reference:\n// https://betterstack.com/community/guides/logging/logging-in-go/\n//\n// Playground Example:\n// https://goplay.tools/snippet/Ty_22SjTQ1j\n\npackage main\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"fmt\"\n\t\"log/slog\"\n\t\"os\"\n\t\"path/filepath\"\n\t\"strings\"\n)\n\nfunc main() {\n\tlogLevelHandler := new(slog.LevelVar)\n\topts := \u0026slog.HandlerOptions{\n\t\tAddSource:   true,\n\t\tReplaceAttr: slogReplaceAttr,\n\t\tLevel:       logLevelHandler, // LevelVar allows for dynamic changing of the log level at runtime!\n\t}\n\tattrs := []slog.Attr{\n\t\tslog.String(\"my_field\", \"is_this\"),\n\t\tslog.Group(\"fastly\",\n\t\t\tslog.String(\"example\", os.Getenv(\"SOME_EXAMPLE\")),\n\t\t),\n\t}\n\tlogger := slog.New(slog.NewTextHandler(os.Stderr, opts).WithAttrs(attrs)) // alternatively use slog.NewJSONHandler()\n\tlogger.Debug(\"Debug message 1\")                                           // not displayed\n\tlogger.Info(\"Info message\")\n\tlogger.Warn(\"Warning message\")\n\tlogger.Error(\"Error message\")\n\tlogLevelHandler.Set(slog.LevelDebug) // dynamically switch the log level\n\tlogger.Debug(\"Debug message 2\")      // is displayed\n\n\t// MUCH MORE PEFORMANT!\n\tlogger.LogAttrs(context.Background(), slog.LevelInfo, \"xxxxxxxxxxxxxxxxxx\",\n\t\tslog.String(\"foo\", \"bar\"),\n\t)\n\n\tvar e error = ErrFoo{Code: 123, Err: errors.New(\"whoops\")}\n\tlogger.LogAttrs(context.Background(), slog.LevelError, \"\",\n\t\tslog.String(\"error\", e.Error()),\n\t)\n\tlogger.LogAttrs(context.Background(), slog.LevelError, \"\",\n\t\tslog.Any(\"error\", e),\n\t)\n\n\tnewLogger := logger.With(slog.Group(\"some_group\", slog.String(\"foo\", \"bar\")))\n\tnewLogger.Info(\"with group\")\n\n\tnewLoggerWithDuplicateGroup := newLogger.With(slog.Group(\"some_group\", slog.String(\"inside_duplicate_group\", \"whatever\"))) // the duplicated group isn't replaced, the attrs are appended to the original group\n\tnewLoggerWithDuplicateGroup.Info(\"with duplicate group\")\n\n\tnewLoggerWithDuplicateGroup.LogAttrs(context.Background(), slog.LevelInfo, \"does an inline group append to existing group on the logger?\",\n\t\tslog.Group(\"some_group\", slog.String(\"a_new_inline_group_key\", \"with some value\")), // the inlined group is appended to the original group\n\t)\n\n\tnewLoggerWithEmptyGroup := newLogger.With(slog.Group(\"some_empty_group\")) // Groups will be omitted if no attributes found\n\tnewLoggerWithEmptyGroup.Info(\"with empty group\")\n\n\tlogger.LogAttrs(context.Background(), slog.LevelError, \"inline group\",\n\t\tslog.Group(\"some_group\", slog.String(\"foo\", \"bar\")), // inline a slog.Group with other slog.Attr\n\t)\n\n\tlogger.LogAttrs(context.Background(), slog.LevelError, \"inline group will be omitted\",\n\t\tslog.Group(\"some_group\"),\n\t)\n\n\tloggerWithDuplicateField := logger.With(slog.String(\"my_field\", \"is_now_overridden\")) // NOPE! It's duplicated! so you'll have to fix that in slogReplaceAttr\n\tloggerWithDuplicateField.Info(\"my message to see if my_field is overridden\")\n\n\tattribute := slog.Any(\"some_array\", []string{\"x\", \"y\", \"z\"})\n\tlogger.Info(\"what does a slice look like\", attribute)\n\n\tthing := Foo\n\tlogger.LogAttrs(context.Background(), slog.LevelError, \"what does a custom iota type look like\",\n\t\tslog.Any(\"my_thing\", thing),\n\t)\n\n\tst := StructThing{\"foo here\", 123, true}\n\tslog.LogAttrs(context.Background(), slog.LevelInfo, \"message text\", slog.Any(\"\", st))      // no field == foo=\"foo here\" bar=123 baz=true\n\tslog.LogAttrs(context.Background(), slog.LevelInfo, \"message text\", slog.Any(\"agent\", st)) // field specified == agent.foo=\"foo here\" agent.bar=123 agent.baz=true\n}\n\ntype StructThing struct {\n\tFoo string\n\tBar int\n\tBaz bool\n}\n\nfunc (st StructThing) LogValue() slog.Value {\n\treturn slog.GroupValue(\n\t\tslog.String(\"foo\", st.Foo),\n\t\tslog.Int(\"bar\", st.Bar),\n\t\tslog.Bool(\"baz\", st.Baz),\n\t)\n}\n\ntype Thing uint32\n\nconst (\n\tUnknown Thing = iota\n\tFoo     Thing = 1 \u003c\u003c (iota - 1)\n\tBar\n\tBaz\n)\n\n// slogReplaceAttr adjusts the output format of some attributes:\n// - changes timestamps to UTC time zone\n// - shortens source.File by removing path\n// - elides error=\u003cnil\u003e\n// - formats dur values in microseconds as NNNµs\n// See https://pkg.go.dev/log/slog#HandlerOptions.ReplaceAttr\n// N.B: TextHandler manages quoting attribute values as necessary.\nfunc slogReplaceAttr(groups []string, a slog.Attr) slog.Attr {\n\t// Limit application of these rules only to top-level keys\n\tif len(groups) == 0 {\n\t\t// Set time zone to UTC\n\t\tif a.Key == slog.TimeKey {\n\t\t\ta.Value = slog.TimeValue(a.Value.Time().UTC())\n\t\t\treturn a\n\t\t}\n\t\t// Remove empty msg=\"\"\n\t\tif a.Equal(slog.String(slog.MessageKey, \"\")) {\n\t\t\treturn slog.Attr{}\n\t\t}\n\t\t// Remove error key=value when error is nil\n\t\tif a.Equal(slog.Any(\"error\", error(nil))) {\n\t\t\treturn slog.Attr{}\n\t\t}\n\t\t// Display a 'partial' path.\n\t\t// This avoids ambiguity when you have multiple files called 'example.go' across different packages.\n\t\t//\n\t\t// NOTE: It's implemented based on my own application \"mustang\" (hence that reference in the path lookup)\n\t\t/*\n\t\t\tif a.Key == slog.SourceKey {\n\t\t\t\tsource, _ := a.Value.Any().(*slog.Source)\n\t\t\t\tsegs := strings.Split(source.File, string(filepath.Separator))\n\t\t\t\tidx := slices.Index(segs, \"mustang\")\n\t\t\t\tpath := strings.Join(segs[idx+1:], string(filepath.Separator))\n\t\t\t\tsource.File = path\n\t\t\t\treturn a\n\t\t\t}\n\t\t*/\n\t\t// Rewritten + change the key from `source` to `caller`.\n\t\tif a.Key == slog.SourceKey {\n\t\t\tif source, ok := a.Value.Any().(*slog.Source); ok {\n\t\t\t\ta.Key = \"caller\"\n\t\t\t\tif _, after, ok := strings.Cut(source.File, \"mustang\"+string(filepath.Separator)); ok {\n\t\t\t\t\tsource.File = after\n\t\t\t\t}\n\t\t\t\treturn a\n\t\t\t}\n\t\t}\n\t}\n\n\t// Present durations and delays as xxxxµs\n\tswitch a.Key {\n\tcase \"dur\", \"delay\", \"p95\", \"previous_p95\", \"remaining\", \"max_wait\":\n\t\ta.Value = slog.StringValue(fmt.Sprintf(\"%dµs\", a.Value.Duration().Microseconds()))\n\t}\n\n\treturn a\n}\n\ntype ErrFoo struct {\n\tCode int // let's pretend we don't want this printed by normal Error() message\n\tErr  error\n}\n\nfunc (ef ErrFoo) Error() string {\n\treturn fmt.Sprintf(\"%d: %s\", ef.Code, ef.Err)\n}\n\n// This method allows us to tell slog to ignore the Code field and just print the Err as a string.\n// https://betterstack.com/community/guides/logging/logging-in-go/#hiding-sensitive-fields-with-the-logvaluer-interface\nfunc (ef ErrFoo) LogValue() slog.Value {\n\treturn slog.StringValue(ef.Err.Error())\n}\n// There are issues with LogAttrs when it wraps slog.Logger's LogAttrs. \n// So we must implement wrapping as described in \n// https://pkg.go.dev/log/slog#hdr-Wrapping_output_methods \n// Which helps to preserve the correct source location.\n\n// Package logging wraps the features we want to expose from log/slog and\n// provides standard constructors for loggers.\npackage logging\n\nimport (\n\t\"context\"\n\t\"io\"\n\t\"log\"\n\t\"log/slog\"\n\t\"os\"\n\t\"path/filepath\"\n\t\"runtime\"\n\t\"strconv\"\n\t\"strings\"\n\t\"time\"\n\n\t\"github.com/domainr/mustang/internal/version\"\n)\n\n// Level allows dynamically changing the output level via .Set() method.\n// Defaults to [slog.LevelInfo].\nvar Level = new(slog.LevelVar)\n\n// Logger describes the set of features we want to expose from log/slog.\n//\n// NOTE: Don't confuse our custom With() signature with (*slog.Logger).With\n// We return a Logger type where the standard library returns a *slog.Logger\ntype Logger interface {\n\tEnabled(ctx context.Context, level slog.Level) bool\n\tLogAttrs(ctx context.Context, level slog.Level, msg string, attrs ...slog.Attr)\n\tWith(args ...any) Logger\n\t_private(private) // prevents any other package from implementing this interface\n}\n\n// NewLogger returns a logging.Logger configured for stderr.\nfunc NewLogger() Logger {\n\treturn NewLoggerWithOutputLevel(os.Stderr, Level)\n}\n\n// NewLoggerWithOutputLevel returns a [Logger] configured with an output writer and Level.\nfunc NewLoggerWithOutputLevel(w io.Writer, l slog.Leveler) Logger {\n\topts := defaultOptions()\n\topts.Level = l\n\treturn (*logger)(slog.New(slog.NewTextHandler(w, opts).WithAttrs(defaultAttrs())))\n}\n\n// NewBareLoggerWithOutputLevel returns a [Logger] configured with an output location and [slog.Leveler].\n// It does not include any additional attributes.\nfunc NewBareLoggerWithOutputLevel(w io.Writer, l slog.Leveler) Logger {\n\topts := defaultOptions()\n\topts.Level = l\n\treturn (*logger)(slog.New(slog.NewTextHandler(w, opts)))\n}\n\ntype private struct{}\n\n// IMPORTANT: logger is an alias to slog.Logger to avoid a double-pointer deference.\n// All methods off the type will need to type-cast a *logger to *slog.Logger.\n// With() must additionally type-cast back to a Logger compatible type.\ntype logger slog.Logger\n\nfunc (*logger) _private(private) {}\n\nfunc (l *logger) Enabled(ctx context.Context, level slog.Level) bool {\n\treturn (*slog.Logger)(l).Enabled(ctx, level)\n}\n\n// LogAttrs effectively wraps slog.Logger's LogAttrs, so we must implement wrapping as described\n// in https://pkg.go.dev/log/slog#hdr-Wrapping_output_methods to preserve the correct source location.\nfunc (l *logger) LogAttrs(ctx context.Context, level slog.Level, msg string, attrs ...slog.Attr) {\n\tif !l.Enabled(context.Background(), level) {\n\t\treturn\n\t}\n\tvar pcs [1]uintptr\n\truntime.Callers(2, pcs[:]) // skip 2 [Callers, LogAttrs]\n\tr := slog.NewRecord(time.Now(), level, msg, pcs[0])\n\tr.AddAttrs(attrs...)\n\t(*slog.Logger)(l).Handler().Handle(ctx, r)\n}\n\nfunc (l *logger) With(args ...any) Logger {\n\treturn (*logger)((*slog.Logger)(l).With(args...))\n}\n\n// Adapt returns a [log.Logger] for use with packages that are not yet compatible with\n// [log/slog].\nfunc Adapt(l Logger, level slog.Level) *log.Logger {\n\t// _private() ensures this type assertion cannot panic.\n\tslogger := (*slog.Logger)(l.(*logger)) //nolint:revive,forcetypeassert\n\treturn slog.NewLogLogger(slogger.Handler(), level)\n}\n\nfunc defaultOptions() *slog.HandlerOptions {\n\treturn \u0026slog.HandlerOptions{\n\t\tAddSource:   true,\n\t\tReplaceAttr: slogReplaceAttr,\n\t\tLevel:       Level,\n\t}\n}\n\nfunc defaultAttrs() []slog.Attr {\n\tappName := strings.Replace(os.Getenv(\"HEROKU_APP_NAME\"), \"mustang\", \"heroku\", 1)\n\tif appName == \"\" {\n\t\tappName = os.Getenv(\"USER\")\n\t}\n\treturn []slog.Attr{slog.Group(\"mustang\",\n\t\tslog.String(\"name\", appName),\n\t\tslog.String(\"version\", version.Version()),\n\t)}\n}\n\n// NullLogger discards logs.\nfunc NullLogger() Logger {\n\t// NOTE: We pass a level not currently defined to reduce operational overhead.\n\t// The intent, unlike passing nil for the opts argument, is for the logger to\n\t// not even bother generating a message that will just be discarded.\n\t// An additional gap of 4 was used as it aligns with Go's original design.\n\t// https://github.com/golang/go/blob/1e95fc7/src/log/slog/level.go#L34-L42\n\treturn (*logger)(slog.New(slog.NewTextHandler(io.Discard, \u0026slog.HandlerOptions{Level: slog.LevelError + 4}))) //nolint:gomnd\n}\n\n// slogReplaceAttr adjusts the log output.\n//\n// - Restricts these changes to top-level keys (not keys within groups)\n//   - Changes default time field value to UTC time zone\n//   - Replaces msg key with event\n//   - Omits event field if empty\n//   - Omits error field if when nil\n//   - Truncates source's filename to mustang directory\n//\n// - Formats duration and delay values in microseconds as xxxxµs\n//\n// See https://pkg.go.dev/log/slog#HandlerOptions.ReplaceAttr\n// N.B: TextHandler manages quoting attribute values as necessary.\nfunc slogReplaceAttr(groups []string, a slog.Attr) slog.Attr {\n\t// Limit application of these rules only to top-level keys\n\tif len(groups) == 0 {\n\t\t// Set time zone to UTC\n\t\tif a.Key == slog.TimeKey {\n\t\t\ta.Value = slog.TimeValue(a.Value.Time().UTC())\n\t\t\treturn a\n\t\t}\n\t\t// Use event as the default MessageKey, remove if empty\n\t\tif a.Key == slog.MessageKey {\n\t\t\ta.Key = \"event\"\n\t\t\tif a.Value.String() == \"\" {\n\t\t\t\treturn slog.Attr{}\n\t\t\t}\n\t\t\treturn a\n\t\t}\n\t\t// Display a 'partial' path.\n\t\t// Avoids ambiguity when multiple files have the same name across packages.\n\t\t// e.g. billing.go appears under 'global', 'billing' and 'server' packages.\n\t\tif a.Key == slog.SourceKey {\n\t\t\tif source, ok := a.Value.Any().(*slog.Source); ok {\n\t\t\t\ta.Key = \"caller\"\n\t\t\t\tif _, after, ok := strings.Cut(source.File, \"mustang\"+string(filepath.Separator)); ok {\n\t\t\t\t\tsource.File = after\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn a\n\t\t}\n\t}\n\n\t// Remove error key=value when error is nil\n\tif a.Equal(slog.Any(\"error\", error(nil))) {\n\t\treturn slog.Attr{}\n\t}\n\n\t// Present durations and delays as xxxxµs\n\tswitch a.Key {\n\tcase \"dur\", \"delay\", \"p95\", \"previous_p95\", \"remaining\", \"max_wait\":\n\t\ta.Value = slog.StringValue(strconv.FormatInt(a.Value.Duration().Microseconds(), 10) + \"µs\")\n\t}\n\n\treturn a\n}\nSimple TEXT implementation:\n\n```go\nvar logger = slog.New(slog.NewTextHandler(os.Stdout, \u0026slog.HandlerOptions{\n\tAddSource: true,\n\tReplaceAttr: func(g []string, a slog.Attr) slog.Attr {\n\t\t// Ensure time is always logged in UTC.\n\t\tif len(g) == 0 \u0026\u0026 a.Key == slog.TimeKey {\n\t\t\ta.Value = slog.TimeValue(a.Value.Time().UTC())\n\t\t}\n\t\t// Remove the directory from the source's filename.\n\t\tif a.Key == slog.SourceKey {\n\t\t\tsource := a.Value.Any().(*slog.Source)\n\t\t\tsource.File = filepath.Base(source.File)\n\t\t}\n\t\treturn a\n\t},\n}))\n```\n\nSimple JSON implementation that shows how to switch log level at runtime:\n\n```go\npackage main\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"log/slog\"\n\t\"os\"\n)\n\nvar Level = new(slog.LevelVar)\n\nfunc main() {\n\tlogger := slog.New(slog.NewJSONHandler(os.Stdout, \u0026slog.HandlerOptions{Level: Level}))\n\n\tctx := context.Background()\n\n\tlogger.LogAttrs(ctx, slog.LevelInfo, \"info_one\")   // printed\n\tlogger.LogAttrs(ctx, slog.LevelDebug, \"debug_one\") // not printed\n\tlogger.Debug(\"debug_two\", \"foo\", \"bar\")            // not printed\n\n\tfmt.Println(\"---\")\n\tLevel.Set(slog.LevelDebug)\n\t\n\tlogger.LogAttrs(ctx, slog.LevelInfo, \"info_one\")                     // printed\n\tlogger.LogAttrs(ctx, slog.LevelDebug, \"debug_one\")                   // printed\n\tlogger.Debug(\"debug_two\", \"foo\", \"bar\", slog.Bool(\"whatever\", true)) // printed\n}\n```\nhttps://play.golang.com/p/yvbOC1lXRGI\n\nHere is an example that demonstrates how groups work and how they can be nested:\n\n```go\npackage main\n\nimport (\n\t\"context\"\n\t\"log/slog\"\n\t\"os\"\n)\n\nfunc main() {\n\tlogger := slog.New(slog.NewJSONHandler(os.Stdout, \u0026slog.HandlerOptions{Level: slog.LevelInfo}))\n\n\tctx := context.Background()\n\tlogger.LogAttrs(ctx, slog.LevelInfo, \"one\", slog.String(\"foo\", \"bar\"))\n\t// {\"time\":\"2009-11-10T23:00:00Z\",\"level\":\"INFO\",\"msg\":\"one\",\"foo\":\"bar\"}\n\n\tlogger = logger.WithGroup(\"mirror\")\n\tlogger.LogAttrs(ctx, slog.LevelInfo, \"two\", slog.String(\"beep\", \"boop\"))\n\t// {\"time\":\"2009-11-10T23:00:00Z\",\"level\":\"INFO\",\"msg\":\"two\",\"mirror\":{\"beep\":\"boop\"}}\n\n\tattrs := []any{\n\t\tslog.String(\"method\", \"GET\"),\n\t}\n\tlogger = logger.With(slog.Group(\"origin_req\", attrs...))\n\tlogger.LogAttrs(ctx, slog.LevelInfo, \"two\", slog.String(\"whatever\", \"wherever\"))\n\t// {\"time\":\"2009-11-10T23:00:00Z\",\"level\":\"INFO\",\"msg\":\"two\",\"mirror\":{\"origin_req\":{\"method\":\"GET\"},\"whatever\":\"wherever\"}}\n}\n```\nhttps://play.golang.com/p/F3lBGUhfVkM\n\n\u003e [!IMPORTANT]\n\u003e Notice `logger.WithGroup(\"mirror\")` is left \"open\".\\\n\u003e There are no attributes pass like with `logger.With(slog.Group(\"origin_req\", attrs...))`.\\\n\u003e This means `slog.String(\"beep\", \"boop\")` is logged _within_ the `\"mirror\"` group.\n\nThis is a working example as used by Domainr\\\nhttps://go.dev/play/p/TH_HdwDaUiN\n\nHere is a text version that's slightly different in setup (more flexible as it doesn't constrain via an interface): \nhttps://go.dev/play/p/1TPwtbQB_Oy\n\n```go\npackage main\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"log/slog\"\n\t\"os\"\n\n\t\"play.ground/logging\"\n)\n\nfunc main() {\n\tctx := context.Background()\n\tlogger := logging.NewLogger()\n\n\tlogger.LogAttrs(ctx, slog.LevelDebug, \"some_event\", slog.String(\"foo\", \"bar\"))\n\tlogger.LogAttrs(ctx, slog.LevelInfo, \"some_event\", slog.String(\"foo\", \"bar\"))\n\tlogger.LogAttrs(ctx, slog.LevelWarn, \"some_event\", slog.String(\"foo\", \"bar\"))\n\tlogger.LogAttrs(ctx, slog.LevelError, \"some_event\", slog.String(\"foo\", \"bar\"))\n\n\tfmt.Println(\"NOTICE NO DEBUG LOG ABOVE, BUT THERE IS BELOW (AFTER CHANGING LOG LEVEL)\")\n\n\tlogging.Level.Set(slog.LevelDebug)\n\tlogger.LogAttrs(ctx, slog.LevelDebug, \"some_event\", slog.String(\"foo\", \"bar\"))\n\n\tlogger = logging.NewLoggerWithOutputLevel(os.Stdout, logging.Level)\n\n\tlogger.LogAttrs(ctx, slog.LevelDebug, \"some_event\", slog.String(\"foo\", \"bar\"))\n\tlogger.LogAttrs(ctx, slog.LevelInfo, \"some_event\", slog.String(\"foo\", \"bar\"))\n\tlogger.LogAttrs(ctx, slog.LevelWarn, \"some_event\", slog.String(\"foo\", \"bar\"))\n\tlogger.LogAttrs(ctx, slog.LevelError, \"some_event\", slog.String(\"foo\", \"bar\"))\n}\n-- go.mod --\nmodule play.ground\n-- logging/logging.go --\npackage logging\n\nimport (\n\t\"context\"\n\t\"io\"\n\t\"log\"\n\t\"log/slog\"\n\t\"os\"\n\t\"path/filepath\"\n\t\"strconv\"\n\t\"strings\"\n)\n\n// Level allows dynamically changing the output level via .Set() method.\n// Defaults to [slog.LevelInfo].\nvar Level = new(slog.LevelVar)\n\n// Logger describes the set of features we want to expose from log/slog.\n//\n// NOTE: Don't confuse our custom With() signature with (*slog.Logger).With\n// We return a Logger type where the standard library returns a *slog.Logger\ntype Logger interface {\n\tEnabled(ctx context.Context, level slog.Level) bool\n\tLogAttrs(ctx context.Context, level slog.Level, msg string, attrs ...slog.Attr)\n\tWith(args ...any) Logger\n\t_private()\n}\n\n// NewLogger returns a logging.Logger configured for stderr.\nfunc NewLogger() Logger {\n\treturn NewLoggerWithOutputLevel(os.Stdout, Level)\n}\n\n// NewLoggerWithOutput returns a [Logger] configured with an output writer.\nfunc NewLoggerWithOutput(w io.Writer) Logger {\n\treturn (*logger)(slog.New(slog.NewJSONHandler(w, defaultOptions()).WithAttrs(defaultAttrs())))\n}\n\n// NewLoggerWithOutputLevel returns a [Logger] configured with an output writer and Level.\nfunc NewLoggerWithOutputLevel(w io.Writer, l slog.Leveler) Logger {\n\topts := defaultOptions()\n\topts.Level = l\n\treturn (*logger)(slog.New(slog.NewJSONHandler(w, opts).WithAttrs(defaultAttrs())))\n}\n\n// NewBareLoggerWithOutputLevel returns a [Logger] configured with an output location and [slog.Leveler].\n// It does not include any additional attributes.\nfunc NewBareLoggerWithOutputLevel(w io.Writer, l slog.Leveler) Logger {\n\topts := defaultOptions()\n\topts.Level = l\n\treturn (*logger)(slog.New(slog.NewJSONHandler(w, opts)))\n}\n\n// nolint:revive\n//\n//lint:ignore U1000 Prevents any other package from implementing this interface\ntype private struct{} //nolint:unused\n\n// IMPORTANT: logger is an alias to slog.Logger to avoid a double-pointer deference.\n// All methods off the type will need to type-cast a *logger to *slog.Logger.\n// With() must additionally type-cast back to a Logger compatible type.\ntype logger slog.Logger\n\nfunc (*logger) _private() {}\n\nfunc (l *logger) Enabled(ctx context.Context, level slog.Level) bool {\n\treturn (*slog.Logger)(l).Enabled(ctx, level)\n}\n\nfunc (l *logger) LogAttrs(ctx context.Context, level slog.Level, msg string, attrs ...slog.Attr) {\n\t(*slog.Logger)(l).LogAttrs(ctx, level, msg, attrs...)\n}\n\nfunc (l *logger) With(args ...any) Logger {\n\treturn (*logger)((*slog.Logger)(l).With(args...))\n}\n\n// Adapt returns a [log.Logger] for use with packages that are not yet compatible with\n// [log/slog].\nfunc Adapt(l Logger, level slog.Level) *log.Logger {\n\t// _private() ensures this type assertion cannot panic.\n\tslogger := (*slog.Logger)(l.(*logger)) //nolint:revive,forcetypeassert\n\treturn slog.NewLogLogger(slogger.Handler(), level)\n}\n\nfunc defaultOptions() *slog.HandlerOptions {\n\treturn \u0026slog.HandlerOptions{\n\t\tAddSource:   true,\n\t\tReplaceAttr: slogReplaceAttr,\n\t\tLevel:       Level,\n\t}\n}\n\nfunc defaultAttrs() []slog.Attr {\n\treturn []slog.Attr{slog.Group(\"app\",\n\t\tslog.String(\"name\", \"my app name\"),\n\t\tslog.String(\"version\", \"my app version\"),\n\t)}\n}\n\n// NullLogger discards logs.\nfunc NullLogger() Logger {\n\t// NOTE: We pass a level not currently defined to reduce operational overhead.\n\t// The intent, unlike passing nil for the opts argument, is for the logger to\n\t// not even bother generating a message that will just be discarded.\n\t// An additional gap of 4 was used as it aligns with Go's original design.\n\t// https://github.com/golang/go/blob/1e95fc7/src/log/slog/level.go#L34-L42\n\treturn (*logger)(slog.New(slog.NewTextHandler(io.Discard, \u0026slog.HandlerOptions{Level: slog.LevelError + 4}))) //nolint:gomnd\n}\n\n// slogReplaceAttr adjusts the log output.\n//\n// - Restricts these changes to top-level keys (not keys within groups)\n//   - Changes default time field value to UTC time zone\n//   - Replaces msg key with event\n//   - Omits event field if empty\n//   - Omits error field if when nil\n//   - Truncates source's filename to domainr-api directory\n//\n// - Formats duration and delay values in microseconds as xxxxµs\n//\n// See https://pkg.go.dev/log/slog#HandlerOptions.ReplaceAttr\n// N.B: TextHandler manages quoting attribute values as necessary.\nfunc slogReplaceAttr(groups []string, a slog.Attr) slog.Attr {\n\t// Limit application of these rules only to top-level keys\n\tif len(groups) == 0 {\n\t\t// Set time zone to UTC\n\t\tif a.Key == slog.TimeKey {\n\t\t\ta.Value = slog.TimeValue(a.Value.Time().UTC())\n\t\t\treturn a\n\t\t}\n\t\t// Use event as the default MessageKey, remove if empty\n\t\tif a.Key == slog.MessageKey {\n\t\t\ta.Key = \"event\"\n\t\t\tif a.Value.String() == \"\" {\n\t\t\t\treturn slog.Attr{}\n\t\t\t}\n\t\t\treturn a\n\t\t}\n\t\t// Display a 'partial' path.\n\t\t// Avoids ambiguity when multiple files have the same name across packages.\n\t\t// e.g. billing.go appears under 'global', 'billing' and 'server' packages.\n\t\tif a.Key == slog.SourceKey {\n\t\t\tif source, ok := a.Value.Any().(*slog.Source); ok {\n\t\t\t\ta.Key = \"caller\"\n\t\t\t\tif _, after, ok := strings.Cut(source.File, \"domainr-api\"+string(filepath.Separator)); ok {\n\t\t\t\t\tsource.File = after\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn a\n\t\t}\n\t}\n\n\t// Remove error key=value when error is nil\n\tif a.Equal(slog.Any(\"error\", error(nil))) {\n\t\treturn slog.Attr{}\n\t}\n\n\t// Present durations and delays as xxxxµs\n\tswitch a.Key {\n\tcase \"dur\", \"delay\", \"p95\", \"previous_p95\", \"remaining\", \"max_wait\":\n\t\ta.Value = slog.StringValue(strconv.FormatInt(a.Value.Duration().Microseconds(), 10) + \"µs\")\n\t}\n\n\treturn a\n}\n```\n","tags":"#go #logs"},{"id":"235f8156a9f20533fbc4ecd36bcc4724","title":"Go: stream new-line delimited JSON to Server ","content":"The `application/x-ndjson` MIME type refers to a type of data format called Newline delimited JSON (NDJSON). NDJSON is a way of storing structured data as a sequence of JSON (JavaScript Object Notation) objects, separated by newline characters. \n\nEach line of an NDJSON file contains a complete JSON object, which means that a single NDJSON file can contain multiple JSON objects. This format is commonly used for streaming large datasets, as it allows data to be processed in a continuous and efficient manner.\n\nThe `application/x-ndjson` MIME type is used to indicate that a file or data stream contains NDJSON formatted data. The `x` in the MIME type indicates that it is an unregistered type, which means that it is not an official MIME type defined by the Internet Assigned Numbers Authority (IANA). However, it is widely used and supported by many applications and APIs that deal with structured data.\n\nHere's an example of how you could use Go to send an NDJSON-formatted payload to an API:\n\n```go\npackage main\n\nimport (\n\t\"bytes\"\n\t\"encoding/json\"\n\t\"fmt\"\n\t\"net/http\"\n)\n\nfunc main() {\n\t// Define some example JSON objects\n\tobj1 := map[string]string{\"name\": \"Alice\", \"age\": \"30\"}\n\tobj2 := map[string]string{\"name\": \"Bob\", \"age\": \"40\"}\n\n\t// Create a buffer to hold the NDJSON payload\n\tvar payload bytes.Buffer\n\n\t// Encode each object as a JSON string and write it to the payload buffer with a newline separator\n\tenc := json.NewEncoder(\u0026payload)\n\tenc.Encode(obj1)\n\tpayload.WriteByte('\\n')\n\tenc.Encode(obj2)\n\tpayload.WriteByte('\\n')\n\n\t// Create a new HTTP request to the API endpoint\n\treq, err := http.NewRequest(\"POST\", \"http://example.com/api\", \u0026payload)\n\tif err != nil {\n\t\tfmt.Println(\"Error creating request:\", err)\n\t\treturn\n\t}\n\n\t// Set the Content-Type header to indicate that we're sending NDJSON data\n\treq.Header.Set(\"Content-Type\", \"application/x-ndjson\")\n\n\t// Send the request and print the response\n\tclient := \u0026http.Client{}\n\tresp, err := client.Do(req)\n\tif err != nil {\n\t\tfmt.Println(\"Error sending request:\", err)\n\t\treturn\n\t}\n\tdefer resp.Body.Close()\n\n\tfmt.Println(\"Response status:\", resp.Status)\n}\n```\n\nIn this example, we define two JSON objects (`obj1` and `obj2`) and encode them as strings using the `json` package. We then write each encoded object to a buffer, with a newline character separating them. This creates an NDJSON-formatted payload.\n\nWe then create a new HTTP request to an API endpoint and set the request body to our NDJSON payload. We also set the `Content-Type` header to indicate that we're sending NDJSON data.\n\nFinally, we send the request using an `http.Client` and print the response status. Note that this example is simplified and doesn't include error handling for the sake of brevity. In a real-world application, you would want to handle errors appropriately.\n\n./stream.sh 100000 | go run client.go\n#!/bin/bash\n\ngenerate_json_object() {\n  echo \"{\\\"key\\\":\\\"$(openssl rand -hex 16)-$RANDOM-$(date +%s)\\\",\\\"value\\\":\\\"$(echo object_$RANDOM | base64)\\\"}\"\n}\n\nfor _ in $(seq 1 \"$1\"); do\n  generate_json_object\ndone\npackage main\n\nimport (\n\t\"log\"\n\t\"net/http\"\n\t\"os\"\n)\n\nfunc main() {\n\treq, err := http.NewRequest(\"POST\", \"http://localhost:8080/stream\", os.Stdin)\n\tif err != nil {\n\t\tlog.Println(\"Failed to create HTTP request:\", err)\n\t}\n\treq.Header.Set(\"Content-Type\", \"application/json\")\n\n\tclient := \u0026http.Client{}\n\tresp, err := client.Do(req)\n\tif err != nil {\n\t\tlog.Println(\"Failed to send HTTP request:\", err)\n\t}\n\tdefer resp.Body.Close()\n\n\tlog.Println(\"Response:\", resp.Status)\n}\npackage main\n\nimport (\n\t\"bufio\"\n\t\"encoding/json\"\n\t\"io\"\n\t\"log\"\n\t\"net/http\"\n\t\"os\"\n)\n\ntype MyServerObject struct {\n\tID   int    `json:\"id\"`\n\tName string `json:\"name\"`\n}\n\nfunc handleJSONStream(w http.ResponseWriter, r *http.Request) {\n\treader := bufio.NewReader(io.TeeReader(r.Body, os.Stdout))\n\tdefer r.Body.Close()\n\n\tdecoder := json.NewDecoder(reader)\n\n\tfor {\n\t\tvar obj MyServerObject\n\t\terr := decoder.Decode(\u0026obj)\n\t\tif err != nil {\n\t\t\tif err.Error() == \"EOF\" {\n\t\t\t\tbreak\n\t\t\t}\n\t\t\thttp.Error(w, \"Failed to decode JSON object\", http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\n\t\tlog.Printf(\"Received object: %+v\", obj)\n\t}\n\n\tw.WriteHeader(http.StatusOK)\n\tw.Write([]byte(\"Data processed successfully\"))\n}\n\nfunc main() {\n\thttp.HandleFunc(\"/stream\", handleJSONStream)\n\tlog.Fatal(http.ListenAndServe(\":8080\", nil))\n}\n","tags":"#go #api #stream #json #ndjson"},{"id":"d8566501ff70f0f09f7262e440c02868","title":"API: Versioning Strategies ","content":"## Terraform Analysis\n\nTerraform uses SDKs for interacting with provider APIs. There isn’t a distinction to be made for Terraform. You just bump the SDK version and it’s down to the individual provider APIs  ‘under the covers’ to handle versioning. So in that case I looked at the top providers listed on [https://registry.terraform.io/browse/providers](https://registry.terraform.io/browse/providers) which are AWS, Azure and Google Cloud Platform.\n\n## AWS\n\nAWS versions its APIs using a versioning system based on the format “YYYY-MM-DD”. The YYYY-MM-DD format is based on the date of the API release. Each API has its own version number, which is incremented with each new release. \n\nFor example, an API released on January 1st, 2020, would have a version number of “2020-01-01”. \n\nIn the SDK you pass in the API version you want, for example…\n\n```\nvar dynamodb = new AWS.DynamoDB({apiVersion: '2011-12-05'});\n```\n\n### Reference\n\n[https://docs.aws.amazon.com/sdk-for-javascript/v2/developer-guide/locking-api-versions.html](https://docs.aws.amazon.com/sdk-for-javascript/v2/developer-guide/locking-api-versions.html)\n\n## Azure\n\nTo quote Microsoft…\n\n\u003e To specify which version of an operation to use, set the api-version query parameter. The version is of the format Group.Major.Minor where Group is in the format ‘YYYY-MM-DD’ and Major is an integer and Minor is an integer.\n\nFor example…\n\n```\n?api-version=2020-09-01.12.0\n```\n\n### Reference:\n\n[https://learn.microsoft.com/en-us/rest/api/batchservice/batch-service-rest-api-versioning](https://learn.microsoft.com/en-us/rest/api/batchservice/batch-service-rest-api-versioning)\n\n## Google Cloud Platform\n\nGoogle uses a path based versioning system. The beginning of the path contains the version and it’s only a major version. The Google documentation states…\n\n\u003e Google APIs must not expose minor or patch version numbers. For example, Google APIs use v1, not v1.0, v1.1, or v1.4.2. From a user's perspective, major versions are updated in place, and users receive new functionality without migration.\n\n### Reference\n\n[https://cloud.google.com/apis/design/versioning](https://cloud.google.com/apis/design/versioning)\n","tags":"#api #versioning"},{"id":"d7def72bd3c20e0e076b90b2e90233b7","title":"Go: Docker Go Image with mounted files ","content":"Start with a Dockerfile:\n\n```Dockerfile\nFROM golang:latest\n\nRUN apt-get update -y \u0026\u0026 apt-get install git -y\n\nCMD [\"/bin/bash\"]\n```\n\nBuild the Dockerfile into an image:\n\n```shell\ndocker build -t go-and-git .\n```\n\nRun the Docker image as a container:\n\n```shell\ndocker run -it -v /Users/integralist/Code/fastly/cli/dist/linux_linux_arm64/fastly:/go/fastly go-and-git\n```\n\n\u003e **NOTE:** The default working directory is `/go` as setup by the Go base image.\n","tags":"#docker #go"},{"id":"ceede527325efbfd320944677b30197b","title":"macOS: find files asynchronously ","content":"#!/bin/bash\n\nreplacement_patterns() {\n  echo \"Processing file: $1\"\n}\n\nreplacement_patterns \"$@\"\n# on macOS we have to use a separate shell process with a separate script file for async processing to work...\n\nfind \"/Users/integralist/Code/path/to/directory\" -type f -print0 | xargs -0 -P \"$(nproc)\" -n 1 bash -c './async.sh \"$@\"' _\n","tags":"#xargs #async #find"},{"id":"ff0a0152fdb0cad90e392c19645bb5ac","title":"Go: convert JSON types when unmarshalling ","content":"package main\n\nimport (\n\t\"encoding/json\"\n\t\"fmt\"\n)\n\nfunc main() {\n\tvar jsonBlob = []byte(`[\n\t{\"str\": \"Foo\", \"num\": \"1\", \"bool\": \"true\", \"its\": 3},\n\t{\"str\": \"Bar\",    \"num\": \"2\", \"bool\": \"false\", \"its\": 4}\n]`)\n\ttype Thing struct {\n\t\tString  string `json:\"str\"`\n\t\tNumber  int    `json:\"num,string\"`\n\t\tBoolean bool   `json:\"bool,string\"`\n\t\t// IntToString string `json:\"its,int\"` // error: json: cannot unmarshal number into Go struct field Thing.its of type string \n\t}\n\tvar things []Thing\n\terr := json.Unmarshal(jsonBlob, \u0026things)\n\tif err != nil {\n\t\tfmt.Println(\"error:\", err)\n\t}\n\tfmt.Printf(\"%#v\", things)\n}\n\n","tags":"#go #json #serialization"},{"id":"927f91c34be67499a6a1a430ddaebe92","title":"Go: basic middleware abstraction ","content":"package traces\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"net/http\"\n\t\"regexp\"\n\n\t\"go.opentelemetry.io/contrib/instrumentation/net/http/otelhttp\"\n\t\"go.opentelemetry.io/otel\"\n\t\"go.opentelemetry.io/otel/attribute\"\n\t\"go.opentelemetry.io/otel/exporters/otlp/otlptrace/otlptracehttp\"\n\t\"go.opentelemetry.io/otel/propagation\"\n\t\"go.opentelemetry.io/otel/sdk/resource\"\n\tsdktrace \"go.opentelemetry.io/otel/sdk/trace\"\n\tsemconv \"go.opentelemetry.io/otel/semconv/v1.24.0\"\n\t\"go.opentelemetry.io/otel/trace\"\n\n\t\"github.com/org/repo/internal/config\"\n\th \"github.com/org/repo/internal/http\"\n)\n\nconst (\n\tserviceName = \"example-app\"\n\tversion     = \"0.1.0\"\n)\n\n// routePattern matches the content inside curly brackets.\nvar routePattern = regexp.MustCompile(`\\{([^{}]+)\\}`)\n\nfunc newResource() *resource.Resource {\n\tinfo := build.Info\n\treturn resource.NewWithAttributes(\n\t\tsemconv.SchemaURL,\n\t\tsemconv.ServiceName(serviceName),\n\t\tsemconv.ServiceVersionKey.String(\n\t\t\tinfo.Version+\"-\"+info.BuildNumber,\n\t\t),\n\t)\n}\n\nfunc New(ctx context.Context, cfg *config.Config) (func(context.Context) error, trace.Tracer, error) {\n\tvar tracerProvider *sdktrace.TracerProvider\n\tif cfg.OtelDisabled {\n\t\ttracerProvider = sdktrace.NewTracerProvider(\n\t\t\tsdktrace.WithResource(newResource()),\n\t\t\tsdktrace.WithSampler(sdktrace.NeverSample()),\n\t\t)\n\t} else {\n\t\texporter, err := otlptracehttp.New(ctx)\n\t\tif err != nil {\n\t\t\treturn nil, nil, fmt.Errorf(\"creating OTLP trace exporter: %w\", err)\n\t\t}\n\n\t\ttracerProvider = sdktrace.NewTracerProvider(\n\t\t\tsdktrace.WithBatcher(exporter),\n\t\t\tsdktrace.WithResource(newResource()),\n\t\t)\n\t}\n\n\totel.SetTracerProvider(tracerProvider)\n\ttracer := tracerProvider.Tracer(serviceName, trace.WithInstrumentationVersion(version))\n\totel.SetTextMapPropagator(propagation.NewCompositeTextMapPropagator(propagation.TraceContext{}, propagation.Baggage{}))\n\n\treturn tracerProvider.Shutdown, tracer, nil\n}\n\nfunc NewHandler(handler http.Handler) http.Handler {\n\treturn otelhttp.NewHandler(handler, \"server\",\n\t\totelhttp.WithMessageEvents(otelhttp.ReadEvents, otelhttp.WriteEvents),\n\t\totelhttp.WithFilter(otelReqFilter),\n\t)\n}\n\n// GetTraceID returns the current traceID if it will be sampled and exported\nfunc GetTraceID(ctx context.Context) string {\n\tspan := trace.SpanFromContext(ctx)\n\tsampled := span.SpanContext().IsSampled()\n\ttraceID := span.SpanContext().TraceID().String()\n\tif traceID != \"\" \u0026\u0026 sampled {\n\t\treturn traceID\n\t}\n\treturn \"\"\n}\n\nfunc Tracer() trace.Tracer {\n\treturn otel.GetTracerProvider().Tracer(serviceName)\n}\n\n// Start creates a span and a context.Context containing the newly-created span.\nfunc Start(ctx context.Context, name string) (context.Context, trace.Span) {\n\treturn Tracer().Start(ctx, name, trace.WithSpanKind(trace.SpanKindInternal))\n}\n\nfunc otelReqFilter(req *http.Request) bool {\n\treturn req.URL.Path != \"/healthcheck\"\n}\n\n// WithSpan starts a trace.\nfunc WithSpan(tracer trace.Tracer) func(next http.Handler) http.Handler {\n\treturn func(next http.Handler) http.Handler {\n\t\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\t\tctx, span := tracer.Start(r.Context(), \"handler_called\")\n\t\t\tdefer span.End()\n\t\t\tnext.ServeHTTP(w, r.WithContext(ctx))\n\t\t})\n\t}\n}\n\n// WithRouteTag annotates spans and metrics with the provided route name with\n// HTTP route attribute.\nfunc WithRouteTag(next http.Handler) http.Handler {\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\troute, _ := h.RoutePatternFromContext(r.Context()) //nolint:contextcheck\n\t\tctx := otel.GetTextMapPropagator().Extract(\n\t\t\tr.Context(), propagation.HeaderCarrier(r.Header),\n\t\t)\n\t\totelhttp.WithRouteTag(route, next).ServeHTTP(w, r.WithContext(ctx))\n\t})\n}\n\n// WithParamAttrs annotates spans with route pattern parameters and their values.\nfunc WithParamAttrs(next http.Handler) http.Handler {\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tctx := r.Context()\n\t\troute, _ := h.RoutePatternFromContext(ctx) //nolint:contextcheck\n\t\tspan := trace.SpanFromContext(ctx)\n\t\tsegments := routePattern.FindAllStringSubmatch(route, -1)\n\t\tfor _, seg := range segments {\n\t\t\tif len(seg) == 2 { //nolint:gomnd\n\t\t\t\tkey := seg[1]\n\t\t\t\tspan.SetAttributes(attribute.String(key, r.PathValue(key)))\n\t\t\t}\n\t\t}\n\t\tnext.ServeHTTP(w, r)\n\t})\n}\n// THIS IS THE REDESIGNED VERSION (see 3. middleware.go for my original approach)\n\npackage middleware\n\nimport (\n\t\"net/http\"\n)\n\n// Decorator is a middleware function.\ntype Decorator func(http.Handler) http.Handler\n\n// Pipeline is a type for wrapping an http.Handler and adding optional logging,\n// metrics and tracing.\ntype Pipeline struct {\n\tmiddleware []Decorator\n}\n\n// New returns a middleware Pipeline.\nfunc New(middleware ...Decorator) *Pipeline {\n\tp := \u0026Pipeline{}\n\tp.middleware = append(p.middleware, middleware...)\n\treturn p\n}\n\n// Decorate wraps next in the defined middleware and executes the pipeline.\nfunc (p *Pipeline) Decorate(next http.Handler) http.Handler {\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tfor i := len(p.middleware) - 1; i \u003e= 0; i-- {\n\t\t\tnext = p.middleware[i](next)\n\t\t}\n\t\tnext.ServeHTTP(w, r)\n\t})\n}\n// THIS IS THE REDESIGNED VERSION (see 4. main.go for my original approach)\n\n// Package main is the entry point for the application.\npackage main\n\nimport (\n\t\"context\"\n\t\"flag\"\n\t\"fmt\"\n\t\"log/slog\"\n\t\"net/http\"\n\t\"os\"\n\t\"os/signal\"\n\t\"runtime\"\n\t\"syscall\"\n\t\"time\"\n\n\t\"github.com/prometheus/client_golang/prometheus\"\n\t\"golang.org/x/sync/errgroup\"\n\n\t\"github.com/org/repo/internal/config\"\n\th \"github.com/org/repo/internal/http\"\n\t\"github.com/org/repo/internal/logging\"\n\t\"github.com/org/repo/internal/metrics\"\n\t\"github.com/org/repo/internal/middleware\"\n\t\"github.com/org/repo/internal/traces\"\n)\n\nvar (\n\tcfgPath     = flag.String(\"cfg\", \"\", \"Path to config\")\n\tmetricsHost = flag.String(\"metrics-host\", \"127.0.0.1\", \"Host to use for metrics \u0026 pprof\")\n\tmetricsPort = flag.Int(\"metrics-port\", 8447, \"Port to expose for metrics \u0026 pprof\") //nolint:gomnd\n)\n\n// ImageTag is the container image version and is displayed in the healthcheck.\n// It is overridden at run/build time (see ../../Makefile).\nvar ImageTag = \"dev\"\n\nfunc main() {\n\tbuild.AddVersionFlag()\n\tflag.Parse()\n\n\t// NOTE: Moving the logic to `app()` allows us to honour `defer` calls.\n\tif err := app(); err != nil {\n\t\tos.Exit(1)\n\t}\n}\n\nfunc app() error {\n\tctx := context.Background()\n\tlogger := logging.NewLogger()\n\n\tcfg, err := config.Load(*cfgPath)\n\tif err != nil {\n\t\tlogger.LogAttrs(ctx, slog.LevelError, \"config_load\", slog.Any(\"error\", fmt.Errorf(\"unable to load config: %w\", err)))\n\t}\n\tif err := cfg.Validate(); err != nil {\n\t\tlogger.LogAttrs(ctx, slog.LevelError, \"config_validate\", slog.Any(\"error\", fmt.Errorf(\"invalid config: %w\", err)))\n\t}\n\n\t// validate secret is available\n\tfmt.Printf(\"foo secret: %#v\\n\", cfg.Secrets)\n\n\t// setup observability\n\tregistry := prometheus.NewRegistry()\n\tmetric := metrics.New(registry)\n\tstate := \"enabled\"\n\tif cfg.OtelDisabled {\n\t\tstate = \"disabled\"\n\t}\n\tlogger.LogAttrs(ctx, slog.LevelInfo, \"trace exporting \"+state)\n\ttraceShutdown, tracer, err := traces.New(ctx, cfg)\n\tif err != nil {\n\t\tlogger.LogAttrs(ctx, slog.LevelError, \"trace create\", slog.Any(\"error\", fmt.Errorf(\"unable to start tracing: %w\", err)))\n\t}\n\tdefer func() {\n\t\t// NOTE: We use a separate context for the shutdown.\n\t\t// This is so that the graceful shutdown of the main HTTP server doesn't\n\t\t// end up cancelling the traceShutdown context before it has a chance to\n\t\t// complete its shutdown process.\n\t\tif err := traceShutdown(context.WithoutCancel(ctx)); err != nil {\n\t\t\tlogger.LogAttrs(ctx, slog.LevelError, \"trace shutdown\", slog.Any(\"error\", err))\n\t\t}\n\t}()\n\n\tg := new(errgroup.Group)\n\ttimeout := time.Duration(10) * time.Second //nolint:gomnd\n\n\t// Setup separate /metrics endpoint for Prometheus scraping.\n\t// Needs to be separate listener as metrics service runs on its own port.\n\tvar (\n\t\tmetricsAddr  string\n\t\tmetricServer *http.Server\n\t)\n\tif *metricsPort != 0 {\n\t\tmetricsAddr = fmt.Sprintf(\"%s:%d\", *metricsHost, *metricsPort)\n\t\tg.Go(func() error {\n\t\t\tmux := http.NewServeMux()\n\t\t\tmux.Handle(\"/metrics\", metric.Handler())\n\t\t\tmetricServer = \u0026http.Server{\n\t\t\t\tAddr:              metricsAddr,\n\t\t\t\tHandler:           mux,\n\t\t\t\tReadHeaderTimeout: timeout, // avoid slowloris https://app.deepsource.com/directory/analyzers/go/issues/GO-S2114\n\t\t\t}\n\t\t\tif err := metricServer.ListenAndServe(); err != nil {\n\t\t\t\terr := fmt.Errorf(\"metrics server failed to listen and serve requests: %w\", err)\n\t\t\t\tlogger.LogAttrs(ctx, slog.LevelError, \"error handling metric requests\",\n\t\t\t\t\tslog.Any(\"error\", err),\n\t\t\t\t\tslog.String(\"metrics_addr\", metricsAddr),\n\t\t\t\t)\n\t\t\t\treturn err\n\t\t\t}\n\t\t\treturn nil\n\t\t})\n\t}\n\n\tlogger = logger.With(\n\t\tslog.Int(\"gomaxprocs\", runtime.GOMAXPROCS(0)),\n\t\tslog.String(\"build_info\", build.Info.String()),\n\t\tslog.String(\"cfg\", *cfgPath),\n\t\tslog.String(\"cfg_addr\", cfg.Addr),\n\t\tslog.String(\"metrics_addr\", metricsAddr),\n\t)\n\tlogger.LogAttrs(ctx, slog.LevelInfo, \"service starting\")\n\n\t// Routing\n\tmux := http.NewServeMux()\n\n\t// NOTE: We have separate pipelines.\n\t// One for the healthcheck and another for all other endpoints.\n\t// This is because we want to avoid tracing the healthcheck endpoint.\n\t// For some apps, tracing the healthcheck can result in poor performance.\n\n\tpipelineHealth := middleware.New(logging.WithRoutePattern(mux, logger), metric.WithHealthCheckMetrics, h.WithHeaders(cfg))\n\thealthHandler := http.HandlerFunc(func(w http.ResponseWriter, _ *http.Request) {\n\t\tw.WriteHeader(http.StatusOK)\n\t\tfmt.Fprintf(w, `{\"status\": \"success\", \"image_tag\": \"%s\"}`, ImageTag)\n\t})\n\tmux.Handle(\"/healthcheck\", pipelineHealth.Decorate(healthHandler))\n\n\t// NOTE: The order of the middleware is deliberate.\n\t// WithSpan updates the request context with a Span ID.\n\t// WithRoutePattern checks for the Span ID and attaches it to the logger.\n\t// WithMetrics, WithRouteTag and WithParamAttrs all check for the route pattern added by WithRoutePattern.\n\n\tpipeline := middleware.New(traces.WithSpan(tracer), logging.WithRoutePattern(mux, logger), metric.WithMetrics, traces.WithRouteTag, traces.WithParamAttrs, h.WithHeaders(cfg))\n\texampleHandler := http.HandlerFunc(func(w http.ResponseWriter, _ *http.Request) {\n\t\tw.WriteHeader(http.StatusOK)\n\t\tfmt.Fprint(w, `{\"endpoint\": \"example\"}`)\n\t})\n\tmux.Handle(\"/example/{id}\", pipeline.Decorate(exampleHandler))\n\n\t// API Server\n\tapiServer := \u0026http.Server{\n\t\tAddr:              cfg.Addr,\n\t\tHandler:           mux,\n\t\tReadHeaderTimeout: timeout, // avoid slowloris https://app.deepsource.com/directory/analyzers/go/issues/GO-S2114\n\t}\n\tg.Go(func() error {\n\t\tif err := apiServer.ListenAndServe(); err != nil {\n\t\t\terr := fmt.Errorf(\"api server failed to listen and serve requests: %w\", err)\n\t\t\tlogger.LogAttrs(ctx, slog.LevelError, \"error handling API requests\",\n\t\t\t\tslog.Any(\"error\", err),\n\t\t\t\tslog.String(\"metrics_addr\", metricsAddr),\n\t\t\t)\n\t\t\treturn err\n\t\t}\n\t\treturn nil\n\t})\n\n\t// Graceful shutdown\n\tg.Go(func() error {\n\t\tquit := make(chan os.Signal, 1)\n\t\tsignal.Notify(quit, syscall.SIGINT, syscall.SIGTERM)\n\t\tsignalType := \u003c-quit\n\t\tlogger.LogAttrs(ctx, slog.LevelWarn, \"http server graceful shutdown\",\n\t\t\tslog.String(\"signal\", signalType.String()),\n\t\t)\n\t\t// NOTE: Shutdown is given a separate context from the API server.\n\t\tif apiServer != nil {\n\t\t\tif err := apiServer.Shutdown(context.Background()); err != nil { //nolint:contextcheck\n\t\t\t\terr := fmt.Errorf(\"unable to gracefully stop API server: %w\", err)\n\t\t\t\tlogger.LogAttrs(ctx, slog.LevelError, \"error shutting down API server\",\n\t\t\t\t\tslog.Any(\"error\", err),\n\t\t\t\t)\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\t\tif metricServer != nil {\n\t\t\tif err := metricServer.Shutdown(context.Background()); err != nil { //nolint:contextcheck\n\t\t\t\terr := fmt.Errorf(\"unable to gracefully stop metrics server: %w\", err)\n\t\t\t\tlogger.LogAttrs(ctx, slog.LevelError, \"error shutting down metrics server\",\n\t\t\t\t\tslog.Any(\"error\", err),\n\t\t\t\t)\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\t\treturn nil\n\t})\n\n\treturn g.Wait()\n}\n\npackage middleware\n\nimport (\n\t\"net/http\"\n)\n\n// Decorator is a middleware function.\ntype Decorator func(http.Handler) http.Handler\n\n// Pipeline is a type for wrapping an http.Handler and adding optional logging,\n// metrics and tracing.\ntype Pipeline struct {\n\tmiddleware []Decorator\n\tmux        *http.ServeMux\n}\n\n// New returns a middleware Pipeline.\nfunc New(mux *http.ServeMux) *Pipeline {\n\treturn \u0026Pipeline{\n\t\tmux: mux,\n\t}\n}\n\n// Use installs one or more middleware in the request cycle.\nfunc (p *Pipeline) Use(middleware ...Decorator) {\n\tp.middleware = append(p.middleware, middleware...)\n}\n\n// Handle registers a handler for the given path.\nfunc (p *Pipeline) Handle(path string, handler http.Handler, middleware ...Decorator) {\n\tfor i := len(middleware) - 1; i \u003e= 0; i-- {\n\t\thandler = middleware[i](handler)\n\t}\n\tfor i := len(p.middleware) - 1; i \u003e= 0; i-- {\n\t\thandler = p.middleware[i](handler)\n\t}\n\tp.mux.Handle(path, handler)\n}\n// Package main is the entry point for the application.\npackage main\n\nimport (\n\t\"context\"\n\t\"flag\"\n\t\"fmt\"\n\t\"log/slog\"\n\t\"net/http\"\n\t\"os\"\n\t\"os/signal\"\n\t\"runtime\"\n\t\"syscall\"\n\t\"time\"\n\n\t\"github.com/prometheus/client_golang/prometheus\"\n\n\t\"github.com/org/repo/internal/config\"\n\t\"github.com/org/repo/internal/logging\"\n\t\"github.com/org/repo/internal/metrics\"\n\t\"github.com/org/repo/internal/middleware\"\n\t\"github.com/org/repo/internal/traces\"\n)\n\nvar (\n\tcfgPath     = flag.String(\"cfg\", \"\", \"Path to config\")\n\tmetricsHost = flag.String(\"metrics-host\", \"127.0.0.1\", \"Host to use for metrics \u0026 pprof\")\n\tmetricsPort = flag.Int(\"metrics-port\", 8447, \"Port to expose for metrics \u0026 pprof\") //nolint:gomnd\n)\n\n// ImageTag is the container image version and is displayed in the healthcheck.\n// It is overridden at run/build time (see ../../Makefile).\nvar ImageTag = \"dev\"\n\nfunc main() {\n\tbuild.AddVersionFlag()\n\tflag.Parse()\n\n\t// NOTE: Moving the logic to `app()` allows us to honour `defer` calls.\n\tif err := app(); err != nil {\n\t\tos.Exit(1)\n\t}\n}\n\nfunc app() error {\n\tctx := context.Background()\n\tlogger := logging.NewLogger()\n\n\tcfg, err := config.Load(*cfgPath)\n\tif err != nil {\n\t\tlogger.LogAttrs(ctx, slog.LevelError, \"config_load\", slog.Any(\"error\", fmt.Errorf(\"unable to load config: %w\", err)))\n\t}\n\tif err := cfg.Validate(); err != nil {\n\t\tlogger.LogAttrs(ctx, slog.LevelError, \"config_validate\", slog.Any(\"error\", fmt.Errorf(\"invalid config: %w\", err)))\n\t}\n\n\t// validate secret is available\n\tfmt.Printf(\"foo secret: %#v\\n\", cfg.Secrets)\n\n\t// setup observability\n\tregistry := prometheus.NewRegistry()\n\tmetric := metrics.New(registry)\n\tstate := \"enabled\"\n\tif cfg.OtelDisabled {\n\t\tstate = \"disabled\"\n\t}\n\tlogger.LogAttrs(ctx, slog.LevelInfo, \"trace exporting \"+state)\n\ttraceShutdown, tracer, err := traces.New(ctx, cfg)\n\tif err != nil {\n\t\tlogger.LogAttrs(ctx, slog.LevelError, \"trace create\", slog.Any(\"error\", fmt.Errorf(\"unable to start tracing: %w\", err)))\n\t}\n\tdefer func() {\n\t\t// NOTE: We use a separate context for the shutdown.\n\t\t// This is so that the graceful shutdown of the main HTTP server doesn't\n\t\t// end up cancelling the traceShutdown context before it has a chance to\n\t\t// complete its shutdown process.\n\t\tif err := traceShutdown(context.WithoutCancel(ctx)); err != nil {\n\t\t\tlogger.LogAttrs(ctx, slog.LevelError, \"trace shutdown\", slog.Any(\"error\", err))\n\t\t}\n\t}()\n\n\tserverError := make(chan error, 1)\n\ttimeout := time.Duration(10) * time.Second //nolint:gomnd\n\n\t// Setup separate /metrics endpoint for Prometheus scraping.\n\t// Needs to be separate listener as metrics service runs on its own port.\n\tvar metricsAddr string\n\tif *metricsPort != 0 {\n\t\tmetricsAddr = fmt.Sprintf(\"%s:%d\", *metricsHost, *metricsPort)\n\t\tgo func() {\n\t\t\tmux := http.NewServeMux()\n\t\t\tmux.Handle(\"/metrics\", metric.Handler())\n\t\t\tserver := \u0026http.Server{\n\t\t\t\tAddr:              metricsAddr,\n\t\t\t\tHandler:           mux,\n\t\t\t\tReadHeaderTimeout: timeout, // avoid slowloris https://app.deepsource.com/directory/analyzers/go/issues/GO-S2114\n\t\t\t}\n\t\t\tif err := server.ListenAndServe(); err != nil {\n\t\t\t\tlogger.LogAttrs(ctx, slog.LevelError, \"error handling metric requests\",\n\t\t\t\t\tslog.Any(\"error\", err),\n\t\t\t\t\tslog.String(\"metrics_addr\", metricsAddr),\n\t\t\t\t)\n\t\t\t\tserverError \u003c- err\n\t\t\t}\n\t\t}()\n\t}\n\n\tselect {\n\tcase err := \u003c-serverError:\n\t\treturn err\n\tcase \u003c-time.After(1 * time.Second):\n\t\t// no-op: allow logic to flow to setting up routing/http server\n\t}\n\n\tlogger = logger.With(\n\t\tslog.Int(\"gomaxprocs\", runtime.GOMAXPROCS(0)),\n\t\tslog.String(\"build_info\", build.Info.String()),\n\t\tslog.String(\"cfg\", *cfgPath),\n\t\tslog.String(\"cfg_addr\", cfg.Addr),\n\t\tslog.String(\"metrics_addr\", metricsAddr),\n\t)\n\tlogger.LogAttrs(ctx, slog.LevelInfo, \"service starting\")\n\n\t// Routing\n\tmux := http.NewServeMux()\n\n\t// NOTE: We have separate pipelines.\n\t// One for the healthcheck and another for all other endpoints.\n\t// This is because we want to avoid tracing the healthcheck endpoint.\n\t// For some apps, tracing the healthcheck can result in poor performance.\n\n\tpipelineHealth := middleware.New(mux)\n\tpipelineHealth.Use(logging.WithRoutePattern(mux, logger), metric.WithHealthCheckMetrics)\n\tpipelineHealth.Handle(\"/healthcheck\", http.HandlerFunc(func(w http.ResponseWriter, _ *http.Request) {\n\t\tw.WriteHeader(http.StatusOK)\n\t\t_, _ = w.Write([]byte(fmt.Sprintf(`{\"status\": \"success\", \"image_tag\": \"%s\"}`, ImageTag)))\n\t}))\n\n\t// NOTE: The order of the middleware is deliberate.\n\t// WithSpan updates the request context with a Span ID.\n\t// WithRoutePattern checks for the Span ID and attaches it to the logger.\n\t// WithMetrics, WithRouteTag and WithParamAttrs all check for the route pattern added by WithRoutePattern.\n\n\tpipeline := middleware.New(mux)\n\tpipeline.Use(traces.WithSpan(tracer), logging.WithRoutePattern(mux, logger), metric.WithMetrics, traces.WithRouteTag, traces.WithParamAttrs)\n\tpipeline.Handle(\"/example/{id}\", http.HandlerFunc(func(w http.ResponseWriter, _ *http.Request) {\n\t\tw.WriteHeader(http.StatusOK)\n\t\t_, _ = w.Write([]byte(`{\"endpoint\": \"example\"}`))\n\t}))\n\n\t// HTTP Server\n\tserver := \u0026http.Server{\n\t\tAddr:              cfg.Addr,\n\t\tHandler:           mux,\n\t\tReadHeaderTimeout: timeout, // avoid slowloris https://app.deepsource.com/directory/analyzers/go/issues/GO-S2114\n\t}\n\tgo func() {\n\t\tif err := server.ListenAndServe(); err != nil {\n\t\t\tlogger.LogAttrs(ctx, slog.LevelError, \"error handling server requests\",\n\t\t\t\tslog.Any(\"error\", err),\n\t\t\t\tslog.String(\"metrics_addr\", metricsAddr),\n\t\t\t)\n\t\t\tserverError \u003c- err\n\t\t}\n\t}()\n\n\tselect {\n\tcase err := \u003c-serverError:\n\t\treturn err\n\tcase \u003c-time.After(1 * time.Second):\n\t\t// no-op: allow logic to flow to setting up graceful shutdown\n\t}\n\n\t// Graceful shutdown\n\tquit := make(chan os.Signal, 1)\n\tsignal.Notify(quit, syscall.SIGINT, syscall.SIGTERM)\n\tsignalType := \u003c-quit\n\tlogger.LogAttrs(ctx, slog.LevelWarn, \"http server graceful shutdown\",\n\t\tslog.String(\"signal\", signalType.String()),\n\t)\n\t// NOTE: Shutdown is given a separate context from the API server.\n\tif err := server.Shutdown(context.Background()); err != nil {\n\t\tlogger.LogAttrs(ctx, slog.LevelError, \"error shutting down server\",\n\t\t\tslog.Any(\"error\", fmt.Errorf(\"unable to gracefully stop server: %w\", err)),\n\t\t)\n\t}\n\n\treturn nil\n}\npackage logging\n\nimport (\n\t\"context\"\n\t\"io\"\n\t\"log\"\n\t\"log/slog\"\n\t\"net/http\"\n\t\"os\"\n\t\"path/filepath\"\n\t\"regexp\"\n\t\"strconv\"\n\t\"strings\"\n\n\th \"github.com/org/repo/internal/http\"\n\t\"github.com/org/repo/internal/traces\"\n)\n\n// Level allows dynamically changing the output level via .Set() method.\n// Defaults to [slog.LevelInfo].\nvar Level = new(slog.LevelVar)\n\n// routePattern matches the content inside curly brackets.\nvar routePattern = regexp.MustCompile(`\\{([^{}]+)\\}`)\n\n// Logger describes the set of features we want to expose from log/slog.\n//\n// NOTE: Don't confuse our custom With() signature with (*slog.Logger).With\n// We return a Logger type where the standard library returns a *slog.Logger\ntype Logger interface {\n\tEnabled(ctx context.Context, level slog.Level) bool\n\tLogAttrs(ctx context.Context, level slog.Level, msg string, attrs ...slog.Attr)\n\tWith(args ...any) Logger\n\t_private()\n}\n\n// NewLogger returns a logging.Logger configured for stderr.\nfunc NewLogger() Logger {\n\treturn NewLoggerWithOutputLevel(os.Stdout, Level)\n}\n\n// NewLoggerWithOutput returns a [Logger] configured with an output writer.\nfunc NewLoggerWithOutput(w io.Writer) Logger {\n\treturn (*logger)(slog.New(slog.NewJSONHandler(w, defaultOptions()).WithAttrs(defaultAttrs())))\n}\n\n// NewLoggerWithOutputLevel returns a [Logger] configured with an output writer and Level.\nfunc NewLoggerWithOutputLevel(w io.Writer, l slog.Leveler) Logger {\n\topts := defaultOptions()\n\topts.Level = l\n\treturn (*logger)(slog.New(slog.NewJSONHandler(w, opts).WithAttrs(defaultAttrs())))\n}\n\n// NewBareLoggerWithOutputLevel returns a [Logger] configured with an output location and [slog.Leveler].\n// It does not include any additional attributes.\nfunc NewBareLoggerWithOutputLevel(w io.Writer, l slog.Leveler) Logger {\n\topts := defaultOptions()\n\topts.Level = l\n\treturn (*logger)(slog.New(slog.NewJSONHandler(w, opts)))\n}\n\n// nolint:revive\n//\n//lint:ignore U1000 Prevents any other package from implementing this interface\ntype private struct{} //nolint:unused\n\n// IMPORTANT: logger is an alias to slog.Logger to avoid a double-pointer deference.\n// All methods off the type will need to type-cast a *logger to *slog.Logger.\n// With() must additionally type-cast back to a Logger compatible type.\ntype logger slog.Logger\n\nfunc (*logger) _private() {}\n\nfunc (l *logger) Enabled(ctx context.Context, level slog.Level) bool {\n\treturn (*slog.Logger)(l).Enabled(ctx, level)\n}\n\nfunc (l *logger) LogAttrs(ctx context.Context, level slog.Level, msg string, attrs ...slog.Attr) {\n\t(*slog.Logger)(l).LogAttrs(ctx, level, msg, attrs...)\n}\n\nfunc (l *logger) With(args ...any) Logger {\n\treturn (*logger)((*slog.Logger)(l).With(args...))\n}\n\n// Adapt returns a [log.Logger] for use with packages that are not yet compatible with\n// [log/slog].\nfunc Adapt(l Logger, level slog.Level) *log.Logger {\n\t// _private() ensures this type assertion cannot panic.\n\tslogger := (*slog.Logger)(l.(*logger)) //nolint:revive,forcetypeassert\n\treturn slog.NewLogLogger(slogger.Handler(), level)\n}\n\nfunc defaultOptions() *slog.HandlerOptions {\n\treturn \u0026slog.HandlerOptions{\n\t\tAddSource:   true,\n\t\tReplaceAttr: slogReplaceAttr,\n\t\tLevel:       Level,\n\t}\n}\n\nfunc defaultAttrs() []slog.Attr {\n\treturn []slog.Attr{slog.Group(\"app\",\n\t\tslog.String(\"name\", build.Info.Project),\n\t\tslog.String(\"version\", build.Info.Version),\n\t)}\n}\n\n// NullLogger discards logs.\nfunc NullLogger() Logger {\n\t// NOTE: We pass a level not currently defined to reduce operational overhead.\n\t// The intent, unlike passing nil for the opts argument, is for the logger to\n\t// not even bother generating a message that will just be discarded.\n\t// An additional gap of 4 was used as it aligns with Go's original design.\n\t// https://github.com/golang/go/blob/1e95fc7/src/log/slog/level.go#L34-L42\n\treturn (*logger)(slog.New(slog.NewTextHandler(io.Discard, \u0026slog.HandlerOptions{Level: slog.LevelError + 4}))) //nolint:gomnd\n}\n\n// slogReplaceAttr adjusts the log output.\n//\n// - Restricts these changes to top-level keys (not keys within groups)\n//   - Changes default time field value to UTC time zone\n//   - Replaces msg key with event\n//   - Omits event field if empty\n//   - Omits error field if when nil\n//   - Truncates source's filename to example-app directory\n//\n// - Formats duration and delay values in microseconds as xxxxµs\n//\n// See https://pkg.go.dev/log/slog#HandlerOptions.ReplaceAttr\n// N.B: TextHandler manages quoting attribute values as necessary.\nfunc slogReplaceAttr(groups []string, a slog.Attr) slog.Attr {\n\t// Limit application of these rules only to top-level keys\n\tif len(groups) == 0 {\n\t\t// Set time zone to UTC\n\t\tif a.Key == slog.TimeKey {\n\t\t\ta.Value = slog.TimeValue(a.Value.Time().UTC())\n\t\t\treturn a\n\t\t}\n\t\t// Use event as the default MessageKey, remove if empty\n\t\tif a.Key == slog.MessageKey {\n\t\t\ta.Key = \"event\"\n\t\t\tif a.Value.String() == \"\" {\n\t\t\t\treturn slog.Attr{}\n\t\t\t}\n\t\t\treturn a\n\t\t}\n\t\t// Display a 'partial' path.\n\t\t// Avoids ambiguity when multiple files have the same name across packages.\n\t\t// e.g. billing.go appears under 'global', 'billing' and 'server' packages.\n\t\tif a.Key == slog.SourceKey {\n\t\t\tif source, ok := a.Value.Any().(*slog.Source); ok {\n\t\t\t\ta.Key = \"caller\"\n\t\t\t\tif _, after, ok := strings.Cut(source.File, \"example-app\"+string(filepath.Separator)); ok {\n\t\t\t\t\tsource.File = after\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn a\n\t\t}\n\t}\n\n\t// Remove error key=value when error is nil\n\tif a.Equal(slog.Any(\"error\", error(nil))) {\n\t\treturn slog.Attr{}\n\t}\n\n\t// Present durations and delays as xxxxµs\n\tswitch a.Key {\n\tcase \"dur\", \"delay\", \"p95\", \"previous_p95\", \"remaining\", \"max_wait\":\n\t\ta.Value = slog.StringValue(strconv.FormatInt(a.Value.Duration().Microseconds(), 10) + \"µs\")\n\t}\n\n\treturn a\n}\n\n// WithRoutePattern logs the http handler with the route pattern.\nfunc WithRoutePattern(mux *http.ServeMux, logger Logger) func(next http.Handler) http.Handler {\n\treturn func(next http.Handler) http.Handler {\n\t\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\t\tctx := h.ContextWithRoutePattern(mux, r)\n\t\t\troute, _ := h.RoutePatternFromContext(ctx) //nolint:contextcheck\n\t\t\tattrs := []any{\n\t\t\t\tslog.String(\"pattern\", route),\n\t\t\t}\n\t\t\tsegments := routePattern.FindAllStringSubmatch(route, -1)\n\t\t\tfor _, seg := range segments {\n\t\t\t\tif len(seg) == 2 { //nolint:gomnd\n\t\t\t\t\tkey := seg[1]\n\t\t\t\t\tattrs = append(attrs, slog.String(key, r.PathValue(key)))\n\t\t\t\t}\n\t\t\t}\n\t\t\tif traceID := traces.GetTraceID(ctx); traceID != \"\" { //nolint:contextcheck\n\t\t\t\tlogger = logger.With(slog.String(\"trace_id\", traceID))\n\t\t\t}\n\t\t\tlogger.LogAttrs(r.Context(), slog.LevelInfo, \"handler_called\", slog.Group(\"request\", attrs...))\n\t\t\tnext.ServeHTTP(w, r.WithContext(ctx)) //nolint:contextcheck\n\t\t})\n\t}\n}\npackage http\n\nimport (\n\t\"context\"\n\t\"net/http\"\n)\n\n// RouteContextKey is a custom type for the key used in context.Context\ntype routeContextKey struct{}\n\n// RoutePatternContextKey is the key to store a route pattern in context.Context\nvar RoutePatternContextKey = routeContextKey{}\n\n// ContextWithRoutePattern sets the request route into the context.Context\nfunc ContextWithRoutePattern(mux *http.ServeMux, r *http.Request) context.Context {\n\t_, route := mux.Handler(r)\n\treturn context.WithValue(r.Context(), RoutePatternContextKey, route)\n}\n\n// RoutePatternFromContext returns the request route from the context.Context\nfunc RoutePatternFromContext(ctx context.Context) (string, bool) {\n\tv := ctx.Value(RoutePatternContextKey)\n\tif v != nil {\n\t\tif s, ok := v.(string); ok {\n\t\t\treturn s, ok\n\t\t}\n\t}\n\treturn \"\", false\n}\npackage metrics\n\nimport (\n\t\"context\"\n\t\"net/http\"\n\t\"time\"\n\n\t\"github.com/prometheus/client_golang/prometheus\"\n\t\"github.com/prometheus/client_golang/prometheus/collectors\"\n\t\"github.com/prometheus/client_golang/prometheus/promauto\"\n\t\"github.com/prometheus/client_golang/prometheus/promhttp\"\n\n\th \"github.com/org/repo/internal/http\"\n\t\"github.com/org/repo/internal/traces\"\n)\n\nconst (\n\tnamespace = \"fastly\"\n\tsubsystem = \"domainr_api\"\n)\n\n// New initializes our prometheus metrics.\nfunc New(registry *prometheus.Registry) *Metrics {\n\tm := \u0026Metrics{\n\t\tregistry: registry,\n\t}\n\n\tregisterAndSetBuildInfo(registry)\n\tregisterUptime(registry)\n\n\tm.registerRequestMetrics()\n\n\tregistry.MustRegister(collectors.NewProcessCollector(collectors.ProcessCollectorOpts{Namespace: namespace}))\n\tregistry.MustRegister(collectors.NewGoCollector())\n\n\treturn m\n}\n\n// Metrics contains all the Prometheus tracked by Domainr API\ntype Metrics struct {\n\tregistry          *prometheus.Registry\n\thealthChecksTotal *prometheus.CounterVec\n\trequestsTotal     *prometheus.CounterVec\n\trequestDuration   *prometheus.HistogramVec\n\trequestSize       *prometheus.SummaryVec\n\tresponseSize      *prometheus.SummaryVec\n}\n\n// Handler is the prometheus http metrics handler.\nfunc (m *Metrics) Handler() http.Handler {\n\treturn promhttp.HandlerFor(m.registry, promhttp.HandlerOpts{\n\t\tEnableOpenMetrics: true,\n\t})\n}\n\n// RegisterCounter returns a counter.\nfunc (m *Metrics) RegisterCounter(name, help string) prometheus.Counter {\n\tcustomCounter := prometheus.NewCounter(prometheus.CounterOpts{\n\t\tNamespace: namespace,\n\t\tSubsystem: subsystem,\n\t\tName:      name,\n\t\tHelp:      help,\n\t})\n\tm.registry.MustRegister(customCounter)\n\treturn customCounter\n}\n\nfunc (m *Metrics) WithMetrics(next http.Handler) http.Handler {\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tlabel := prometheus.Labels{}\n\t\tif route, ok := h.RoutePatternFromContext(r.Context()); ok {\n\t\t\tlabel = prometheus.Labels{\"route\": route}\n\t\t}\n\n\t\t// Wraps the provided http.Handler to observe the request result with the provided metrics.\n\t\tpromhttp.InstrumentHandlerCounter(\n\t\t\tm.requestsTotal.MustCurryWith(label),\n\t\t\tpromhttp.InstrumentHandlerDuration(\n\t\t\t\tm.requestDuration.MustCurryWith(label),\n\t\t\t\tpromhttp.InstrumentHandlerRequestSize(\n\t\t\t\t\tm.requestSize.MustCurryWith(label),\n\t\t\t\t\tpromhttp.InstrumentHandlerResponseSize(\n\t\t\t\t\t\tm.responseSize.MustCurryWith(label),\n\t\t\t\t\t\tnext,\n\t\t\t\t\t),\n\t\t\t\t),\n\t\t\t\t[]promhttp.Option{promhttp.WithExemplarFromContext(getTraceID)}...,\n\t\t\t),\n\t\t\t[]promhttp.Option{promhttp.WithExemplarFromContext(getTraceID)}...,\n\t\t).ServeHTTP(w, r)\n\t})\n}\n\nfunc (m *Metrics) WithHealthCheckMetrics(next http.Handler) http.Handler {\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tlabel := prometheus.Labels{}\n\t\tif route, ok := h.RoutePatternFromContext(r.Context()); ok {\n\t\t\tlabel = prometheus.Labels{\"route\": route}\n\t\t}\n\n\t\t// Wraps the provided http.Handler to observe the request result with the provided metrics.\n\t\tpromhttp.InstrumentHandlerCounter(\n\t\t\tm.healthChecksTotal.MustCurryWith(label),\n\t\t\tnext,\n\t\t).ServeHTTP(w, r)\n\t})\n}\n\nfunc (m *Metrics) registerRequestMetrics() {\n\tm.healthChecksTotal = promauto.With(m.registry).NewCounterVec(\n\t\tprometheus.CounterOpts{\n\t\t\tNamespace: namespace,\n\t\t\tSubsystem: subsystem,\n\t\t\tName:      \"health_checks\",\n\t\t\tHelp:      \"Number of health check requests received\",\n\t\t}, []string{\"code\", \"route\"},\n\t)\n\tm.requestsTotal = promauto.With(m.registry).NewCounterVec(\n\t\tprometheus.CounterOpts{\n\t\t\tNamespace: namespace,\n\t\t\tSubsystem: subsystem,\n\t\t\tName:      \"requests_total\",\n\t\t\tHelp:      \"Tracks the number of HTTP requests.\",\n\t\t}, []string{\"code\", \"route\"},\n\t)\n\tm.requestDuration = promauto.With(m.registry).NewHistogramVec(\n\t\tprometheus.HistogramOpts{\n\t\t\tNamespace: namespace,\n\t\t\tSubsystem: subsystem,\n\t\t\tName:      \"request_duration_seconds\",\n\t\t\tHelp:      \"Tracks the latencies for HTTP requests.\",\n\t\t\tBuckets:   prometheus.DefBuckets,\n\t\t},\n\t\t[]string{\"code\", \"route\"},\n\t)\n\tm.requestSize = promauto.With(m.registry).NewSummaryVec(\n\t\tprometheus.SummaryOpts{\n\t\t\tNamespace: namespace,\n\t\t\tSubsystem: subsystem,\n\t\t\tName:      \"request_size_bytes\",\n\t\t\tHelp:      \"Tracks the size of HTTP requests.\",\n\t\t},\n\t\t[]string{\"code\", \"route\"},\n\t)\n\tm.responseSize = promauto.With(m.registry).NewSummaryVec(\n\t\tprometheus.SummaryOpts{\n\t\t\tNamespace: namespace,\n\t\t\tSubsystem: subsystem,\n\t\t\tName:      \"response_size_bytes\",\n\t\t\tHelp:      \"Tracks the size of HTTP responses.\",\n\t\t},\n\t\t[]string{\"code\", \"route\"},\n\t)\n}\n\nfunc getTraceID(ctx context.Context) prometheus.Labels {\n\tif traceID := traces.GetTraceID(ctx); traceID != \"\" {\n\t\treturn prometheus.Labels{\"traceID\": traceID}\n\t}\n\treturn nil\n}\n\nfunc registerAndSetBuildInfo(registry *prometheus.Registry) {\n\tinfo := build.Info\n\tversion := prometheus.NewGaugeVec(prometheus.GaugeOpts{\n\t\tNamespace: namespace,\n\t\tName:      \"build_info\",\n\t\tHelp:      \"Build information for domainr-api.\",\n\t}, []string{\n\t\t\"version\",\n\t\t\"revision\",\n\t\t\"goversion\",\n\t})\n\tregistry.MustRegister(version)\n\n\tversion.WithLabelValues(\n\t\tinfo.Version+\"-\"+info.BuildNumber,\n\t\tinfo.GitRevision,\n\t\tinfo.GoVersion,\n\t).Set(1)\n}\n\nfunc registerUptime(registry *prometheus.Registry) {\n\tstart := time.Now()\n\tuptime := prometheus.NewGaugeFunc(prometheus.GaugeOpts{\n\t\tNamespace: namespace,\n\t\tName:      \"uptime_duration_seconds\",\n\t\tHelp:      \"Process uptime\",\n\t}, func() float64 {\n\t\treturn time.Since(start).Seconds()\n\t})\n\tregistry.MustRegister(uptime)\n}\n","tags":"#go #middleware"},{"id":"a4418dc1fc7940e2ee77183461e6ed9d","title":"Make: Check if Makefile target is called with a required input arg ","content":"# Check that given variables are set and all have non-empty values,\n# die with an error otherwise.\n#\n# PARAMS:\n#   1. Variable name(s) to test.\n#   2. (optional) Error message to print.\n#\n# EXAMPLE:\n# @:$(call check_defined, ENV_REGION, you must set ENV_REGION=usc1|awsuse2)\n#\ncheck_defined = \\\n    $(strip $(foreach 1,$1, \\\n        $(call __check_defined,$1,$(strip $(value 2)))))\n__check_defined = \\\n    $(if $(value $1),, \\\n        $(error Undefined $1$(if $2, ($2))$(if $(value @), \\\n                required by target `$@')))\n\n","tags":"#Makefile #make"},{"id":"4447885192c7e84e01ca7c9f2e08ef17","title":"Make: Makefile help output ","content":"# See also: https://gist.github.com/Integralist/d61a365912576bcef88b29bd11207df3\n\n.DEFAULT_GOAL := run  ## Default make target\nTOOLS = \"\"            ## List of dev tools\nTOOLS = \\\n\tgithub.com/mgechev/revive \\\n\tgolang.org/x/lint/golint \\\n\tgolang.org/x/tools/go/analysis/passes/nilness/cmd/nilness \\\n\tgolang.org/x/vuln/cmd/govulncheck \\\n\thonnef.co/go/tools/cmd/staticcheck \\\n\tmvdan.cc/gofumpt\n\n# .PHONY: help\n# help: ## Displays list of Makefile targets and documented variables\n# \t@echo \"Targets:\"\n# \t@grep -h -E '^[0-9a-zA-Z_.-]+:.*?## .*$$' $(MAKEFILE_LIST) | sort | awk 'BEGIN {FS = \":.*?## \"}; {printf \"  \\033[36m%-20s\\033[0m %s\\n\", $$1, $$2}'\n# \t@echo \"\"\n# \t@echo \"Variables:\"\n# \t@grep -h -E '^[0-9a-zA-Z_.-]+\\s[?:]?=.*?## .*$$' $(MAKEFILE_LIST) | sort | awk 'BEGIN {FS = \"[?:]?=.*?## \"}; {printf \"  \\033[36m%-20s\\033[0m %s\\n\", $$1, $$2}'\n# \t@echo \"\"\n# \t@echo \"Default target:\"\n# \t@printf \"  \\033[36m%s\\033[0m\\n\" $(.DEFAULT_GOAL)\n\n# \n# The following implementation of `help` uses the length of the longest target name.\n# Where as the above, earlier, implementation used a hardcoded length of 20.\n# The problem with the above implementation is a long target name will then push out the 'columns'.\n# \n\n\n.PHONY: help\nhelp: ## Displays list of Makefile targets and documented variables\n\t@echo \"Targets:\"\n\t@MAX_LEN_TARGET=$$(grep -h -E '^[0-9a-zA-Z_.-]+:.*?## .*$$' $(MAKEFILE_LIST) | awk 'BEGIN {FS = \":.*?## \"; max=0} {len=length($$1); if (len\u003emax) max=len} END {print max}'); \\\n\tgrep -h -E '^[0-9a-zA-Z_.-]+:.*?## .*$$' $(MAKEFILE_LIST) | sort | \\\n\tawk -v max_len=\"$$MAX_LEN_TARGET\" 'BEGIN {FS = \":.*?## \"}; {printf \"  \\033[36m%-\" max_len \"s\\033[0m %s\\n\", $$1, $$2}'\n\t@echo \"\"\n\t@echo \"Variables:\"\n\t@MAX_LEN_VAR=$$(grep -h -E '^[0-9a-zA-Z_.-]+\\s[?:]?=.*?## .*$$' $(MAKEFILE_LIST) | awk 'BEGIN {FS = \"[?:]?=.*?## \"; max=0} {len=length($$1); if (len\u003emax) max=len} END {print max}'); \\\n\tgrep -h -E '^[0-9a-zA-Z_.-]+\\s[?:]?=.*?## .*$$' $(MAKEFILE_LIST) | sort | \\\n\tawk -v max_len=\"$$MAX_LEN_VAR\" 'BEGIN {FS = \"[?:]?=.*?## \"}; {printf \"  \\033[36m%-\" max_len \"s\\033[0m %s\\n\", $$1, $$2}'\n\t@echo \"\"\n\t@echo \"Default target:\"\n\t@printf \"  \\033[36m%s\\033[0m\\n\" $(.DEFAULT_GOAL)\n\n.PHONY: api-update\napi-update: ## Update all API application dependencies\n\tgo get -u -t ./...\n\tgo mod tidy\n\tif [ -d \"vendor\" ]; then go mod vendor; fi\n\n.PHONY: fmt\nfmt: ## Format all Go files using gofumpt\n\tgo tool -modfile=tools.mod gofumpt -w .\n\n.PHONY: lint-all\nlint-all: lint-golint lint-govet lint-govul lint-nilness lint-revive lint-staticcheck ## Lint project using all linters\n\n.PHONY: lint-golint\nlint-golint: ## Lint project using golint\n\tgo tool -modfile=tools.mod golint -set_exit_status $(shell go list -f '{{.Dir}}' ./... )\n\n.PHONY: lint-govet\nlint-govet: ## Lint project using go vet\n\tgo vet ./...\n\n.PHONY: lint-govul\nlint-govul: ## Lint project using govulncheck\n\tgo tool -modfile=tools.mod govulncheck ./...\n\n.PHONY: lint-nilness\nlint-nilness: ## Lint project using nilness\n\tgo tool -modfile=tools.mod nilness ./...\n\n.PHONY: lint-revive\nlint-revive: ## Lint project using revive\n\tgo tool -modfile=tools.mod revive -config revive.toml ./...\n\n.PHONY: lint-staticcheck\nlint-staticcheck: ## Lint project using staticcheck\n\tgo tool -modfile=tools.mod staticcheck ./...\n\n.PHONY: run\nrun: ## Run the API server (opts: HUMANLOG=true)\n\t@# humanlog doesn't sort keys lexicographically.\n\t@# to do that we must set `--sort-longest=false`\n\t@# this causes the key sorting we want (as a side effect)\n\t@# while at the same time avoiding humanlog from trying to sort by key length\n\tgo run ./cmd/api/main.go $(if \\\n\t\t$(filter true,$(HUMANLOG)),| \\\n\t\t\thumanlog \\\n\t\t\t\t--message-fields=event \\\n\t\t\t\t--sort-longest=false \\\n\t\t\t\t--truncate=false, \\\n\t)\n\n.PHONY: test\ntest: ## Run the Go test suite\n\tgo test ./...\n\n.PHONY: tools-install\ntools-install: ## Install dev tools\n\t@if [ ! -f tools.mod ]; then \\\n\t\techo \"Initializing tools.mod\"; \\\n\t\tgo mod init -modfile=tools.mod github.com/fastly/ascerta/tools; \\\n\tfi\n\t@$(foreach tool,$(TOOLS), \\\n\t\tif ! go tool -modfile=tools.mod | grep \"$(tool)\" \u003e/dev/null; then \\\n\t\t\techo \"installing $(tool)\"; \\\n\t\t\tgo get -modfile=tools.mod -tool \"$(tool)\"@latest; \\\n\t\tfi; \\\n\t)\n\t@[ -x \"$(shell which humanlog)\" ] || curl -sSL \"https://humanlog.io/install.sh\" | NONINTERACTIVE=true bash\n\n.PHONY: tools-update\ntools-update: ## Update dev tools\n\tgo get -u -modfile=tools.mod tool\n\tgo mod tidy\n\n# checkmake (https://github.com/mrtazz/checkmake) requires these targets be set\n.PHONY: all clean test\n# IF YOU NEED TO EXCLUDE TARGETS FROM A PARENT MAKEFILE!\n\ninclude base.mk\n\n# Regex pattern of targets to omit from the help output (`make h`).\nOMIT_TARGETS := (help|lint):\n\n.PHONY: h\nh:  ## Filtered version of `help` target from base.mk\n\t@printf \"Targets\\n\"\n\t@grep -h -E '^[0-9a-zA-Z_.-]+:.*?## .*$$' $(MAKEFILE_LIST) | sort | grep -vE '$(OMIT_TARGETS)' | awk 'BEGIN {FS = \":.*?## \"}; {printf \"\\033[36m%-22s\\033[0m %s\\n\", $$1, $$2}'\n\t@printf \"\\nDefault target\\n\"\n\t@printf \"\\033[36m%s\\033[0m\" $(.DEFAULT_GOAL)\n\t@printf \"\\n\\nMake Variables\\n\"\n\t@grep -h -E '^[0-9a-zA-Z_.-]+\\s:=.*?## .*$$' $(MAKEFILE_LIST) || true | sort | awk 'BEGIN {FS = \":.*?## \"}; {printf \"\\033[36m%-25s\\033[0m %s\\n\", $$1, $$2}'\n\n","tags":"#make #makefile #help #docs"},{"id":"94be4633641bc644ef3b9cb50d8926fb","title":"OpenSSL: Generate Certificate for Code Signing ","content":"\u003e **NOTE:** The explanation of the code was auto-generated by AI (so some of the explanations could be incorrect).\n\n```shell\nopenssl genrsa -des3 -out rootCA.key 4096\n```\n\nThis code generates a new RSA private key with a length of 4096 bits and encrypts it using the Triple DES algorithm with a passphrase. The private key is saved in a file named `rootCA.key`. This command is commonly used to generate a root certificate authority (CA) key, which is used to sign and issue digital certificates for other entities.\n\n```shell\nopenssl req -x509 -new -nodes -key rootCA.key -sha256 -days 1024 -out rootCA.crt\n```\n\nThis code generates a self-signed X.509 certificate using the RSA private key stored in the `rootCA.key` file. The certificate is valid for 1024 days and is saved in the `rootCA.crt` file. The `-x509` option specifies that a self-signed certificate should be generated, while the `-new` option indicates that a new certificate request should be created. The `-nodes` option specifies that the private key should not be encrypted. The `-sha256` option specifies the hash algorithm to use for the certificate. This command is commonly used to generate a root certificate authority (CA) certificate, which is used to sign and issue digital certificates for other entities.\n\n```shell\ncat \u003c\u003c EOF \u003e code_sign_csr.conf\n[ req ]\ndefault_bits  = 2048             # RSA key size\nencrypt_key   = yes              # Protect private key\ndefault_md    = sha256           # MD to use\nutf8          = yes              # Input is UTF-8\nstring_mask   = utf8only         # Emit UTF-8 strings\nprompt        = yes              # Prompt for DN\ndistinguished_name = codesign_dn # DN template\nreq_extensions = codesign_reqext # Desired extensions\n\n[ codesign_dn ]\ncommonName      = the-company.com\ncommonName_max  = 64\n\n[ codesign_reqext ]\nkeyUsage        = critical,digitalSignature\nextendedKeyUsage = critical,codeSigning\nsubjectKeyIdentifier = hash\nEOF\n```\n\nThis code creates a configuration file named `code_sign_csr.conf` with settings for generating a certificate signing request (CSR) for code signing purposes. The configuration file specifies the default RSA key size of 2048 bits, the SHA-256 message digest algorithm, and UTF-8 encoding. It also prompts for the distinguished name (DN) and specifies the desired extensions for the CSR. The `codesign_dn` section specifies the common name for the certificate as `the-company.com`, while the `codesign_reqext` section specifies the key usage, extended key usage, and subject key identifier for the certificate. This configuration file can be used with the `openssl req` command to generate a CSR for code signing purposes.\n\n```shell\nopenssl req -new -newkey rsa:2048 -keyout testsign.key -sha256 -nodes -out testsign.csr -subj \"/CN=The Company Engineering Code Sign Cert\" -config code_sign_csr.conf\n```\n\nThis code generates a new RSA private key with a length of 2048 bits and a new certificate signing request (CSR) using the `openssl req` command. The private key is saved in a file named `testsign.key`, and the CSR is saved in a file named `testsign.csr`. The `-new` option specifies that a new CSR should be created, while the `-newkey` option specifies that a new private key should be generated. The `-nodes` option specifies that the private key should not be encrypted. The `-sha256` option specifies the hash algorithm to use for the CSR. The `-subj` option specifies the subject of the CSR, which includes the common name `The Company Engineering Code Sign Cert`. The `-config` option specifies the configuration file to use for the CSR, which is `code_sign_csr.conf`. This command is commonly used to generate a CSR for code signing purposes.\n\n```shell\ncat \u003c\u003c EOF \u003e code_sign_cert.conf\nauthorityKeyIdentifier=keyid,issuer\nbasicConstraints=CA:FALSE\nsubjectAltName = @alt_names\n[alt_names]\nDNS.1 = fastly.com\nEOF\n```\n\nThis code creates a configuration file named `code_sign_cert.conf` with settings for generating a code signing certificate. The configuration file specifies the authority key identifier, basic constraints, and subject alternative name (SAN) for the certificate. The `authorityKeyIdentifier` option specifies the key identifier and issuer of the certificate authority (CA) that issued the certificate. The `basicConstraints` option specifies that the certificate is not a CA. The `subjectAltName` option specifies the SAN for the certificate, which is defined in the `alt_names` section. In this case, the SAN is a DNS name `fastly.com`. This configuration file can be used with the `openssl x509` command to generate a code signing certificate.\n\n```shell\nopenssl x509 -req -CA rootCA.crt -CAkey rootCA.key -in testsign.csr -out testsign.crt -days 365 -CAcreateserial -extfile code_sign_cert.conf\n```\n\nThis code generates a code signing certificate using the `openssl x509` command. The certificate is generated by signing the certificate signing request (CSR) stored in the `testsign.csr` file with the root certificate authority (CA) key stored in the `rootCA.key` file. The resulting certificate is saved in the `testsign.crt` file. The `-req` option specifies that a CSR is being used as input. The `-CA` and `-CAkey` options specify the root CA certificate and key to use for signing the CSR. The `-days` option specifies the validity period of the certificate, which is set to 365 days. The `-CAcreateserial` option specifies that a serial number file should be created for the CA. The `-extfile` option specifies the configuration file to use for the certificate, which is `code_sign_cert.conf`. This command is commonly used to generate a code signing certificate for signing software or code.\n\n```shell\nopenssl x509 -in testsign.crt -noout -text\nopenssl x509 -in rootCA.crt -noout -text\n```\n\nThese commands display the details of the X.509 certificates stored in the `testsign.crt` and `rootCA.crt` files, respectively. The `-in` option specifies the input file containing the certificate. The `-noout` option specifies that no output should be generated other than the certificate details. The `-text` option specifies that the certificate should be displayed in human-readable text format. The output includes information such as the certificate version, serial number, signature algorithm, issuer and subject distinguished names, validity period, public key information, and any extensions included in the certificate. These commands are commonly used to inspect the details of X.509 certificates.\n\n```shell\nopenssl pkcs12 -export -out testsign.p12 -inkey testsign.key -in testsign.crt\nopenssl pkcs12 -export -out rootCA.p12 -inkey rootCA.key -in rootCA.crt\n```\n\nThese commands create PKCS#12 files containing the private key and certificate for the `testsign` and `rootCA` entities, respectively. The `-export` option specifies that a PKCS#12 file should be created. The `-out` option specifies the output file name. The `-inkey` option specifies the input file containing the private key. The `-in` option specifies the input file containing the certificate. The resulting PKCS#12 file contains the private key and certificate in a password-protected format. These commands are commonly used to export a private key and certificate for use in other systems or applications.\n\n\n## UPDATE\n\nI asked AI to generate code to produce a Software Publishing Certificate (spc) and it gave me back...\n\n```shell\nopenssl req -x509 -newkey rsa:2048 -keyout private_key.pem -out spc.pem -days 365 -nodes\n```\n\nThis code generates a self-signed X.509 certificate using the RSA private key generated by the `openssl req` command. The private key is saved in a file named `private_key.pem`, and the certificate is saved in a file named `spc.pem`. The `-x509` option specifies that a self-signed certificate should be generated, while the `-newkey` option specifies that a new private key should be generated. The `-nodes` option specifies that the private key should not be encrypted. The `-days` option specifies the validity period of the certificate, which is set to 365 days. This command is commonly used to generate a self-signed certificate for testing or development purposes.\n","tags":"#openssl #cert #codesign #AI"},{"id":"abbffe4c06712f46db1bcffdd82ef652","title":"Shell: single line Ruby script in shell ","content":"cat tokens.txt | xargs -I % ruby -e 'require \"digest\"; puts Digest::SHA256.hexdigest(\"%\")'\n","tags":"#ruby #shell #script"},{"id":"57accaf446cf3e7974cd01d57158532c","title":"AWK: extract first changelog entry ","content":"We want just the 'v1.0.0-beta.2' changelog block, not 'v1.0.0-beta.1'...\n\n```\n# Changelog\n\n## [v1.0.0-beta.2](...)\n\n**Bug fixes:**\n\n- ...\n\n**Enhancements:**\n\n- ...\n- ...\n\n**Documentation:**\n\n- ...\n- ...\n- ...\n\n## [v1.0.0-beta.1](...)\n\n**Enhancements:**\n\n* More stuff\n\n...\n```\n\nThe following awk script does this for us...\n\n```shell\ncat CHANGELOG.md | awk '/^##/{block++} {if (block==1) {print}}'\n```\n\nAwk works by reading the input 'line by line'. Our script checks if the conditional pattern `^##`  matches, which is the start of the changelog entry, and if so it increments the variable `block`. Next, it checks the variable value and prints each line as long as the variable is equal to `1`. \n\nThe moment we reach the next changelog entry, the `block` variable will be incremented to `2` and so the block that prints each line will not execute.\n","tags":"#awk #changelog"},{"id":"e27f16821806aa8037c442d805fc2e44","title":"Git: Generate change log between two tags ","content":"#!/bin/bash\n\ntags=$(git for-each-ref --sort=-creatordate --format '%(refname) %(creatordate)' refs/tags | grep -Eo 'client/rust@v?[^ ]+')\nlatest_tag=$(echo \"$tags\" | head -n 1)\nsecond_tag=$(echo \"$tags\" | head -n 2 | tail -1)\nrelease_version=$(echo \"$latest_tag\" | cut -d @ -f 2)\n\n# echo \"all tags for this language: $tags\"\n# echo \"latest tag: $latest_tag\"\n# echo \"second tag: $second_tag\"\n\nchanges=$(git log --pretty=\"- %s\" \"$latest_tag\"...\"$second_tag\" --no-merges)\n\n# echo \"$changes\"\n\n# NOTE: xargs trims whitespace\nprintf \"# \\`v$release_version\\`\\n\\n## CHANGES (commits: $(echo \"$changes\" | wc -l | xargs))\\n\\n$changes\\n\" \u003e release_notes.md\n\n","tags":"#changelog #git"},{"id":"bdc3a6391682d351516ebcf766229e5b","title":"Go: spinner ","content":"package main\n\nimport (\n\t\"time\"\n\n\t\"github.com/theckman/yacspin\"\n)\n\nfunc main() {\n\tspinner, _ := yacspin.New(yacspin.Config{\n\t\tCharSet:           yacspin.CharSets[9],\n\t\tFrequency:         100 * time.Millisecond,\n\t\tStopCharacter:     \"✓\",\n\t\tStopColors:        []string{\"fgGreen\"},\n\t\tStopFailCharacter: \"✗\",\n\t\tStopFailColors:    []string{\"fgRed\"},\n\t\tSuffix:            \" \",\n\t\t// NotTTY:            true,\n\t})\n\n\t_ = spinner.Start()\n\tspinner.Message(\"1.\")\n\n\ttime.Sleep(4 * time.Second)\n\n\tspinner.Message(\"2.\")\n\n\ttime.Sleep(4 * time.Second)\n\n\tspinner.StopMessage(\"2.\")\n\n\t_ = spinner.Stop()\n\n\t_ = spinner.Start()\n\n\tspinner.Message(\"3.\")\n\n\ttime.Sleep(4 * time.Second)\n\n\tspinner.StopFailMessage(\"3.\")\n\n\t_ = spinner.StopFail()\n}\n","tags":"#go #spinner"},{"id":"bc358eb37de04fa536e34fcc4a7e8cba","title":"Perl: add language to markdown code block ","content":"```bash\n# Ensure all code blocks without a language get 'plain' appended.\n# NOTE: constraint is that there needs to be an empty line preceding the code block.\ncat file.mdx | perl -pe 'BEGIN { undef $/ }; s/(?\u003c=^\\n)(```)(\\n.+?```)/\\1plain\\2/s'\n```\n\n\u003e **NOTE**: The Perl variable `$/` stores the line ending, used for processing files line-by-line. By calling `undef` on it, we cause Perl to slurp the entire file all in one string at once for us to process.\n\u003e\n\u003e **WARNING**: If the code block has a non-empty preceding line, and the contents of the code block has an empty line before the closing code fence, then the current pattern will accidentally match. So if that's the case, we need to ensure all code blocks don't have an unnecessary empty line at the bottom of them.\nExample: https://regex101.com/r/6wcYU9/1\n\nThe following block will get `plain` appended:\n\n```\nContent here\n```\n\nAnd this one:\n\n```\nContent here\n```\n\nBUT for this to work we expect the code block to have an empty line preceding it.\n\nSo the following will NOT get `plain` appended because it violates the empty preceding line expectation:\n\na non-empty line before the code block\n```\ncontent here\n```\n\nHere is a code block that has a language already:\n\n```http\nsome text here\n```\n\nOne more time, let's see an expected code block match:\n\n```\nsome stuff\n```\n","tags":"#perl #regex #codeblock #markdown"},{"id":"1e9df4944e366e46471953864858ff7e","title":"Go: recursively search for a file until reaching user's home directory ","content":"package main\n\nimport (\n\t\"errors\"\n\t\"fmt\"\n\t\"os\"\n\t\"path/filepath\"\n)\n\nfunc main() {\n\t// NOTE: Changing to /tmp was to catch issue with user not running under HOME.\n\terr := os.Chdir(\"/tmp\")\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\n\twd, err := os.Getwd()\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\n\thome, err := os.UserHomeDir()\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\n\terr = recurse(wd, home)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n}\n\nfunc recurse(wd, home string) error {\n\tparent := filepath.Dir(wd)\n\n\tvar noManifest bool\n\tpath := filepath.Join(wd, \"package.json\")\n\tfmt.Println(\"checking\", path)\n\tif _, err := os.Stat(path); errors.Is(err, os.ErrNotExist) {\n\t\tnoManifest = true\n\t}\n\n\tif !noManifest {\n\t\tfmt.Println(\"found a manifest!\")\n\t\treturn nil\n\t}\n\n\t// NOTE: The first condition catches if we reach the user's 'root' directory.\n\tif wd != parent \u0026\u0026 wd != home {\n\t\treturn recurse(parent, home)\n\t}\n\n\tfmt.Println(\"no manifest found\")\n\treturn nil\n}\n","tags":"#go #search #recursive"},{"id":"0f0a549adc4af44167a7222725767eb6","title":"Rust: flatten vector of Results ","content":"use std::result::Result::{Ok, Err};\n\nfn main() {\n    let v = vec![Ok(\"foo\"), Ok(\"bar\"), Err(\"whoops\"), Ok(\"baz\")]; // Err should be skipped\n    for r in v.into_iter().flatten() {\n        println!(\"{:#?}\", r);\n    }\n}\n\n/*\n\"foo\"\n\"bar\"\n\"baz\"\n*/\n","tags":"#rust"},{"id":"62b7ba713197ee331d80cb3479903ff3","title":"Go: remove cookie from http.Request ","content":"// For proxy situations where you want to strip a cookie from the incoming request at the proxy layer, before proxying it onto the actual backend.\n\npackage main\n\nimport (\n\t\"fmt\"\n\t\"net/http\"\n)\n\nfunc main() {\n\treq := \u0026http.Request{\n\t\tHeader: make(http.Header),\n\t}\n\treq.Header.Add(\"Cookie\", \"name1=value; name2=value2; name3=value3\")\n\tfmt.Printf(\"%+v\\n\", req.Header)\n\tFilterClientCookies(req, \"name2\")\n\tfmt.Printf(\"%+v\\n\", req.Header)\n}\n\n// FilterClientCookies removes a list of cookies from the \"Cookie\" request header by name.\nfunc FilterClientCookies(r *http.Request, names ...string) {\n\tfilter := make(map[string]struct{}, len(names))\n\tfor _, name := range names {\n\t\tfilter[name] = struct{}{}\n\t}\n\n\tcookies := r.Cookies()\n\tr.Header.Del(\"Cookie\")\n\n\tfor _, c := range cookies {\n\t\tif _, ok := filter[c.Name]; ok {\n\t\t\tcontinue\n\t\t}\n\t\tr.Header.Add(\"Cookie\", fmt.Sprintf(\"%s=%s\", c.Name, c.Value))\n\t}\n}\n// For proxy situations where you want to strip a cookie from the incoming request at the proxy layer, before proxying it onto the actual backend.\n\npackage main\n\nimport (\n\t\"fmt\"\n\t\"net/http\"\n\t\"strings\"\n)\n\nfunc main() {\n\th := make(http.Header)\n\th.Add(\"Cookie\", \"name1=value; name2=value2; name3=value3\")\n\tfmt.Printf(\"%+v\\n\", h)\n\n\tcs := strings.Split(h.Get(\"Cookie\"), \";\")\n\th.Del(\"Cookie\")\n\n\tcookieToRemove := \"name2\"\n\tfor _, c := range cs {\n\t\ts := strings.TrimSpace(c)\n\t\tif strings.HasPrefix(s, fmt.Sprintf(\"%s=\", cookieToRemove)) {\n\t\t\tcontinue\n\t\t}\n\t\th.Add(\"Cookie\", s)\n\t}\n\n\tfmt.Printf(\"%+v\\n\", h)\n}\n\nfunc removeFromSlice(s []string, i int) []string {\n\ts[i] = s[len(s)-1]\n\treturn s[:len(s)-1]\n}\n","tags":"#go #http"},{"id":"f9d739957cdec30a6a55b87862175c06","title":"API Clients: Publishing packages for multiple languages ","content":"# Manual release process\n\nThe following steps describe the manual steps to take so you can publish a specific Fastly API client.\n\n## fastly-go\n\n- Clone https://github.com/fastly/fastly-go\n- Run `tag=\"v1.0.0-beta.0\" \u0026\u0026 git tag -s $tag -m $tag \u0026\u0026 git push origin $tag`\n- Create a new 'release' https://github.com/fastly/fastly-go/releases\n- Check https://pkg.go.dev/github.com/fastly/fastly-go for latest release\n\n## fastly-js\n\n- Clone https://github.com/fastly/fastly-js\n- Run `tag=\"v3.0.0\" \u0026\u0026 git tag -s $tag -m $tag \u0026\u0026 git push origin $tag`\n- Run `npm login` and follow instructions\n- Run `npm publish --dry-run` and check there are no errors\n- Run `npm publish` to publish the module to https://www.npmjs.com/package/fastly\n\n\u003e **Reference**: https://docs.npmjs.com/cli/v9/commands/npm-publish\n\n## fastly-perl\n\n...\n\n## fastly-php\n\n- Clone https://github.com/fastly/fastly-php\n- Run `tag=\"v1.0.0\" \u0026\u0026 git tag -s $tag -m $tag \u0026\u0026 git push origin $tag`\n- Create a new 'release' https://github.com/fastly/fastly-php/releases\n- Check https://packagist.org/packages/fastly/fastly for latest release\n\n## fastly-py\n\n- Clone https://github.com/fastly/fastly-py\n- Run `tag=\"v1.0.0\" \u0026\u0026 git tag -s $tag -m $tag \u0026\u0026 git push origin $tag`\n- Run `python3 -m pip install --upgrade build \u0026\u0026 python3 -m build` to build the package\n- Run `python3 -m pip install --upgrade twine \u0026\u0026 python3 -m twine upload --repository pypi dist/*` to publish the package to https://pypi.org/project/fastly/\n\n\u003e **Reference**: https://packaging.python.org/en/latest/tutorials/packaging-projects/\n\n## fastly-ruby\n\n- Clone https://github.com/fastly/fastly-ruby\n- Run `tag=\"v4.0.0\" \u0026\u0026 git tag -s $tag -m $tag \u0026\u0026 git push origin $tag`\n- Create a new 'release' https://github.com/fastly/fastly-ruby/releases\n- Run `gem build fastly.gemspec`\n- Run `gem push fastly-4.0.0.gem`\n\n## fastly-rust\n\n- Clone https://github.com/fastly/fastly-rust \n- Run `cargo login` and following instructions\n- Run `cargo publish --dry-run` and check there are no errors\n- Run `cargo publish` to publish the crate to https://crates.io/crates/fastly-api\n\n\u003e **Reference**: https://doc.rust-lang.org/cargo/reference/publishing.html\n\n","tags":"#publish #package #ruby #php #python #go #js #javascript #rust #api #clients"},{"id":"9136adf9891c3e93480b02aa32de3b8a","title":"Go: Getting package documentation published ","content":"- Run `tag=\"v1.0.0-beta.0\" \u0026\u0026 git tag -s $tag -m $tag \u0026\u0026 git push origin $tag`\n- Create a new 'release' https://github.com/fastly/fastly-go/releases\n- Run `GOPROXY=https://proxy.golang.org go get github.com/fastly/fastly-go@v1.0.0-beta.0`\n- Check https://proxy.golang.org/github.com/fastly/fastly-go/@v/v1.0.0-beta.0.info\n- Wait a bit and then check https://pkg.go.dev/github.com/fastly/fastly-go\n","tags":"#go #pkg #docs"},{"id":"a265f0d352379a8d484e65b71f7ac511","title":"Terraform: Debugging Variables ","content":"https://www.terraform.io/internals/debugging\n\n- `TF_LOG`: `TRACE`, `DEBUG`, `INFO`, `WARN` or `ERROR` (or `JSON` which is JSON formatted `TRACE` logs).\n- `TF_LOG_CORE`: only terraform logs.\n- `TF_LOG_PROVIDER`: only provider logs.\n- `TF_LOG_PATH`: set along with one of the above to ensure logs are sent to a file.\n","tags":"#terraform #debug #log"},{"id":"be72bd063606fd36c38403791a638d0e","title":"Rust: Smart Pointers ","content":"## Summary\n\n- `Box\u003cT\u003e`: A pointer type for heap allocation.\n- `Rc\u003cT\u003e`: A read-only, single-threaded reference-counting (i.e. multiple owners) pointer Ω.\n- `Arc\u003cT\u003e`: A read-only, thread-safe (i.e. extra performance overhead) reference-counting (i.e. multiple owners) pointer †.\n- `Cell\u003cT\u003e`: A single-threaded mutable memory location (where values are _moved_ in and out of the cell).\n- `RefCell\u003cT\u003e`: A single-threaded mutable memory location with dynamically checked (i.e. at _runtime_) borrow rules.\n\n\u003e Ω Wrap the value inside the `Rc` with either `Cell\u003cT\u003e` or `RefCell\u003cT\u003e` for mutability.  \n\u003e † Wrap the value inside the `Arc` with either `Mutex`, `RwLock` or one of the `Atomic*` types for mutability.\n\n\u003e **NOTE**: Not discussed here are `Mutex\u003cT\u003e` and `RwLock\u003cT\u003e`, which provide mutual-exclusion.\n\n## Context\n\nA _pointer_ is a general concept for a variable that contains an address in memory. This address refers to, or “points at,” some other data. The most common kind of pointer in Rust is a reference. References are indicated by the \u0026 symbol and borrow the value they point to. They don’t have any special capabilities other than referring to data, and have no overhead.\n\n_Smart pointers_, on the other hand, are data structures that act like a pointer but also have additional metadata and capabilities.\n\n\u003e **NOTE**: Both `String` and `Vec\u003cT\u003e` types count as smart pointers because they own some memory and allow you to manipulate it. They also have metadata and extra capabilities or guarantees. \n\nSmart pointers are usually implemented using structs. Unlike an ordinary struct, smart pointers implement the `Deref` and `Drop` traits. The `Deref` trait allows an instance of the smart pointer struct to behave like a reference so you can write your code to work with either references or smart pointers. The `Drop` trait allows you to customize the code that's run when an instance of the smart pointer goes out of scope.\n\n## `Box\u003cT\u003e`\n\nBoxes allow you to store data on the heap rather than the stack. What remains on the stack is the pointer to the heap data.\n\nUsage:\n\n- When you have a type whose size can’t be known at compile time and you want to use a value of that type in a context that requires an exact size (e.g. recursive data types).\n- When you have a large amount of data and you want to transfer ownership but ensure the data won’t be copied when you do so (e.g. only the small amount of pointer data is copied around on the stack, while the data it references stays in one place on the heap).\n- When you want to own a value and you care only that it’s a type that implements a particular trait rather than being of a specific type (i.e. _trait objects_ used for dynamic dispatch).\n\n## `Rc\u003cT\u003e`\n\nThis type is an abbreviation for _reference counting_ and it enables multiple ownership. It lets us have multiple “owning” pointers to the same data, and the data will be freed (destructors will be run) when all pointers are out of scope.\n\nWe use the `Rc\u003cT\u003e` type when we want to allocate some data on the heap for multiple parts of our program to read and we can’t determine at compile time which part will finish using the data last. \n\n\u003e **NOTE**: `Rc\u003cT\u003e` is only for use in single-threaded scenarios. When shared ownership between threads is needed, `Arc\u003cT\u003e` (Atomic Reference Counted) can be used.\n\n## `Arc\u003cT\u003e`\n\nThe same as `Rc\u003cT\u003e` but thread-safe (it has the same API as `Rc\u003cT\u003e` to make them interchangeable). But thread-safety comes with a performance cost so if you don't need thread-safety, then definitely opt for `Rc\u003cT\u003e` instead.\n\n## `Cell\u003cT\u003e`/`RefCell\u003cT\u003e`\n\nRust memory safety is based on this rule: Given an object `T`, it is only possible to have one of the following:\n\n- Having several immutable references (`\u0026T`) to the object.\n- Having one mutable reference (`\u0026mut T`) to the object.\n\nThis rule can be bent using `Cell\u003cT\u003e` and is referred to as _interior mutability_.\n\n`Cell\u003cT\u003e` implements interior mutability by moving values in and out of the `Cell\u003cT\u003e`. \n\nTo use references instead of values, use the `RefCell\u003cT\u003e` type, and acquire a write lock before mutating.\n\nBorrows for `RefCell\u003cT\u003e`s are tracked _at runtime_, unlike Rust’s native reference types which are entirely tracked statically, at compile time. Because `RefCell\u003cT\u003e` borrows are _dynamic_ it is possible to attempt to borrow a value that is already mutably borrowed; when this happens it results in thread panic.\n\n\u003e **NOTE**: Neither `Cell\u003cT\u003e` nor `RefCell\u003cT\u003e` are thread safe (they do not implement `Sync`).\n\nMany shared smart pointer types, including `Rc\u003cT\u003e` and `Arc\u003cT\u003e`, provide containers that can be cloned and shared between multiple parties. The contained values can only be borrowed with `\u0026`, not `\u0026mut`. Without cells it would be impossible to mutate data inside of these smart pointers at all.\n\nIt’s very common then to put a `RefCell\u003cT\u003e` inside shared pointer types to reintroduce mutability. But as `RefCell\u003cT\u003e`s are for single-threaded scenarios, consider using `RwLock\u003cT\u003e` or `Mutex\u003cT\u003e` instead of `RefCell\u003cT\u003e` if you need shared mutability in a multi-threaded situation.\n","tags":"#rust"},{"id":"d9ba0028ce7c6b90280f73c71cb27cf5","title":"Shell: Write to a variable multiple times before writing to disk ","content":"function bar {\n  example=$(echo \"$example\" | rg $1 \\\n    --case-sensitive \\\n    --type go \\\n    --type md \\\n    --color never \\\n    --no-line-number \\\n    --passthru \\\n    --replace $2)\n}\n\nfunction foo {\n  example=$(\u003cfastly-go/go.mod)\n  bar \"github\" \"GITHUB\"\n  bar \"google\" \"GOOGLE\"\n  echo \"$example\" \u003e final.txt\n  cat final.txt\n  rm final.txt\n}\n\nfoo\n","tags":"#bash #shell #performance"},{"id":"dd65c727ea3aabe3333d7995eb9665c9","title":"Rust: Tokio Spawn and Retry ","content":"use std::any::type_name;\nuse tokio_retry::strategy::{jitter, FixedInterval};\nuse tokio_retry::Retry;\n\n#[derive(Debug)]\nstruct ImageId {\n    id: Option\u003cString\u003e,\n}\n\nasync fn action() -\u003e Result\u003cImageId, ()\u003e {\n    println!(\"action(): doing stuff async\");\n    Ok(ImageId {\n        id: Some(String::from(\"some id\")),\n    })\n}\n\nasync fn something() -\u003e Result\u003cu64, ()\u003e {\n    Ok(999)\n}\n\nasync fn something_with_an_arg(n: u8) -\u003e Result\u003cu8, ()\u003e {\n    Ok(n)\n}\n\nasync fn something_with_an_arg_that_errors() -\u003e Result\u003cu8, ()\u003e {\n    Err(())\n}\n\nfn type_of\u003cT\u003e(_: \u0026T) {\n    println!(\"type_of(): {}\", type_name::\u003cT\u003e())\n}\n\n#[tokio::main]\nasync fn main() -\u003e Result\u003c(), ()\u003e {\n    let handle = tokio::spawn(async move { action().await });\n\n    type_of(\u0026handle);\n\n    // Calling await returns a Result containing whatever was returned from the `async` closure\n    // executed from inside the `spawn` method. In this case another Result which was returned by\n    // the `action()` async function. That nested Result contains the ImageId struct.\n    let task = handle.await;\n    println!(\"task: {:?}\", task); // Ok(Ok(ImageId { id: Some(\"some id\") }))\n    println!(\"task unwrapped: {:?}\", task.unwrap().unwrap().id.unwrap()); // \"some id\"\n\n    let retry_strategy = FixedInterval::from_millis(1000)\n        .map(jitter) // add jitter to delays\n        .take(10); // limit to 10 retries\n\n    let result = Retry::spawn(retry_strategy.clone(), action).await?;\n    println!(\"retry result.id from action(): {:#?}\", result.id);\n\n    // Demonstrating how to pass arguments to an asynchronous function by way of defining an async\n    // block first and calling the async function from within it (as the Retry::spawn method\n    // doesn't allow us to pass arguments to the specified 'action').\n    //\n    // NOTE: You can't use the ? operator within an async block as a closure can't bubble up the\n    // error type. Although, that said I didn't try specifying a specific return type using -\u003e so\n    // maybe it would work. For the purposes of this example it doesn't matter.\n    let result = Retry::spawn(retry_strategy.clone(), || async {\n        println!(\"doing stuff async in a closure\");\n        something().await\n    })\n    .await?;\n    println!(\"retry result from closure: {}\", result);\n\n    // We have to clone this to avoid 'move' semantic issues that we otherwise would encounter if\n    // we just tried to call retry_strategy.clone() as the argument inside the tokio::spawn's async\n    // block. This happens because we move retry_strategy into the first async block, and then when\n    // we do another spawn later we'd then try and move it when it has already been moved. I didn't\n    // realise that it would be moved because I was calling .clone() and so expected the cloned\n    // instance to be moved, but it kinda makes sense that the variable itself is moved.\n    //\n    // Maybe we could avoid this with a reference, but I'm trying to keep the example as close to a\n    // real project I'm trying to include Retry::spawn into.\n    let clone_strategy = retry_strategy.clone();\n\n    // Demonstrating that the async block can return any type of data, and also that we're able to\n    // do a retry operation within a tokio spawned task.\n    let handle = tokio::spawn(async move {\n        (\n            \"some random key\",\n            Retry::spawn(clone_strategy, action).await,\n        )\n    });\n    let task = handle.await;\n    println!(\"task: {:?}\", task); // Ok(Ok(ImageId { id: Some(\"some id\") }))\n\n    // Demonstrating the same as above, but additionally the use of a closure to allow us to pass\n    // arguments to the Retry::spawn 'action'.\n    //\n    // NOTE: If the argument value 123 passed to something_with_an_arg was a complex type (e.g. a\n    // type that doesn't implement Copy), then this would cause an error related to the closure\n    // implementing FnOnce and not the required FnMut (that Retry::spawn expects). See here\n    // https://stackoverflow.com/a/30232500/14849316 explanation of FnOnce, FnMut and Fn. But in\n    // essence we might be moving a type from the closure's environment into the\n    // something_with_an_arg and that would mean it's FnOnce. The solution would be to change the\n    // signature for something_with_an_arg to accept a reference so we pass a reference as the\n    // argument type and thus the closure becomes FnMut because it doesn't move any variables.\n    let clone_strategy = retry_strategy.clone();\n    let handle = tokio::spawn(async move {\n        (\n            \"some random key\",\n            Retry::spawn(clone_strategy, || async {\n                something_with_an_arg(123).await\n            })\n            .await,\n        )\n    });\n    let task = handle.await;\n    println!(\"task: {:?}\", task); // Ok(Ok(ImageId { id: Some(\"some id\") }))\n\n    // NOTE: retry_strategy has now 'moved' into (i.e. been consumed by) the async block so it\n    // can't be used again after this point in the code (see above `clone_strategy` variables).\n    let handle = tokio::spawn(async move {\n        (\n            \"some random key\",\n            Retry::spawn(retry_strategy.clone(), || async {\n                println!(\"trying a function that errors\");\n                something_with_an_arg_that_errors().await\n            })\n            .await,\n        )\n    });\n    let task = handle.await;\n    println!(\"task: {:?}\", task); // Ok(Ok(ImageId { id: Some(\"some id\") }))\n\n    Ok(())\n}\n","tags":"#rust #async #retry"},{"id":"86a7d94a832b432b5139ad28c074df32","title":"JS: Getting JS module published ","content":"- Run `tag=\"v3.0.0\" \u0026\u0026 git tag -s $tag -m $tag \u0026\u0026 git push origin $tag`\n- Run `npm login` and follow instructions\n- Run `npm publish --dry-run` and check there are no errors\n- Run `npm publish` to publish the module to https://www.npmjs.com/package/fastly\n","tags":"#js #javascript #npm #module"},{"id":"b065aea92c072d5b9ce7d6a829204155","title":"JS: sort two-dimensional Array ","content":"// sortBy accepts a two-dimensional array (results) and an array that indicates\n// the required ordering for the data based on the given groupings (groups).\n//\n// EXAMPLE:\n// The following inputs:\n//\n//    results = [[\"Foo\", 3], [\"Bar\", 2], [\"Baz\", 1]]\n//    groups  = [\"Baz\", \"Bar\", \"Foo\"]\n//\n//  Will sort the results into:\n//\n//    [[\"Baz\", 1], [\"Bar\", 2], [\"Foo\", 3]]\n//\nfunction sortBy(results, groups) {\n  groups.reverse().forEach((name) =\u003e {\n    // This line ensures 'name' is the first element in the 'results' array.\n    // By iterating over the given 'groups' in reverse we can enforce the required ordering.\n    // All other elements are left in-place.\n    results.sort((a, _) =\u003e (a[0] === name ? -1 : 0))\n  })\n}\n","tags":"#js #javascript #sort"},{"id":"89ad7fe05f72941b87c6e3512c30d940","title":"RipGrep: inline file replacements ","content":"#!/bin/bash\n\n# DESCRIPTION:\n# Replaces all instances where...\n#\n#   `Id` should be `ID`\n#   `Acl` should be `ACL`\n#   `Http` should be `HTTP`\n#\n# DEPENDENCIES:\n# brew install ripgrep\n\nCLIENT=$1\n\nfunction replace {\n  local pattern=$1\n  local replacement=$2\n  local file=$3\n\n  rg $1 \\\n    --case-sensitive \\\n    --type go \\\n    --type md \\\n    --color never \\\n    --no-line-number \\\n    --passthru \\\n    --replace $2 \\\n    \"$file\" \u003e tmp.txt \u0026\u0026 mv tmp.txt \"$file\"\n\n  rm tmp.txt 2\u003e /dev/null\n}\n\nFILES=\"./$CLIENT/**/*\"\nfor f in $FILES\ndo\n  echo \"Processing $f...\"\n  # ID\n  replace '\\b(\\w+)Id([A-Z]\\w+)?\\b' '${1}ID${2}' \"$f\"\n  # ACL\n  replace '([a-z])?Acl(\\w+)?\\b' '${1}ACL${2}' \"$f\"\n  # HTTP\n  replace '([a-z])?Http(\\w+)?\\b' '${1}HTTP${2}' \"$f\"\ndone\n\ncd ./tests/simple-client-test/go-client-test\ngo run main.go\ncd -\n","tags":"#riggrep #rg #sed #replacement #bash #shell"},{"id":"a7a84316dd7fd210b06e813fc799246f","title":"Rust: Basic parsing of go.mod with Rust ","content":"[package]\nname = \"testing-parse-gomod\"\nversion = \"0.1.0\"\nedition = \"2021\"\n\n# See more keys and their definitions at https://doc.rust-lang.org/cargo/reference/manifest.html\n\n[dependencies]\nsemver = \"1.0.4\"\nmodule whatever\n\ngo 1.18\n\nrequire example.com/foo/bar v1.0.0\nrequire example.com/foo/bar/v2 v2.0.0\n\nrequire (\n    example.com/beep/boop v3.0.0\n    example.com/quick/quack v4.0.0\n)\n\nrequire (\n    example.com/something/else v5.0.0\n)\n// https://go.dev/ref/mod#go-mod-file-require\n// https://go.dev/ref/mod#pseudo-versions\n\nuse semver::Version;\n\ntype AvailableDependency = (String, Version, Vec\u003cString\u003e);\n\nconst GO_MOD: \u0026str = include_str!(\"../go.mod\");\n\nfn main() {\n    let mut block = false;\n    let deps: Vec\u003cAvailableDependency\u003e = GO_MOD\n        .lines()\n        .filter_map(|v| {\n            let segs: Vec\u003c\u0026str\u003e = v.split(' ').collect();\n            if segs.len() == 1 {\n                if segs[0] == \")\" {\n                    block = false;\n                }\n                return None;\n            }\n            if block {\n                let nested_dep: Vec\u003c_\u003e = segs.iter().filter(|v| !v.is_empty()).collect();\n                let mut version = nested_dep[1].chars();\n                version.next();\n\n                return Some((\n                    nested_dep[0].to_string(),\n                    Version::parse(version.as_str())\n                        .expect(\"could not parse default dependency version\"),\n                    vec![],\n                ));\n            }\n            if segs[0] == \"require\" {\n                if segs[1] == \"(\" {\n                    block = true;\n                    return None;\n                }\n\n                let slice = \u0026segs[1..];\n                let mut version = slice[1].chars();\n                version.next();\n\n                return Some((\n                    slice[0].to_string(),\n                    Version::parse(version.as_str())\n                        .expect(\"could not parse default dependency version\"),\n                    vec![],\n                ));\n            }\n            None\n        })\n        .collect();\n\n    println!(\"{:#?}\", deps);\n}\n","tags":"#rust #go #serialization"},{"id":"91ebbc27690439687a804fa6860fd355","title":"Auth: CLI Device Authorization Flow with Auth0 ","content":"package authenticate\n\n// https://auth0.com/docs/get-started/authentication-and-authorization-flow/device-authorization-flow\n// https://auth0.com/docs/get-started/authentication-and-authorization-flow/call-your-api-using-the-device-authorization-flow\n\nimport (\n\t\"encoding/json\"\n\t\"fmt\"\n\t\"io\"\n\t\"net/http\"\n\t\"net/url\"\n\t\"strings\"\n\t\"time\"\n\n\t\"github.com/fastly/cli/pkg/cmd\"\n\t\"github.com/fastly/cli/pkg/config\"\n\tfsterr \"github.com/fastly/cli/pkg/errors\"\n\t\"github.com/fastly/cli/pkg/text\"\n)\n\n// RootCommand is the parent command for all subcommands in this package.\n// It should be installed under the primary root command.\ntype RootCommand struct {\n\tcmd.Base\n}\n\n// Auth0DeviceCodeURL is the Auth0 device code URL.\nconst Auth0DeviceCodeURL = \"https://\u003cYOUR_DOMAIN\u003e.us.auth0.com\"\n\n// Auth0ClientID is the Auth0 Client ID.\nconst Auth0ClientID = \"\u003cYOUR_CLIENT_ID\u003e\"\n\n// Auth0Audience is the unique identifier of the API your app wants to access.\nconst Auth0Audience = \"https://\u003cYOUR_API\u003e/\"\n\n// Auth0GrantType is an extension grant type (MUST be URL encoded).\nvar Auth0GrantType = url.QueryEscape(\"urn:ietf:params:oauth:grant-type:device_code\")\n\n// NewRootCommand returns a new command registered in the parent.\nfunc NewRootCommand(parent cmd.Registerer, globals *config.Data) *RootCommand {\n\tvar c RootCommand\n\tc.Globals = globals\n\tc.CmdClause = parent.Command(\"authenticate\", \"Authenticate with Fastly (returns temporary, auto-rotated, API token)\")\n\treturn \u0026c\n}\n\n// Exec implements the command interface.\nfunc (c *RootCommand) Exec(_ io.Reader, out io.Writer) error {\n\tdeviceCodeResponse, err := getDeviceCode()\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tintro := \"Please open the following URL and enter your user code: \" + deviceCodeResponse.UserCode\n\ttext.Description(out, intro, deviceCodeResponse.VerificationURI)\n\n\tvar accessTokenResponse chan *AccessTokenResponse\n\n\tinterval := time.Duration(deviceCodeResponse.Interval) * time.Second\n\tdeviceCodeExpiration := time.Duration(deviceCodeResponse.ExpiresIn) * time.Second\n\n\tgo pollForAccessToken(\n\t\tdeviceCodeResponse.DeviceCode,\n\t\tinterval,\n\t\tdeviceCodeExpiration,\n\t\taccessTokenResponse,\n\t\tc.Globals.ErrLog,\n\t)\n\n\tselect {\n\tcase atr := \u003c-accessTokenResponse:\n\t\tfmt.Printf(\"%+v\\n\", atr)\n\tcase \u003c-time.After(deviceCodeExpiration):\n\t\treturn fsterr.RemediationError{\n\t\t\tInner:       fmt.Errorf(\"user code expired\"),\n\t\t\tRemediation: \"Please re-run the command and complete the authorization flow.\",\n\t\t}\n\t}\n\n\treturn nil\n}\n\n// getDeviceCode retrieves a device code from Auth0.\nfunc getDeviceCode() (deviceCodeResponse DeviceCodeResponse, err error) {\n\tpath := \"/oauth/device/code\"\n\n\t// TODO: In the future we may want to restrict the API scope (see 'scope').\n\t// https://auth0.com/docs/get-started/authentication-and-authorization-flow/call-your-api-using-the-device-authorization-flow#device-code-parameters\n\tpayload := fmt.Sprintf(\"client_id=%s\u0026audience=%s\", Auth0ClientID, url.QueryEscape(Auth0Audience))\n\n\treq, err := http.NewRequest(\"POST\", Auth0DeviceCodeURL+path, strings.NewReader(payload))\n\tif err != nil {\n\t\treturn deviceCodeResponse, err\n\t}\n\n\treq.Header.Add(\"content-type\", \"application/x-www-form-urlencoded\")\n\n\tres, err := http.DefaultClient.Do(req)\n\tif err != nil {\n\t\treturn deviceCodeResponse, err\n\t}\n\tdefer res.Body.Close()\n\n\tbody, err := io.ReadAll(res.Body)\n\tif err != nil {\n\t\treturn deviceCodeResponse, err\n\t}\n\n\terr = json.Unmarshal(body, \u0026deviceCodeResponse)\n\tif err != nil {\n\t\treturn deviceCodeResponse, err\n\t}\n\n\treturn deviceCodeResponse, nil\n}\n\n// DeviceCodeResponse is the API response for an Auth0 Device Code request.\ntype DeviceCodeResponse struct {\n\t// DeviceCode is the unique code for the device.\n\tDeviceCode string `json:\"device_code\"`\n\t// ExpiresIn indicates the lifetime (in seconds) of the device_code and user_code.\n\tExpiresIn int `json:\"expires_in\"`\n\t// Interval indicates the interval (in seconds) at which the app should poll the token URL to request a token.\n\tInterval int `json:\"interval\"`\n\t// UserCode contains the code that should be input at the verification_uri to authorize the device.\n\tUserCode string `json:\"user_code\"`\n\t// VerificationURI contains the URL the user should visit to authorize the device.\n\tVerificationURI string `json:\"verification_uri\"`\n\t// VerificationURIComplete contains the complete URL the user should visit to authorize the device.\n\tVerificationURIComplete string `json:\"verification_uri_complete\"`\n}\n\nfunc pollForAccessToken(\n\tdeviceCode string,\n\tinterval time.Duration,\n\tdeviceCodeExpiration time.Duration,\n\taccessTokenResponse chan *AccessTokenResponse,\n\terrLog fsterr.LogInterface,\n) {\n\tpath := \"/oauth/token\"\n\tpayload := fmt.Sprintf(\"grant_type=%s\u0026device_code=%s\u0026client_id=%s\", Auth0GrantType, deviceCode, Auth0ClientID)\n\tctx := map[string]any{\n\t\t\"path\":    path,\n\t\t\"payload\": payload,\n\t}\n\n\treq, err := http.NewRequest(\"POST\", Auth0DeviceCodeURL+path, strings.NewReader(payload))\n\tif err != nil {\n\t\terrLog.AddWithContext(err, ctx)\n\t\treturn\n\t}\n\n\treq.Header.Add(\"content-type\", \"application/x-www-form-urlencoded\")\n\n\tticker := time.NewTicker(interval)\n\tdefer ticker.Stop()\n\tdone := make(chan bool)\n\tgo func() {\n\t\ttime.Sleep(deviceCodeExpiration)\n\t\tdone \u003c- true\n\t}()\n\tfor {\n\t\tselect {\n\t\tcase \u003c-done:\n\t\t\treturn\n\t\tcase \u003c-ticker.C:\n\t\t\t// NOTE: We extract the logic into a func to avoid a defer within a loop.\n\t\t\tcheckAccessToken(req, errLog, ctx, accessTokenResponse, done)\n\t\t}\n\t}\n}\n\nfunc checkAccessToken(\n\treq *http.Request,\n\terrLog fsterr.LogInterface,\n\tctx map[string]any,\n\taccessTokenResponse chan *AccessTokenResponse,\n\tdone chan bool,\n) {\n\t// TODO: Handle all the different error scenarios appropriately.\n\t// https://auth0.com/docs/get-started/authentication-and-authorization-flow/call-your-api-using-the-device-authorization-flow#token-responses\n\tres, err := http.DefaultClient.Do(req)\n\tif err != nil {\n\t\terrLog.AddWithContext(err, ctx)\n\t\treturn\n\t}\n\tdefer res.Body.Close()\n\n\tbody, err := io.ReadAll(res.Body)\n\tif err != nil {\n\t\terrLog.AddWithContext(err, ctx)\n\t\treturn\n\t}\n\n\tvar atr *AccessTokenResponse\n\terr = json.Unmarshal(body, atr)\n\tif err != nil {\n\t\terrLog.AddWithContext(err, ctx)\n\t\treturn\n\t}\n\n\tdone \u003c- true\n\taccessTokenResponse \u003c- atr\n}\n\n// AccessTokenResponse is the API response for an Auth0 Access Token request.\ntype AccessTokenResponse struct {\n\t// AccessToken can be exchanged for a Fastly API token.\n\tAccessToken string `json:\"access_token\"`\n\t// ExpiresIn indicates the lifetime (in seconds) of the access token.\n\tExpiresIn int `json:\"expires_in\"`\n\t// IDToken contains user information that must be decoded and extracted.\n\tIDToken string `json:\"id_token\"`\n\t// RefreshToken is used to obtain a new Access Token or ID Token after the previous one has expired.\n\tRefreshToken string `json:\"refresh_token\"`\n\t// TokenType indicates which HTTP authentication scheme is used (e.g. Bearer).\n\tTokenType string `json:\"token_type\"`\n}\n","tags":"#auth #auth0 #device #cli"},{"id":"a124e35573a74496b16fa746742231a4","title":"Rust: Measure the elapsed time between two code sections in Rust ","content":"use std::time::{Duration, Instant};\n\nfn main() {\n    let start = Instant::now();\n    expensive_function();\n    let duration = start.elapsed();\n\n    println!(\"Time elapsed in expensive_function() is: {:?}\", duration);\n}\n","tags":"#rust #debug"},{"id":"fdf8374a593eeef8db8fed0fb868d5eb","title":"Make: Makefile prompt for user input ","content":"TEST?=$$(go list ./... |grep -v 'vendor')\nGOFMT_FILES?=$$(find . -name '*.go' |grep -v vendor)\nWEBSITE_REPO=github.com/hashicorp/terraform-website\nPKG_NAME=fastly\nFULL_PKG_NAME=github.com/fastly/terraform-provider-fastly\nVERSION_PLACEHOLDER=version.ProviderVersion\nVERSION=$(shell git describe --tags --always)\nVERSION_SHORT=$(shell git describe --tags --always --abbrev=0)\nDOCS_PROVIDER_VERSION=$(subst v,,$(VERSION_SHORT))\n\nGOHOSTOS ?= $(shell go env GOHOSTOS || echo unknown)\nGOHOSTARCH ?= $(shell go env GOHOSTARCH || echo unknown)\n\nTEST_PARALLELISM?=4\n\ndefault: build\n\nbuild: clean\n\tgo build -o bin/terraform-provider-$(PKG_NAME)_$(VERSION) -ldflags=\"-X $(FULL_PKG_NAME)/$(VERSION_PLACEHOLDER)=$(VERSION)\"\n\t@sh -c \"'$(CURDIR)/scripts/generate-dev-overrides.sh'\"\n\ntest:\n\tgo test $(TEST) || exit 1\n\techo $(TEST) | \\\n\t\txargs -t -n4 go test $(TESTARGS) -timeout=30s -parallel=$(TEST_PARALLELISM)\n\ntestacc: fmtcheck\n\tTF_ACC=1 go test $(TEST) -v $(TESTARGS) -parallel=$(TEST_PARALLELISM) -timeout 360m -ldflags=\"-X=$(FULL_PKG_NAME)/$(VERSION_PLACEHOLDER)=acc\"\n\n# WARNING: This target will delete infrastructure.\nclean_test:\n\t@printf 'WARNING: This will delete infrastructure. Continue? (y/n) '; \\\n\tread answer; \\\n\tif echo \"$$answer\" | grep -iq '^y'; then \\\n\t  SILENCE=true make sweep || true; \\\n\t\tfastly service list --token $$FASTLY_API_KEY | grep -E '^tf\\-' | awk '{print $$2}' | xargs -I % fastly service delete --token $$FASTLY_API_KEY -f -s %; \\\n\t\tTEST_PARALLELISM=8 make testacc; \\\n\tfi\n\nsweep:\n\t@if [ \"$(SILENCE)\" != \"true\" ]; then \\\n\t\techo \"WARNING: This will destroy infrastructure. Use only in development accounts.\"; \\\n\tfi\n\tgo test ./fastly -v -sweep=ALL $(SWEEPARGS) -timeout 30m || true\n\nclean:\n\trm -rf ./bin\n\n.PHONY: build test testacc sweep clean\n","tags":"#make #shell"},{"id":"d50a2e06dbb8f1b2e510eac2f28b3e1d","title":"Auth: OAuth2 and OIDC (OpenID Connect) ","content":"\u003e **Reference video**: https://www.youtube.com/watch?v=5th6CSQTdpM\n\n## OAuth2\n\nOAuth is about \"authorization\" and not \"authentication\". \n\n### Authentication vs Authorization\n\n- Authentication is the process of verification that an individual, entity or website is who it claims to be.\n- Authorization is the function of specifying access rights to resources.\n\nIf there was only authentication, then we know _who_ you are (and that you really are you and not someone pretending to be you), but we don't know what you're allowed to access. e.g. a person enters an office building, but they might not be allowed to enter the IT computer room (without authorization the person can just walk into the IT computer room).\n\nIf there was only authorization, then we know _what_ you can access, but we don't know if it's really you accessing the resource. e.g. a bad person stole an employee's key to get into the office's IT computer room but there was no security guard at the office's front door to check if the bad person was really the employee (i.e. really the owner of the key).\n\n### Resource Owner\n\nIf you have a jacket, then the jacket is the \"resource\" and you are the owner of that jacket (i.e. you are the \"resource owner\").\n\n### Resource Server\n\nIf you put your jacket into a locker, then the locker is the \"resource server\".\n\n### Authorization Server\n\nThe locker is locked. The lock is the \"authorization server\" (the auth server ensures only you can access your jacket).\n\n### Client/Application\n\nIf you ask your friend to get your coat for you, then you're asking them to act on your behalf and so your friend is a \"client\" or \"application\".\n\n### Access Token\n\nAn access token is something you present to the resource server to get access to your resource that is stored there.\n\nThere are different ways to 'implement' an access token, such as a \"Bearer Token\", \"JWT Token\", \"Opaque Token\".\n\nAccess tokens are typically short-lived and once expired you need to get a new access token to replace the expired one.\n\n### Refresh Token\n\nA refresh token is a way to get more access tokens once they have expired.\n\n### Scopes\n\nA scope is equivalent to a \"role\" or a \"permission\". It indicates what can be accessed using the access token.\n\n### Grant Types\n\nThere are different ways for a resource owner to acquire an access token (in order of how common they are):\n\n- Client Credentials: Service-to-Service communication (simplest).\n- Authorization Code: Browser-based user login such as web, mobile, SPAs and CLIs (add PKCE for extra security, e.g. a public CLI code base which can't store secret data).\n- Device Code: Televisions and environments with limited input capabilities\n- Refresh: Obtain new tokens when one expires (works in tandem with the \"Authorization Code\" flow to help avoid having to do that full flow again when your token expires).\n- Password \u0026 Implicit: Less secure option for CLI, mobile apps and SPAs (AVOID!).\n\n#### Client Credentials\n\nClient is trusted and contains an id and a secret which are used to acquire the token.\n\nThis is analogous to you losing your key for accessing your resource in the resource server and so a janitor (the client/app) uses its trusted id/secret to open the lock (the Authorization Server) to retrieve your jacket (the resource).\n\n#### Password (AVOID)\n\nThis is very similar to Client Credentials, but highlights how insecure it is compared. Instead of having a client/app that is _trusted_ you are giving your key to the lock directly to the client/app and they're opening the lock for you. Your key should only be held by you but now you've given it away to someone else temporarily who might accidentally lose the key or hold onto it and do bad things with it in the future.\n\n#### Authorization Code\n\nThis flow is \"browser based\" (making heavy use of HTTP redirects) making it a bit awkward for some devices like CLIs.\n\nMost cases the user will be presented with a screen where they have to approve permissions being granted to the client/application.\n\nIt can be extended through the use of PKCE which means the client/application will _generate_ a secret that is exchanged for an access token (still with permission approval screen).\n\nThis is analogous to you wanting to lend your jacket to your friend. Your friend goes to the locker and the lock (which is a very technically advanced lock) calls you to confirm it's OK for your friend to get access to your jacket. You enter your key (login) and confirm the access. Your friend is given a temporary key (auth code) and uses that to obtain a key (access token) to open the lock and gets the jacket.\n\n\u003e **NOTE**: The \"Implicit\" flow is very similar to the Authorization Code flow but there is no \"auth code\" given out, the client/app is just given the access token immediately. So \"Implicit\" is less secure because of this as the access token provided to the client/application could get intercepted along the way (unlike with the \"auth code\" addition in the Authorization Code flow).\n\n## OIDC\n\nOpenID Connect is about \"identity\" (who you are, not what you can do).\n\nIt's an extension of OAuth2, so most of what we've already seen is the same with OIDC.\n\nOIDC has an Authorization Code flow like OAuth2 which doesn't provide an \"access token\" (like OAuth2) but an \"ID token\" which is used to login to something (typically used with SSO).\n\nThere is also a \"Hybrid\" flow which gives you _both_ an ID token and an Access token.\n\nThis is analogous to you wanting to go to a swimming pool, but it's members only. Someone at the gate redirects you to the ticket booth (authorization server) and once you show your ID (i.e. login) you are given back a wrist band (i.e. an ID token) which can be used to enter the swimming pool.\n","tags":"#OAuth #OIDC"},{"id":"76f8be7cd5bb6e75587d58146daf0ab5","title":"Auth: CLI PKCE with Auth0 or KeyCloak (inc code examples + sequence diagram) ","content":"// Demonstrated with a proof-of-concept developed for the Fastly CLI.\n\npackage authenticate\n\nimport (\n\t\"context\"\n\t\"encoding/json\"\n\t\"fmt\"\n\t\"io\"\n\t\"net/http\"\n\t\"strings\"\n\n\t\"github.com/fastly/cli/pkg/cmd\"\n\t\"github.com/fastly/cli/pkg/config\"\n\tfsterr \"github.com/fastly/cli/pkg/errors\"\n\t\"github.com/fastly/cli/pkg/text\"\n\t\"github.com/hashicorp/cap/jwt\"\n\t\"github.com/hashicorp/cap/oidc\"\n\t\"github.com/skratchdot/open-golang/open\"\n)\n\n// RootCommand is the parent command for all subcommands in this package.\n// It should be installed under the primary root command.\ntype RootCommand struct {\n\tcmd.Base\n}\n\n// AuthRemediation is a generic remediation message for an error authorizing.\nconst AuthRemediation = \"Please re-run the command. If the problem persists, please file an issue: https://github.com/fastly/cli/issues/new?labels=bug\u0026template=bug_report.md\"\n\n// Auth0CLIAppURL is the Auth0 device code URL.\nconst Auth0CLIAppURL = \"https://\u003cYOUR_DOMAIN\u003e.us.auth0.com\"\n\n// Auth0ClientID is the Auth0 Client ID.\nconst Auth0ClientID = \"\u003cCLIENT_ID\u003e\"\n\n// Auth0Audience is the unique identifier of the API your app wants to access.\nconst Auth0Audience = \"https://\u003cYOUR_API\u003e/\"\n\n// Auth0RedirectURL is the endpoint Auth0 will pass an authorization code to.\nconst Auth0RedirectURL = \"http://localhost:8080/callback\"\n\n// NewRootCommand returns a new command registered in the parent.\nfunc NewRootCommand(parent cmd.Registerer, globals *config.Data) *RootCommand {\n\tvar c RootCommand\n\tc.Globals = globals\n\tc.CmdClause = parent.Command(\"authenticate\", \"Authenticate with Fastly (returns temporary, auto-rotated, API token)\")\n\treturn \u0026c\n}\n\n// Exec implements the command interface.\nfunc (c *RootCommand) Exec(_ io.Reader, out io.Writer) error {\n\tverifier, err := oidc.NewCodeVerifier()\n\tif err != nil {\n\t\treturn fsterr.RemediationError{\n\t\t\tInner:       fmt.Errorf(\"failed to generate a code verifier: %w\", err),\n\t\t\tRemediation: AuthRemediation,\n\t\t}\n\t}\n\n\tresult := make(chan authorizationResult)\n\n\ts := server{\n\t\tresult:   result,\n\t\trouter:   http.NewServeMux(),\n\t\tverifier: verifier,\n\t}\n\ts.routes()\n\n\tvar serverErr error\n\n\tgo func() {\n\t\terr := s.startServer()\n\t\tif err != nil {\n\t\t\tserverErr = err\n\t\t}\n\t}()\n\n\tif serverErr != nil {\n\t\treturn serverErr\n\t}\n\n\ttext.Info(out, \"Starting localhost server to handle the authentication flow.\")\n\n\tauthorizationURL, err := generateAuthorizationURL(verifier)\n\tif err != nil {\n\t\treturn fsterr.RemediationError{\n\t\t\tInner:       fmt.Errorf(\"failed to generate an authorization URL: %w\", err),\n\t\t\tRemediation: AuthRemediation,\n\t\t}\n\t}\n\n\ttext.Break(out)\n\ttext.Description(out, \"We're opening the following URL in your default web browser so you may authenticate with Fastly\", authorizationURL)\n\n\terr = open.Run(authorizationURL)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"failed to open your default browser: %w\", err)\n\t}\n\n\tar := \u003c-result\n\tif ar.err != nil || ar.sessionToken == \"\" {\n\t\treturn fsterr.RemediationError{\n\t\t\tInner:       fmt.Errorf(\"failed to authorize: %w\", ar.err),\n\t\t\tRemediation: AuthRemediation,\n\t\t}\n\t}\n\n\t// NOTE: your id_token might not contain a custom claim with its own access token inside (YMMV).\n\tfmt.Println(\"session token:\", ar.sessionToken)\n\n\treturn nil\n}\n\ntype server struct {\n\tresult   chan authorizationResult\n\trouter   *http.ServeMux\n\tverifier *oidc.S256Verifier\n}\n\nfunc (s *server) startServer() error {\n\terr := http.ListenAndServe(\":8080\", s.router)\n\tif err != nil {\n\t\treturn fsterr.RemediationError{\n\t\t\tInner:       fmt.Errorf(\"failed to start local server: %w\", err),\n\t\t\tRemediation: AuthRemediation,\n\t\t}\n\t}\n\treturn nil\n}\n\nfunc (s *server) routes() {\n\ts.router.HandleFunc(\"/callback\", s.handleCallback())\n}\n\nfunc (s *server) handleCallback() http.HandlerFunc {\n\treturn func(w http.ResponseWriter, r *http.Request) {\n\t\tauthorizationCode := r.URL.Query().Get(\"code\")\n\t\tif authorizationCode == \"\" {\n\t\t\tfmt.Fprint(w, \"ERROR: no authorization code returned\\n\")\n\t\t\ts.result \u003c- authorizationResult{\n\t\t\t\terr: fmt.Errorf(\"no authorization code returned\"),\n\t\t\t}\n\t\t\treturn\n\t\t}\n\n\t\t// Exchange the authorization code and the code verifier for a JWT.\n\t\t// NOTE: I use the identifier `j` to avoid overlap with the `jwt` package.\n\t\tcodeVerifier := s.verifier.Verifier()\n\t\tj, err := getJWT(codeVerifier, authorizationCode)\n\t\tif err != nil || j.AccessToken == \"\" || j.IDToken == \"\" {\n\t\t\tfmt.Fprint(w, \"ERROR: failed to exchange code for JWT\\n\")\n\t\t\ts.result \u003c- authorizationResult{\n\t\t\t\terr: fmt.Errorf(\"failed to exchange code for JWT\"),\n\t\t\t}\n\t\t\treturn\n\t\t}\n\n\t\t_, err = verifyJWTSignature(j.AccessToken)\n\t\tif err != nil {\n\t\t\ts.result \u003c- authorizationResult{\n\t\t\t\terr: err,\n\t\t\t}\n\t\t\treturn\n\t\t}\n\n\t\tclaims, err := verifyJWTSignature(j.IDToken)\n\t\tif err != nil {\n\t\t\ts.result \u003c- authorizationResult{\n\t\t\t\terr: err,\n\t\t\t}\n\t\t\treturn\n\t\t}\n\n\t\t// NOTE: This is only for the Fastly CLI setup.\n\t\tsessionToken, err := extractSessionToken(claims)\n\t\tif err != nil {\n\t\t\ts.result \u003c- authorizationResult{\n\t\t\t\terr: err,\n\t\t\t}\n\t\t\treturn\n\t\t}\n\n\t\tfmt.Fprint(w, \"Authenticated successfully. Please close this page and return to the Fastly CLI in your terminal.\")\n\t\ts.result \u003c- authorizationResult{\n\t\t\tjwt:          j,\n\t\t\tsessionToken: sessionToken,\n\t\t}\n\t}\n}\n\ntype authorizationResult struct {\n\terr          error\n\tjwt          JWT\n\tsessionToken string\n}\n\nfunc generateAuthorizationURL(verifier *oidc.S256Verifier) (string, error) {\n\tchallenge, err := oidc.CreateCodeChallenge(verifier)\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\n\tauthorizationURL := fmt.Sprintf(\n\t\t\"%s/authorize?audience=%s\"+\n\t\t\t\"\u0026scope=openid\"+\n\t\t\t\"\u0026response_type=code\u0026client_id=%s\"+\n\t\t\t\"\u0026code_challenge=%s\"+\n\t\t\t\"\u0026code_challenge_method=S256\u0026redirect_uri=%s\",\n\t\tAuth0CLIAppURL, Auth0Audience, Auth0ClientID, challenge, Auth0RedirectURL)\n\n\treturn authorizationURL, nil\n}\n\nfunc getJWT(codeVerifier, authorizationCode string) (JWT, error) {\n\tpath := \"/oauth/token\"\n\n\tpayload := fmt.Sprintf(\n\t\t\"grant_type=authorization_code\u0026client_id=%s\u0026code_verifier=%s\u0026code=%s\u0026redirect_uri=%s\",\n\t\tAuth0ClientID,\n\t\tcodeVerifier,\n\t\tauthorizationCode,\n\t\t\"http://localhost:8080\", // NOTE: not redirected to, just a security check.\n\t)\n\n\treq, err := http.NewRequest(\"POST\", Auth0CLIAppURL+path, strings.NewReader(payload))\n\tif err != nil {\n\t\treturn JWT{}, err\n\t}\n\n\treq.Header.Add(\"content-type\", \"application/x-www-form-urlencoded\")\n\n\tres, err := http.DefaultClient.Do(req)\n\tif err != nil {\n\t\treturn JWT{}, err\n\t}\n\tdefer res.Body.Close()\n\n\tif res.StatusCode != http.StatusOK {\n\t\treturn JWT{}, fmt.Errorf(\"failed to exchange code for jwt (status: %s)\", res.Status)\n\t}\n\n\tbody, err := io.ReadAll(res.Body)\n\tif err != nil {\n\t\treturn JWT{}, err\n\t}\n\n\t// NOTE: I use the identifier `j` to avoid overlap with the `jwt` package.\n\tvar j JWT\n\terr = json.Unmarshal(body, \u0026j)\n\tif err != nil {\n\t\treturn JWT{}, err\n\t}\n\n\treturn j, nil\n}\n\n// JWT is the API response for an Auth0 Token request.\ntype JWT struct {\n\t// AccessToken can be exchanged for a Fastly API token.\n\tAccessToken string `json:\"access_token\"`\n\t// ExpiresIn indicates the lifetime (in seconds) of the access token.\n\tExpiresIn int `json:\"expires_in\"`\n\t// IDToken contains user information that must be decoded and extracted.\n\tIDToken string `json:\"id_token\"`\n\t// TokenType indicates which HTTP authentication scheme is used (e.g. Bearer).\n\tTokenType string `json:\"token_type\"`\n}\n\nfunc verifyJWTSignature(token string) (claims map[string]any, err error) {\n\tctx := context.Background()\n\n\t// NOTE: The last argument is optional and is for validating the JWKs endpoint\n\t// (which we don't need to do, so we pass an empty string)\n\tkeySet, err := jwt.NewJSONWebKeySet(ctx, Auth0CLIAppURL+\"/.well-known/jwks.json\", \"\")\n\tif err != nil {\n\t\treturn claims, fmt.Errorf(\"failed to verify signature of access token: %w\", err)\n\t}\n\n\tclaims, err = keySet.VerifySignature(ctx, token)\n\tif err != nil {\n\t\treturn claims, fmt.Errorf(\"failed to verify signature of access token: %w\", err)\n\t}\n\n\treturn claims, nil\n}\n\nfunc extractSessionToken(claims map[string]any) (string, error) {\n\tif i, ok := claims[\"ui_token\"]; ok {\n\t\tif m, ok := i.(map[string]any); ok {\n\t\t\tif v, ok := m[\"access_token\"]; ok {\n\t\t\t\tif t, ok := v.(string); ok {\n\t\t\t\t\tif t != \"\" {\n\t\t\t\t\t\treturn t, nil\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\treturn \"\", fmt.Errorf(\"failed to extract session token from JWT custom claim\")\n}\n// NOTE: https://keycloak.ext.awsuse2.dev.k8s.secretcdn.net/realms/fastly/.well-known/openid-configuration\n\npackage authenticate\n\nimport (\n\t\"context\"\n\t\"encoding/json\"\n\t\"fmt\"\n\t\"io\"\n\t\"net/http\"\n\t\"strings\"\n\n\t\"github.com/fastly/cli/pkg/cmd\"\n\t\"github.com/fastly/cli/pkg/config\"\n\tfsterr \"github.com/fastly/cli/pkg/errors\"\n\t\"github.com/fastly/cli/pkg/profile\"\n\t\"github.com/fastly/cli/pkg/text\"\n\t\"github.com/hashicorp/cap/jwt\"\n\t\"github.com/hashicorp/cap/oidc\"\n\t\"github.com/skratchdot/open-golang/open\"\n)\n\n// RootCommand is the parent command for all subcommands in this package.\n// It should be installed under the primary root command.\ntype RootCommand struct {\n\tcmd.Base\n}\n\n// AuthRemediation is a generic remediation message for an error authorizing.\nconst AuthRemediation = \"Please re-run the command. If the problem persists, please file an issue: https://github.com/fastly/cli/issues/new?labels=bug\u0026template=bug_report.md\"\n\n// AuthProviderCLIAppURL is the auth provider's device code URL.\nconst AuthProviderCLIAppURL = \"https://keycloak.\u003cYOUR_DOMAIN\u003e\"\n\n// AuthProviderClientID is the auth provider's Client ID.\nconst AuthProviderClientID = \"\u003cCLIENT_ID\u003e\"\n\n// AuthProviderAudience is the unique identifier of the API your app wants to access.\nconst AuthProviderAudience = \"https://\u003cYOUR_API\u003e/\"\n\n// AuthProviderRedirectURL is the endpoint the auth provider will pass an authorization code to.\nconst AuthProviderRedirectURL = \"http://localhost:8080/callback\"\n\n// NewRootCommand returns a new command registered in the parent.\nfunc NewRootCommand(parent cmd.Registerer, globals *config.Data) *RootCommand {\n\tvar c RootCommand\n\tc.Globals = globals\n\tc.CmdClause = parent.Command(\"authenticate\", \"Authenticate with Fastly (returns temporary, auto-rotated, API token)\")\n\treturn \u0026c\n}\n\n// Exec implements the command interface.\nfunc (c *RootCommand) Exec(_ io.Reader, out io.Writer) error {\n\tverifier, err := oidc.NewCodeVerifier()\n\tif err != nil {\n\t\treturn fsterr.RemediationError{\n\t\t\tInner:       fmt.Errorf(\"failed to generate a code verifier: %w\", err),\n\t\t\tRemediation: AuthRemediation,\n\t\t}\n\t}\n\n\tresult := make(chan authorizationResult)\n\n\ts := server{\n\t\tresult:   result,\n\t\trouter:   http.NewServeMux(),\n\t\tverifier: verifier,\n\t}\n\ts.routes()\n\n\tvar serverErr error\n\n\tgo func() {\n\t\terr := s.startServer()\n\t\tif err != nil {\n\t\t\tserverErr = err\n\t\t}\n\t}()\n\n\tif serverErr != nil {\n\t\treturn serverErr\n\t}\n\n\ttext.Info(out, \"Starting localhost server to handle the authentication flow.\")\n\n\tauthorizationURL, err := generateAuthorizationURL(verifier)\n\tif err != nil {\n\t\treturn fsterr.RemediationError{\n\t\t\tInner:       fmt.Errorf(\"failed to generate an authorization URL: %w\", err),\n\t\t\tRemediation: AuthRemediation,\n\t\t}\n\t}\n\n\ttext.Break(out)\n\ttext.Description(out, \"We're opening the following URL in your default web browser so you may authenticate with Fastly\", authorizationURL)\n\n\terr = open.Run(authorizationURL)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"failed to open your default browser: %w\", err)\n\t}\n\n\tar := \u003c-result\n\tif ar.err != nil || ar.sessionToken == \"\" {\n\t\treturn fsterr.RemediationError{\n\t\t\tInner:       fmt.Errorf(\"failed to authorize: %w\", ar.err),\n\t\t\tRemediation: AuthRemediation,\n\t\t}\n\t}\n\n\ttext.Success(out, \"Session token (persisted to your local configuration): %s\", ar.sessionToken)\n\n\tprofileName, _ := profile.Default(c.Globals.File.Profiles)\n\tif profileName == \"\" {\n\t\t// FIXME: Return a more appropriate remediation.\n\t\treturn fsterr.RemediationError{\n\t\t\tInner:       fmt.Errorf(\"no profiles available\"),\n\t\t\tRemediation: fsterr.ProfileRemediation,\n\t\t}\n\t}\n\n\tps, ok := profile.Edit(profileName, c.Globals.File.Profiles, func(p *config.Profile) {\n\t\tp.Token = ar.sessionToken\n\t})\n\tif !ok {\n\t\treturn fsterr.RemediationError{\n\t\t\tInner:       fmt.Errorf(\"failed to update default profile with new session token\"),\n\t\t\tRemediation: \"Run `fastly profile update` and manually paste in the session token.\",\n\t\t}\n\t}\n\tc.Globals.File.Profiles = ps\n\n\tif err := c.Globals.File.Write(c.Globals.Path); err != nil {\n\t\tc.Globals.ErrLog.Add(err)\n\t\treturn fmt.Errorf(\"error saving config file: %w\", err)\n\t}\n\n\t// FIXME: Don't just update the default profile.\n\t// Allow user to configure this via a --profile flag.\n\n\treturn nil\n}\n\ntype server struct {\n\tresult   chan authorizationResult\n\trouter   *http.ServeMux\n\tverifier *oidc.S256Verifier\n}\n\nfunc (s *server) startServer() error {\n\t// TODO: Consider using a random port to avoid local network conflicts.\n\t// Chat with authentication provider about how to use a random port.\n\terr := http.ListenAndServe(\":8080\", s.router)\n\tif err != nil {\n\t\treturn fsterr.RemediationError{\n\t\t\tInner:       fmt.Errorf(\"failed to start local server: %w\", err),\n\t\t\tRemediation: AuthRemediation,\n\t\t}\n\t}\n\treturn nil\n}\n\nfunc (s *server) routes() {\n\ts.router.HandleFunc(\"/callback\", s.handleCallback())\n}\n\nfunc (s *server) handleCallback() http.HandlerFunc {\n\treturn func(w http.ResponseWriter, r *http.Request) {\n\t\tauthorizationCode := r.URL.Query().Get(\"code\")\n\t\tif authorizationCode == \"\" {\n\t\t\tfmt.Fprint(w, \"ERROR: no authorization code returned\\n\")\n\t\t\ts.result \u003c- authorizationResult{\n\t\t\t\terr: fmt.Errorf(\"no authorization code returned\"),\n\t\t\t}\n\t\t\treturn\n\t\t}\n\n\t\t// Exchange the authorization code and the code verifier for a JWT.\n\t\t// NOTE: I use the identifier `j` to avoid overlap with the `jwt` package.\n\t\tcodeVerifier := s.verifier.Verifier()\n\t\tj, err := getJWT(codeVerifier, authorizationCode)\n\t\tif err != nil || j.AccessToken == \"\" || j.IDToken == \"\" {\n\t\t\tfmt.Fprint(w, \"ERROR: failed to exchange code for JWT\\n\")\n\t\t\ts.result \u003c- authorizationResult{\n\t\t\t\terr: fmt.Errorf(\"failed to exchange code for JWT\"),\n\t\t\t}\n\t\t\treturn\n\t\t}\n\n\t\tclaims, err := verifyJWTSignature(j.AccessToken)\n\t\tif err != nil {\n\t\t\ts.result \u003c- authorizationResult{\n\t\t\t\terr: err,\n\t\t\t}\n\t\t\treturn\n\t\t}\n\n\t\tsessionToken, err := extractSessionToken(claims)\n\t\tif err != nil {\n\t\t\ts.result \u003c- authorizationResult{\n\t\t\t\terr: err,\n\t\t\t}\n\t\t\treturn\n\t\t}\n\n\t\tfmt.Fprint(w, \"Authenticated successfully. Please close this page and return to the Fastly CLI in your terminal.\")\n\t\ts.result \u003c- authorizationResult{\n\t\t\tjwt:          j,\n\t\t\tsessionToken: sessionToken,\n\t\t}\n\t}\n}\n\ntype authorizationResult struct {\n\terr          error\n\tjwt          JWT\n\tsessionToken string\n}\n\nfunc generateAuthorizationURL(verifier *oidc.S256Verifier) (string, error) {\n\tchallenge, err := oidc.CreateCodeChallenge(verifier)\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\n\tauthorizationURL := fmt.Sprintf(\n\t\t\"%s/realms/fastly/protocol/openid-connect/auth?audience=%s\"+\n\t\t\t\"\u0026scope=openid\"+\n\t\t\t\"\u0026response_type=code\u0026client_id=%s\"+\n\t\t\t\"\u0026code_challenge=%s\"+\n\t\t\t\"\u0026code_challenge_method=S256\u0026redirect_uri=%s\",\n\t\tAuthProviderCLIAppURL, AuthProviderAudience, AuthProviderClientID, challenge, AuthProviderRedirectURL)\n\n\treturn authorizationURL, nil\n}\n\nfunc getJWT(codeVerifier, authorizationCode string) (JWT, error) {\n\tpath := \"/realms/fastly/protocol/openid-connect/token\"\n\n\tpayload := fmt.Sprintf(\n\t\t\"grant_type=authorization_code\u0026client_id=%s\u0026code_verifier=%s\u0026code=%s\u0026redirect_uri=%s\",\n\t\tAuthProviderClientID,\n\t\tcodeVerifier,\n\t\tauthorizationCode,\n\t\t\"http://localhost:8080/callback\", // NOTE: not redirected to, just a security check.\n\t)\n\n\treq, err := http.NewRequest(\"POST\", AuthProviderCLIAppURL+path, strings.NewReader(payload))\n\tif err != nil {\n\t\treturn JWT{}, err\n\t}\n\n\treq.Header.Add(\"content-type\", \"application/x-www-form-urlencoded\")\n\n\tres, err := http.DefaultClient.Do(req)\n\tif err != nil {\n\t\treturn JWT{}, err\n\t}\n\tdefer res.Body.Close()\n\n\tif res.StatusCode != http.StatusOK {\n\t\treturn JWT{}, fmt.Errorf(\"failed to exchange code for jwt (status: %s)\", res.Status)\n\t}\n\n\tbody, err := io.ReadAll(res.Body)\n\tif err != nil {\n\t\treturn JWT{}, err\n\t}\n\n\tvar j JWT\n\terr = json.Unmarshal(body, \u0026j)\n\tif err != nil {\n\t\treturn JWT{}, err\n\t}\n\n\treturn j, nil\n}\n\n// JWT is the API response for a Token request.\ntype JWT struct {\n\t// AccessToken can be exchanged for a Fastly API token.\n\tAccessToken string `json:\"access_token\"`\n\t// ExpiresIn indicates the lifetime (in seconds) of the access token.\n\tExpiresIn int `json:\"expires_in\"`\n\t// IDToken contains user information that must be decoded and extracted.\n\tIDToken string `json:\"id_token\"`\n\t// TokenType indicates which HTTP authentication scheme is used (e.g. Bearer).\n\tTokenType string `json:\"token_type\"`\n}\n\nfunc verifyJWTSignature(token string) (claims map[string]any, err error) {\n\tctx := context.Background()\n\tpath := \"/realms/fastly/protocol/openid-connect/certs\"\n\n\t// NOTE: The last argument is optional and is for validating the JWKs endpoint\n\t// (which we don't need to do, so we pass an empty string)\n\tkeySet, err := jwt.NewJSONWebKeySet(ctx, AuthProviderCLIAppURL+path, \"\")\n\tif err != nil {\n\t\treturn claims, fmt.Errorf(\"failed to verify signature of access token: %w\", err)\n\t}\n\n\tclaims, err = keySet.VerifySignature(ctx, token)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"failed to verify signature of access token: %w\", err)\n\t}\n\n\treturn claims, nil\n}\n\nfunc extractSessionToken(claims map[string]any) (string, error) {\n\tif i, ok := claims[\"legacy_session_token\"]; ok {\n\t\tif t, ok := i.(string); ok {\n\t\t\tif t != \"\" {\n\t\t\t\treturn t, nil\n\t\t\t}\n\t\t}\n\t}\n\treturn \"\", fmt.Errorf(\"failed to extract session token from JWT custom claim\")\n}\n# Render this with https://sequencediagram.org/\n\ntitle CLI PKCE Auth Flow\n\nparticipant User\nparticipant Terminal\nparticipant CLI\nparticipant Local HTTP Server\nparticipant KeyCloak\nparticipant Okta\n\nUser-\u003eTerminal: **Opens Terminal**\nTerminal-\u003eCLI: **Types command:**\\n\"\"fastly authenticate\"\"\nCLI--\u003eCLI: \"\"oidc.NewCodeVerifier()\"\"\nCLI--\u003eLocal HTTP Server: **Start local HTTP server**\nCLI-\u003eKeyCloak: **Opens Web Browser to KeyCloak's 'Device Code' URL**\\n\"\"https://example.whatever.com\\n/realms/fastly/protocol/openid-connect\\n/auth?audience=...etc\"\"\nCLI--\u003eCLI: 🚫 **Blocks execution until JWT received**\nKeyCloak--\u003eKeyCloak: **Displays Login UI**\nUser-\u003eKeyCloak: **Enters email address**\nKeyCloak--\u003eKeyCloak: **Identifies Provider as Okta**\nKeyCloak--\u003eOkta: **Redirect user to Okta**\\n\"\"https://whatever.oktapreview.com/app/\\nwhateversamlfastlycontrol_1/\\nwhatever/sso/saml\"\"\nUser-\u003eOkta: **Logs into Okta**\nOkta-\u003eLocal HTTP Server: **Redirect user to Local Server callback**\\n\"\"http://localhost:8080/callback?\\nsession_state=\u003c\u003e\u0026code=\u003c\u003e\"\"\nLocal HTTP Server--\u003eLocal HTTP Server: **Exchange \"\"code\"\" param and \"\"code_verifier\"\"\\nfor a JWT and validate its signature, then\\nextract a session token from the JWT.**\nLocal HTTP Server-\u003eCLI: **Send session token**\nLocal HTTP Server--\u003eLocal HTTP Server: **Display success message to user.\\nAsk them to close browser window\\nand return to their terminal.**\nCLI--\u003eCLI: ✅ **Unblocks execution\\nPersist session token to profile config**\nCLI-\u003eTerminal: **Display success message to user**\n","tags":"#auth #auth0 #pkce #cli #keycloak"},{"id":"f55a601cf3ccdb7fc8a671c854383e3a","title":"Vim: increment numbers across blocks ","content":"So I had an interesting problem where I had a block of code like... \n\n```\n\"testing0.testing-performance-domain.com\" = {\n  val1 = \"value_1\"\n  ...\n}\n```\n\nThe ... is lots of key/value lines, so it ends up being a large 'block'.\n\nI needed to duplicate the block multiple times (200 in fact) but the first line needed an incremented number, so...\n\n```\n\"testing1.testing-performance-domain.com\" = {\n  val1 = \"value_1\"\n  ...\n}\n\"testing2.testing-performance-domain.com\" = {\n  val1 = \"value_1\"\n  ...\n}\n\"testing3.testing-performance-domain.com\" = {\n  val1 = \"value_1\"\n  ...\n}\n```\n\nThe way I solved this was to:\n\n- make sure the `\"a` register contained `0`.\n- `V%y` (copy the block).\n- `199P` (duplicate it, as we need two hundred blocks).\n- `qq` (on the first line of the first block I record the following macro `0f0v\"ap^AvTg\"ay`).\n  - `0` go to start of the line.\n  - `f0` find the first zero (e.g. the zero in `testing0`).\n  - `v\"ap` select the zero and replace it with the contents of the `\"a` register (the first time round this would be the same number: `0`).\n  - `^A` press Ctrl-a to increment the number pasted from the register.\n    - The cursor is always placed at the end of the number.\n    - So if number is 123 then the cursor would be on 3.\n  - `vTg` select back to just before the `g` in the preceding word \"testing\" (i.e. select the new number).\n  - `\"ay` and yank the new number into the same `\"a` register.\n- I then reset the first block to zero (so `\"testing0.testing-performance-domain.com\" = {`)\n- `:g/\\v^\\s\\s\\s\\s\"testing\\d/norm @q` find all relevant blocks and run the macro.\n","tags":"#vim #increment"},{"id":"091de4e072fbd84442afd6668bdc657d","title":"Go: REDACT tokens via regex pattern ","content":"package main\n\nimport (\n\t\"fmt\"\n\t\"regexp\"\n)\n\nvar (\n\tTokenRegEx     = regexp.MustCompile(`Token ([\\w-]+)`)\n\tTokenFlagRegEx = regexp.MustCompile(`(-t|--token)(\\s*=?\\s*['\"]?)([\\w-]+)(['\"]?)`)\n)\n\nfunc filterToken(input string) (inputFiltered string) {\n\tinputFiltered = TokenRegEx.ReplaceAllString(input, \"Token REDACTED\")\n\tinputFiltered = TokenFlagRegEx.ReplaceAllString(inputFiltered, \"${1}${2}REDACTED${4}\")\n\treturn inputFiltered\n}\n\nfunc main() {\n\tfmt.Println(filterToken(\"Title:  Token aBcd1EF23g7HiJklmN4O_PQ5rS-6Tuv7_ expired at 2022-06-19T10:51:18Z\"))\n\tfmt.Println(\"\\n.........................................\\n\")\n\tfmt.Println(filterToken(\"-t aBcd1EF23g7HiJklmN4O_PQ5rS-6Tuv7_\"))\n\tfmt.Println(filterToken(\"-t=aBcd1EF23g7HiJklmN4O_PQ5rS-6Tuv7_\"))\n\tfmt.Println(filterToken(\"--token aBcd1EF23g7HiJklmN4O_PQ5rS-6Tuv7_\"))\n\tfmt.Println(filterToken(\"--token=aBcd1EF23g7HiJklmN4O_PQ5rS-6Tuv7_\"))\n\tfmt.Println(filterToken(\"--token 'aBcd1EF23g7HiJklmN4O_PQ5rS-6Tuv7_'\"))\n\tfmt.Println(filterToken(`--token \"aBcd1EF23g7HiJklmN4O_PQ5rS-6Tuv7_\"`))\n\tfmt.Println(filterToken(\"--token='aBcd1EF23g7HiJklmN4O_PQ5rS-6Tuv7_'\"))\n\tfmt.Println(filterToken(`--token=\"aBcd1EF23g7HiJklmN4O_PQ5rS-6Tuv7_\"`))\n\tfmt.Println(filterToken(\"--token   aBcd1EF23g7HiJklmN4O_PQ5rS-6Tuv7_\"))\n\tfmt.Println(filterToken(\"--token   aBcd1EF23g7HiJklmN4O_PQ5rS-6Tuv7_\"))\n\tfmt.Println(filterToken(\"--token   'aBcd1EF23g7HiJklmN4O_PQ5rS-6Tuv7_'\"))\n\tfmt.Println(filterToken(`--token   \"aBcd1EF23g7HiJklmN4O_PQ5rS-6Tuv7_\"`))\n\tfmt.Println(filterToken(\"-taBcd1EF23g7HiJklmN4O_PQ5rS-6Tuv7_\"))\n\tfmt.Println(filterToken(\"--tokenaBcd1EF23g7HiJklmN4O_PQ5rS-6Tuv7_\"))\n\tfmt.Println(filterToken(\"-t'aBcd1EF23g7HiJklmN4O_PQ5rS-6Tuv7_'\"))\n\tfmt.Println(filterToken(\"--token'aBcd1EF23g7HiJklmN4O_PQ5rS-6Tuv7_'\"))\n\tfmt.Println(filterToken(`-t\"aBcd1EF23g7HiJklmN4O_PQ5rS-6Tuv7_\"`))\n\tfmt.Println(filterToken(`--token\"aBcd1EF23g7HiJklmN4O_PQ5rS-6Tuv7_\"`))\n\tfmt.Println(filterToken(\"--token = aBcd1EF23g7HiJklmN4O_PQ5rS-6Tuv7_\"))\n}\n","tags":"#go #regex"},{"id":"2f502863c079c5537bc7d5577c61cb98","title":"Git: How to ignore root file but not a sub directory of the same name ","content":"Imagine you have the following tree structure:\n\n```\n.\n├── cmd\n│   └── fastly\n├── fastly\n```\n\nYou want to avoid commiting the `fastly` file in the root, but you're OK with `cmd/fastly` being committed.\n\nTo achieve this we need to use a specific wildcard glob that at first glance appears unintuitive:\n\n```gitignore\n**/fastly\n!cmd/fastly\n```\n\nWhat the first line does is match _both_ `./fastly` and `./cmd/fastly`, while the second line allows you to negate the `./cmd/fastly`.\n\nOriginally, the first line was set to `fastly` but it turns out if you do that, the second line will no longer work because the first line is matched anywhere in the path, and that means gitignore cannot negate files inside an an already ignored directory (which this would do, i.e. `fastly` isn't ignoring the root `fastly` file, it's ignoring _anything_ that contains `fastly`).\n\nThe reason `**/fastly` didn't immediately spring to mind for me is because I read it as matching any subdirectory containing `fastly` (e.g. it would match `cmd/fastly`), when in fact the `**/` is misleading because it will match either `./` or `\u003csome-directory-name\u003e/` and that's why it works to match `./fastly` and `./cmd/fastly` and thus we can safely negate the second line of our gitignore, because we've not just blanket ignored every possible folder containing `fastly`, we have this time in fact constrained our match to include the root file.\n","tags":"#git #ignore"},{"id":"f9f54403afe6400d8278ff4a2462b3e5","title":"Network: Debug Wifi Issues ","content":"https://twitter.com/benskuhn/status/952245967931215872?s=20\u0026t=rrNonVZFmkypiwccLlfWcA\n\nTo find out if you have any misbehaving apps, open the \"Wireless Diagnostics\" app and then click on its \"Window \u003e Logs\" menu option and enable background wifi logging, hit \"refresh,\" then run `tail /var/log/wifi.log | grep 'SCAN request'` to get a list of PIDs requesting scans.\n","tags":"#wifi #network #debug"},{"id":"20358d358840cb749bb4249a463af932","title":"macOS: Install Windows on macOS with VirtualBox ","content":"First install VirtualBox:\\\nhttps://www.virtualbox.org/wiki/Testbuilds\n\nNext download the Windows ISO:\\\nhttps://www.microsoft.com/software-download/windows11\n\nWatch this video which explains some of the VirtualBox setup:\\\nhttps://www.youtube.com/watch?v=1BOcED3RFGM\u0026t=1s\n","tags":"#virtualbox #vm #windows"},{"id":"ad42a27c7b0eaa2a56f6c9c5ed555e1e","title":"Terraform: Debugging with Delve ","content":"https://developer.hashicorp.com/terraform/plugin/debugging#debugger-based-debugging\n\n```txt\n(first shell)  dlv debug . --headless -- --debug\n(second shell) dlv connect \u003coutput from first shell\u003e\n               continue\n               \u003cCtrl-c\u003e\n               break path/to/file.go:123\n(third shell)  export TF_REATTACH_PROVIDERS=\"...\"\n               terraform apply\n(second shell) continue (do your step debugging)\n               \u003cCtrl-c\u003e (then run another terraform command from third shell)\n```\n\nYou can also debug tests (example below is for github.com/fastly/terraform-provider-fastly)...\n\n```\ncd ./fastly\nTF_ACC=true dlv test -- -test.v -test.run TestAccFastlyServiceVCL_syslog_useTLS\nbreak block_fastly_service_logging_syslog_test.go:253 // break inside the test code\nbreak block_fastly_service_logging_syslog.go:342      // break inside the execute terraform code (trigged by the test)\n```\n","tags":"#terraform #debug #delve"},{"id":"d6c1001c252c84a9c128fa3e8c477be2","title":"Go: Playground multiple files ","content":"package main\n\nimport (\n\t\"play.ground/foo\"\n)\n\nfunc main() {\n\tfoo.Bar()\n}\n\n-- go.mod --\nmodule play.ground\n\n-- foo/foo.go --\npackage foo\n\nimport \"fmt\"\n\nfunc Bar() {\n\tfmt.Println(\"The Go playground now has support for multiple files!\")\n}\n\n","tags":"#go #playground"},{"id":"fe0761860384b67797f78112aa83e733","title":"Go: r.Host vs r.URL.Host ","content":"For clarity on `r.Host` vs `r.URL.Host` see:  \nhttps://stackoverflow.com/a/42926149/14849316\n\nBut in summary:\n\n```\nGET https://www.google.com/?q=xxx HTTP/1.1\nHost: [gg.proxy.com](http://gg.proxy.com/)\n```\n\nWill set `r.URL.Host` to [`www.google.com`](http://www.google.com/) and `Host` to [`gg.proxy.com`](http://gg.proxy.com/).  \n\nWhile for `GET /?q=xxx HTTP/1.1` the `r.URL.Host` will be empty.\n\n## UPDATE go 1.17\n\n```\n// RFC 7230, section 5.3: Must treat\n//      GET /index.html HTTP/1.1\n//      Host: www.google.com\n// and\n//      GET http://www.google.com/index.html HTTP/1.1\n//      Host: doesntmatter\n// the same. In the second case, any Host line is ignored.\nreq.Host = req.URL.Host\n```\n","tags":"#go #http"},{"id":"b4c3231f0c95d59cf977c2911125a0a4","title":"Fastly: Terraform 1.0.0 Migration Guide ","content":"## Migration Guide\n\n**Resources omit `_v1` suffix**:\n\nAll resources now have a consistent naming convention which omit the previous v1 suffix.\n\n- `fastly_service_v1` -\u003e `fastly_service_vcl` (renamed with `_vcl` suffix)\n- `fastly_service_acl_entries_v1` -\u003e `fastly_service_acl_entries`\n- `fastly_service_dictionary_items_v1` -\u003e `fastly_service_dictionary_items`\n- `fastly_service_dynamic_snippet_content_v1` -\u003e `fastly_service_dynamic_snippet_content`\n- `fastly_user_v1` -\u003e `fastly_user`\n\n**Logging resources have consistent naming format**:\n\nAll logging resources now have a consistent naming convention with the provider prefixed with `logging_`.\n\n- `bigquerylogging` -\u003e `logging_bigquery`\n- `blobstoragelogging` -\u003e `logging_blobstorage`\n- `gcslogging` -\u003e `logging_gcs`\n- `httpslogging` -\u003e `logging_https`\n- `logentries` -\u003e `logging_logentries`\n- `papertrail` -\u003e `logging_papertrail`\n- `s3logging` -\u003e `logging_s3`\n- `splunk` -\u003e `logging_splunk`\n- `sumologic` -\u003e `logging_sumologic`\n- `syslog` -\u003e `logging_syslog`\n\n**Director `capacity` removed**:\n\nThe Fastly API never supported the `capacity` field for a `director` resource (this was added to the Terraform provider by mistake). Load balancing of director backends is managed by the `weight` field on each associated `backend` resource.\n\n**GCS Logging field `email` renamed**:\n\nThe Fastly API was updated with a new [`user`](https://developer.fastly.com/reference/api/logging/gcs/) field to replace `email`.\n\n**Logging `format` and `format_version` defaults changed**:\n\nPre-1.0.0 the default values for `format` and `format_version` were incorrectly set to an older version `1`. All new logging endpoints use the version `2` custom log format by default.\n\n**Backend `auto_loadbalance` default changed**:\n\nThe Fastly web interface defaults \"Auto load balance\" to \"No\". The most common reason for having multiple backends in a single service is to route different paths to different backends, rather than load balance between different origins. The provider pre-1.0.0 defaulted `auto_loadbalance` to `true`, which was considered unexpected behaviour. The default is now `false`.\n\n**Gzip `content_types` and `extensions` type changed**:\n\nThe `content_types` and `extensions` fields for a `gzip` resource, pre-1.0.0, were implemented as a [`TypeSet`](https://www.terraform.io/plugin/sdkv2/schemas/schema-types#typeset) (an **unordered** collection of items whose state index is calculated by the hash of the attributes of the set). This would result in confusing and unexpected diffs. Now they are implemented as a [`TypeList`](https://www.terraform.io/plugin/sdkv2/schemas/schema-types#typelist) (an **ordered** collection of items).\n\n**Automatically opt-in to `ignore_changes` behaviour for versionless resources**:\n\nThe versionless resources (ACL entries, Dictionary items and Dynamic VCL Snippets) are sometimes used in a way whereby they are \"seeded\" via Terraform and then updated/managed externally via the API or UI console. For this, the documentation suggests using `ignore_changes`, a built-in Terraform meta-argument, that allows the user to specify fields to ignore and from which to allow the state to drift.\n\nHowever, sometimes this isn't obvious or the user doesn't understand this suggestion until it is too late, and data ends up getting lost. This happens because the user makes changes elsewhere and doesn't use `ignore_changes`, so Terraform takes action to remove the state drift and deletes their changes. This data is then unrecoverable.\n\nIn 1.0.0 the default behaviour of these resources has changed. Terraform now ignores any changes, and only allows the \"dangerous\" behaviour by explicitly opting in with a `manage_*` option (e.g. `manage_entries`, `manage_items`, `manage_snippets` depending on the versionless resource).\n","tags":"#delete #fastly #work"},{"id":"2f03f0f2333b872e3ab543477355892d","title":"Go: generate range between two numbers ","content":"// https://goplay.tools/snippet/9m0HHtWF2B8\n\npackage main\n\nimport (\n\t\"fmt\"\n)\n\nfunc main() {\n\tfor i := range [101]int{} {\n\t\tfmt.Printf(\"9%03d\\n\", i) // prints 9000 - 9100\n\t}\n}\n\n// NOTE: This isn't necessary for the purpose I was thinking to use it because go already provides a means to pick an unused port to listen on.\n//\n// This is done by setting the port to either an empty string or \":0\".\n\nfunc StartServer() {\n\tl, err := net.Listen(\"tcp\", \":0\")\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\tdefer l.Close()\n\tlog.Println(\"listening at\", l.Addr().(*net.TCPAddr).Port)\n\thttp.Serve(l, Server{}) // Server is a type that implements ServeHTTP()\n}\n","tags":"#go"},{"id":"be89a373655fc00f50adcfea04dc9525","title":"Shell: Authenticated curl of the GitHub API ","content":"curl -i -u integralist:$api_token https://api.github.com/users/octocat \n","tags":"#curl #bash #auth #github #api"},{"id":"2a466d1d6298453796e84bb155debf53","title":"macOS: Force eject DVD from external drive ","content":"drutil list\ndrutil tray eject \u003cnumber\u003e\n","tags":"#macOS #disk #drive #dvd"},{"id":"2a4f935f186379d6f638807fec4af9a7","title":"Rust: anyhow vs thiserror ","content":"`anyhow` helps create error values out of arbitrary strings.\n\nHelpful to wrap error messages that don’t need distinct types, which is often the case in applications that just end up logging the error and don’t need to distinguish between lots of types.\n\n`thiserror` helps make proper errors out of custom types (e.g. an enum with lots of different variants).\n\nHelpful if you want to give each possible error its own type, which is often the case in libraries.\n","tags":"#rust #errorhandling"},{"id":"040909cecc68ee0e2f1dd5b91e5cafb6","title":"Go: handle unknown json data structure ","content":"package main\n\nimport (\n\t\"encoding/json\"\n\t\"fmt\"\n\t\"log\"\n)\n\nfunc main() {\n\tvar (\n\t\ti    interface{}\n\t\tm    map[string]interface{}\n\t\tok   bool\n\t\terr  error\n\t\tdata []byte\n\t)\n\n\tdata = []byte(`{\"name\":\"example\", \"foo\":123, \"bar\":true, \"baz\":\"something\"}`)\n\tif err = json.Unmarshal(data, \u0026i); err != nil {\n\t\tlog.Fatal(err)\n\t}\n\n\tfmt.Printf(\"i: %+v\\n\", i)\n\n\tif m, ok = i.(map[string]interface{}); !ok {\n\t\tlog.Fatal(\"failed to type assert data\")\n\t}\n\n\tfmt.Printf(\"m: %+v\\n\", m)\n\n\tif _, ok := m[\"name\"]; ok {\n\t\tm[\"name\"] = \"dynamic\"\n\t}\n\n\tfmt.Printf(\"m: %+v\\n\", m)\n\n\tif data, err = json.Marshal(m); err != nil {\n\t\tlog.Fatal(err)\n\t}\n\n\tfmt.Printf(\"data: %+v\\n\", string(data))\n}\n","tags":"#go #json #serialization"},{"id":"42ac0bbe464a0378fb9bb0eaf42e8312","title":"Go: combine two structs with json.Marshal ","content":"package main\n\nimport (\n\t\"encoding/json\"\n\t\"fmt\"\n)\n\ntype A struct {\n\tName        string `json:\"name\"`\n\tDescription string `json:\"description\"`\n\tURL         string `json:\"url\"`\n}\n\ntype B struct {\n\tName string `json:\"name\"`\n\t*A\n}\n\nfunc main() {\n\ta := A{Name: \"test\", Description: \"desc\", URL: \"https://example.com\"}\n\tb := B{Name: \"new name\"}\n\n\tb.A = \u0026a\n\n\tdata, _ := json.Marshal(b)\n\n\tfmt.Println(string(data))\n}\n","tags":"#go #json #serialization"},{"id":"9ea80fda8f332baf87844afa7ee63139","title":"Go: simplicity of mitchellh/cli ","content":"// https://pkg.go.dev/github.com/mitchellh/cli\npackage main\n\nimport (\n\t\"fmt\"\n\t\"log\"\n\t\"os\"\n\n\t\"github.com/mitchellh/cli\"\n)\n\ntype cmd struct {\n\thelp, synopsis string\n}\n\nfunc (c cmd) Run(args []string) (exit int) {\n\tfmt.Printf(\"\\n\\nargs: %+v\\n\\n\", args)\n\treturn\n}\n\nfunc (c cmd) Help() string {\n\treturn c.help\n}\n\nfunc (c cmd) Synopsis() string {\n\treturn c.synopsis\n}\n\nfunc fooCommandFactory() (cli.Command, error) {\n\treturn cmd{help: \"foo help\", synopsis: \"a foo command\"}, nil\n}\n\nfunc barCommandFactory() (cli.Command, error) {\n\treturn cmd{help: \"bar help\", synopsis: \"a bar command\"}, nil\n}\n\nfunc main() {\n\tc := cli.NewCLI(\"app\", \"1.0.0\")\n\tc.Args = os.Args[1:]\n\tc.Commands = map[string]cli.CommandFactory{\n\t\t\"foo\": fooCommandFactory,\n\t\t\"bar\": barCommandFactory,\n\t}\n\n\texitStatus, err := c.Run()\n\tif err != nil {\n\t\tlog.Println(err)\n\t}\n\n\tos.Exit(exitStatus)\n}\n","tags":"#go"},{"id":"c123665c4e4153fdfef58b658e51f879","title":"Shell: Generate Go documentation ","content":"#!/bin/bash\n\nset -e\n\nPACKAGE_LIST=\"\"\nfor pkg in $(go list  ./...); do \n\techo \"Generating $pkg ...\"\n\tif [[ \"$pkg\" == *\"internal\"* ]]; then\n\t\t# Skip internal packages\n\t\t:\n\telse\n\t\tPACKAGE_LIST=\"$PACKAGE_LIST $pkg\"\n\t\trm -rf docs/$pkg\n\t\tmkdir -p docs/$pkg\n\t\t# Piping into tail to skip the go module warning\n\t\tgodoc -url=pkg/$pkg | tail -n +2 \u003e docs/$pkg/index.html\n\tfi\ndone\n\n# Following: https://rohanverma.net/blog/2020/11/24/generating-go-documentation/\necho \"Generating gomarkdoc to pandoc ...\"\ngomarkdoc $PACKAGE_LIST \u003e docs/fastly-tinygo-docs.md\npandoc docs/fastly-tinygo-docs.md \\\n\t--toc \\\n\t--metadata title=\"Fastly C@E TinyGo - User Docs\" \\\n\t-c https://unpkg.com/sakura.css/css/sakura.css \\\n\t--self-contained \\\n\t-o docs/fastly-tinygo-docs.html\n","tags":"#go #shell"},{"id":"8df24d51ae2ad99f3abbc8df156faaef","title":"Go: GitHub API Client ","content":"package main\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"log\"\n\t\"os\"\n\t\"sort\"\n\t\"strings\"\n\t\"sync\"\n\n\t\"github.com/fatih/color\"\n\t\"github.com/google/go-github/v42/github\"\n\t\"golang.org/x/oauth2\"\n)\n\nvar (\n\tbold  = color.New(color.FgHiYellow).Add(color.Bold).SprintFunc()\n\ttitle = color.New(color.FgHiRed).Add(color.Underline).Add(color.Bold).SprintFunc()\n)\n\nfunc main() {\n\tclient := NewGitHubClient()\n\torg := \"fastly\"\n\n\tvar wg sync.WaitGroup\n\twg.Add(2)\n\n\tgo DisplayReposMissingDescription(client, org, \u0026wg)\n\tgo DisplayDomainSquatters(client, org, \u0026wg)\n\n\twg.Wait()\n}\n\n// NewGitHubClient returns a client for making API requests to GitHub.\n//\n// NOTE:\n// Ensure you have an API token exposed via the environment variable:\n// GITHUB_TOKEN_TERMINAL_TOOL\nfunc NewGitHubClient() *github.Client {\n\tsts := oauth2.StaticTokenSource(\n\t\t\u0026oauth2.Token{\n\t\t\tAccessToken: os.Getenv(\"GITHUB_TOKEN_TERMINAL_TOOL\"),\n\t\t},\n\t)\n\tc := oauth2.NewClient(context.Background(), sts)\n\n\treturn github.NewClient(c)\n}\n\n// NewOptions configures the ListByOrg API endpoint.\nfunc NewOptions() *github.RepositoryListByOrgOptions {\n\treturn \u0026github.RepositoryListByOrgOptions{\n\t\tListOptions: github.ListOptions{\n\t\t\tPerPage: 100,\n\t\t},\n\t}\n}\n\n// DisplayReposMissingDescription prints all the repos that have no\n// description, including whether the repo is private or public.\n//\n// NOTE:\n// This function is run concurrently with DisplayDomainSquatters.\n// To prevent interweaving of printed output we write data to a buffer which is\n// then flushed once the search operation is finished.\nfunc DisplayReposMissingDescription(client *github.Client, org string, wg *sync.WaitGroup) {\n\tvar b strings.Builder\n\n\tfmt.Fprintf(\u0026b, \"%s\\n\\n\", title(\"Repos with no description...\"))\n\n\topts := NewOptions()\n\tcount := 0\n\n\tfor {\n\t\trepos, resp, err := client.Repositories.ListByOrg(context.Background(), org, opts)\n\t\tif err != nil {\n\t\t\tlog.Fatal(err)\n\t\t}\n\t\tfor _, r := range repos {\n\t\t\tif r.GetDescription() == \"\" {\n\t\t\t\tcount += 1\n\t\t\t\tfmt.Fprintf(\u0026b, \"%s: %s\\n%s %t\\n\\n\", bold(\"URL\"), r.GetHTMLURL(), bold(\"Private?\"), r.GetPrivate())\n\t\t\t}\n\t\t}\n\t\tif resp.NextPage == 0 {\n\t\t\tbreak\n\t\t}\n\t\topts.Page = resp.NextPage\n\t}\n\n\tfmt.Fprintf(\u0026b, \"Total repos without a description: %d\\n\\n\", count)\n\tfmt.Println(b.String())\n\n\twg.Done()\n}\n\n// DisplayDomainSquatters prints all the repos that contain only a single\n// README.md file, including whether the repo is private or public.\n//\n// NOTE:\n// This function is run concurrently with DisplayReposMissingDescription.\n// To prevent interweaving of printed output we write data to a buffer which is\n// then flushed once the search operation is finished.\n//\n// TODO:\n// Some repos have content in non-default branches. This suggests the repo\n// might be WIP (Work in Progress). We should update the script to inspect the\n// last modified date for the branch. If modified recently (e.g. within the\n// last month), then it's probably safe to keep the repo. Otherwise we should\n// reach out to the team/person responsible for the repo about removing it.\nfunc DisplayDomainSquatters(client *github.Client, org string, wg *sync.WaitGroup) {\n\tvar b strings.Builder\n\n\tfmt.Fprintf(\u0026b, \"%s\\n\\n\", title(\"Repos that are domain squatting...\"))\n\n\topts := NewOptions()\n\tcount := 0\n\n\tfor {\n\t\trepos, resp, err := client.Repositories.ListByOrg(context.Background(), \"fastly\", opts)\n\t\tif err != nil {\n\t\t\tlog.Fatal(err)\n\t\t}\n\t\tsort.Slice(repos, func(i, j int) bool {\n\t\t\treturn repos[i].GetName() \u003c repos[j].GetName()\n\t\t})\n\t\tfor _, r := range repos {\n\t\t\t_, directoryContent, _, err := client.Repositories.GetContents(context.Background(), org, r.GetName(), \"/\", nil)\n\t\t\tif err != nil {\n\t\t\t\tif !strings.Contains(err.Error(), \"This repository is empty\") {\n\t\t\t\t\tlog.Fatal(err)\n\t\t\t\t}\n\t\t\t}\n\t\t\tif len(directoryContent) == 1 \u0026\u0026 strings.ToLower(directoryContent[0].GetName()) == \"readme.md\" {\n\t\t\t\tcount += 1\n\t\t\t\tfmt.Fprintf(\u0026b, \"%s: %s\\n%s %t\\n\\n\", bold(\"URL\"), r.GetHTMLURL(), bold(\"Private?\"), r.GetPrivate())\n\t\t\t}\n\t\t}\n\t\tif resp.NextPage == 0 {\n\t\t\tbreak\n\t\t}\n\t\topts.Page = resp.NextPage\n\t}\n\n\tfmt.Fprintf(\u0026b, \"Total repos that are domain squatting: %d\", count)\n\tfmt.Println(b.String())\n\n\twg.Done()\n}\npackage main\n\nimport (\n\t\"context\"\n\t\"flag\"\n\t\"fmt\"\n\t\"log\"\n\t\"os\"\n\t\"sort\"\n\t\"strings\"\n\t\"sync\"\n\n\t\"github.com/fatih/color\"\n\t\"github.com/google/go-github/v42/github\"\n\t\"golang.org/x/oauth2\"\n)\n\nvar (\n\tbold  = color.New(color.FgHiYellow).Add(color.Bold).SprintFunc()\n\ttitle = color.New(color.FgHiRed).Add(color.Underline).Add(color.Bold).SprintFunc()\n)\n\nfunc main() {\n\tmd := flag.Bool(\"missing\", false, \"Display repos missing descriptions\")\n\tds := flag.Bool(\"squatters\", false, \"Display repos that are domain squatting\")\n\tflag.Parse()\n\n\tclient := NewGitHubClient()\n\torg := \"fastly\"\n\n\tif !*md \u0026\u0026 !*ds {\n\t\tflag.PrintDefaults()\n\t}\n\n\tvar wg sync.WaitGroup\n\tif *md {\n\t\twg.Add(1)\n\t\tgo DisplayReposMissingDescription(client, org, \u0026wg)\n\t}\n\tif *ds {\n\t\twg.Add(1)\n\t\tgo DisplayDomainSquatters(client, org, \u0026wg)\n\t}\n\twg.Wait()\n}\n\n// NewGitHubClient returns a client for making API requests to GitHub.\n//\n// NOTE:\n// Ensure you have an API token exposed via the environment variable:\n// GITHUB_TOKEN_TERMINAL_TOOL\nfunc NewGitHubClient() *github.Client {\n\tsts := oauth2.StaticTokenSource(\n\t\t\u0026oauth2.Token{\n\t\t\tAccessToken: os.Getenv(\"GITHUB_TOKEN_TERMINAL_TOOL\"),\n\t\t},\n\t)\n\tc := oauth2.NewClient(context.Background(), sts)\n\n\treturn github.NewClient(c)\n}\n\n// NewOptions configures the ListByOrg API endpoint.\nfunc NewOptions() *github.RepositoryListByOrgOptions {\n\treturn \u0026github.RepositoryListByOrgOptions{\n\t\tListOptions: github.ListOptions{\n\t\t\tPerPage: 100,\n\t\t},\n\t}\n}\n\n// DisplayReposMissingDescription prints all the repos that have no\n// description, including whether the repo is private or public.\n//\n// NOTE:\n// This function is run concurrently with DisplayDomainSquatters.\n// To prevent interweaving of printed output we write data to a buffer which is\n// then flushed once the search operation is finished.\nfunc DisplayReposMissingDescription(client *github.Client, org string, wg *sync.WaitGroup) {\n\tvar b strings.Builder\n\n\tfmt.Fprintf(\u0026b, \"%s\\n\\n\", title(\"Repos with no description...\"))\n\n\topts := NewOptions()\n\tcount := 0\n\n\tfor {\n\t\trepos, resp, err := client.Repositories.ListByOrg(context.Background(), org, opts)\n\t\tif err != nil {\n\t\t\tlog.Fatal(err)\n\t\t}\n\t\tfor _, r := range repos {\n\t\t\tif r.GetDescription() == \"\" {\n\t\t\t\tcount += 1\n\t\t\t\tfmt.Fprintf(\u0026b, \"%s: %s\\n%s %t\\n\\n\", bold(\"URL\"), r.GetHTMLURL(), bold(\"Private?\"), r.GetPrivate())\n\t\t\t}\n\t\t}\n\t\tif resp.NextPage == 0 {\n\t\t\tbreak\n\t\t}\n\t\topts.Page = resp.NextPage\n\t}\n\n\tfmt.Fprintf(\u0026b, \"Total repos without a description: %d\\n\\n\", count)\n\tfmt.Println(b.String())\n\n\twg.Done()\n}\n\n// DisplayDomainSquatters prints all the repos that contain only a single\n// README.md file, including whether the repo is private or public.\n//\n// NOTE:\n// This function is run concurrently with DisplayReposMissingDescription.\n// To prevent interweaving of printed output we write data to a buffer which is\n// then flushed once the search operation is finished.\n//\n// TODO:\n// Some repos have content in non-default branches. This suggests the repo\n// might be WIP (Work in Progress). We should update the script to inspect the\n// last modified date for the branch. If modified recently (e.g. within the\n// last month), then it's probably safe to keep the repo. Otherwise we should\n// reach out to the team/person responsible for the repo about removing it.\nfunc DisplayDomainSquatters(client *github.Client, org string, wg *sync.WaitGroup) {\n\tvar b strings.Builder\n\n\tfmt.Fprintf(\u0026b, \"%s\\n\\n\", title(\"Repos that are domain squatting...\"))\n\n\topts := NewOptions()\n\tcount := 0\n\n\tfor {\n\t\trepos, resp, err := client.Repositories.ListByOrg(context.Background(), \"fastly\", opts)\n\t\tif err != nil {\n\t\t\tlog.Fatal(err)\n\t\t}\n\t\tsort.Slice(repos, func(i, j int) bool {\n\t\t\treturn repos[i].GetName() \u003c repos[j].GetName()\n\t\t})\n\t\tfor _, r := range repos {\n\t\t\t_, directoryContent, _, err := client.Repositories.GetContents(context.Background(), org, r.GetName(), \"/\", nil)\n\t\t\tif err != nil {\n\t\t\t\tif !strings.Contains(err.Error(), \"This repository is empty\") {\n\t\t\t\t\tlog.Fatal(err)\n\t\t\t\t}\n\t\t\t}\n\t\t\tif len(directoryContent) == 1 \u0026\u0026 strings.ToLower(directoryContent[0].GetName()) == \"readme.md\" {\n\t\t\t\tcount += 1\n\t\t\t\tfmt.Fprintf(\u0026b, \"%s: %s\\n%s %t\\n\\n\", bold(\"URL\"), r.GetHTMLURL(), bold(\"Private?\"), r.GetPrivate())\n\t\t\t}\n\t\t}\n\t\tif resp.NextPage == 0 {\n\t\t\tbreak\n\t\t}\n\t\topts.Page = resp.NextPage\n\t}\n\n\tfmt.Fprintf(\u0026b, \"Total repos that are domain squatting: %d\", count)\n\tfmt.Println(b.String())\n\n\twg.Done()\n}\n// NOTE: GitHub API rate limit is 5,000 requests per hour for 'user-to-server'.\npackage main\n\nimport (\n\t\"context\"\n\t\"flag\"\n\t\"fmt\"\n\t\"log\"\n\t\"os\"\n\t\"strings\"\n\t\"sync\"\n\t\"sync/atomic\"\n\n\t\"github.com/fatih/color\"\n\t\"github.com/google/go-github/v42/github\"\n\t\"golang.org/x/oauth2\"\n)\n\n// perPage is the number of items per page to be loaded from the API.\nconst perPage = 100\n\nvar (\n\tbold  = color.New(color.FgHiYellow).Add(color.Bold).SprintFunc()\n\ttitle = color.New(color.FgHiRed).Add(color.Underline).Add(color.Bold).SprintFunc()\n)\n\nfunc main() {\n\tmd := flag.Bool(\"missing\", false, \"Display repos missing descriptions\")\n\tds := flag.Bool(\"squatters\", false, \"Display repos that are domain squatting\")\n\tflag.Parse()\n\n\tclient := NewGitHubClient()\n\torg := \"fastly\"\n\n\tif !*md \u0026\u0026 !*ds {\n\t\tflag.PrintDefaults()\n\t}\n\n\tpages := numOfPages(client, org)\n\trepos := fetchRepos(client, org, pages)\n\n\tvar wg sync.WaitGroup\n\tif *md {\n\t\twg.Add(1)\n\t\tgo DisplayReposMissingDescription(repos, \u0026wg)\n\t}\n\tif *ds {\n\t\twg.Add(1)\n\t\tgo DisplayDomainSquatters(repos, client, org, \u0026wg)\n\t}\n\twg.Wait()\n}\n\n// NewGitHubClient returns a client for making API requests to GitHub.\n//\n// NOTE:\n// Ensure you have an API token exposed via the environment variable:\n// GITHUB_TOKEN_TERMINAL_TOOL\nfunc NewGitHubClient() *github.Client {\n\tsts := oauth2.StaticTokenSource(\n\t\t\u0026oauth2.Token{\n\t\t\tAccessToken: os.Getenv(\"GITHUB_TOKEN_TERMINAL_TOOL\"),\n\t\t},\n\t)\n\tc := oauth2.NewClient(context.Background(), sts)\n\n\treturn github.NewClient(c)\n}\n\n// numOfPages calculates the number of pages that need to be paginated based on\n// the total public and private repos across the `perPage` constant.\nfunc numOfPages(client *github.Client, org string) int {\n\to, _, err := client.Organizations.Get(context.Background(), org)\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\treturn (o.GetPublicRepos() + o.GetOwnedPrivateRepos()) / perPage\n}\n\n// fetchRepos makes multiple concurrent API requests for repositories.\nfunc fetchRepos(client *github.Client, org string, numOfPages int) []*github.Repository {\n\tvar m sync.Mutex\n\trepos := []*github.Repository{}\n\n\tprocess := func(page int, wg *sync.WaitGroup) {\n\t\topts := NewOptions()\n\t\topts.Page = page\n\n\t\trepositories, _, err := client.Repositories.ListByOrg(context.Background(), org, opts)\n\t\tif err != nil {\n\t\t\tlog.Fatal(err)\n\t\t}\n\t\tfor _, r := range repositories {\n\t\t\tm.Lock()\n\t\t\trepos = append(repos, r)\n\t\t\tm.Unlock()\n\t\t}\n\t\twg.Done()\n\t}\n\n\tvar wg sync.WaitGroup\n\twg.Add(numOfPages)\n\tfor i := 1; i \u003c= numOfPages; i++ {\n\t\tgo process(i, \u0026wg)\n\t}\n\twg.Wait()\n\n\treturn repos\n}\n\n// NewOptions configures the ListByOrg API endpoint.\nfunc NewOptions() *github.RepositoryListByOrgOptions {\n\treturn \u0026github.RepositoryListByOrgOptions{\n\t\tListOptions: github.ListOptions{\n\t\t\tPerPage: perPage,\n\t\t},\n\t}\n}\n\n// DisplayReposMissingDescription prints all the repos that have no\n// description, including whether the repo is private or public.\n//\n// NOTE:\n// This function is run concurrently with DisplayDomainSquatters.\n// To prevent interweaving of printed output we write data to a buffer which is\n// then flushed once the search operation is finished.\n//\n// TODO:\n// The two Display* functions both need to paginate over the same amount of\n// pages, so only do it once and then store off the data to pass into both\n// functions instead of repeating the operations.\nfunc DisplayReposMissingDescription(repos []*github.Repository, wg *sync.WaitGroup) {\n\tvar (\n\t\tb     strings.Builder\n\t\tcount int\n\t)\n\n\tfmt.Fprintf(\u0026b, \"%s\\n\\n\", title(\"Repos with no description...\"))\n\n\tfor _, r := range repos {\n\t\tif r.GetDescription() == \"\" {\n\t\t\tcount += 1\n\t\t\tfmt.Fprintf(\u0026b, \"%s: %s\\n%s %t\\n\\n\", bold(\"URL\"), r.GetHTMLURL(), bold(\"Private?\"), r.GetPrivate())\n\t\t}\n\t}\n\n\tfmt.Fprintf(\u0026b, \"Total repos without a description: %d\\n\\n\", count)\n\tfmt.Println(b.String())\n\n\twg.Done()\n}\n\n// DisplayDomainSquatters prints all the repos that contain only a single\n// README.md file, including whether the repo is private or public.\n//\n// NOTE:\n// This function is run concurrently with DisplayReposMissingDescription.\n// To prevent interweaving of printed output we write data to a buffer which is\n// then flushed once the search operation is finished.\n//\n// Additionally we execute the API requests for repo file contents\n// concurrently, and we use a semaphore pattern to batch those requests\n// otherwise the GitHub API will issue us a secondary rate limit message.\n//\n// TODO:\n// Some repos have content in non-default branches. This suggests the repo\n// might be WIP (Work in Progress). We should update the script to inspect the\n// last modified date for the branch. If modified recently (e.g. within the\n// last month), then it's probably safe to keep the repo. Otherwise we should\n// reach out to the team/person responsible for the repo about removing it.\nfunc DisplayDomainSquatters(repos []*github.Repository, client *github.Client, org string, wg *sync.WaitGroup) {\n\tvar (\n\t\tb     strings.Builder\n\t\tcount uint64\n\t\tm     sync.Mutex\n\t)\n\n\tfmt.Fprintf(\u0026b, \"%s\\n\\n\", title(\"Repos that are domain squatting...\"))\n\n\tsemaphore := make(chan struct{}, 50) // 50 is the maximum number of concurrent processes that may run at any time\n\n\tprocess := func(r *github.Repository, wg2 *sync.WaitGroup) {\n\t\t// Will block once more than 100 instances of `process` are called.\n\t\tsemaphore \u003c- struct{}{}\n\n\t\t// Empty buffered channel by one so the next call to `process` can begin.\n\t\tdefer func() { \u003c-semaphore }()\n\n\t\t// Done must be called before pulling from the semaphore channel.\n\t\tdefer wg2.Done()\n\n\t\t_, directoryContent, _, err := client.Repositories.GetContents(context.Background(), org, r.GetName(), \"/\", nil)\n\t\tif err != nil {\n\t\t\tif !strings.Contains(err.Error(), \"This repository is empty\") {\n\t\t\t\tlog.Fatal(err)\n\t\t\t}\n\t\t}\n\t\tif len(directoryContent) == 1 \u0026\u0026 strings.ToLower(directoryContent[0].GetName()) == \"readme.md\" {\n\t\t\tatomic.AddUint64(\u0026count, 1)\n\n\t\t\t// The strings.Builder type is not thread-safe.\n\t\t\tm.Lock()\n\t\t\tfmt.Fprintf(\u0026b, \"%s: %s\\n%s %t\\n\\n\", bold(\"URL\"), r.GetHTMLURL(), bold(\"Private?\"), r.GetPrivate())\n\t\t\tm.Unlock()\n\t\t}\n\t}\n\n\tvar wg2 sync.WaitGroup\n\twg2.Add(len(repos))\n\tfor _, r := range repos {\n\t\tgo process(r, \u0026wg2)\n\t}\n\twg2.Wait()\n\tclose(semaphore)\n\n\tfmt.Fprintf(\u0026b, \"Total repos that are domain squatting: %d\", count)\n\tfmt.Println(b.String())\n\n\twg.Done()\n}\npackage main\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"log\"\n\t\"os\"\n\t\"sort\"\n\t\"strings\"\n\n\t\"github.com/fatih/color\"\n\t\"github.com/google/go-github/v42/github\"\n\t\"golang.org/x/oauth2\"\n)\n\nfunc main() {\n\tctx := context.Background()\n\tts := oauth2.StaticTokenSource(\n\t\t\u0026oauth2.Token{AccessToken: os.Getenv(\"GITHUB_TOKEN_TERMINAL_TOOL\")},\n\t)\n\ttc := oauth2.NewClient(ctx, ts)\n\n\tclient := github.NewClient(tc)\n\n\t// orgs, _, err := client.Organizations.List(context.Background(), \"integralist\", nil)\n\t// if err != nil {\n\t// \tlog.Fatal(err)\n\t// }\n\t// fmt.Printf(\"orgs: %+v\\n\", orgs)\n\n\t// opt := \u0026github.RepositoryListByOrgOptions{Type: \"private\"}\n\t// repos, _, err := client.Repositories.ListByOrg(context.Background(), \"fastly\", opt)\n\t// if err != nil {\n\t// \tlog.Fatal(err)\n\t// }\n\t// fmt.Printf(\"private repos: %d\\n\", len(repos))\n\n\tbold := color.New(color.FgHiYellow).Add(color.Bold).SprintFunc()\n\ttitle := color.New(color.FgHiRed).Add(color.Underline).Add(color.Bold)\n\ttitle.Print(\"Repos with no description...\\n\\n\")\n\n\t// repos, _, err := client.Repositories.ListByOrg(context.Background(), \"fastly\", nil)\n\t// if err != nil {\n\t// \tlog.Fatal(err)\n\t// }\n\n\t// for _, repo := range repos {\n\t// \tif repo.GetDescription() == \"\" {\n\t// \t\tfmt.Printf(\"%s: %s\\n%s %t\\n\\n\", bold(\"URL\"), repo.GetHTMLURL(), bold(\"Private?\"), repo.GetPrivate())\n\t// \t}\n\t// }\n\n\torg := \"fastly\"\n\topts := \u0026github.RepositoryListByOrgOptions{\n\t\tListOptions: github.ListOptions{\n\t\t\tPerPage: 100,\n\t\t},\n\t}\n\tcount := 0\n\n\tfor {\n\t\trepos, resp, err := client.Repositories.ListByOrg(context.Background(), org, opts)\n\t\tif err != nil {\n\t\t\tlog.Fatal(err)\n\t\t}\n\t\tfor _, r := range repos {\n\t\t\tif r.GetDescription() == \"\" {\n\t\t\t\tcount += 1\n\t\t\t\tfmt.Printf(\"%s: %s\\n%s %t\\n\\n\", bold(\"URL\"), r.GetHTMLURL(), bold(\"Private?\"), r.GetPrivate())\n\t\t\t}\n\t\t}\n\t\tif resp.NextPage == 0 {\n\t\t\tbreak\n\t\t}\n\t\topts.Page = resp.NextPage\n\t}\n\tfmt.Printf(\"Total repos without a description: %d\\n\\n\", count)\n\n\ttitle.Print(\"Repos that are domain squatting...\\n\\n\")\n\n\topts = \u0026github.RepositoryListByOrgOptions{\n\t\tListOptions: github.ListOptions{\n\t\t\tPerPage: 100,\n\t\t},\n\t}\n\tcount = 0\n\n\tfor {\n\t\trepos, resp, err := client.Repositories.ListByOrg(context.Background(), org, opts)\n\t\tif err != nil {\n\t\t\tlog.Fatal(err)\n\t\t}\n\t\tsort.Slice(repos, func(i, j int) bool {\n\t\t\treturn repos[i].GetName() \u003c repos[j].GetName()\n\t\t})\n\t\tfor _, r := range repos {\n\t\t\t_, directoryContent, _, err := client.Repositories.GetContents(context.Background(), org, r.GetName(), \"/\", nil)\n\t\t\tif err != nil {\n\t\t\t\tif !strings.Contains(err.Error(), \"This repository is empty\") {\n\t\t\t\t\tlog.Fatal(err)\n\t\t\t\t}\n\t\t\t}\n\t\t\tif len(directoryContent) == 1 \u0026\u0026 strings.ToLower(directoryContent[0].GetName()) == \"readme.md\" {\n\t\t\t\tcount += 1\n\t\t\t\tfmt.Printf(\"%s: %s\\n%s %t\\n\\n\", bold(\"URL\"), r.GetHTMLURL(), bold(\"Private?\"), r.GetPrivate())\n\t\t\t}\n\t\t}\n\t\tif resp.NextPage == 0 {\n\t\t\tbreak\n\t\t}\n\t\topts.Page = resp.NextPage\n\t}\n\tfmt.Printf(\"Total repos that are domain squatting: %d\", count)\n}\n","tags":"#go #api"},{"id":"777a9d9f554f916fb30e911754c2eb54","title":"Rust: parse string to custom type ","content":"// https://twitter.com/integralist/status/1508844091504836612\n//\n// Learning #rustlang and (yes it's a contrived example) \n// I'm liking being able to piggy back off existing methods like .parse() \n// and having it serialise data into a custom type via the FromStr trait.\n//\n// EXPLANATION:\n// Roughly what is happening here is when we call parse() on the given \n// string \"beep\" the compiler checks the type (in this case Foo is \n// assigned to the variable f) and so it knows that Foo needs to \n// implement the FromStr trait (which it sees that it does). So when the \n// compiler then calls FromStr::from_self(self) (the self evaluating to \n// the string \"beep\" and subsequently the correlating type Foo) it's able \n// to swap out the traits from_self with the `impl std::str::FromStr for \n// Foo` implementation.\n//\n// A similar example of this 'inference' of an implementation, and being \n// able to call a trait method that has no default implementation, is:\n//\n// fn takes_vec(v: Vec\u003ci32\u003e) {}\n// fn main() {\n//   takes_vec(FromIterator::from_iter(0..10));\n// }\n//\n// Internally the range (0..10) is called with .collect() like so:\n//\n// (0..10).collect()\n//\n// Which means the compiler knows that the range must be collected into\n// a Vect\u003ci32\u003e, and from there the compiler then knows to swap out the\n// call to FromIterator::from_iter with the Vector's own implementation.\n\n#[derive(Debug)]\nstruct Foo {\n    bar: String,\n}\n\n// http://doc.rust-lang.org/1.59.0/std/str/trait.FromStr.html\nimpl std::str::FromStr for Foo {\n    type Err = Box\u003cdyn std::error::Error\u003e;\n\n    fn from_str(s: \u0026str) -\u003e Result\u003cSelf, Self::Err\u003e {\n        Ok(Foo{bar: s.to_string()})\n    }\n}\n\nfn main() {\n    let f = Foo{bar: \"baz\".to_string()};\n    println!(\"{:#?}\", f);\n    println!(\"{:#?}\", f.bar);\n\n    let f: Foo = \"beep\".parse().unwrap();\n    println!(\"{:#?}\", f);\n}\n","tags":"#rust #trait"},{"id":"cbb09aef4897d2a6a2c03499f8e03064","title":"Go: Docker Go/TinyGo Application ","content":"The following build command is used...\n\n```bash\ndocker buildx build --platform linux/arm64 -t testing-tinygo . -f ./Dockerfile\n```\n\n...to avoid the following error:\n\n```\nThe requested image's platform (linux/amd64) does not match the detected host platform (linux/arm64/v8) and no specific platform was requested\n```\n\nThe `Dockerfile` used is:\n\n```Dockerfile\nFROM golang:1.18.1 AS golang\n\n# Move to fiddle workspace\nWORKDIR /app\n\n# Copy default workspace\nCOPY src src\nCOPY go.mod .\n\n# Enable access to internal repositories\nRUN apt-get update \u0026\u0026 apt-get install -y git\nRUN git config --global url.\"https://\u003cREDACTED\u003e:x-oauth-basic@github.com/\".insteadOf \"https://github.com/\"\nRUN mkdir -p /root/.ssh\nRUN echo \"StrictHostKeyChecking no\" \u003e /root/.ssh/config\nENV GOPRIVATE=github.com/fastly\n\n# Fetch dependencies ahead of time\nRUN go get ./...\nRUN go mod download\n\nFROM tinygo/tinygo:0.23.0\n\n# Move to fiddle workspace\nWORKDIR /tmp/fiddle\n\n# Pull files from previous build stage.\nCOPY --from=golang /go /go\nCOPY --from=golang /app/src ./src\nCOPY --from=golang /app/go.mod ./go.mod\nCOPY --from=golang /app/go.sum ./go.sum\n\n# Enable access to internal repositories\nRUN apt-get update \u0026\u0026 apt-get install -y git\nRUN git config --global url.\"https://\u003cREDACTED\u003e:x-oauth-basic@github.com/\".insteadOf \"https://github.com/\"\nRUN mkdir -p /root/.ssh\nRUN echo \"StrictHostKeyChecking no\" \u003e /root/.ssh/config\nENV GOPRIVATE=github.com/fastly\n\n# Compile the project\nRUN mkdir bin/\nRUN tinygo build -target=wasi -wasm-abi=generic -gc=conservative -scheduler=asyncify -o bin/main.wasm ./src\n```\n\n\u003e **NOTE**: We don't need multi-stage build. We can just build straight from `tinygo` image (see below).\n\n```Dockerfile\nFROM tinygo/tinygo:0.23.0\n\n# Move to fiddle workspace\nWORKDIR /tmp/fiddle\n\n# Copy over template files\nCOPY src src\nCOPY go.mod .\n\n# Enable access to internal repositories\nRUN apt-get update \u0026\u0026 apt-get -y install git\nRUN git config --global url.\"https://\u003cREDACTED\u003e:x-oauth-basic@github.com/\".insteadOf \"https://github.com/\"\nRUN mkdir -p /root/.ssh\nRUN echo \"StrictHostKeyChecking no\" \u003e /root/.ssh/config\nENV GOPRIVATE=github.com/fastly\n\n# Fetch dependencies ahead of time\nRUN go get ./...\nRUN go mod download\n\n# Compile the project\nRUN mkdir bin/\nRUN tinygo build -target=wasi -wasm-abi=generic -gc=conservative -scheduler=asyncify -o bin/main.wasm ./src\n```\n","tags":"#docker #go"},{"id":"5d597e6069299ddb6698e637b13471c1","title":"Rust: Parse program releases ","content":"#![allow(unused)]\n\nuse std::{\n    fmt::Display,\n    fs::File,\n    io::{BufRead, BufReader, Read},\n};\n\n#[derive(Debug, Clone, Copy, PartialEq, Eq)]\nstruct SemVer {\n    major: u16,\n    minor: u16,\n    patch: u16,\n}\n\nimpl SemVer {\n    fn new(major: u16, minor: u16, patch: u16) -\u003e SemVer {\n        SemVer {\n            major,\n            minor,\n            patch,\n        }\n    }\n\n    fn new_short(major: u16) -\u003e SemVer {\n        Self::new(major, 0, 0)\n    }\n\n    fn info(\u0026self) {\n        println!(\n            \"hi, I'm a semver: {}.{}.{}\",\n            self.major, self.minor, self.patch\n        )\n    }\n\n    fn patch(\u0026mut self) -\u003e \u0026mut u16 {\n        \u0026mut self.patch\n    }\n}\n\nimpl Default for SemVer {\n    fn default() -\u003e Self {\n        Self::new_short(1)\n    }\n}\n\nimpl Display for SemVer {\n    fn fmt(\u0026self, f: \u0026mut std::fmt::Formatter\u003c'_\u003e) -\u003e std::fmt::Result {\n        write!(f, \"{}.{}.{}\", self.major, self.minor, self.patch)\n    }\n}\n\n// http://doc.rust-lang.org/1.59.0/std/convert/trait.From.html\nimpl From\u003c\u0026str\u003e for SemVer {\n    fn from(s: \u0026str) -\u003e Self {\n        let vs: Vec\u003cu16\u003e = s.split('.').filter_map(|item| item.parse().ok()).collect();\n        assert!(vs.len() == 3);\n        SemVer {\n            major: vs[0],\n            minor: vs[1],\n            patch: vs[2],\n        }\n    }\n}\n\n#[derive(Debug)]\nstruct Program {\n    name: String,\n    release_history: Vec\u003cSemVer\u003e,\n}\n\nfn main() -\u003e Result\u003c(), std::io::Error\u003e {\n    // create a `Vec` to hold the list of programs\n    let mut programs: Vec\u003cProgram\u003e = Vec::new();\n\n    // open \"releases.txt\", bail on error\n    let f = File::open(\"releases.txt\")?;\n    let reader = BufReader::new(f);\n\n    // use a `BufReader` to iterate over the lines of the file handle\n    // if the line can be read (it might be invalid data), split it on \",\"\n    // take the first element of your split - that's the name\n    // the rest is a list of \u0026str slices that each can be MAPPED INTO a SemVer!\n    // we're still in iterator land - time to collect and push the result to our program vec\n    // \n    // TODO: Investigate reducing down with either .map or .filter_map.\n    for line in reader.lines().flatten() {\n        let line: Vec\u003c\u0026str\u003e = line.split(',').collect();\n        let program = line[0];\n\n        if !program.is_empty() {\n            let versions = line[1..].iter().filter(|item| !item.is_empty());\n            let mut semvers: Vec\u003cSemVer\u003e = Vec::new();\n            for version in versions {\n                semvers.push(SemVer::from(*version))\n            }\n            if !semvers.is_empty() {\n                programs.push(Program{\n                    name: program.to_string(),\n                    release_history: semvers,\n                });\n            }\n        }\n    }\n\n    // finally, print the program vec.\n    println!(\"{:#?}\", programs);\n\n    Ok(())\n}\nhello-world,0.0.1,0.0.5,1.0.0\n\nno-versions-with-comma,\nsemver-training,0.0.1\nno-versions-no-comma\nfoo-with-sparse-array-of-versions,1.0.1,,2.0.0\nfile-io,0.1.5,1.0.1,2.0.0,2.0.5\n","tags":"#rust #exercise #io #file #semver #trait"},{"id":"82676169a06231d0e71badbde9fdd55a","title":"Laptop: New Laptop Software Installation ","content":"## Backup\n\n```bash\ncd ~/\nmkdir /tmp/keys\ngpg --export-secret-keys --armor \u003cNAME\u003e \u003e /tmp/keys/\u003cNAME\u003e.asc\ngpg --symmetric /tmp/keys/\u003cNAME\u003e.asc\ngpg --export-ownertrust \u003e /tmp/keys/trustdb.txt \n\nzip -r /tmp/keys/sshbackup ~/.ssh/\nunzip -l /tmp/keys/sshbackup.zip\ngpg --symmetric /tmp/keys/sshbackup.zip\n\nrm -rf /tmp/keys\n```\n\n## Steps\n\n1. Install Rust.\n  ```\n  curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh\n  ```\n2. Install Go.\n  ```\n  https://go.dev/dl/\n  ```\n3. Import GPG/SSH keys.\n  ```txt\n  mkdir /tmp/keys\n  cd /tmp/keys\n  \n  gpg --decrypt /tmp/keys/\u003cNAME\u003e.gpg \u003e \u003cNAME\u003e\n  gpg --import \u003cNAME\u003e.asc\n  \n  rm ~/.gnupg/trustdb.gpg\n  gpg --import-ownertrust \u003c /tmp/keys/trustdb.txt\n  \n  gpg --decrypt /tmp/keys/sshbackup.zip.gpg \u003e sshbackup.zip\n  unzip /tmp/keys/sshbackup.zip\n  mv /tmp/keys/.ssh/ ~/\n  \n  rm -rf /tmp/keys\n  ```\n4. Setup SSH.\n  ```txt\n  eval \"$(ssh-agent -s)\"\n  ssh-add --apple-use-keychain ~/.ssh/github\n  ```\n5. Install Alacritty.\n  ```txt\n  https://github.com/alacritty/alacritty/releases\n  mkdir .bash_completion\n  curl https://raw.githubusercontent.com/alacritty/alacritty/master/extra/completions/alacritty.bash -o ~/.bash_completion/alacritty\n  ```\n6. Install Fig.\n  ```txt\n  https://fig.io/\n  ```\n7. Install Homebrew + packages.\n  ```txt\n  https://brew.sh\n  brew bundle --file /tmp/Brewfile install\n  ```\n8. Change default shell to bash.\n  ```txt\n  echo /opt/homebrew/bin/zsh | sudo tee -a /etc/shells\n  chsh -s /opt/homebrew/bin/zsh\n  ```\n9. Configure Vim-Plug.\n  ```\n  sh -c 'curl -fLo \"${XDG_DATA_HOME:-$HOME/.local/share}\"/nvim/site/autoload/plug.vim --create-dirs \\\n       https://raw.githubusercontent.com/junegunn/vim-plug/master/plug.vim'\n  ```\n10. Setup dotfiles.\n  ```\n  cd /tmp\n  git clone https://github.com/tmux-plugins/tpm ~/.tmux/plugins/tpm # don't forget to execute inside tmux: prefix + I to install plugins\n  git clone https://github.com/Integralist/dotfiles.git\n  curl https://raw.githubusercontent.com/git/git/master/contrib/completion/git-prompt.sh -o ~/.git-prompt.sh\n  curl https://raw.githubusercontent.com/git/git/master/contrib/completion/git-completion.zsh -o ~/.zsh/_git\n  cp -R .alacritty.yml .zsh .zshrc .config .gitconfig .gitignore .gnupg .ignore .inputrc .leptonrc .tmux.conf ~/\n  chown -R $(whoami) ~/.gnupg/\n  chmod 600 ~/.gnupg/*\n  chmod 700 ~/.gnupg\n  ```\n11. Setup password store.\n  ```txt\n  KEY_ID=$(gpg --list-keys \u003cNAME\u003e | head -n 2 | tail -n 1 | cut -d ' ' -f 7)\n  pass init $KEY_ID\n  pass git init\n  pass git remote add origin git@github.com:\u003cprivate/repo\u003e\n  pass git pull\n  ```\n12. Safari extensions.\n  ```\n  AdBlock One\n  Dark Reader for Safari\n  Super Agent for Safari (Cookie Consent Automation)\n  Tab Sessions\n  ```\n13. Configure OS.\n  ```\n  - Dock (Automatically hide and show the Dock)\n  - Keyboard (Key Repeat = Fast, Delay Until Repeat = Short)\n  - Accessibility \u003e Zoom (Use keyboard shortcuts to zoom)\n  - Date \u0026 Time \u003e Clock (Show date + Display the time with seconds)\n  - Mission Control (disable \"Automatically rearrange Spaces based on most recent use\")\n  - Terminal Developer Mode (`spctl developer-mode enable-terminal`)\n  - Wake up from sleep (`sudo pmset -a standbydelay 7200`)\n  ```\ntap \"homebrew/bundle\"\ntap \"homebrew/cask\"\ntap \"homebrew/cask-fonts\"\ntap \"homebrew/cask-versions\"\ntap \"homebrew/core\"\ntap \"hashicorp/tap\"\ntap \"ms-jpq/sad\"\ntap \"tinygo-org/tools\"\ntap \"veeso/tuifeed\"\ntap \"warrensbox/tap\"\nbrew \"bandwhich\"\nbrew \"zsh\"\nbrew \"zsh-completion\"\nbrew \"bat\"\nbrew \"broot\"\nbrew \"curl\"\nbrew \"coreutils\"\nbrew \"dog\"\nbrew \"duf\"\nbrew \"dust\"\nbrew \"exa\"\nbrew \"fd\"\nbrew \"fnm\"\nbrew \"fswatch\"\nbrew \"fzf\"\nbrew \"git\"\nbrew \"git-delta\"\nbrew \"gnu-sed\"\nbrew \"gnupg\"\nbrew \"gping\"\nbrew \"htop\"\nbrew \"hugo\"\nbrew \"jo\"\nbrew \"jq\"\nbrew \"neovim\"\nbrew \"tree\"\nbrew \"pass\"\nbrew \"pass-otp\"\nbrew \"pinentry-mac\"\nbrew \"procs\"\nbrew \"pwgen\"\nbrew \"reattach-to-user-namespace\"\nbrew \"rm-improved\"\nbrew \"rust-analyzer\"\nbrew \"sd\"\nbrew \"starship\"\nbrew \"the_silver_searcher\"\nbrew \"tmux\"\nbrew \"tokei\"\nbrew \"watch\"\nbrew \"zbar\"\nbrew \"zoxide\"\nbrew \"hashicorp/tap/terraform\"\nbrew \"tinygo-org/tools/tinygo\"\nbrew \"veeso/tuifeed/tuifeed\"\nbrew \"warrensbox/tap/tfswitch\"\ncask \"caffeine\"\ncask \"dash\"\ncask \"font-go-mono-nerd-font\"\ncask \"font-hack-nerd-font\"\ncask \"lepton\"\ncask \"makemkv\"\ncask \"slack\"\ncask \"spotify\"\ncask \"vlc\"\n","tags":"#laptop"},{"id":"f408726ed8cbe0d29aab3f6704f91ad6","title":"Go: Compile go program for Windows ","content":"env GOOS=windows GOARCH=amd64 go build -o fastly.exe cmd/fastly/main.go\n","tags":"#go #compiler #windows"},{"id":"93e6874fe1a2ed0a5a27e244293dd7c5","title":"Go: Version \u003c1.16 Embed Data ","content":"Go version `1.16` introduced an `embed` package which made embedding static data very easy.\n\nIn prior versions you would need to run `go generate` with a script that searched for files based on a given pattern, read the file into memory and to generate a new `.go` file with the file data assigned to package level constants.\n\nThe below demonstrates this process.\n\n```\n.\n├── README.md\n├── golang.svg\n├── images.go\n├── main.go\n└── scripts\n    └── embed.go\n```\n\n## Embed\n\n```go\npackage main\n\nimport (\n\t\"io\"\n\t\"io/ioutil\"\n\t\"os\"\n\t\"strings\"\n)\n\n// Reads all .svg files in the current folder\n// and encodes them as strings literals in images.go\n//\n// NOTE: The images.go file will be within the `main` package namespace.\nfunc main() {\n\tfs, _ := ioutil.ReadDir(\".\")\n\tout, _ := os.Create(\"images.go\")\n\tout.Write([]byte(\"package main \\n\\nconst (\\n\"))\n\tfor _, f := range fs {\n\t\tif strings.HasSuffix(f.Name(), \".svg\") {\n\t\t\tout.Write([]byte(strings.TrimSuffix(f.Name(), \".svg\") + \" = `\"))\n\t\t\tf, _ := os.Open(f.Name())\n\t\t\tio.Copy(out, f)\n\t\t\tout.Write([]byte(\"`\\n\"))\n\t\t}\n\t}\n\tout.Write([]byte(\")\\n\"))\n}\n```\n\n## Main\n\n\u003e **NOTE**: Run with `go run .` so that all `main` package files are picked up.\n\n```go\npackage main\n\nimport \"fmt\"\n\n//go:generate go run scripts/embed.go\n\nfunc main() {\n\tfmt.Print(golang)\n}\n```\n\n## SVG\n\n```\n\u003c?xml version=\"1.0\" encoding=\"utf-8\"?\u003e\n\u003c!-- Generator: Adobe Illustrator 22.1.0, SVG Export Plug-In . SVG Version: 6.00 Build 0)  --\u003e\n\u003csvg version=\"1.1\" id=\"Layer_1\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" x=\"0px\" y=\"0px\"\n\t viewBox=\"0 0 254.5 225\" style=\"enable-background:new 0 0 254.5 225;\" xml:space=\"preserve\"\u003e\n\u003cstyle type=\"text/css\"\u003e\n\t.st0{fill:#2DBCAF;}\n\t.st1{fill:#5DC9E1;}\n\t.st2{fill:#FDDD00;}\n\t.st3{fill:#CE3262;}\n\t.st4{fill:#00ACD7;}\n\t.st5{fill:#FFFFFF;}\n\u003c/style\u003e\n\u003cg\u003e\n\t\u003cg\u003e\n\t\t\u003cg\u003e\n\t\t\t\u003cg\u003e\n\t\t\t\t\u003cpath class=\"st4\" d=\"M40.2,101.1c-0.4,0-0.5-0.2-0.3-0.5l2.1-2.7c0.2-0.3,0.7-0.5,1.1-0.5l35.7,0c0.4,0,0.5,0.3,0.3,0.6\n\t\t\t\t\tl-1.7,2.6c-0.2,0.3-0.7,0.6-1,0.6L40.2,101.1z\"/\u003e\n\t\t\t\u003c/g\u003e\n\t\t\u003c/g\u003e\n\t\u003c/g\u003e\n\t\u003cg\u003e\n\t\t\u003cg\u003e\n\t\t\t\u003cg\u003e\n\t\t\t\t\u003cpath class=\"st4\" d=\"M25.1,110.3c-0.4,0-0.5-0.2-0.3-0.5l2.1-2.7c0.2-0.3,0.7-0.5,1.1-0.5l45.6,0c0.4,0,0.6,0.3,0.5,0.6\n\t\t\t\t\tl-0.8,2.4c-0.1,0.4-0.5,0.6-0.9,0.6L25.1,110.3z\"/\u003e\n\t\t\t\u003c/g\u003e\n\t\t\u003c/g\u003e\n\t\u003c/g\u003e\n\t\u003cg\u003e\n\t\t\u003cg\u003e\n\t\t\t\u003cg\u003e\n\t\t\t\t\u003cpath class=\"st4\" d=\"M49.3,119.5c-0.4,0-0.5-0.3-0.3-0.6l1.4-2.5c0.2-0.3,0.6-0.6,1-0.6l20,0c0.4,0,0.6,0.3,0.6,0.7l-0.2,2.4\n\t\t\t\t\tc0,0.4-0.4,0.7-0.7,0.7L49.3,119.5z\"/\u003e\n\t\t\t\u003c/g\u003e\n\t\t\u003c/g\u003e\n\t\u003c/g\u003e\n\t\u003cg\u003e\n\t\t\u003cg id=\"CXHf1q_3_\"\u003e\n\t\t\t\u003cg\u003e\n\t\t\t\t\u003cg\u003e\n\t\t\t\t\t\u003cpath class=\"st4\" d=\"M153.1,99.3c-6.3,1.6-10.6,2.8-16.8,4.4c-1.5,0.4-1.6,0.5-2.9-1c-1.5-1.7-2.6-2.8-4.7-3.8\n\t\t\t\t\t\tc-6.3-3.1-12.4-2.2-18.1,1.5c-6.8,4.4-10.3,10.9-10.2,19c0.1,8,5.6,14.6,13.5,15.7c6.8,0.9,12.5-1.5,17-6.6\n\t\t\t\t\t\tc0.9-1.1,1.7-2.3,2.7-3.7c-3.6,0-8.1,0-19.3,0c-2.1,0-2.6-1.3-1.9-3c1.3-3.1,3.7-8.3,5.1-10.9c0.3-0.6,1-1.6,2.5-1.6\n\t\t\t\t\t\tc5.1,0,23.9,0,36.4,0c-0.2,2.7-0.2,5.4-0.6,8.1c-1.1,7.2-3.8,13.8-8.2,19.6c-7.2,9.5-16.6,15.4-28.5,17\n\t\t\t\t\t\tc-9.8,1.3-18.9-0.6-26.9-6.6c-7.4-5.6-11.6-13-12.7-22.2c-1.3-10.9,1.9-20.7,8.5-29.3c7.1-9.3,16.5-15.2,28-17.3\n\t\t\t\t\t\tc9.4-1.7,18.4-0.6,26.5,4.9c5.3,3.5,9.1,8.3,11.6,14.1C154.7,98.5,154.3,99,153.1,99.3z\"/\u003e\n\t\t\t\t\u003c/g\u003e\n\t\t\t\t\u003cg\u003e\n\t\t\t\t\t\u003cpath class=\"st4\" d=\"M186.2,154.6c-9.1-0.2-17.4-2.8-24.4-8.8c-5.9-5.1-9.6-11.6-10.8-19.3c-1.8-11.3,1.3-21.3,8.1-30.2\n\t\t\t\t\t\tc7.3-9.6,16.1-14.6,28-16.7c10.2-1.8,19.8-0.8,28.5,5.1c7.9,5.4,12.8,12.7,14.1,22.3c1.7,13.5-2.2,24.5-11.5,33.9\n\t\t\t\t\t\tc-6.6,6.7-14.7,10.9-24,12.8C191.5,154.2,188.8,154.3,186.2,154.6z M210,114.2c-0.1-1.3-0.1-2.3-0.3-3.3\n\t\t\t\t\t\tc-1.8-9.9-10.9-15.5-20.4-13.3c-9.3,2.1-15.3,8-17.5,17.4c-1.8,7.8,2,15.7,9.2,18.9c5.5,2.4,11,2.1,16.3-0.6\n\t\t\t\t\t\tC205.2,129.2,209.5,122.8,210,114.2z\"/\u003e\n\t\t\t\t\u003c/g\u003e\n\t\t\t\u003c/g\u003e\n\t\t\u003c/g\u003e\n\t\u003c/g\u003e\n\u003c/g\u003e\n\u003c/svg\u003e\n```\n","tags":"#go"},{"id":"889ab6d1d9052f05de06a6b1ecd1c5a1","title":"Go: godoc example code generation ","content":"Add a file named in a specific format (e.g. `example_\u003cwhatever\u003e_test.go`) and the file has to include a function that has the format `Example\u003cType\u003e_\u003cMethod\u003e` so the `godoc` command knows to attach the file contents to the given type and specifically the specified method.\n","tags":"#go"},{"id":"eb2b71ea654c1e79ff73b404aff18325","title":"Go: macOS bug ","content":"# https://github.com/golang/go/issues/41572#issuecomment-924436853\n#\n# Looks to only happen when the application is compiled with the -race flag and is doing a net.LookupAddr.\n#\n# Prefixing the MallocNanoZone=0 env var worked for me.\n\nMallocNanoZone=0 TEST_COMPUTE_INIT=1 TEST_COMPUTE_BUILD=1 TEST_COMPUTE_DEPLOY=1 TESTARGS='-timeout 2m -v -run TestList ./pkg/commands/authtoken/...' make test\n","tags":"#macOS #go #bug"},{"id":"d203513edc2ef3d5dd28ea6a74bdf0f2","title":"Go: Kingpin CLI IsGlobalFlagsOnly ","content":"// IsGlobalFlagsOnly indicates if the user called the binary with any\n// permutation order of the globally defined flags.\n//\n// NOTE: Some global flags accept a value while others do not. The following\n// algorithm takes this into account by mapping the flag to an expected value.\n// For example, --verbose doesn't accept a value so is set to zero.\n//\n// EXAMPLES:\n//\n// The following would return false as a command was specified:\n//\n// args: [--verbose -v --endpoint ... --token ... -t ... --endpoint ...  version] 11\n// total: 10\n//\n// The following would return true as only global flags were specified:\n//\n// args: [--verbose -v --endpoint ... --token ... -t ... --endpoint ...] 10\n// total: 10\nfunc IsGlobalFlagsOnly(args []string) bool {\n\t// Global flags are defined in pkg/app/run.go#84\n\tglobals := map[string]int{\n\t\t\"--verbose\":  0,\n\t\t\"-v\":         0,\n\t\t\"--token\":    1,\n\t\t\"-t\":         1,\n\t\t\"--endpoint\": 1,\n\t}\n\tvar total int\n\tfor _, a := range args {\n\t\tfor k := range globals {\n\t\t\tif a == k {\n\t\t\t\ttotal += 1\n\t\t\t\ttotal += globals[k]\n\t\t\t}\n\t\t}\n\t}\n\treturn len(args) == total\n}\n","tags":"#go"},{"id":"8660015f338619c7ab9f78e53272ea67","title":"Rust: ANSI Escape Code Clear Line ","content":"use std::{thread::sleep, time::Duration};\n\nconst CLEAR: \u0026str = \"\\x1B[2J\\x1B[1;1H\"; // clears the line before printing the next character\n\nfn expensive_calculation(_n: \u0026i32) {\n    sleep(Duration::from_secs(1));\n}\n\nfn main() {\n    let v: Vec\u003ci32\u003e = vec![1, 2, 3];\n    let mut i: usize = 1;\n    for n in v.iter() {\n        println!(\"{}{}\", CLEAR, \"*\".repeat(i));\n        i += 1;\n        expensive_calculation(n);\n    }\n}\n// Something I noticed in a CLI tool...\n\nfunc (p *InteractiveProgress) replaceLine(format string, args ...interface{}) {\n\t// Clear the current line.\n\tn := utf8.RuneCountInString(p.currentOutput)\n\tswitch runtime.GOOS {\n\tcase \"windows\":\n\t\tfmt.Fprintf(p.output, \"%s\\r\", strings.Repeat(\" \", n))\n\tdefault:\n\t\tdel, _ := hex.DecodeString(\"7f\")\n\t\tsequence := fmt.Sprintf(\"\\b%s\\b\\033[K\", del)\n\t\tfmt.Fprintf(p.output, \"%s\\r\", strings.Repeat(sequence, n))\n\t}\n\n\t// Generate the new line.\n\ts := fmt.Sprintf(format, args...)\n\tp.currentOutput = s\n\tfmt.Fprint(p.output, p.currentOutput)\n}\n","tags":"#rust #ansi"},{"id":"3443beeb64e19a62b879739e854ef885","title":"Terraform: The problem with Terraform's schema.TypeSet ","content":"Set elements are viewed as opaque values that are added/removed. \n\nIf any elements \"change\", then the set's \"identity\" has changed. \n\nThe contents of the set is hashed, and so the changing of the content results in the set _as a whole_ needing to be recreated.\n\nThis is why if you update a field inside a `schema.TypeSet` in Terraform, and you run a `terraform plan` you'll see the entire resource marked as needing to be deleted and recreated.\n\nOfficial GitHub discussion: https://github.com/hashicorp/terraform/pull/2336#issuecomment-115744243\n","tags":"#terraform"},{"id":"8dd5fee7c884aa2a1bf709de37108e19","title":"Go: loop over struct fields ","content":"package main\n\nimport (\n\t\"fmt\"\n\t\"reflect\"\n)\n\ntype Student struct {\n\tFname  string\n\tLname  string\n\tCity   string\n\tMobile int64\n}\n\nfunc main() {\n\ts := Student{\"Chetan\", \"Tulsyan\", \"Bangalore\", 7777777777}\n\tv := reflect.ValueOf(s)\n\ttypeOfS := v.Type()\n\n\tfor i := 0; i \u003c v.NumField(); i++ {\n\t\tfmt.Printf(\"Field: %s\\tValue: %v\\n\", typeOfS.Field(i).Name, v.Field(i).Interface())\n\t}\n}\n","tags":"#go #reflection"},{"id":"4a2137c733156fbfd7656d72afb5b8d8","title":"macOS: view shutdown logs ","content":"log show --predicate 'eventMessage contains \"Previous shutdown cause\"' --last 24h\n","tags":"#macOS #logs"},{"id":"3735994921455c0b5f89d5e6899b7052","title":"Rust: Packages, Crates, Modules ","content":"## Summary\n\n- **Packages**: A package is one or more crates that provide a set of functionality.\n- **Crates**: A tree of modules that produces a library or executable.\n- **Modules**: Modules let us organize code within a crate into groups for readability and easy reuse.\n\n\u003e [Ref](https://doc.rust-lang.org/book/ch07-00-managing-growing-projects-with-packages-crates-and-modules.html)\n\n## Package\n\nA package contains a `Cargo.toml` file that describes how to build the crates defined within the package.\n\nA package must contain at least one crate, it can be either a 'library' crate or a 'binary' crate. \n\nA package can contain multiple binary crates, but can only one library crate.\n\nA package can have multiple binary crates by placing files in the `src/bin` directory: each file will be a separate binary crate.\n\n## Crate\n\nTo show Rust where to find an item in a module tree, we use a path in the same way we use a path when navigating a filesystem. If we want to call a function, we need to know its path.\n\nThis can be achieved using either an 'absolute' path or a 'relative' path.\n\n**Filename**: `src/lib.rs`\n\n```rust\nmod front_of_house {\n    mod hosting {\n        fn add_to_waitlist() {}\n    }\n}\n\npub fn eat_at_restaurant() {\n    // Absolute path\n    crate::front_of_house::hosting::add_to_waitlist();\n\n    // Relative path\n    front_of_house::hosting::add_to_waitlist();\n}\n```\n\n## Module\n\nYou can define a module within the root library or binary crate or you can define them in separate files within the `src` directory.\n\n**Filename**: `src/foo.rs`\n\n```rust\n// foo module\n\npub mod bar {\n    pub trait Thing {\n        fn do_thing(\u0026self);\n    }\n\n    pub fn baz() {\n        println!(\"baz called!\")\n    }\n\n    #[derive(Debug)]\n    pub struct SomeStruct {\n        pub some_field: u8,\n    }\n\n    impl SomeStruct {\n        pub fn new(some_field: u8) -\u003e SomeStruct {\n            SomeStruct { some_field }\n        }\n    }\n\n    impl Thing for SomeStruct {\n        fn do_thing(\u0026self) {\n            println!(\"do a thing\");\n        }\n    }\n}\n```\n\n**Filename**: `src/main.rs`\n\n```rust\nmod foo;\n\nuse crate::foo::bar;\nuse crate::foo::bar::Thing; // you must import the trait implemented for SomeStruct\n\nfn main() {\n    bar::baz();\n\n    let ss = bar::SomeStruct::new(123);\n    println!(\"{:?}\", ss);\n    println!(\"{}\", ss.some_field);\n    ss.do_thing();\n}\n```\n\n\u003e **NOTE**: Using a semicolon after `mod foo` rather than using a block `{...}` tells Rust to load the contents of the module from another file with the same name as the module.\n","tags":"#rust #rustlang #learn"},{"id":"719c37b2cd00e10554f643787de72d84","title":"Go: updating a pointer field value ","content":"I have a struct with a field that’s a pointer, and I want to update the value.\n\nThe following code does that (notice the memory address for the field changes, which is what I would expect once I change the value)...\n\n```go\npackage main\n\nimport \"fmt\"\n\ntype S struct {\n\tF *int\n}\n\nfunc main() {\n\ts := new(S)\n\tfmt.Printf(\"%+v\\n\", s) // \u0026{F:\u003cnil\u003e}\n\n\ti := 1\n\ts.F = \u0026i\n\tfmt.Printf(\"%+v\\n\", s)    // \u0026{F:0xc000018050}\n\tfmt.Printf(\"%+v\\n\", *s.F) // 1\n\n\ti2 := 2\n\ts.F = \u0026i2\n\tfmt.Printf(\"%+v\\n\", s)    // \u0026{F:0xc000018060}\n\tfmt.Printf(\"%+v\\n\", *s.F) // 2\n}\n```\n\nNow, in the following example I’ve modified the code from `s.F = \u0026i2` to `*s.F = i2` and I can see that the change is applied because when I print a dereference of the struct field I see the updated value `2` but the memory address appears to be the same as when the value was set to `1`. This is because I didn’t assign a _new_ memory address (like I did with `\u0026i2`) but went directly to the memory location (e.g. `*s.F`) and updated the value.\n\n```go\npackage main\n\nimport \"fmt\"\n\ntype S struct {\n\tF *int\n}\n\nfunc main() {\n\ts := new(S)\n\tfmt.Printf(\"%+v\\n\", s) // \u0026{F:\u003cnil\u003e}\n\n\ti := 1\n\ts.F = \u0026i\n\tfmt.Printf(\"%+v\\n\", s)    // \u0026{F:0xc000018050}\n\tfmt.Printf(\"%+v\\n\", *s.F) // 1\n\n\ti2 := 2\n\t*s.F = i2\n\tfmt.Printf(\"%+v\\n\", s)    // \u0026{F:0xc000018050}\n    fmt.Printf(\"%+v\\n\", *s.F) // 2\n}\n```\n\nSo the latter could be considered better because it doesn’t cause another allocation of memory.\n","tags":"#go"},{"id":"80fa38b86e9f93e6721d0c9452bc3b9f","title":"Shell: Track list of open files ","content":"#!/usr/bin/env zsh\n\nthreshold=6000\n\nwhile true; do\n  files=$(lsof | wc -l | xargs) # xargs for trimming white space\n  replace=\"\\033[0K\\r\"\n  threshold=$threshold\n  msg=\"lsof:$files (threshold: $threshold)\"\n\n  echo -ne \"$msg$replace\"\n\n  if [[ ! -z \"${TMUX}\" ]]; then\n    tmux rename-window -t 1 \"$msg\"\n  fi\n\n  if [ $files -ge $threshold ]; then\n    say \"threshold $threshold exceeded\"\n    threshold=$( expr $threshold + 1000 )\n  fi\n\n  sleep 1\ndone\n","tags":"#bash #tmux #lsof #unix #shell #monitor #zsh"},{"id":"30ce5612ba4883f2de9ba69cfa51cc3d","title":"Bash: moreutils examples ","content":"# brew install moreutils\n# https://joeyh.name/code/moreutils/\n\n# vipe allows you to use vim to inspect data in the middle of a pipeline\n$ echo '{\"foo\": {\"bar\": 123}}' | vipe --suffix json | jq\n{\n  \"foo\": {\n    \"bar\": 123\n  }\n}\n\n# pee is like tee but for pipes\n#\n# Each command is run and fed a copy of the standard input.\n# The output of all commands is sent to stdout.\n#\n# NOTE: a copy of the input is not sent to stdout, like tee does\n# If that is desired, use pee cat.\n#\n# In the following example we want the _original_ stdout from cat \n# to be passed over to the wc command, hence we use `pee cat`.\n$ seq 5 1 \u003e file\n$ cat file | pee cat 'sort -u \u003e sorted' 'sort -R \u003e unsorted' | wc -l\n       5\n       \n# If we didn't use `pee cat` then the example pee pipelines we run\n# wouldn't cause any stdout for the `wc` command to receive as stdin.\n# \n# We could mimic `pee cat` (although not quite) by having a pipeline\n# that uses `xargs` to echo the input, but instead of getting 5 lines \n# of output (from cat'ing the file) we get `5 4 3 2 1` on one line. \n# Hence in the following example I use `wc -w` and not `wc -l`.\n$ cat file | pee 'sort -u \u003e sorted' 'sort -R \u003e unsorted' 'xargs' | wc -w\n       5\n","tags":"#bash #moreutils #shell"},{"id":"3097838786e069c33afe668ae767a367","title":"Go: type asserting/coercing ","content":"/*\nbar and baz are structs with pointer reference to a foo struct.\nthere's a fooer interface for the foo struct\nwe also have a function that accepts a fooer\nthe purpose of the function is to coerce the arg from an interface type to a concrete type\n*/\npackage main\n\nimport (\n\t\"fmt\"\n)\n\ntype foo struct {\n\tmsg     string\n\tenabled bool\n}\n\nfunc (f *foo) do(thing string) (string, error) {\n\treturn fmt.Sprintf(\"done %s -- %s\", thing, f.msg), nil\n}\n\ntype fooer interface {\n\tdo(thing string) (string, error)\n}\n\ntype bar struct {\n\tthing *foo\n}\n\ntype baz struct {\n\tthing *foo\n}\n\nfunc assignMsg(f fooer) {\n\tif foothing, ok := f.(*foo); ok {\n\t\tfoothing.msg = \"assigned dynamically\"\n\t}\n\tfmt.Println(f.do(\"something here\"))\n}\n\nfunc main() {\n\tbr := bar{thing: \u0026foo{enabled: true}}\n\tbz := baz{thing: \u0026foo{enabled: true}}\n\tfmt.Printf(\"br: %+v\\n\", br)\n\tfmt.Printf(\"bz: %+v\\n\", bz)\n\n\tret, _ := br.thing.do(\"with bar\")\n\tfmt.Println(ret)\n\n\tret, _ = bz.thing.do(\"with baz\")\n\tfmt.Println(ret)\n\n\tassignMsg(br.thing)\n}\n\n","tags":"#go "},{"id":"845c4cbb4badfd43fe11dc1b1bba2eb4","title":"Go: unzip(.zip) and untar(.tar.gz) contents of archive to specified destination ","content":"// untar will decompress a tar.gz archive, moving all files and folders\n// within the archive (parameter 1) to an output directory (parameter 2).\nfunc untar(src io.Reader, dst string) error {\n\tgr, err := gzip.NewReader(src)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"error creating gzip reader: %w\", err)\n\t}\n\tdefer gr.Close()\n\n\ttr := tar.NewReader(gr)\n\n\tfor {\n\t\theader, err := tr.Next()\n\n\t\tswitch {\n\n\t\t// If no more files are found return\n\t\tcase err == io.EOF:\n\t\t\treturn nil\n\n\t\t// Return any other error\n\t\tcase err != nil:\n\t\t\treturn err\n\n\t\t// If the header is nil, skip it\n\t\tcase header == nil:\n\t\t\tcontinue\n\n\t\t// Skip the any files duplicated as hidden files\n\t\tcase strings.HasPrefix(header.Name, \"._\"):\n\t\t\tcontinue\n\t\t}\n\n\t\t// The target location where the dir/file should be created\n\t\tsegs := strings.Split(header.Name, string(filepath.Separator))\n\t\tsegs = segs[1:]\n\t\ttarget := filepath.Join(dst, filepath.Join(segs...))\n\n\t\tfi := header.FileInfo()\n\n\t\tif fi.IsDir() {\n\t\t\tos.MkdirAll(target, os.ModePerm)\n\t\t\tcontinue\n\t\t}\n\n\t\tif err = os.MkdirAll(filepath.Dir(target), os.ModePerm); err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tfd, err := os.OpenFile(target, os.O_WRONLY|os.O_CREATE|os.O_TRUNC, fi.Mode())\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\t// NOTE: We use looped CopyN() not Copy() to avoid gosec G110 (CWE-409):\n\t\t// Potential DoS vulnerability via decompression bomb.\n\t\tfor {\n\t\t\t_, err := io.CopyN(fd, tr, 1024)\n\t\t\tif err != nil {\n\t\t\t\tif err == io.EOF {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\n\t\tfd.Close()\n\t}\n}\n// unzip will decompress a zip archive, moving all files and folders\n// within the zip file (parameter 1) to an output directory (parameter 2).\nfunc unzip(src string, dst string) ([]string, error) {\n\tvar filenames []string\n\n\tr, err := zip.OpenReader(src)\n\tif err != nil {\n\t\treturn filenames, err\n\t}\n\tdefer r.Close()\n\n\tfor _, f := range r.File {\n\t\t// The zip contains a folder, and inside that folder are the files we're\n\t\t// interested in. So while looping over the files (whose .Name field is the\n\t\t// full path including the containing folder) we strip out the first path\n\t\t// segment to ensure the files we need are extracted to the current directory.\n\t\tsegs := strings.Split(f.Name, string(filepath.Separator))\n\t\tsegs = segs[1:]\n\t\tfpath := filepath.Join(dst, filepath.Join(segs...))\n\t\tfilenames = append(filenames, fpath)\n\n\t\tif f.FileInfo().IsDir() {\n\t\t\tos.MkdirAll(fpath, os.ModePerm)\n\t\t\tcontinue\n\t\t}\n\n\t\tif err = os.MkdirAll(filepath.Dir(fpath), os.ModePerm); err != nil {\n\t\t\treturn filenames, err\n\t\t}\n\n\t\tfd, err := os.OpenFile(fpath, os.O_WRONLY|os.O_CREATE|os.O_TRUNC, f.Mode())\n\t\tif err != nil {\n\t\t\treturn filenames, err\n\t\t}\n\n\t\trc, err := f.Open()\n\t\tif err != nil {\n\t\t\treturn filenames, err\n\t\t}\n\n\t\t// NOTE: We use looped CopyN() not Copy() to avoid gosec G110 (CWE-409):\n\t\t// Potential DoS vulnerability via decompression bomb.\n\t\tfor {\n\t\t\t_, err := io.CopyN(fd, rc, 1024)\n\t\t\tif err != nil {\n\t\t\t\tif err == io.EOF {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t\treturn filenames, err\n\t\t\t}\n\t\t}\n\n\t\tfd.Close()\n\t\trc.Close()\n\n\t\tif err != nil {\n\t\t\treturn filenames, err\n\t\t}\n\t}\n\n\treturn filenames, nil\n}\n","tags":"#go"},{"id":"6f8aab46f67b5dcff33e1974c8127c52","title":"Go: Custom Error Log Abstraction ","content":"// NOTE: This is code I implemented in the open-source github.com/fastly/cli repo.\n\npackage errors\n\nimport (\n\t\"fmt\"\n\t\"os\"\n\t\"path/filepath\"\n\t\"runtime\"\n\t\"strings\"\n\t\"sync\"\n\t\"text/template\"\n\t\"time\"\n\n\t\"github.com/fastly/go-fastly/v5/fastly\"\n)\n\n// LogPath is the location of the fastly CLI error log.\nvar LogPath = func() string {\n\tif dir, err := os.UserConfigDir(); err == nil {\n\t\treturn filepath.Join(dir, \"fastly\", \"errors.log\")\n\t}\n\tif dir, err := os.UserHomeDir(); err == nil {\n\t\treturn filepath.Join(dir, \".fastly\", \"errors.log\")\n\t}\n\tpanic(\"unable to deduce user config dir or user home dir\")\n}()\n\n// LogInterface represents the LogEntries behaviours.\ntype LogInterface interface {\n\tAdd(err error)\n\tAddWithContext(err error, ctx map[string]interface{})\n\tPersist(logPath string, args []string) error\n}\n\n// Log is the primary interface for consumers.\nvar Log = new(LogEntries)\n\n// LogEntries represents a list of recorded log entries.\ntype LogEntries []LogEntry\n\n// Add adds a new log entry.\nfunc (l *LogEntries) Add(err error) {\n\tlogMutex.Lock()\n\t*l = append(*l, createLogEntry(err))\n\tlogMutex.Unlock()\n}\n\n// AddWithContext adds a new log entry with extra contextual data.\nfunc (l *LogEntries) AddWithContext(err error, ctx map[string]interface{}) {\n\tle := createLogEntry(err)\n\tle.Context = ctx\n\n\tlogMutex.Lock()\n\t*l = append(*l, le)\n\tlogMutex.Unlock()\n}\n\n// Persist persists recorded log entries to disk.\nfunc (l LogEntries) Persist(logPath string, args []string) error {\n\tif len(l) == 0 {\n\t\treturn nil\n\t}\n\n\terrMsg := \"error accessing audit log file: %w\"\n\n\tf, err := os.OpenFile(logPath, os.O_APPEND|os.O_CREATE|os.O_WRONLY, 0600)\n\tif err != nil {\n\t\treturn fmt.Errorf(errMsg, err)\n\t}\n\n\tif fi, err := f.Stat(); err == nil {\n\t\tif fi.Size() \u003e= FileRotationSize {\n\t\t\tf.Close()\n\n\t\t\tf, err = os.Create(logPath)\n\t\t\tif err != nil {\n\t\t\t\treturn fmt.Errorf(errMsg, err)\n\t\t\t}\n\t\t}\n\t}\n\n\t// G307 (CWE-): Deferring unsafe method \"*os.File\" on type \"Close\".\n\t// gosec flagged this:\n\t// Disabling because this file isn't critical to the functioning of the CLI\n\t// and we only attempt to close it at the end of the user's execution flow.\n\t/* #nosec */\n\tdefer f.Close()\n\n\tcmd := \"\\nCOMMAND:\\nfastly \" + strings.Join(args, \" \") + \"\\n\\n\"\n\tif _, err := f.Write([]byte(cmd)); err != nil {\n\t\treturn err\n\t}\n\n\trecord := `TIMESTAMP:\n{{.Time}}\n\nERROR:\n{{.Err}}\n{{ range $key, $value := .Caller }}\n{{ $key }}:\n{{ $value }}\n{{ end }}\n{{ range $key, $value := .Context }}\n  {{ $key }}: {{ $value }}\n{{ end }}\n`\n\tt := template.Must(template.New(\"record\").Parse(record))\n\tfor _, entry := range l {\n\t\terr := t.Execute(f, entry)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\tf.Write([]byte(\"------------------------------\\n\\n\"))\n\n\treturn nil\n}\n\n// createLogEntry generates the boilerplate of a LogEntry.\nfunc createLogEntry(err error) LogEntry {\n\tle := LogEntry{\n\t\tTime: Now(),\n\t\tErr:  err,\n\t}\n\n\t_, file, line, ok := runtime.Caller(2)\n\tif ok {\n\t\tle.Caller = map[string]interface{}{\n\t\t\t\"FILE\": file[strings.Index(file, \"/pkg/\"):],\n\t\t\t\"LINE\": line,\n\t\t}\n\t}\n\n\treturn le\n}\n\n// LogEntry represents a single error log entry.\ntype LogEntry struct {\n\tTime    time.Time\n\tErr     error\n\tCaller  map[string]interface{}\n\tContext map[string]interface{}\n}\n\n// Caller represents where an error occurred.\ntype Caller struct {\n\tFile string\n\tLine int\n}\n\n// Appending to a slice isn't threadsafe, and although we currently don't\n// expect this to be a problem we can't predict future logic requirements that\n// might result in more asynchronous operations, so we play it safe and utilise\n// a lock before updating the LogEntries.\nvar logMutex sync.Mutex\n\n// Now is exposed so that we may mock it from our test file.\n//\n// NOTE: The ideal way to deal with time is to inject it as a dependency and\n// then the caller can provide a stubbed value, but in this case we don't want\n// to have the CLI's business logic littered with lots of calls to time.Now()\n// when that call can be handled internally by the .Add() method.\nvar Now = time.Now\n\n// FileRotationSize represents the size the log file needs to be before we\n// truncate it.\n//\n// NOTE: To enable easier testing of the log rotation logic, we don't define\n// this as a constant but as a variable so the test file can mutate the value\n// to something much smaller, meaning we can commit a small test file as part\n// of the testing logic that will trigger a 'over the threshold' scenario.\nvar FileRotationSize int64 = 5242880 // 5mb\n","tags":"#go #errors #logs"},{"id":"148f6285e74786dcbdc208b83f047aee","title":"Zig: Install LSP ","content":"# reinstall the latest zig\nbrew uninstall --force zig\nbrew install zig --HEAD\nzig version # at the time of writing: 0.9.0-dev.954+c4f97d336\n\n# then build zls from source:\ngit clone --recurse-submodules https://github.com/zigtools/zls\ncd zls\nzig build -Drelease-safe\n./zig-out/bin/zls config \n\n# finally add zls executive path to your .rc file\nPATH=\"$HOME/zig/zig-out/bin:$PATH\"\n","tags":"#lsp #zig #zls"},{"id":"ef5eb39ec34f5b8734bd81958be3a5e1","title":"Go: embed static file inside of compiled binary ","content":"// Refer to https://tip.golang.org/pkg/embed/ for lots of examples\n//\n// Here are some embed patterns to try (these can be layered on top of each other with a single variable!):\n//\n// downloads/*                       -\u003e embed.FS\n// image/ css/ js/                   -\u003e embed.FS\n// favicon.ico robots.txt index.html -\u003e embed.FS\n//\n// When using `var f embed.FS` you can then utilise that type's methods:\n// \n// func (FS) Open\n// func (FS) ReadDir\n// func (FS) ReadFile\n//\n// FS implements fs.FS, so it can be used with any package that understands file system interfaces, including net/http, text/template, and html/template.\n\npackage main\n\nimport (\n\t_ \"embed\"\n\t\"fmt\"\n)\n\n//go:embed config.toml\nvar config string // []byte might be more flexible!\n\nfunc main() {\n\tfmt.Printf(\"%+v\\n\", config)\n  \n\t// You can also combine it with a static file server.\n    /*\n\thttp.Handle(\"/\", http.FileServer(http.FS(static)))\n\tlog.Fatal(http.ListenAndServe(\":8080\", nil))\n    */\n}\nGo version `1.16` introduced an `embed` package which made embedding static data very easy.\n\nIn prior versions you would need to run `go generate` with a script that searched for files based on a given pattern, read the file into memory and to generate a new `.go` file with the file data assigned to package level constants.\n\nThe below demonstrates this process.\n\n```\n.\n├── README.md\n├── golang.svg\n├── images.go\n├── main.go\n└── scripts\n    └── embed.go\n```\n\n## Embed\n\n```go\npackage main\n\nimport (\n\t\"io\"\n\t\"io/ioutil\"\n\t\"os\"\n\t\"strings\"\n)\n\n// Reads all .svg files in the current folder\n// and encodes them as strings literals in images.go\n//\n// NOTE: The images.go file will be within the `main` package namespace.\nfunc main() {\n\tfs, _ := ioutil.ReadDir(\".\")\n\tout, _ := os.Create(\"images.go\")\n\tout.Write([]byte(\"package main \\n\\nconst (\\n\"))\n\tfor _, f := range fs {\n\t\tif strings.HasSuffix(f.Name(), \".svg\") {\n\t\t\tout.Write([]byte(strings.TrimSuffix(f.Name(), \".svg\") + \" = `\"))\n\t\t\tf, _ := os.Open(f.Name())\n\t\t\tio.Copy(out, f)\n\t\t\tout.Write([]byte(\"`\\n\"))\n\t\t}\n\t}\n\tout.Write([]byte(\")\\n\"))\n}\n```\n\n## Main\n\n\u003e **NOTE**: Run with `go run .` so that all `main` package files are picked up.\n\n```go\npackage main\n\nimport \"fmt\"\n\n//go:generate go run scripts/embed.go\n\nfunc main() {\n\tfmt.Print(golang)\n}\n```\n\n## SVG\n\n```\n\u003c?xml version=\"1.0\" encoding=\"utf-8\"?\u003e\n\u003c!-- Generator: Adobe Illustrator 22.1.0, SVG Export Plug-In . SVG Version: 6.00 Build 0)  --\u003e\n\u003csvg version=\"1.1\" id=\"Layer_1\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" x=\"0px\" y=\"0px\"\n\t viewBox=\"0 0 254.5 225\" style=\"enable-background:new 0 0 254.5 225;\" xml:space=\"preserve\"\u003e\n\u003cstyle type=\"text/css\"\u003e\n\t.st0{fill:#2DBCAF;}\n\t.st1{fill:#5DC9E1;}\n\t.st2{fill:#FDDD00;}\n\t.st3{fill:#CE3262;}\n\t.st4{fill:#00ACD7;}\n\t.st5{fill:#FFFFFF;}\n\u003c/style\u003e\n\u003cg\u003e\n\t\u003cg\u003e\n\t\t\u003cg\u003e\n\t\t\t\u003cg\u003e\n\t\t\t\t\u003cpath class=\"st4\" d=\"M40.2,101.1c-0.4,0-0.5-0.2-0.3-0.5l2.1-2.7c0.2-0.3,0.7-0.5,1.1-0.5l35.7,0c0.4,0,0.5,0.3,0.3,0.6\n\t\t\t\t\tl-1.7,2.6c-0.2,0.3-0.7,0.6-1,0.6L40.2,101.1z\"/\u003e\n\t\t\t\u003c/g\u003e\n\t\t\u003c/g\u003e\n\t\u003c/g\u003e\n\t\u003cg\u003e\n\t\t\u003cg\u003e\n\t\t\t\u003cg\u003e\n\t\t\t\t\u003cpath class=\"st4\" d=\"M25.1,110.3c-0.4,0-0.5-0.2-0.3-0.5l2.1-2.7c0.2-0.3,0.7-0.5,1.1-0.5l45.6,0c0.4,0,0.6,0.3,0.5,0.6\n\t\t\t\t\tl-0.8,2.4c-0.1,0.4-0.5,0.6-0.9,0.6L25.1,110.3z\"/\u003e\n\t\t\t\u003c/g\u003e\n\t\t\u003c/g\u003e\n\t\u003c/g\u003e\n\t\u003cg\u003e\n\t\t\u003cg\u003e\n\t\t\t\u003cg\u003e\n\t\t\t\t\u003cpath class=\"st4\" d=\"M49.3,119.5c-0.4,0-0.5-0.3-0.3-0.6l1.4-2.5c0.2-0.3,0.6-0.6,1-0.6l20,0c0.4,0,0.6,0.3,0.6,0.7l-0.2,2.4\n\t\t\t\t\tc0,0.4-0.4,0.7-0.7,0.7L49.3,119.5z\"/\u003e\n\t\t\t\u003c/g\u003e\n\t\t\u003c/g\u003e\n\t\u003c/g\u003e\n\t\u003cg\u003e\n\t\t\u003cg id=\"CXHf1q_3_\"\u003e\n\t\t\t\u003cg\u003e\n\t\t\t\t\u003cg\u003e\n\t\t\t\t\t\u003cpath class=\"st4\" d=\"M153.1,99.3c-6.3,1.6-10.6,2.8-16.8,4.4c-1.5,0.4-1.6,0.5-2.9-1c-1.5-1.7-2.6-2.8-4.7-3.8\n\t\t\t\t\t\tc-6.3-3.1-12.4-2.2-18.1,1.5c-6.8,4.4-10.3,10.9-10.2,19c0.1,8,5.6,14.6,13.5,15.7c6.8,0.9,12.5-1.5,17-6.6\n\t\t\t\t\t\tc0.9-1.1,1.7-2.3,2.7-3.7c-3.6,0-8.1,0-19.3,0c-2.1,0-2.6-1.3-1.9-3c1.3-3.1,3.7-8.3,5.1-10.9c0.3-0.6,1-1.6,2.5-1.6\n\t\t\t\t\t\tc5.1,0,23.9,0,36.4,0c-0.2,2.7-0.2,5.4-0.6,8.1c-1.1,7.2-3.8,13.8-8.2,19.6c-7.2,9.5-16.6,15.4-28.5,17\n\t\t\t\t\t\tc-9.8,1.3-18.9-0.6-26.9-6.6c-7.4-5.6-11.6-13-12.7-22.2c-1.3-10.9,1.9-20.7,8.5-29.3c7.1-9.3,16.5-15.2,28-17.3\n\t\t\t\t\t\tc9.4-1.7,18.4-0.6,26.5,4.9c5.3,3.5,9.1,8.3,11.6,14.1C154.7,98.5,154.3,99,153.1,99.3z\"/\u003e\n\t\t\t\t\u003c/g\u003e\n\t\t\t\t\u003cg\u003e\n\t\t\t\t\t\u003cpath class=\"st4\" d=\"M186.2,154.6c-9.1-0.2-17.4-2.8-24.4-8.8c-5.9-5.1-9.6-11.6-10.8-19.3c-1.8-11.3,1.3-21.3,8.1-30.2\n\t\t\t\t\t\tc7.3-9.6,16.1-14.6,28-16.7c10.2-1.8,19.8-0.8,28.5,5.1c7.9,5.4,12.8,12.7,14.1,22.3c1.7,13.5-2.2,24.5-11.5,33.9\n\t\t\t\t\t\tc-6.6,6.7-14.7,10.9-24,12.8C191.5,154.2,188.8,154.3,186.2,154.6z M210,114.2c-0.1-1.3-0.1-2.3-0.3-3.3\n\t\t\t\t\t\tc-1.8-9.9-10.9-15.5-20.4-13.3c-9.3,2.1-15.3,8-17.5,17.4c-1.8,7.8,2,15.7,9.2,18.9c5.5,2.4,11,2.1,16.3-0.6\n\t\t\t\t\t\tC205.2,129.2,209.5,122.8,210,114.2z\"/\u003e\n\t\t\t\t\u003c/g\u003e\n\t\t\t\u003c/g\u003e\n\t\t\u003c/g\u003e\n\t\u003c/g\u003e\n\u003c/g\u003e\n\u003c/svg\u003e\n```\n","tags":"#go"},{"id":"a510abba8319923bca889c8c22f73f9a","title":"Terraform: Provider Local Dev Environment ","content":"\u003e [Terraform Documentation Reference](https://www.terraform.io/docs/cli/config/config-file.html#development-overrides-for-provider-developers)\n\n```bash\nexport TF_CLI_CONFIG_FILE=/example-project/dev.tfrc\n```\n\n\u003e NOTE: if you use `~/` instead of an absolute path, then be sure your shell expands it to an absolute path (e.g. `echo $TF_CLI_CONFIG_FILE` should show the absolute path).\n\nThe `dev.tfrc` file:\n\n```tf\nprovider_installation {\n  # Use /your-terraform-provider as an overridden package directory for the\n  # your/provider provider. This disables the version and checksum\n  # verifications for this provider and forces Terraform to look for the\n  # null provider plugin in the given directory.\n  dev_overrides {\n    \"your/provider\" = \"/absolute/path/to/your-terraform-provider/bin\" # wherever directory the binary is compiled and accessible from\n  }\n  \n  # For all other providers, install them directly from their origin provider\n  # registries as normal. If you omit this, Terraform will _only_ use\n  # the dev_overrides block, and so no other providers will be available.\n  direct {}\n}\n```\n\nIf your provider exists here `https://registry.terraform.io/providers/foo/bar/latest` then `your/provider` above would be set to `foo/bar` in this example.\n\nMake a change to your terraform provider code in `/your-terraform-provider` directory. Build your terraform provider binary (e.g. `go build`) and then from your `/example-project` project directory (where you have your terraform code that _consumes_ the provider) run `terraform init` so it picks up the updated provider binary to be used.\n\n\u003e **NOTE**: use `log.Print\u003cT\u003e()` functions not `fmt.Print\u003cT\u003e()` because when using `TF_LOG=TRACE` you'll cause terraform to error.\n\nYou can then run `terraform plan` prefixed with either `TF_LOG=\u003cTRACE|DEBUG|INFO\u003e` or `TF_LOG_PROVIDER=\u003cTRACE|DEBUG|INFO\u003e` (the latter only displays log data for the provider and not all providers + terraform itself (which can be _very_ noisy).\n\n## Alternative Approach\n\nAnother approach still used by the official hashicorp boilerplate repo is to stick your provider plugin into `~/.terraform.d/plugins/`.\n\n```Makefile\nTEST?=$$(go list ./... | grep -v 'vendor')\nHOSTNAME=hashicorp.com\nNAMESPACE=edu\nNAME=hashicups\nBINARY=terraform-provider-${NAME}\nVERSION=0.2\nOS_ARCH=darwin_amd64\n\ndefault: install\n\nbuild:\n\tgo build -o ${BINARY}\n\nrelease:\n\tGOOS=darwin GOARCH=amd64 go build -o ./bin/${BINARY}_${VERSION}_darwin_amd64\n\tGOOS=freebsd GOARCH=386 go build -o ./bin/${BINARY}_${VERSION}_freebsd_386\n\tGOOS=freebsd GOARCH=amd64 go build -o ./bin/${BINARY}_${VERSION}_freebsd_amd64\n\tGOOS=freebsd GOARCH=arm go build -o ./bin/${BINARY}_${VERSION}_freebsd_arm\n\tGOOS=linux GOARCH=386 go build -o ./bin/${BINARY}_${VERSION}_linux_386\n\tGOOS=linux GOARCH=amd64 go build -o ./bin/${BINARY}_${VERSION}_linux_amd64\n\tGOOS=linux GOARCH=arm go build -o ./bin/${BINARY}_${VERSION}_linux_arm\n\tGOOS=openbsd GOARCH=386 go build -o ./bin/${BINARY}_${VERSION}_openbsd_386\n\tGOOS=openbsd GOARCH=amd64 go build -o ./bin/${BINARY}_${VERSION}_openbsd_amd64\n\tGOOS=solaris GOARCH=amd64 go build -o ./bin/${BINARY}_${VERSION}_solaris_amd64\n\tGOOS=windows GOARCH=386 go build -o ./bin/${BINARY}_${VERSION}_windows_386\n\tGOOS=windows GOARCH=amd64 go build -o ./bin/${BINARY}_${VERSION}_windows_amd64\n\ninstall: build\n\tmkdir -p ~/.terraform.d/plugins/${HOSTNAME}/${NAMESPACE}/${NAME}/${VERSION}/${OS_ARCH}\n\tmv ${BINARY} ~/.terraform.d/plugins/${HOSTNAME}/${NAMESPACE}/${NAME}/${VERSION}/${OS_ARCH}\n\ntest: \n\tgo test -i $(TEST) || exit 1                                                   \n\techo $(TEST) | xargs -t -n4 go test $(TESTARGS) -timeout=30s -parallel=4                    \n\ntestacc: \n\tTF_ACC=1 go test $(TEST) -v $(TESTARGS) -timeout 120m   \n```\n","tags":"#terraform #tf #local #dev #environment"},{"id":"baa244ccb85f1e67044136f6e2f71001","title":"Git: multiple branches ","content":"# do some work\ncd ./repo\ngit checkout some_feature\n\n# I need to make a hotfix, but I don't want to disturn my messy 'some_feature' branch\n# I don't want to have to stash things and get things cleaned up\n# So I create a new 'worktree'\ngit worktree list\ngit worktree add ../hotfix\n\n# open new terminal shell\n# and make changes in my new 'hotfix' branch\ncd ./hotfix\n\n# merge my hotfix stuff back into 'main'\ngit checkout main\ngit merge hotfix\n\n# ensure my original 'some_feature' is up-to-date with 'main'\ncd ../repo\ngit rebase main\n\n# clean-up the 'hotfix' working tree (this will delete that directory)\ngit worktree remove hotfix\n","tags":"#git"},{"id":"2489824d4d9c59444c2478683034a141","title":"Go: cross platform subprocess ","content":"// This works on macOS and also all these Window 10 variants: command prompt, Cygwin, PowerShell, WSL 🎉\npackage main\n\nimport (\n\t\"fmt\"\n\t\"log\"\n\t\"os/exec\"\n\t\"runtime\"\n)\n\nfunc main() {\n\tshell := \"sh\"\n\tflag := \"-c\"\n\tif runtime.GOOS == \"windows\" {\n\t\tshell = \"cmd.exe\"\n\t\tflag = \"/C\"\n\t}\n\tbuild := \"go version \u0026\u0026 go version\"\n\n\tcmd := exec.Command(shell, flag, build)\n\tout, err := cmd.Output()\n\tif err != nil {\n\t\tlog.Fatal()\n\t}\n\tfmt.Println(string(out))\n}\n","tags":"#go #windows #macos"},{"id":"8a9cb8924f75ae42487fd877b03360e2","title":"Go: timeouts and custom http client ","content":"package main\n\nimport (\n\t\"context\"\n\t\"crypto/tls\"\n\t\"fmt\"\n\t\"io\"\n\t\"log\"\n\t\"net\"\n\t\"net/http\"\n\t\"strings\"\n\t\"time\"\n\n\t\"github.com/miekg/dns\"\n)\n\nfunc main() {\n\tclient := \u0026http.Client{\n\t\tTimeout: time.Second * 5,\n\t\tTransport: \u0026http.Transport{\n\t\t\t// Avoid: \"x509: certificate signed by unknown authority\"\n\t\t\tTLSClientConfig: \u0026tls.Config{\n\t\t\t\tInsecureSkipVerify: true,\n\t\t\t},\n\t\t\tDialContext: func(ctx context.Context, network string, addr string) (net.Conn, error) {\n\t\t\t\tipv4, err := resolveIPv4(addr)\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn nil, err\n\t\t\t\t}\n\t\t\t\ttimeout, err := time.ParseDuration(\"10s\")\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn nil, err\n\t\t\t\t}\n\t\t\t\treturn (\u0026net.Dialer{\n\t\t\t\t\tTimeout: timeout,\n\t\t\t\t}).DialContext(ctx, network, ipv4)\n\t\t\t},\n\t\t},\n\t}\n\n\t// Also try: https://v4.testmyipv6.com/\n\treq, err := http.NewRequest(\"GET\", \"https://ipv4.lookup.test-ipv6.com/\", nil)\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\n\tres, err := client.Do(req)\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\n\tb, err := io.ReadAll(res.Body)\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\tfmt.Printf(\"%+v\\n\", string(b))\n}\n\n// resolveIPv4 resolves an address to IPv4 address.\nfunc resolveIPv4(addr string) (string, error) {\n\turl := strings.Split(addr, \":\")\n\n\tm := new(dns.Msg)\n\tm.SetQuestion(dns.Fqdn(url[0]), dns.TypeA)\n\tm.RecursionDesired = true\n\n    // NOTE: you shouldn't consult or rely on /etc/resolv.conf as it has proven historically to contain nameservers that don't respond.\n\tconfig, _ := dns.ClientConfigFromFile(\"/etc/resolv.conf\")\n\tc := new(dns.Client)\n\tr, _, err := c.Exchange(m, net.JoinHostPort(config.Servers[0], config.Port))\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\tfor _, ans := range r.Answer {\n\t\tif a, ok := ans.(*dns.A); ok {\n\t\t\turl[0] = a.A.String()\n\t\t}\n\t}\n\n\treturn strings.Join(url, \":\"), nil\n}\n// This enables you to utilise a package such as https://github.com/miekg/dns to resolve the hostname.\n\npackage main\n\nimport (\n  \"context\"\n  \"io/ioutil\"\n  \"log\"\n  \"net\"\n  \"net/http\"\n  \"time\"\n)\nfunc main() {\n  dialer := \u0026net.Dialer{\n    Timeout:   30 * time.Second,\n    KeepAlive: 30 * time.Second,\n  }\n\n  http.DefaultTransport.(*http.Transport).DialContext = func(ctx context.Context, network, addr string) (net.Conn, error) {\n    if addr == \"google.com:443\" {\n      addr = \"216.58.198.206:443\"\n    }\n    return dialer.DialContext(ctx, network, addr)\n  }\n\n  resp, err := http.Get(\"https://www.google.com\")\n  if err != nil {\n    log.Fatalln(err)\n  }\n  defer resp.Body.Close()\n\n  body, err := ioutil.ReadAll(resp.Body)\n  if err != nil {\n    log.Fatalln(err)\n  }\n\n  log.Println(string(body))\n}\n**Server Timeouts**\\\n![Go Server Timeouts](https://gist.github.com/user-attachments/assets/38f12dd7-ced3-4707-a25a-6cb28401a915)\n\n\u003e [!TIP]\n\u003e Use `context.WithTimeout` when you need to enforce timeouts on internal operations like database queries or HTTP calls, especially when you want to propagate cancellation signals through the call stack to prevent resource leaks or manage goroutines. It's ideal for fine-grained control within a handler. In contrast, use `http.TimeoutHandler` when you want a simple way to enforce a timeout on the entire HTTP handler response, particularly when you don’t control the handler logic or don’t need to cancel ongoing work—it only cuts off the response after the timeout but doesn’t stop the underlying processing.\n\n\u003e [!WARNING]\n\u003e Be careful when using `http.TimeoutHander`. If automatically applied to all handlers (as part of a middleware pipeline) then it will not work when it comes to a streaming endpoint (see the relevant Cloudflare article linked in the NOTE below).\n\n**Client Timeouts**\\\n![Go Client Timeouts](https://user-images.githubusercontent.com/180050/120481192-c6f79080-c3a7-11eb-87de-a93b5de81ec8.png)\n\n\u003e [!NOTE]\n\u003e Read the following articles:\\\n\u003e [Resilient HTTP servers using timeouts](https://ieftimov.com/posts/make-resilient-golang-net-http-servers-using-timeouts-deadlines-context-cancellation/)\\\n\u003e [Guide to `net/http` timeouts](https://blog.cloudflare.com/the-complete-guide-to-golang-net-http-timeouts/)\\\n\u003e Also, [here](https://github.com/hashicorp/go-cleanhttp/blob/master/cleanhttp.go#L22-L42) are some Transport settings you might want.\n\nAlthough not explicitly stated, DNS resolution appears to be taken into consideration as part of the overall `http.Client.Timeout` setting. If you need to set your own DNS timeout, then it seems https://github.com/miekg/dns is a popular solution.\n\nAdditionally, it's important to realise how golang resolves hostnames to IPs (i.e. DNS resolution):  \nhttps://golang.org/pkg/net/#hdr-Name_Resolution\n\nWhen cross-compiling binaries you'll find that CGO is typically disabled in favour of the native Go resolver. You can enforce CGO or native like so:\n\n```\nenv GODEBUG=netdns=cgo+2 go run main.go\nenv GODEBUG=netdns=go+2 go run main.go\n```\npackage main\n\nimport (\n\t\"crypto/tls\"\n\t\"errors\"\n\t\"fmt\"\n\t\"io\"\n\t\"log\"\n\t\"net\"\n\t\"net/http\"\n\t\"syscall\"\n\t\"time\"\n)\n\nfunc main() {\n\tclient := \u0026http.Client{\n\t\tTimeout: time.Second * 5,\n\t\tTransport: \u0026http.Transport{\n\t\t\t// Avoid: \"x509: certificate signed by unknown authority\"\n\t\t\tTLSClientConfig: \u0026tls.Config{\n\t\t\t\tInsecureSkipVerify: true,\n\t\t\t},\n\t\t\t// Inspect the network connection type\n\t\t\tDialContext: (\u0026net.Dialer{\n\t\t\t\tControl: func(network, address string, c syscall.RawConn) error {\n\t\t\t\t\t// Reference: https://golang.org/pkg/net/#Dial\n\t\t\t\t\tif network == \"tcp4\" {\n\t\t\t\t\t\treturn errors.New(\"we don't want you to use IPv4\")\n\t\t\t\t\t}\n\t\t\t\t\treturn nil\n\t\t\t\t},\n\t\t\t}).DialContext,\n\t\t},\n\t}\n\n\treq, err := http.NewRequest(\"GET\", \"https://ipv4.lookup.test-ipv6.com/\", nil)\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\n\tres, err := client.Do(req)\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\n\tb, err := io.ReadAll(res.Body)\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\tfmt.Printf(\"%+v\\n\", string(b))\n}\npackage main\n\nimport (\n  \"context\"\n  \"io/ioutil\"\n  \"log\"\n  \"net\"\n  \"net/http\"\n  \"time\"\n)\n\nfunc main() {\n  var (\n    dnsResolverIP        = \"8.8.8.8:53\" // Google DNS resolver.\n    dnsResolverProto     = \"udp\"        // Protocol to use for the DNS resolver\n    dnsResolverTimeoutMs = 5000         // Timeout (ms) for the DNS resolver (optional)\n  )\n\n  dialer := \u0026net.Dialer{\n    Resolver: \u0026net.Resolver{\n      PreferGo: true,\n      Dial: func(ctx context.Context, network, address string) (net.Conn, error) {\n        d := net.Dialer{\n          Timeout: time.Duration(dnsResolverTimeoutMs) * time.Millisecond,\n        }\n        return d.DialContext(ctx, dnsResolverProto, dnsResolverIP)\n      },\n    },\n  }\n\n  dialContext := func(ctx context.Context, network, addr string) (net.Conn, error) {\n    return dialer.DialContext(ctx, network, addr)\n  }\n\n  http.DefaultTransport.(*http.Transport).DialContext = dialContext\n  httpClient := \u0026http.Client{}\n\n  // Testing the new HTTP client with the custom DNS resolver.\n  resp, err := httpClient.Get(\"https://www.google.com\")\n  if err != nil {\n    log.Fatalln(err)\n  }\n  defer resp.Body.Close()\n\n  body, err := ioutil.ReadAll(resp.Body)\n  if err != nil {\n    log.Fatalln(err)\n  }\n\n  log.Println(string(body))\n}\npackage main\n\nimport (\n\t\"context\"\n\t\"crypto/tls\"\n\t\"fmt\"\n\t\"io\"\n\t\"log\"\n\t\"net\"\n\t\"net/http\"\n\t\"time\"\n)\n\nfunc main() {\n\tclient := \u0026http.Client{\n\t\tTimeout: time.Second * 5,\n\t\tTransport: \u0026http.Transport{\n\t\t\t// Avoid: \"x509: certificate signed by unknown authority\"\n\t\t\tTLSClientConfig: \u0026tls.Config{\n\t\t\t\tInsecureSkipVerify: true,\n\t\t\t},\n\t\t\tDialContext: func(ctx context.Context, network string, addr string) (net.Conn, error) {\n\t\t\t\treturn (\u0026net.Dialer{}).DialContext(ctx, \"tcp4\", addr)\n\t\t\t},\n\t\t},\n\t}\n\n\t// Fastly's DNS system controls whether we will report IPv6 addresses for a\n\t// given hostname, and in the case of developer.fastly.com it CNAMEs to the\n\t// Fastly map devhub.fastly.net which is configured to opt-in or out of v6\n\t// support at the map level. The devhub map has dual-stack enabled on it.\n\t// Therefore, it will announce v6 addresses for it if a client sends AAAA DNS\n\t// queries for the hostname.\n\treq, err := http.NewRequest(\"GET\", \"https://developer.fastly.com/api/internal/cli-config\", nil)\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\n\tres, err := client.Do(req)\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\n\tb, err := io.ReadAll(res.Body)\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\tfmt.Printf(\"%+v\\n\", string(b))\n}\n","tags":"#go #http #dns"},{"id":"0058659d37c2bf0691cc7bde8c9579c3","title":"Go: nested struct embedding ","content":"package main\n\nimport (\n\t\"fmt\"\n)\n\ntype Optional struct {\n\tWasSet bool\n}\n\ntype OptionalString struct {\n\tOptional\n\tValue string\n}\n\ntype OptionalFoo struct {\n\tOptionalString\n}\n\nfunc main() {\n\tvar o OptionalFoo\n\to.WasSet = true\n\t\n\t// The following two field lookups are identical\n\tfmt.Printf(\"%+v\\n\", o.WasSet)\n\tfmt.Printf(\"%+v\\n\", o.OptionalString.Optional.WasSet)\n}\n\n","tags":"#go"},{"id":"129d30f3fff68667bb1a1f778f90ab7a","title":"Python: Run Python tests using -m","content":"## Syntax\n\n```bash\npython -m \u003cpath/to/test/directory/\u003e.\u003cname_of_test_file\u003e\n```\n\n## Example\n\nGiven the following directory structure:\n\n```\n└── test\n    ├── __init__.py\n    ├── foo.py\n    └── bar.py\n```\n\nYou can execute the tests in each file like so:\n\n```bash\npython -m test.foo\npython -m test.bar\n```\n\nThis requires the code to use:\n\n```python\nif __name__ == '__main__':\n    unittest.main()\n```\n\nSee also: https://realpython.com/python-testing/#executing-your-first-test\n","tags":""},{"id":"74652e4486141a802c4e65803649cfe0","title":"Vim: filter quickfix/location list results ","content":"```viml\n:packadd cfilter\n:Cfilter! /xyz/\n```\n\nThe `!` is like `grep -v`. \n\nSo  `:Cfilter /xyz/` would filter the results so only those items that have xyz will be kept. If you add the `!` then the results will be everything _except_ xyz. \n\n\u003e **NOTE**: if you're using something like Ack/Ag then you can use that tools own filtering flags, but if that's not appropriate for whatever reason, then this solution is very useful.\n\nA 'pattern' is basic regex syntax by default (you can get `\\v` magic/advanced variation too). \n\nSo by default it means, for example, a regex quantifier like `+` will need to be escaped `\\+`.\n\nSo if you use the basic syntax you'll find `*` is easier to work with as it doesn't need escaping:\n\n```viml\n:Cfilter! '.*/common/.*'\n```\n\nCompared to:\n\n```viml\n:Cfilter! '.\\+/common/.\\+'\n```\n\nBut `\\v` helps for more advanced regex syntax:\n\n```viml\n:Cfilter! '\\v.+/common/.+'\n```\n\n\u003e **NOTE**: I've used `'` single quotes as delimeters as I was filtering content that looked like unix file paths.\n\nRefer to `:help cfilter-plugin` for more information.\n","tags":"#vim #filter #quickfix #locationlist"},{"id":"32a615581c9d0af1b5f53f4f9ba64607","title":"Vim: programming autocomplete with no plugins ","content":"```viml\nfiletype plugin on\nset omnifunc=syntaxcomplete#Complete\n```\n\n`\u003cC-x\u003e\u003cC-o\u003e`\n  \nVim also provides the native command `\u003cC-n\u003e` for autocompletion based on words existing in all opened files (buffers).\n","tags":"#vim #autocomplete"},{"id":"525f7cf4683e67fc90f1e2b7a917cbfe","title":"Go: reverse slice loop ","content":"## OLD SKOOL\n\n```go\npackage main\n\nimport (\n\t\"fmt\"\n)\n\nfunc main() {\n\ts := []int{1, 2, 3, 4, 5}\n\tfor i := len(s) - 1; i \u003e= 0; i-- {\n\t\tfmt.Println(s[i])\n\t}\n}\n```\n\n## MODERN\n\n```go\npackage main\n\nimport (\n\t\"fmt\"\n\t\"slices\"\n)\n\nfunc main() {\n\ts := []int{1, 2, 3, 4, 5}\n\tslices.Reverse(s)\n\tfmt.Println(s)\n}\n```\n","tags":"#go"},{"id":"27e6c7a74957186916d9a0fa0adc697f","title":"Organizational Values ","content":"- We have a **curious** spirit.\n- We **focus** on our **customers**.\n- We are **trustworthy**.\n- We act with **passion**.\n- We operate with **integrity**.\n- We are **competitive** without arrogance.\n- We embrace **transparency**.\n- We are **good** people.\n","tags":"#values"},{"id":"58784fe99234f095bfbae7ea509bd8f2","title":"API vs ABI ","content":"## Summary\n\nAn API is a _compile time_ interface (e.g. using non-project functionality provided by an external library). Where as an ABI is a _runtime_ interface (e.g. an interface used by a program during execution, where the program is internally communicating with machine code).\n\n## Explanation\n\nAn ABI is just an API for two machines, expressed more strictly and at a lower level than an API would be — thus Application Binary Interface vs. Application Programing Interface.\n\nIt's not true that every communication layer between (for example) an SDK and something else is necessarily going through an ABI.\n\nThe distinction is that ABI is only relevant to binary interactions (e.g. an SDK communicating with a separate binary program; that linking process occurs at _runtime_, through an ABI) rather than just interactions in a general sense (e.g. an SDK communicating with an external REST API).\n\n## Contrived Example\n\nAn ABI incompatible change is if I change a method `A#m()` from taking a `String` as an argument to `String...` argument. \n\nThis is not ABI compatible because you have to recompile any code that is calling that function, but it is API compatible as you can resolve the issue by recompiling the caller without any code changes in the caller.\n\n\u003e Find more examples here: https://stackoverflow.com/questions/3784389/difference-between-api-and-abi\n\n## Real Life Example\n\nWe had a rust crate `foo` that depended on another crate `bar` (i.e. `foo` would interact with `bar`) and so both had to be available on the user's system. \n\nA user would write their own rust program that consumed `foo`. As part of setting up their environment we'd ensure that `bar` got installed (as it was a required for `foo` to work), but the user didn't need to know about `bar` (and for the most part they didn't know about it). They only knew that `foo` provided an API they wanted to use, and so the fact that `foo` called `bar` internally didn't matter to the user (they just had to make sure `bar` existed on their system).\n\nRemember that the user's program, and the `foo` and `bar` dependencies are all written in rust code, but ultimately for them to be used together the user has to _compile_ their program (and the dependencies) to machine code.\n\nSo imagine we have `foo` at version 1, and `bar` at version 1. Both work fine together.\n\nNow a change to `bar` is released as version 2, which is incompatible with `foo` version 1.\n\nWhen the user installs `foo` and `bar`, they get `foo` version 1 and `bar` version 2. This means their rust program breaks because the interactions between the `foo` crate and `bar` are broken.\n\nSubsequently the user would need to install an updated version of `foo` which was compatible with `bar`. This meant when releasing changes to `bar` we had to ensure that our environment setup scripts would ensure that the correct version of `foo` would be installed alongside the appropriate version of `bar`. The user still knew nothing about this, as they only cared about `foo`.\n","tags":"#API #ABI"},{"id":"c6a3d8f06d1da7af9706b3c741edd544","title":"Go: Useful tools to run over your project ","content":"go mod tidy\ngofmt -l ./cmd ./pkg\ngo vet ./{cmd,pkg}/...\nstaticcheck ./{cmd,pkg}/...\ngolint ./{cmd,pkg}/...\ngosec -quiet -exclude=G104 ./{cmd,pkg}/...\n","tags":"#go #linting"},{"id":"5df830bae2bc2883b998625af743e041","title":"The Benefits of Diversity ","content":"**Creativity**  \nDifferent identities lead to different perspectives, which can mean more creativity in brainstorming and problem-solving sessions.\n\n**Innovation**  \nWorkplaces with more diversity are 1.7 times more likely to be innovation leaders in their fields.\n\n**Efficiency**  \nA Harvard Business Review study showed that diverse teams are able to solve problems faster than cognitively similar people.\n\n**Revenues**  \nA McKinsey \u0026 Company report showed that diverse workplaces were more likely to outperform their rivals.\n\n**Engagement**  \nA Deloitte analysis showed that workplaces with diverse, inclusive employees had higher engagement, and were better able to retain talent.\n\n**Reputation**  \nWorkplaces that prioritize diversity are seen in a more positive light than those that don’t, including by members of majority groups.\n","tags":"#diversity"},{"id":"e319a258695531ef683077e677904156","title":"Fastly: Terraform CLI with Terraform ","content":"variable \"name\" {\n  type    = string\n  default = \"testing-cli-to-tf-compute\"\n}\n\u003e **NOTE:** The example is for an older version of the Fastly Terraform provider, a more recent version (e.g. 5.4.0 at the time of writing) uses a different setup (shown below) so you'll need to tweak the older examples.\n\n```hcl\nterraform {\n  required_providers {\n    fastly = {\n      source  = \"fastly/fastly\"\n      version = \"5.4.0\"\n    }\n  }\n}\n\ndata \"fastly_package_hash\" \"example\" {\n  filename = \"./pkg/testing-fastly-tf-cli-deploys.tar.gz\"\n}\n\nresource \"fastly_service_compute\" \"testing-fastly-tf-cli-deploys\" {\n  name = \"testing-fastly-tf-cli-deploys\"\n\n  domain {\n    name = \"testing-fastly-tf-cli-deploys.edgecompute.app\"\n  }\n\n  package {\n    filename         = \"./pkg/testing-fastly-tf-cli-deploys.tar.gz\"\n    source_code_hash = data.fastly_package_hash.example.hash\n  }\n\n  force_destroy = true\n}\n```\n\n---\n\nWe use the Fastly CLI (`v0.28.0`) to initialize a new project, and to build a wasm package.\n\nOnce we have built the wasm package, we use Terraform to manage the creation of an actual service and the deployment of the package to that service.\n\nHere is the directory structure:\n\n```\n├── Cargo.lock\n├── Cargo.toml\n├── README.md\n├── bin\n│   └── main.wasm\n├── fastly.toml\n├── pkg\n│   └── testing-cli-noservicecreationtilldeploy.tar.gz\n├── rust-toolchain\n├── src\n│   └── main.rs\n└── terraform\n    ├── main.tf\n    ├── provider.tf\n    └── variables.tf\n```\n\n\u003e **NOTE**: there is a way to get Terraform to _build_ the package for you (i.e. rather than _you_ manually calling `fastly compute build` Terraform will do it), but it's a messy solution ([reference](https://gist.github.com/24767b93df2f368c333ca0ba54ce0e13)).\n\nRunning `terraform apply` from within the `terraform` directory will display:\n\n```tf\nTerraform will perform the following actions:\n\n  # fastly_service_compute.test_service will be created\n  + resource \"fastly_service_compute\" \"test_service\" {\n      + activate       = true\n      + active_version = (known after apply)\n      + cloned_version = (known after apply)\n      + comment        = \"Managed by Terraform\"\n      + force_destroy  = true\n      + id             = (known after apply)\n      + name           = \"testing-cli-to-tf-compute\"\n\n      + backend {\n          + address               = \"127.0.0.1\"\n          + auto_loadbalance      = true\n          + between_bytes_timeout = 10000\n          + connect_timeout       = 1000\n          + error_threshold       = 0\n          + first_byte_timeout    = 15000\n          + max_conn              = 200\n          + name                  = \"originless\"\n          + port                  = 80\n          + ssl_check_cert        = true\n          + use_ssl               = false\n          + weight                = 100\n        }\n\n      + domain {\n          + comment = \"test domain\"\n          + name    = \"testing-cli-to-tf-compute.edgecompute.app\"\n        }\n\n      + package {\n          + filename         = \"../pkg/testing-cli-noservicecreationtilldeploy.tar.gz\"\n          + source_code_hash = \"21c8218135b2f4f97f559719af3d03d05bd39336a45c5ce50fd91e8f8654778bf7b49dbe1743e64d3607fc0e80ae3d5d0e9f1f46bb731f34ee76a2cc02a61688\"\n        }\n    }\n```\n\n\u003e **NOTE**: For testing purposes of the CLI logic I had to keep re-initialising my CLI project, which meant having to rebuild the rust dependency tree each time (very slow). To avoid doing that, don't `rm -rf *` but instead only `rm -r bin/ pkg/ src/ fastly.toml` and so long as you're going to use the same rust starter kit, then you'll get a much quicker build step.\nlocals {\n  pkg = regex(\"name = \\\"(?P\u003cname\u003e[^\\\"]+)\", file(\"../fastly.toml\"))\n}\n\nresource \"fastly_service_compute\" \"test_service\" {\n  name = var.name\n\n  domain {\n    name    = \"${var.name}.edgecompute.app\"\n    comment = \"test domain\"\n  }\n\n  package {\n    filename         = \"../pkg/${local.pkg.name}.tar.gz\"\n    source_code_hash = filesha512(\"../pkg/${local.pkg.name}.tar.gz\")\n  }\n\n  backend {\n    name    = \"originless\"\n    address = \"127.0.0.1\"\n    port    = 80\n  }\n\n  force_destroy = true\n}\nterraform {\n  required_providers {\n    fastly = {\n      source  = \"fastly/fastly\"\n      version = \"0.29.1\"\n    }\n  }\n}\n","tags":"#fastly #cli #terraform #wasm"},{"id":"c78c6b991fdde95919721927d6995872","title":"Terraform: ignore_changes ","content":"\u003e The `ignore_changes` feature is intended to be used when a resource is created with references to data that may change in the future, but should not affect said resource after its creation. -- [Documentation](https://www.terraform.io/docs/language/meta-arguments/lifecycle.html#ignore_changes)\n\nThe pattern is: I want to ensure that this service has a dictionary called \"foo\" with a key \"bar\" with an intial value of \"baz\", but after that I will managed the key/values externally.\n\nThis means you can't go back and add, edit or delete the data added as part of the HCL. That data will forever exist. New data will be expected to be 'managed' (i.e. added, edited, deleted) _outside_ of Terraform.\n","tags":"#terraform #tf"},{"id":"bd980df3edc046a3a461db670f1d2989","title":"Docker: Dockerised Fastly CLI ","content":"FROM rust:latest\nLABEL maintainer=\"Fastly OSS \u003coss@fastly.com\u003e\"\n\nENV RUST_TOOLCHAIN=stable\nRUN rustup toolchain install ${RUST_TOOLCHAIN}\nRUN rustup target add wasm32-wasi --toolchain ${RUST_TOOLCHAIN}\n\nRUN apt-get update \u0026\u0026 apt-get install -y curl jq\nRUN export FASTLY_CLI_VERSION=$(curl --silent https://api.github.com/repos/fastly/cli/releases/latest | jq -r .tag_name | cut -d 'v' -f 2) \\\n  GOARCH=$(dpkg --print-architecture) \\\n  \u0026\u0026 curl -vL \"https://github.com/fastly/cli/releases/download/v${FASTLY_CLI_VERSION}/fastly_v${FASTLY_CLI_VERSION}_linux-$GOARCH.tar.gz\" -o fastly.tar.gz \\\n  \u0026\u0026 curl -vL \"https://github.com/fastly/cli/releases/download/v${FASTLY_CLI_VERSION}/fastly_v${FASTLY_CLI_VERSION}_SHA256SUMS\" -o sha256sums \\\n  \u0026\u0026 dlsha=$(shasum -a 256 fastly.tar.gz | cut -d \" \" -f 1) \u0026\u0026 expected=$(cat sha256sums | awk -v pat=\"$dlsha\" '$0~pat' | cut -d \" \" -f 1) \\\n  \u0026\u0026 if [[ \"$dlsha\" != \"$expected\" ]]; then echo \"shasums don't match\" \u0026\u0026 exit 1; fi\n\nRUN tar -xzf fastly.tar.gz --directory /usr/bin \u0026\u0026 rm fastly.tar.gz\n\nWORKDIR /app\nENTRYPOINT [\"/usr/bin/fastly\"]\nCMD [\"--help\"]\n\n# docker build -t fastly/cli/rust . -f ./Dockerfile-rust\n# docker run -v $PWD:/app -it -p 7676:7676 fastly/cli/rust compute serve --addr=\"0.0.0.0:7676\"\n","tags":"#docker #fastly #cli #shasum #awk #regex #rust"},{"id":"7c694e98c7da5ae1bd034e9c23ae9ea0","title":"Go: Style Guide ","content":"# Table of Contents\n\n- [Reference Materials](#reference-materials)\n- [Naming Summary](#naming-summary)\n- [Whitespace](#whitespace)\n- [Quick note on Code Design](#quick-note-on-code-design)\n- [Quick guide to Error wrapping](#quick-guide-to-error-wrapping)\n- [Quick guide to `panic`](#quick-guide-to-panic)\n- [Quick guide to slice 'gotchas'](#quick-guide-to-slice-gotchas)\n- [Quick guide to pass-by-value vs pass-by-pointer](#quick-guide-to-pass-by-value-vs-pass-by-pointer)\n- [Quick guide to functions with large signature](#quick-guide-to-functions-with-large-signature)\n\n## Reference Materials\n\n- [Effective Go](https://golang.org/doc/effective_go)\n- [Code Review Comments](https://github.com/golang/go/wiki/CodeReviewComments)\n- [What's in a name?](https://talks.golang.org/2014/names.slide)\n- [Commit messages](https://github.com/golang/go/wiki/CommitMessage)\n- [Comments](https://github.com/golang/go/wiki/Comments)\n- [Slice Gotchas](https://blogtitle.github.io/go-slices-gotchas/)\n- [Thinking about interfaces](https://www.integralist.co.uk/posts/go-interfaces/)\n- [Understanding memory allocation](https://gist.github.com/Integralist/22ced4b4700df1e6cbec88c1074c8b2d)\n\n\u003e **NOTE**: Refer to the [specification](https://golang.org/ref/spec) if ever confused about what the expected behaviour is. \n\n## Naming Summary\n\n- Choose package names that lend meaning to the names they export.\n- Where types are descriptive, name should be short (1 or 2 char name).\n- If longer name required, consider refactoring into smaller functions.\n- Commonly used names:\n  - Prefer `i` to `index`.\n  - Prefer `r` to `reader`.\n  - Prefer `buf` to `buffer`.\n  - Prefer `cfg` to `config`.\n  - Prefer `dst, src` to `destination, source`.\n  - Prefer `in, out` when referring to stdin/stdout.\n  - Prefer `rx, tx` when dealing with channels (i.e. receiver, transmitter).\n  - Prefer `data` when referring to file content (whether a `string` or `[]byte`).\n  - Use `ok` instead of longer alternatives.\n- Errors:\n  - Types: `\u003cT\u003eError` (example: `type ExitError struct {...}`).\n  - Values: `Err\u003cT\u003e` (example: `var ErrFormat = errors.New(\"image: unknown format\")`).\n- Interfaces:\n  - When an interface includes multiple methods, choose a name that accurately describes its purpose.\n  - Interfaces that specify just one method are usually just that function name with 'er' appended to it.\n    - Sometimes the result isn't correct English, but we do it anyway.\n    - Sometimes we use English to make it nicer.\n- Return values on exported functions should only be named for documentation purposes.\n  - Side effect is that the variable is initialised at start of function with zero value.\n  - This can, in _rare_ cases, lead to a nice code design.\n- `Set\u003cT\u003e` vs `Register\u003cT\u003e`\n  - Set: use when flipping a bit (example: setting int, string etc).\n  - Register: use when operation is going _into_ something (example: registering a CLI _flag_ into a command).\n\n\u003e **NOTE**: Refer also to https://github.com/kettanaito/naming-cheatsheet\n\n## Whitespace\n\nThe go standard library has no strong conventions or idioms for how to handle whitespace. So try and be concise without leaving the user with a wall of text to digest. Additionally, you can use block syntax `{...}` to help group related logic:\n\n```go\n// Simple code is fine to condense the whitespace.\nif ... {\n  foo\n  for x := range y {\n    ...\n  }\n  bar\n}\n\n// Complex code could benefit from some whitespace (also separate block syntax for grouping related logic).\nif {\n  ...\n\n  {\n    ...grouping of related logic...\n  }\n\n  ...\n}\n```\n\n## Quick note on Code Design\n\nNot always obvious but be wary of returning concrete types when building a package to be used as a library.\n\nHere is an example of why this might be problematic: we had a library that defined a constructor that returned a struct of type `*T`. This struct had methods attached and inside of those methods were API calls. We built a separate CLI that consumed the package library and realised our CLI's test suite wasn't able to mock the type appropriately as some of the fields on the struct were private and would determine if an attached method would make an API call.\n\nThe solution was for us to return an interface. This made it simple to mock the behaviours we wanted (e.g. pretend there was an API error, how does our CLI handle it).\n\n## Quick guide to Error wrapping\n\nWhen you wrap errors your message **should include**:\n\n- A pointer to where within your method the failure occurred.\n- Values that will be useful during debugging (e.g ids).\n- (sometimes) details about why the error occurred.\n- Other relevant info the caller doesnt know.\n\nAnd your message **should NOT include**:\n\n- The name of your function\n- Any of the arguments to your function\n- Any other information that is already known to the caller\n\nHere is a BAD example where the caller of a function that fails is seeing duplicate information:\n\n```go\n// Source\nfunc MightFail(id string) error {\n    err := sqlStatement()\n    if err != nil {\n        return fmt.Errorf(\"mightFail failed with id %v because of sql: %w\", id, err\n    }\n    ...\n    return nil\n}\n\n// Caller\nfunc business(ids []string) error {\n    for _, id := range ids {\n        err := MightFail(id)\n        if err != nil {\n            return fmt.Errorf(\"business failed MightFail on id %v: %w\", id, err)\n        }\n    }\n}\n```\n\nThe resolution to the above bad code is: only include information the caller doesn’t have. The caller is free to annotate your errors with information such as the name of your function, arguments they passed in, etc. There is no need for you to provide that information to them, as its obvious up front. If this same logic is applied consistently you'll end up with error messages that are high-signal and to-the-point.\n\nSee also the article \"[When life gives you lemons, write better error messages](https://scribe.rip/when-life-gives-you-lemons-write-better-error-messages-46c5223e1a2f)\", from which the following images are sourced.\n\n**Bad error message**:\n\n![bad error message](https://user-images.githubusercontent.com/180050/197973153-1ffdb242-d9c2-47e1-a772-3cf1c6b9a169.png)\n\n**Good error message**:\n\n![good error message](https://user-images.githubusercontent.com/180050/197973167-bd7b55e0-73e8-412e-8c91-f24b5ecf1324.png)\n\n## Quick guide to `panic`\n\n- The use of `panic` is reserved for when an error is _unrecoverable_.\n- What constitutes an \"unrecoverable\" error is contentious. Here are some definitions:\n    - To indicate that something impossible has happened, such as exiting an infinite loop.\n    - During initialization, if the library truly cannot set itself up, it might be reasonable to `panic`.\n    - When something internally has fundamentally failed.\n    - When a programmer gives something to a function which the function explicitly states is invalid.\n- [`bytes.Truncate`](https://github.com/golang/go/blob/8ac6544/src/bytes/buffer.go#L88-L90) is an example of the last sub-point.\n  - The above example could be considered _aggressive_. \n  - Instead the standard library could have returned an error so the caller could decide the appropriate action to take.\n- The use (and conditions) of `panic` should be documented (example: [`bytes.Truncate`](https://github.com/golang/go/blob/8ac6544/src/bytes/buffer.go#L81))\n- The use of `recover` is for when you disagree with the library authors.\n- Wherever possible avoid `panic` and return an error for the caller to handle.\n\n## Quick guide to slice 'gotchas'\n\nWhen taking a slice of a slice you might stumble into behaviour which appears confusing at first. The `cap`, `len` and `data` fields might change, but the underlying array is not re-allocated, nor copied over and so modifications to the slice will modify the original backing array.\n\n\u003e Refer to the golang language specification section on [\"full slice expressions\"](https://golang.org/ref/spec#Slice_expressions) syntax (`[low : high : max]`) for controlling the capacity of a slice.\n\n### Ghost update 1\n\nThe underlying array is modified after updating an element on the slice:\n\n```go\na := []int{1, 2}\nb := a[:1]     /* [1]     */\nb[0] = 42      /* [42]    */\nfmt.Println(a) /* [42, 2] */\n```\n\n### Ghost update 2\n\nWhen data gets appended to `b` (a slice of the `a` slice), the underlying array has enough capacity to hold two more elements, so `append` will not re-allocate. This means that appending to `b` might not only change `a` but also `c` (a slice of the `a` slice).\n\n```go\na := []int{1, 2, 3, 4}\nb := a[:2] /* [1, 2] */\nc := a[2:] /* [3, 4] */\nb = append(b, 5)\nfmt.Println(a) /* [1 2 5 4] */\nfmt.Println(b) /* [1 2 5]   */\nfmt.Println(c) /* [5 4]     */\n```\n\nThe fix is `b := a[:2:2]` which sets the capacity of the `b` slice such that `append` will cause a new array to be allocated. This means `a` will not be modified, nor will the `c` slice of `a`.\n\n\u003e **NOTE**:  there are more examples/explanations in https://blogtitle.github.io/go-slices-gotchas/\n\n## Quick guide to pass-by-value vs pass-by-pointer\n\n\u003e Reference articles: [goinbigdata.com](https://goinbigdata.com/golang-pass-by-pointer-vs-pass-by-value/) and [dave.cheney.net](https://dave.cheney.net/2017/04/29/there-is-no-pass-by-reference-in-go).\n\nIn essence when people say 'pass by reference', the point they're trying to get across is: \"this _isn't_ a copy of the value being passed\". Where as 'pass by reference' is a very _specific_ type of behaviour.\n\nAll primitive/basic types (int and its variants, float and its variants, boolean, string, array, and struct) in Go are passed by value.\n\nMaps and slices are passed by pointer (sometimes incorrectly called pass-by-reference). This is where a new copy of the 'pointer' to the same memory address is created.\n\nGo does not have pass-by-reference semantics because Go does not have 'reference variables' (which is something you'd find in C++). \n\nIn C++ you can create `a = 10` and then _alias_ `b` to `a` (`\u0026b = a`) such that updating `b` would _affect_ `a`. Go doesn't have this behaviour. Every variable is stored in its own memory space. Meaning if we had `b := \u0026a` and updated `b` then we wouldn't cause any change to `a`.\n\nWhen we define a function that accepts a pointer (e.g. `changeName(p *Person)`) and we pass a pointer to it (e.g. `changeName(\u0026person)`) the variable person is modified inside the `changeName` function. This happens because `\u0026person` and `p` are two _different_ pointers to the _same_ struct which is stored at the same memory address. This is quite different to C++'s reference variables.\n\n## Quick guide to functions with large signature\n\nYour functions should have concise/relevant arguments passed in.\n\nDon't, for example, pass in an argument whose type is a large object and which the function then has to know how that object is structured as that's violating the Law of Demeter. Instead choose a field from the object to pass in as it'll likely have a simpler type (like a `string` or `int`).\n\nThree approaches to dealing with functions that potentially could have a large number of arguments...\n\n1. Make multiple functions to help reduce the number of arguments.\n2. Pass in a `\u003cT\u003eOptions` struct.\n3. Variadic arguments that accept a func type.\n\nI would say go with option 1 whenever possible, and almost never choose option 2 over option 3 as the latter is much more flexible.\n\nThe problem with option 2 is that it can become quite cumbersome to construct an object with lots of fields, and more importantly it can be hard to know which fields are _required_ and which are _optional_. Yes it's nice that you can easily omit optional fields easily, but then option 3 also provides that benefit while also solving the problem of knowing what arguments are required vs optional.\n\nUsing option 3 can be helpful when you want to make the function signature clear, by accepting a couple of concrete arguments that are _required_ for the function to work, while shifting _optional_ arguments into separate functions, as demonstrated below...\n\n```go\ntype Client struct {\n  host, proxy string\n  port int\n}\n\ntype Option func(*Client) // call this function to apply the option\n\nfunc WithPort(port int) Option {\n  return func(c *Client) { c.port = port }\n}\n\nfunc WithProxy(proxy string) Option {\n  return func(c *Client) { c.proxy = proxy }\n}\n\nfunc NewClient(host string, options ...Option) *Client {\n  c := \u0026Client{host: host, port: 80} // default values\n  for _, option := range options {\n    option(c) // apply the options by calling each one of them\n  }\n  return c\n}\n```\n","tags":"#go #guides"},{"id":"5438adc0f4862c809264e1d151560563","title":"Yaml: merge key and reference pointer ","content":"\u003e NOTE: use https://onlineyamltools.com/convert-yaml-to-json for testing conversions.\n\n## Lists\n\nYou can create a reference pointer using `\u0026` and dereference the pointer using `*` as shown here:\n\n```yaml\nfoo:\n - \u0026ref |-\n  x\n - y\n - z\n\nbar:\n  - *ref\n  - a\n  - b\n```\n\nThis will produce the following JSON (notice the `x` list element was duplicated):\n\n```json\n{\n  \"foo\": [\n    \"x\",\n    \"y\",\n    \"z\"\n  ],\n  \"bar\": [\n    \"x\",\n    \"a\",\n    \"b\"\n  ]\n}\n```\n\n## Objects\n\nThis works for key value objects too by using the 'merge key' syntax `\u003c\u003c` with a pointer to an object:\n\n```yaml\nref: \u0026obj\n  foo: bar\n\nanother_key:\n \u003c\u003c : *obj\n beep: boop\n```\n\nThis will produce the following JSON (notice the `foo: bar` key/value was duplicated):\n\n```json\n{\n  \"ref\": {\n    \"foo\": \"bar\"\n  },\n  \"another_key\": {\n    \"foo\": \"bar\",\n    \"beep\": \"boop\"\n  }\n}\n```\n\n\u003e [Merge Key reference](https://yaml.org/type/merge.html) (spacing doesn't matter, e.g. `\u003c\u003c: *obj` vs `\u003c\u003c : *obj`)\n\n### Nested example\n\nThe following example is a list of objects:\n\n```yaml\ndockers:\n- \u003c\u003c: \u0026docker_opts\n    use_buildx: true\n    dockerfile: Dockerfile\n  image_templates:\n    - \"ghcr.io/fastly/cli:{{ .Version }}-386\"\n  build_flag_templates:\n    - \"--platform=linux/386\"\n- \u003c\u003c: *docker_opts\n  image_templates:\n    - \"ghcr.io/fastly/cli:{{ .Version }}-amd64\"\n  build_flag_templates:\n    - \"--platform=linux/amd64\"\n- \u003c\u003c: *docker_opts\n  image_templates:\n    - \"ghcr.io/fastly/cli:{{ .Version }}-arm64\"\n  build_flag_templates:\n    - \"--platform=linux/arm64\"\n  goarch: arm64\n```\n\n## Caveats\n\nThis doesn't work as well when it comes to grouping multiple list elements:\n\n```yaml\nfoo: \u0026ref\n - y\n - z\n\nbar:\n  - *ref\n  - a\n  - b\n```\n\nAs this will nest the reference instead of merging it:\n\n```json\n{\n  \"foo\": [\n    \"y\",\n    \"z\"\n  ],\n  \"bar\": [\n    [\n      \"y\",\n      \"z\"\n    ],\n    \"a\",\n    \"b\"\n  ]\n}\n```\n\nThis also doesn't work (at all) for copying individual key/value fields (i.e. you can only reference an object 'block').\n\nThe following example is broken:\n\n```yaml\nfoo: \u0026ref bar # the \u0026ref isn't invalid (i.e. it doesn't break the yaml parser)\nbeep: boop\nnested:\n  \u003c\u003c : *ref   # but 'using' the ref in this way IS invalid\n```\n","tags":"#yaml #syntax #dereference #pointer #merge"},{"id":"cbf2814b2565b540fdf986d4975a007a","title":"Go: panic vs os.Exit ","content":"`panic` signals \"the programmer has made a fundamental mistake and execution cannot continue safely\", whereas `os.Exit` signals \"the programmer has decided that the process should terminate here\" — different meanings. Also, important difference in behavior: `panic` will unwind the callstack, which means it will call any pending `defer` statements; `os.Exit` will just do a hard kill, so it won't.\n","tags":"#go #guides"},{"id":"39338a06a94dfea93c652cb664f5148a","title":"Go: TOML Examples with custom Marshaller ","content":"DECODE\n\n{Managed:by CLI Testing:{Backends:map[bar.baz:{URL:https://barbaz.com/} foo:{URL:https://foo.com/} qux:{URL:https://qux.com/}]}}\n\nmanaged = \"by CLI\"\n\n[testing]\n\n  [testing.backends]\n\n    [testing.backends.\"bar.baz\"]\n      url = \"https://barbaz.com/\"\n\n    [testing.backends.foo]\n      url = \"https://foo.com/\"\n\n    [testing.backends.qux]\n      url = \"https://qux.com/\"\n\nUNMARSHAL\n\n{Managed:by CLI Testing:{Backends:map[bar.baz:{URL:https://barbaz.com/} foo:{URL:https://foo.com/} qux:{URL:https://qux.com/}]}}\n\nmanaged = \"by CLI\"\n\n[testing]\n\n  [testing.backends]\n\n    [testing.backends.\"bar.baz\"]\n      url = \"https://barbaz.com/\"\n\n    [testing.backends.foo]\n      url = \"https://foo.com/\"\n\n    [testing.backends.qux]\n      url = \"https://qux.com/\"\nThe following files demonstrate how the CLI will handle the input toml.\n\nHere are the files:\n\n- [`example.toml`](#file-example-toml): it represents similar content to what `fastly.toml` holds and we expect the CLI to manage.\n- [`main.go`](#file-main-go): a reduced test case go program that attempts to decode/encode the provided toml to see how it handles things by default.\n- [`output`](#file-output): shows the output of the go program.\n\n## Summary\n\nThe TOML library will continue to produce more verbose output, and will overwrite the users toml with the verbose variation (only for `fastly.toml`, as that's the only file that CLI manages).\n\n## Custom Marshaller\n\nI've written a custom marshaller but there are some issues to keep in mind.\n\nFirst, here's the implementation of the custom marshal:\n\n```go\nfunc (m Manifest) MarshalTOML() ([]byte, error) {\n\tvar b bytes.Buffer\n\n\tb.WriteString(\"managed = \" + m.Managed + \"\\n\\n\")\n\tb.WriteString(\"[testing.backends]\\n\")\n\n\tfor k, v := range m.Testing.Backends {\n\t\tline := fmt.Sprintf(\"%s = { url = \\\"%s\\\" }\\n\", k, v.URL)\n\t\tb.WriteString(line)\n\t}\n\n\treturn b.Bytes(), nil\n}\n```\n\nHere are the issues:\n\n1. The order of the backends are non-deterministic so they won't necessarily match what the user entered originally.\n2. This is a very simple implementation and so we don't analyse the original syntax. This means if the user writes their toml over multiple lines, then the CLI will overwrite that with the more concise version defined in `MarshalTOML`.\n3. The user is going to mostly copy/paste toml between `fastly.toml` and their environment files. Meaning: there will be a difference between the `fastly.toml` (which the CLI will overwrite the toml with more verbose toml syntax) and the environment files that the CLI doesn't manage.\nmanaged = \"by CLI\"\n\n[testing.backends]\nfoo = { url = \"https://foo.com/\"}\n\"bar.baz\" = { url = \"https://barbaz.com/\"}\nqux = { url = \"https://qux.com/\"}\npackage main\n\nimport (\n\t\"fmt\"\n\t\"io\"\n\t\"log\"\n\t\"os\"\n\n\t\"github.com/pelletier/go-toml\"\n)\n\nfunc main() {\n\tfpath := \"example.toml\"\n\n    \t// NOTE: trying both Decode/Encode and Unmarshal/Marshal to see if there were any differences (there aren't).\n\n\tmd := decode(fpath)\n\ttoml.NewEncoder(os.Stdout).Encode(md)\n\n\tmu := unmarshal(fpath)\n\tb, _ := toml.Marshal(mu)\n\tfmt.Println(string(b))\n}\n\nfunc decode(fpath string) Manifest {\n\tfmt.Println(\"\\nDECODE\")\n\n\tvar m Manifest\n\n\tf, err := os.OpenFile(fpath, os.O_RDWR|os.O_CREATE, 0755)\n\tif err != nil {\n\t\tfmt.Println(\"decode: %w\", err)\n\t}\n\n\ttoml.NewDecoder(f).Decode(\u0026m)\n\n\tfmt.Printf(\"\\n%+v\\n\\n\", m)\n\n\treturn m\n}\n\nfunc unmarshal(fpath string) Manifest {\n\tfmt.Println(\"\\nUNMARSHAL\")\n\n\tvar m Manifest\n\n\tf, err := os.OpenFile(fpath, os.O_RDWR|os.O_CREATE, 0755)\n\tif err != nil {\n\t\tfmt.Println(\"unmarshal: %w\", err)\n\t}\n\n\tb, err := io.ReadAll(f)\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\n\ttoml.Unmarshal(b, \u0026m)\n\n\tfmt.Printf(\"\\n%+v\\n\\n\", m)\n\n\treturn m\n}\n\ntype Manifest struct {\n\tManaged string  `toml:\"managed\"`\n\tTesting Testing `toml:\"testing\"`\n}\n\ntype Testing struct {\n\tBackends map[string]Backend `toml:\"backends\"`\n}\n\ntype Backend struct {\n\tURL string `toml:\"url\"`\n}\n","tags":"#go #serialization"},{"id":"8b603ac63dd84f4f2efc16d671e5db22","title":"Go: signal handling SIGINT/SIGTERM of a subprocess ","content":"#!/usr/bin/env bash\n\nwhile :\ndo\n  date \"+%H:%M:%S\"\n  sleep 1\ndone\nfunc main() {\n\tsig := make(chan os.Signal, 1)\n\n\tsignals := []os.Signal{\n\t\tsyscall.SIGINT,\n\t\tsyscall.SIGTERM,\n\t}\n\n\tsignal.Notify(sig, signals...)\n\n\tcmd := exec.Command(\"./binary.sh\")\n\tcmd.Stdout = out\n\n\tgo func(sig chan os.Signal, cmd *exec.Cmd) {\n\t\t\u003c-sig\n\t\tsignal.Stop(sig)\n\n\t\terr := cmd.Process.Signal(os.Kill)\n\t\tif err != nil {\n\t\t\tlog.Fatal(err)\n\t\t}\n\t}(sig, cmd)\n\n\terr := cmd.Start()\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tcmd.Wait()\n}\n","tags":"#go"},{"id":"e47ac6d674c246d77e69d55e03c6b121","title":"Go: handle long running process ","content":"#!/usr/bin/env bash\n#\n# NOTE: don't forget to `chmod +x process.sh`\n\nwhile :\ndo\n  date \"+%H:%M:%S\"\n  sleep 1\ndone\n\npackage main\n\nimport (\n\t\"log\"\n\t\"os\"\n\t\"os/exec\"\n\t\"time\"\n)\n\nfunc main() {\n\tcmd := exec.Command(\"./process.sh\")\n\tcmd.Stdout = os.Stdout\n\tcmd.Stderr = os.Stderr\n\n\terr := cmd.Start()\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\n\ttimer := time.NewTimer(time.Second * 5)\n\n\tgo func(timer *time.Timer, cmd *exec.Cmd) {\n\t\tfor range timer.C {\n\t\t\terr := cmd.Process.Signal(os.Kill)\n\t\t\tif err != nil {\n\t\t\t\tlog.Fatal(err)\n\t\t\t}\n\t\t}\n\t}(timer, cmd)\n\n\tcmd.Wait()\n}\n","tags":"#go"},{"id":"17a7cb39505d8949bea14cd30fec5738","title":"Go: new vs make ","content":"- https://golang.org/ref/spec#Allocation\n- https://golang.org/ref/spec#The_zero_value\n- https://golang.org/doc/effective_go#allocation_new\n- https://golang.org/doc/effective_go#allocation_make\n\n## Summary\n\n- `make`: allocates memory to hold a built-in type (slice, map or channel) with `len` and `cap` (capacity) set accordingly to the type's zero value (immediately usable).\n- `new`: allocates memory to hold both built-in and custom user types with fields zeroed, not immediately usable for some types.\n\n\u003e **NOTE**: This means `t := new(T)` and `var t *T` are equivalent.  \n\n**Example**:\n```go\nm := new(int)\nfmt.Printf(\"%+v | %p | %T\\n\", *m, m, m) // 0 | 0xc000110008 | *int`\n```\npackage main\n\nimport (\n\t\"fmt\"\n)\n\nfunc main() {\n\t// The new built-in function allocates memory.\n\t// The first argument is a type, not a value.\n\t// The value returned is a pointer to a newly allocated zero value of that type.\n\tp := new([]int)\n\t// len, cap == 0\n\n\tfmt.Println(\"underlying array should be nil, i.e. comparison should return true:\", *p == nil)\n\n\t// we can't append to p (as p is a pointer)\n\t// so we have to dereference p to append to it\n\t// also *p == nil until we append to the underlying array\n\t// once we've appended some data the underlying array is no longer nil\n\t*p = append(*p, 1)\n\n\tfmt.Println(\"underlying array should no longer be nil, i.e. comparison should return false:\", *p == nil)\n\n\t// The make built-in function allocates and initializes an object of type slice, map, or chan (only).\n\t// Like new, the first argument is a type, not a value.\n\t// Unlike new, make's return type is the same as the type of its argument, not a pointer to it.\n\tv := make([]int, 5, 10)\n\t// len = 5, cap = 10\n\n\tfmt.Println(\"v should not be nil, i.e. comparison should return false:\", v == nil)\n\n\tfmt.Printf(\"\\np:\\n%+v\\n%T\\n\\n\", p, p) // \u0026[]\n\tfmt.Printf(\"v:\\n%+v\\n%T\\n\\n\", v, v)   // [0 0 0 0 0]\n\n}\n","tags":"#go #performance"},{"id":"e23fe5cd55e87cf3043c1c32322640fa","title":"Go: Application Design ","content":"\u003e Most information is copied verbatim from https://pace.dev/blog/2020/02/12/why-you-shouldnt-use-func-main-in-golang-by-mat-ryer.html\n\u003e\n\u003e Also consider:\n\u003e - https://golang.org/doc/effective_go\n\u003e - https://github.com/golang/go/wiki/CodeReviewComments\n\u003e - https://the-zen-of-go.netlify.app/\n\nCall a `run` function from `main` to decouple the two and to enable easier testing:\n\n```go\nconst (\n\t// exitFail is the exit code if the program\n\t// fails.\n\texitFail = 1\n)\n\nfunc main() {\n\tif err := run(os.Args, os.Stdout); err != nil {\n\t\tfmt.Fprintf(os.Stderr, \"%s\\n\", err)\n\t\tos.Exit(exitFail)\n\t}\n}\n\nfunc run(args []string, stdout io.Writer) error {\n\tif len(args) \u003c 2 {\n\t\treturn errors.New(\"no names\")\n\t}\n\tfor _, name := range args[1:] {\n\t\tfmt.Fprintf(stdout, \"Hi %s\", name)\n\t}\n\treturn nil\n}\n```\n\nWe can use flags inside the run function using the flag.NewFlagSet function and avoid using global flags altogether:\n\n```go\nflags := flag.NewFlagSet(args[0], flag.ExitOnError)\nvar (\n\tverbose    = flags.Bool(\"v\", false, \"verbose logging\")\n\tformat     = flags.String(\"f\", \"Hi %s\", \"greeting format\")\n)\nif err := flags.Parse(args[1:]); err != nil {\n\treturn err\n}\n```\n\nTest code can set any flags they like when calling `run` by passing in different args:\n\n```go\nerr := run([]string{\"program\", \"-v\", \"-debug=true\", \"-another=2\"})\n```\n\nThis allows you to write tests covering different flag usage too.\n","tags":"#go #guide"},{"id":"68501b147bfea6060043b380f749c073","title":"Go: Install the Go programming language (with multiple versions + installing binaries) ","content":"## UPDATE\n\nJust install [stefanmaric/g](https://github.com/stefanmaric/g).\n\nOtherwise, for all the gory details see the following...\n\n## Install Go\n\nYou can either download the latest release from https://golang.org/doc/install or a specific release, e.g. `https://go.dev/dl/go1.18.1.darwin-arm64.pkg`.\n\n\u003e **NOTE:** Test on Docker using: `docker run -v $(pwd):/go-project-to-build -it ubuntu bash`\n\n```shell\napt-get update\napt-get install -y wget\nwget -c https://golang.org/dl/go1.22.0.linux-amd64.tar.gz\ntar -C /usr/local -xvzf go1.22.0.linux-amd64.tar.gz\n/usr/local/go/bin/go version\nexport PATH=\"/usr/local/go/bin:$PATH\"\ngo version\nexport PATH=\"~/go/bin:$PATH\" # for handling `go install`ed binaries\n```\n\nThe installation directory will be: `/usr/local/go`.\n\nOnce you have Go installed, you can then use the `go` command to either install go based tools/binaries or other versions of Go (see below).\n\n\u003e **NOTE**: Additionally, you can automate the install via a terminal using the following shell function:\n\n```bash\n# you can swap `ag` for `grep` if you prefer less dependencies\nalias golatest=\"curl -L https://github.com/golang/go/tags 2\u003e\u00261 | ag '/golang/go/releases/tag/go[\\w.]+' -o | cut -d '/' -f 6 | awk NR==1 | ag '\\d.+' -o\"\n\nfunction go_install {\n  if [ -z \"$1\" ]; then\n    echo USAGE: go_install 1.18.1 OR go_install \\$\\(golatest\\)\n    return\n  fi\n  v=$1\n  osname=$(uname -s | tr '[:upper:]' '[:lower:]')\n  hardware=$(uname -m)\n  mkdir -p ~/goversions\n  if ! test -f \"~/goversions/go$v.$osname-$hardware.pkg\"; then\n    printf \"\\nDownloading %s\\n\\n\" \"go$v.$osname-$hardware\"\n    curl -L -o ~/goversions/go$v.$osname-$hardware.pkg https://go.dev/dl/go$v.$osname-$hardware.pkg\n  fi\n  echo \"\"\n  sudo rm -rf /usr/local/go; sudo installer -pkg ~/goversions/go$v.$osname-$hardware.pkg -target /usr/local/\n  clear\n  go version\n}\n```\n\n## Installing binaries\n\nAs of version go 1.16 `go install` is now responsible only for installing binaries, _not_ modifying a `go.mod` file (that's what `go get` is for).\n\n```bash\ngo install example.com/cmd@v1.0.0\ngo install example.com/cmd@latest\n```\n\n\u003e **NOTE**: See [reference documentation](https://go.dev/ref/mod#go-install).\n\n## Installing different go versions\n\nThe following is the 'official' approach...\n\nhttps://go.dev/doc/manage-install#installing-multiple\n\n```bash\ngo install golang.org/dl/go1.18@latest\ngo1.18 download\ngo1.18 version # go version go1.18 darwin/amd64\nalias go=go1.18\n\n# if you want a simple binary overwrite of the global go\ngo install golang.org/dl/go1.18@latest\ngo1.18 download\nsudo cp $(which go1.18) $(which go) # requires sudo as it's copying into /usr/local/...\n\n# latest (tip) with additional/unreleased feature\ngo install golang.org/dl/gotip\ngotip download dev.fuzz # also download a dev/tip specific tool/feature\ngotip test -fuzz=FuzzFoo\n```\n\n\u003e **NOTE**: If using version of go \u003c 1.16 you'll need to use `go get` instead of `go install`.\n\n## Basic switcher using `go.mod` as reference\n\n```bash\n# This function identifies the go version specified in a project's go.mod\n# It then attempts to switch to a binary of that version.\n# If none exists it will instruct you how to download it.\n#\n# NOTE: Some tools, e.g. TinyGo, won't work with this approach because we're\n# just replacing the go binary and the VERSION file, where the originally\n# installed version of go will have things like CGO files that TinyGo will try\n# to use and if those don't align with the version of the binary we've switched\n# to, then it means TinyGo will fail to compile. \n#\n# In that scenario you're better off using the `go_install` shell function \n# approach at the top of the page.\nfunction go_version {\n    if [ -f \"go.mod\" ]; then\n        v=$(grep -E '^go \\d.+$' ./go.mod | grep -oE '\\d.+$')\n        if [[ ! $(go version | grep \"go$v\") ]]; then\n          echo \"\"\n          echo \"About to switch go version to: $v\"\n          if ! command -v \"$HOME/go/bin/go$v\" \u0026\u003e /dev/null\n          then\n            echo \"run: go install golang.org/dl/go$v@latest \u0026\u0026 go$v download \u0026\u0026 sudo cp \\$(which go$v) \\$(which go)\"\n            return\n          fi\n          sudo cp $(which go$v) $(which go)\n          echo -n go$v | sudo tee $(dirname $(dirname $(which go)))/VERSION \u003e /dev/null\n        fi\n    fi\n}\n\n# To support the configuring our go environment we will override the cd\n# command to call the go logic for checking the go version.\n#\n# NOTE: We use `command` and not `builtin` because the latter doesn't take into\n# account anything available on the user's $PATH but also because it didn't\n# work with the Starship prompt which seems to override cd also.\nfunction cd {\n  command cd \"$@\"\n  RET=$?\n  go_version\n  return $RET\n}\n```\n\n## Unofficial: goenv\n\nhttps://github.com/syndbg/goenv\n\nThe nice thing about goenv is that it lets you more easily automate a switch between projects using either `GOENV_VERSION` or `.go-version` ([docs](https://github.com/syndbg/goenv/blob/master/HOW_IT_WORKS.md#choosing-the-go-version)).\n\n## Linux\n\n```bash\nsudo apt-get update\nsudo apt-get upgrade # this takes a LONG time\nsudo apt-get install golang-go\n```\n\nOR\n\n```bash\nwget https://dl.google.com/go/go1.17.2.linux-amd64.tar.gz\nsudo tar -xvf go1.17.2.linux-amd64.tar.gz # this takes a LONG time\nsudo mv go /usr/local\n\nexport GOROOT=/usr/local/go\nexport GOPATH=$HOME/go\nexport PATH=$GOPATH/bin:$GOROOT/bin:$PATH\n\nsource ~/.bashrc\n```\n\nOR\n\n```bash\nwget -c https://golang.org/dl/go1.22.1.linux-amd64.tar.gz\nsudo tar -C /usr/local -xvzf go1.22.1.linux-amd64.tar.gz\nexport PATH=/usr/local/go/bin:$PATH\n```\n","tags":"#go #install"},{"id":"41e6946a23a73022a84d5b383949faf9","title":"S3: backend for Terraform ","content":"# S3 backend for Terraform\n\n\u003e Copied verbatim from https://github.com/ozbillwang/terraform-best-practices\n\nCreatee a s3 bucket and dynamodb table to use as terraform backend.\n\n* dynamodb_table_name = terraform-lock\n* s3_bucket_name = \u003caccount_id\u003e-terraform-states\n\n# usage\n\n```\n# make sure you are on the right aws account\npip install awscli\naws s3 ls\n\n# If you don't set default region in your aws configuration, and you want to create the resources in region \"us-east-1\"\nexport AWS_DEFAULT_REGION=us-east-1\nexport AWS_REGION=us-east-1\n\n# Dry-run\nterraform init\nterraform plan\n\n# apply the change\nterraform apply\n```\n# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n# CREATE AN S3 BUCKET AND DYNAMODB TABLE TO USE AS A TERRAFORM BACKEND\n# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n# ----------------------------------------------------------------------------------------------------------------------\n# REQUIRE A SPECIFIC TERRAFORM VERSION OR HIGHER\n# This module has been updated with 0.12 syntax, which means it is no longer compatible with any versions below 0.12.\n# This module is forked from https://github.com/gruntwork-io/intro-to-terraform/tree/master/s3-backend\n# ----------------------------------------------------------------------------------------------------------------------\n\nterraform {\n  required_version = \"\u003e= 0.12\"\n}\n\n# ------------------------------------------------------------------------------\n# CONFIGURE OUR AWS CONNECTION\n# ------------------------------------------------------------------------------\n\nprovider \"aws\" {}\n\n# ------------------------------------------------------------------------------\n# CREATE THE S3 BUCKET\n# ------------------------------------------------------------------------------\n\ndata \"aws_caller_identity\" \"current\" {}\n\nlocals {\n  account_id    = data.aws_caller_identity.current.account_id\n}\n\nresource \"aws_s3_bucket\" \"terraform_state\" {\n  # With account id, this S3 bucket names can be *globally* unique.\n  bucket = \"${local.account_id}-terraform-states\"\n\n  # Enable versioning so we can see the full revision history of our\n  # state files\n  versioning {\n    enabled = true\n  }\n\n  # Enable server-side encryption by default\n  server_side_encryption_configuration {\n    rule {\n      apply_server_side_encryption_by_default {\n        sse_algorithm = \"AES256\"\n      }\n    }\n  }\n}\n\n# ------------------------------------------------------------------------------\n# CREATE THE DYNAMODB TABLE\n# ------------------------------------------------------------------------------\n\nresource \"aws_dynamodb_table\" \"terraform_lock\" {\n  name         = \"terraform-lock\"\n  billing_mode = \"PAY_PER_REQUEST\"\n  hash_key     = \"LockID\"\n\n  attribute {\n    name = \"LockID\"\n    type = \"S\"\n  }\n}\noutput \"s3_bucket_name\" {\n  value       = aws_s3_bucket.terraform_state.id\n  description = \"The NAME of the S3 bucket\"\n}\n\noutput \"s3_bucket_arn\" {\n  value       = aws_s3_bucket.terraform_state.arn\n  description = \"The ARN of the S3 bucket\"\n}\n\noutput \"s3_bucket_region\" {\n  value       = aws_s3_bucket.terraform_state.region\n  description = \"The REGION of the S3 bucket\"\n}\n\noutput \"dynamodb_table_name\" {\n  value       = aws_dynamodb_table.terraform_lock.name\n  description = \"The ARN of the DynamoDB table\"\n}\n\noutput \"dynamodb_table_arn\" {\n  value       = aws_dynamodb_table.terraform_lock.arn\n  description = \"The ARN of the DynamoDB table\"\n}\n```terraform\n# main.tf\nterraform {\n  backend \"s3\" {\n    encrypt = true\n  }\n}\n\n# example of 'partial configuration':\n# https://www.terraform.io/docs/backends/config.html#partial-configuration\n#\n# cat config/backend-dev.conf\nbucket  = \"\u003caccount_id\u003e-terraform-states\"\nkey     = \"development/service-name.tfstate\"\nencrypt = true\nregion  = \"ap-southeast-2\"\ndynamodb_table = \"terraform-lock\"\n```\n\n\u003e **NOTE**: you'll need a config/dev.tfvars too to set your other environment values.\n\n```bash\nenv=dev\nterraform get -update=true\nterraform init -backend-config=config/backend-${env}.conf\nterraform plan -var-file=config/${env}.tfvars\nterraform apply -var-file=config/${env}.tfvars\n```\n","tags":"#terraform #s3"},{"id":"3aa30eea6ec1fdd3874e130b84bfb6a9","title":"Go: prepend line to stop of a file that uses toml marshal ","content":"package main\n\nimport (\n\t\"bufio\"\n\t\"fmt\"\n\t\"os\"\n\n\ttoml \"github.com/pelletier/go-toml\"\n)\n\nfunc main() {\n\terr := Write(\"fastly.toml\")\n\tif err != nil {\n\t\tfmt.Printf(\"%+v\\n\", err)\n\t}\n}\n\ntype Manifest struct {\n\tFoo string\n\tBar int\n}\n\nfunc Write(filename string) error {\n\tm := Manifest{\"foo\", 123}\n\n\tfp, err := os.Create(filename)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tif err := toml.NewEncoder(fp).Encode(\u0026m); err != nil {\n\t\treturn err\n\t}\n\n\tcontents := make([]string, 0)\n\n\tif _, err := fp.Seek(0, 0); err == nil {\n\t\tscanner := bufio.NewScanner(fp)\n\t\tfor scanner.Scan() {\n\t\t\tcontents = append(contents, scanner.Text())\n\t\t}\n\n\t\tif _, err := fp.Seek(0, 0); err == nil {\n\t\t\twriter := bufio.NewWriter(fp)\n\t\t\twriter.WriteString(\"# my link here\\n\")\n\n\t\t\tfor _, line := range contents {\n\t\t\t\t_, err := writer.WriteString(line + \"\\n\")\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn err\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif err := writer.Flush(); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\t}\n\n\tif err := fp.Sync(); err != nil {\n\t\treturn err\n\t}\n\n\tif err := fp.Close(); err != nil {\n\t\treturn err\n\t}\n\n\treturn nil\n}\n","tags":"#go #serialization"},{"id":"248aa0436d281e3cd44debaf7d83441d","title":"Go: compile Rust program via shell to Cargo ","content":"package main\n\nimport (\n\t\"bytes\"\n\t\"fmt\"\n\t\"io\"\n\t\"os\"\n\t\"os/exec\"\n\t\"strings\"\n)\n\nfunc main() {\n    // just testing to see if there are problems with spaces.\n\tos.Setenv(\"TEST_WITH_SPACE\", os.Getenv(\"DOES_NOT_EXIST\")+` -C debuginfo=2`)\n\n\targs := []string{\n\t\t\"+1.49.0\",\n\t\t\"build\",\n\t\t\"--release\",\n\t\t\"--target\",\n\t\t\"wasm32-wasi\",\n\t\t\"--color\",\n\t\t\"always\",\n\t\t\"--verbose\",\n\t}\n\n\t// Execute the `cargo build` commands with the Wasm WASI target, release\n\t// flags and env vars.\n\tcmd := NewStreamingExec(\"cargo\", args, os.Environ(), true, os.Stdout)\n\tif err := cmd.Exec(); err != nil {\n\t\tfmt.Println(\"%s\", err)\n\t}\n}\n\n// StreamingExec models a generic command execution that consumers can use to\n// execute commands and stream their output to an io.Writer. For example\n// compute commands can use this to standardize the flow control for each\n// compiler toolchain.\ntype StreamingExec struct {\n\tcommand string\n\targs    []string\n\tenv     []string\n\tverbose bool\n\toutput  io.Writer\n}\n\n// NewStreamingExec constructs a new StreamingExec instance.\nfunc NewStreamingExec(cmd string, args, env []string, verbose bool, out io.Writer) *StreamingExec {\n\treturn \u0026StreamingExec{\n\t\tcmd,\n\t\targs,\n\t\tenv,\n\t\tverbose,\n\t\tout,\n\t}\n}\n\n// Exec executes the compiler command and pipes the child process stdout and\n// stderr output to the supplied io.Writer, it waits for the command to exit\n// cleanly or returns an error.\nfunc (s StreamingExec) Exec() error {\n\tcmd := exec.Command(s.command, s.args...)\n\tcmd.Env = append(os.Environ(), s.env...)\n\n\t// Pipe the child process stdout and stderr to our own output writer.\n\tvar stderrBuf bytes.Buffer\n\tcmd.Stdout = s.output\n\tcmd.Stderr = io.MultiWriter(s.output, \u0026stderrBuf)\n\n\tif err := cmd.Run(); err != nil {\n\t\tif !s.verbose \u0026\u0026 stderrBuf.Len() \u003e 0 {\n\t\t\treturn fmt.Errorf(\"error during execution process:\\n%s\", strings.TrimSpace(stderrBuf.String()))\n\t\t}\n\t\treturn fmt.Errorf(\"error during execution process\")\n\t}\n\n\treturn nil\n}\n","tags":"#go #rust #compiler"},{"id":"f28a60096c46b59226e60bc590126516","title":"Fastly: Terraform Workspace example ","content":"The Terraform Workspace feature only provides state isolation and is designed for testing out changes (synonymous with `git branch`).\n\nHashiCorp provides [guidelines](https://www.terraform.io/docs/language/state/workspaces.html#when-to-use-multiple-workspaces) on when to use the Terraform Workspace.\n\n```bash\nterraform init\nterraform workspace new stage\nterraform workspace new prod\nterraform workspace list\nterraform workspace select stage\n```\n\n\u003e **NOTE**: you can't `terraform workspace delete default` so best to just ignore it, or treat it as your 'production' instead of creating a prod workspace.\nterraform {\n  required_providers {\n    fastly = {\n      source  = \"fastly/fastly\"\n      version = \"0.27.0\"\n    }\n  }\n}\n\nvariable \"backend\" {\n  type    = string\n  default = \"httpbin.org\"\n}\n\nresource \"fastly_service_v1\" \"service\" {\n  name = \"Example Service\"\n\n  domain {\n    name = \"www.example.com\"\n  }\n\n  backend {\n    address = \"${terraform.workspace}.${var.backend}\"\n    name    = \"${terraform.workspace == \"prod\" ? \"www\" : \"staging\"}-httpbin\"\n  }\n\n  force_destroy = true\n}\n","tags":"#fastly #terraform #hcl #workspace"},{"id":"864f134dfdcd8715b3a03addefdc3b13","title":"Fastly: Terraform Multiple Environments using Modules ","content":"resource \"fastly_service_v1\" \"service\" {\n  name = \"Example Service\"\n\n  domain {\n    name = \"${var.subdomain}.example.com\"\n  }\n\n  backend {\n    address = \"httpbin.org\"\n    name    = \"httpbin\"\n  }\n\n  vcl {\n    content = file(\"${path.module}/vcl/main.vcl\")\n    main    = true\n    name    = \"custom_vcl\"\n  }\n\n  force_destroy = true\n}\n\nvariable \"subdomain\" {\n  type    = string\n  default = \"stage\"\n}\nsubdomain = \"staging\"\nmodule \"www\" {\n  source    = \"../modules/service-vcl\"\n  subdomain = var.subdomain\n}\n\nmodule \"compute\" {\n  source    = \"../modules/service-compute\"\n  subdomain = var.subdomain\n}\nterraform {\n  required_providers {\n    fastly = {\n      source  = \"fastly/fastly\"\n      version = \"0.27.0\"\n    }\n  }\n}\nvariable \"subdomain\" {\n  type    = string\n  default = \"www\"\n}\n# Terraform Environments using Modules\n\n```\n.\n├── modules\n│   ├── service-compute\n│   │   ├── main.tf\n│   │   ├── package-built-locally-via-cli.tar.gz\n│   │   ├── provider.tf\n│   │   └── variables.tf\n│   └── service-vcl\n│       ├── main.tf\n│       ├── provider.tf\n│       ├── variables.tf\n│       └── vcl\n│           └── main.vcl\n├── prod\n│   ├── inputs.tfvars\n│   ├── main.tf\n│   ├── provider.tf\n│   └── variables.tf\n└── stage\n    ├── inputs.tfvars\n    ├── main.tf\n    ├── provider.tf\n    └── variables.tf\n```\n\nWithin each directory (`prod` and `stage`) run `terraform init`.\n\nThen inside each directory run `terraform plan -var-file=\"inputs.tfvars\"`.\n\n\u003e **NOTE**: I don't show the contents for every file as most are the same as others. For example, `provider.tf` is the same across all directories. The stage and prod directories are all the same with the exception of the `inputs.tfvars` (e.g. I use the default variable value in prod, where I provide my own value for the variable in stage) and the `variables.tf` (where I set different default values for each environment).\nresource \"fastly_service_compute\" \"service\" {\n  name = \"Compute Service\"\n\n  domain {\n    name = \"${var.subdomain}-compute.example.com\"\n  }\n\n  package {\n    filename         = \"${path.module}/package-built-locally-via-cli.tar.gz\"\n    source_code_hash = filesha512(\"${path.module}/package-built-locally-via-cli.tar.gz\")\n  }\n\n  backend {\n    address = \"httpbin.org\"\n    name    = \"httpbin\"\n  }\n\n  force_destroy = true\n}\nvariable \"subdomain\" {\n  type = string\n}\n","tags":"#terraform #environments #hcl #fastly"},{"id":"d9c2aae82f3442d35ebc16b7ac372ce6","title":"Vim: replace document quotations with monospace equivalent ","content":"%s/[‘’]/'/g\n%s/[“”]/\"/g\n","tags":"#vim #quotes #monospace #substitution"},{"id":"08fc2d98b3906fcd24ba4fd56473103d","title":"Rust: Print the type of a reference ","content":"use std::any::type_name;\n\nfn type_of\u003cT\u003e(_: \u0026T) {\n    println!(\"{}\", type_name::\u003cT\u003e())\n}\n\nfn main() {\n    type_of(\u0026\"foo\");               // \u0026str\n    type_of(\u0026String::from(\"foo\")); // alloc::string::String\n    type_of(\u0026123);                 // i32\n    type_of(\u00261.23);                // f64\n}\n","tags":"#rust #type #reflection"},{"id":"ac32f8f42244171183c5142a624c741d","title":"Go: syntax differences with Rust ","content":"The following examples are written from the perspective of an engineer who writes code using the Go programming language, and so you'll find that I've written notes about how Rust is different and I don't really cover the why or how of the example Go code. Additionally, the Go examples are far from exhaustive because I'm using this as a 'scratch pad' for my Rust learnings.\n\n- [Error Handling](#error-handling)\n- [Structs](#structs)\n- [Interface](#interface)\n\n## Error Handling\n\n### Go example\n\n```go\npackage main\n\nimport (\n\t\"fmt\"\n\t\"log\"\n\t\"os\"\n)\n\nfunc main() {\n\tf, err := os.Open(\"hello.txt\")\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\tfmt.Println(f)\n}\n```\n\n### Rust example\n\n```rust\nuse std::fs::File;\n\nfn main() {\n    let f = File::open(\"hello.txt\");\n\n    let f = match f {\n        Ok(file) =\u003e file,\n        Err(error) =\u003e panic!(\"Problem opening the file: {:?}\", error),\n    };\n}\n```\n\n### Notes\n\nRust uses a [`std::result::Result`](https://doc.rust-lang.org/std/result/enum.Result.html) Enumerator to encapsulate the returned value, which could be either a `Ok(T)` or `Err(E)` variant.\n\n\u003e **NOTE**: The more correct way to describe an enum is [enumerated type](https://en.wikipedia.org/wiki/Enumerated_type).\n\nEnumerators are a powerful feature in Rust, unlike in Go where you don't have enumerators but `iota` (that and half-baked custom implementations using custom types with constants).\n\nThe use of constants to vaguely mimic a form of enum would be:\n\n```go\ntype TokenScope string\n\nconst (\n\tGlobalScope TokenScope = \"global\"\n\tPurgeSelectScope TokenScope = \"purge_select\"\n\tPurgeAllScope TokenScope = \"purge_all\"\n)\n```\n\nWhile using `iota` is better, it doesn't have the same flexibility and expressiveness as rust:\n\n```go\npackage main\n\nimport (\n\t\"fmt\"\n)\n\n// InputType is a base for the different input variants.\ntype InputType int64\n\n// Variants of an InputType\n//\n// NOTE: These can be passed anywhere the InputType is specified.\nconst (\n\tInputTypeUndefined InputType = iota // 0\n\tInputTypeEmail                      // 1\n\tInputTypeNumber                     // 2\n\tInputTypeURL                        // 3\n)\n\n// Notice the return type acts a bit like an interface\n// in that we're able to return any of the defined input types\n// as they all are a subset of InputType.\nfunc (it InputType) Convert(s string) InputType {\n\tswitch s {\n\tcase \"email\":\n\t\treturn InputTypeEmail\n\tcase \"number\":\n\t\treturn InputTypeNumber\n\tcase \"url\":\n\t\treturn InputTypeURL\n\t}\n\treturn InputTypeUndefined\n}\n\n// It represents a new instance of InputType\n//\n// NOTE: \n// You can't call a method on the type without first creating a new instance. \n// So to make things easier for a consumer I make it a package level public variable.\n// This means you'll likely need to think more about how you name this variable as you'll have to also remeber this is likely to be in a separate package.\nvar It = new(InputType)\n\nfunc main() {\n\tfmt.Println(It.Convert(\"email\") == InputTypeEmail)   // true\n\tfmt.Println(It.Convert(\"number\") == InputTypeNumber) // true\n\tfmt.Println(It.Convert(\"url\") == InputTypeURL)       // true\n\tfmt.Println(It.Convert(\"nope\") == InputTypeURL)      // false\n}\n```\n\nThere's many ways to get to the value from within the `Result` Enum (i.e. you'll want to get either the value inside of the `Ok` or the `Err` variants). \n\nThe most verbose variation, which is to use a `match` statement, is demonstrated in the above example where we take the value extracted from the `Result` Enum and overwrite the `f` variable to now contain the extracted value.\n\nOther ways to get at the value contained in a `Result` are:\n\n- `?`: append this [operator](https://doc.rust-lang.org/book/ch09-02-recoverable-errors-with-result.html#a-shortcut-for-propagating-errors-the--operator) and it'll return either the value inside of `Ok` or return the error inside `Err`.\n- `unwrap`: returns the `Ok` value otherwise the program will panic.\n- `expect`: same as `unwrap` except you can customise the panic message.\n\n\u003e NOTE: These methods are implemented on both [`std::result::Result`](https://doc.rust-lang.org/std/result/enum.Result.html) and [`std::option::Option`](https://doc.rust-lang.org/std/option/enum.Option.html).\n\nThe above are the most common ways to get at the value contained in a `Result` or `Option` enum, but there are also:\n\n- `unwrap_or`: returns the `Ok` or `Some` value (in the case of an `Option` enum variant), otherwise returns your given 'default' value.\n- `unwrap_or_else`: returns the `Ok` or `Some` value (in the case of an `Option` enum variant), otherwise computes it from a closure.\n\nOne last thing to mention about error handling in Rust is the following `if let` pattern, which is used when using `match` is overly explicit/verbose due to its exhaustive nature:\n\n```rust\nlet number = Some(7); // pretend this was generated by a function returning a std::option::Option\n\nif let Some(i) = number {\n    println!(\"Matched {:?}!\", i);\n}\n```\n\n\u003e **Refer**: https://doc.rust-lang.org/rust-by-example/flow_control/if_let.html\n\n## Structs\n\n- Define a struct.\n- Define `hello` function with struct as the receiver.\n- Define a constructor function.\n\n### Go example\n\n```go\npackage main\n\nimport \"fmt\"\n\ntype Foo struct {\n\tbar string\n\tbaz int\n}\n\nfunc (f Foo) hello() {\n\tfmt.Printf(\"%s, %d\\n\", f.bar, f.baz)\n}\n\nfunc NewFoo() *Foo {\n\treturn \u0026Foo{\n\t\tbar: \"bar\",\n\t\tbaz: 123,\n\t}\n}\n\nfunc main() {\n\tf := Foo{\n\t\tbar: \"bar\",\n\t\tbaz: 123,\n\t}\n\tfmt.Printf(\"f: %+v\\n\\n\", f)\n\n\tf.hello()\n\n\tfp := NewFoo()\n\tfmt.Printf(\"\\nfp: %+v\\n\\n\", fp)\n\t\n\tfp.hello()\n}\n```\n\n### Rust example\n\n```rust\n#[derive(Debug)]\nstruct Foo\u003c'a\u003e {\n\tbar: \u0026'a str,\n    baz: u8,\n}\n\nimpl\u003c'a\u003e Foo\u003c'a\u003e {\n    fn hello(\u0026self) {\n        println!(\"{}, {}\", self.bar, self.baz);\n    }\n    \n    fn new(bar: \u0026str, baz: u8) -\u003e Foo {\n        Foo {\n            bar,\n            baz,\n        }\n    }\n}\n\nfn main() {\n\tlet f = Foo {\n  \t\tbar: \"bar\",\n        baz: 123,\n  \t};\n  \t\n  \tprintln!(\"{:#?}\", f);\n  \t\n  \tf.hello();\n  \t\n  \tlet foo = Foo::new(\"new bar\", 255);\n  \t\n  \tfoo.hello();\n}\n```\n\n### Rust requirements\n\nTo print the struct we need to implement `Debug` (so we 'derive' it using existing implementation rather than implement it ourselves). \n\nWe have to add a lifetime `'a` to the struct so that Rust will compile the code (for safety reasons Rust needs to ensure the referenced string assigned to the field lives long enough for the code to be considered safe).\n\nThe compiler also complains when defining a method on Foo using `impl`: \"implicit elided lifetime not allowed here\". The resolution is: \"indicate the anonymous lifetime\", which is done using `\u003c'_\u003e`:\n\n```rust\nimpl Foo\u003c'_\u003e\n```\n\nIf we read the [Rust documentation on elision rules](https://blog.rust-lang.org/2018/12/06/Rust-1.31-and-rust-2018.html#more-lifetime-elision-rules) we'll see that the 'anonymous lifetime' is just a new rule that enables syntax sugar that makes the more explicit lifetime code (i.e. `impl\u003c'a\u003e Foo\u003c'a\u003e`) simpler.\n\nFor the sake of the example, I used the more explicit version because it makes understanding the Rust code and the relationship of the `'a` lifetime clearer.\n\n### Notes\n\nThe `impl` block actually creates a 'namespace', meaning we have to call `new` using the namespace: `Foo::new()`. \n\nWhen a function's arguments match the field names of a struct, you can omit the typical `key: value` format. So instead of `Foo{bar: bar}` we just write `Foo{bar}`.\n\nYou can't omit a struct field in Rust. Unlike in Go which will automatically assign a default value (the type's zero value). To do this in Rust you need to derive `Default` on the struct and splat the remaining fields using `Default::default()`...\n\n```rust\n#[derive(Debug, Default)]\nstruct Foo {\n    bar: u8,\n    baz: bool,\n}\n\nfn main() {\n    let f = Foo {\n        bar: 123,\n        ..Default::default()\n    };\n    println!(\"{:?}\", f);\n    println!(\"{} {}\", f.bar, f.baz); // There would be a WARNING if we didn't read the fields.\n}\n```\n\nAlternatively assign the field type to an `Option` type, that way it will default to `None`.\n\n## Interface\n\nIn traditional programming languages an interface defines a contract. It states that a certain object follows the behaviours expected by implementing the assigned interface.\n\n### Go example\n\n```go\npackage main\n\nimport \"fmt\"\n\ntype foo interface {\n\tbar()\n}\n\nfunc callBar(value foo) {\n\tvalue.bar()\n}\n\ntype x int\ntype y string\n\nfunc (t x) bar() {\n\tfmt.Printf(\"Int: %d\\n\", t)\n}\nfunc (t y) bar() {\n\tfmt.Printf(\"String: %s\\n\", t)\n}\n\nfunc main() {\n\tcallBar(x(1))\n\tcallBar(y(\"foo\"))\n}\n```\n\n### Rust example\n\n```rust\ntrait Foo { \n    fn bar(\u0026self); \n}\n\nimpl Foo for i32 { \n    fn bar(\u0026self) {}\n}\n\nimpl Foo for String { \n    fn bar(\u0026self) {}\n}\n\n// impl Trait (i.e. Generics) short-hand:\n// fn call_bar(value: impl T)\nfn call_bar\u003cT: Foo\u003e(value: T) {\n    value.bar()\n}\n\nfn main() {\n    call_bar(1i32);\n    call_bar(\"foo\".to_string());\n}\n```\n\n### Notes\n\nIn Go the concept of an interface is more flexible than the traditional definition because your objects can implement an interface without _explicitly_ being assigned it. This means a single object could in theory implement lots of different interfaces (hence why it's more flexible than traditional programming languages, because in those languages you'd need to explicitly assign _multiple_ interfaces to an object).\n\nFrom an implementation stand point, Go uses 'dynamic dispatch' when dealing with interfaces, while methods on a struct or any other concrete type are always resolved statically ([reference](https://golang.org/doc/faq#How_do_I_get_dynamic_dispatch_of_methods)). This means it is faster to compile a Go program but isn't as fast to run because when dealing with interface method resolution the value of the 'receiver' that a method is implemented on can only be determined at runtime (this can also, in extreme cases, be less memory safe).\n\nIn Rust the concept of an interface is referred to as a 'trait'. Traits are just as flexible as Go, and more so in the sense that they provide both 'dynamic dispatch' _and_ 'static dispatch' (the latter meaning the code doesn't have a single function, like with dynamic dispatch, but has multiple functions compiled that reflect each receiver -- this is possible due to the use of generics in the rust language).\n\n\u003e **NOTE**: Refer to [this article](https://www.ncameron.org/blog/dyn-trait-and-impl-trait-in-rust/#preliminary-traits-are-not-types) for the difference between a 'type' and a 'trait' in Rust.\n\nIn the above Rust example the two `call_bar` calls will actually compile to two distinct functions, like:\n\n```rust\nfn call_bar_int(value: int) { value.bar() }\nfn call_bar_string(value: String) { value.bar() }\n```\n\nThis is because it uses trait bounds (i.e. `\u003cT: Foo\u003e`). If the example used a 'trait object' (see [docs on trait objects](https://doc.rust-lang.org/book/ch17-02-trait-objects.html#defining-a-trait-for-common-behavior)), then it would cause 'dynamic dispatch' to be utilised. Dynamic dispatch means the two `call_bar` calls will always call the single `call_bar` function, with the address of `bar` loaded from the interface's [vtable](http://en.wikipedia.org/wiki/Virtual_method_table).\n\n\u003e **Refer**: riptutorial.com for more details on [static vs dynamic dispatch in Rust](https://riptutorial.com/rust/example/4656/static-and-dynamic-dispatch) and also this Rust by Example page on [dyn Trait](https://doc.rust-lang.org/rust-by-example/trait/dyn.html).\n\n### Marker Traits\n\nImagine we have a trait for an `Animal` that defines a `make_noise` method. We want to call function and pass any object that defines `make_noise` but we only want to do this for 'pets' not all 'animals'. \n\nSo how can we make it so that we only accept pets? This is where marker traits are useful:\n\n```rust\npub trait Pet {}\n\nimpl Pet for Dog {}\nimpl Pet for Cat {}\n```\n\nOkay so far so good so now we know that these are pets not just animals. We call these marker traits because they have no functions for you to implement, but they allow you to “mark” the type with the trait. How do we tell our function to utilize this functionality then? \n\n```rust\nfn record_pet_noise\u003cP: Animal + Pet\u003e(pet: \u0026P) -\u003e Result\u003cSound, Mp4EncodeError\u003e {\n  let noise = pet.make_noise();\n  mp4_encode(noise)\n}\n```\n\nWe added another trait boundary to `P` which says “We accept a type only if it implements the traits Animal and Pet.” Pet is a marker trait. It doesn’t do anything, but it restricts what types are acceptable.\n\n### Trait Bounds\n\nWe can compose behaviours using a 'trait bound', which determines what something should be able to do...\n\n```rust\ntrait Bar: PartialEq + Debug {\n\tfn something_specific_for_bar(\u0026self);\n}\n```\n\nIn the above example, the `Bar` trait requires the implementator to also implement the `PartialEq` and `Debug` traits.\n\n\u003e **NOTE**: Go does something similar with embedding interfaces within interfaces.\n\nWe've already seen trait bounds in the earlier example, but it can take multiple forms...\n\n```rust\nfn call_bar\u003cT: Foo\u003e(value: T) {\n    value.bar()\n}\n\nfn call_bar\u003cT\u003e(value: T) \nwhere \n    T: Foo,\n{\n    value.bar()\n}\n\nfn call_bar(value: impl Foo) {\n    value.bar()\n}\n```\n\nThe last example is preferred, but often the trait bounds can be complex enough that the second variation with a `where` clause is better. \n\nThe first example is the most traditional relative to other languages.\n","tags":"#go #rust"},{"id":"b6ab05389128723d004c339b2769a485","title":"Shell: Repeat a single character N times ","content":"# repeat the character x twenty times\nprintf 'x%.0s' {1..20}\n","tags":"#bash #shell #repeat"},{"id":"24767b93df2f368c333ca0ba54ce0e13","title":"Terraform: Fastly C@E Service ","content":"This is a dirty hack to get a locally changed file to be depended on by an external resource provided by the Fastly Terraform provider.\n\ni.e. get Terraform to actual compile the wasm binary that would otherwise be manually produced using `fastly compute build`.\n\n\u003e **NOTE:** The example is for an older version of the Fastly Terraform provider, a more recent version (e.g. 5.4.0 at the time of writing) uses a different setup (shown below) so you'll need to tweak the older examples.\n\n```hcl\nterraform {\n  required_providers {\n    fastly = {\n      source  = \"fastly/fastly\"\n      version = \"5.4.0\"\n    }\n  }\n}\n\ndata \"fastly_package_hash\" \"example\" {\n  filename = \"./pkg/testing-fastly-tf-cli-deploys.tar.gz\"\n}\n\nresource \"fastly_service_compute\" \"testing-fastly-tf-cli-deploys\" {\n  name = \"testing-fastly-tf-cli-deploys\"\n\n  domain {\n    name = \"testing-fastly-tf-cli-deploys.edgecompute.app\"\n  }\n\n  package {\n    filename         = \"./pkg/testing-fastly-tf-cli-deploys.tar.gz\"\n    source_code_hash = data.fastly_package_hash.example.hash\n  }\n\n  force_destroy = true\n}\n```\n# https://www.terraform.io/docs/language/settings/index.html\nterraform {\n  # https://www.terraform.io/docs/language/providers/requirements.html\n  required_providers {\n    # https://registry.terraform.io/providers/fastly/fastly\n    fastly = {\n      source  = \"fastly/fastly\"\n      version = \"0.27.0\"\n    }\n    # https://registry.terraform.io/providers/hashicorp/null\n    null = {\n      source = \"hashicorp/null\"\n      version = \"3.1.0\"\n    }\n    # https://registry.terraform.io/providers/hashicorp/local\n    local = {\n      source = \"hashicorp/local\"\n      version = \"2.1.0\"\n    }\n  }\n}\n\n# https://registry.terraform.io/providers/fastly/fastly/latest/docs/resources/service_compute\nresource \"fastly_service_compute\" \"test_service\" {\n  name = \"compute_dictionary\"\n\n  domain {\n    name    = \"integralist-computehack.edgecompute.app\"\n    comment = \"test-domain\"\n  }\n\n  package {\n    filename         = data.local_file.package_name.filename\n    source_code_hash = sha512(data.local_file.package_name.content)\n    \n    # if I was just working with a standard pre-built package (i.e. a package I manually compiled) I'd use...\n    #\n    # filename         = \"package-built-locally-via-cli.tar.gz\"\n    # source_code_hash = filesha512(\"package-built-locally-via-cli.tar.gz\")\n  }\n\n  backend {\n    address = \"127.0.0.1\"\n    name    = \"originless\"\n    port    = 80\n  }\n\n  force_destroy = true\n}\n\n\n# https://registry.terraform.io/providers/hashicorp/null/latest/docs/resources/resource\nresource \"null_resource\" \"build_package\" {\n  triggers = {\n    package_name = \"package.tar.gz\"\n  }\n  \n  # https://www.terraform.io/docs/language/resources/provisioners/local-exec.html\n  provisioner \"local-exec\" {\n    command = \"fastly compute build\" \n  }\n}\n\n# https://registry.terraform.io/providers/hashicorp/local/latest/docs/data-sources/file\ndata \"local_file\" \"package_name\" {\n  filename = null_resource.build_package.triggers.package_name\n}\n","tags":"#terraform #fastly #compute #serverless #edge"},{"id":"dee6daacb1972b97d56aa170e518c160","title":"Terraform: Modules for structuring your resources ","content":"resource \"fastly_service_compute\" \"service\" {\n  name = \"Compute Service\"\n\n  domain {\n    name = \"compute.example.com\"\n  }\n\n  package {\n    filename         = \"${path.module}/package-built-locally-via-cli.tar.gz\"\n    source_code_hash = filesha512(\"${path.module}/package-built-locally-via-cli.tar.gz\")\n  }\n\n  backend {\n    address = \"httpbin.org\"\n    name    = \"httpbin\"\n  }\n\n  force_destroy = true\n}\nmodule \"www\" {\n  source = \"./modules/www.example.com\"\n}\n\nmodule \"compute\" {\n  source = \"./modules/compute.example.com\"\n}\nterraform {\n  required_providers {\n    fastly = {\n      source  = \"fastly/fastly\"\n      version = \"0.27.0\"\n    }\n  }\n}\nresource \"fastly_service_v1\" \"service\" {\n  name = \"Example Service\"\n\n  domain {\n    name = \"www.example.com\"\n  }\n\n  backend {\n    address = \"httpbin.org\"\n    name    = \"httpbin\"\n  }\n\n  vcl {\n    content = file(\"${path.module}/vcl/main.vcl\")\n    main    = true\n    name    = \"custom_vcl\"\n  }\n\n  force_destroy = true\n}\n\n```\n.\n├── main.tf\n├── modules\n│   ├── compute.example.com\n│   │   ├── main.tf\n│   │   ├── package-built-locally-via-cli.tar.gz\n│   │   └── provider.tf\n│   └── www.example.com\n│       ├── main.tf\n│       ├── provider.tf\n│       └── vcl\n│           └── main.vcl\n└── provider.tf\n```\n\nThe `provider.tf` is the same file across the entire project, but we have to duplicate it as each module needs its own provider dependency graph (otherwise `terraform init` will fail).\n\nIMPORTANT: if you use a 'known' provider (e.g. a hashicorp provider, like `hashicorp/aws`), then child modules don't need to define those dependencies in a `required_providers` block. But as `fastly/fastly` isn't a hashicorp provider (not any more it's not; it _used_ to be) it means we need a `provider.tf` in every child module. See https://www.terraform.io/docs/language/modules/develop/providers.html#implicit-provider-inheritance for details.\n\nThe `package-built-locally-via-cli.tar.gz` was something I generated using the [Fastly CLI](https://github.com/fastly/cli) with `fastly compute build`.\n\n\u003e **NOTE**: the use of `path.module` is documented here https://www.terraform.io/docs/language/expressions/references.html#filesystem-and-workspace-info\n\nIf using more providers and with more complex structuring (e.g. you reuse your modules), then it’s strongly recommended you implement a \"[module composition](https://www.terraform.io/docs/language/modules/develop/composition.html)\" approach to using Terraform modules, as this allows for greater flexibility and code reuse.\n\nHashiCorp also provides their own [guidelines](https://www.terraform.io/docs/language/modules/develop/index.html#when-to-write-a-module) on when to write a module.\n","tags":"#terraform #modules #fastly"},{"id":"c29ff647e5fb2f5c5001aa50a9288d8f","title":"Go: remove line from file ","content":"We had a bug where a line `[manifest_version]` was being added by accident.\nauthors = [\"integralist@fastly.com\"]\ndescription = \"testing\"\nlanguage = \"rust\"\n[manifest_version]\nname = \"testing\"\nservice_id = \"123\"\npackage main\n\nimport (\n\t\"bufio\"\n\t\"bytes\"\n\t\"log\"\n\t\"os\"\n)\n\nfunc main() {\n\tfpath := \"fastly.toml\"\n\n\tf, err := os.Open(fpath)\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\tdefer f.Close()\n\n\tvar bs []byte\n\tbuf := bytes.NewBuffer(bs)\n\n\tscanner := bufio.NewScanner(f)\n\tfor scanner.Scan() {\n\t\tif scanner.Text() != \"[manifest_version]\" {\n\t\t\t_, err := buf.Write(scanner.Bytes())\n\t\t\tif err != nil {\n\t\t\t\tlog.Fatal(err)\n\t\t\t}\n\t\t\t_, err = buf.WriteString(\"\\n\")\n\t\t\tif err != nil {\n\t\t\t\tlog.Fatal(err)\n\t\t\t}\n\t\t}\n\t}\n\tif err := scanner.Err(); err != nil {\n\t\tlog.Fatal(err)\n\t}\n\n\terr = os.WriteFile(fpath, buf.Bytes(), 0666)\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n}\n","tags":"#go"},{"id":"3427d0defce6e1ed8f09aaa2f2ab7f6a","title":"Memory: The Stack and the Heap ","content":"## The Stack and the Heap\n\n\u003e Copied verbatim from https://doc.rust-lang.org/stable/book/ch04-01-what-is-ownership.html#the-stack-and-the-heap\n\nIn many programming languages, you don’t have to think about the stack and the heap very often. But in a systems programming language like Rust, whether a value is on the stack or the heap has more of an effect on how the language behaves and why you have to make certain decisions. Parts of ownership will be described in relation to the stack and the heap later in this chapter, so here is a brief explanation in preparation.\n\nBoth the stack and the heap are parts of memory that are available to your code to use at runtime, but they are structured in different ways. The stack stores values in the order it gets them and removes the values in the opposite order. This is referred to as last in, first out. Think of a stack of plates: when you add more plates, you put them on top of the pile, and when you need a plate, you take one off the top. Adding or removing plates from the middle or bottom wouldn’t work as well! Adding data is called pushing onto the stack, and removing data is called popping off the stack.\n\nAll data stored on the stack must have a known, fixed size. Data with an unknown size at compile time or a size that might change must be stored on the heap instead. The heap is less organized: when you put data on the heap, you request a certain amount of space. The memory allocator finds an empty spot in the heap that is big enough, marks it as being in use, and returns a pointer, which is the address of that location. This process is called allocating on the heap and is sometimes abbreviated as just allocating. Pushing values onto the stack is not considered allocating. Because the pointer is a known, fixed size, you can store the pointer on the stack, but when you want the actual data, you must follow the pointer.\n\nThink of being seated at a restaurant. When you enter, you state the number of people in your group, and the staff finds an empty table that fits everyone and leads you there. If someone in your group comes late, they can ask where you’ve been seated to find you.\n\nPushing to the stack is faster than allocating on the heap because the allocator never has to search for a place to store new data; that location is always at the top of the stack. Comparatively, allocating space on the heap requires more work, because the allocator must first find a big enough space to hold the data and then perform bookkeeping to prepare for the next allocation.\n\nAccessing data in the heap is slower than accessing data on the stack because you have to follow a pointer to get there. Contemporary processors are faster if they jump around less in memory. Continuing the analogy, consider a server at a restaurant taking orders from many tables. It’s most efficient to get all the orders at one table before moving on to the next table. Taking an order from table A, then an order from table B, then one from A again, and then one from B again would be a much slower process. By the same token, a processor can do its job better if it works on data that’s close to other data (as it is on the stack) rather than farther away (as it can be on the heap). Allocating a large amount of space on the heap can also take time.\n\nWhen your code calls a function, the values passed into the function (including, potentially, pointers to data on the heap) and the function’s local variables get pushed onto the stack. When the function is over, those values get popped off the stack.\n","tags":"#stack #heap #memory"},{"id":"d47c2e8c6064ec065108ad59df6e1fb9","title":"Go: custom Unmarshal using json.RawMessage ","content":"// https://play.golang.org/p/_lYDvs0Ukux\n//\n// Demonstrates how to handle a complex data structure that doesn't work well with golang.\n// We write a custom unmarshal that puts the data into a more appropriate data structure.\n\npackage main\n\nimport (\n\t\"encoding/json\"\n\t\"fmt\"\n\t\"log\"\n)\n\nfunc main() {\n\tvar d DomainValidationResult\n\terr := json.Unmarshal([]byte(data), \u0026d)\n\tlog.Printf(\"%+v (err %v)\", h, err)\n}\n\nconst data = `\n  [\n    {\n      \"comment\": \"\",\n      \"name\": \"www.example.com\",\n      \"service_id\": \"SU1Z0isxPaozGVKXdv0eY\",\n      \"version\": 1,\n      \"created_at\": \"2020-03-15T20:10:09.000Z\",\n      \"updated_at\": \"2020-03-15T20:10:09.000Z\",\n      \"deleted_at\": null\n    },\n    \"global.prod.fastly.net.\",\n    true\n  ]\n`\n\n// DomainValidationResult defines an idiomatic representation of the API\n// response.\ntype DomainValidationResult struct {\n\tMetadata DomainMetadata\n\tName     string\n\tValid    bool\n}\n\n// UnmarshalJSON works around the badly designed API response by coercing the\n// raw data into a more appropriate data structure.\nfunc (d *DomainValidationResult) UnmarshalJSON(data []byte) error {\n\tvar tuple []json.RawMessage\n\tif err := json.Unmarshal(data, \u0026tuple); err != nil {\n\t\treturn fmt.Errorf(\"initial: %w\", err)\n\t}\n\n\tif want, have := 3, len(tuple); want != have {\n\t\treturn fmt.Errorf(\"unexpected array length: want %d, have %d\", want, have)\n\t}\n\n\tif err := json.Unmarshal(tuple[0], \u0026d.Metadata); err != nil {\n\t\treturn fmt.Errorf(\"metadata: %w\", err)\n\t}\n\n\tif err := json.Unmarshal(tuple[1], \u0026d.Name); err != nil {\n\t\treturn fmt.Errorf(\"name: %w\", err)\n\t}\n\n\tif err := json.Unmarshal(tuple[2], \u0026d.Valid); err != nil {\n\t\treturn fmt.Errorf(\"valid: %w\", err)\n\t}\n\n\treturn nil\n}\n\n// DomainMetadata represents a domain name configured for a Fastly service.\ntype DomainMetadata struct {\n\tComment   string     `json:\"comment\"`\n\tName      string     `json:\"name\"`\n\tServiceID string     `json:\"service_id\"`\n\tVersion   int        `json:\"version\"`\n\tCreatedAt *time.Time `json:\"created_at\"`\n\tUpdatedAt *time.Time `json:\"updated_at\"`\n\tDeletedAt *time.Time `json:\"deleted_at\"`\n}\npackage main\n\nimport (\n\t\"encoding/json\"\n\t\"fmt\"\n)\n\nfunc main() {\n\tvar v Component\n\n\tif err := json.Unmarshal(data, \u0026v); err != nil {\n\t\tpanic(err)\n\t}\n\n\tfmt.Printf(\"%#v\\n\", v)\n}\n\nvar data = []byte(`{\"type\": \"foo\", \"config\": {\"name\": \"test\"}}`)\n// THE OTHER TYPE FOR COMPARISON \u003e\u003e var data = []byte(`{\"type\": \"bar\", \"config\": {\"value\": 123}}`)\n\ntype Component struct {\n\tType   string      `json:\"type\"`\n\tConfig interface{} `json:\"config\"`\n}\n\nfunc (c *Component) UnmarshalJSON(data []byte) error {\n\n\tvar v struct {\n\t\tType string          `json:\"type\"`\n\t\tData json.RawMessage `json:\"config\"`\n\t}\n\n\tif err := json.Unmarshal(data, \u0026v); err != nil {\n\t\treturn err\n\t}\n\n\tc.Type = v.Type\n\n\tswitch v.Type {\n\tcase \"foo\":\n\t\tvar f FooConfig\n\n\t\tif err := json.Unmarshal(v.Data, \u0026f); err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tc.Config = f\n\tcase \"bar\":\n\t\tvar b BarConfig\n\n\t\tif err := json.Unmarshal(v.Data, \u0026b); err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tc.Config = b\n\t}\n\n\treturn nil\n}\n\ntype FooConfig struct {\n\tName string `json:\"name\"`\n}\n\ntype BarConfig struct {\n\tValue int `json:\"value\"`\n}\n","tags":"#go #json #serialization"},{"id":"d927ec1a82d4e4594279dcedebff78d2","title":"Rust: Ownership, Borrowing, Lifetimes ","content":"## Ownership\n\n\u003e NOTE: all information learned from https://doc.rust-lang.org/stable/book/ch04-00-understanding-ownership.html\n\nUnderstanding ownership requires understanding 'stack' vs 'heap' memory.\n\n- Stack data is released once it goes out of scope (e.g. once a function ends the arguments passed are dropped).\n- Stack is quick because the values are literal and can be hardcoded into the compiled binary.\n- This means stack values are immutable.\n- Heap is for memory that grows or has unknown size and needs to be explicitly dropped.\n- Heap is slower as it is allocated at _runtime_ and you have to follow a 'pointer' to find the data in heap memory.\n- Rust primitive/scalar types (int, bool, float, char, string literal etc) are stored in stack memory.\n- Most other complex types (String, Box etc.) are stored into heap memory.\n\n### Rules\n\n- Each value in Rust has a variable that’s called its _owner_.\n- There can only be one owner at a time.\n- When the owner goes out of scope, the value will be dropped.\n  - Primitive types are popped from the stack memory automatically when out of scope.\n  - Complex types must implement a `drop` function which Rust will call when out of scope (to explicitly deallocate heap memory).\n\n### Gotchas\n\n- Primitive types are 'copied' (`a = 1; b = a`) because they exist in stack memory and are known size (i.e. cheap to copy).\n  - Primitive types have a `Copy` trait that enable this.\n- Complex types 'move' ownership (`a = String::from(\"hello\"); b = a`).\n  - Complex types _do not_ have a `Copy` trait (which is a common error).\n- One an owner changes, the previous owner cannot be reused (e.g. you can't reference the previous owner variable in a print statement after ownership has changed).\n- To allow an owner to stay an owner, you'd need to 'clone' the complex type (e.g `a = String::from(\"hello\"); b = a.clone()`) which will actually duplicate the heap memory (so it's not cheap!).\n- Passing a variable (i.e. owner) to a function will move or copy, just as assignment does.\n- Returning values can also transfer ownership.\n  - Returning a complex type will move ownership to the caller (and the variable the result is assigned to becomes the new owner).\n  - In this scenario `drop` is not called, even if the owner was created within the function, as would normally be the case if a variable went out of scope at the end of the function.\n  \n## Borrowing\n\n\u003e NOTE: all information learned from https://doc.rust-lang.org/stable/book/ch04-02-references-and-borrowing.html\n\nTaking ownership and then returning ownership with every function is a bit tedious. To prevent this you can pass a 'reference' to a complex type (e.g. function `foo(s: \u0026String)` and caller `foo(\u0026a)`).\n\nIn the above example the `s` variable will (depending on function implementation) go out of scope, and yet nothing will happen (i.e. it won't be dropped) because the function doesn't _own_ what `s` refers to.\n\nIn order to mutate something borrowed, the caller and the receiver need to define the type as a 'mutable' type:\n\n```rust\nfn main() {\n    let mut s = String::from(\"hello\");\n\n    change(\u0026mut s);\n}\n\nfn change(some_string: \u0026mut String) {\n    some_string.push_str(\", world\");\n}\n```\n\n### Gotchas\n\n- You can have only one mutable reference (i.e. this prevents data races).\n- You can have multiple mutable references only if the scope allows for it.\n  - e.g. `{let a = \u0026mut s;} let b = \u0026mut s;` (as `a` will go out of scope before `b` is reached).\n- Multiple immutable references is safe.\n- We cannot have a mutable reference _while_ we have an immutable one (as this otherwise could change the value of the immutable reference).\n- A reference's scope is from when it's defined to where it's last used.\n  - This means you _can_ define multiple immutable references and a mutable reference as long as the immutable references go out of scope before the mutable reference.\n- Returning a variable created within function (while it being returned as a reference) isn't allowed because the variable will be dropped once out of scope (this avoids a 'dangling pointer').\n  - You must instead return the variable itself rather than a reference, and this will cause the ownership to be moved instead.\n  \n## Lifetimes\n\n\u003e NOTE: all information learned from https://doc.rust-lang.org/stable/book/ch10-03-lifetime-syntax.html\n\nLifetimes ultimately are coupled to references, hence the compiler uses what's called a \"borrow checker\" to validate lifetimes (as a 'reference' is a term related to the concept of \"borrowing\").\n\nRust prevents variables from trying to hold references to data that has since gone out of scope (i.e. dangling pointer). \n\nThe 'lifetime' of a reference begins when the reference is created and ends when it's last used. \n\nIf a function returns a reference that changes depending on some logic (e.g. if X return A else return B, where A/B are two different references) then the borrow checker can't statically analyse if your code is safe as it doesn't know which reference will be returned at runtime.\n\nIn those cases we need to add lifetime annotations...\n\n```rust\nfn longest\u003c'a\u003e(x: \u0026'a str, y: \u0026'a str) -\u003e \u0026'a str {\n    if x.len() \u003e y.len() {\n        x\n    } else {\n        y\n    }\n}\n```\n\nThe `longest` function definition states all references in the signature must have the same lifetime `'a`.\n\nWe’re specifying that the borrow checker should reject any values that don't adhere to these constraints.\n\nThe lifetime named 'static' is a special lifetime. It signals that something has the lifetime of the entire program. \n\nString literals can be assigned the type `\u0026'static` lifetime annotation as a way to indicate the reference is always alive, i.e. they are baked into the data segment of the final binary. \n","tags":"#rust #rustlang #ownership #memory"},{"id":"9f4279bc4b98deebd4a1c27c022d56c1","title":"Terminal: Colour Support ","content":"#!/usr/bin/perl\n# Author: Todd Larason \u003cjtl@molehill.org\u003e\n# $XFree86: xc/programs/xterm/vttests/256colors2.pl,v 1.2 2002/03/26 01:46:43 dickey Exp $\n\n# use the resources for colors 0-15 - usually more-or-less a\n# reproduction of the standard ANSI colors, but possibly more\n# pleasing shades\n#\n# Run: perl ttycolours.pl\n\n# colors 16-231 are a 6x6x6 color cube\nfor ($red = 0; $red \u003c 6; $red++) {\n    for ($green = 0; $green \u003c 6; $green++) {\n\tfor ($blue = 0; $blue \u003c 6; $blue++) {\n\t    printf(\"\\x1b]4;%d;rgb:%2.2x/%2.2x/%2.2x\\x1b\\\\\",\n\t\t   16 + ($red * 36) + ($green * 6) + $blue,\n\t\t   ($red ? ($red * 40 + 55) : 0),\n\t\t   ($green ? ($green * 40 + 55) : 0),\n\t\t   ($blue ? ($blue * 40 + 55) : 0));\n\t}\n    }\n}\n\n# colors 232-255 are a grayscale ramp, intentionally leaving out\n# black and white\nfor ($gray = 0; $gray \u003c 24; $gray++) {\n    $level = ($gray * 10) + 8;\n    printf(\"\\x1b]4;%d;rgb:%2.2x/%2.2x/%2.2x\\x1b\\\\\",\n\t   232 + $gray, $level, $level, $level);\n}\n\n\n# display the colors\n\n# first the system ones:\nprint \"System colors:\\n\";\nfor ($color = 0; $color \u003c 8; $color++) {\n    print \"\\x1b[48;5;${color}m  \";\n}\nprint \"\\x1b[0m\\n\";\nfor ($color = 8; $color \u003c 16; $color++) {\n    print \"\\x1b[48;5;${color}m  \";\n}\nprint \"\\x1b[0m\\n\\n\";\n\n# now the color cube\nprint \"Color cube, 6x6x6:\\n\";\nfor ($green = 0; $green \u003c 6; $green++) {\n    for ($red = 0; $red \u003c 6; $red++) {\n\tfor ($blue = 0; $blue \u003c 6; $blue++) {\n\t    $color = 16 + ($red * 36) + ($green * 6) + $blue;\n\t    print \"\\x1b[48;5;${color}m  \";\n\t}\n\tprint \"\\x1b[0m \";\n    }\n    print \"\\n\";\n}\n\n\n# now the grayscale ramp\nprint \"Grayscale ramp:\\n\";\nfor ($color = 232; $color \u003c 256; $color++) {\n    print \"\\x1b[48;5;${color}m  \";\n}\nprint \"\\x1b[0m\\n\";\n","tags":"#perl #terminal #colours"},{"id":"916a82907c7a14c64df41f32c5c45a2a","title":"Network: Quick Fastly Logging Endpoint in Terminal ","content":"Whenever I need logging and can't be bothered to spin up infrastructure, I like to set up a log endpoint on my machine using ngrok and nc:\n\nNgrok:\n\n```bash\nngrok tcp 514\n# point logging to 0.tcp.ngrok.io:SOMEPORT\n```\n\nNetcat:\n\n```bash\nnc -lkv 514 \n# logs straight to your terminal\n```\n","tags":"#fastly #logging #terminal #shell #ngrok #netcat"},{"id":"d2f688fbb20879daa130c0a9b9517a21","title":"Go: custom toml unmarshal wrapper for string to int ","content":"package main\n\nimport (\n\t\"fmt\"\n\t\"strconv\"\n\t\"strings\"\n\n\ttoml \"github.com/pelletier/go-toml\"\n)\n\ntype StringInt struct {\n\tint\n}\n\nfunc (si *StringInt) UnmarshalText(text []byte) error {\n\tvar err error\n\n\ts := string(text)\n\n\tif si.int, err = strconv.Atoi(s); err == nil {\n\t\treturn nil\n\t}\n\n\tif f, err := strconv.ParseFloat(s, 32); err == nil {\n\t\tintfl := int(f)\n\t\tif intfl == 0 {\n\t\t\tsi.int = 1\n\t\t} else {\n\t\t\tsi.int = intfl\n\t\t}\n\t\treturn nil\n\t}\n\n\tif strings.Contains(s, \".\") {\n\t\tsegs := strings.Split(s, \".\")\n\t\tif len(segs) == 3 {\n\t\t\t// yes this could be more robust but for now I'm trusting a string with a \".\" means semver :grimace:\n\t\t\tif segs[0] != \"0\" {\n\t\t\t\tif si.int, err = strconv.Atoi(segs[0]); err == nil {\n\t\t\t\t\treturn nil\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tsi.int = 1\n\t\t\t\treturn nil\n\t\t\t}\n\n\t\t}\n\t}\n\n\treturn fmt.Errorf(\"unsupported: %s\", text)\n}\n\ntype FileTest struct {\n\tVersion1 StringInt `toml:\"version1\"`\n\tVersion2 StringInt `toml:\"version2\"`\n\tVersion3 StringInt `toml:\"version3\"`\n\tVersion4 StringInt `toml:\"version4\"`\n\tVersion5 StringInt `toml:\"version5\"`\n\tVersion6 StringInt `toml:\"version6\"`\n\tVersion7 StringInt `toml:\"version7\"`\n}\n\nfunc main() {\n\tdata := []byte(`\n\tversion1 = \"1\"\n\tversion2 = 1\n\tversion3 = \"0.1.0\"\n\tversion4 = \"1.0.0\"\n\tversion5 = 0.1\n\tversion6 = \"0.2.0\"\n\tversion7 = \"2.0.0\"\n\t`)\n\n\tfile := FileTest{}\n\ttoml.Unmarshal(data, \u0026file)\n\tformat := \"version1 (\\\"1\\\"):\\n\\t%d\\nversion2 (1):\\n\\t%d\\nversion3 (\\\"0.1.0\\\"):\\n\\t%d\\nversion4 (\\\"1.0.0\\\"):\\n\\t%d\\nversion5 (0.1):\\n\\t%d\\nversion6 (\\\"0.2.0\\\"):\\n\\t%d\\nversion7 (\\\"2.0.0\\\"):\\n\\t%d\\n\"\n\tfmt.Printf(format, file.Version1.int, file.Version2.int, file.Version3.int, file.Version4.int, file.Version5.int, file.Version6.int, file.Version7.int)\n}\n\n","tags":"#go #serialization"},{"id":"b94c8945ac6f8c9a9ef888efed6c8cb4","title":"Terraform: Modules ","content":"To use modules they must abide by the following directory structure:\n\n```\n.\n├── modules\n│   └── your_module_name_here\n│       └── whatever_you_want_to_call_this.tf\n│       └── outputs.tf\n├── outputs.tf\n├── service.tf\n```\n\n\u003e NOTE: multiple `outputs.tf` files. We'll demonstrate below how to reference a module's output variable from within our 'root' module (i.e. `service.tf`) .\n\nYou would then consume the module from within your root module like so:\n\n```tf\nmodule \"foo\" {\n  source = \"./modules/your_module_name_here\"\n  some_input_variable = \"example\"\n}\n```\n\nThe module itself would look like so:\n\n```tf\n// providers must be set in every module (not just the root module)\nterraform {\n  required_providers {\n    fastly = {\n      source  = \"fastly/fastly\"\n      version = \"0.25.0\"\n    }\n  }\n}\n\nvariable \"some_input_variable\" {\n  type        = string\n  description = \"Some sort of value\"\n}\n\nresource \"fastly_service_v1\" \"test_service\" {\n  name = \"testing_tf_modules\"\n  domain {\n    name = \"tfmodules-${var.some_input_variable}.integralist-test.com\"\n  }\n  backend {\n    address = \"httpbin.org\"\n    name    = \"httpbin\"\n  }\n  force_destroy = true\n}\n```\n\nThe module's `outputs.tf` would look like:\n\n```tf\noutput \"active\" {\n  value = fastly_service_v1.test_service_foo.active_version\n}\n```\n\nWhile the root module's `outputs.tf` would look like:\n\n```tf\noutput \"active\" {\n  value = fastly_service_v1.test_service.active_version\n}\n\noutput \"active_foo\" {\n  value = module.foo.active\n}\n```\n\nNotice the syntax to reference the module's output variable from within the root module: `module.\u003cmodule_name\u003e.\u003cmodule_output_variable_name\u003e`.\n","tags":"#terraform #tf #modules"},{"id":"982fe71b4f8aedebed83bed8474f1876","title":"Terraform: Fastly Service] ","content":"resource \"fastly_service_v1\" \"test_service\" {\n  name = \"My Test Service\"\n\n  domain {\n    name = \"training.fastly.com\"\n  }\n\n  backend {\n    address = \"httpbin.org\"\n    name    = \"test-backend\"\n  }\n  \n  vcl {\n    content = file(\"vcl/main.vcl\")\n    main    = true\n    name    = \"custom_vcl\"\n  }\n\n  force_destroy = true\n}\noutput \"active\" {\n  value = fastly_service_v1.test_service.active_version\n}\nterraform {\n  required_providers {\n    fastly = {\n      source  = \"fastly/fastly\"\n      version = \"0.27.0\"\n    }\n  }\n}\n","tags":"#fastly #terraform"},{"id":"f2e55ede1b6dcb772cf572cba6f52745","title":"Vim: Display number of windows, buffers, tabs ","content":":echo winnr('$')\n:echo bufnr('$')\n:echo tabpagenr('$')\n","tags":"#vim #display #count #windows #buffers #tabs"},{"id":"b7e8b3529871b18c1adb69ae40ccb118","title":"Go: Debugging with Delve ","content":"- `git clone git@github.com:fastly/cli.git`\n- `cd cli`\n- `go install github.com/go-delve/delve/cmd/dlv@latest` (install the debugger)\n- `dlv debug ./cmd/fastly/main.go -- compute deploy` (start up the debugger)\n- `break ./pkg/commands/compute/deploy.go:89` (add break point within the 'deploy' code file)\n- `cond \u003cbreakpoint_name_or_id\u003e \u003cboolean expression\u003e` (e.g. `cond 1 commandName == \"sso\"`)\n- `continue` (this would be typed into the debugger prompt and would cause the code to run until the breakpoint)\n\nFrom there you can use `n` (next) to go from line-to-line or `s` (step-into) to jump into any function calls, along with `print` to see what the code is doing.\n\nTo exercise the test code:\n\n- `dlv test ./pkg/example/... -- -test.v -test.run TestExample/specific_test_case`\n- `break ./pkg/example/example_test.go:123`\n\n\u003e **NOTE**: If you see the error \"cannot use -c flag with multiple packages\" then `cd` into the package directory (e.g. `cd ./pkg/example \u0026\u0026 dlv test`).\n\n## Examples\n\nFastly Terraform Tests:\n\n```bash\ncd ./fastly\nTF_ACC=true dlv test -- -test.v -test.run TestAccFastlyServiceVCL_syslog_useTLS\nbreak block_fastly_service_logging_syslog_test.go:253 // break inside the test code\nbreak block_fastly_service_logging_syslog.go:342      // break inside the execute terraform code (trigged by the test)\n```\n\nFastly CLI Tests:\n\n```bash\ncd ./pkg/commands/compute\nTEST_COMPUTE_BUILD=1 dlv test -- -test.v -test.run TestBuildAssemblyScript/successful_build\nbreak build_test.go:328\n```\n# https://blog.gopheracademy.com/advent-2015/debugging-with-delve/\n#\n# connect - connect to headless debug server.\n# debug - run in same directory as `go build`, builds binary with extra debug info (e.g. dlv debug .)\n# run - similar to debug but no build step.\n# exec - run and attach to an existing binary.\n# test - useful for debugging a test suite (or you have no main function, e.g. it's a library package).\n# attach - attach to a running process.\n# trace - prints information whenever a tracepoint is hit, but not full debug session (only on tui version, not gui `dlv trace [regexp]`).\n\n# note: the install steps presume you're using go 1.16 or newer.\n\ngo install github.com/go-delve/delve/cmd/dlv@latest\n\n# dependencies required:\n#\n# xcode-select --install\n# sudo /usr/sbin/DevToolsSecurity -enable\n#\n# see https://github.com/go-delve/delve/tree/master/Documentation/installation for details\n\ngo install github.com/aarzilli/gdlv@latest\n\n# now replace: \n# go run \u003cprogram\u003e\n#\n# with:\n# gdlv run \u003cprogram\u003e\n#\n# Press \"Ctrl+\" to increase font-size.\n# Type \"help\" to see all available commands.\n\n# in order to use `dlv exec` you need to compile the binary like so:\n\ngo build -gcflags=\"all=-N -l\" -o \"debug\" ./cmd/yourapp\n\n# to set breakpoints:\n# https://github.com/go-delve/delve/tree/master/Documentation/cli#break\n#\n# \u003cfilename\u003e:\u003cline\u003e Specifies the line in filename. filename can be the partial path to a file or even just the base name as long as the expression remains unambiguous.\n#\n# Example (break on line 22 of the file):\nbreak main.go:22\n\n# \u003cfunction\u003e[:\u003cline\u003e] Specifies the line inside function. The full syntax for function is \u003cpackage\u003e.(*\u003creceiver type\u003e).\u003cfunction name\u003e however the only required element is the function name, everything else can be omitted as long as the expression remains unambiguous. For setting a breakpoint on an init function (ex: main.init), the \u003cfilename\u003e:\u003cline\u003e syntax should be used to break in the correct init function at the correct location.\n#\n# Example (break on the first line within the function `main`):\nbreak main.main:1\nbreak compute.(*ServeCommand).Exec:20 # NOTE: The line number is relative to the function!\n\n# debugging tests is a lot more confusing...\n# https://stackoverflow.com/questions/43380530/debugging-tests-with-delve\ndlv test ./pkg/example/...\ndlv test ./pkg/example/... -- -test.v -test.run TestExample/specific_test_case\nbreak someRandomNameToDescribeMyBreakpoint pkg/example/example_test.go:123\n","tags":"#go #debugging"},{"id":"5268eb6a9ea56aeb9bea1b362e1b7036","title":"Vim: pretty print json ","content":"\" Replace buffer with output\n:%!python -m json.tool\n\n\" Append output to buffer\n:read !cat % | python -m json.tool\n","tags":"#vim #json #pretty #print"},{"id":"28ea658092a78306071c46aebd56c607","title":"API: OpenAPI Generator ","content":"#!/usr/bin/env bash\n\nlanguages=(\"bash\" \"go\" \"javascript\" \"php\" \"python\" \"ruby\" \"rust\" \"typescript-fetch\")\n\nfor lang in \"${languages[@]}\";\ndo\n  for filename in .source-cache/.api-documentation/schemas/*;\n  do\n    name=$(basename $filename | cut -f 1 -d '.')\n    openapi-generator generate --skip-validate-spec -i \"${filename}\" -g \"${lang}\" -o \"/tmp/api-code-gen/${lang}/${name}/\"\n  done\ndone\n","tags":"#openapi #api #generator"},{"id":"fce85a72a28f5a5313002f8c972e883b","title":"Go: thread-safe bytes.Buffer ","content":"type Buffer struct {\n    b bytes.Buffer\n    m sync.Mutex\n}\nfunc (b *Buffer) Read(p []byte) (n int, err error) {\n    b.m.Lock()\n    defer b.m.Unlock()\n    return b.b.Read(p)\n}\nfunc (b *Buffer) Write(p []byte) (n int, err error) {\n    b.m.Lock()\n    defer b.m.Unlock()\n    return b.b.Write(p)\n}\nfunc (b *Buffer) String() string {\n    b.m.Lock()\n    defer b.m.Unlock()\n    return b.b.String()\n}\nfunc (b *Buffer) Bytes() []byte {\n    b.m.Lock()\n    defer b.m.Unlock()\n    return b.b.Bytes()\n}\nfunc (b *Buffer) Cap() int {\n    b.m.Lock()\n    defer b.m.Unlock()\n    return b.b.Cap()\n}\nfunc (b *Buffer) Grow(n int) {\n    b.m.Lock()\n    defer b.m.Unlock()\n    b.b.Grow(n)\n}\nfunc (b *Buffer) Len() int {\n    b.m.Lock()\n    defer b.m.Unlock()\n    return b.b.Len()\n}\nfunc (b *Buffer) Next(n int) []byte {\n    b.m.Lock()\n    defer b.m.Unlock()\n    return b.b.Next(n)\n}\nfunc (b *Buffer) ReadByte() (c byte, err error) {\n    b.m.Lock()\n    defer b.m.Unlock()\n    return b.b.ReadByte()\n}\nfunc (b *Buffer) ReadBytes(delim byte) (line []byte, err error) {\n    b.m.Lock()\n    defer b.m.Unlock()\n    return b.b.ReadBytes(delim)\n}\nfunc (b *Buffer) ReadFrom(r io.Reader) (n int64, err error) {\n    b.m.Lock()\n    defer b.m.Unlock()\n    return b.b.ReadFrom(r)\n}\nfunc (b *Buffer) ReadRune() (r rune, size int, err error) {\n    b.m.Lock()\n    defer b.m.Unlock()\n    return b.b.ReadRune()\n}\nfunc (b *Buffer) ReadString(delim byte) (line string, err error) {\n    b.m.Lock()\n    defer b.m.Unlock()\n    return b.b.ReadString(delim)\n}\nfunc (b *Buffer) Reset() {\n    b.m.Lock()\n    defer b.m.Unlock()\n    b.b.Reset()\n}\nfunc (b *Buffer) Truncate(n int) {\n    b.m.Lock()\n    defer b.m.Unlock()\n    b.b.Truncate(n)\n}\nfunc (b *Buffer) UnreadByte() error {\n    b.m.Lock()\n    defer b.m.Unlock()\n    return b.b.UnreadByte()\n}\nfunc (b *Buffer) UnreadRune() error {\n    b.m.Lock()\n    defer b.m.Unlock()\n    return b.b.UnreadRune()\n}\nfunc (b *Buffer) WriteByte(c byte) error {\n    b.m.Lock()\n    defer b.m.Unlock()\n    return b.b.WriteByte(c)\n}\nfunc (b *Buffer) WriteRune(r rune) (n int, err error) {\n    b.m.Lock()\n    defer b.m.Unlock()\n    return b.b.WriteRune(r)\n}\nfunc (b *Buffer) WriteString(s string) (n int, err error) {\n    b.m.Lock()\n    defer b.m.Unlock()\n    return b.b.WriteString(s)\n}\nfunc (b *Buffer) WriteTo(w io.Writer) (n int64, err error) {\n    b.m.Lock()\n    defer b.m.Unlock()\n    return b.b.WriteTo(w)\n}\n","tags":"#go #concurrency"},{"id":"8f39eb897316e1cbeaf9eff8326cfa59","title":"Go: Code Generation ","content":"\u003e [!NOTE]\n\u003e As of Go 1.17 `go run` works with a version.\\\n\u003e So you can avoid the tools.go pattern with something like this (if necessary):\\\n\u003e `//go:generate go run golang.org/x/tools/cmd/stringer@v0.25.0 -type=Scope -linecomment`\\\n\u003e Refer to https://gist.github.com/Integralist/e19c9faee86e797125e6d95fe1188912 for more details.\n\nFiles required:\n\n```\n.\n├── gen.go\n├── generator\n│   └── gen.go\n```\n\nRunning `go generate` will cause a `main.go` file to be created in the root directory.\n\n## gen.go\n\n```go\n//go:generate go run generator/gen.go\n\npackage gen\n```\n\n## generator/gen.go\n\n```go\n//go:build ignore\n// +build ignore\n\npackage main\n\nimport (\n\t\"log\"\n\t\"os\"\n\t\"text/template\"\n\t\"time\"\n)\n\n// Data represents information we'll inject into our code generation template.\ntype Data struct {\n\tTimestamp time.Time\n}\n\nfunc main() {\n\ttmpl := template.Must(template.New(\"\").Parse(`// Code generated by go generate; DO NOT EDIT.\n// This file was generated by robots at\n// {{ .Timestamp }}\npackage main\n\nimport (\n\t\"fmt\"\n)\n\nfunc main() {\n\tfmt.Println(\"this was generated code\")\n}\n\t`))\n\n\tf, err := os.Create(\"main.go\")\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\tdefer f.Close()\n\n\ttmpl.Execute(f, Data{\n\t\tTimestamp: time.Now(),\n\t})\n}\n```\n\n## Package Structure\n\nIf you would like to have your code split up over multiple files then you can do that, but it will mean your final compiled binary will include code not actually utilized.\n\nIf we extend on the above example...\n\n```\n.\n├── gen.go\n├── generator\n│   ├── gen.go\n│   └── openapi\n│       └── openapi.go\n├── go.mod\n```\n\nBy adding a `go.mod` file to the root directory:\n\n```\nmodule testing-code-gen\n\ngo 1.16\n```\n\nIt means we can put the code generator logic into multiple files within the `/generator` directory and then reference it, like so:\n\n```go\n// +build ignore\n\npackage main\n\nimport (\n\t...\n\t\"testing-code-gen/generator/openapi\"\n)\n\n...\n\nfunc main() {\n    ...\n\topenapi.Parse() // prints \"openapi parser executed\"\n}\n```\n\nThe contents of `openapi.go` is as follows:\n\n```go\npackage openapi\n\nimport \"fmt\"\n\nfunc Parse() {\n\tfmt.Println(\"openapi parser executed\")\n}\n```\n\n## Caveats\n\n- You can reference non-standard library dependencies as long as they're defined in the `go.mod` from the root directory.\n- The `go generate` treats the environment as if it's the root of the directory.\n  - Files you create will be placed in the root directory.\n  - Any paths you reference will need to be relative to the root directory (e.g. `./generator/openapi/...`) even when from inside nested directories.\n  \n## Reference material\n\n- https://golang.org/cmd/go/#hdr-Generate_Go_files_by_processing_source\n- https://blog.carlmjohnson.net/post/2016-11-27-how-to-use-go-generate/\n- https://blog.carlmjohnson.net/post/2021/how-to-use-go-embed/\n```\n.\n├── README.md\n├── client.go\n├── fastly.yaml\n├── generator\n│   └── generator.go\n├── go.mod\n├── go.sum\n└── main.go\n\n2 directories, 7 files\n```\n\nThe following code is what's inside the `generator/generator.go` file:\n\n```go\n//go:build ignore\n\npackage main\n\nimport (\n\t\"fmt\"\n\t\"log\"\n\t\"os\"\n\t\"strings\"\n\t\"text/template\"\n\t\"time\"\n\n\t\"github.com/pb33f/libopenapi\"\n\tvalidator \"github.com/pb33f/libopenapi-validator\"\n\tv3 \"github.com/pb33f/libopenapi/datamodel/high/v3\"\n\t\"golang.org/x/text/cases\"\n\t\"golang.org/x/text/language\"\n)\n\n// TemplateData represents information we'll inject into our code generation template.\ntype TemplateData struct {\n\t// Resources is a map of predefined API resources.\n\tResources map[string]*Resource\n\t// Timestamp represents when the code was generated.\n\tTimestamp time.Time\n\t// Title is the name of the API.\n\tTitle string\n\t// Description is a description of the Fastly API.\n\tDescription string\n}\n\n// Resource is an individual API endpoint.\ntype Resource struct {\n\t// Description is the description of the API resource.\n\tDescription string\n\t// ExternalDocs is the Developer Hub API documentation page for the resource.\n\tExternalDocs string\n\t// Endpoints is a list of endpoints available for the resource.\n\tEndpoints []Endpoint\n}\n\n// Endpoint is an individual API endpoint for the resource.\ntype Endpoint struct {\n\t// Path is the API endpoint.\n\tPath string\n\t// Params is the API path parameters.\n\tParams []Param\n\t// Servers is a list of API hosts.\n\tServers []*v3.Server\n\t// Operations is a list of API operations (e.g. GET, POST, DELETE etc).\n\t// Each operation is an object containing the details of the operation.\n\t// This includes details of the request body, response body, metadata etc.\n\tOperations map[string]*v3.Operation\n}\n\n// Param is an individual parameter (path or query)\ntype Param struct {\n\t// Name is the name of the parameter.\n\tName string\n\t// Description is the description of the parameter.\n\tDescription string\n\t// In indicates whether the param is in the path or the query.\n\tIn string\n\t// Required indicates if the param must be provided.\n\tRequired bool\n\t// Type is the type of the parameter (e.g. string, integer etc).\n\t// The generator needs to transform the type into a language specific format.\n\tType string\n}\n\nfunc main() {\n\tschema, _ := os.ReadFile(\"fastly.yaml\")\n\n\tdocument, err := libopenapi.NewDocument(schema)\n\tif err != nil {\n\t\tpanic(fmt.Sprintf(\"cannot create new document: %s\", err))\n\t}\n\n\thighLevelValidator, validatorErrs := validator.NewValidator(document)\n\tif len(validatorErrs) \u003e 0 {\n\t\tfor _, e := range validatorErrs {\n\t\t\tfmt.Printf(\"validatorErr: %+v\\n\", e)\n\t\t}\n\t\treturn\n\t}\n\n\tvalid, validationErrs := highLevelValidator.ValidateDocument()\n\tif !valid {\n\t\tfor _, e := range validationErrs {\n\t\t\tfmt.Printf(\"Type: %s, Failure: %s\\n\", e.ValidationType, e.Message)\n\t\t\tfmt.Printf(\"Fix: %s\\n\\n\", e.HowToFix)\n\t\t}\n\t}\n\n\tporcelain, errors := document.BuildV3Model()\n\tif len(errors) \u003e 0 {\n\t\tfor i := range errors {\n\t\t\tfmt.Printf(\"error: %e\\n\", errors[i])\n\t\t}\n\t\tpanic(fmt.Sprintf(\"cannot create v3 model from document: %d errors reported\", len(errors)))\n\t}\n\n\td := TemplateData{\n\t\tResources: map[string]*Resource{},\n\t\tTimestamp: time.Now(),\n\t\tTitle:     porcelain.Model.Info.Title,\n\t\t// FIXME: Rewrite Markdown syntax used in the description (e.g. hyperlinks).\n\t\tDescription: strings.ReplaceAll(porcelain.Model.Info.Description, \"\\n\", \" \"),\n\t}\n\n\t// The following code locates the resource metadata associated with a path,\n\t// and stores all relevant data into a Resource data type which can be looked\n\t// up via a map key (i.e. the Data struct's Resources map field).\n\tfor path, data := range porcelain.Model.Paths.PathItems {\n\t\tif path != \"/service/{service_id}/version/{version_id}/backend/{backend_name}\" {\n\t\t\tcontinue\n\t\t}\n\n\t\tops := data.GetOperations()\n\t\tif len(ops) == 0 {\n\t\t\treturn\n\t\t}\n\n\t\tvar resourceName string\n\t\tfor _, op := range ops {\n\t\t\tif len(op.Tags) == 0 {\n\t\t\t\treturn\n\t\t\t}\n\t\t\tresourceName = op.Tags[0]\n\t\t\tbreak\n\t\t}\n\n\t\tif resourceName == \"\" {\n\t\t\tfmt.Printf(\"error: the resource path '%s' had no tag in any operation for us to identify the resource\\n\", path)\n\t\t\treturn\n\t\t}\n\n\t\tr := \u0026Resource{}\n\t\tif resource, ok := d.Resources[resourceName]; ok {\n\t\t\tr = resource\n\t\t}\n\n\t\tif r.Description == \"\" \u0026\u0026 r.ExternalDocs == \"\" {\n\t\t\tfor _, metadata := range porcelain.Model.Tags {\n\t\t\t\tif metadata.Name == resourceName {\n\t\t\t\t\tr.Description = metadata.Description\n\t\t\t\t\tr.ExternalDocs = metadata.ExternalDocs.URL\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tvar params []Param\n\t\tfor _, param := range data.Parameters {\n\t\t\t// TODO: Make the switch work for multiple languages (not just Go).\n\t\t\tvar t string\n\t\t\tswitch v := param.Schema.Schema().Type[0]; v {\n\t\t\tcase \"integer\":\n\t\t\t\tt = \"int\"\n\t\t\tdefault:\n\t\t\t\tt = v\n\t\t\t}\n\t\t\tp := Param{\n\t\t\t\tName:        param.Name,\n\t\t\t\tDescription: param.Description,\n\t\t\t\tIn:          param.In,\n\t\t\t\tRequired:    param.Required,\n\t\t\t\tType:        t,\n\t\t\t}\n\t\t\tparams = append(params, p)\n\t\t}\n\n\t\tr.Endpoints = append(r.Endpoints, Endpoint{\n\t\t\tPath:    path,\n\t\t\tParams:  params,\n\t\t\tServers: data.Servers,\n\t\t\t// TODO: Generate response objects using defined schemas.\n\t\t\t// That means we need to pass the schema for each operation.\n\t\t\t// Which means passing a custom object, not `data.GetOperations()`.\n\t\t\t// As we can't call a method (e.g. `data.Schema.Schema()`) within the template.\n\t\t\t// See the below for loop (which should be deleted to avoid output).\n\t\t\tOperations: data.GetOperations(),\n\t\t})\n\n\t\td.Resources[resourceName] = r\n\n\t\tfor op, data := range data.GetOperations() {\n\t\t\tfmt.Printf(\"op: %+v\\n\", op)\n\t\t\tfor code, resp := range data.Responses.Codes {\n\t\t\t\tfmt.Printf(\"code: %+v\\n\", code)\n\t\t\t\tfor mime, data := range resp.Content {\n\t\t\t\t\tfmt.Printf(\"%+v | %+v\\n\", mime, data.Schema.Schema())\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\t// NOTE: We need to use a trick to include backticks in a raw string literal.\n\t//\n\t// e.g. `\u003cTEXT\u003e` would become ` + \"`\u003cTEXT\u003e`\" + `\n\t//\n\t// You stop the raw string literal backtick, then concatenate with normal\n\t// string but the normal string happens to include backticks. Then you restart\n\t// the raw string literal's backtick.\n\n\ttmpl := template.Must(template.New(\"\").Funcs(template.FuncMap{\n\t\t\"toCamelCase\": func(s string) string {\n\t\t\twords := strings.Split(s, \"-\")\n\t\t\tif len(words) == 1 {\n\t\t\t\twords = strings.Split(s, \"_\")\n\t\t\t}\n\t\t\tfor i := 0; i \u003c len(words); i++ {\n\t\t\t\twords[i] = cases.Title(language.English).String(words[i])\n\t\t\t}\n\t\t\treturn strings.Join(words, \"\")\n\t\t},\n\t\t\"title\": cases.Title(language.English).String,\n\t}).Parse(`// Package fastly provides access to an API client for {{ .Title }}\n//\n// {{ .Description }}\npackage fastly\n\n// Code generated by go generate; DO NOT EDIT.\n// This file was generated by robots at\n// {{ .Timestamp }}\n\nimport (\n\t\"bytes\"\n\t\"encoding/json\"\n\t\"fmt\"\n\t\"io\"\n\t\"mime/multipart\"\n\t\"net/http\"\n\t\"net/url\"\n\t\"os\"\n\t\"path/filepath\"\n\t\"reflect\"\n\t\"strconv\"\n\t\"strings\"\n\t\"sync\"\n\t\"time\"\n\n\t\"github.com/google/go-querystring/query\"\n\t\"github.com/google/jsonapi\"\n\t\"github.com/hashicorp/go-cleanhttp\"\n\t\"github.com/mitchellh/mapstructure\"\n)\n\n// API CLIENT LOGIC\n// TODO: Move to a separate file for maintainability.\n\n// APIKeyHeader is the name of the header that contains the Fastly API key.\nconst APIKeyHeader = \"Fastly-Key\"\n\n// DefaultEndpoint is the default endpoint for Fastly. Since Fastly does not\n// support an on-premise solution, this is likely to always be the default.\nconst DefaultEndpoint = \"https://api.fastly.com\"\n\n// EndpointEnvVar is the name of an environment variable that can be used\n// to change the URL of API requests.\nconst EndpointEnvVar = \"FASTLY_API_URL\"\n\n// DebugEnvVar is the name of an environment variable that can be used to switch\n// the API client into debug mode.\nconst DebugEnvVar = \"FASTLY_DEBUG_MODE\"\n\n// ProjectVersion is the version of this library.\nvar ProjectVersion = \"0.0.1\"\n\n// UserAgent is the user agent for this particular client.\nvar UserAgent = fmt.Sprintf(\"FastlyAPIClient/Go/%s\", ProjectVersion)\n\n// NewClient creates a new API client with the given key and the default API\n// endpoint. Because Fastly allows some requests without an API key, this\n// function will not error if the API token is not supplied. Attempts to make a\n// request that requires an API key will return a 403 response.\nfunc NewClient(key string) (*Client, error) {\n\tendpoint, ok := os.LookupEnv(EndpointEnvVar)\n\n\tif !ok {\n\t\tendpoint = DefaultEndpoint\n\t}\n\n\treturn NewClientForEndpoint(key, endpoint)\n}\n\n// NewClientForEndpoint creates a new API client with the given key and API\n// endpoint. Because Fastly allows some requests without an API key, this\n// function will not error if the API token is not supplied. Attempts to make a\n// request that requires an API key will return a 403 response.\nfunc NewClientForEndpoint(key string, endpoint string) (*Client, error) {\n\tclient := \u0026Client{apiKey: key, Address: endpoint}\n\t\n\tif endpoint, ok := os.LookupEnv(DebugEnvVar); ok \u0026\u0026 endpoint == \"true\" {\n\t\tclient.debugMode = true\n\t}\n\n\treturn client.init()\n}\n\n// Client is the main entrypoint to the Fastly golang API library.\ntype Client struct {\n\t// Address is the address of Fastly's API endpoint.\n\tAddress string\n\t// HTTPClient is the HTTP client to use. If one is not provided, a default\n\t// client will be used.\n\tHTTPClient *http.Client\n\n\t// apiKey is the Fastly API key to authenticate requests.\n\tapiKey string\n\t// debugMode enables HTTP request/response dumps.\n\tdebugMode bool\n\t// remaining is last observed value of http header Fastly-RateLimit-Remaining\n\tremaining int\n\t// reset is last observed value of http header Fastly-RateLimit-Reset\n\treset int64\n\t// updateLock forces serialization of calls that modify a service.\n\t// Concurrent modifications have undefined semantics.\n\tupdateLock sync.Mutex\n\t// url is the parsed URL from Address\n\turl *url.URL\n}\n\nfunc (c *Client) init() (*Client, error) {\n\t// Until we do a request, we don't know how many are left.\n\t// Use the default limit as a first guess:\n\t// https://developer.fastly.com/reference/api/#rate-limiting\n\tc.remaining = 1000\n\n\tu, err := url.Parse(c.Address)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tc.url = u\n\n\tif c.HTTPClient == nil {\n\t\tc.HTTPClient = cleanhttp.DefaultClient()\n\t}\n\n\treturn c, nil\n}\n\n// RateLimitRemaining returns the number of non-read requests left before\n// rate limiting causes a 429 Too Many Requests error.\nfunc (c *Client) RateLimitRemaining() int {\n\treturn c.remaining\n}\n\n// RateLimitReset returns the next time the rate limiter's counter will be\n// reset.\nfunc (c *Client) RateLimitReset() time.Time {\n\treturn time.Unix(c.reset, 0)\n}\n\n// Get issues an HTTP GET request.\nfunc (c *Client) Get(p string, ro *RequestOptions) (*http.Response, error) {\n\tif ro == nil {\n\t\tro = new(RequestOptions)\n\t}\n\tro.Parallel = true\n\treturn c.Request(\"GET\", p, ro)\n}\n\n// Head issues an HTTP HEAD request.\nfunc (c *Client) Head(p string, ro *RequestOptions) (*http.Response, error) {\n\tif ro == nil {\n\t\tro = new(RequestOptions)\n\t}\n\tro.Parallel = true\n\treturn c.Request(\"HEAD\", p, ro)\n}\n\n// Patch issues an HTTP PATCH request.\nfunc (c *Client) Patch(p string, ro *RequestOptions) (*http.Response, error) {\n\treturn c.Request(\"PATCH\", p, ro)\n}\n\n// PatchForm issues an HTTP PUT request with the given interface form-encoded.\nfunc (c *Client) PatchForm(p string, i interface{}, ro *RequestOptions) (*http.Response, error) {\n\treturn c.RequestForm(\"PATCH\", p, i, ro)\n}\n\n// PatchJSON issues an HTTP PUT request with the given interface json-encoded.\nfunc (c *Client) PatchJSON(p string, i interface{}, ro *RequestOptions) (*http.Response, error) {\n\treturn c.RequestJSON(\"PATCH\", p, i, ro)\n}\n\n// PatchJSONAPI issues an HTTP PUT request with the given interface json-encoded.\nfunc (c *Client) PatchJSONAPI(p string, i interface{}, ro *RequestOptions) (*http.Response, error) {\n\treturn c.RequestJSONAPI(\"PATCH\", p, i, ro)\n}\n\n// Post issues an HTTP POST request.\nfunc (c *Client) Post(p string, ro *RequestOptions) (*http.Response, error) {\n\treturn c.Request(\"POST\", p, ro)\n}\n\n// PostForm issues an HTTP POST request with the given interface form-encoded.\nfunc (c *Client) PostForm(p string, i interface{}, ro *RequestOptions) (*http.Response, error) {\n\treturn c.RequestForm(\"POST\", p, i, ro)\n}\n\n// PostJSON issues an HTTP POST request with the given interface json-encoded.\nfunc (c *Client) PostJSON(p string, i interface{}, ro *RequestOptions) (*http.Response, error) {\n\treturn c.RequestJSON(\"POST\", p, i, ro)\n}\n\n// PostJSONAPI issues an HTTP POST request with the given interface json-encoded.\nfunc (c *Client) PostJSONAPI(p string, i interface{}, ro *RequestOptions) (*http.Response, error) {\n\treturn c.RequestJSONAPI(\"POST\", p, i, ro)\n}\n\n// PostJSONAPIBulk issues an HTTP POST request with the given interface json-encoded and bulk requests.\nfunc (c *Client) PostJSONAPIBulk(p string, i interface{}, ro *RequestOptions) (*http.Response, error) {\n\treturn c.RequestJSONAPIBulk(\"POST\", p, i, ro)\n}\n\n// Put issues an HTTP PUT request.\nfunc (c *Client) Put(p string, ro *RequestOptions) (*http.Response, error) {\n\treturn c.Request(\"PUT\", p, ro)\n}\n\n// PutForm issues an HTTP PUT request with the given interface form-encoded.\nfunc (c *Client) PutForm(p string, i interface{}, ro *RequestOptions) (*http.Response, error) {\n\treturn c.RequestForm(\"PUT\", p, i, ro)\n}\n\n// PutFormFile issues an HTTP PUT request (multipart/form-encoded) to put a file to an endpoint.\nfunc (c *Client) PutFormFile(urlPath string, filePath string, fieldName string, ro *RequestOptions) (*http.Response, error) {\n\treturn c.RequestFormFile(\"PUT\", urlPath, filePath, fieldName, ro)\n}\n\n// PutFormFileFromReader issues an HTTP PUT request (multipart/form-encoded) to put a file to an endpoint.\nfunc (c *Client) PutFormFileFromReader(urlPath string, fileName string, fileBytes io.Reader, fieldName string, ro *RequestOptions) (*http.Response, error) {\n\treturn c.RequestFormFileFromReader(\"PUT\", urlPath, fileName, fileBytes, fieldName, ro)\n}\n\n// PutJSON issues an HTTP PUT request with the given interface json-encoded.\nfunc (c *Client) PutJSON(p string, i interface{}, ro *RequestOptions) (*http.Response, error) {\n\treturn c.RequestJSON(\"PUT\", p, i, ro)\n}\n\n// PutJSONAPI issues an HTTP PUT request with the given interface json-encoded.\nfunc (c *Client) PutJSONAPI(p string, i interface{}, ro *RequestOptions) (*http.Response, error) {\n\treturn c.RequestJSONAPI(\"PUT\", p, i, ro)\n}\n\n// Delete issues an HTTP DELETE request.\nfunc (c *Client) Delete(p string, ro *RequestOptions) (*http.Response, error) {\n\treturn c.Request(\"DELETE\", p, ro)\n}\n\n// DeleteJSONAPI issues an HTTP DELETE request with the given interface json-encoded.\nfunc (c *Client) DeleteJSONAPI(p string, i interface{}, ro *RequestOptions) (*http.Response, error) {\n\treturn c.RequestJSONAPI(\"DELETE\", p, i, ro)\n}\n\n// DeleteJSONAPIBulk issues an HTTP DELETE request with the given interface json-encoded and bulk requests.\nfunc (c *Client) DeleteJSONAPIBulk(p string, i interface{}, ro *RequestOptions) (*http.Response, error) {\n\treturn c.RequestJSONAPIBulk(\"DELETE\", p, i, ro)\n}\n\n// RequestForm makes an HTTP request with the given interface being encoded as\n// form data.\nfunc (c *Client) RequestForm(verb, p string, i interface{}, ro *RequestOptions) (*http.Response, error) {\n\tif ro == nil {\n\t\tro = new(RequestOptions)\n\t}\n\n\tif ro.Headers == nil {\n\t\tro.Headers = make(map[string]string)\n\t}\n\tro.Headers[\"Content-Type\"] = \"application/x-www-form-urlencoded\"\n\n\tv, err := query.Values(i)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tbody := v.Encode()\n\tif ro.HealthCheckHeaders {\n\t\tbody = parseHealthCheckHeaders(body)\n\t}\n\n\tro.Body = strings.NewReader(body)\n\tro.BodyLength = int64(len(body))\n\n\treturn c.Request(verb, p, ro)\n}\n\n// RequestFormFile makes an HTTP request to upload a file to an endpoint.\nfunc (c *Client) RequestFormFile(verb, urlPath string, filePath string, fieldName string, ro *RequestOptions) (*http.Response, error) {\n\tfile, err := os.Open(filepath.Clean(filePath))\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"error reading file: %v\", err)\n\t}\n\tdefer file.Close() // #nosec G307\n\n\treturn c.RequestFormFileFromReader(verb, urlPath, filepath.Base(filePath), file, fieldName, ro)\n}\n\n// RequestFormFileFromReader makes an HTTP request to upload a raw reader to an endpoint.\nfunc (c *Client) RequestFormFileFromReader(verb, urlPath string, fileName string, fileBytes io.Reader, fieldName string, ro *RequestOptions) (*http.Response, error) {\n\tvar body bytes.Buffer\n\twriter := multipart.NewWriter(\u0026body)\n\tpart, err := writer.CreateFormFile(fieldName, fileName)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"error creating multipart form: %v\", err)\n\t}\n\n\t_, err = io.Copy(part, fileBytes)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"error copying file to multipart form: %v\", err)\n\t}\n\n\terr = writer.Close()\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"error closing multipart form: %v\", err)\n\t}\n\n\tif ro == nil {\n\t\tro = new(RequestOptions)\n\t}\n\tif ro.Headers == nil {\n\t\tro.Headers = make(map[string]string)\n\t}\n\tro.Headers[\"Content-Type\"] = writer.FormDataContentType()\n\tro.Headers[\"Accept\"] = \"application/json\"\n\tro.Body = \u0026body\n\tro.BodyLength = int64(body.Len())\n\n\treturn c.Request(verb, urlPath, ro)\n}\n\n// RequestJSON constructs JSON HTTP request.\nfunc (c *Client) RequestJSON(verb, p string, i interface{}, ro *RequestOptions) (*http.Response, error) {\n\tif ro == nil {\n\t\tro = new(RequestOptions)\n\t}\n\n\tif ro.Headers == nil {\n\t\tro.Headers = make(map[string]string)\n\t}\n\tro.Headers[\"Content-Type\"] = \"application/json\"\n\tro.Headers[\"Accept\"] = \"application/json\"\n\n\tbody, err := json.Marshal(i)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tro.Body = bytes.NewReader(body)\n\tro.BodyLength = int64(len(body))\n\n\treturn c.Request(verb, p, ro)\n}\n\n// RequestJSONAPI constructs JSON API HTTP request.\nfunc (c *Client) RequestJSONAPI(verb, p string, i interface{}, ro *RequestOptions) (*http.Response, error) {\n\tif ro == nil {\n\t\tro = new(RequestOptions)\n\t}\n\n\tif ro.Headers == nil {\n\t\tro.Headers = make(map[string]string)\n\t}\n\tro.Headers[\"Content-Type\"] = jsonapi.MediaType\n\tro.Headers[\"Accept\"] = jsonapi.MediaType\n\n\tif i != nil {\n\t\tvar buf bytes.Buffer\n\t\tif err := jsonapi.MarshalPayload(\u0026buf, i); err != nil {\n\t\t\treturn nil, err\n\t\t}\n\n\t\tro.Body = \u0026buf\n\t\tro.BodyLength = int64(buf.Len())\n\t}\n\treturn c.Request(verb, p, ro)\n}\n\n// RequestJSONAPIBulk constructs bulk JSON API HTTP request.\nfunc (c *Client) RequestJSONAPIBulk(verb, p string, i interface{}, ro *RequestOptions) (*http.Response, error) {\n\tif ro == nil {\n\t\tro = new(RequestOptions)\n\t}\n\n\tif ro.Headers == nil {\n\t\tro.Headers = make(map[string]string)\n\t}\n\tro.Headers[\"Content-Type\"] = jsonapi.MediaType + \"; ext=bulk\"\n\tro.Headers[\"Accept\"] = jsonapi.MediaType + \"; ext=bulk\"\n\n\tvar buf bytes.Buffer\n\tif err := jsonapi.MarshalPayload(\u0026buf, i); err != nil {\n\t\treturn nil, err\n\t}\n\n\tro.Body = \u0026buf\n\tro.BodyLength = int64(buf.Len())\n\n\treturn c.Request(verb, p, ro)\n}\n\n// Request makes an HTTP request against the HTTPClient using the given verb,\n// Path, and request options.\nfunc (c *Client) Request(verb, p string, ro *RequestOptions) (*http.Response, error) {\n\treq, err := c.RawRequest(verb, p, ro)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tif ro == nil || !ro.Parallel {\n\t\tc.updateLock.Lock()\n\t\tdefer c.updateLock.Unlock()\n\t}\n\t\n    if c.debugMode {\n\t\tdump, _ := httputil.DumpRequest(req, true)\n\t\tfmt.Printf(\"http.Request (dump): %q\\n\", dump)\n\t}\n\n\t// nosemgrep: trailofbits.go.invalid-usage-of-modified-variable.invalid-usage-of-modified-variable\n\tresp, err := checkResp(c.HTTPClient.Do(req))\n\tif err != nil {\n\t\treturn resp, err\n\t}\n\n\tif c.debugMode {\n\t\tdump, _ := httputil.DumpResponse(resp, true)\n\t\tfmt.Printf(\"http.Response (dump): %q\\n\", dump)\n\t}\n\n\tif verb != \"GET\" \u0026\u0026 verb != \"HEAD\" {\n\t\tremaining := resp.Header.Get(\"Fastly-RateLimit-Remaining\")\n\t\tif remaining != \"\" {\n\t\t\tif val, err := strconv.Atoi(remaining); err == nil {\n\t\t\t\tc.remaining = val\n\t\t\t}\n\t\t}\n\t\treset := resp.Header.Get(\"Fastly-RateLimit-Reset\")\n\t\tif reset != \"\" {\n\t\t\tif val, err := strconv.ParseInt(reset, 10, 64); err == nil {\n\t\t\t\tc.reset = val\n\t\t\t}\n\t\t}\n\t}\n\n\treturn resp, nil\n}\n\n// RawRequest accepts a verb, URL, and RequestOptions struct and returns the\n// constructed http.Request and any errors that occurred\nfunc (c *Client) RawRequest(verb, p string, ro *RequestOptions) (*http.Request, error) {\n\t// Ensure we have request options.\n\tif ro == nil {\n\t\tro = new(RequestOptions)\n\t}\n\n\t// Append the path to the URL.\n\tu := strings.TrimRight(c.url.String(), \"/\") + \"/\" + strings.TrimLeft(p, \"/\")\n\n\t// Create the request object.\n\trequest, err := http.NewRequest(verb, u, ro.Body)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tparams := make(url.Values)\n\tfor k, v := range ro.Params {\n\t\tparams.Add(k, v)\n\t}\n\trequest.URL.RawQuery = params.Encode()\n\n\t// Set the API key.\n\tif len(c.apiKey) \u003e 0 {\n\t\trequest.Header.Set(APIKeyHeader, c.apiKey)\n\t}\n\n\t// Set the User-Agent.\n\trequest.Header.Set(\"User-Agent\", UserAgent)\n\n\t// Add any custom headers.\n\tfor k, v := range ro.Headers {\n\t\trequest.Header.Add(k, v)\n\t}\n\n\t// Add Content-Length if we have it.\n\tif ro.BodyLength \u003e 0 {\n\t\trequest.ContentLength = ro.BodyLength\n\t}\n\n\treturn request, nil\n}\n\n// RequestOptions is the list of options to pass to the request.\ntype RequestOptions struct {\n\t// Body is an io.Reader object that will be streamed or uploaded with the\n\t// Request.\n\tBody io.Reader\n\t// BodyLength is the final size of the Body.\n\tBodyLength int64\n\t// Headers is a map of key-value pairs that will be added to the Request.\n\tHeaders map[string]string\n\t// HealthCheckHeaders indicates if there is any special parsing required to\n\t// support the health check API endpoint (refer to client.RequestForm).\n\t//\n\t// TODO: Lookout for this when it comes to the future code-generated API\n\t// client world, as this special case might get omitted accidentally.\n\tHealthCheckHeaders bool\n\t// Can this request run in parallel\n\tParallel bool\n\t// Params is a map of key-value pairs that will be added to the Request.\n\tParams map[string]string\n}\n\n// checkResp wraps an HTTP request from the default client and verifies that the\n// request was successful. A non-200 request returns an error formatted to\n// included any validation problems or otherwise.\nfunc checkResp(resp *http.Response, err error) (*http.Response, error) {\n\t// If the err is already there, there was an error higher up the chain, so\n\t// just return that.\n\tif err != nil {\n\t\treturn resp, err\n\t}\n\n\tswitch resp.StatusCode {\n\tcase 200, 201, 202, 204, 205, 206:\n\t\treturn resp, nil\n\tdefault:\n\t\treturn resp, NewHTTPError(resp)\n\t}\n}\n\n// HTTPError is a custom error type that wraps an HTTP status code with some\n// helper functions.\ntype HTTPError struct {\n  Errors []*ErrorObject ` + \"`mapstructure:\\\"errors\\\"`\" + `\n\t// StatusCode is the HTTP status code (2xx-5xx).\n\tStatusCode int\n\t// RateLimitRemaining is the number of API requests remaining in the current\n\t// rate limit window. A nil value indicates the API returned no value for\n\t// the associated Fastly-RateLimit-Remaining response header.\n\tRateLimitRemaining *int\n\t// RateLimitReset is the time at which the current rate limit window resets,\n\t// as a Unix timestamp. A nil value indicates the API returned no value for\n\t// the associated Fastly-RateLimit-Reset response header.\n\tRateLimitReset *int\n}\n\n// ErrorObject is a single error.\ntype ErrorObject struct {\n\tCode   string                  ` + \"`mapstructure:\\\"code\\\"`\" + `\n\tDetail string                  ` + \"`mapstructure:\\\"detail\\\"`\" + `\n\tID     string                  ` + \"`mapstructure:\\\"id\\\"`\" + `\n\tMeta   *map[string]interface{} ` + \"`mapstructure:\\\"meta\\\"`\" + `\n\tStatus string                  ` + \"`mapstructure:\\\"status\\\"`\" + `\n\tTitle  string                  ` + \"`mapstructure:\\\"title\\\"`\" + `\n}\n\n// legacyError represents the older-style errors from Fastly. It is private\n// because it is automatically converted to a jsonapi error.\ntype legacyError struct {\n\tDetail  string ` + \"`mapstructure:\\\"detail\\\"`\" + `\n\tMessage string ` + \"`mapstructure:\\\"msg\\\"`\" + `\n\tTitle   string ` + \"`mapstructure:\\\"title\\\"`\" + `\n}\n\n// NewHTTPError creates a new HTTP error from the given code.\nfunc NewHTTPError(resp *http.Response) *HTTPError {\n\tvar e HTTPError\n\te.StatusCode = resp.StatusCode\n\n\tif v, err := strconv.Atoi(resp.Header.Get(\"Fastly-RateLimit-Remaining\")); err == nil {\n\t\te.RateLimitRemaining = \u0026v\n\t}\n\tif v, err := strconv.Atoi(resp.Header.Get(\"Fastly-RateLimit-Reset\")); err == nil {\n\t\te.RateLimitReset = \u0026v\n\t}\n\n\tif resp.Body == nil {\n\t\treturn \u0026e\n\t}\n\n\t// Save a copy of the body as it's read/decoded.\n\t// If decoding fails, it can then be used (via addDecodeErr)\n\t// to create a generic error containing the body's read contents.\n\tvar bodyCp bytes.Buffer\n\tbody := io.TeeReader(resp.Body, \u0026bodyCp)\n\taddDecodeErr := func() {\n\t\t// There are 2 errors at this point:\n\t\t//  1. The response error.\n\t\t//  2. The error decoding the response.\n\t\t// The response error is still most relevant to users (just unable to be decoded).\n\t\t// Provide the response's body verbatim as the error 'Detail' with the assumption\n\t\t// that it may contain useful information, e.g. 'Bad Gateway'.\n\t\t// The decode error could be conflated with the response error, so it is omitted.\n\t\te.Errors = append(e.Errors, \u0026ErrorObject{\n\t\t\tTitle:  \"Undefined error\",\n\t\t\tDetail: bodyCp.String(),\n\t\t})\n\t}\n\n\tswitch resp.Header.Get(\"Content-Type\") {\n\tcase jsonapi.MediaType:\n\t\t// If this is a jsonapi response, decode it accordingly.\n\t\tif err := decodeBodyMap(body, \u0026e); err != nil {\n\t\t\taddDecodeErr()\n\t\t}\n\n\tcase \"application/problem+json\":\n\t\t// Response is a \"problem detail\" as defined in RFC 7807.\n\t\tvar problemDetail struct {\n\t\t\tDetail string ` + \"`json:\\\"detail,omitempty\\\"`\" + ` // A human-readable description of the specific error, aiming to help the user correct the problem\n\t\t\tStatus int    ` + \"`json:\\\"status\\\"`\" + `           // HTTP status code\n\t\t\tTitle  string ` + \"`json:\\\"title,omitempty\\\"`\" + `  // A short name for the error type, which remains constant from occurrence to occurrence\n\t\t\tURL    string ` + \"`json:\\\"type,omitempty\\\"`\" + `   // URL to a human-readable document describing this specific error condition\n\t\t}\n\t\tif err := json.NewDecoder(body).Decode(\u0026problemDetail); err != nil {\n\t\t\taddDecodeErr()\n\t\t} else {\n\t\t\te.Errors = append(e.Errors, \u0026ErrorObject{\n\t\t\t\tTitle:  problemDetail.Title,\n\t\t\t\tDetail: problemDetail.Detail,\n\t\t\t\tStatus: strconv.Itoa(problemDetail.Status),\n\t\t\t})\n\t\t}\n\n\tdefault:\n\t\tvar lerr *legacyError\n\t\tif err := decodeBodyMap(body, \u0026lerr); err != nil {\n\t\t\taddDecodeErr()\n\t\t} else if lerr != nil {\n        \tmsg := lerr.Message\n            if msg == \"\" \u0026\u0026 lerr.Title != \"\" {\n            \tmsg = lerr.Title\n            }\n\t\t\te.Errors = append(e.Errors, \u0026ErrorObject{\n\t\t\t\tTitle:  msg,\n\t\t\t\tDetail: lerr.Detail,\n\t\t\t})\n\t\t}\n\t}\n\n\treturn \u0026e\n}\n\n// Error implements the error interface and returns the string representing the\n// error text that includes the status code and the corresponding status text.\nfunc (e *HTTPError) Error() string {\n\tvar b bytes.Buffer\n\n\tfmt.Fprintf(\u0026b, \"%d - %s:\", e.StatusCode, http.StatusText(e.StatusCode))\n\n\tfor _, e := range e.Errors {\n\t\tfmt.Fprintf(\u0026b, \"\\n\")\n\n\t\tif e.ID != \"\" {\n\t\t\tfmt.Fprintf(\u0026b, \"\\n    ID:     %s\", e.ID)\n\t\t}\n\n\t\tif e.Title != \"\" {\n\t\t\tfmt.Fprintf(\u0026b, \"\\n    Title:  %s\", e.Title)\n\t\t}\n\n\t\tif e.Detail != \"\" {\n\t\t\tfmt.Fprintf(\u0026b, \"\\n    Detail: %s\", e.Detail)\n\t\t}\n\n\t\tif e.Code != \"\" {\n\t\t\tfmt.Fprintf(\u0026b, \"\\n    Code:   %s\", e.Code)\n\t\t}\n\n\t\tif e.Meta != nil {\n\t\t\tfmt.Fprintf(\u0026b, \"\\n    Meta:   %v\", *e.Meta)\n\t\t}\n\t}\n\n\tif e.RateLimitRemaining != nil {\n\t\tfmt.Fprintf(\u0026b, \"\\n    RateLimitRemaining: %v\", *e.RateLimitRemaining)\n\t}\n\tif e.RateLimitReset != nil {\n\t\tfmt.Fprintf(\u0026b, \"\\n    RateLimitReset:     %v\", *e.RateLimitReset)\n\t}\n\n\treturn b.String()\n}\n\n// String implements the stringer interface and returns the string representing\n// the string text that includes the status code and corresponding status text.\nfunc (e *HTTPError) String() string {\n\treturn e.Error()\n}\n\n// IsNotFound returns true if the HTTP error code is a 404, false otherwise.\nfunc (e *HTTPError) IsNotFound() bool {\n\treturn e.StatusCode == 404\n}\n\n// decodeBodyMap is used to decode an HTTP response body into a mapstructure struct.\nfunc decodeBodyMap(body io.Reader, out interface{}) error {\n\tvar parsed interface{}\n\tdec := json.NewDecoder(body)\n\tif err := dec.Decode(\u0026parsed); err != nil {\n\t\treturn err\n\t}\n\n\treturn decodeMap(parsed, out)\n}\n\n// decodeMap decodes the ` + \"`in`\" + ` struct or map to a mapstructure tagged ` + \"`out`\" + `.\n// It applies the decoder defaults used throughout go-fastly.\n// Note that this uses opposite argument order from Go's copy().\nfunc decodeMap(in interface{}, out interface{}) error {\n\tdecoder, err := mapstructure.NewDecoder(\u0026mapstructure.DecoderConfig{\n\t\tDecodeHook: mapstructure.ComposeDecodeHookFunc(\n\t\t\tmapToHTTPHeaderHookFunc(),\n\t\t\tstringToTimeHookFunc(),\n\t\t),\n\t\tWeaklyTypedInput: true,\n\t\tResult:           out,\n\t})\n\tif err != nil {\n\t\treturn err\n\t}\n\treturn decoder.Decode(in)\n}\n\n// mapToHTTPHeaderHookFunc returns a function that converts maps into an\n// http.Header value.\nfunc mapToHTTPHeaderHookFunc() mapstructure.DecodeHookFunc {\n\treturn func(\n\t\tf reflect.Type,\n\t\tt reflect.Type,\n\t\tdata interface{},\n\t) (interface{}, error) {\n\t\tif f.Kind() != reflect.Map {\n\t\t\treturn data, nil\n\t\t}\n\t\tif t != reflect.TypeOf(new(http.Header)) {\n\t\t\treturn data, nil\n\t\t}\n\n\t\ttyped, ok := data.(map[string]interface{})\n\t\tif !ok {\n\t\t\treturn nil, fmt.Errorf(\"cannot convert %T to http.Header\", data)\n\t\t}\n\n\t\tn := map[string][]string{}\n\t\tfor k, v := range typed {\n\t\t\tswitch tv := v.(type) {\n\t\t\tcase string:\n\t\t\t\tn[k] = []string{tv}\n\t\t\tcase []string:\n\t\t\t\tn[k] = tv\n\t\t\tcase int, int8, int16, int32, int64:\n\t\t\t\tn[k] = []string{fmt.Sprintf(\"%d\", tv)}\n\t\t\tcase float32, float64:\n\t\t\t\tn[k] = []string{fmt.Sprintf(\"%f\", tv)}\n\t\t\tdefault:\n\t\t\t\treturn nil, fmt.Errorf(\"cannot convert %T to http.Header\", v)\n\t\t\t}\n\t\t}\n\n\t\treturn n, nil\n\t}\n}\n\n// stringToTimeHookFunc returns a function that converts strings to a time.Time\n// value.\nfunc stringToTimeHookFunc() mapstructure.DecodeHookFunc {\n\treturn func(\n\t\tf reflect.Type,\n\t\tt reflect.Type,\n\t\tdata interface{},\n\t) (interface{}, error) {\n\t\tif f.Kind() != reflect.String {\n\t\t\treturn data, nil\n\t\t}\n\t\tif t != reflect.TypeOf(time.Now()) {\n\t\t\treturn data, nil\n\t\t}\n\n\t\t// Convert it by parsing\n\t\tv, err := time.Parse(time.RFC3339, data.(string))\n\t\tif err != nil {\n\t\t\t// DictionaryInfo#get uses it's own special time format for now.\n\t\t\treturn time.Parse(\"2006-01-02 15:04:05\", data.(string))\n\t\t}\n\t\treturn v, err\n\t}\n}\n\n// parseHealthCheckHeaders returns the serialised body with the custom health\n// check headers appended.\n//\n// NOTE: The Google query library we use for parsing and encoding the provided\n// struct values doesn't support the format headers=[\"Foo: Bar\"] and so we\n// have to manually construct this format.\nfunc parseHealthCheckHeaders(s string) string {\n\theaders := []string{}\n\tresult := []string{}\n\tsegs := strings.Split(s, \"\u0026\")\n\tfor _, s := range segs {\n\t\tif strings.HasPrefix(strings.ToLower(s), \"headers=\") {\n\t\t\tv := strings.Split(s, \"=\")\n\t\t\tif len(v) == 2 {\n\t\t\t\theaders = append(headers, fmt.Sprintf(\"%q\", strings.ReplaceAll(v[1], \"%3A+\", \":\")))\n\t\t\t}\n\t\t} else {\n\t\t\tresult = append(result, s)\n\t\t}\n\t}\n\tif len(headers) \u003e 0 {\n\t\tresult = append(result, \"headers=%5B\"+strings.Join(headers, \",\")+\"%5D\")\n\t}\n\treturn strings.Join(result, \"\u0026\")\n}\n\n// NewFieldError returns an error that formats as the given text.\nfunc NewFieldError(kind string) *FieldError {\n\treturn \u0026FieldError{\n\t\tkind: kind,\n\t}\n}\n\n// FieldError represents a custom error type for API data fields.\ntype FieldError struct {\n\tkind    string\n\tmessage string\n}\n\n// Error fulfills the error interface.\n//\n// NOTE: some fields are optional but still need to present an error depending\n// on the API they are associated with. For example, when updating a service\n// the 'name' and 'comment' fields are both optional, but at least one of them\n// needs to be provided for the API call to have any purpose (otherwise the API\n// backend will just reject the call, thus being a waste of network resources).\n//\n// Because of this we allow modifying the error message to reflect whether the\n// field was either missing or some other type of error occurred.\nfunc (e *FieldError) Error() string {\n\tif e.message != \"\" {\n\t\treturn fmt.Sprintf(\"problem with field '%s': %s\", e.kind, e.message)\n\t}\n\n\treturn fmt.Sprintf(\"missing required field '%s'\", e.kind)\n}\n\n// Message prints the error message.\nfunc (e *FieldError) Message(msg string) *FieldError {\n\te.message = msg\n\treturn e\n}\n\n// CODE-GENERATED LOGIC\n\n{{ range $key, $resource := .Resources }}// RESOURCE:\n//\n// {{ title $key }}\n//\n// RESOURCE DESCRIPTION:\n//\n// {{ $resource.Description }}\n//\n// API DOCUMENTATION:\n//\n// {{ $resource.ExternalDocs }}\n{{ range $index, $endpoint := $resource.Endpoints }}\n{{ range $opName, $operation := $endpoint.Operations }}\n{{ range $code, $resp := $operation.Responses.Codes }}\ntype {{ toCamelCase $operation.OperationId }}Resp{{ $code }}{{ $resp.Description }} struct {\n{{ range $mime, $data := $resp.Content }}\n// {{ $mime }} | {{ $data }}\n{{ end }}\n}\n{{ end }}\n\ntype {{ toCamelCase $operation.OperationId }}Input struct {\n{{ range $param := $endpoint.Params }}\n  // {{ toCamelCase $param.Name }}: {{ $param.Description }} {{ if eq $param.Required true }}(required){{ end }}\n  {{ toCamelCase $param.Name }} {{ $param.Type }}\n{{ end }}\n}\n\n// {{ toCamelCase $operation.OperationId }}: {{ $operation.Description }}\nfunc (c *Client) {{ toCamelCase $operation.OperationId }}(i *{{ toCamelCase $operation.OperationId }}Input) (*Backend, error) {\n{{ range $param := $endpoint.Params }}\n  {{ if eq $param.Required true }}\n  if i.{{ toCamelCase $param.Name }} == {{ if eq $param.Type \"string\" }}\"\"{{ else if eq $param.Type \"int\" }}0{{ end }} {\n    return nil, NewFieldError(\"{{ toCamelCase $param.Name }}\")\n  }\n  {{ end }}\n{{ end }}\n\n  path := \"{{ $endpoint.Path }}\"\n\n  // TODO: Figure out how to identify whether url.PathEscape(i.\u003cField\u003e) is needed.\n  {{ range $param := $endpoint.Params }}\n  path = strings.Replace(path, fmt.Sprintf(\"{%s}\", \"{{ $param.Name }}\"), i.{{ toCamelCase $param.Name }}, -1)\n  {{ end }}\n\n  // TODO: Figure out how to identify correct method to call.\n  // Will likely need TemplateData to provide a mapping.\n  // e.g. If the API is JSON-API then we'd need methods like PostJSONAPI etc.\n\tresp, err := c.{{ title $opName }}(path, nil)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tdefer resp.Body.Close()\n\n\tvar b *Backend\n\tif err := decodeBodyMap(resp.Body, \u0026b); err != nil {\n\t\treturn nil, err\n\t}\n\treturn b, nil\n}\n{{ end }}\n\n{{ range $server := $endpoint.Servers }}\n  // {{ $server.URL }}\n{{ end }}\n\n{{ range $opName, $operation := $endpoint.Operations }}\n  // Name:        {{ $opName }}\n  // Deprecated:  {{ $operation.Deprecated }}\n  // Security:    {{ $operation.Security }}\n  // Description: {{ $operation.Description }}\n  // OperationID: {{ toCamelCase $operation.OperationId }}\n  // RequestBody: {{ $operation.RequestBody }}\n  // Responses:   {{ $operation.Responses }}\n  // Extensions:  {{ $operation.Extensions }}\n  // Parameters:  {{ $operation.Parameters }}\n{{ end }}\n{{ end }}\n{{ end }}\n`))\n\n\tf, err := os.Create(\"client.go\")\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\tdefer f.Close()\n\n\ttmpl.Execute(f, d)\n}\n```\nThe above template code/logic produces the below code (refer to \"Code Output\"). \n\n## Caveats\n\nThe outputted code is incomplete as I didn't get a chance to finish the implementation. \n\nThe code generation logic also ouputs more whitespace, which is typical of code-generation as it's a trade-off between template maintainability and code readability. \n\n## Notes\n\nFor the sake of reviewing the output below, I've manually removed unnecessary white space to make it easier to read + I've also removed the HTTP client logic † \n\n\u003e † The HTTP client code takes up most of the space and isn't dynamically generated, but copied from the go-fastly client library. I did this as the library is battle-tested and works with all the Fastly API request/response types (including JSON-API) so it made sense to use that rather than attempt to rewrite it from scratch.\n\nI also wrote the code-generator to produce a single file for the output, where as for a real project you'd have it output to different files for maintainability.\n\nThe code generator logic was also constrained to producing output for a single resource path `\"/service/{service_id}/version/{version_id}/backend/{backend_name}\"`.\n\n## What's working?\n\nWhat this example output demonstrates is... \n\n- Generation of individual operations (e.g. `DeleteBackend`, `GetBackend`, `UpdateBackend` etc)\n- Generation of operation inputs (e.g. `DeleteBackendInput`, `GetBackendInput`, `UpdateBackendInput` etc)\n- Validation for 'required' input fields. \n- Interpolation of the input fields into the request path.\n\n## What's missing?\n\nThings outstanding:\n\n- Generate response object for each operation.\n- Use path escape for fields that require it.\n- Check for query params and ensure they're added to the request.\n- Check for request body and ensure that's added to the request.\n- Call the JSON-API methods if dealing with those types of endpoints.\n \n## Code Output\n \n```go\n// Code generated by go generate; DO NOT EDIT.\n// This file was generated by robots at\n// 2023-06-21 10:03:11.390429 +0100 BST m=+0.299988084\n//\n// Everything below this line is generated from our OpenAPI schemas.\n\n// Package fastly provides access to an API client for Fastly API\n//\n// Via the Fastly API you can perform any of the operations that are possible within the management console,  including creating services, domains, and backends, configuring rules or uploading your own application code, as well as account operations such as user administration and billing reports. The API is organized into collections of endpoints that allow manipulation of objects related to Fastly services and accounts. For the most accurate and up-to-date API reference content, visit our [Developer Hub](https://developer.fastly.com/reference/api/) \npackage fastly\n\nimport (\n\t\"bytes\"\n\t\"encoding/json\"\n\t\"fmt\"\n\t\"io\"\n\t\"mime/multipart\"\n\t\"net/http\"\n\t\"net/url\"\n\t\"os\"\n\t\"path/filepath\"\n\t\"reflect\"\n\t\"strconv\"\n\t\"strings\"\n\t\"sync\"\n\t\"time\"\n\n\t\"github.com/google/go-querystring/query\"\n\t\"github.com/google/jsonapi\"\n\t\"github.com/hashicorp/go-cleanhttp\"\n\t\"github.com/mitchellh/mapstructure\"\n)\n\n// API CLIENT LOGIC I'VE STRIPPED OUT SO YOU CAN SEE THE ACTUAL CODE-GENERATED LOGIC...\n\n\n// RESOURCE:\n//\n// Backend\n//\n// RESOURCE DESCRIPTION:\n//\n// A backend (also sometimes called an origin server) is a server identified by IP address or hostname, from which Fastly will fetch your content. There can be multiple backends attached to a service, but each backend is specific to one service. By default, the first backend added to a service configuration will be used for all requests (provided it meets any [conditions](/reference/api/vcl-services/condition) attached to it). If multiple backends are defined for a service, the first one that has no attached conditions, or whose condition is satisfied for the current request, will be used, unless that behavior is modified using the `auto_loadbalance` field described below.\n//\n// API DOCUMENTATION:\n//\n// https://developer.fastly.com/reference/api/services/backend\n\ntype DeleteBackendResp200OK struct {\n  // INCOMPLETE: NOT FINISHED IMPLEMENTING RESPONSE GENERTION.\n  // application/json | {0x140063f59b0 \u003cnil\u003e map[body:0x1400217d5e0] map[] map[] 0x1400197da40}\n}\n\ntype DeleteBackendInput struct {\n  // ServiceId: Alphanumeric string identifying the service. (required)\n  ServiceId string\n  // VersionId: Integer identifying a service version. (required)\n  VersionId int\n  // BackendName: The name of the backend. (required)\n  BackendName string\n}\n\n// DeleteBackend: Delete the backend for a particular service and version.\nfunc (c *Client) DeleteBackend(i *DeleteBackendInput) (*Backend, error) {\n  if i.ServiceId == \"\" {\n    return nil, NewFieldError(\"ServiceId\")\n  }\n  \n  if i.VersionId == 0 {\n    return nil, NewFieldError(\"VersionId\")\n  }\n  \n  if i.BackendName == \"\" {\n    return nil, NewFieldError(\"BackendName\")\n  }\n  \n  // TODO: Figure out how to identify whether url.PathEscape(i.\u003cField\u003e) is needed.\n  path := \"/service/{service_id}/version/{version_id}/backend/{backend_name}\"\n  path = strings.Replace(path, fmt.Sprintf(\"{%s}\", \"service_id\"), i.ServiceId, -1)\n  path = strings.Replace(path, fmt.Sprintf(\"{%s}\", \"version_id\"), i.VersionId, -1)\n  path = strings.Replace(path, fmt.Sprintf(\"{%s}\", \"backend_name\"), i.BackendName, -1)\n  \n  // TODO: Figure out how to identify correct method to call.\n  // Will likely need TemplateData to provide a mapping.\n  // e.g. If the API is JSON-API then we'd need methods like PostJSONAPI etc.\n  resp, err := c.Delete(path, nil)\n  if err != nil {\n\treturn nil, err\n  }\n  defer resp.Body.Close()\n\n  var b *Backend\n  if err := decodeBodyMap(resp.Body, \u0026b); err != nil {\n\treturn nil, err\n  }\n  return b, nil\n}\n\ntype GetBackendResp200OK struct {\n  // INCOMPLETE: NOT FINISHED IMPLEMENTING RESPONSE GENERTION.\n  // application/json | {0x140063f5350 \u003cnil\u003e map[body:0x1400217d4f0] map[] map[] 0x1400197d880}\n}\n\ntype GetBackendInput struct {\n  // ServiceId: Alphanumeric string identifying the service. (required)\n  ServiceId string\n  // VersionId: Integer identifying a service version. (required)\n  VersionId int\n  // BackendName: The name of the backend. (required)\n  BackendName string\n}\n\n// GetBackend: Get the backend for a particular service and version.\nfunc (c *Client) GetBackend(i *GetBackendInput) (*Backend, error) {\n  if i.ServiceId == \"\" {\n    return nil, NewFieldError(\"ServiceId\")\n  }\n  \n  if i.VersionId == 0 {\n    return nil, NewFieldError(\"VersionId\")\n  }\n  \n  if i.BackendName == \"\" {\n    return nil, NewFieldError(\"BackendName\")\n  }\n  \n  // TODO: Figure out how to identify whether url.PathEscape(i.\u003cField\u003e) is needed.\n  path := \"/service/{service_id}/version/{version_id}/backend/{backend_name}\"\n  path = strings.Replace(path, fmt.Sprintf(\"{%s}\", \"service_id\"), i.ServiceId, -1)\n  path = strings.Replace(path, fmt.Sprintf(\"{%s}\", \"version_id\"), i.VersionId, -1)\n  path = strings.Replace(path, fmt.Sprintf(\"{%s}\", \"backend_name\"), i.BackendName, -1)\n  \n  // TODO: Figure out how to identify correct method to call.\n  // Will likely need TemplateData to provide a mapping.\n  // e.g. If the API is JSON-API then we'd need methods like PostJSONAPI etc.\n  resp, err := c.Get(path, nil)\n  if err != nil {\n    return nil, err\n  }\n  defer resp.Body.Close()\n\n  var b *Backend\n  if err := decodeBodyMap(resp.Body, \u0026b); err != nil {\n\treturn nil, err\n  }\n  return b, nil\n}\n\ntype UpdateBackendResp200OK struct {\n  // INCOMPLETE: NOT FINISHED IMPLEMENTING RESPONSE GENERTION.\n  // application/json | {0x140063f5740 \u003cnil\u003e map[body:0x1400217d590] map[] map[] 0x140005e3a40}\n}\n\ntype UpdateBackendInput struct {\n  // ServiceId: Alphanumeric string identifying the service. (required)\n  ServiceId string\n  // VersionId: Integer identifying a service version. (required)\n  VersionId int\n  // BackendName: The name of the backend. (required)\n  BackendName string\n}\n\n// UpdateBackend: Update the backend for a particular service and version.\nfunc (c *Client) UpdateBackend(i *UpdateBackendInput) (*Backend, error) {\n  if i.ServiceId == \"\" {\n    return nil, NewFieldError(\"ServiceId\")\n  }\n  \n  if i.VersionId == 0 {\n    return nil, NewFieldError(\"VersionId\")\n  }\n  \n  if i.BackendName == \"\" {\n    return nil, NewFieldError(\"BackendName\")\n  }\n  \n  // TODO: Figure out how to identify whether url.PathEscape(i.\u003cField\u003e) is needed.\n  path := \"/service/{service_id}/version/{version_id}/backend/{backend_name}\"\n  path = strings.Replace(path, fmt.Sprintf(\"{%s}\", \"service_id\"), i.ServiceId, -1)\n  path = strings.Replace(path, fmt.Sprintf(\"{%s}\", \"version_id\"), i.VersionId, -1)\n  path = strings.Replace(path, fmt.Sprintf(\"{%s}\", \"backend_name\"), i.BackendName, -1)  \n\n  // TODO: Figure out how to identify correct method to call.\n  // Will likely need TemplateData to provide a mapping.\n  // e.g. If the API is JSON-API then we'd need methods like PostJSONAPI etc.\n  resp, err := c.Put(path, nil)\n  if err != nil {\n\treturn nil, err\n  }\n  defer resp.Body.Close()\n\n  var b *Backend\n  if err := decodeBodyMap(resp.Body, \u0026b); err != nil {\n\treturn nil, err\n  }\n  return b, nil\n}\n```\n","tags":"#go"},{"id":"c112bf8c131b4cc4d52e4e237c880383","title":"Windows: Terminal Development ","content":"The following notes are based around a CLI tool I had built in [Go](https://go.dev/) that would read a configuration file containing a 'build script' and would open a subshell to run the script. \n\nI had reports from Windows users that it wasn't working. I was using `cmd.exe` as the Terminal (as it's the default for Windows, so we know it's always available), but it doesn't support the POSIX command substitution syntax (e.g. `$()`). \n\nThe simplest solution ended up being to avoid command substitution (which in my case was possible as the build script was doing `$(npm bin)/webpack` and that could be changed to `npm exec webpack`), but at the time of this investigation I was not aware of `npm exec` (or `npx` for that matter) and so I was looking at different terminals for Windows to understand which of them supported 'command substitution'. \n\nI inevitably stumbled into a nightmare.\n\nHere are few terminals available (non-exhaustive list)...\n\n1. [Command Prompt](https://learn.microsoft.com/en-us/windows-server/administration/windows-commands/cmd) (Cmd.exe)\n2. [Cygwin](https://www.cygwin.com)\n3. [Git for Windows](https://gitforwindows.org) (e.g. provides a BASH emulation used to run Git from the command line)\n4. [PowerShell](https://learn.microsoft.com/en-us/powershell/scripting/overview?view=powershell-7.2)\n5. [Windows Subsystem for Linux](https://learn.microsoft.com/en-us/windows/wsl/install) (WSL)\n6. [Windows Terminal](https://learn.microsoft.com/en-us/windows/terminal/)\n\n\u003e **NOTE**: Windows Terminal looks to be a nice terminal interface, but the shell itself appears to just be PowerShell. So it might not be worth testing against if you already test your code against PowerShell.\n\n## PowerShell\n\nI tried to switch to using `powershell.exe` (which although not installed by default, is the next simplest shell to get installed for Windows) and I discovered it doesn't support the 'logical AND' operator `\u0026\u0026`. This means you have to use a more arcane `-and` syntax, but this would make my build script incompatible with other shells that _are_ POSIX compatible. \n\nIn an example project we _could_ have configured our CLI code to pattern match `\u0026\u0026` and then, when on a Windows OS, replaced it with `-and` but I then discovered PowerShell fails to execute a binary using the syntax `$(npm bin)/webpack` (I would hit this issue again later when testing the new Windows Terminal). \n\nTo avoid `\u0026\u0026` we an do the following in Bash `bin=$(npm bin); $bin/webpack` but in PowerShell you can't assign the result of a command substitution to a variable.\n\n## Cmd.exe\n\nInterestingly, `cmd.exe` _does_ support `\u0026\u0026` but as we know, it fails to support `$()`. There is an alternative syntax but I couldn't get it to work (even with a simple example), let alone something more complex like: \n\n```shell\nfor /F \"tokens=*\" %n IN ('npm bin') DO @(%n\\webpack)\n```\n\nBut this is a very confusing syntax. Also, I'm not sure how to 'chain' the command. \n\nHaving to logic hop around this sort of code would be a project maintenance/sustainability concern (if we were to go to these lengths to support building on Windows).\n\nIt also means to ensure our scripts stays compatible with the majority of users on actual POSIX/Bash shells we'd have to have the CLI parse the build script and identify any `$()` usage and replace it with the above more complex syntax, which would be a very brittle solution (especially if there was nested usage of `$()`).\n\n## Cygwin\n\nI didn't test with Cygwin. I've used it in the past for testing but it is a specialised tool that provides an isolated environment to work within and so that could cause problems if there are expectations for the CLI to be able to access files outside of that environment. \n\nAlso, from my understanding Cygwin is less commonly used nowadays and so it's unlikely we would want to require users to install it just to use the CLI. Ideally a tool that doesn't require an isolated environment would be better.\n\n## Git for Windows\n\nI installed Git for Windows but found it also created its own isolated environment, and I also couldn't figure out how to share files from my host Windows machine to it.\n\n## Windows Subsystem for Linux (WSL)\n\nInstalling WSL requires Windows 10+, which might exclude some Window developers (looks like Windows 10 was released in 2015 so maybe users on an earlier version is not a concern). WSL also sets up an isolated environment but what is interesting is that it also (_partially_ at least) integrates with `cmd.exe` and PowerShell (e.g. you can pass commands to be executed to the isolated environment from the host environment). \n\nThis integration is not a panacea, as although a simple execution like `wsl ls -a` (which prints all files from my host Windows machine) works fine, when I try to execute something like `wsl ls $(npm bin)` it fails to access the directory. This means a more complex mounting of files into the WSL is necessary and again highlights the 'isolated environment' concern I had with Cygwin and Git for Windows.\n\n## Windows Terminal\n\nWhen installing the new Windows Terminal, it appears to be an enhanced PowerShell (it actually shows as 'PowerShell' in the terminal), as it supports `\u0026\u0026` as well as other posix/Bash flavoured syntax. Although executing  `ls $(npm bin)` worked (unlike WSL), the moment I tried `$(npm bin)/webpack` to execute the binary within the directory, the command execution failed because of some unsupported syntax (i.e. the forward slash was not recognised). Meaning if we have to modify our scripts, then it isn't going to be compatible with other shells. This error also occurred with the standard PowerShell.\n\n## Makefile\n\nAlso worth noting that my project's Makefile had a line like the following:\n\n```Makefile\nGO_FILES = $(shell find cmd pkg -type f -name '*.go')\n```\n\nThis didn't work on Windows as there is no `find` command available. So I had to fix this like so:\n\n```Makefile\nifeq ($(OS), Windows_NT)\n\tSHELL = cmd.exe\n    .SHELLFLAGS = /c\n\tGO_FILES = $(shell where /r pkg *.go)\n\tGO_FILES += $(shell where /r cmd *.go)\nelse\n\tGO_FILES = $(shell find cmd pkg -type f -name '*.go')\nendif\n```\n\nAdditionally, our CLI program uses `cmd.exe` but the CI environment where we run our integration tests was running PowerShell! \n\nThis means the above Makefile change would break our CI as some of the POSIX shell code was working fine in PowerShell, and then we suddenly changed things to be `cmd.exe` (e.g. I had a variable that worked with PowerShell but failed in `cmd.exe`: `./{cmd,pkg}/...` and so I had to change it to `./...` to avoid issues).\n```shell\nC:\\Users\\markm\u003e cmd.exe /C \"echo 123 \u0026\u0026 echo 456\"\n123\n456\t\n\nC:\\Users\\markm\u003e mkdir go\nC:\\Users\\markm\u003e type nul \u003e main.go\nC:\\Users\\markm\u003e dir\nC:\\Users\\markm\u003e Xcopy \u003csrc\u003e \u003cdest\u003e /E/H/C/I\n```\n```shell\nset PATH \"%PATH%;C:\\NewDirectory\"\n```\n- `command+r` to open \"Run\" UI.\n- type `%appdata%` to open folder to that directory.\n- Go to `C:\\Users\\Administrator\\AppData\\Local` and `mkdir nvim`.\n- `git clone https://github.com/integralist/nvim.git` inside of the `nvim` directory\n- Move all the files into the `nvim` directory and start up `nvim`\n","tags":"#terminals #windows #os #dev #nvim"},{"id":"1d13805ac04cd10afaa2252dd144ae8e","title":"Writing: Article Notes and Asides ","content":"\u003e **NOTE**: few people affected.  \n\u003e **IMPORTANT**: lots of people affected.  \n\u003e **HINT**: examples and use cases, but could just be omitted.  \n\u003e **WARNING**: avoid doing something dangerous.\n\nIf it doesn’t fit, then maybe it should be part of the content.\n\n## Example of not using aside\n\nThe message you want to get across is: \"you should use an API key but you can call this particular endpoint without one\".\n\nThe message affects everyone so you might think to use an `IMPORTANT` aside, but this doesn't feel important enough to be an aside, so just include it in the main content.\n","tags":"#writing #notes #asides"},{"id":"c9c14aea7f6aed97840eaea2b5c14fdd","title":"Shell: Short one line Bash if else statement ","content":"# yay\nexport FOO=true\n[[ $FOO == \"true\" ]] \u0026\u0026 echo yay || echo nay\n\n# nay\nexport BAR=false\n[[ $BAR == \"true\" ]] \u0026\u0026 echo yay || echo nay\n","tags":"#bash #shell #if #conditional"},{"id":"7de01a8ae89a9b035a22d61535e21230","title":"Go: Generics ","content":"## When to use Generics?\n\nIf you find yourself writing the exact same code multiple times, where the only difference between the copies is the code uses different types, _consider_ whether you can use a generic type parameter.\n\nIt's probably also useful anywhere you have `[]interface{}` today, for example a caching library might define something like...\n\n```go\nGet(key string) (interface{}, error)\n```\n\nThis could be changed to...\n\n```go\nGet[V any](key string) (V, error)\n```\n\nWith the `interface{}` type you always need code to cast back the value to what you expect and have error cases if by any chance someone put something in the cache with the wrong type. Now this validation can be done at compile time.\n\n## Help\n\n- [Video](https://www.youtube.com/watch?v=KepBhuQJT9E)\n- [Constraints](https://github.com/golang/go/blob/master/src/constraints/constraints.go)\n- [Initial `1.18beta1` release notes](https://tip.golang.org/doc/go1.18#generics)\n\n## Examples\n\n### Generic errors.As\n\n```go\nfunc As[T error](err error) (bool, T) {\n\tvar target T\n\tok := errors.As(err, \u0026target)\n\treturn ok, target\n}\n\nfunc main() {\n\tif _, err := os.Open(\"non-existing\"); err != nil {\n\t\tok, perr := As[*fs.PathError](err)\n\t\tif ok {\n\t\t\tfmt.Println(\"Failed at path:\", perr.Path)\n\t\t} else {\n\t\t\tfmt.Println(err)\n\t\t}\n\t}\n}\n```\n\n### Pass multiple struct types to generic function\n\nCaveat is you need to define an interface that has methods described for each field you expect to store in the struct.\n\nIn the following example you might be better off using `any` (i.e. `interface{}`) for dynamic dispatch rather than static dispatch (i.e. generics). \n\nYou might get better performance and less chance of a runtime error with generics but is the code complexity worth it? Up to you to decide.\n\n```go\npackage main\n\nimport (\n\t\"fmt\"\n)\n\ntype ServiceVCL struct {\n\tName string\n\tFoo  bool // doesn't exist on ServiceCompute\n}\n\nfunc (s ServiceVCL) GetName() string {\n\treturn s.Name\n}\n\nfunc (s ServiceVCL) GetFoo() (v bool) {\n\treturn s.Foo\n}\n\nfunc (s ServiceVCL) GetBar() (v int) {\n\treturn v\n}\n\ntype ServiceCompute struct {\n\tName string\n\tBar  int // doesn't exist on ServiceVCL\n}\n\nfunc (s ServiceCompute) GetName() string {\n\treturn s.Name\n}\n\nfunc (s ServiceCompute) GetFoo() (v bool) {\n\treturn v\n}\n\nfunc (s ServiceCompute) GetBar() (v int) {\n\treturn s.Bar\n}\n\ntype Service interface {\n\tServiceVCL | ServiceCompute\n\tGetName() (name string)\n\tGetFoo() (foo bool)\n\tGetBar() (bar int)\n}\n\ntype ServiceWrapper[T Service] struct {\n\tData T\n}\n\nfunc New[T Service](service T) *ServiceWrapper[T] {\n\tsw := ServiceWrapper[T]{}\n\tsw.Data = service\n\treturn \u0026sw\n}\n\nfunc Accept[T Service](sw *ServiceWrapper[T]) {\n\tfmt.Printf(\"Wrapper: %+v\\n\", sw)\n\tfmt.Printf(\"GetName(): %s\\n\", sw.Data.GetName())\n\tfmt.Printf(\"GetFoo(): %t\\n\", sw.Data.GetFoo())\n\tfmt.Printf(\"GetBar(): %d\\n\", sw.Data.GetBar())\n}\n\nfunc main() {\n\tvcl := ServiceVCL{\n\t\tName: \"VCL\",\n\t\tFoo:  true,\n\t}\n\tcompute := ServiceCompute{\n\t\tName: \"Compute\",\n\t\tBar:  123,\n\t}\n\n\tswv := New(vcl)\n\tswc := New(compute)\n\n\tfmt.Printf(\"vcl: %+v\\n\", swv)\n\tfmt.Printf(\"compute: %+v\\n\", swc)\n\n\tAccept(swv)\n\tAccept(swc)\n}\n```\n","tags":"#go #generics"},{"id":"01aed051251476c4bd6daa4b076eb23a","title":"Python: progress bar ","content":"# https://mdk.fr/blog/how-apt-does-its-fancy-progress-bar.html\n#\n# For the record here's what's used (\\033 is ESC):\n#\n# `ESC 7`           is DECSC   (Save Cursor)\n# `ESC 8`           is DECRC   (Restore Cursor)\n# `ESC [ Pn ; Pn r` is DECSTBM (Set Top and Bottom Margins)\n# `ESC [ Pn A`      is CUU     (Cursor Up)\n# `ESC [ Pn ; Pn f` is HVP     (Horizontal and Vertical Position)\n# `ESC [ Ps K`      is EL      (Erase In Line)\n\nimport os\nimport time\nfrom datetime import datetime\n\ncolumns, lines = os.get_terminal_size()\n\n\ndef write(s):\n    print(s, end=\"\")\n    time.sleep(1)\n\n\nwrite(\"\\n\")                  # Ensure the last line is available.\nwrite(\"\\0337\")               # Save cursor position\nwrite(f\"\\033[0;{lines-1}r\")  # Reserve the bottom line\nwrite(\"\\0338\")               # Restore the cursor position\nwrite(\"\\033[1A\")             # Move up one line\n\ntry:\n    for i in range(250):\n        time.sleep(0.2)\n        write(f\"Hello {i}\")\n        write(\"\\0337\")                     # Save cursor position\n        write(f\"\\033[{lines};0f\")          # Move cursor to the bottom margin\n        write(datetime.now().isoformat())  # Write the date\n        write(\"\\0338\")                     # Restore cursor position\n        write(\"\\n\")\nexcept KeyboardInterrupt:\n    pass\nfinally:\n    write(\"\\0337\")             # Save cursor position\n    write(f\"\\033[0;{lines}r\")  # Drop margin reservation\n    write(f\"\\033[{lines};0f\")  # Move the cursor to the bottom line\n    write(\"\\033[0K\")           # Clean that line\n    write(\"\\0338\")             # Restore cursor position\n","tags":"#python #python3 #ansi #escape #progress"},{"id":"0a6472a5b08f468c2d7697a4ef5b807d","title":"Git: stage hunks for untracked files in git ","content":"If you've created a bunch of new files in git, use `git add --intent-to-add` (or `git add -N`) to move the files from untracked to unstaged. \n\nThis way you can incrementally stage hunks similar to how you can stage hunks from previously committed files.\n","tags":"#git #patch #staged #untracked"},{"id":"a9ea0a57f95639a8e18c5bc78586888d","title":"Compiler: Understanding linker files ","content":"A **static library(.a)** is a library that can be linked directly into the final executable produced by the linker,it is contained in it and there is no need to have the library into the system where the executable will be deployed.\n\nA **shared library(.so)** is a library that is linked but not embedded in the final executable, so will be loaded when the executable is launched and need to be present in the system where the executable is deployed.\n\nA **dynamic link library on windows(.dll)** is like a shared library(.so) on linux but there are some differences between the two implementations that are related to the OS (Windows vs Linux) :\n\nA **DLL** can define two kinds of functions: exported and internal. The exported functions are intended to be called by other modules, as well as from within the DLL where they are defined. Internal functions are typically intended to be called only from within the DLL where they are defined.\n\nAn **SO** library on Linux doesn't need special export statement to indicate exportable symbols, since all symbols are available to an interrogating process.\n","tags":"#system #c #compiler #linker"},{"id":"06be2e6f79e2120284c2613b4eeb260d","title":"GPG: Fixing GPG and Agent Errors ","content":"## Updated gpg and gpg-agent via Homebrew\n\n**Error**:\n\n```bash\n$ pass show Some/Example/Service\n\ngpg: WARNING: server 'gpg-agent' is older than us (2.3.1 \u003c 2.3.2)\ngpg: problem with fast path key listing: IPC parameter error - ignored\ngpg: public key decryption failed: No pinentry\ngpg: decryption failed: No pinentry\n```\n\n**Solution**:\n\n```bash\ngpgconf --kill all\n```\n","tags":"#gpg #gpgagent #agent #pass"},{"id":"53303137d6dbb4ecc80a0384f29eb051","title":"Python: download YouTube Videos ","content":"from pytube import YouTube\nfrom pytube.cli import on_progress\n\nvideos = [\n    'https://www.youtube.com/watch?v=FOO',\n    'https://www.youtube.com/watch?v=BAR',\n    'https://www.youtube.com/watch?v=BAZ',\n]\n\nfor video in videos:\n    YouTube(video, on_progress_callback=on_progress).streams.filter(\n        progressive=True,\n        file_extension='mp4',\n    ).order_by('resolution').desc().first().download()\n","tags":"#python #python3 #pytube #youtube #download"},{"id":"cc610e9cf70c6a52042cc3ae9a7ba97e","title":"Go: text indenting ","content":"// https://play.golang.org/p/aug7FboQQQ_g\n\npackage main\n\nimport (\n\t\"fmt\"\n\t\"strings\"\n\n\t\"github.com/mitchellh/go-wordwrap\"\n)\n\nfunc wrapIndent(s string, lim uint, indent uint) string {\n\tlim -= indent\n\twrapped := wordwrap.WrapString(s, lim)\n\tvar result []string\n\tfor _, line := range strings.Split(wrapped, \"\\n\") {\n\t\tresult = append(result, strings.Repeat(\" \", int(indent))+line)\n\t}\n\treturn strings.Join(result, \"\\n\")\n}\n\nfunc main() {\n\tfmt.Printf(\"%s\\n\\n\", wrapIndent(text, 80, 0))\n\tfmt.Printf(\"%s\\n\\n\", wrapIndent(text, 80, 4))\n}\n\nconst text = `Lorem ipsum dolor sit amet consectetur adipisicing elit. Maxime mollitia, molestiae quas vel sint commodi repudiandae consequuntur voluptatum laborum numquam blanditiis harum quisquam eius sed odit fugiat iusto fuga praesentium optio, eaque rerum! Provident similique accusantium nemo autem. Veritatis obcaecati tenetur iure eius earum ut molestias architecto voluptate aliquam nihil, eveniet aliquid culpa officia aut! Impedit sit sunt quaerat, odit, tenetur error, harum nesciunt ipsum debitis quas aliquid. Reprehenderit, quia. Quo neque error repudiandae fuga?`\n\n","tags":"#go #tty"},{"id":"2d59134acebbc909ec7eb56ff93310c3","title":"Security: Confidentiality, Integrity, Availability, and the Factors of Authentication ","content":"- **Confidentiality**: Information is only available to those who should have access.\n- **Integrity**: Data is known to be correct and trusted.\n- **Availability**: Information is available for use by legitimate users when it is needed.\n\n## Confidentiality\n\nConfidentiality stems from the \"least privilege\" principle, which means the information should only be visible by the parties who have the need to know. Improper authentication, unauthorized access, information exposure all lead to a breach of confidentiality. The more sensitive the information held within an application, the higher level of assurance is needed. \n\n## Integrity\n\nIntegrity is about preserving the information contents as they are and preventing tampering, while it is in transit or at rest. The more important the role of the application, the more important it is for its information to be trusted as decisions are made based on this information. If a malicious user can change the information, then they can affect the decisions being made. \n\n## Availability\n\nAvailability is concerned with the ability of a user to access the information, within certain parameters and complete their mission. If the information in an application is not available, then decisions that are based on this information can not be made.\n\n## The Factors of Authentication\n\nThe factors of authentication: \n\n- Something you know (e.g. password).\n- Something you have (e.g. yubi key).\n- Something you are  (e.g. fingerprint).\n\nThis is commonly referred to as \"multi-factor authentication\" (MFA), or historically \"two-factor authentication\" (2FA).\n","tags":"#security #confidentiality #integrity #availability"},{"id":"fab775b0e7071281a206673356f80530","title":"Go: Complex mapstructure example ","content":"package main\n\nimport (\n\t\"encoding/json\"\n\t\"errors\"\n\t\"fmt\"\n\t\"io\"\n\t\"log\"\n\t\"net/http\"\n\t\"reflect\"\n\t\"strings\"\n\t\"time\"\n\n\t\"github.com/mitchellh/mapstructure\"\n)\n\nfunc main() {\n\tvar rd *ResponseData\n\n\t// The 1 should be converted to `bool` type with value of `true`.\n\t// The null should become `nil` due to pointer type in ResponseData field.\n\tr := strings.NewReader(`{\"bool\": 1, \"possibly_null\": null}`)\n\trc := io.NopCloser(r)\n\n\tif err := decodeBodyMap(rc, \u0026rd); err != nil {\n\t\tlog.Fatal(err)\n\t}\n\n\tfmt.Printf(\"%+v\\n\", rd) // \u0026{Bool:true PossiblyNull:\u003cnil\u003e}\n}\n\ntype ResponseData struct {\n\tBool         bool `mapstructure:\"bool\"`\n\tPossiblyNull *int `mapstructure:\"possibly_null\"`\n}\n\n// decodeBodyMap is used to decode an HTTP response body into a mapstructure struct.\n// It closes `body`.\nfunc decodeBodyMap(body io.ReadCloser, out any) error {\n\tdefer body.Close()\n\n\tvar parsed any\n\tdec := json.NewDecoder(body)\n\tif err := dec.Decode(\u0026parsed); err != nil {\n\t\treturn err\n\t}\n\n\treturn decodeMap(parsed, out)\n}\n\n// decodeMap decodes an `in` struct or map to a mapstructure tagged `out`.\n// It applies the decoder defaults used throughout go-fastly.\n// Note that this uses opposite argument order from Go's copy().\nfunc decodeMap(in, out any) error {\n\tdecoder, err := mapstructure.NewDecoder(\u0026mapstructure.DecoderConfig{\n\t\tDecodeHook: mapstructure.ComposeDecodeHookFunc(\n\t\t\tmapToHTTPHeaderHookFunc(),\n\t\t\tstringToTimeHookFunc(),\n\t\t),\n\t\tWeaklyTypedInput: true,\n\t\tResult:           out,\n\t})\n\tif err != nil {\n\t\treturn err\n\t}\n\treturn decoder.Decode(in)\n}\n\n// mapToHTTPHeaderHookFunc returns a function that converts maps into an\n// http.Header value.\nfunc mapToHTTPHeaderHookFunc() mapstructure.DecodeHookFunc {\n\treturn func(\n\t\tf reflect.Type,\n\t\tt reflect.Type,\n\t\tdata any,\n\t) (any, error) {\n\t\tif f.Kind() != reflect.Map {\n\t\t\treturn data, nil\n\t\t}\n\t\tif t != reflect.TypeOf(new(http.Header)) {\n\t\t\treturn data, nil\n\t\t}\n\n\t\ttyped, ok := data.(map[string]any)\n\t\tif !ok {\n\t\t\treturn nil, fmt.Errorf(\"cannot convert %T to http.Header\", data)\n\t\t}\n\n\t\tn := map[string][]string{}\n\t\tfor k, v := range typed {\n\t\t\tswitch tv := v.(type) {\n\t\t\tcase string:\n\t\t\t\tn[k] = []string{tv}\n\t\t\tcase []string:\n\t\t\t\tn[k] = tv\n\t\t\tcase int, int8, int16, int32, int64:\n\t\t\t\tn[k] = []string{fmt.Sprintf(\"%d\", tv)}\n\t\t\tcase float32, float64:\n\t\t\t\tn[k] = []string{fmt.Sprintf(\"%f\", tv)}\n\t\t\tdefault:\n\t\t\t\treturn nil, fmt.Errorf(\"cannot convert %T to http.Header\", v)\n\t\t\t}\n\t\t}\n\n\t\treturn n, nil\n\t}\n}\n\n// stringToTimeHookFunc returns a function that converts strings to a time.Time\n// value.\nfunc stringToTimeHookFunc() mapstructure.DecodeHookFunc {\n\treturn func(\n\t\tf reflect.Type,\n\t\tt reflect.Type,\n\t\tdata any,\n\t) (any, error) {\n\t\tif f.Kind() != reflect.String {\n\t\t\treturn data, nil\n\t\t}\n\t\tif t != reflect.TypeOf(time.Now()) {\n\t\t\treturn data, nil\n\t\t}\n\n\t\t// Convert it by parsing\n\t\td, ok := data.(string)\n\t\tif !ok {\n\t\t\treturn nil, errors.New(\"failed to type assert `data` to a string\")\n\t\t}\n\t\tv, err := time.Parse(time.RFC3339, d)\n\t\tif err != nil {\n\t\t\t// DictionaryInfo#get uses it's own special time format for now.\n\t\t\treturn time.Parse(\"2006-01-02 15:04:05\", d)\n\t\t}\n\t\treturn v, err\n\t}\n}\n","tags":"#go #serialization"},{"id":"38c5c64704649231515129743b1e4033","title":"Git: restore and switch to replace git checkout ","content":"https://www.banterly.net/2021/07/31/new-in-git-switch-and-restore/\n\n```bash\ngit switch -c/--create \u003cbranch\u003e\ngit switch -d/--detach \u003ccommit|tag\u003e\ngit restore -- test.txt               # restores uncommitted changes to indexed version in the current branch.\ngit restore --source=main -- test.txt # restores committed changes to version from the specified source (branch, tag or commit).\n```\n","tags":"#git"},{"id":"57f24924f7100ee06e0032240f0cb70c","title":"Vim: search multiple lines with line breaks using PCRE_DOTALL mode ","content":"As noted in this thread: https://github.com/ggreer/the_silver_searcher/issues/459#issuecomment-118785490\n\nThe trick to get the PCRE engine have `.` to include new lines is to prefix your pattern with 'Perl options' (http://www.pcre.org/original/doc/html/pcrepattern.html#SEC13). \n\nSo to get `PCRE_DOTALL` we need to prefix our regex pattern with `(?s)`.\n\nFor example, consider a file `test.txt` with the following content:\n\n```\nLine 1\nLine 2\nLine 3\n```\n\nWe can match all three lines using:\n\n```bash\nag '(?s)Line 1.+Line 3' test.txt\n```\n\n\u003e **NOTE:** The above only works on a file, not when data is piped into `ag`.\n\nIf you want to check for lines not preceded by another line, e.g. you're looking for...\n\n```yaml\nname:\n  anyOf:\n    - ...\n```\n\nWhile avoiding:\n\n```yaml\nname:\n  type: object\n  anyOf:\n    - ...\n```\n\nThen use a negative lookbehind assertion:\n\n```\nrg --context 2 --pcre2 --regexp '(?\u003c!type: object)anyOf:'\n```\n\n## Ingore any matches with a lookahead\n\nImagine you have the following code across multiple files:\n\n```go\nserviceID, serviceVersion, err := cmd.ServiceDetails(cmd.ServiceDetailsOpts{\n\tAllowActiveLocked:  true,\n\tClient:             c.Globals.Client,\n\tManifest:           c.manifest,\n\tOut:                out,\n\tServiceVersionFlag: c.serviceVersion,\n\tVerboseMode:        c.Globals.Flag.Verbose,\n})\n```\n\nYou want to find every instance of the function call `cmd.ServiceDetails` but ignore any that have a `ServiceNameFlag` field set (which isn't set in the above example).\n\nTo achieve this you'd use a negative lookahead `(?!\u003cpattern\u003e)`. The following example uses the Vim ack plugin to search for the function call, then lookahead to make sure we don't find the field, and then keep matching until the end of the function call...\n\n```\n:Ack! '(?s)cmd\\.ServiceDetails\\((?!.+?ServiceNameFlag).+?}\\)'\n```\n","tags":"#silversearcher #ag #ack #grep #PCRE #regex #vim #lookahead #ripgrep"},{"id":"a959a200de07caffbc826b2cd415e6df","title":"Vim: Tips ","content":"## Make two windows scroll together\n\n`:windo set scrollbind` and `:windo set cursorbind`\n\n## Go to file and line number\n\n`gf` takes you to the file referenced (e.g. `[Makefile](../Makefile)`) but if you add a `:` followed by a line number to the link (e.g. `[Makefile](../Makefile:123)`) then pressing `gF` will take you to the specific line number as well.\n\n## Delete line above or below the current line\n\n`:-d` and `:+d` delete the line above or below the current line, unlike `dj` or `dk` which would also delete the current line.\n\n## Copy line to another location\n\n`:copy` allows you to copy a line to another location\n\ne.g. `:10 copy 20` copies the range, in this case line 10, to _below_ line 20), where I had always `:10y` then moved to the destination.\n\n## Paste a register\n\n`:\u003crange\u003eput \u003cregister\u003e` allows you to paste a register to a specific line.\n\n## QuickFix Window Filtering\n\n`:packadd cfilter` enables filtering results from quickfix window (e.g. `:Cfilter /pattern/`, also has negated version `Cfilter!`).\n\n## Append to multiple lines\n\nTo 'append' to multiple lines: `Ctrl+v` and select multiple lines, then `$`, then `Shift+a` and start typing (this is the opposite of 'insert' with `Ctrl+v` and `Shift+i`).\n\n## Format text width\n\nTo autoformat text to a specific width (e.g. `set textwidth=80`), first select the text and then execute `gq`. This is super useful for when you have a code comment that you need to tweak/edit, and then it messes up the line breaks. You can just select the entire text and `gq` to have it fixed!\n\n## Format JSON with jq\n\n`:%!jq` will format the entire file\n\n## Modelines\n\nhttps://vimhelp.org/options.txt.html#modeline\n\n- Markdown: `\u003c!-- vim: set colorcolumn=57,80: --\u003e`\n- Go: `// vim: foldmethod=indent foldlevel=0`\n\n## Edit files via terminal\n\n```shell\nvim -E -s config.txt \u003c\u003c-EOF\n:%s/foo/bar/\n:update\n:quit\nEOF\n```\n\n## Sort All Arrays\n\nThis uses `:g/regex1/,/regex2/command` syntax.\n\n`:g/\\[/+1,/\\]/-1sort`\n\nIt will operate on all lines between the lines matching `/regex1/` and `/regex2/` \n\nWe use this to sort a bunch of arrays in a file that looked like:\n\n```\nsome_var = [\n  one,\n  two,\n  three,\n]\n\nanother_var = [\n  pineapple,\n  banana,\n  apple,\n]\n```\n","tags":"#vim #tips #tricks"},{"id":"190c817aa46200e13e4b4b88391e5479","title":"Go: mocking multiple stdin prompts ","content":"// https://play.golang.org/p/w0VPpYMytnG\n//\n// NOTE: This is a correct way to implement, but a quicker/smaller solution would have been not to create the `bufio.NewScanner` instance (unfortunately the `input()` implementation was legacy code that couldn't be updated).\n\npackage main\n\nimport (\n\t\"bufio\"\n\t\"bytes\"\n\t\"fmt\"\n\t\"io\"\n\t\"log\"\n\t\"strings\"\n\t\"time\"\n)\n\nfunc input(r io.Reader) (string, error) {\n\ts := bufio.NewScanner(r)\n\tfor {\n\t\tif ok := s.Scan(); !ok {\n\t\t\treturn \"\", s.Err()\n\t\t}\n\t\tline := strings.TrimSpace(s.Text())\n\t\treturn line, nil\n\t}\n}\n\nfunc run(r io.Reader, w io.Writer) error {\n\ts, err := input(r)\n\tif err != nil {\n\t\treturn err\n\t}\n\tfmt.Printf(\"first input(): %+v\\n\", s)\n\tfmt.Fprintf(w, \"%+v\\n\", s)\n\n\ts, err = input(r)\n\tif err != nil {\n\t\treturn err\n\t}\n\tfmt.Printf(\"second input(): %+v\\n\", s)\n\tfmt.Fprintf(w, \"%+v\\n\", s)\n\n\treturn nil\n}\n\nfunc main() {\n\tvar stdout bytes.Buffer\n\n\tstdin, prompt := io.Pipe()\n\n\t// Wait for user input\n\tinputc := make(chan string)\n\tgo func() {\n\t\tfor input := range inputc {\n\t\t\tfmt.Fprintln(prompt, input)\n\t\t}\n\t}()\n\n\t// Wait for `run()` to read user input\n\tdone := make(chan bool)\n\n\t// Call `run()` and wait for response\n\tgo func() {\n\t\terr := run(stdin, \u0026stdout)\n\t\tif err != nil {\n\t\t\tlog.Fatal(err)\n\t\t}\n\t\tdone \u003c- true\n\t}()\n\n\t// User provides input\n\t//\n\t// NOTE: Must provide as much input as is expected to be waited on by `run()`.\n\t//       For example, if `run()` calls `input()` twice, then provide two messages.\n\t//       Otherwise the select statement will trigger the timeout error.\n\tinputc \u003c- \"foo!\"\n\tinputc \u003c- \"bar!\"\n\n\t// Wait for result\n\tselect {\n\tcase \u003c-done:\n\t\tfmt.Print(\"\\ngot result!\\n\")\n\tcase \u003c-time.After(time.Second):\n\t\tfmt.Print(\"oh no! no result! timeout!\\n\")\n\t}\n\n\t// Inspect stdout\n\tfmt.Printf(\"\\nstdout:\\n%+v\\n\", stdout.String())\n}\n// https://play.golang.org/p/fO6yo1r77ym\n\npackage main\n\nimport (\n\t\"bufio\"\n\t\"fmt\"\n\t\"io\"\n\t\"strings\"\n)\n\nfunc input(r io.Reader) (string, error) {\n\ts := bufio.NewScanner(r)\n\tfor {\n\t\tif ok := s.Scan(); !ok {\n\t\t\treturn \"\", s.Err()\n\t\t}\n\t\tline := strings.TrimSpace(s.Text())\n\t\treturn line, nil\n\t}\n}\n\ntype inputWrapper struct {\n\t*bufio.Scanner\n\treused *strings.Reader\n}\n\nfunc (i inputWrapper) More() (string, error) {\n\tif !i.Scanner.Scan() {\n\t\treturn \"\", i.Scanner.Err()\n\t}\n\tline := i.Scanner.Text()\n\tif i.reused == nil {\n\t\ti.reused = strings.NewReader(line)\n\t}\n\ti.reused.Reset(line)\n\treturn input(i.reused)\n}\n\nfunc main() {\n\n\tr := strings.NewReader(\"example.com\\ngoogle.com\")\n\tinput := inputWrapper{Scanner: bufio.NewScanner(r)}.More\n\n\tfmt.Println(input())\n\tfmt.Println(input())\n}\n","tags":"#go #tty"},{"id":"d2542276df2302d2e7a0475e6d58e816","title":"Shell: xarg examples ","content":"seq 10 | xargs -t -I % -n 2 -p echo \"foo % bar % baz % qux % qiz %\"\n\n# -t prints what would be executed\n# -I lets you choose a character to act as a placeholder for input (commonly {} is used, but % looks nicer and fits programming syntax)\n#    otherwise input is _appended_ to the end of the command\n# -n works only if -I isnt' provided and controls how many lines of input are passed to the 'utility' to be executed (e.g. the echo command)\n#    for example: `seq 5 | xargs -n 2` would print `1 2` on one line, then `3 4` on the next line, then finally `5`\n# -p prompts you to confirm if the command should be executed (if set, then you don't also need -t)\n#\n# Also, the performance of using xargs to remove/rename files is magnitudes faster than `find` with the `-exec` flag!\n","tags":"#xargs #bash #shell"},{"id":"2d04049c8d13189f0893e5b295d30daa","title":"Rust: setup toolchain environment ","content":"The default toolchain in rust is \"stable\".\n\nA user can execute `rustup override set \u003ctoolchain\u003e` to change the default toolchain (e.g. to \"nightly\" or a specific toolchain version installed using `rustup toolchain install \u003ctoolchain\u003e`), and this will be reflected when running either `rustup show active-toolchain` or `rustc --version` (i.e. either of those latter commands will show the version set to be the same as the specified override). The `rustup override set` command also takes priority over anything set within a `rust-toolchain` file:\n\n```toml\n[toolchain]\nchannel = \"stable\" # \u003c\u003c this would be overridden by `rustup override set \u003ctoolchain\u003e`\ntargets = [ \"wasm32-wasi\" ]\n```\n\n\u003e **NOTE**: The behaviour triggered by `rustup default \u003ctoolchain\u003e` is also reflected in the output of `rustup show active-toolchain` and `rustc --version`, but (unlike `rustup override set`) the behaviour concedes to whatever is defined inside the `rust-toolchain` file.\n\nAdditionally the `cargo build` command can accept a `+\u003ctoolchain\u003e` indicator (e.g. `cargo +1.54.0 build`) and that can override any of the prior behaviours I've covered.\n\nHere are some useful commands for understanding the rust environment:\n\n- `rustup show` (combines a bunch of the below data into a 'summary' view)\n- `rustup default`\n- `rustup show active-toolchain`\n- `rustup override list`\n- `rustup toolchain list`\n- `rustup target list --installed --toolchain \u003ctoolchain\u003e`\n- `rustup target add \u003ctarget\u003e --toolchain \u003ctoolchain\u003e`\n- `rustup update \u003ctoolchain\u003e` (e.g. update what 'stable' refers to †)\n- `rustc --print sysroot`\n- `ls -la $(rustc --print sysroot)/lib/rustlib` (check for installed targets like `wasm32-wasi`)\n\n\u003e † Which is different to any specific toolchain that has been manually installed (using `rustup toolchain install \u003ctoolchain\u003e`) and then set to be the default using `rustup default \u003ctoolchain\u003e`.\n\nRefer to https://rust-lang.github.io/rustup/concepts/toolchains.html for more information on the toolchain specification.\n","tags":"#rust #rustlang #environment #overrides #toolchain"},{"id":"8c0140da58fd6575373f6f1d98367170","title":"Go: difference between URL host and Request Header Host ","content":"The `r.URL` field is created by parsing the HTTP request URI.\n\nThe `r.Host` field is the value of the `Host` request header. It's the same value as calling `r.Header.Get(\"Host\")`.\n\nIf the HTTP request on the wire is:\n\n```\nGET /pub/WWW/TheProject.html HTTP/1.1\nHost: www.example.org:8080\n```\n\n...then `r.URL.Host` is `\"\"` and `r.Host` is `www.example.org:8080`.\n\nThe value of `r.URL.Host` and `r.Host` are almost always different. \n\nOn a proxy server, `r.URL.Host` is the host of the target server and `r.Host` is the host of the proxy server itself. \n\nWhen not connecting through a proxy, the client does not specify a host in the request URI. In this scenario, `r.URL.Host` is the empty string.\n\nIf you are not implementing a proxy, then you should use `r.Host` to determine the host.\n","tags":"#go #http"},{"id":"6d63e271c9301627d560b4786f629cac","title":"Writing: kbd vs code vs pre vs samp ","content":"- `\u003ckbd\u003e` represents keyboard input.\n- `\u003csamp\u003e` represents sample computer output.\n- `\u003ccode\u003e` represents programming code input as an _inline_ element. \n- `\u003cpre\u003e` represents programming code input as a _block-level_ markup.\n","tags":"#kbd #markup #render #code"},{"id":"87742ba01bb58be8b0e293b5ba3fbfd3","title":"Vim: word motion to be camelcase sensitive ","content":"function! Word()\n    \" Get cursor current position\n    let curpos = getpos(\".\")\n    \" Apply movement\n    normal! w\n    \" Get cursor potential next position\n    let wcurpos = getpos(\".\")\n    \" Return cursor to original place\n    call setpos(\".\", curpos)\n    \" Get the string between the two cursor positions\n    let line = getline(line(\".\"))\n    if curpos[1] == wcurpos[1] \" word within the same line\n            let str = line[curpos[2]-1:wcurpos[2]-1]\n    else\n            \" word motion goes to next line\n            let str = line[curpos[2]-1:]\n    endif\n    \" Look for upper case in the string\n    let m = match(str, '[A-Z]', 1)\n    \" If upper case letter found\n    if m \u003e= 1\n            exec \"normal \". m .\"l\"\n    else\n            \" else just move as normal\n            normal! w\n    endif\nendfunction\n\nnnoremap w :call Word()\u003ccr\u003e\n","tags":"#vim #viml"},{"id":"6772c8861b1fb7dadc2a816e14e1fdf9","title":"Go: API JSON with empy vs null fields issues ","content":"\u003e Reference: https://willnorris.com/2014/05/go-rest-apis-and-pointers/\n\nIf a struct field isn't populated, and is marshalled to JSON, then the field's zero value will be used (e.g. type string zero value == \"\", type int zero value == 0).\n\nYou can use `omitempty` to prevent the field from being marshalled, but then you won't know if the zero value was intentional or not (e.g. a user might _want_ to set an type int field to zero or a type string field to an empty string).\n\nTo avoid that situation you need to have the field be set to a _pointer_ of the type. This is because the zero value for a pointer is `nil`. This means if the field is `nil` then the field was never set but if it looks like a zero value for the type being pointed to, then you know it was set to the zero value intentionally.\npackage main\n\nimport (\n\t\"encoding/json\"\n)\n\ntype Repository struct {\n\tName        *string `json:\"name,omitempty\"`\n\tDescription *string `json:\"description,omitempty\"`\n\tPrivate     *bool   `json:\"private,omitempty\"`\n}\n\nfunc (r *Repository) MarshalJSON() ([]byte, error) {\n\ttype CustomRepository struct {\n\t\tName        any `json:\"name,omitempty\"`\n\t\tDescription any `json:\"description,omitempty\"`\n\t\tPrivate     any `json:\"private,omitempty\"`\n\t}\n\n\tcr := CustomRepository{}\n\n\tif r.Name != nil \u0026\u0026 *r.Name == \"\" {\n\t\tvar name *string\n\t\tcr.Name = name\n\t} else if r.Name == nil {\n\t\t// This handles the case where you want the field omitted from the JSON response completely\n\t} else {\n\t\tcr.Name = r.Name\n\t}\n\n\tif r.Description != nil \u0026\u0026 *r.Description == \"\" {\n\t\tvar description *string\n\t\tcr.Description = description\n\t} else if r.Description == nil {\n\t\t// This handles the case where you want the field omitted from the JSON response completely\n\t} else {\n\t\tcr.Description = r.Description\n\t}\n\n\tif r.Private != nil \u0026\u0026 *r.Private == false {\n\t\tvar private *bool\n\t\tcr.Private = private\n\t} else if r.Private == nil {\n\t\t// This handles the case where you want the field omitted from the JSON response completely\n\t} else {\n\t\tcr.Private = r.Private\n\t}\n\n\treturn json.Marshal(cr)\n}\n\nfunc main() {\n\tname := \"\"\n\tdescription := \"\"\n\tprivate := false\n\n\t// Explicitly set name to be a pointer to an empty string (e.g. I want this unset vs passing `nil` which means I've not set the field).\n\tr := \u0026Repository{Name: \u0026name}\n\tb, _ := json.Marshal(r)\n\tprintln(string(b)) // {\"name\":null}\n\n\t// Explicitly set name/description/private all to be pointers to their zero value (e.g. I want them all unset vs passing `nil` which means I've not set any of these fields).\n\tr = \u0026Repository{Name: \u0026name, Description: \u0026description, Private: \u0026private}\n\tb, _ = json.Marshal(r)\n\tprintln(string(b)) // {\"name\":null,\"description\":null,\"private\":null} \u003c\u003c\u003c ISSUE: how do we make this work for someone who WANTS to set a bool type to `false` (rather than turn it to `null`)\n\n\t// Explicitly set actual values (e.g. I want these fields to be set to these values, not unset)\n\tname = \"foo\"\n\tdescription = \"bar\"\n\tprivate = true\n\tr = \u0026Repository{Name: \u0026name, Description: \u0026description, Private: \u0026private}\n\tb, _ = json.Marshal(r)\n\tprintln(string(b)) // {\"name\":\"foo\",\"description\":\"bar\",\"private\":true}\n\n\t// Explicitly set nothing\n\tr = \u0026Repository{}\n\tb, _ = json.Marshal(r)\n\tprintln(string(b)) // {}\n}\n// We use pointers to avoid a `null` being coerced into a type's zero value.\n// e.g. `Bar` would otherwise contain an \"\" when, for something like Terraform, we need to know if it was set at all.\npackage main\n\nimport (\n\t\"encoding/json\"\n\t\"fmt\"\n\t\"log\"\n\t\"strings\"\n)\n\ntype Response struct {\n\tFoo *int    `json:\"foo\"`\n\tBar *string `json:\"bar\"`\n}\n\nfunc main() {\n\tresp := strings.NewReader(`{\"foo\": 123, \"bar\": null}`)\n\tvar r *Response\n\tif err := json.NewDecoder(resp).Decode(\u0026r); err != nil {\n\t\tlog.Fatal(err)\n\t}\n\tfmt.Printf(\"%#v\\n\", r)\n\tfmt.Printf(\"%d\\n\", *r.Foo)\n\tfmt.Printf(\"%s\\n\", *r.Bar) // panic: runtime error: invalid memory address or nil pointer dereference\n}\n","tags":"#go #json #api"},{"id":"bfa2372133bf8297072eeb6621ffd290","title":"Go: Understanding AST parser ","content":"Use http://goast.yuroyoro.net/ to parse some go code and then you can use that output to help visually inform your own go code that uses the `ast` package https://pkg.go.dev/go/ast@go1.17.2 \n","tags":"#AST"},{"id":"ec8ec475cc168620355bdca28d928e56","title":"PHP: setup Composer with local code ","content":"## Install Composer\n- macOS comes with php version 7.3.24\n- Download composer ([instructions](https://getcomposer.org/download/)) and move binary to your `$PATH`\n- Create a new project directory (e.g. `~/path/to/your/code/project`)\n- Run `$ composer init` and select the 'project' package type.\n\n### Debugging\n\nFor debugging use https://github.com/tacnoman/dephpugger (e.g. `composer require tacnoman/dephpugger`). \n\nYou'll need `xdebug` too, which has to be installed via `pecl` and _that_ is only available on PHP when installed via macOS Homebrew. \n\nAlso, with latest version of xdebug you'll find some properties have been updated and so until there is a newer version of dephpugger that supports xdebug 3 you'll have to manually update `vendor/tacnoman/dephpugger/src/Dephpug/Console/CliCommand.php` with renamed fields (see https://xdebug.org/docs/errors#CFG-C-CHANGED and the upgrade guide for details).\n\nThe summary of those changes being:\n\n```diff\n- $command = \"{$configVar} {$phpPath} -dxdebug.remote_enable=1 -dxdebug.remote_mode=req -dxdebug.remote_port={$debuggerPort} -dxdebug.remote_host=127.0.0.1 {$phpFile}\";\n+ $command = \"{$configVar} {$phpPath} -dxdebug.mode=debug -dxdebug.start_with_request=trigger -dxdebug.client_port={$debuggerPort} -dxdebug.client_host=127.0.0.1 {$phpFile}\";\n```\n\nNow you can open three shells:\n\n1. In your code add `xdebug_break();` where necessary.\n2. Start the debugger server: `$ php vendor/bin/dephpugger debugger`.\n3. Run your code using the debugger's `cli` client: `$ php vendor/bin/dephpugger cli main.php`.\n\n## Set local code as a project dependency\n\n```bash\n$ cd ~/path/to/local/package\n$ git init\n$ echo -e \"vendor\\ncomposer.lock\" \u003e .gitignore\n$ git add ./\n$ git commit -m \"Initial Commit\"\n```\n\nEnsure the local package's `composer.json` file has a `name` key defined with an appropriate value, as you'll need to reference that shortly.\n\nNow go back to your project directory and update the `composer.json` to reference the local package code as a dependency:\n\n```json\n{\n    …\n    \"require\": {\n        \"foo/bar\": \"dev-main\"\n    },\n    \"repositories\": [{\n        \"type\": \"vcs\",\n        \"url\": \"/path/to/local/package\"\n    }]\n}\n```\n\n\u003e **NOTE**: The `dev-` prefix inside the `require` block denotes a development branch, where typically a semver value (like `1.0.0`) would otherwise be required.\n","tags":"#php #composer #local"},{"id":"deb63f56bb6178493b0b378d89030cb9","title":"Go: recursive function ","content":"package main\n\nimport (\n\t\"fmt\"\n)\n\nfunc recurse(n int) string {\n\tif n == 0 {\n\t\treturn fmt.Sprintf(\"done: %d\", n)\n\t}\n\tfmt.Println(n)\n\treturn recurse(n - 1)\n}\n\nfunc main() {\n\tfmt.Println(recurse(3))\n\tfmt.Println(recurse(2))\n\tfmt.Println(recurse(1))\n\tfmt.Println(recurse(0))\n}\n\n// Here is a real world example using recursion to simplify the tree style traversal of a complex map.\n//\n// In this example `segs` is a slice of CLI arguments (e.g. `foo bar baz`) and we have a nested map data structure that's built around these arguments. We want to get to the nested map assigned to `baz`.\n//\n// NOTE: Each recursive call not only decrements the `n` counter but also removes the previous CLI arg so `segs` becomes shorter on each iteration.\nfunc recurse(n int, segs []string, c commands) commands {\n\tif n == 0 {\n\t\treturn c\n\t}\n\tdata, ok := c[segs[0]]\n\tif ok {\n\t\tdata, ok := data.(map[string]interface{})\n\t\tif ok {\n\t\t\treturn recurse(n-1, segs[1:], data)\n\t\t}\n\t}\n\treturn nil\n}\n","tags":"#go #recursive"},{"id":"06d2d5f896a3939ce208f37f2c2c2d05","title":"Go: Replace Makefile with Taskfile ","content":"# https://taskfile.dev\n\nversion: '3'\n\nenv:\n  GO111MODULE: on\n  GOPROXY: https://proxy.golang.org,direct\n\nvars:\n  DOCKER: '{{default \"docker\" .DOCKER}}'\n\ntasks:\n  dev:\n    desc: Setup pre-commit\n    cmds:\n      - cp -f scripts/pre-commit.sh .git/hooks/pre-commit\n\n  setup:\n    desc: Install dependencies\n    cmds:\n      - go mod tidy\n\n  build:\n    desc: Build the binary\n    cmds:\n      - go build\n\n  test:\n    desc: Run tests\n    env:\n      LC_ALL: C\n    vars:\n      TEST_OPTIONS: '{{default \"\" .TEST_OPTIONS}}'\n      SOURCE_FILES: '{{default \"./...\" .TEST_OPTIONS}}'\n      TEST_PATTERN: '{{default \".\" .TEST_PATTERN}}'\n    cmds:\n      - go test {{.TEST_OPTIONS}} -failfast -race -coverpkg=./... -covermode=atomic -coverprofile=coverage.txt {{.SOURCE_FILES}} -run {{.TEST_PATTERN}} -timeout=5m\n\n  cover:\n    desc: Run all the tests and opens the coverage report\n    cmds:\n      - go tool cover -html=coverage.txt\n\n  fmt:\n    desc: gofmt and goimports all go files\n    cmds:\n      - gofumpt -w -l -s .\n\n  ci:\n    desc: Run all the tests and code checks\n    deps: [build test]\n\n  imgs:\n    desc: Download and resize images\n    cmds:\n      - wget -O www/docs/static/logo.png https://github.com/goreleaser/artwork/raw/master/goreleaserfundo.png\n      - wget -O www/docs/static/card.png \"https://og.caarlos0.dev/**GoReleaser**%20%7C%20Deliver%20Go%20binaries%20as%20fast%20and%20easily%20as%20possible.png?theme=light\u0026md=1\u0026fontSize=80px\u0026images=https://github.com/goreleaser.png\"\n      - wget -O www/docs/static/avatar.png https://github.com/goreleaser.png\n      - convert www/docs/static/avatar.png -define icon:auto-resize=64,48,32,16 docs/static/favicon.ico\n      - convert www/docs/static/avatar.png -resize x120 www/docs/static/apple-touch-icon.png\n\n  docs:serve:\n    desc: Start documentation server\n    cmds:\n      - '{{.DOCKER}} run --rm -it -p 8000:8000 -v ${PWD}/www:/docs docker.io/squidfunk/mkdocs-material'\n\n  docs:build:\n    desc: Build documentation\n    cmds:\n      - yum install -y jq\n      - pip install mkdocs-material mkdocs-minify-plugin lunr\n      - ./scripts/get-releases.sh\n      - (cd www \u0026\u0026 mkdocs build)\n\n  todo:\n    desc: Show to-do items per file\n    silent: true\n    cmds:\n      - grep --exclude-dir=vendor --exclude-dir=node_modules --exclude=Makefile --text --color -nRo -E ' TODO:.*|SkipNow' .\n","tags":"#go #build"},{"id":"b78bcff09166a8dea9cabfcd7af96383","title":"Go: sharing behaviours between individual structs and a base struct ","content":"package main\n\nimport (\n\t\"fmt\"\n)\n\ntype JavaScript struct {\n\tpostProcessing bool\n\ttoolchain      string\n}\n\nfunc (j JavaScript) Validate() {\n\tfmt.Printf(\"validating with %s\\n\", j.toolchain)\n\n\tif j.postProcessing {\n\t\tfmt.Println(\"post processing\")\n\t}\n}\n\nfunc (j JavaScript) Build() {\n\tfmt.Printf(\"do our own JavaScript thing with %s\\n\", j.toolchain)\n}\n\nfunc (j *JavaScript) Toolchain(toolchain string) {\n\tj.toolchain = toolchain\n}\n\ntype AssemblyScript struct {\n\tJavaScript\n}\n\nfunc (a AssemblyScript) Build() {\n\tfmt.Printf(\"do our own AssemblyScript thing with %s\\n\", a.toolchain)\n}\n\nfunc main() {\n\tjs := JavaScript{true, \"yarn\"}\n\tjs.Validate() // validating with yarn + post processing\n\tjs.Build()    // do our own JavaScript thing with yarn\n\n\tas := AssemblyScript{JavaScript{false, \"npm\"}}\n\tas.Validate() // validating with npm\n\tas.Build()    // do our own AssemblyScript thing with npm\n\n\tas2 := AssemblyScript{JavaScript{false, \"npm\"}}\n\tas2.Toolchain(\"beepboop\")\n\tas2.Validate() // validating with beepboop\n\tas2.Build()    // do our own AssemblyScript thing with beepboop\n}\n","tags":"#go #principles"},{"id":"0500e6b5aabf95034cd83eff8c9e2ead","title":"Shell: autocomplete for your custom programs ","content":"Here's an example taken from the https://github.com/fastly/cli\n\n```bash\n_fastly_bash_autocomplete() {\n    local cur prev opts base\n    COMPREPLY=()\n    cur=\"${COMP_WORDS[COMP_CWORD]}\"\n    opts=$( ${COMP_WORDS[0]} --completion-bash ${COMP_WORDS[@]:1:$COMP_CWORD} )\n    COMPREPLY=( $(compgen -W \"${opts}\" -- ${cur}) )\n    return 0\n}\ncomplete -F _fastly_bash_autocomplete fastly\n```\n\nNotice the last line is what sets up the bash autocomplete and says whenever the user types `fastly` and then `\u003cTab\u003e` to call the shell function `_fastly_bash_autocomplete`.\n\nThat function then sets an environment variable `COMPREPLY` to contain a list of values that should be returned to the user.\n\nThat list is generated by evaluating a separate command called `compgen` and passing it the list of available options to present to the user.\n\nThe available opts are stored in the local variable `opts` and that is produced by executing the `fastly` binary (i.e. `${COMP_WORDS[0]}`) and passing it a flag that the binary knows how to handle (i.e. `--completion-bash`).\nOne of the nicest facilities of the modern shell is the built in \"completion\" support. These facilities allow you to complete commands and their arguments easily. Read on for a brief introduction to adding your own command completions.\n\nMost shells allow command completion, typically bound to the TAB key, which allow you to complete the names of commands stored upon your PATH, file names, or directory names. This is typically used like so:\n\n```\nls /bo[TAB]\n```\n\nWhen you press the TAB key the argument /bo is automatically replaced with the value /boot.\n\nRecently some shells have started allowing you to do even more: completing arguments to commands. Two notable shells which allow this are zsh, and bash. Since I'm a bash user I'm only going to cover that.\n\nThe Debian bash package supplies a command line completion file /etc/bash_completion which sets up some common support.\n\nIf you're not using it right now you can load it by typing into your shell \". /etc/bash_completion\" as shown here:\n\n```\nskx@lappy:~$ . /etc/bash_completion\nskx@lappy:~$\n```\n\nOnce this is done you'll be able to TAB-complete many common arguments to programs, for example:\n\n```\nskx@lappy:~$ apt-get upd[TAB]\nskx@lappy:~$ apt-get upg[TAB]\n```\n\nBut how do you extend the support yourself? Well the completion routines supplied make use of several internal bash commands such as complete. These can be used by your own shell startup files, or more easily by creating a small file and dropping it into the directory /etc/bash_completion.d/.\n\nWhen the bash_completion file is sourced (or loaded) everything inside the /etc/bash_completion.d directory is also loaded. This makes it a simple matter to add your own hooks.\n\nOne of the things which bash allows you to complete is hostnames, this can be very useful for some commands.\n\nI remotely manage some computers using VNC and I usually do that by running the command \"xvncviewer hostname\".\n\nTo allow bash to complete the hostname fragment I type with we'll use the complete command to tell it that xvncviewer requires a hostname:\n\n```\nskx@lappy:~$ complete -F _known_hosts xvncviewer\n\nOnce I've done this I can type [TAB] to complete hostnames:\n\nskx@lappy:~$ xvncviewer s[TAB]\nsavannah.gnu.org            ssh.tardis.ed.ac.uk\nscratchy                    steve.org.uk\nsecurity.debian.org         security-master.debian.org\nsun\nskx@lappy:~$ xvncviewer sc[TAB]\n```\n\nThis has now completed the hostname scratchy for me.\n\nThe function _known_hosts is defined in the file /etc/bash_completion. How did I know I could use it? By using the command \"complete -p\" to display all of the bindings in use:\n\n```\nskx@lappy:~$ complete -p\n....\ncomplete -F _known_hosts tracepath6\ncomplete -F _known_hosts host\n...\n```\n\nSo what have we learnt so far?\n\n    Command line completion exists.\n    Completion is implemented in the file /etc/bash_completion\n    New completion commands may be placed inside the directory /etc/bash_completion.d\n    We can list all the current completion routines bound via \"complete -p\"\n\nIn part two we'll look at defining custom command line handling routines - similar to those already in place. So we can add command line completion to our own programs, or commands not yet covered.\n\nUntil then you might want to experiment a little yourself.\n","tags":"#bash #shell #autocomplete"},{"id":"9b02493b0b2d54eeea0183c28edab2d1","title":"Network: BGP Debugging Tools ","content":"\u003e Reference: https://jvns.ca/blog/2021/10/05/tools-to-look-at-bgp-routes/\n\n- **BGP View**: https://bgpview.io/asn/AS54113 (Fastly's ASN).\n- **BGP Play**: https://stat.ripe.net/special/bgplay (replay BGP events/announcements).\n\nCLI tools:\n\n- `mtr -z \u003chost\u003e`: https://github.com/traviscross/mtr\n- `traceroute -a \u003chost\u003e`: a basic built-in tool\n- `route get \u003chost\u003e`: a basic built-in tool to lookup and display the route for a destination\n- `dig \u003chost\u003e`: a basic built-in tool to lookup and display the route for a destination\n\n\u003e NOTE: For `mtr` see [the comment thread](https://github.com/traviscross/mtr/issues/387#issuecomment-942348598) for setting up `sudo` rights.\n","tags":"#bgp #network"},{"id":"685d23c8e8ced3afb1a4e4546f2933d6","title":"Go: CLI progress spinner ","content":"package text\n\nimport (\n\t\"bytes\"\n\t\"context\"\n\t\"encoding/hex\"\n\t\"fmt\"\n\t\"io\"\n\t\"os\"\n\t\"runtime\"\n\t\"strings\"\n\t\"sync\"\n\t\"time\"\n\t\"unicode/utf8\"\n\n\t\"github.com/mattn/go-isatty\"\n)\n\n// Progress is a producer contract, abstracting over the quiet and verbose\n// Progress types. Consumers may use a Progress value in their code, and assign\n// it based on the presence of a -v, --verbose flag. Callers are expected to\n// call Step for each new major step of their procedural code, and Write with\n// the verbose or detailed output of those steps. Callers must eventually call\n// either Done or Fail, to signal success or failure respectively.\ntype Progress interface {\n\tio.Writer\n\tTick(rune)\n\tStep(string)\n\tDone()\n\tFail()\n}\n\n// NewProgress returns a Progress based on the given verbosity level or whether\n// the current process is running in a terminal environment.\nfunc NewProgress(output io.Writer, verbose bool) Progress {\n\tvar progress Progress\n\tif verbose {\n\t\tprogress = NewVerboseProgress(output)\n\t} else if isatty.IsTerminal(os.Stdout.Fd()) || isatty.IsCygwinTerminal(os.Stdout.Fd()) {\n\t\tprogress = NewInteractiveProgress(output)\n\t} else {\n\t\tprogress = NewQuietProgress(output)\n\t}\n\treturn progress\n}\n\n// Ticker is a small consumer contract for the Spin function,\n// capturing part of the Progress interface.\ntype Ticker interface {\n\tTick(r rune)\n}\n\n// Spin calls Tick on the target with the relevant frame every interval. It\n// returns when context is canceled, so should be called in its own goroutine.\nfunc Spin(ctx context.Context, frames []rune, interval time.Duration, target Ticker) error {\n\tvar (\n\t\tcursor = 0\n\t\tticker = time.NewTicker(interval)\n\t)\n\tdefer ticker.Stop()\n\tfor {\n\t\tselect {\n\t\tcase \u003c-ticker.C:\n\t\t\ttarget.Tick(frames[cursor])\n\t\t\tcursor = (cursor + 1) % len(frames)\n\t\tcase \u003c-ctx.Done():\n\t\t\treturn ctx.Err()\n\t\t}\n\t}\n}\n\n// InteractiveProgress is an implementation of Progress that includes a spinner at the\n// beginning of each Step, and where newline-delimited lines written via Write\n// overwrite the current step line in the output.\ntype InteractiveProgress struct {\n\tmtx    sync.Mutex\n\toutput io.Writer\n\n\tstepHeader     string       // title of current step\n\twriteBuffer    bytes.Buffer // receives Write calls\n\tlastBufferLine string       // last full line in writeBuffer\n\tcurrentOutput  string       // the content of the current line displayed to user\n\n\tcancel func()          // tell Spin to stop\n\tdone   \u003c-chan struct{} // wait for Spin to stop\n}\n\n// NewInteractiveProgress returns a InteractiveProgress outputting to the writer.\nfunc NewInteractiveProgress(output io.Writer) *InteractiveProgress {\n\tp := \u0026InteractiveProgress{\n\t\toutput:     output,\n\t\tstepHeader: \"Initializing...\",\n\t}\n\n\tvar (\n\t\tctx, cancel = context.WithCancel(context.Background())\n\t\tdone        = make(chan struct{})\n\t)\n\tgo func() {\n\t\tSpin(ctx, []rune{'-', '\\\\', '|', '/'}, 100*time.Millisecond, p)\n\t\tclose(done)\n\t}()\n\tp.cancel = cancel\n\tp.done = done\n\n\treturn p\n}\n\nfunc (p *InteractiveProgress) replaceLine(format string, args ...interface{}) {\n\t// Clear the current line.\n\tn := utf8.RuneCountInString(p.currentOutput)\n\tswitch runtime.GOOS {\n\tcase \"windows\":\n\t\tfmt.Fprintf(p.output, \"%s\\r\", strings.Repeat(\" \", n))\n\tdefault:\n\t\tdel, _ := hex.DecodeString(\"7f\")\n\t\tsequence := fmt.Sprintf(\"\\b%s\\b\\033[K\", del)\n\t\tfmt.Fprintf(p.output, \"%s\\r\", strings.Repeat(sequence, n))\n\t}\n\n\t// Generate the new line.\n\ts := fmt.Sprintf(format, args...)\n\tp.currentOutput = s\n\tfmt.Fprint(p.output, p.currentOutput)\n}\n\nfunc (p *InteractiveProgress) getStatus() string {\n\tif p.lastBufferLine != \"\" {\n\t\treturn p.lastBufferLine // takes precedence\n\t}\n\treturn p.stepHeader\n}\n\n// Tick implements the Progress interface.\nfunc (p *InteractiveProgress) Tick(r rune) {\n\tp.mtx.Lock()\n\tdefer p.mtx.Unlock()\n\n\tp.replaceLine(\"%s %s\", string(r), p.getStatus())\n}\n\n// Write implements the Progress interface, emitting each incoming byte slice\n// to the internal buffer to be written to the terminal on the next tick.\nfunc (p *InteractiveProgress) Write(buf []byte) (int, error) {\n\tp.mtx.Lock()\n\tdefer p.mtx.Unlock()\n\n\tp.writeBuffer.Write(buf)\n\tp.lastBufferLine = LastFullLine(p.writeBuffer.String())\n\n\treturn len(buf), nil\n}\n\n// Step implements the Progress interface.\nfunc (p *InteractiveProgress) Step(msg string) {\n\tmsg = strings.TrimSpace(msg)\n\n\tp.mtx.Lock()\n\tdefer p.mtx.Unlock()\n\n\t// Previous step complete.\n\tp.replaceLine(\"%s %s\", Bold(\"✓\"), p.stepHeader)\n\tfmt.Fprintln(p.output)\n\n\t// Reset all the stepwise state.\n\tp.stepHeader = msg\n\tp.writeBuffer.Reset()\n\tp.lastBufferLine = \"\"\n\tp.currentOutput = \"\"\n\n\t// New step beginning.\n\tp.replaceLine(\"%s %s\", Bold(\"·\"), p.stepHeader)\n}\n\n// Done implements the Progress interface.\nfunc (p *InteractiveProgress) Done() {\n\t// It's important to cancel the Spin goroutine before taking the lock,\n\t// because otherwise it's possible to generate a deadlock if the output\n\t// io.Writer is also synchronized.\n\tp.cancel()\n\t\u003c-p.done\n\n\tp.mtx.Lock()\n\tdefer p.mtx.Unlock()\n\n\tp.replaceLine(\"%s %s\", Bold(\"✓\"), p.stepHeader)\n\tfmt.Fprintln(p.output)\n}\n\n// Fail implements the Progress interface.\nfunc (p *InteractiveProgress) Fail() {\n\tp.cancel()\n\t\u003c-p.done\n\n\tp.mtx.Lock()\n\tdefer p.mtx.Unlock()\n\n\tp.replaceLine(\"%s %s\", Bold(\"✗\"), p.stepHeader)\n\tfmt.Fprintln(p.output)\n}\n\n// LastFullLine returns the last full \\n delimited line in s. That is, s must\n// contain at least one \\n for LastFullLine to return anything.\nfunc LastFullLine(s string) string {\n\tlast := strings.LastIndex(s, \"\\n\")\n\tif last \u003c 0 {\n\t\treturn \"\"\n\t}\n\n\tprev := strings.LastIndex(s[:last], \"\\n\")\n\tif prev \u003c 0 {\n\t\tprev = 0\n\t}\n\n\treturn strings.TrimSpace(s[prev:last])\n}\n\n//\n//\n//\n\n// QuietProgress is an implementation of Progress that attempts to be quiet in\n// it's output. I.e. it only prints each Step as it progresses and discards any\n// intermediary writes between steps. No spinners are used, therefore it's\n// useful for non-TTY environiments, such as CI.\ntype QuietProgress struct {\n\toutput     io.Writer\n\tnullWriter io.Writer\n}\n\n// NewQuietProgress returns a QuietProgress outputting to the writer.\nfunc NewQuietProgress(output io.Writer) *QuietProgress {\n\tqp := \u0026QuietProgress{\n\t\toutput:     output,\n\t\tnullWriter: io.Discard,\n\t}\n\tqp.Step(\"Initializing...\")\n\treturn qp\n}\n\n// Tick implements the Progress interface. It's a no-op.\nfunc (p *QuietProgress) Tick(r rune) {}\n\n// Tick implements the Progress interface.\nfunc (p *QuietProgress) Write(buf []byte) (int, error) {\n\treturn p.nullWriter.Write(buf)\n}\n\n// Step implements the Progress interface.\nfunc (p *QuietProgress) Step(msg string) {\n\tfmt.Fprintln(p.output, strings.TrimSpace(msg))\n}\n\n// Done implements the Progress interface. It's a no-op.\nfunc (p *QuietProgress) Done() {}\n\n// Fail implements the Progress interface. It's a no-op.\nfunc (p *QuietProgress) Fail() {}\n\n//\n//\n//\n\n// VerboseProgress is an implementation of Progress that treats Step and Write\n// more or less the same: it simply pipes all output to the provided Writer. No\n// spinners are used.\ntype VerboseProgress struct {\n\toutput io.Writer\n}\n\n// NewVerboseProgress returns a VerboseProgress outputting to the writer.\nfunc NewVerboseProgress(output io.Writer) *VerboseProgress {\n\treturn \u0026VerboseProgress{\n\t\toutput: output,\n\t}\n}\n\n// Tick implements the Progress interface. It's a no-op.\nfunc (p *VerboseProgress) Tick(r rune) {}\n\n// Tick implements the Progress interface.\nfunc (p *VerboseProgress) Write(buf []byte) (int, error) {\n\treturn p.output.Write(buf)\n}\n\n// Step implements the Progress interface.\nfunc (p *VerboseProgress) Step(msg string) {\n\tfmt.Fprintln(p.output, strings.TrimSpace(msg))\n}\n\n// Done implements the Progress interface. It's a no-op.\nfunc (p *VerboseProgress) Done() {}\n\n// Fail implements the Progress interface. It's a no-op.\nfunc (p *VerboseProgress) Fail() {}\n\n//\n//\n//\n\n// NullProgress is an implementation of Progress which discards everything\n// written into it and produces no output.\ntype NullProgress struct {\n\toutput io.Writer\n}\n\n// NewNullProgress returns a NullProgress.\nfunc NewNullProgress() *NullProgress {\n\treturn \u0026NullProgress{\n\t\toutput: io.Discard,\n\t}\n}\n\n// Tick implements the Progress interface. It's a no-opt\nfunc (p *NullProgress) Tick(r rune) {}\n\n// Tick implements the Progress interface.\nfunc (p *NullProgress) Write(buf []byte) (int, error) {\n\treturn p.output.Write(buf)\n}\n\n// Step implements the Progress interface.\nfunc (p *NullProgress) Step(msg string) {}\n\n// Done implements the Progress interface. It's a no-op.\nfunc (p *NullProgress) Done() {}\n\n// Fail implements the Progress interface. It's a no-op.\nfunc (p *NullProgress) Fail() {}\n","tags":"#go #tty"},{"id":"858a88f5925a10aa71c4db78863958a3","title":"Go: form encoding with various packages ","content":"package main\n\nimport (\n\t\"fmt\"\n\t\"net/url\"\n\n\t\"github.com/hetiansu5/urlquery\"\n)\n\n// An OptionData is test structure\ntype OptionData struct {\n\tServices []string `query:\"services,omitempty\"`\n\tTeeP     *T       `query:\"tp,omitempty\"`\n\tTee      T        `query:\"t,omitempty\"`\n\tInt      int      `query:\"integer,omitempty\"`\n}\n\n// A SelfQueryEncoder is test structure\ntype SelfQueryEncoder struct{}\n\n// Escape is test func\nfunc (u SelfQueryEncoder) Escape(s string) string {\n\tfmt.Println(\"Escape\", s)\n\treturn url.QueryEscape(s)\n}\n\n// UnEscape is test func\nfunc (u SelfQueryEncoder) UnEscape(s string) (string, error) {\n\tfmt.Println(\"UnEscape\", s)\n\treturn url.QueryUnescape(s)\n}\n\ntype T bool\n\nfunc marshal(data OptionData) {\n\tfmt.Printf(\"%+v\\n\", data)\n\n\tbuilder := urlquery.NewEncoder(\n\t\turlquery.WithNeedEmptyValue(true),\n\t\turlquery.WithQueryEncoder(SelfQueryEncoder{}))\n\tbytes, err := builder.Marshal(data)\n\tif err != nil {\n\t\tfmt.Println(err)\n\t\treturn\n\t}\n\tu, _ := url.QueryUnescape(string(bytes))\n\tfmt.Println(u)\n}\n\nfunc main() {\n\tmarshal(OptionData{\n\t\tServices: []string{\n\t\t\t\"A\",\n\t\t\t\"B\",\n\t\t},\n\t})\n\n\tmarshal(OptionData{\n\t\tServices: []string{\n\t\t\t\"A\",\n\t\t\t\"B\",\n\t\t},\n\t\tInt: 123,\n\t})\n\n\tmarshal(OptionData{\n\t\tServices: []string{\n\t\t\t\"A\",\n\t\t\t\"B\",\n\t\t},\n\t\tInt: 0, // is omitted if we set WithNeedEmptyValue(true) but we don't WANT that option set because it means even if the field is not set by the user, it will have a default value set in the output\n\t})\n\n\ttp := T(true)\n\tmarshal(OptionData{\n\t\tServices: []string{\n\t\t\t\"A\",\n\t\t\t\"B\",\n\t\t},\n\t\tTeeP: \u0026tp,\n\t\tTee:  T(true),\n\t})\n\n\ttp = T(false)\n\tmarshal(OptionData{\n\t\tServices: []string{\n\t\t\t\"A\",\n\t\t\t\"B\",\n\t\t},\n\t\tTeeP: \u0026tp,\n\t\tTee:  T(false),\n\t})\n}\npackage main\n\nimport (\n\t\"bytes\"\n\t\"fmt\"\n\t\"net/url\"\n\n\t\"github.com/ajg/form\"\n\t\"github.com/google/go-querystring/query\" // NOTE: Only handles encoding, not decoding!\n\t\"github.com/gorilla/schema\"\n\t\"github.com/pasztorpisti/qs\"\n\t\"github.com/hetiansu5/urlquery\"\n)\n\ntype A struct {\n\tServices []string `form:\"services\"`\n}\n\ntype B struct {\n\tServices []string `url:\"services,brackets,omitempty\"` // needed the 'brackets' bit to make it work\n}\n\ntype C struct {\n\tServices []string `schema:\"services\"`\n}\n\ntype D struct {\n\tServices []string `qs:\"services\"`\n}\n\ntype E struct {\n\tServices []string `query:\"services\"`\n}\n\nfunc main() {\n\tfmt.Println(\"we want: services[]=A\u0026services[]=B\\n\")\n\n\tfmt.Println(\"ajg/form\")\n\ta := A{Services: []string{\"A\", \"B\"}}\n\tbuf := new(bytes.Buffer)\n\tform.NewEncoder(buf).DelimitWith('|').Encode(a)\n\tu, _ := url.QueryUnescape(buf.String())\n\tfmt.Println(\"❌\", u)\n\n\tfmt.Println(\"google/go-querystring\")\n\tb := B{Services: []string{\"A\", \"B\"}}\n\tv, _ := query.Values(b)\n\tfmt.Println(\"✅\", v.Encode())\n\tu, _ = url.QueryUnescape(v.Encode())\n\tfmt.Println(\"✅\", u)\n\n\tfmt.Println(\"gorilla/schema\")\n\tc := C{Services: []string{\"A\", \"B\"}}\n\tencoder := schema.NewEncoder()\n\tform := url.Values{}\n\tencoder.Encode(c, form)\n\tfmt.Println(\"❌\", form.Encode())\n\n\tfmt.Println(\"pasztorpisti/qs\")\n\td := D{Services: []string{\"A\", \"B\"}}\n\ts, _ := qs.Marshal(\u0026d)\n\tfmt.Println(\"❌\", s)\n\n\tfmt.Println(\"hetiansu5/urlquery\")\n\te := E{Services: []string{\"A\", \"B\"}}\n\tbytes, _ := urlquery.Marshal(e)\n\tfmt.Println(\"✅\", string(bytes))\n\tu, _ = url.QueryUnescape(string(bytes))\n\tfmt.Println(\"✅\", u)\n}\npackage main\n\nimport (\n\t\"bytes\"\n\t\"fmt\"\n\t\"net/url\"\n\n\t\"github.com/ajg/form\"\n)\n\ntype Compatibool bool\n\nfunc (b Compatibool) MarshalText() ([]byte, error) {\n\tif b {\n\t\treturn []byte(\"1\"), nil\n\t}\n\treturn []byte(\"0\"), nil\n}\n\ntype T bool\n\ntype options struct {\n\tFoo      string       `form:\"foo,omitempty\"`\n\tInt      int          `form:\"integer,omitempty\"`\n\tTeeP     *T           `form:\"tp,omitempty\"`\n\tTee      T            `form:\"t,omitempty\"`\n\tServices []string     `form:\"services,omitempty\"`\n\tCP       *Compatibool `form:\"cp,omitempty\"`\n\tC        Compatibool  `form:\"c,omitempty\"`\n}\n\nfunc TBool(b bool) *T {\n\tt := T(b)\n\treturn \u0026t\n}\n\nfunc CBool(b bool) *Compatibool {\n\tc := Compatibool(b)\n\treturn \u0026c\n}\n\nfunc main() {\n\tvar i interface{}\n\ti = options{Foo: \"b\", TeeP: TBool(true), Tee: T(true), Services: []string{\"A\", \"B\"}, CP: CBool(true), C: Compatibool(true)}\n\n\tbuf := new(bytes.Buffer)\n\tform.NewEncoder(buf).KeepZeros(true).DelimitWith('|').Encode(i)\n\tu, _ := url.QueryUnescape(buf.String())\n\tfmt.Println(u)\n\n\ti = options{Foo: \"b\", TeeP: TBool(false), Tee: T(false), Services: []string{\"A\", \"B\"}, CP: CBool(false), C: Compatibool(false)}\n\n\tbuf = new(bytes.Buffer)\n\tform.NewEncoder(buf).KeepZeros(true).DelimitWith('|').Encode(i)\n\tu, _ = url.QueryUnescape(buf.String())\n\tfmt.Println(u) // C is omitted as if it wasn't set.\n}\npackage main\n\nimport (\n\t\"fmt\"\n\t\"net/url\"\n\n\t\"github.com/google/go-querystring/query\"\n)\n\ntype T bool\n\nfunc (t T) EncodeValues(key string, v *url.Values) error {\n\tfmt.Printf(\"key: %+v, t: %+v, v: %+v\\n\", key, t, v)\n\tswitch t {\n\tcase true:\n\t\tv.Add(key, \"1\")\n\tcase false:\n\t\tv.Add(key, \"0\")\n\t}\n\treturn nil\n}\n\ntype options struct {\n\tFoo  string `url:\"foo,omitempty\"`\n\tTeeP *T     `url:\"tp,omitempty\"`\n\tTee  T      `url:\"t,omitempty\"`\n}\n\nfunc main() {\n\tfmt.Println(\"No TeeP or Tee set\")\n\tv, _ := query.Values(options{Foo: \"a\"})\n\tfmt.Printf(\"v.Encode: %+v\\n\\n\", v.Encode())\n\n\tfmt.Println(\"TeeP and Tee set to true\")\n\tt := T(true)\n\tv, _ = query.Values(options{Foo: \"b\", TeeP: \u0026t, Tee: T(true)})\n\tfmt.Printf(\"v.Encode: %+v\\n\\n\", v.Encode())\n\n\tfmt.Println(\"TeeP and Tee set to false\")\n\tt = T(false)\n\tv, _ = query.Values(options{Foo: \"c\", TeeP: \u0026t, Tee: T(false)})\n\tfmt.Printf(\"v.Encode: %+v\\n\\n\", v.Encode()) // NOTE: Tee doesn't cause EncodeValues() to be called?\n}\n\n/*\nNo TeeP or Tee set\nv.Encode: foo=a\n\nTeeP and Tee set to true\nkey: tp, t: true, v: \u0026map[foo:[b]]\nkey: t, t: true, v: \u0026map[foo:[b] tp:[1]]\nv.Encode: foo=b\u0026t=1\u0026tp=1\n\nTeeP and Tee set to false\nkey: tp, t: false, v: \u0026map[foo:[c]]\nv.Encode: foo=c\u0026tp=0\n*/\n","tags":"#go #serialization"},{"id":"7ea8e0f8bf5d958f67e4915d68f6b153","title":"Design: nice fonts ","content":"Helvetica, Arial, sans-serif\n","tags":"#fonts"},{"id":"f21d57a8fcada8d4c2ac79bece4337b4","title":"Go: Cross Compile Binary ","content":"env GOOS=darwin  GOARCH=amd64 go build -o fastly     ./cmd/fastly/main.go\nenv GOOS=windows GOARCH=amd64 go build -o fastly.exe ./cmd/fastly/main.go\n","tags":"#go #compiler #build"},{"id":"157a91212e785d7d78544314622c5c24","title":"git: --theirs and --ours ","content":"https://nitaym.github.io/ourstheirs/\n\nThe summary is: `git checkout` has the following flags whose assigned values can be very confusing.\n\n- `--ours` == `main`\n- `--theirs` == the feature branch.\n\nThe flag values don't change between `git merge` and `git rebase` (e.g. †) so it's safe to remember the above values. \n\n\u003e † `git switch main \u0026\u0026 git merge feature` vs `git switch feature \u0026\u0026 git rebase main`.\n\n## Rebase Example\n\nI typically rebase `feature` over my `main` branch:\n\n```bash\ngit switch feature\ngit pull --rebase origin main\ngit checkout --theirs \u003cfile\u003e\ngit add \u003cfile\u003e\ngit rebase --continue\n```\n","tags":"#git #rebase #merge"},{"id":"20060a9be3eafcdfd3c13c1d120bee97","title":"Go: Enums ","content":"package main\n\nimport (\n\t\"fmt\"\n)\n\n// Product is a base for the different product variants.\ntype Product int64\n\n// Implements Stringer interface so that fmt.Printf will \n// be able to to convert from int64 to string via %s format.\nfunc (p Product) String() string {\n\tswitch p {\n\tcase ProductBrotliCompression:\n\t\treturn \"brotli_compression\"\n\tcase ProductDomainInspector:\n\t\treturn \"domain_inspector\"\n\tcase ProductFanout:\n\t\treturn \"fanout\"\n\tcase ProductImageOptimizer:\n\t\treturn \"image_optimizer\"\n\tcase ProductOriginInspector:\n\t\treturn \"origin_inspector\"\n\tcase ProductWebSockets:\n\t\treturn \"websockets\"\n\t}\n\treturn \"unknown\"\n}\n\nconst (\n\tProductUndefined Product = iota\n\tProductBrotliCompression\n\tProductDomainInspector\n\tProductFanout\n\tProductImageOptimizer\n\tProductOriginInspector\n\tProductWebSockets\n)\n\n// ProductEnablementInput is used as input to the various ProductEnablement\n// functions.\ntype ProductEnablementInput struct {\n\t// ProductID is the ID of the product and is constrained by the Product type (required).\n\tProductID Product\n\t// ServiceID is the ID of the service (required).\n\tServiceID string\n}\n\n// GetProductEnablement retrieves the specified resource.\nfunc (c *Client) GetProductEnablement(i *ProductEnablementInput) (*ProductEnablement, error) {\n\tif i.ProductID == ProductUndefined {\n\t\treturn nil, ErrMissingProductID\n\t}\n\tif i.ServiceID == \"\" {\n\t\treturn nil, ErrMissingServiceID\n\t}\n\n\tpath := fmt.Sprintf(\"/enabled-products/%s/services/%s\", i.ProductID, i.ServiceID)\n\tresp, err := c.Get(path, nil)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tdefer resp.Body.Close()\n\n\tvar h *ProductEnablement\n\tif err := decodeBodyMap(resp.Body, \u0026h); err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn h, nil\n}\n","tags":"#go"},{"id":"6a33445b768888f6b9869b1516428bb3","title":"Shell: jq and yq examples ","content":"💡 [Documentation]([url](https://jqlang.org/manual/)) with interactive search for functions (_very_ useful)\n\n\u003e [The Primeagen Video](https://www.youtube.com/watch?v=n8sOmEe2SDg\u0026ab_channel=ThePrimeTime)\n\n- [Basic Examples](#basic-examples)\n- [Advanced Examples](#advanced-examples)\n\n## Basic Examples\n\nHere's some basic usage examples...\n\n```shell\n$ cat /tmp/example.json | jq\n{\n  \"foo\": \"bar\",\n  \"errors\": [\n    \"beep\"\n  ]\n}\n{\n  \"foo\": null,\n  \"errors\": [\n    \"boop\"\n  ]\n}\n{\n  \"foo\": {\n    \"a\": 1,\n    \"b\": 2\n  },\n  \"errors\": [\n    \"beep\"\n  ]\n}\n{\n  \"foo\": {\n    \"a\": 3,\n    \"b\": 4\n  },\n  \"errors\": [\n    \"beep\",\n    \"boop\"\n  ]\n}\n\n$ jq \u003c /tmp/example.json\n{\n  \"foo\": \"bar\",\n  \"errors\": [\n    \"beep\"\n  ]\n}\n{\n  \"foo\": null,\n  \"errors\": [\n    \"boop\"\n  ]\n}\n{\n  \"foo\": {\n    \"a\": 1,\n    \"b\": 2\n  },\n  \"errors\": [\n    \"beep\"\n  ]\n}\n{\n  \"foo\": {\n    \"a\": 3,\n    \"b\": 4\n  },\n  \"errors\": [\n    \"beep\",\n    \"boop\"\n  ]\n}\n\n$ jq .foo \u003c /tmp/example.json\n\"bar\"\nnull\n{\n  \"a\": 1,\n  \"b\": 2\n}\n{\n  \"a\": 3,\n  \"b\": 4\n}\n\n$ jq keys \u003c /tmp/example.json\n[\n  \"errors\",\n  \"foo\"\n]\n[\n  \"errors\",\n  \"foo\"\n]\n[\n  \"errors\",\n  \"foo\"\n]\n[\n  \"errors\",\n  \"foo\"\n]\n\n$ jq '{renamed: .foo}' \u003c /tmp/example.json\n{\n  \"renamed\": \"bar\"\n}\n{\n  \"renamed\": null\n}\n{\n  \"renamed\": {\n    \"a\": 1,\n    \"b\": 2\n  }\n}\n{\n  \"renamed\": {\n    \"a\": 3,\n    \"b\": 4\n  }\n}\n\n$ jq 'select(.foo != null) | {renamed: .foo}' \u003c /tmp/example.json\n{\n  \"renamed\": \"bar\"\n}\n{\n  \"renamed\": {\n    \"a\": 1,\n    \"b\": 2\n  }\n}\n{\n  \"renamed\": {\n    \"a\": 3,\n    \"b\": 4\n  }\n}\n\n$ jq 'select(.foo != null and (.foo | type == \"object\") and .foo.a \u003e 1) | {renamed: .foo}' \u003c /tmp/example.json\n{\n  \"renamed\": {\n    \"a\": 3,\n    \"b\": 4\n  }\n}\n\n$ jq 'select(.foo != null and (.foo | type == \"object\") and .foo.a \u003e 1 and (.errors | length \u003e 1 and any(.[]; contains(\"boop\")))) | {renamed: .foo, errs: .errors}' \u003c /tmp/example.json \n{\n  \"renamed\": {\n    \"a\": 3,\n    \"b\": 4\n  },\n  \"errs\": [\n    \"beep\",\n    \"boop\"\n  ]\n}\n```\n\nWhen opened in Neovim:\n\n```shell\n:%!jq\n:%!jq -c\n:'\u003c,'\u003e!jq\n:%!jq -c 'select(.errors | length \u003e 1)'\n```\n\n## Advanced Examples\n\nMore advanced `jq` examples...\n\n- [Extract fields from nd-json stream using interpolation syntax](#extract-fields-from-nd-json-stream-using-interpolation-syntax)\n- [Extract object from a list that is itself assigned to an object](#extract-object-from-a-list-that-is-itself-assigned-to-an-object)\n- [Download a release binary from GitHub](#download-a-release-binary-from-github)\n- [Combine multiple objects into one](#combine-multiple-objects-into-one)\n- [Complex transforming of nested data with .jq script](#complex-transforming-of-nested-data-with-jq-script)\n- [Adding new key to an object](#adding-new-key-to-an-object)\n- [List all unique keys recursively](#list-all-unique-keys-recursively)\n- [List all array items who have different values across specified keys](#list-all-array-items-who-have-different-values-across-specified-keys)\n- [List all array items who have a timeout larger than a set value](#list-all-array-items-who-have-a-timeout-larger-than-a-set-value)\n- [List all array items who have nested object key not set](#list-all-array-items-who-have-nested-object-key-not-set)\n- [Unique entries by key](#unique-entries-by-key)\n\n`yq` examples...\n\n- List all array items who have different values across specified keys\n\n## Extract fields from nd-json stream using interpolation syntax\n\nWith the following nd-json stream:\n\n```json\n{\n  \"result\": {\n    \"agent\": \"foo\",\n    \"count\": \"80\",\n  }\n}\n{\n  \"result\": {\n    \"agent\": \"bar\",\n    \"count\": \"123\",\n  }\n}\n```\n\nYou can produce the following output:\n\n```\n\"client: foo, count: 80\"\n\"client: bar, count: 123\"\n```\n\nBy executing the following command:\n\n```shell\ncat data.json | jq '.result | \"client: \\(.agent), count: \\(.count)\"'\n```\n\nThe `.result` accesses the relevant field on each object in the stream.\n\nWe use `|` to pipe the data to the next 'script' which defines the output string we want.\n\nThe `\\()` is interpolation syntax (you pass in the field, e.g. `.count`). Interpolation must be used inside a string.\n\n\u003e **NOTE:** Make sure the interpolation syntax is quoted! See below JSON example that would break otherwise...\n\n```shell\n# i.e. JSON strings need to be quoted hence \"\\(\u003cFIELD\u003e)\"\n\n# GOOD\nfastly kv-store list --json | jq '.Data.[] | {\"name\": \"\\(.Name)\", \"store_id\": \"\\(.StoreID)\"}'\n\n# BROKEN\nfastly kv-store list --json | jq '.Data.[] | {\"name\": \\(.Name), \"store_id\": \\(.StoreID)}'\n```\n\n## Extract object from a list that is itself assigned to an object\n\nHere is the example JSON\n\n```\n{\n  \"commands\": [\n    {\n      \"name\": \"...\",\n      ...\n    },\n  ]\n}\n```\n\nWe want to get the object that has a `\"name\"` field set with a value of `\"compute\"`. This means we need to first get the top-level `\"commands\"` field, then dip inside its assigned list and find the relevant object.\n\n```bash\ngo run cmd/fastly/main.go help --format json | jq '.commands[] | select(.name | contains(\"compute\"))'\n```\n\n\u003e **NOTE:** an alternative to `contains` would be `==` operator: `fastly service list --json | jq 'map(select(.Name == \"testing-tf-provider-reactivation-bug\"))'`\n\n## Download a release binary from GitHub\n\n```bash\n$ curl -s https://api.github.com/repos/hashicorp/terraform-plugin-docs/releases/latest | \\\n\tjq '.assets[] | select(.name | test(\"darwin\")) | .browser_download_url' | \\\n    xargs -I {} curl -sLo /tmp/tfplugindocs.zip {} | \\\n    cd /tmp | \\\n    unzip tfplugindocs.zip tfplugindocs | \\\n    chmod +x ./tfplugindocs | \\\n    ./tfplugindocs -h\n```\n\nBelow is an alternative approach I found via https://smarterco.de/download-latest-version-from-github-with-curl/\n\n```bash\nDOWNLOAD_URL=$(curl -s https://api.github.com/repos/felixb/swamp/releases/latest \\\n        | grep browser_download_url \\\n        | grep swamp_amd64 \\\n        | cut -d '\"' -f 4)\ncurl -s -L --create-dirs -o ~/downloadDir \"$DOWNLOAD_URL\"\n```\n\n## Combine multiple objects into one\n\n```bash\nfunction configure_rig_environment {\n  # The rig platform sets up the environment variables from the config.yml\n  # before even the scripts/prebuild (as part of a docker image build) is\n  # triggered. Because of the config.yml interpolation with other yaml files,\n  # it means we need to reset the CONFIG environment variable for testing.\n\n  # first we need to convert the config.yml into json\n  python -c 'import sys, yaml, json; json.dump(yaml.load(sys.stdin), sys.stdout, indent=4)' \u003c /app/config.yml \u003e /tmp/config.json\n\n  # we extract the location/overrides (which doesn't change between environments).\n  cat /tmp/config.json | jq .default.config.locations \u003e /tmp/locations.json\n  cat /tmp/config.json | jq .default.config.overrides \u003e /tmp/overrides.json\n\n  # then we store off the current config (this is missing the\n  # locations/overrides) as they're only merged in after the image was built.\n  echo $CONFIG \u003e /tmp/config.json\n\n  # next we combine the three configs back into one\n  # and we generate a new environment.json file for it\n  # -c is for generating compact json and not pretty-printed json\n  jq -c -s '.[0] * {\"locations\": .[1]} * {\"overrides\": .[2]}' /tmp/config.json /tmp/locations.json /tmp/overrides.json \u003e /tmp/environment.json\n\n  # finally, we re-export the config with the new combined values\n  # shellcheck disable=SC2155\n  export CONFIG=$(cat /tmp/environment.json)\n}\n```\n\n## Complex transforming of nested data with .jq script\n\nWe have the following YAML, and I want all API paths and HTTP methods that contain a `x-fastly-preprocess-exclude` that matches a string I'm searching for (e.g. only filter the data when I'm searching for `fastly-ruby`)...\n\n```yaml\npaths:\n  /content/edge_check:\n    get:\n      summary: Check status of content in each POP's cache\n      description: Retrieve headers and MD5 hash of the content for a particular URL from each Fastly edge server. This API is limited to 200 requests per hour.\n      operationId: content-check\n      parameters:\n        - name: url\n          in: query\n          description: Full URL (host and path) to check on all nodes. if protocol is omitted, http will be assumed.\n          style: form\n          explode: true\n          schema:\n            type: string\n            example: https://www.example.com/foo/bar\n      responses:\n        \"200\":\n          description: OK\n          content:\n            application/json:\n              schema:\n                type: array\n                items:\n                  $ref: \"#/components/schemas/content\"\n              examples:\n                body:\n                  value:\n                    $ref: \"examples/content-edge-check.yaml\"\n      x-fastly-preprocess-exclude:\n        - fastly-ruby # fastly-ruby cannot handle a property named 'hash'\n\n```\n\nWe convert it to JSON and pipe that JSON data to a `jq` script...\n\n```bash\n#!/bin/bash\n\n__dir=$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" \u0026\u0026 pwd)\n\nCLIENT=$1\nISSUES=\"\\nThe $CLIENT API client currently does not support the following endpoints:\\n\\n\"\nHAS_ISSUES=false\nDEFAULT_URL=\"https://developer.fastly.com/reference/api/\"\n\n# Create temporary file that will eventually contain all unsupported endpoints.\ntmp=\"$(mktemp)\"\n\nfor schema in ./api-documentation/src/*.yaml; do\n  # NOTE: We convert each YAML schema into JSON and process it with jq.\n  json=$(ruby -rjson -ryaml -e \"puts YAML.load_file('$schema', permitted_classes: [Time]).to_json\")\n\n  # We need the API endpoint so we can link to it in the API client's README.\n  url=$(echo $json | jq -r '.externalDocs.url')\n  if [[ \"$url\" == null ]]; then\n    url=\"$DEFAULT_URL\"\n  fi\n\n  exclude_all=$(echo $json | jq --arg client \"$CLIENT\" -r '. | if has(\"x-fastly-preprocess-exclude\") then (if (.[\"x-fastly-preprocess-exclude\"] | contains([$client])) or (.[\"x-fastly-preprocess-exclude\"] | contains([\"api-client\"])) then true else false end) else false end')\n  EXCLUDE_ALL=\"$exclude_all\"\n\n  result=$(echo $json | jq -f \"$__dir/transmogrify.jq\" --arg exclude_all \"$EXCLUDE_ALL\" --arg client \"$CLIENT\" --arg url \"$url\")\n\n  if [[ \"$result\" != \"\" ]]; then\n    HAS_ISSUES=true\n\n    # NOTE:\n    # We get the 'raw' value (jq -r) to avoid having \"\" around the output string.\n    # The reason for storing the results into a tmp file is so we can sort the endpoints.\n    echo $result | jq -r \u003e\u003e $tmp\n    cat $tmp | sort -o $tmp\n  fi\ndone\n\n# NOTE:\n# The Awk command is used to replace line breaks with the literal \\n.\n# Otherwise Awk will later error with the message \"newline in string\".\nISSUES=\"${ISSUES}$(cat $tmp | awk '{ printf \"%s\\\\n\", $0 }')\"\n\nif [[ \"$HAS_ISSUES\" == true ]]; then\n  # NOTE: I've used Awk as (when installed) it's consistent across OS' unlike sed.\n  awk -v issues=\"$ISSUES\" '1;/## Issues/{ print issues; }' \"$CLIENT/README.md\"\nfi\n\n# Cleanup.\nrm -rf tmp\n```\n\nHere's our `jq` transmorgrify.jq script file...\n\n```jq\n.paths | with_entries(\n    # If we're excluding all endpoints, then all we need to do is to grab the\n    # keys and convert them into a comma-separated string.\n    #\n    # Otherwise, we need to find only those endpoints that have an\n    # x-fastly-preprocess-exclude containing the API client we're looking for.\n    #\n    # .key is the API endpoint path (e.g. /service/{service_id}/version/{version_id}/acl)\n    # .value is an object containing the supported HTTP methods (e.g. {\"get\": {...metadata...}, \"post\": {...metadata...}})\n    if $exclude_all == \"true\" then\n      .value |= (\n        . | keys | map(select(. != \"parameters\")) | join(\", \")\n      )\n    else\n      # We modify the .value to replace the metadata associated with each HTTP\n      # method with a list containing the API client we're searching for inside\n      # of the x-fastly-preprocess-exclude field.\n      #\n      # e.g. {\"/some/path\": {\"get\": [\"fastly-rust\"], \"post\": [\"fastly-rust\"]}}\n      .value |= (\n          . | with_entries(\n              # .key is the HTTP method (e.g. \"get\", \"post\" etc)\n              # .value is the metadata object (e.g. {\"summary\": \"...\", \"x-fastly-preprocess-exclude\": [...]})\n              #\n              # We modify the .value from an object of metadata to a list\n              # containing only the excluded API client we're searching for\n              # inside of the x-fastly-preprocess-exclude field.\n              #\n              # e.g. {\"get\": [\"fastly-rust\"]} or {\"get\": [\"api-client\"]}\n              .value |= (\n                  if (type==\"object\" and has(\"x-fastly-preprocess-exclude\")) then\n                    .[\"x-fastly-preprocess-exclude\"]\n                  else\n                    []\n                  end\n              )\n              # We make sure to filter out the API clients that aren't relevant\n              # to our search. We also search for the generic \"api-client\",\n              # which means exclude ALL clients.\n              | select((.value | contains([$client])) or (.value | contains([\"api-client\"])))\n          )\n      )\n      # For each HTTP method object, keep it, if it's not empty.\n      | select(.value != {})\n      # We modify the .value from an object like:\n      # {\"get\": [\"fastly-rust\"], \"post\": [\"fastly-rust\"]}\n      #\n      # To a comma-separated string like:\n      # \"get, post\".\n      #\n      # We do this by first getting the keys as an array [\"get\", \"post\"], then\n      # using join() to turn it into a string.\n      #\n      # e.g. {\"/some/path\": \"get, post\"}\n      | .value |= (. | keys | map(select(. != \"parameters\")) | join(\", \"))\n    end\n)\n# We only keep objects (e.g. {\"/some/path\": \"get, post\"}) that aren't empty.\n| select(. != {})\n# Finally, we convert the object (e.g. {\"/some/path\": \"get, post\"}) into a\n# string that is formated so it can be inserted into a Markdown file.\n#\n# e.g. \"- /some/path (get, post)\"\n#\n# The trick is to modify the object key to be the final string, then get all the\n# keys as an array, and join the array with a newline.\n#\n# I use `with_entries` to modify the key to also contain its value (e.g. the key\n# becomes \"- /some/path (GET, POST)\").\n#\n# You'll notice I use `ascii_upcase` to capitalize the HTTP methods.\n# Then I create an array from the modified keys and join those by a new line.\n#\n# Additionally I wrap the path in a Markdown link and set the URL using the $url\n# variable that is passed into the jq script via jq's --arg flag.\n| with_entries(.value as $v | .key |= \"- [\" + . + \"](\" + $url +\") (\" + ($v | ascii_upcase) + \")\") | keys | join(\"\\n\")\n\n# EXAMPLE OUTPUT:\n#\n# - [/user-groups/{user_group_id}](...) (PATCH)\n# - [/user-groups/{user_group_id}/roles](...) (DELETE, POST)\n# - [/user-groups/{user_group_id}/service-groups](...) (DELETE, POST)\n# - [/user-groups/{user_group_id}/members](...) (DELETE, POST)\n#\n# DOCUMENTATION REFERENCE:\n#\n# with_entries:\n# converts object to list of key/value objects, modifies the data, then converts back to an object.\n# https://stedolan.github.io/jq/manual/#to_entries,from_entries,with_entries\n#\n# select:\n# returns input value if it matches the given condition.\n# https://stedolan.github.io/jq/manual/#select(boolean_expression)\n#\n# keys:\n# takes object and returns the keys in an array.\n# https://stedolan.github.io/jq/manual/#keys,keys_unsorted\n#\n# |= is a \"modification assignment operator\" which means it assigns the new value after processing.\n```\n\n## Adding new key to an object\n\nYou can use the `+=` with an object `{...}`\n\n```jq\n# .paths == {\"/api/path\": {\"parameters\": [...], \"get\": {...}, \"post\": {...}}}\n.paths | with_entries(\n  # .key == /api/path\n  # .value == {parameters: [...], get: {...}, post: {...}}\n  .value |= (\n    . | with_entries(\n      # .key == 'parameters' and all support HTTP methods (e.g. 'get', 'post').\n      # .value == the values assigned to the keys, e.g. HTTP methods have {\"summary\": \"\", ...etc}.\n      .value |= (\n        if (type==\"object\" and has(\"summary\")) then\n          .summary\n        elif (type==\"array\") then # i.e. \"parameters\" is an array\n          . | map(.\"$ref\" | split(\"/\") | last)\n        else\n          \"No summary\"\n        end\n      )\n    ) | . += {\"documentation\": $api_url}\n  )\n)\n```\n\n## List all unique keys recursively\n\nYaml file:\n\n```yaml\n- metadata:\n    foo: some_string\n    bar: 123\n    baz:\n      - an\n      - array\n    qux:\n      an: object\n      with: more_keys\n```\n\nCommand:\n\n```shell\nyq -o=json example.yaml | jq '[.[] | select(.metadata != null) | .metadata | paths | join(\".\")] | unique | sort'\n```\n\n## List all array items who have different values across specified keys\n\nYaml file:\n\n```yaml\n- host: foo\n  tls_server_name: foo\n- host: bar\n  tls_server_name: ... # this has a different value to the host key\n- host: baz\n  tls_server_name: baz\n```\n\nCommand:\n\n```shell\nyq e '.[] | select(has(\"tls_server_name\") and .tls_server_name != .host) | {\"tls_server_name\": .tls_server_name, \"host\": .host}' resources/checkers.yaml\n```\n\nOutput:\n\n```\nhost: bar\ntls_server_name: ...\n```\n\n## List all array items who have a timeout larger than a set value\n\nYaml file:\n\n```yaml\n- name: foo\n  timeout: '10s'\n- name: bar\n  timeout: '5s'\n- name: baz\n  timeout: '20s'\n```\n\nCommand:\n\n```shell\n# converts yaml to json so we use jq\ncat resources/checkers.yaml | yq eval -o=json | jq '.[] | select(.timeout != null and (.timeout | sub(\"s$\"; \"\") | tonumber) \u003e 10) | {name: .name, timeout: .timeout}'\n\n# just uses yq but notice we MUST quote the json key names\n# also yq will continue to output yaml even though we define a json output!\nyq '.[] | select(.timeout != null and (.timeout | sub(\"s$\"; \"\") | tonumber) \u003e 10) | {\"name\": .name, \"timeout\": .timeout}' resources/checkers.yaml\n```\n\nOutput:\n\n```json\n{\n  \"name\": \"nic.in\",\n  \"timeout\": \"30s\"\n}\n{\n  \"name\": \"nic.gdn\",\n  \"timeout\": \"15s\"\n}\n{\n  \"name\": \"zdns\",\n  \"timeout\": \"20s\"\n}\n```\n\n```yaml\nname: nic.in\ntimeout: 30s\n\nname: nic.gdn\ntimeout: 15s\n\nname: zdns\ntimeout: 20s\n```\n\n## List all array items who have nested object key not set\n\n```yaml\n- name: foo\n  metadata:\n    logins:\n      console: # KEY IS SET HERE\n        url: 123\n- name: bar\n  metadata:\n    logins:\n      ote: # KEY IS NOT SET HERE\n        url: 123\n```\n\n```shell\nyq eval -o=json '.' example.yaml | jq -r 'map(select(.metadata.logins.console == null) | .name)'\n```\n\n## Unique entries by key\n\nWe have to wrap our data in an array `'[.[] | select(.tls_certificate != null)]'` and then we can use `unique_by`:\n\n```shell\n$ yq -o=json example.yaml | jq '[.[] | select(.tls_certificate != null)] | unique_by(.tls_certificate)[] | {tls_cert: .tls_certificate}'\n\n{\n  \"tls_cert\": \"$EXAMPLE_1\"\n}\n{\n  \"tls_cert\": \"$EXAMPLE_2\"\n}\n```\n","tags":"#jq #yq #shell #bash #json"},{"id":"639f8418c2bec1721dd55723c3344e04","title":"JS: streaming server response ","content":"// Backend: https://sse-demo-dot-rd---product.uc.r.appspot.com\n// Example: https://fiddle.fastlydemo.net/fiddle/ba54f417\n\nconst CITIES = ['Atlanta', 'Berlin', 'Dublin', 'Boston', 'Denver', 'Tokyo', 'Singapore'];\nconst REGEX_SSE_LINE = /^([^:]+?)\\s*:\\s*(.*?)\\s*$/;\n\nconst parseSSE = (str) =\u003e {\n  return str\n    .split('\\n')\n    .map(line =\u003e line.match(REGEX_SSE_LINE))\n    .filter(matchResult =\u003e matchResult !== null)\n    .reduce((out, [, k, v]) =\u003e ({\n      ...out,\n      [k]: (k === 'data' \u0026\u0026 v) ? JSON.parse(v) : v\n    }))\n  ;\n};\n\nconst isValidEvent = (sseEvent) =\u003e {\n  if (!sseEvent.data) return true;   // Allow unrecognised events through\n  const city = sseEvent.data.destination;\n  const shouldEmit = CITIES.includes(city);\n  console.log('City: '+city+', include: '+ shouldEmit);\n  return shouldEmit;\n};\n\nasync function handler(event) {\n  const clientReq = event.request;\n  const backendResponse = await fetch(clientReq, { backend: \"origin_0\" });\n\n  const filteredStream = streamFilter(backendResponse.body, {\n    delimiter: '\\n\\n',\n    parser: parseSSE,\n    validator: isValidEvent,\n  });\n\n  return new Response(filteredStream, {\n    headers: {\n      ...backendResponse.headers,\n      'cache-control': 'private, no-store'\n    }\n  });\n}\n\naddEventListener(\"fetch\", event =\u003e event.respondWith(handler(event)));\n\n// *********** HELPER FUNCTIONS *************\n\n/**\n * Streamfilter\n * Takes a stream and returns a new stream.\n * \n * - inputStream: The stream to filter\n * - options.delimiter: Separator between events in the stream\n * - options.parser: Function to parse a single event\n * - options.validator: Function to determine whether an event should be included in the output stream\n */\nconst streamFilter = (inputStream, options) =\u003e {\n  let buffer = ''; \n  const decoder = new TextDecoder();\n  const encoder = new TextEncoder();\n  const inputReader = inputStream.getReader();\n  const outputStream = new ReadableStream({\n    start() {\n      buffer = '';\n    },\n\n    // When the output stream is read...\n    pull(controller) {\n\n      // Read from the input stream...\n      return inputReader.read().then(({value: chunk, done: readerDone}) =\u003e {\n        const chunkStr = decoder.decode(chunk);\n        let events = chunkStr ? (buffer + chunkStr).split(options.delimiter) : buffer;\n\n        // If we're not done the last event will be incomplete\n        if (!readerDone) {\n          buffer = events.pop();\n        }\n\n        // Re-emit the events from the input stream into\n        // the output stream if they meet our criteria\n        events\n          .filter(str =\u003e options.validator(options.parser(str)))\n          .forEach(str =\u003e controller.enqueue(encoder.encode(str+options.delimiter)))\n        ;\n\n        // Flush the queue, and close the stream if we're done\n        controller.enqueue(encoder.encode(''));\n        if (readerDone) {\n          controller.close();\n        }\n      });\n    }\n  });\n  return outputStream;\n}\n","tags":"#js #javascript #stream"},{"id":"c0933883cc79aa0d84162d839cfc6253","title":"Go: Populate or update pkg.go.dev with new package ","content":"## Add\n\nIf you want a project to appear in https://pkg.go.dev then visit the expected page and click on the \"Request ...\" button.\n\ne.g.\n\n```\nhttps://pkg.go.dev/github.com/integralist/go-flags\n```\n\nI clicked on the button \"Request github.com/integralist/go-flags\" and it started to populate.\n\n## Update\n\nhttps://pkg.go.dev/github.com/fastly/go-fastly/v3@main\n\nor \n\nhttps://pkg.go.dev/github.com/fastly/go-fastly/v3@v3.8.0 (and there should be a button that will show letting you pull the version specified).\n\nOr yet another way is:\n\nhttps://sum.golang.org/lookup/github.com/fastly/go-fastly/v3@v3.8.0\n","tags":"#go #dependencies"},{"id":"68e71bd4f8374ecf839a7500f9656d36","title":"Videos: YouTube 'Watch' Channels ","content":"- [Bark and Jack](https://www.youtube.com/channel/UCvIIb5YF8sUnm1D62jCvVVw): great down to earth personality, cool watches, very easy to listen to.\n- [WatchFinder](https://www.youtube.com/user/watchfinder): awesome/expensive unique watches and their backgrounds (exquisite close-up footage)\n- [Theo and Harris](https://www.youtube.com/channel/UCqhmd5fM8oJrJnahTxaMUUA): high end quality pieces reviewed/discussed\n- [The Urban Gentry](https://www.youtube.com/user/theurbangentry): can waffle on, but he does great historical deep dives\n- [Watch Advisor](https://www.youtube.com/channel/UCFh-oKEXamVSLQRzG2_23wQ): I just enjoy listening to him talk because of his accent lol\n- [Long Island Watches](https://www.youtube.com/user/islandwatchdotcom): cheaper end watches, interesting selections come up\n- [Jenni](https://www.youtube.com/channel/UC4TLvsSDZQb-TBrhDID3jPg): female watch reviewer (great quality footage)\n- [WatchBox Reviews](https://www.youtube.com/channel/UCpIdSH75bNfHIsryKCTzTWw): short reviews\n- [WatchBox Studios](https://www.youtube.com/user/watchuwantinc): long form discussions\n","tags":"#youtube #watches"},{"id":"06bd3469e3958b9b4481d197b0fc93f1","title":"Security: Encryption, Hashing, Signatures ","content":"- Encryption helps ensure _confidentiality_. \n- Hashing can help ensure _integrity_. \n- Digital signatures or message authentication codes (MAC, including keyed hashing such as HMAC) can be used to verify _authenticity_. \n","tags":"#security #sec #encryption #hash #signatures #hmac"},{"id":"143faf7ca6b8090e112ec0752ff7e1ca","title":"macOS: System Information ","content":"# Documentation:\n#\n# - man sw_vers\n# - man system_profiler\n#\n# Product Name:\n# Neither of the above solutions provide the OS 'product name' (e.g. Catalina, Mojave, High Sierra etc.)\n# So I curl Wikipedia's macOS version history page and parse out the name.\n#\n# The problem in doing so is that I need a version number (e.g. 10.15) \n# but the version number provided by `sw_vers -productVersion` is the full version (e.g. 10.15.16)\n# meaning we need to strip the last segment (this is done with the following bash trick: `${version%.*}`)\n# also when grepping for the product name it comes up twice in the Wikipedia page, so I use `uniq` to remove duplicates\n\nalias sys='sw_vers \u0026\u0026 echo \u0026\u0026 system_profiler SPSoftwareDataType \u0026\u0026 curl -s https://en.wikipedia.org/wiki/MacOS_version_history | grep -Eo \"Version $(version=$(sw_vers -productVersion) \u0026\u0026 echo ${version%.*}): \\\"[^\\\"]+\\\"\" | uniq'\n\n# Example Output:\n# \n# ProductName:    Mac OS X\n# ProductVersion: 10.15.6\n# BuildVersion:   19G2021\n# \n# Software:\n# \n#     System Software Overview:\n# \n#       System Version: macOS 10.15.6 (19G2021)\n#       Kernel Version: Darwin 19.6.0\n#       Boot Volume: Macintosh HD\n#       Boot Mode: Normal\n#       Computer Name: Integralist-MBPr\n#       User Name: Integralist (integralist)\n#       Secure Virtual Memory: Enabled\n#       System Integrity Protection: Enabled\n#       Time since boot: 3 days 2:37\n# \n# Version 10.15: \"Catalina\"\n","tags":"#macos #system #information #shell #bash"},{"id":"510068111c4e2ac933c8d7a3710e732e","title":"Git: Revision Range ","content":"\u003e Reference: https://git-scm.com/book/en/v2/Git-Tools-Revision-Selection\n\nLog commits in `feature` branch that aren't in `master`:\n\n```bash\ngit log master..feature\n```\n\nIf you `git pull` your `master` branch you might find there are additional commits from your colleagues. So you might want to check what commits were recently merged into `master` that aren't in your `feature` branch:\n\n```bash\ngit log feature..master\n```\n\nThe triple dot range will show you all the git commits that aren't common to both branches. \n\nImagine we have a `master` branch with the commits `A, B`. We create the `feature` branch and add `C, D` commits. Then we go back to `master` and add `E, F` commits. In this scenario both branches have `A, B` commits, but diverge from there. The following log example will report `C, D, E, F` because these commits aren't common to both branches:\n\n```bash\ngit log master...feature\n```\n","tags":"#git #revision #range"},{"id":"a6e36f6b32573242f0b21918a4c56a27","title":"Ruby: RVM ","content":"# install rvm\n#\ncurl -sSL https://get.rvm.io | bash\n\n# lookup available ruby interpreters \n#\nrvm list known\n\n# install specific ruby version\n#\nrvm install \"ruby-2.5.3\"\n\n# create a project scoped gemset (e.g. similar to a virtual environment in Python)\n#\nrvm 2.5.3@foo --create\n\n# switch to specific version\n#\nrvm 2.5.3@foo\n","tags":"#ruby #rvm"},{"id":"0f11d3d94bcf564dcd7ad414a2611d83","title":"Go: Module Versioning ","content":"\u003e Reference: https://blog.golang.org/v2-go-modules\n\nYou have a dependency you want to use, like `github.com/integralist/delete-just-testing`.\n\n```go\n// delete-just-testing/foo/foo.go \n//\npackage foo\n\nimport \"fmt\"\n\nfunc Bar() {\n\tfmt.Println(\"bar\")\n}\n```\n\nThat dependency has the following `go.mod` file:\n\n```go\nmodule github.com/integralist/delete-just-testing\n\ngo 1.15\n```\n\n\u003e Note: Major version suffixes are not allowed at major versions v0 or v1 (e.g. you can't do `module github.com/integralist/delete-just-testing/v1`). There is no need to change the module path between v0 and v1 because v0 versions are unstable and have no compatibility guarantee. Additionally, for most modules, v1 is backwards compatible with the last v0 version; a v1 version acts as a _commitment_ to compatibility, rather than an indication of incompatible changes compared with v0. -- [official reference](https://golang.org/ref/mod#major-version-suffixes).\n\nWe want to create a new program, so we start by initializing a new go module for our project:\n\n```bash\ngo mod init testing_gomodules\n```\n\nWe create an `app.go` main package:\n\n```go\npackage main\n\nimport (\n\t\"fmt\"\n\n\t\"github.com/integralist/delete-just-testing/foo\"\n)\n\nfunc main() {\n\tfmt.Println(\"main\")\n\n\tfoo.Bar()\n}\n```\n\nWe execute `go run app.go` and find our `go.mod` file is updated:\n\n```bash\n$ go run app.go\ngo: finding module for package github.com/integralist/delete-just-testing/foo\ngo: downloading github.com/integralist/delete-just-testing v0.0.0-20200921145455-530f3130809d\ngo: found github.com/integralist/delete-just-testing/foo in github.com/integralist/delete-just-testing v0.0.0-20200921145455-530f3130809d\nmain\nbar\n```\n\nThe `go.mod` file for our project now looks like:\n\n```go\nmodule testing_gomodules\n\ngo 1.15\n\nrequire github.com/integralist/delete-just-testing v0.0.0-20200921145455-530f3130809d // indirect\n```\n\n\u003e Note: when I was running through this example I had pulled in the dependency into my project _before_ I had actually assigned a `v1.0.0` tag, so the go toolchain generates a [pseudo-version](https://golang.org/ref/mod#pseudo-versions) for you. If I had tagged the commit with `v1.0.0` before trying to use the dependency then instead of the pseudo-version I would have seen `v1.0.0` after the module path.\n\nIf we (as the dependency author) want to update our code to be v2, then we have two strategies:\n\n1. create a new `v2/` directory and copy our package into it (this is for backwards compatibility with go versions below 1.13 that don't understand go modules).\n2. just rename the module in the `go.mod` file (which will require you to update all _explicit_ imports in your code's test files + consumers will need to do the same).\n\n\u003e Note: `go get -u` doesn't help consumers of our dependency get the latest major version. If you run `go list -u -m all` you'll see minor and patch updates but not major version updates. This goes back to how the go team [perceive v2 and higher major version releases](https://github.com/golang/go/wiki/Modules#releasing-modules-v2-or-higher) (i.e. they should be a different directory or new module path).\n\nNow let's say we take the second approach of just changing the `go.mod` name in our dependency repository:\n\n```go\nmodule github.com/integralist/delete-just-testing/v2 // \u003c\u003c updated to append /v2\n\ngo 1.15\n```\n\nThen the consumer will need to update their import path to get that change: \n\n```go\npackage main\n\nimport (\n\t\"fmt\"\n\n\t\"github.com/integralist/delete-just-testing/v2/foo\" // \u003c\u003c updated to include /v2\n)\n\nfunc main() {\n\tfmt.Println(\"main\")\n\n\tfoo.Bar()\n}\n```\n\n...they'll also discover they have an updated `go.mod`:\n\n```go\nmodule testing_gomodules\n\ngo 1.15\n\nrequire (\n\tgithub.com/integralist/delete-just-testing v0.0.0-20200921145455-530f3130809d\n\tgithub.com/integralist/delete-just-testing/v2 v2.0.0\n)\n```\n\nYou'll see we have the tagged `v2.0.0` pulled in alongside the original. Running `go mod tidy` will remove the old version.\n\n\u003e Note: if you change the import path back to the non `/v2` version you'll discover the old `v0.0.0...` [pseudo-version](https://golang.org/ref/mod#pseudo-versions) is put back into your `go.mod` file and you can again use `go mod tidy` to remove the `v2.0.0` dependency. This is cool, because although the old pre-v2 code doesn't exist any more at HEAD in the dependency's `master` branch, the go toolchain is still able to retrieve it.\n\n## Easy module path update in Vim\n\nImagine you're using a package called `go-fastly` and it's currently defined at version `2.0.0` so it uses `/v2` in its module path. But then an upgrade to `3.0.0` is released so you need to bump your imports from `v2` to reference `v3`.\n\n```viml\n:Ack! --go 'go-fastly/v2'\n:cdo s/v2/v3/ | update\n```\n\nIf you don't have Ack! because you're using a basic vim configuration (e.g. `vim -u ~/.vimrc-basic`), then use the following instead...\n\n```viml\n:vimgrep /go\\-fastly\\/v2/j fastly/*go\n:copen\n:cdo s/v2/v3/ | update\n```\n\n\u003e **NOTE**: The reason to use `vim -u ~/.vimrc-basic` is because of vim-go and the golang LSP can cause the Vim quickfix window to get updated (various warnings/errors etc about the code) and this means `:cdo` fails to complete as the quickfix list it was working with has changed. So using a basic Vim configuration means I can use `:cdo` and have the files updated in a fraction of the time as no LSP means much faster processing.\n\n## Branch vs Directory Versioning\n\nWhen creating a new module version most people use git branches to separate v0/v1 and v2,v3...etc and git tag appropriately when creating new releases.\n\nAn alternative is to use the same branch but separate directories for each version (this way you can more easily share code between the versions that haven't actually changed).\n\n1. Directory Versioning Approach\nWith directory versioning, instead of creating a new Git branch for each major version (v2, v3, etc.), you place the code for each major version in a dedicated folder within your repository. Each version has its own go.mod file and module path reflecting the correct version.\n\nHere is a directory structure example:\n\n```\n├── v1\n│   ├── go.mod\n│   └── main.go\n├── v2\n│   ├── go.mod\n│   └── main.go\n└── v3\n    ├── go.mod\n    └── main.go\n```\n\nIn this case, each folder (v1, v2, v3) contains the source code for its respective version, along with its own go.mod file specifying the correct module path.\n\nThe `v1/go.mod` would contain `module github.com/your/module`.\n\nThe `v2/go.mod` would contain `module github.com/your/module/v2`.\n\nThe `v3/go.mod` would contain `module github.com/your/module/v3`.\n\nWhen users import and use your module, they must reference the correct version using the module path that corresponds to the major version they want.\n\n```go\n// v0/v1\nimport \"github.com/your/module\"\n// v2\nimport \"github.com/your/module/v2\"\n// v3\nimport \"github.com/your/module/v3\"\n```\n\nUsing `go get` or `go install` would then look like this...\n\n```shell\n# Install version 1\ngo get github.com/your/module@v1.5.0\n\n# Install version 2\ngo get github.com/your/module/v2@v2.3.0\n\n# Install version 3\ngo get github.com/your/module/v3@v3.0.0\n```\n","tags":"#go #dependencies"},{"id":"33db869da23d0729d1e332e21803f891","title":"Go: Running Benchmarks ","content":"\u003e Reference: https://dave.cheney.net/2013/06/30/how-to-write-benchmarks-in-go\n\nRunning benchmarks requires the `-bench` flag to be given a valid regex pattern:\n\n```go\ngo test -v -bench=.\n```\n\n\u003e Note: this will still run all the tests (as you're using the `go test` subcommand).\n\nRun benchmarks but disable tests from being run:\n\n```go\ngo test -v -bench=. -run=XXX\n```\n\n\u003e Note: we've disabled the tests by passing a valid regex pattern to the `-run` flag, which will not match any known tests.\n","tags":"#go #performance"},{"id":"f6ec67152756d7d40476159a9094e4ee","title":"Terraform: what should and shouldn't be there ","content":"**Summary**  \nStore configuration, NOT data.\n\n**Why?**  \nData is going to be stored in the tfstate file and because of how the `terraform` command-line interface works (e.g. it communicates with a separate 'core' process over gRPC) there's a size limitation of 4mb going over the wire.\n\n**Additional Comments**  \nPopulating resources with data externally from Terraform is very dangerous, as you're side-stepping the protection guarantees that Terraform is designed to provide. If Terraform's tfstate file doesn't know about data that's been created/pushed externally (i.e. data not defined within a terraform file and CRUD'ed using the `terraform` CLI), then Terraform is going to delete that data on the next plan/apply operation because (as far as Terraform is concerned) it shouldn't exist. \n\nConsider the [Fastly terraform provider](https://registry.terraform.io/providers/fastly/fastly/latest/docs). We've seen the following situations:\n\n- **Edge Dictionary loses records**: Fastly provides an 'edge dictionary' which can be created via terraform, but once created the values can be updated via Fastly API calls. This means if you were to define initial key/values in terraform for the edge dictionary, it would mean any new content added outside of terraform (which is the whole benefit of an edge dictionary, to allow dynamic updates without requiring a redeploy of a service) will cause the new content to be lost whenever a new `terraform apply` is actioned (unless you set `ignore_changes` as stated in [the Fastly documentation](https://registry.terraform.io/providers/fastly/fastly/latest/docs/resources/service_dictionary_items_v1)) as terraform's tfstate file will not contain the new edge dictionary elements that were added via API calls.  \n  \n- **Large number of ACL records causes gRPC error**: A customer had lots of ACL records data defined in their terraform HCL and so eventually the tfstate file would be pushed via gRPC to the 'core' process and that's when a gRPC error would bubble up (due to the 4mb limitation). The solution is to use terraform to manage the existence of an ACL 'container' and then manage the population of ACL records via some other service or tool (e.g. a script that uses the Fastly API to CRUD ACL records). To prevent terraform from getting confused you would need to set `ignore_changes` so it knows that any additional data discovered shouldn't be stored in the tfstate file.\n\n\u003e **NOTE**: if you manage data in terraform, and only add `ignore_changes` until _much_ later (e.g. after adding 50k ACL records you finally add `ignore_changes`), then you'll discover that terraform's tfstate file will still know about the data and try to move it around (e.g. `terraform plan` will attempt to pull down 50k records and pass it internally to its 'core' process, thus triggering the gRPC 4mb limit error). The only way to solve the issue from the point is to remove the data from the tfstate file using `terraform rm`.\n","tags":"#tf #terraform #fastly"},{"id":"2b4298d4d287376b8a939c4e9eadd693","title":"Fastly Terraform Import ","content":"\u003e NOTE: these instructions have been genericised from a real example, and so your mileage may vary.\n\nI first create a `provider.tf` file.\n\n```terraform\nterraform {\n  required_providers {\n    fastly = {\n      source  = \"fastly/fastly\"\n      version = \"0.28.2\"\n    }\n  }\n}\nprovider \"fastly\" {\n  api_key = \"\u003cAPI_KEY\u003e\"\n}\n```\n\nNext I create a `main.tf` placeholder file (I name the resource `import_testing` but you will likely want to name it something different).\n\n```terraform\nresource \"fastly_service_v1\" \"import_testing\" {}\n```\n\nI use a program called `tfswitch` (https://github.com/warrensbox/terraform-switcher) to manage multiple terraform versions, but you can just [download the latest version direct from HashiCorp](https://www.terraform.io/downloads.html) if you don't have multiple projects (e.g. each project using a different Terraform version).\n\nI use `tfswitch` to install the latest version of Terraform (currently `v0.15.1`).\n\nI run `terraform init` which displays a bunch of information, but the relevant section is in green and says \"Terraform has been successfully initialized!\"\n\nI then import the service using:\n\n```bash\nterraform import fastly_service_v1.import_testing \u003cSERVICE_ID\u003e\n```\n\nNotice the use of `import_testing` as the name I assigned to the `fastly_service_v1` resource. If you decide to change the name as I suggested earlier, you will want to be sure to update this command to reflect that change. Also `\u003cSERVICE_ID\u003e` should be replaced with your actual Service ID.\n\nRunning this command will display some information, but the relevant section is in green and says \"Import successful!\".\n\nI don't _need_ to run the next command, but I like to have a look at the local state straight after an initial import:\n\n```bash\nterraform show\n```\n\nThe `show` subcommand pretty prints the internal Terraform state (i.e. what's in the `terraform.tfstate` that has been created in the local directory where the other Terraform files, `provider.tf`/`main.tf` are located).\n\nThe next crucial command is to run:\n\n```\nterraform show -no-color \u003e main.tf\n```\n\nThis will overwrite the 'placeholder' content that was in the `main.tf` file with a bunch of Terraform HCL code.\n\nThis code is a HCL version of the Terraform internal state, which will include a bunch of things that **_shouldn't_** be present in a typical Terraform file you would normally write manually by hand.\n\nThis means I need to manually edit the updated `main.tf` content so it doesn't include internal state attributes that would cause a `terraform plan` to get confused. I start by first executing `terraform validate` to be sure that otherwise Terraform is happy.\n\nThis should print the message \"Success! The configuration is valid.\"\n\nAt this point I also run a `terraform plan` to see if Terraform thinks any changes are needed (I know from experience that Terraform will be confused and so I typically run this just out of interest).\n\nI can see in the output (I've shortened it for brevity):\n\n```diff\n~ resource \"fastly_service_v1\" \"import_testing\" {\n    + comment  = \"Managed by Terraform\"\n    + vcl {\n        + content = \u003c\u003c-EOT\n    - vcl {\n        - content = \u003c\u003c-EOT\n        - main    = true -\u003e null\n        - name    = \"customvcl\" -\u003e null\n```\n\nSo we can see from this that it is seeing `comment` as a new attribute and the `vcl` attribute is being deleted and recreated.\n\nSo here's where I open up `main.tf` and manually remove attributes I know should be deleted (and add/modify certain attributes)...\n\n**Attributes to delete**:\n- `active_version`\n- `id`\n\n**Attributes to add**:\n- `comment = \"\"` (I just added it under the `name = \"\u003c...\u003e\"` attribute).\n\n**Attributes to modify**:\n- `content` (inside the `vcl` block) should no longer use `\u003c\u003c-EOT` inlined VCL and should now become `content = file(\"vcl/main.vcl\")`\n\nThat last point will require you to download your main VCL file and stick it inside a `vcl` directory next to your other Terraform files `provider.tf` and `main.tf`.\n\nOne other change I need to make is to the `terraform.state` file itself. I modify this file so that `\"activate\": null` becomes `\"activate\": true`. The `activate` field is specific to the Fastly Terraform Provider and is not returned by the Fastly API and so that's why we need to tweak it when doing an import of a service.\n\nAlthough not used in this example, I've historically had to delete fields such as `dictionary_id`.\n\n\u003e **NOTE**: If you see any `(sensitive value)` values, then replace them with actual secrets (although it might be best to use `file()` for multi-line keys). You should have a read through Fastly's \"[Orchestration using Terraform and the Fastly Terraform Provider](https://developer.fastly.com/learning/integrations/orchestration/terraform/)\" which has a [best practices](https://developer.fastly.com/learning/integrations/orchestration/terraform/#best-practices) section that covers how to handle sensitive data.\n\nNow if I run a `terraform plan` I'll see:\n\n```\nNo changes. Infrastructure is up-to-date.\n```\n#!/usr/bin/env bash\n#\n# Explanation:\n# I use this to help me identify when newlines are causing diff conflicts.\n\n# Get plan\nterraform plan -out=tfplan \u003e /dev/null 2\u003e\u00261\n\n# Convert plan to json\nCHANGES=$(terraform show -json tfplan | jq '.resource_changes[].change')\n\n# Diff before and after with newlines expanded\ndiff -u \\\n  \u003c(echo \"$CHANGES\" | jq '.before' | sed 's/\\\\n/\\//g') \\\n  \u003c(echo \"$CHANGES\" | jq '.after' | sed 's/\\\\n/\\//g')\n","tags":"#iac"},{"id":"1c11e1caeae96045c8aab003015d455a","title":"Reviews: Self Review Bullet List ","content":"Avoid process heavy steps to writing a self-review. The following questions ask direct and valueable questions.\n\n\u003e Note: sourced from [this tweet thread](https://twitter.com/bcantrill/status/1216491507089166336)\n\n1. What are you most proud of in the last six months?\n2. What did you learn?\n3. Where did you struggle?\n4. What are you anxious about in the coming six months?\n5. What are you excited about in the coming six months?\n","tags":"#work #buzzfeed #process #reviews"},{"id":"2166bc061a4046ea0de978f771bbee04","title":"Go: Pointers - Guidelines ","content":"## Reference\n\nInformation was pulled from https://medium.com/@kent.rancourt/go-pointers-when-to-use-pointers-4f29256ddff3\n\n## Problems with Pointers\n\n- nil dereferencing.\n- accidental mutation.\n\n\u003e an unrelated comment would be, from a code design perspective, functions should not dip inside of data structures to access nested fields (I've seen this done to access a pointer to a struct): [law of demeter](https://en.wikipedia.org/wiki/Law_of_Demeter).\n\n1. Avoid pointers (you can always justify your way into using them later if necessary).\n2. Don't expect pointers to be more efficient: benchmark! (pass-by-value 'copies' are placed in the 'stack' not 'heap' and thus are handled faster by the CPU).\n3. When returning a pointer, also return a bool to indicate success (in case of error, returning an empty struct will cause a nil dereference error for caller if they don't expect an empty struct).\n4. Use a pointer when a function needs to modify its receiver (e.g. create method on struct whose receiver is a pointer, that way user can pass around/work with a non-pointer and when calling the method will the compiler switch to a pointer receiver to allow data modification).\n5. Use a pointer when you need a singleton.\n\n## Best Practice for Singleton\n\nFor components with great importance, we should control the terms on which others interact with them. To do this, create an exported interface with a non-exported implementation, where pointers to the component in question implement the interface.\n\n```go\npackage main\n\nimport (\n\t\"fmt\"\n)\n\ntype S struct {\n\t// ...\n}\n\ntype Cache interface {\n\tAdd(key string, val S)\n\tGet(key string)\n\tClear()\n}\n\ntype cache struct {\n\tfoo string\n\tbar int\n}\n\nfunc NewCache() Cache { // \u003c--- This is what the caller sees\n\treturn \u0026cache{\"beep\", 456} // \u003c--- It's a pointer, but they don't need to know\n}\n\nfunc (c *cache) Add(key string, val S) {\n\t// ...\n}\n\nfunc (c *cache) Get(key string) {\n\t// ...\n}\n\nfunc (c *cache) Clear() {\n\t// ...\n}\n\nfunc main() {\n\tc := NewCache()\n\tfmt.Printf(\"%+v\\n\", c) // \u003c--- caller can see the structure \u0026{foo:beep bar:456}\n\tfmt.Printf(\"%+v\\n\", c.foo) // \u003c--- but they can't interact with it (compile time error: c.foo undefined (type Cache has no field or method foo))\n}\n```\n","tags":"#go #guide"},{"id":"605cbf83fe856bac13eed76b251484c8","title":"Docker: jump into running container ","content":"docker run -it \u003chash\u003e /bin/bash\n","tags":"#docker #container #running #interactive #debugging"},{"id":"596aa6ddd65130402145fe5f2843471e","title":"Go: Sorting ","content":"// We already have sort.Ints() so this is a redundant implementation.\n\npackage main\n\nimport (\n\t\"fmt\"\n\t\"sort\"\n)\n\ntype items []int\n\nfunc (i items) Len() int {\n\treturn len(i)\n}\n\nfunc (i items) Less(a, b int) bool {\n\treturn i[a] \u003c i[b]\n}\n\nfunc (i items) Swap(a, b int) {\n\ti[a], i[b] = i[b], i[a]\n}\n\nfunc main() {\n\ti := []int{25, 1, 10, 5, 4, 7}\n\tsort.Sort(items(i))\n\tfmt.Println(i)\n}\npackage main\n\nimport (\n\t\"fmt\"\n\t\"sort\"\n)\n\ntype items []string\n\nfunc (i items) Len() int {\n\treturn len(i)\n}\n\nfunc (i items) Less(a, b int) bool {\n\treturn len(i[a]) \u003c len(i[b])\n}\n\nfunc (i items) Swap(a, b int) {\n\ti[a], i[b] = i[b], i[a]\n}\n\nfunc main() {\n\ti := []string{\"peach\", \"banana\", \"kiwi\"}\n\tsort.Sort(items(i))\n\tfmt.Println(i)\n}\n\n// In this example I want the 'default' starter kit to be first in the list.\n// We can't use the greater-than \u003e operator on a bool type so we have to convert to int.\n\npackage main\n\nimport (\n\t\"fmt\"\n\t\"sort\"\n\t\"strings\"\n)\n\ntype StarterKits struct {\n\tPath string\n}\n\nfunc main() {\n\tkits := []StarterKits{\n\t\t{Path: \"https://github.com/fastly/compute-starter-kit-rust-beacon-termination\"},\n\t\t{Path: \"https://github.com/fastly/compute-starter-kit-rust-static-content\"},\n\t\t{Path: \"https://github.com/fastly/compute-starter-kit-rust-default\"},\n\t}\n\tsort.Slice(kits, func(i, j int) bool {\n\t\tsuffix := \"rust-default\"\n\t\ta := strings.HasSuffix(kits[i].Path, suffix)\n\t\tb := strings.HasSuffix(kits[j].Path, suffix)\n\t\tvar (\n\t\t\tbitSetA int8\n\t\t\tbitSetB int8\n\t\t)\n\t\tif a {\n\t\t\tbitSetA = 1\n\t\t}\n\t\tif b {\n\t\t\tbitSetB = 1\n\t\t}\n\t\tfmt.Println(bitSetA, bitSetB)\n\t\treturn bitSetA \u003e bitSetB\n\t})\n\tfmt.Println(kits)\n}\n","tags":"#go"},{"id":"08ee3edb38514b4c68c05ae42fface89","title":"Go: test command usage ","content":"# go test \u003cpath_to_tests\u003e -- can be ./... for all found files or a specific path\n# use -v for verbose output\n# use -race to enable race detector\n# use -run to execute a single test\n#\ngo test ./pkg/logging/syslog/ -v -race -run TestSyslogList\n","tags":"#go #tests"},{"id":"206e546da66cf1a0dba6583f87b9e1ed","title":"Go: 'Application' and 'Workspace' Directory Structure ","content":"# Workspace \n\n\u003e [!NOTE]\n\u003e This information was copied from an older article, which didn't cover Go Modules.  \n\u003e https://www.digitalocean.com/community/tutorials/understanding-the-gopath\n\nInside of a Go Workspace, or `GOPATH`, there are three directories: `bin`, `pkg`, and `src`. Each of these directories has special meaning to the Go tool chain.\n\n## bin\n\nThe `$GOPATH/bin` directory is where Go places binaries that `go install` compiles. Our operating system uses the `$PATH` environment variable to find binary applications that can execute without a full path. It is recommended to add this directory to our global `$PATH` variable.\n\n## pkg\n\nThe `$GOPATH/pkg` directory is where Go stores pre-compiled object files to speed up subsequent compiling of programs. Typically, most developers won’t need to access this directory. If you experience issues with compilation, you can safely delete this directory and Go will then rebuild it.\n\n## src\n\nThe `src` directory is where all of our `.go` files, or source code, must be located (pre 1.13 when go modules were introduced!). This shouldn’t be confused with the source code the Go tooling uses, which is located at the `$GOROOT`. As we write Go applications, packages, and libraries, we will place these files under `$GOPATH/src/path/to/code`.\n\n# Application Structure\n\nIn order of priority:\n\n- https://blog.golang.org/organizing-go-code\n- https://rakyll.org/style-packages/\n- https://peter.bourgon.org/go-best-practices-2016/#repository-structure\n- https://github.com/golang-standards/project-layout (unofficial, and generally frowned upon by _official_ go authors †)\n\n\u003e † https://github.com/golang-standards/project-layout/issues/117\n\nOne of the Google Go authors states:\n\nFor the record, the _minimal_ standard layout for an importable Go repo is really:\n\n- Put a `LICENSE` file in your root\n- Put a `go.mod` file in your root\n- Put Go code in your repo, in the root or organized into a directory tree as you see fit\n\nThat's it. That's the \"standard\".\n\nIn particular:\n\n- It is not required to put commands in cmd/.\n- It is not required to put packages in pkg/.\n- It is not required to put web stuff in web/.\n- It is not required to put APIs in api/.\n- It is not required to put web stuff in web/.\n- It is not required to put configurations in configs/.\n- It is not required to put systemd scripts in init/.\n- It is not required to put shell scripts in scripts/.\n- It is not required to put Docker files in build/package/.\n- It is not required to put CI configs in build/ci/.\n- It is not required to put deployment configs in deployments/.\n- It is not required to put test support in test/.\n- It is not required to put documentation in docs/.\n- It is not required to put supporting tools in tools/.\n- It is not required to put examples in examples/.\n- It is not required to put third_party code in third_party/.\n- It is not required to put git hooks in githooks/\n- It is not required to put static assets in assets/.\n- It is not required to put website data in website/.\n\nThe importable `golang.org/x` repos break every one of these \"rules\".\n","tags":"#go #project"},{"id":"198c5a8cc7581c6dcf59374ef6948fc2","title":"Go: Custom Vegeta Attack ","content":"package main\n\nimport (\n\t\"fmt\"\n\t\"math/rand\"\n\t\"time\"\n\n\tvegeta \"github.com/tsenart/vegeta/lib\"\n)\n\n// randNDigits produces a random number N digits long.\n//\n// e.g. the args (0000, 9999) produces a random number inbetween that range and\n// would also be four digits in length.\n//\nfunc randNDigits(low, hi int) int {\n\treturn low + rand.Intn(hi-low)\n}\n\nfunc NewCustomTargeter() vegeta.Targeter {\n\treturn func(tgt *vegeta.Target) error {\n\t\tif tgt == nil {\n\t\t\treturn vegeta.ErrNilTarget\n\t\t}\n\n\t\tpayload := fmt.Sprintf(`{\"id\": %d}`, randNDigits(0000, 9999))\n\n\t\ttgt.Method = \"POST\"\n\t\ttgt.URL = \"https://httpbin.org/post\"\n\t\ttgt.Body = []byte(payload)\n\n\t\treturn nil\n\t}\n}\n\nfunc main() {\n\t/*\n\t\ttargeter := vegeta.NewStaticTargeter(vegeta.Target{\n\t\t\tMethod: \"GET\",\n\t\t\tURL:    \"http://localhost:9100/\",\n\t\t})\n\t*/\n\n\ttargeter := NewCustomTargeter()\n\tattacker := vegeta.NewAttacker()\n\n\trate := vegeta.Rate{Freq: 100, Per: time.Second}\n\tduration := 4 * time.Second\n\n\tvar metrics vegeta.Metrics\n\tfor res := range attacker.Attack(targeter, rate, duration, \"Load Test\") {\n\t\tmetrics.Add(res)\n\t}\n\tmetrics.Close()\n\n\tfmt.Printf(\"%+v\\n\", metrics)\n\n\t/*\n\t\t{\n\t\t  Latencies:{\n\t\t    Total:43.957975822s\n\t\t    Mean:109.894939ms\n\t\t    P50:84.906555ms\n\t\t    P95:290.766111ms\n\t\t    P99:343.919767ms\n\t\t    Max:373.975574ms\n\t\t    estimator:0xc000384058\n\t\t  }\n\t\t  Histogram:\u003cnil\u003e\n\t\t  BytesIn:{\n\t\t    Total:158322\n\t\t    Mean:395.805\n\t\t  }\n\t\t  BytesOut:{\n\t\t    Total:4761\n\t\t    Mean:11.9025\n\t\t  }\n\t\t  Earliest:2020-09-03 17:02:46.839298954 +0100 BST m=+0.011156791\n\t\t  Latest:2020-09-03 17:02:50.829355988 +0100 BST m=+4.001213825\n\t\t  End:2020-09-03 17:02:51.012499584 +0100 BST m=+4.184357421\n\t\t  Duration:3.990057034s\n\t\t  Wait:183.143596ms\n\t\t  Requests:400\n\t\t  Rate:100.24919358082539\n\t\t  Throughput:95.84969318860665\n\t\t  Success:1\n\t\t  StatusCodes:map[200:400]\n\t\t  Errors:[]\n\t\t  errors:map[]\n\t\t  success:400\n\t\t}\n\t*/\n}\n\nmodule test_vegeta\n\ngo 1.14\n\nrequire (\n\tgithub.com/influxdata/tdigest v0.0.1 // indirect\n\tgithub.com/mailru/easyjson v0.7.6 // indirect\n\tgithub.com/tsenart/vegeta v12.7.0+incompatible\n\tgolang.org/x/net v0.0.0-20200822124328-c89045814202 // indirect\n)\n","tags":"#go #performance"},{"id":"6bc0f9cb5a6d614ba3297e2c4a3a8050","title":"Work: Onboarding Best Practices ","content":"## Reference\n\n- https://www.justingarrison.com/blog/2020-08-31-remote-onboarding/\n- https://twitter.com/rothgar/status/1296911972215058432\n- https://twitter.com/rothgar/status/1296911975314677760\n\n## Problems\n\nThe problems I've had on-boarding remotely are\n\n- knowing what is expected of me\n- figuring out social norms and process\n- building trust and empathy\n- understanding current WIP and context\n- getting frequent feedback for how I'm doing\n- finding who to ask\n- remembering everything\n\n## Best Practices\n\n0. Equipment, accounts, access should all be setup BEFORE day 1. If someone starts work without these things you need to make that process better first.\n\nBefore day 1 your manager should reach out to provide their email address and cell number in case you have problems.\nAn email/text/phone call with what to expect can go a long way to make the process better\n\n1. First thing should be a video call with your manager. Ideally they will be available for questions for at least the first 1/2 of the day. If you run into problems they should be able to take action right away and not when they're done with meetings\n\n2. The manager should prepare a list of things to read in your first week. Wiki, chat rooms, code, etc. \n\nThis list should be explained during the first call and sent as an email to reference over the first few weeks.\n\nOne of those links should be documented expectations. Not informal, verbal information. Documented publicly to make sure everyone is on the same page (new hire, manager, co-workers)\n\nIdeally every company \u003e100 people will have an up to date website with org chart information, user aliases, email, phone numbers, etc. This is going to be crucial to new hires to understand how the company works and who they can talk to\n\nBonus points if the website has a way for the user to bookmark people and add private notes (this helps them remember context on when they met people) and name pronunciation.\n\nAmazon has phonetool with a couple of those features. Disney had rostr. WDAS had ohana\n\nYou need to invite the new hire into your #YELLING channel too. Maybe not day 1. But it should happen by day 3.\n\n3. Introduction meetings should be already planned and scheduled with co-workers and teams. Manager should send an introduction email for each meeting to introduce you and say what everyone on the meeting does\n\ne.g.\nThis is team X\nAdam is the manager\nJill is the Sr developer\n\n4. Manager should schedule a follow-up call for Wed or Thurs to check in and have a casual chat. Some people aren't comfortable asking questions via chat in new teams/companies.\n\n5. There should be an onboarding buddy which has a call day 1 or early day 2. They should daily chat with the new hire for the first ~1-2 weeks to see if there's anything they can help with.\n\n6. Optionally if onboarding a developer it's nice to open onboarding tickets in jira (or whatever you use) so they can be familiar with the workflows/planning and the team can track their onboarding process and help if they're stuck.\n\n7. End of week 1 or 2 there should be a team building/casual call with as many people on the immediate team as possible (timezones allowing) Build trust early and play games, ice breakers, whatever.\n","tags":"#onboarding #work #interviews"},{"id":"ddab5cf44b223a681e099a1ce107ba85","title":"Shell: Multiple searches via abstraction and grep ","content":"I have the following abstraction around the `ag` search tool:\n\n```bash\nfunction search {\n  # search for files based on content pattern\n  # uses 'silver searcher' `ag`\n\n  local flags=${1:-}\n  local pattern=$2\n  local directory=${3:-.}\n  local exclude=(\n    '(js/d3/|jquery|prototype).*\\.js'\n    '\\.eps'\n    '\\.gif'\n    '\\.git/'\n    '\\.html'\n    '\\.jpg'\n    '\\.json'\n    '\\.map'\n    '\\.mypy_cache'\n    '\\.psd'\n    '\\.sav'\n    '\\.so'\n    '\\.sql'\n    'build/'\n    'build\\.js'\n    'dist/'\n    'fb\\.js'\n    'node_modules'\n    'swagger'\n    'tests/'\n    'vendors-bundle\\.js'\n  )\n\n  if [ -z \"$1\" ]; then\n    printf \"\\\\n\\\\tUsage:\\\\n\\\\t\\\\tsearch \u003cflags:[--]\u003e \u003cpattern:['']\u003e \u003cdirectory:[./]\u003e\\\\n\"\n\n    # shellcheck disable=SC1117\n    # disabled because \\\\\\\\b for literal \\b (with double quotes) is ridiculous\n    printf '\\n\\tExample:\\n\\t\\tsearch -- \"def\\\\b\" ~/python/app'\n    printf '\\n\\t\\tsearch \"-G Dockerfile --context=5\" \"FROM\" ./'\n    return\n  fi\n\n  exclude_joined=$(join_by '|' ${exclude[@]})\n\n  # for some reason I can't just execute the command, I needed to evaluate it?\n  #\n  cmd=$(echo time ag --ignore \"'($exclude_joined)'\" \"$flags\" \"'$pattern'\" \"$directory\" 2\u003e/dev/null)\n  eval $cmd\n\n  # OLD IMPLEMENTATIONS...\n  #\n  # time sift -n -X json --err-skip-line-length --group --exclude-ipath \"$exclude\" \"$flags\" \"$pattern\" \"$directory\" 2\u003e/dev/null\n  # time grep --exclude-dir .git -irlno $pattern $directory\n}\n```\n\nI needed a way to search all Dockerfiles and then from the results of that search I needed to search another file (service.yml) for another phrase (launch_type).\n\nI couldn't do this with the search abstraction because when dealing with `xargs` the command needs to exist in `/bin/sh` and my `search` abstraction only exists when spinning up a `/bin/bash` shell. So I had to resort to using `grep` to do the secondary search.\n\n\u003e Note: I even tried doing `xargs -I {} bash -c \"search ...\"` but it still couldn't locate the search abstraction I had defined.\n\n```bash\nsearch \"-G Dockerfile -l\" \"FROM go\" | cut -d '/' -f 1 | tee /tmp/goservices | xargs -I {} grep -r --include service.yml launch_type {}\n```\n","tags":"#bash #shell #grep #search #ag #silversearcher"},{"id":"ed6f0b6948d8557abe2c80a192125f0e","title":"Security: Path Traversal ","content":"# Path-Traversal\nPath Traversal Tips\n\n\n\u003e   Always try path traversal sequences using both forward slashes and backslashes.\n    Many input filters check for only one of these, when the filesystem\n    may support both.\n\u003e 2. Try simple URL-encoded representations of traversal sequences using the\n   following encodings. Be sure to encode every single slash and dot within\n   your input:\n   * Dot — %2e\n   * Forward slash — %2f\n   * Backslash — %5c\n\u003e 3. Try using 16-bit Unicode encoding:\n  * Dot — %u002e\n  * Forward slash — %u2215\n  * Backslash — %u2216\n\u003e 4. Try double URL encoding:\n  * Dot — %252e\n  * Forward slash — %252f\n  * Backslash — %255c\n\u003e 5. Try overlong UTF-8 Unicode encoding:\n  * Dot — %c0%2e, %e0%40%ae, %c0ae, and so on\n  * Forward slash — %c0%af, %e0%80%af, %c0%2f, and so on\n  * Backslash — %c0%5c, %c0%80%5c, and so on\nYou can use the illegal Unicode payload type within Burp Intruder to\ngenerate a huge number of alternate representations of any given character\nand submit this at the relevant place within your target parameter.\nThese representations strictly violate the rules for Unicode representation\nbut nevertheless are accepted by many implementations of Unicode\ndecoders, particularly on the Windows platform.\n\u003e 6. If the application is attempting to sanitize user input by removing traversal\nsequences and does not apply this filter recursively, it may be\npossible to bypass the filter by placing one sequence within another.\n\nFor example:\n  * `....//`\n  * `....\\/`\n  * `..../\\`\n  * `....\\\\`\n\npackage main\n\nimport (\n\t\"fmt\"\n\t\"os\"\n\t\"path\"\n\t\"path/filepath\"\n\t\"regexp\"\n)\n\nfunc cleanup(input string) string {\n\tswitch input {\n\tcase \"%2e\":\n\t\treturn \".\"\n\tcase \"%2f\":\n\t\treturn \"/\"\n\tdefault:\n\t\treturn input\n\t}\n}\n\nfunc main() {\n\tre := regexp.MustCompile(`(?i)%2(?:e|f)`)\n\n\tpaths := []string{\n\t\t\"../\",\n\t\t\"%2e./\",\n\t\t\".%2e/\",\n\t\t\"..%2f\",\n\t\t\"%2e%2e/\",\n\t\t\"%2e%2e%2f\",\n\t\t\"foo/../bar\",\n\t\t\"/static-assets/example/pages[...slug].js\",\n\t}\n\n\tfor _, p := range paths {\n\t\tfmt.Println(\"\\ninput path:\", p)\n\n\t\tp = re.ReplaceAllStringFunc(p, cleanup)\n\t\tfmt.Println(\"replace path:\", p)\n\n\t\tif !filepath.IsAbs(p) {\n\t\t\tp = path.Clean(string(os.PathSeparator) + p)\n\t\t\tfmt.Println(\"clean path:\", p)\n\t\t}\n\t}\n}\n// services that include this shared VCL should ensure they do not utilize the\n// same error code, otherwise they may end up sending the wrong response.\n//\n\nsub security_recv {\n  // we want to prevent path traversal vulnerabilities such as:\n  //\n  // curl -v \"https://httpbin.org/status/200/../../anything/status/404/\"\n  //\n  // this ^^ would cause the server to go to /anything/status/404/ not /status/200\n  //\n  // this could be an issue because the upstream server might be able to\n  // communicate with private/internal APIs, and so this type of attack could\n  // enable the caller to access whatever data the server would normally only\n  // have access to.\n  //\n  // example pattern match:\n  // https://regex101.com/r/RYhmwW/2\n  //\n  // NOTES:\n  // we utilize a 'long string' {\"...\"} instead of a string literal \"...\"\n  // to avoid interpretting the %2E as a period character when VCL statically\n  // compiles a regex (which would change the pattern quite significantly!)\n  //\n  // DOCUMENTATION:\n  // https://developer.fastly.com/reference/vcl/types/string/\n  //\n  if (req.url.path ~ {\"(?i)(\\.|%2E){2}(/|%2F)\"}) {\n    error 699 \"Bad Request\";\n  }\n}\n\nsub security_error {\n  if (obj.status == 699) {\n    set obj.status = 400;\n    synthetic {\"Bad Request\"};\n    return(deliver);\n  }\n}\n","tags":"#security #hack #pentesting #traversal #path #encoding"},{"id":"f043af7c820246215b2a2524585b3270","title":"Better Terraform Diff ","content":"#!/usr/bin/env bash\n\n# Get plan\nterraform plan -out=tfplan \u003e /dev/null 2\u003e\u00261\n\n# Convert plan to json\nCHANGES=$(terraform show -json tfplan | jq '.resource_changes[].change')\n\n# Diff before and after with newlines expanded\ndiff -u \\\n  \u003c(echo \"$CHANGES\" | jq '.before' | sed 's/\\\\n/\\//g') \\\n  \u003c(echo \"$CHANGES\" | jq '.after' | sed 's/\\\\n/\\//g')\n\n# If you prefer to use another diff tool like `git diff`\necho \"$CHANGES\" | jq '.before' | sed 's/\\\\n/\\//g' \u003e before\necho \"$CHANGES\" | jq '.after' | sed 's/\\\\n/\\//g' \u003e after\ngit diff --no-index before after\nrm before after\n","tags":"#shell #iac"},{"id":"d9c1e5680ac4574f9f5b120087a925bb","title":"Datadog Terraform - Import Existing Resource ","content":"# -- define a boilerplate resource as per https://www.terraform.io/docs/import/usage.html --\n# -- avoid datadog_timeboard as that's deprecated in favour of datadog_dashboard --\n# terraform init\n# terraform 0.13upgrade .\n# terraform init\n# terraform import datadog_dashboard.example_timeboard abc-de1-fgh\n# terraform import datadog_monitor.example_monitor 12345678\n# terraform show -no-color \u003e\u003e main.tf\n# -- delete boilerplate 'resource' block and clean up appended version --\n# terraform validate\n# terraform fmt\n# terraform plan\n# -- delete any incorrect syntax from 'terraform show' such as going from \u003c\u003c~EOT to \u003c\u003cEOT --\n# -- delete any unknown keys that exist because of 'terraform show' and which shouldn't be part of actual terraform code --\n# -- clean up any inline messages that might have different spacing due to HEREDOC format of \u003c\u003cEOT --\n# -- when using a datadog_timeboard there were the following issues... --\n# -- ensure jsonencode() is given keys as strings whenever $ syntax used as it'll cause validation errors --\n# -- some graph widgets aren't really graphs (e.g. a \"note\" widget) so it is missing the \"title\" field + wont have a \"request\" block either --\n\nprovider \"datadog\" {\n  api_key = var.datadog_api_key\n  app_key = var.datadog_app_key\n}\n\nresource \"datadog_monitor\" \"example_monitor\" {}\nresource \"datadog_dashboard\" \"example_timeboard\" {}\nvariable \"datadog_api_key\" {\n  default = \"123\"\n}\n\nvariable \"datadog_app_key\" {\n  default = \"456\"\n}\n\n","tags":"#iac"},{"id":"1ef7f2da72e4a520a8fca1aeb7b45074","title":"CLI Diff Tools ","content":"- https://www.colordiff.org/ (`diff | colordiff | less -R`)\n- https://www.jefftk.com/icdiff\n- https://github.com/dandavison/delta (need to use it with git: `git diff --no-index file1.txt file2.txt`)\n","tags":"#shell"},{"id":"d92513dc93e019e7337d9bfa7790fee3","title":"Convert a Map to a Struct ","content":"Going from a map (such as `map[string]interface`) to a struct is possible, but you need to run through the following steps:\n\n- `json.Marshal(\u003cmap\u003e)` into json (returns: `[]byte`)\n- `json.Unmarshal(\u003cjsonByteSlice\u003e, \u003cpointerToStruct\u003e)`\n\n\u003e Note: an example of why you would do this is when getting a JSON API response (in that scenario you'd also have to first `json.Unmarshal` the JSON data into a map, so that's yet _another_ step!)\n\nIt would be nice if the steps could just be:\n\n- Decode `map[string]interface` to `\u003cpointerToStruct\u003e`.\n\nThis is where the `mitchellh/mapstructure` package comes in. It utilizes reflection to support this behaviour.\n\n```go\npackage main\n\nimport (\n\t\"fmt\"\n\n\t\"github.com/mitchellh/mapstructure\"\n)\n\ntype Data struct {\n\tFoo int\n\tBar string\n\tBaz bool `mapstructure:\"beep\"` // demonstrates how to translate a map key to a different struct field\n}\n\nfunc main() {\n\tm := map[string]interface{}{\n\t\t\"foo\":  5,\n\t\t\"bar\":  \"nice\",\n\t\t\"beep\": true, // this will be stored in a field called 'Baz'\n\t}\n\tfmt.Printf(\"%+v\\n\", m) // map[bar:nice boolean:true foo:5]\n\n\tvar result Data\n\tmapstructure.Decode(m, \u0026result)\n\tfmt.Printf(\"%+v\\n\", result) // {Foo:5 Bar:nice Baz:true}\n}\n```\n","tags":"#go #serialization"},{"id":"4bdf64d8c4d36dcc204cd6e44233bf22","title":"Mock HTTP Response via RoundTripper interface ","content":"package main\n\nimport (\n\t\"bytes\"\n\t\"fmt\"\n\t\"io/ioutil\"\n\t\"net/http\"\n\t\"os\"\n\t\"time\"\n)\n\ntype MockRoundTripper struct{}\n\nfunc (rt MockRoundTripper) RoundTrip(req *http.Request) (*http.Response, error) {\n\tfmt.Printf(\"http.Request: %+v\\n\", req)\n\n\tres := \u0026http.Response{\n\t\tStatusCode: 404,\n\t\tBody:       ioutil.NopCloser(bytes.NewBufferString(\"Not Found!?\")),\n\t\tHeader:     make(http.Header),\n\t}\n\n\treturn res, nil\n}\n\nfunc main() {\n\thttpclient := \u0026http.Client{\n\t\tTimeout:   time.Second * 10,\n\t\tTransport: MockRoundTripper{},\n\t}\n\n\tresponse, err := httpclient.Get(\"https://www.integralist.co.uk/\")\n\tif err != nil {\n\t\tfmt.Println(err.Error())\n\t\tos.Exit(1)\n\t}\n\tdefer response.Body.Close()\n\n\tbody, err := ioutil.ReadAll(response.Body)\n\tif err != nil {\n\t\tfmt.Println(err.Error())\n\t\tos.Exit(1)\n\t}\n\n\tfmt.Println(string(body))\n\tfmt.Println(response.Status)\n}\n// modified from https://gist.github.com/jarcoal/8940980\n//\n\npackage main\n\nimport (\n\t\"bytes\"\n\t\"fmt\"\n\t\"io/ioutil\"\n\t\"net/http\"\n\t\"os\"\n\t\"time\"\n)\n\ntype Responder func(*http.Request) (*http.Response, error)\n\ntype MockRoundTripperMultiples struct {\n\thost       string\n\tresponders map[string]Responder\n}\n\nfunc (rt MockRoundTripperMultiples) RoundTrip(req *http.Request) (*http.Response, error) {\n\tkey := req.Method + \" \" + req.URL.String()\n\n\tfor k, r := range rt.responders {\n\t\tif k != key {\n\t\t\tcontinue\n\t\t}\n\t\treturn r(req)\n\t}\n\n\treturn http.DefaultTransport.RoundTrip(req)\n}\n\nfunc (rt *MockRoundTripperMultiples) RegisterResponder(method, path string, responder Responder) {\n\tif rt.responders == nil {\n\t\trt.responders = make(map[string]Responder)\n\t}\n\trt.responders[method+\" \"+rt.BuildURL(path)] = responder\n}\n\nfunc (rt *MockRoundTripperMultiples) BuildURL(path string) string {\n\treturn \"https://\" + rt.host + path\n}\n\nfunc requestOK(*http.Request) (*http.Response, error) {\n\treturn \u0026http.Response{\n\t\tStatusCode: 200,\n\t\tBody:       ioutil.NopCloser(bytes.NewBufferString(\"OK!!!\")),\n\t\tHeader:     make(http.Header),\n\t}, nil\n}\n\nfunc requestBad(*http.Request) (*http.Response, error) {\n\treturn \u0026http.Response{\n\t\tStatusCode: 400,\n\t\tBody:       ioutil.NopCloser(bytes.NewBufferString(\"Bad Request!??\")),\n\t\tHeader:     make(http.Header),\n\t}, nil\n}\n\nfunc get(url string, httpclient *http.Client) *http.Response {\n\tres, err := httpclient.Get(url)\n\tif err != nil {\n\t\tfmt.Println(err.Error())\n\t\tos.Exit(1)\n\t}\n\n\treturn res\n}\n\nfunc read(url string, httpclient *http.Client) {\n\tres := get(url, httpclient)\n\n\tbody, err := ioutil.ReadAll(res.Body)\n\tif err != nil {\n\t\tfmt.Println(err.Error())\n\t\tos.Exit(1)\n\t}\n\tdefer res.Body.Close()\n\n\tfmt.Println(string(body))\n\tfmt.Println(res.Status)\n}\n\nfunc main() {\n\ttransport := \u0026MockRoundTripperMultiples{\n\t\thost: \"www.integralist.co.uk\",\n\t}\n\ttransport.RegisterResponder(\"GET\", \"/good\", requestOK)\n\ttransport.RegisterResponder(\"GET\", \"/bad\", requestBad)\n\n\thttpclient := \u0026http.Client{\n\t\tTimeout:   time.Second * 10,\n\t\tTransport: transport,\n\t}\n\n\tread(\"https://www.integralist.co.uk/good\", httpclient)\n\tread(\"https://www.integralist.co.uk/bad\", httpclient)\n\n\t// no registered 'responder' matches the following URL so it will fallback to\n\t// using http.DefaultTransport.RoundTrip implementation to make a 'real'\n\t// network request.\n\tread(\"https://www.integralist.co.uk/about\", httpclient)\n}\n## 2025 Update\n\nHere's the latest approach I've used:\nhttps://github.com/fastly/cli/pull/1374/commits/98742dcfebe896e7b97bfbdb8f72906aede71594\n\nFirst, the test itself:\n\n```go\n// pkg/commands/domainv1/domain_test.go\npackage domainv1_test\n\nimport (\n\t\"bytes\"\n\t\"fmt\"\n\t\"io\"\n\t\"net/http\"\n\t\"testing\"\n\n\tv1 \"github.com/fastly/go-fastly/v9/fastly/domains/v1\"\n\n\troot \"github.com/fastly/cli/pkg/commands/domainv1\"\n\t\"github.com/fastly/cli/pkg/testutil\"\n)\n\nfunc TestDomainV1Create(t *testing.T) {\n\tfqdn := \"www.example.com\"\n\tsid := \"123\"\n\tdid := \"domain-id\"\n\n\tscenarios := []testutil.CLIScenario{\n\t\t{\n\t\t\tArgs:      \"\",\n\t\t\tWantError: \"error parsing arguments: required flag --fqdn not provided\",\n\t\t},\n\t\t{\n\t\t\tArgs: fmt.Sprintf(\"--fqdn %s --service-id %s\", fqdn, sid),\n\t\t\tClient: \u0026http.Client{\n\t\t\t\tTransport: \u0026testutil.MockRoundTripper{\n\t\t\t\t\tResponse: \u0026http.Response{\n\t\t\t\t\t\tStatusCode: http.StatusOK,\n\t\t\t\t\t\tStatus:     http.StatusText(http.StatusOK),\n\t\t\t\t\t\tBody: io.NopCloser(bytes.NewReader(testutil.GenJSON(v1.Data{\n\t\t\t\t\t\t\tDomainID:  did,\n\t\t\t\t\t\t\tFQDN:      fqdn,\n\t\t\t\t\t\t\tServiceID: \u0026sid,\n\t\t\t\t\t\t}))),\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\tWantOutput: fmt.Sprintf(\"SUCCESS: Created domain '%s' (domain-id: %s, service-id: %s)\", fqdn, did, sid),\n\t\t},\n\t}\n\ttestutil.RunCLIScenarios(t, []string{root.CommandName, \"create\"}, scenarios)\n}\n```\n\nSecond, the supporting test util functions:\n\n```go\n// pkg/testutil/client.go\n\npackage testutil\n\nimport (\n  \"encoding/json\"\n  \"net/http\"\n)\n\n// MockRoundTripper implements [http.RoundTripper] for mocking HTTP responses\ntype MockRoundTripper struct {\n\tResponse *http.Response\n\tErr      error\n}\n\n// RoundTrip executes a single HTTP transaction, returning a Response for the\n// provided Request.\nfunc (m *MockRoundTripper) RoundTrip(req *http.Request) (*http.Response, error) {\n\treturn m.Response, m.Err\n}\n\n// GenJSON returns JSON encoding of data, or empty object in case of an error.\nfunc GenJSON(data any) []byte {\n\tb, err := json.Marshal(data)\n\tif err != nil {\n\t\treturn []byte(\"{}\")\n\t}\n\treturn b\n}\n```\n\nThird, modified scenario codebase:\n\n```go\n// pkg/testutil/scenarios.go\n\nvar acf global.APIClientFactory\nif scenario.Client != nil {\n  acf = func(_, _ string, _ bool) (api.Interface, error) {\n    fc, err := fastly.NewClientForEndpoint(\"no-key\", \"api.example.com\")\n    if err != nil {\n      return nil, fmt.Errorf(\"failed to mock fastly.Client: %w\", err)\n    }\n    fc.HTTPClient = scenario.Client\n    return fc, nil\n  }\n} else {\n  acf = mock.APIClient(scenario.API)\n}\nopts.APIClientFactory = acf\n```\n","tags":"#go #http"},{"id":"d7766801960dfe275bfd3bfe30359966","title":"HTTP routing in Go ","content":"## Reference\n\n- https://benhoyt.com/writings/go-routing/\n- https://github.com/benhoyt/go-routing\n\n## Approaches\n\n- **Regex Table**: loop through pre-compiled regexes and pass matches using the request context.\n- **Regex Switch**: a switch statement with cases that call a regex-based match() helper which scans path parameters into variables.\n- **Pattern Matcher**: similar to the above, but using a simple pattern matching function instead of regexes.\n- **Split Switch**: split the path on / and then switch on the contents of the path segments.\n- **ShiftPath**: Axel Wagner’s hierarchical ShiftPath technique.\n\n## Performance\n\nIn this comparison we're not concerned about speed. Most of the approaches loop or switch through a list of routes (in contrast to fancy trie-lookup structures). All of these approaches only add a few microseconds to the request time, and that isn't an issue in the majority of web applications.\n\n## Opinions\n\nBelow are the opinions of the author of the article (linked above), while my (@integralist) own preference is towards \"Regex Switch\" due to the ease of implementation and the ease of understanding for engineers working on the code, as well as the extra flexibility you get over the \"Regex Table\" approach.\n\n### Regex Table\n\n- https://benhoyt.com/writings/go-routing/#regex-table\n- https://github.com/benhoyt/go-routing/blob/master/retable/route.go\n\nIt's basically a table of pre-compiled regexp objects with a little 21-line routing function that loops through them, and calls the first one that matches both the path and the HTTP method.\n\nThere's nothing particularly clever about the regex table approach, and it's similar to how a number of the third-party packages work. But it's so simple it only takes a few lines of code and a few minutes to write. It's also easy to modify if you need to: for example, to add logging, change the error responses to JSON, and so on.\n\n### Regex Switch\n\n- https://benhoyt.com/writings/go-routing/#regex-switch\n- https://github.com/benhoyt/go-routing/blob/master/reswitch/route.go\n\nThe second approach still uses regexes, but with a simple imperative switch statement and a `match()` helper to go through the matches. The advantage of this approach is that you can call other functions or test other things in each case. Also, the signature of the `match` function allows you to \"scan\" path parameters into variables in order to pass them to the handlers more directly.\n\nI must admit to being quite fond of this approach. I like how simple and direct it is, and I think the scan-like behaviour for path parameters is clean. Overall, despite liking the clarity of this approach and the scan-like `match()` helper, a point against it is the messiness required to cache the regex compilation.\n\n### Pattern Matcher\n\n- https://benhoyt.com/writings/go-routing/#pattern-matcher\n- https://github.com/benhoyt/go-routing/blob/master/pat/route.go\n\nThis approach is similar to the regex switch method, but instead of regexes it uses a simple, custom pattern matcher.\n\nThe patterns supplied to the custom `match()` function handle one wildcard character, `+`, which matches (and captures) any characters till the next `/` in the request path. This is of course much less powerful than regex matching, but generally I've not needed anything more than \"match till next slash\" in my routes.\n\nI quite like this approach (and it's efficient), but the byte-by-byte matching code was a little fiddly to write – definitely not as simple as calling `regex.FindStringSubmatch()`.\n\n### Split Switch\n\n- https://benhoyt.com/writings/go-routing/#split-switch\n- https://github.com/benhoyt/go-routing/blob/master/split/route.go\n\nThis approach simply splits the request path on `/` and then uses a switch with case statements that compare the number of path segments and the content of each segment. It's direct and simple, but also a bit error-prone, with lots of hard-coded lengths and indexes.\n\nSo while I like the bare-bones simplicity of this approach – just basic string equality comparisons – the verbosity of the matching and the error-prone integer constants would make me think twice about actually using it for anything but very simple routing.\n\n### ShiftPath\n\n- https://benhoyt.com/writings/go-routing/#shiftpath\n- https://github.com/benhoyt/go-routing/blob/master/shiftpath/route.go\n\nA technique involving a small `ShiftPath()` helper that returns the first path segment, and shifts the rest of the URL down. The current handler switches on the first path segment, then delegates to sub-handlers which do the same thing on the rest of the URL.\n\nWhile I like the idea of just using the standard library, and the path-shifting technique is quite clever, I strongly prefer seeing my URLs all in one place – This approach spreads the logic across many handlers, so it's difficult to see what handles what. It's also quite a lot of code, some of which is error prone.\n\nOn balance, I find it too verbose and think it'd be difficult for people reading the code to quickly answer the question, \"given this HTTP method and URL, what happens?\"\n","tags":"#go #http"},{"id":"bb73c04c2764cdf40cdcb0eabe845eba","title":"Ex-mode Automation ","content":"vim -E -s config.txt \u003c\u003c-EOF\n  :%s/foo/bar/\n  :update\n  :quit\nEOF\n# UPDATE INTERFACE FILE\n#\n# The interface file contains all the API functions we expect to use from the\n# go-fastly SDK. When adding a new command, we want to update this file to\n# reflect any new API functions we're intending to use.\n#\n# I use Vim to handle the processing because it's easier for me (@integralist)\n# to write the otherwise complex logic, compared to trying to use bash or some\n# other tool such as Awk.\n#\n# STEPS:\n# - We locate the Interface type.\n# - Copy the last set of interface methods.\n# - Capture line number for start of copied methods (to use in substitution).\n# - Rename the API (three separate places per line).\n#\n# NOTE:\n# Any backslash in the substitution commands (e.g. \\v) need to be double escaped.\n#   - Once because the backslash is inside the :exe command's expected string.\n#   - And then again because of the parent HEREDOC container.\n#\n# CAVEATS:\n# This isn't a perfect process. Its successfulness is based on whether the last\n# set of commands align with our expectations. It will still produce ~95%\n# expected output, but if there's an extra API function (e.g. BatchModify) then\n# that line won't have the relevant API name replaced as we only look for the\n# common CRUD methods (Create, Delete, Get, List, Update).\n#\nCLI_API=\"FooBar\"\nvim -E -s pkg/api/interface.go \u003c\u003c-EOF\n\t:g/type Interface interface/norm $%k\n\t:norm V{yP]mk\n\t:norm {\n\t:call setreg('a', line('.'))\n\t:norm ]mk\n\t:exe getreg(\"a\")\",\"line(\".\")\"s/\\\\\\v(Create|Delete|Get|List|Update)[^(]+/\\\\\\1${CLI_API}/\"\n\t:exe getreg(\"a\")\",\"line(\".\")\"s/\\\\\\v(fastly\\\\\\.)(Create|Delete|Get|List|Update)[^)]+(Input)/\\\\\\1\\\\\\2${CLI_API}\\\\\\3/\"\n\t:exe getreg(\"a\")\",\"line(\".\")\"s/\\\\\\v\\\\\\((\\\\\\[\\\\\\])?\\\\\\*(fastly\\\\\\.)[^,]+/(\\\\\\1*\\\\\\2${CLI_API}/\"\n\t:update\n\t:quit\nEOF\n\n# The above takes advantage of multiple Vim features to workaround the fact that we're constrained primarily to using Ex commands to achieve this automation...\n#\n# 1. We can't use / to search for content, so I have to use :global along with :normal to get my cursor to where it needs to be.\n# \n# 2. I don't know how many lines need to be copied, so I rely on Vim's notion of a \"paragraph\" i.e. `{` motion\n#\n# 3. Once I've copied the relevant text I need to get back to the original position my cursor was at. I would normally use \u003cCtrl-o\u003e to go back once in Vim's jumplist, but there's no Ex mode equivalent command to achieve this and I also couldn't get :execute to work with \u003cCtrl-o\u003e inside a :normal string expression. So I resorted to another Vim motion `]m` which luckily for my use case jumped me to the bottom of the code function I was in (which was where I needed to be). I could have just reused the :global trick but I wanted to avoid duplication of logic if possible and the motion was a quick win.\n#\n# 4. When using a substiution you can manually select the lines you want as a range, but with automation I don't know what the range should be (as it has to be programmatically determined) so this meant I needed to use some VimL. I start by using the `{` motion to get back to the top of the section of code I want to apply a substitution to and store the current line into a register using `setreg(...)` and `line('.')`. I then jump back to where I was before and I use `getreg(...)` to use as the start of my substitution range followed by `line('.')` as the end of the range. All of this is wrapped up with `:execute` and so we have to use the `\",\"` string in-between to build up the range, and also put the substitution into a string.\n#\n# 5. As mentioned in the above NOTE I needed to double escape the backslashes used in the substitution. Which is a super pain.\n","tags":"#shell #vim"},{"id":"116263155d901190aece7b67d3d2852c","title":"Walk different types via reflection ","content":"// Write a function:\n//\n// walk(x interface{}, fn func(string)) \n//\n// ...which takes a struct x and calls fn for all strings fields found inside.\n//\n\nfunc walk(x interface{}, fn func(input string)) {\n    val := getValue(x)\n\n    walkValue := func(value reflect.Value) {\n        walk(value.Interface(), fn)\n    }\n\n    switch val.Kind() {\n    case reflect.String:\n        fn(val.String())\n    case reflect.Struct:\n        for i := 0; i \u003c val.NumField(); i++ {\n            walkValue(val.Field(i))\n        }\n    case reflect.Slice, reflect.Array:\n        for i := 0; i \u003c val.Len(); i++ {\n            walkValue(val.Index(i))\n        }\n    case reflect.Map:\n        for _, key := range val.MapKeys() {\n            walkValue(val.MapIndex(key))\n        }\n    case reflect.Chan:\n        for v, ok := val.Recv(); ok; v, ok = val.Recv() {\n            walk(v.Interface(), fn)\n        }\n    case reflect.Func:\n        valFnResult := val.Call(nil)\n        for _, res := range valFnResult {\n            walk(res.Interface(), fn)\n        }\n    }\n}\n","tags":"#go"},{"id":"c48d34af47e8fa39afba6caa42b69877","title":"Functional Programming Map ","content":"// REFERENCE:\n// https://blog.burntsushi.net/type-parametric-functions-golang/\n//\n\npackage main\n\nimport (\n\t\"fmt\"\n\t\"log\"\n\t\"reflect\"\n)\n\nfunc Map(f interface{}, xs interface{}) interface{} {\n\tvf := reflect.ValueOf(f)\n\tvxs := reflect.ValueOf(xs)\n\n\tftype := vf.Type()\n\txstype := vxs.Type()\n\n\t// 1) Map's first parameter type must be `func(A) B`\n\tif ftype.Kind() != reflect.Func {\n\t\tlog.Panicf(\"`f` should be %s but got %s\", reflect.Func, ftype.Kind())\n\t}\n\tif ftype.NumIn() != 1 {\n\t\tlog.Panicf(\"`f` should have 1 parameter but it has %d parameters\",\n\t\t\tftype.NumIn())\n\t}\n\tif ftype.NumOut() != 1 {\n\t\tlog.Panicf(\"`f` should return 1 value but it returns %d values\",\n\t\t\tftype.NumOut())\n\t}\n\n\t// 2) Map's second parameter type must be `[]A1` where `A == A1`.\n\tif xstype.Kind() != reflect.Slice {\n\t\tlog.Panicf(\"`xs` should be %s but got %s\", reflect.Slice, xstype.Kind())\n\t}\n\tif xstype.Elem() != ftype.In(0) {\n\t\tlog.Panicf(\"type of `f`'s parameter should be %s but xs contains %s\",\n\t\t\tftype.In(0), xstype.Elem())\n\t}\n\n\t// 3) Map's return type must be `[]B1` where `B == B1`.\n\ttys := reflect.SliceOf(vf.Type().Out(0))\n\n\tvys := reflect.MakeSlice(tys, vxs.Len(), vxs.Len())\n\tfor i := 0; i \u003c vxs.Len(); i++ {\n\t\ty := vf.Call([]reflect.Value{vxs.Index(i)})[0]\n\t\tvys.Index(i).Set(y)\n\t}\n\treturn vys.Interface()\n}\n\nfunc main() {\n\tsquared := Map(func(x int) int { return x * x }, []int{1, 2, 3}).([]int)\n\n\tfmt.Printf(\"%+v\\n\", squared) // [1 4 9]\n  \n\tsquared = Map(func(a string) int { return len(a) }, []int{1, 2, 3}).([]int)\n\t\n\tfmt.Printf(\"%+v\\n\", squared) // panic: type of `f`'s parameter should be string but xs contains int\n}\n","tags":"#go"},{"id":"aa651c6fdaf812b6ba7e3d04193b6434","title":"Go: defer with os.Exit(N) ","content":"package main\n\nimport (\n\t\"fmt\"\n\t\"os\"\n\t\"runtime\"\n)\n\n/*\nGoexit terminates the goroutine that calls it. No other goroutine is affected. Goexit runs all deferred calls before terminating the goroutine. Because Goexit is not a panic, any recover calls in those deferred functions will return nil.\n\nCalling Goexit from the main goroutine terminates that goroutine without func main returning. Since func main has not returned, the program continues execution of other goroutines. If all other goroutines exit, the program crashes.\n\nhttps://golang.org/pkg/runtime/#Goexit\n*/\n\nfunc main() {\n\tdefer os.Exit(0)\n\tfmt.Println(\"Hello, playground\")\n\tdefer fmt.Println(\"end\")\n\truntime.Goexit() // instead of os.Exit(1)\n}\n\n","tags":"#go"},{"id":"6aacefc40dbde3d39a17c4813721f063","title":"Go: manage external tools via go modules ","content":"\u003e [!IMPORTANT]\n\u003e Read https://gist.github.com/Integralist/e19c9faee86e797125e6d95fe1188912 instead.\n\n## Go 1.16\n\nAs of Go version `1.16` the `go` command changed behaviour for `get` and `install`:\n\n- `install`: the recommended way to install packages (ignoring \n- `get`: adds dependencies to your project's go modules file (i.e. `go.mod`).\n\nThe `go install` command now accepts a version suffix:\n\n```\ngo install example.com/cmd@v1.0.0\n```\n\n## Pre Go 1.16\n\nBefore Go version `1.16` we needed to resort to other ways of getting a resource.\n\nHave the following package `tools/tools.go`:\n\n```go\n// +build tools\n\npackage tools\n\nimport (\n\t// document generation\n\t_ \"github.com/hashicorp/terraform-plugin-docs/cmd/tfplugindocs\"\n)\n```\n\n\u003e **Note**: the use of a build tag means `go build` won't compile the code into your binary.\n\nHave the following `Makefile`:\n\n```Makefile\nBIN=$(CURDIR)/bin\n$(BIN)/%:\n\t@echo \"Installing tools from tools/tools.go\"\n\t@cat tools/tools.go | grep _ | awk -F '\"' '{print $$2}' | GOBIN=$(BIN) xargs -tI {} go install {}\n\n# Inject ./bin into PATH to allow scripts/generate-docs.go to access local tfplugindocs binary\ngenerate-docs: $(BIN)/tfplugindocs\n\tPATH=$(PATH):$(BIN) go run scripts/generate-docs.go\n\nvalidate-docs: $(BIN)/tfplugindocs\n\t$(BIN)/tfplugindocs validate\n```\n\n\u003e **Note**: pay special attention to the fact that `$` is a reserved symbol in a Makefile so we have to escape it: `$$`.\n\nNow you'll find you have the dependency installed:\n\n```bash\nls -la $GOPATH/bin\n\n-rwxr-xr-x   1 integralist  staff  22965276  2 Feb 13:52 tfplugindocs*\n```\n","tags":"#go #dependencies"},{"id":"4493c6f895c6771b13d0324949c08977","title":"Pretty Print Dictionary ","content":"import json\n\nprint(json.dumps({\"foo\": {\"bar\": {\"baz\": 123}}}, indent=2, default=str))\n\n# outputs...\n{\n  \"foo\": {\n    \"bar\": {\n      \"baz\": 123\n    }\n  }\n}\n","tags":"#python"},{"id":"9434e6fa5977f9626b470b46a0d02149","title":"CI: Github Action Workflow Example ","content":"See https://github.com/Integralist/actions-testing for working examples.\n\n\u003e **DOCS**: [Syntax](https://docs.github.com/en/actions/learn-github-actions/workflow-syntax-for-github-actions) and [Expressions](https://docs.github.com/en/actions/learn-github-actions/expressions).\n\nThe following example demonstrates a few things...\n\n1. Events using `on`.\n2. Generating multiple jobs using `strategy.matrix`.\n3. Overriding specific variables using `include`.\n4. Setting environment variables using `env`.\n5. Defining a multiline script (for readability) using yaml `|` operator.\n\n```yml\n# .github/workflows/release.yaml \n\nname: Main\n\non:\n  push:\n    tags:\n      - 'v*.*.*'\n\njobs:\n  build:\n    strategy:\n      matrix:\n        rust-toolchain: [stable]\n        os: [ubuntu-latest, macos-latest, windows-latest]\n        arch: [amd64, arm64]\n        include:\n          - os: ubuntu-latest\n            name: linux\n          - os: macos-latest\n            name: darwin\n            rust-target: x86_64-apple-darwin\n          - os: windows-latest\n            name: windows\n            extension: .exe\n    runs-on: ${{ matrix.os }}\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v2\n        with:\n          submodules: true\n\n      - name: Install latest Rust toolchain\n        uses: actions-rs/toolchain@v1\n        with:\n          toolchain: ${{ matrix.rust-toolchain }}\n          target: ${{ matrix.rust-target }}\n          default: true\n          override: true\n\n      - name: Extract tag name\n        uses: olegtarasov/get-tag@v2.1\n        id: tagName\n        \n    - name: Test\n      run: make test\n      shell: bash\n      env:\n        TEST_COMPUTE_INIT: true\n        TEST_COMPUTE_BUILD: true\n        TEST_COMPUTE_DEPLOY: true\n\n      - name: Build\n        run: |\n          cargo build --all --release --locked\n          cd target/release\n\n      - name: Package\n        run: |\n          strip viceroy${{ matrix.extension }}\n          tar czf viceroy_${{ steps.tagName.outputs.tag }}_${{ matrix.name }}-${{ martrix.arch }}.tar.gz viceroy${{ matrix.extension }}\n\n      - name: Release\n        uses: softprops/action-gh-release@v1\n        with:\n          files: |\n            target/release/viceroy_${{ steps.tagName.outputs.tag }}_${{ matrix.name }}-${{ martrix.arch }}.tar.gz\n        env:\n          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n```\n# .github/workflows/release.yaml \nname: Main\n\non:\n  push:\n    tags:\n      - \"v*.*.*\"\n\njobs:\n  build:\n    strategy:\n      matrix:\n        rust-toolchain: [stable]\n        os: [ubuntu-latest, macos-11, windows-latest]\n        arch: [amd64, arm64]\n        exclude:\n          - os: windows-latest\n            arch: arm64\n        include:\n          - os: ubuntu-latest\n            name: linux\n            rust_abi: unknown-linux-gnu\n          - os: macos-11\n            name: darwin\n            rust_abi: apple-darwin\n          - os: windows-latest\n            name: windows\n            rust_abi: pc-windows-msvc\n            extension: .exe\n          - arch: arm64\n            rust_arch: aarch64\n          - arch: amd64\n            rust_arch: x86_64\n\n    runs-on: ${{ matrix.os }}\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v2\n        with:\n          submodules: true\n\n      - name: Install latest Rust toolchain\n        uses: actions-rs/toolchain@v1\n        with:\n          toolchain: ${{ matrix.rust-toolchain }}\n          target: ${{ matrix.rust_arch }}-${{ matrix.rust_abi }}\n          default: true\n          override: true\n\n      - name: Install C cross-compilation toolchain\n        if: ${{ matrix.name == 'linux' \u0026\u0026 matrix.arch != 'amd64' }}\n        run: |\n          sudo apt install -f -y gcc-${{ matrix.rust_arch }}-linux-gnu\n          echo CC=${{ matrix.rust_arch }}-linux-gnu-gcc \u003e\u003e $GITHUB_ENV\n          echo RUSTFLAGS='-C linker=${{ matrix.rust_arch }}-linux-gnu-gcc' \u003e\u003e $GITHUB_ENV\n      - name: Extract tag name\n        uses: olegtarasov/get-tag@v2.1\n        id: tagName\n\n      - name: Build\n        uses: actions-rs/cargo@v1\n        with:\n          command: build\n          args: --release --all --locked --target=${{ matrix.rust_arch }}-${{ matrix.rust_abi }}\n\n      - name: Strip symbols (linux)\n        if: ${{ matrix.name == 'linux' }}\n        run: |\n          ${{ matrix.rust_arch }}-linux-gnu-strip target/${{ matrix.rust_arch }}-${{ matrix.rust_abi }}/release/viceroy${{ matrix.extension }}\n      - name: Strip symbols (non-linux)\n        if: ${{ matrix.name != 'linux' }}\n        run: |\n          strip target/${{ matrix.rust_arch }}-${{ matrix.rust_abi }}/release/viceroy${{ matrix.extension }}\n      - name: Package\n        run: |\n          cd target/${{ matrix.rust_arch }}-${{ matrix.rust_abi }}/release\n          tar czf viceroy_${{ steps.tagName.outputs.tag }}_${{ matrix.name }}-${{ matrix.arch }}.tar.gz viceroy${{ matrix.extension }}\n      - name: Release\n        uses: softprops/action-gh-release@v1\n        with:\n          files: |\n            target/${{ matrix.rust_arch }}-${{ matrix.rust_abi }}/release/viceroy_${{ steps.tagName.outputs.tag }}_${{ matrix.name }}-${{ matrix.arch }}.tar.gz\n        env:\n          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n","tags":"#github #git #actions #workflows"},{"id":"10491f2601ffdd6bec306554470c6b0e","title":"Go: Make directory if it does not exist ","content":"// makeDirectoryIfNotExists asserts whether a directory exists and makes it\n// if not. Returns nil if exists or successfully made.\nfunc makeDirectoryIfNotExists(path string) error {\n\tfi, err := os.Stat(path)\n\tswitch {\n\tcase err == nil \u0026\u0026 fi.IsDir():\n\t\treturn nil\n\tcase err == nil \u0026\u0026 !fi.IsDir():\n\t\treturn fmt.Errorf(\"%s already exists as a regular file\", path)\n\tcase os.IsNotExist(err):\n\t\treturn os.MkdirAll(path, 0750)\n\tcase err != nil:\n\t\treturn err\n\t}\n\n\treturn nil\n}\n","tags":"#go"},{"id":"711796e832db34e19c93e4fd106c6383","title":"CRDT: conflict-free replicated data type ","content":"Operations on CRDTs need to adhere to the following rules:\n\n- Associativity `(a+(b+c)=(a+b)+c)`, so that grouping doesn't matter.\n- Commutativity `(a+b=b+a)`, so that order of application doesn't matter.\n- Idempotence `(a+a=a)`, so that duplication doesn't matter.\n\nData types as well as operations have to be specifically crafted to meet these rules. CRDTs have known implementations for counters, registers, sets, graphs, and others.  \n","tags":"#crdt #distributed"},{"id":"6c57675906fd4c0e8895092e8ea1ea1c","title":"Shell: rename multiple files extension ","content":"for f in *.markdown.tmpl; \ndo \n  name=$(basename $f .markdown.tmpl) \u0026\u0026 mv $f \"$name.md.tmpl\"; \ndone\n","tags":"#bash #rename #extension"},{"id":"e19c9faee86e797125e6d95fe1188912","title":"Go: development tools as dependencies ","content":"There are multiple ways to deal with non-application dependencies (i.e. \"tools\" that your project needs).\n\n- [go tool](#go-tool)\n  - [caveats and issues](#caveats-and-issues)\n  - [multiple module files](#multiple-module-files)\n- [tools.go](#toolsgo)\n- [go run](#go-run)\n\n## go tool\n\nAs of Go 1.24 (Feb 2025)\n\nTo add a new tool:\n\n```shell\ngo get -tool golang.org/x/lint/golint\ngo get -tool github.com/mgechev/revive@latest\n```\n\nTo run the tool:\n\n```shell\ngo tool golint -h\ngo tool golang.org/x/lint/golint -h # in case of naming overlap\n```\n\nTo see a list of all tools:\n\n```shell\ngo tool\n```\n\nTo update all tools:\n\n```shell\ngo get -u tool\n```\n\nIf you check the `go.mod` you'll see a new tool syntax:\n\n```go.mod\nmodule testing-tools\n\ngo 1.23.4\n\ntool (\n    github.com/mgechev/revive\n    golang.org/x/lint/golint\n)\n```\n\n### caveats and issues\n\nNow, there is a problem (sort of), which is that you'll see a bunch of _indirect_ dependencies showing up in the `go.mod`.\n\nThis is because these are the dependencies that your \"tools\" need.\n\nI'm less concerned about that as a side-effect of using the new `go tools` feature, but I appreciate it's not ideal.\n\nMy concern being: it's more mental overhead.\n\nYou don't know if these _indirect_ dependencies are transient dependencies used by your application dependencies, or if they're dependencies for the \"tools\" you've installed.\n\nThe reason I'm not usually _that fussed_ by this is because I only really care about the \"direct\" dependencies, and those are always clear because they don't have `// indirect` following them. \n\n**So the following instructions are only relevant if you really care about this**.\n\n### multiple module files\n\nThere is another option on the table that we can use, and it doesn't appear to be too much additional maintenance or mental overhead, which is great. But it does have a downside (see the `IMPORTANT` note at the end of this section).\n\nEssentially, the approach is to have a separate modfile for tools. \n\nIt means we'd have multiple files now, like this...\n\n```\ngo.mod\ngo.sum\ntools.mod\ntools.sum\n```\n\n\u003e [!NOTE]\n\u003e If you give the `tools.mod` a unique module name, let's say `go.mod` uses `github.com/example/foo`, and so you make `tools.mod` use `github.com/example/foo/tools` then be aware that the use of `go mod` is going to make your `tools.mod` think it needs the module from `go.mod` and it'll add it as a dependency (this makes things weird in special cases), so it might be worth making the module name the same between `go.mod` and `tools.mod`.\n\nTo install a new tool:\n\n```bash\n# instead of...\ngo get -tool github.com/mgechev/revive\n\n# we do...\ngo get -modfile=tools.mod -tool github.com/mgechev/revive\n```\n\n\u003e [!TIP]\n\u003e To _remove_ a tool you can do the above but set the version to `@none`.\n\nAnd if we want to use that tool we have to make sure to specify the modfile:\n\n```\n$ go tool revive --version\ngo: no such tool \"revive\"\n\n$ go tool -modfile=tools.mod revive --version\nversion 1.7.0\n```\n\nHaving to specify the `-modfile` flag isn't a big issue for me as I typically have `go tool` abstracted inside various Makefile targets, so I'm only ever calling a Makefile target (or in the case of stringer have it codified in the go generate directive in the code itself).\n\nAs far as updating tools, you can either do it a dependency at a time or all of them at once:\n\n```bash\n# instead of...\ngo get -u -tool github.com/mgechev/revive@latest\ngo get -u tool\n\n# we do...\ngo get -u -modfile=tools.mod -tool github.com/mgechev/revive@latest\ngo get -u -modfile=tools.mod tool\n```\n\nSame for listing the installed tools:\n\n```bash\n# instead of...\ngo tool\n\n# we do...\ngo tool -modfile=tools.mod\n```\n\n\u003e [!TIP]\n\u003e Can also try `go list -modfile=tools.mod tool`\n\n\nTo verify the integrity of the tool dependencies:\n\n```\ngo mod verify -modfile=tools.mod\n```\n\nHere's an associated Makefile:\n\n```Makefile\n.PHONY: deps-app-update\ndeps-app-update: ## Update all application dependencies\n\tgo get -u -t ./...\n\tgo mod tidy\n\tif [ -d \"vendor\" ]; then go mod vendor; fi\n\t\n.PHONY: deps-outdated\ndeps-outdated:  ## Lists direct dependencies that have a newer version available\n\t@go list -u -m -json all | go tool -modfile=tools.mod go-mod-outdated -update -direct\n\t\nTOOLS = \\\n\tcuelang.org/go/cmd/cue \\\n\tgithub.com/client9/misspell/cmd/misspell \\\n\tgithub.com/go-delve/delve/cmd/dlv \\\n\tgithub.com/mgechev/revive \\\n\tgithub.com/psampaz/go-mod-outdated \\\n\tgithub.com/stealthrocket/wasi-go/cmd/wasirun \\\n\tgithub.com/stern/stern \\\n\tgithub.com/tetratelabs/wazero/cmd/wazero \\\n\tgolang.org/x/lint/golint \\\n\tgolang.org/x/tools/cmd/stringer \\\n\tgolang.org/x/tools/go/analysis/passes/nilness/cmd/nilness \\\n\tgolang.org/x/vuln/cmd/govulncheck \\\n\thonnef.co/go/tools/cmd/staticcheck \\\n\tmvdan.cc/gofumpt \\\n\n.PHONY: tools\ntools:\n\t@$(foreach tool,$(TOOLS), \\\n\t\tif ! go tool -modfile=tools.mod | grep \"$(tool)\" \u003e/dev/null; then \\\n\t\t\tgo get -modfile=tools.mod -tool \"$(tool)\"@latest; \\\n\t\tfi; \\\n\t)\n\n.PHONY: tools-update\ntools-update:\n\tgo get -u -modfile=tools.mod tool\n\tgo mod tidy -modfile=tools.mod\n```\n\n\u003e [!IMPORTANT]\n\u003e This approach keeps the main `go.mod` and `go.sum` clean of any tool dependencies, but not the other way around. So the `tools.mod` and `tools.sum` will ultimately contain all the dependencies from the main `go.mod` (that is a side-effect of running `go mod tidy -modfile=tools.mod` as `go mod` always consults the main `go.mod`, hence all of its dependencies end up in your `tools.mod` and `tools.sum`). \n\u003e\n\u003e This is unavoidable. There is no way to get around it (trust me, I've tried 😅). \n\u003e\n\u003e Now, this isn't the end of the world as the `tools` directive is still at the top of the `tools.mod` and is very clear as to what \"tools\" are installed, but yeah, you'll also see a bunch of `require` directives (related to your main Go project) as well, unfortunately.\n\u003e\n\u003e One thing you could do, is only run the `go get -u -modfile=tools.mod tool` command, which would keep your `tools.mod` clean, and would only update `tools.sum` with the relevant updated dependencies. The problem with that is the old dependencies aren't cleaned out. e.g. if you updated tool \"foo\" from version 1.0 to 2.0 then both versions appear in your `tools.sum` (this is why we have `go mod tidy` to ensure only 2.0 is present in the `tools.sum`). So one approach would simple be to manually clean up the `go.sum` everytime after running `go get -u -modfile=tools.mod tool` -- it's not that difficult as you just look for the new tool version added and remove the old one, but it's a manual process and that sucks).\n\u003e \n\u003e **UPDATE Aug 2025:**\\\n\u003e I was having issues with importing a public package (e.g. `pkg/package_name`) from within my own module. It was related to compiling a Protobuf schema into a `.go` stub file that I wanted to import and use within my own module's code. And I found the following approach helped me to avoid an issue where `go mod tidy` wanted me to `go get` my own package (which didn't make any sense to me). The way I avoid that was to copy my tools.mod and tools.sum into a temp directory and then `cd` there and run `go mod tidy` and it appeared to work fine. What's weird is I'm pretty sure I tried this approach before and it didn't work as far as keeping out my main application's dependencies from the tools dependencies. So this might be the way to go.\n\n```Makefile\n.PHONY: tools-update\ntools-update: ## Update dev tools\n\t@$(foreach tool,$(TOOLS), \\\n\t\techo \"updating $(tool)\"; \\\n\t\tgo get -u -modfile=tools.mod -tool \"$(tool)\"@latest; \\\n\t)\n\tgo install google.golang.org/protobuf/cmd/protoc-gen-go@latest\n\t@echo \"Tidying tool dependencies...\"\n\t@mkdir -p .tmp_tools\n\t@cp tools.mod .tmp_tools/go.mod\n\t@if [ -f tools.sum ]; then cp tools.sum .tmp_tools/go.sum; fi\n\t@cd .tmp_tools \u0026\u0026 go mod tidy\n\t@mv .tmp_tools/go.mod tools.mod\n\t@if [ -f .tmp_tools/go.sum ]; then mv .tmp_tools/go.sum tools.sum; fi\n\t@rm -rf .tmp_tools\n```\n\n## tools.go\n\n\u003e [!NOTE]\n\u003e For more details on code generation in a general sense, refer to:\\\n\u003e https://gist.github.com/Integralist/8f39eb897316e1cbeaf9eff8326cfa59\n\nThe following file `internal/tools/tools.go` uses a build tag to avoid the dependencies being compiled into your application binary...\n\n```go\n//go:build tools\n\n// Package tools manages go-based tools that are used to develop in this repo.\npackage tools\n\nimport (\n\t_ \"github.com/nbio/cart\"\n\t_ \"github.com/nbio/slugger\"\n\t_ \"github.com/psampaz/go-mod-outdated\"\n\t_ \"github.com/stealthrocket/wasi-go/cmd/wasirun\"\n\t_ \"github.com/tetratelabs/wazero/cmd/wazero\"\n\t_ \"golang.org/x/lint/golint\"\n\t_ \"golang.org/x/tools/cmd/stringer\"\n\t_ \"golang.org/x/vuln/cmd/govulncheck\"\n)\n\n//go:generate go install github.com/nbio/cart\n//go:generate go install github.com/nbio/slugger\n//go:generate go install github.com/psampaz/go-mod-outdated\n//go:generate go install github.com/stealthrocket/wasi-go/cmd/wasirun\n//go:generate go install github.com/tetratelabs/wazero/cmd/wazero\n//go:generate go install golang.org/x/lint/golint\n//go:generate go install golang.org/x/vuln/cmd/govulncheck\n//go:generate go install golang.org/x/tools/cmd/stringer\n```\n\nNotice the `go:generate` comments? Yup, we invoke them like so (notice the `-tags` flag):\n\n```Makefile\ntools: internal/tools/tools.go\n\tgo generate -v -x -tags tools ./internal/tools/...\n```\n\n## go run\n\nAn alternative to this approach is to use `go run` directly, which downloads tools to a cache but doesn't install them and yet still gives you explicit versioning consistency across developer's machines...\n\n```go\n//go:generate go run golang.org/x/tools/cmd/stringer@v0.25.0 -type=Scope -linecomment\n```\n\nI then invoke go generation with:\n\n```Makefile\n.PHONY: go-gen\ngo-gen: ## Invoke go generate\n\t@# The `-x` flag prints the shell commands that `go generate` runs.\n\tgo generate -v -x ./mustang/status/...\n```\n\n\u003e \\[!TIP\\]\n\u003e If you're developing whilst offline, then one advantage the tools.go pattern\n\u003e has is that it works whilst offline because the tool is explicitly installed.\n\u003e But to work around that with `go run` you can set `export GOPROXY=direct` and\n\u003e as long as you have the module in your local cache you'll be able to use it.\n\n","tags":"#go #dependencies"},{"id":"5e0bd295c7db33c7900876fa934949e2","title":"CLI: terminology and design guidelines ","content":"## Guidelines\n\nThe following information was copied verbatim from https://clig.dev/ (an excellent resource).\n\nThis is only a small subset of the overall content, so I highly recommend reading the full document (see link above).\n\n## Terminology\n\n- _Arguments_, or _args_, are positional parameters to a command. For example, the file paths you provide to `cp` are args. The order of args is often important: `cp foo bar` means something different from `cp bar foo`.\n- _Flags_ are named parameters, denoted with either a hyphen and a single-letter name (`-r`) or a double hyphen and a multiple-letter name (`--recursive`). They may or may not also include a user-specified value (`--file foo.txt`, or `--file=foo.txt`). The order of flags, generally speaking, does not affect program semantics.\n\n\u003e **NOTE**: You might sometimes see in CLI `--help` output sections such as `FLAGS:` and `OPTIONS:` (the latter functions the same as the flags section). The difference is, and there's no official document or guidelines to support the following, that 'Flags' are boolean on/off switches (e.g. `--debug`) while 'Options' are flags that accept a value (e.g. `--id=123`). This all depends on the library you use to create your CLI. For instance, some libraries will generate `REQUIRED FLAGS` and `OPTIONAL FLAGS` sections instead.\n\n## Example Structure\n\n```bash\n\u003ccommand|program\u003e [\u003cflags|options\u003e] \u003csubcommand\u003e [\u003cflags|options\u003e] [\u003cargs\u003e ...]\n```\n\n\u003e Note: 'command' is the name of the binary executable (i.e. the 'program') while 'options' was historically used to suggest the input as being 'optional' and so it typically maps to flags.\n\n## Best Practices\n\n**Prefer flags to args**. It’s a bit more typing, but it makes it much clearer what is going on. It also makes it easier to make changes to how you accept input in the future. Sometimes when using args, it’s impossible to add new input without breaking existing behavior or creating ambiguity.\n\n**Have full-length versions of all flags**. For example, have both `-h` and `--help`. Having the full version is useful in scripts where you want to be verbose and descriptive, and you don’t have to look up the meaning of flags everywhere.\n\n**Only use one-letter flags for commonly used flags,** particularly at the top-level when using subcommands. That way you don’t “pollute” your namespace of short flags, forcing you to use convoluted letters and cases for flags you add in the future.\n\n**Multiple arguments are fine for simple actions against multiple files.** For example, `rm file1.txt file2.txt file3.txt`. This also makes it work with globbing: `rm *.txt`.\n\n**If you’ve got two or more arguments for different things, you’re probably doing something wrong.** The exception is a common, primary action, where the brevity is worth memorizing. For example, `cp \u003csource\u003e \u003cdestination\u003e`.\n\n**If a complex piece of software has lots of objects and operations that can be performed on those objects, it is a common pattern to use two levels of subcommand for this, where one is a noun and one is a verb**. For example, `docker container create` (`container` is the noun; `create` is the verb). Be consistent with the verbs you use across different types of objects. \n\n## Common Flags\n\nHere’s a list of commonly used options:\n\n- `-a, --all`: All. For example, ps, fetchmail.\n- `-c, --color`: Configure Always/Auto/Never enum variants as colour output might not work for every TTY.\n- `-d, --debug`: Show debugging output.\n- `-f, --force`: Force. For example, rm -f will force the removal of files, even if it thinks it does not have permission to do it. This is also useful for commands which are doing something destructive that usually require user confirmation, but you want to force it to do that destructive action in a script.\n- `--json`: Display JSON output. See the output section.\n- `-h, --help`: Help. This should only mean help. See the help section.\n- `--no-input`: See the interactivity section.\n- `-o, --output`: Output file. For example, sort, gcc.\n- `-p, --port`: Port. For example, psql, ssh.\n- `-q, --quiet`: Quiet. Display less output. This is particularly useful when displaying output for humans that you might want to hide when running in a script.\n- `-u, --user`: User. For example, ps, ssh.\n- `--version`: Version.\n- `-v`: This can often mean either verbose or version. You might want to use -d for verbose and this for version, or for nothing to avoid confusion.\n","tags":"#cli #terminology #flags #arguments #args #options #design #guidelines #clap"},{"id":"61c77417bc253aac77e853ecbf206cb1","title":"Rust: Book Examples ","content":"use rand::Rng;\nuse std::cmp::Ordering;\nuse std::io;\n\nfn main() {\n    let secret_number = rand::thread_rng().gen_range(1, 101);\n\n    println!(\"secret number: {}\", secret_number);\n\n    loop {\n        println!(\"input a guess...\");\n\n        let mut guess = String::new();\n\n        io::stdin()\n            .read_line(\u0026mut guess)\n            .expect(\"failed to read input\");\n\n        let guess: u32 = guess.trim().parse().expect(\"please type a number\");\n\n        println!(\"you guessed: {}\", guess);\n\n        match guess.cmp(\u0026secret_number) {\n            Ordering::Less =\u003e println!(\"too small\"),\n            Ordering::Greater =\u003e println!(\"too big\"),\n            Ordering::Equal =\u003e {\n                println!(\"you win\");\n                break;\n            }\n        }\n    }\n}\n","tags":"#rust #rng"},{"id":"e4580cf4eb8d92e587511c66fc496f02","title":"Extract mp4 from m3u8 ","content":"ffmpeg -i https://123.streamlock.net/obitus_vods/_definst_/mp4:obitusvods/vivedia-wowza-vod/vb/394110_2020-07-31_2233BEC.mp4/playlist.m3u8 -c copy -bsf:a aac_adtstoasc output.mp4\n","tags":"#ffmpeg #shell"},{"id":"0040b2e6d80765b956c5b1e12613e58e","title":"GPG: Github Commit Signing Key ","content":"https://gist.github.com/troyfontaine/18c9146295168ee9ca2b30c00bd1b41e\n\n## PROBLEM 0: Quick Fix?\n\nWhatever your problem, try restarting your GPG Agent (it will auto-restart the next time gpg is used): \n\n```\ngpgconf --kill gpg-agent\nkillall gpg-agent\n```\n\nAlso try `GIT_TRACE=1 ...` to see which internal command is failing and try running the command to get at the underlying error. \n\n## PROBLEM 1: Homebrew changes install locations\n\nMy global `~/.gitconfig` had a `[gpg]` section which was configured to the location of the `gpp` binary. I installed a newer Homebrew version (as part of a new laptop setup) and discovered that Homebrew changed the location of where binaries are installed so I needed to `which gpg` to find the new location and update my global git config.\n\n## PROBLEM 2: New Laptop\n\nI pulled down a project from GitHub but forgot that originally (on my old laptop) I would have updated the project's local `.git/config` file to include my user details, and the fact I want to sign my commits (see \"Project Specific Summary\" below). So just make sure that data is added.\n\n## PROBLEM 3: Missing GPG_TTY\n\nI was finding, after a long time of being able to sign commits using the instructions from this gist, that I couldn't sign my commits all of a sudden. \n\nThere's a few things you can try.\n\nIn one instance I needed an esoteric way to tell Git about my user...\n\n```bash\nexport GPG_TTY=$(tty)\n```\n\n## PROBLEM 4: Conflicting branch names\n\nAnother issue I found was I shouldn't have a branch named the same as the tag version because git won't know what to do (make sure to delete the branch if it's already merged into your primary branch, or rename it otherwise). So now I don't name my branches `v1.0.0` but `integralist/v1.0.0` as this means when I add the tag `v1.0.0` there's no confusion as to what's being referenced.\n\nIf your GPG key expires then you can't just update the expiry. You need to delete the public key from your GitHub account and re-add it in the GitHub UI like you did when first creating the public key ([docs](https://docs.github.com/en/authentication/troubleshooting-commit-signature-verification/updating-an-expired-gpg-key)).\n\n---\n\n## Project Specific Summary\n\n```ini\nvim .git/config\n\n[user]\n  name = Foo Bar\n  email = foobar@example.com\n  signingkey = 123\n[commit]\n\tgpgsign = true\n    \ngit tag -s v1.1.0 -m \"v1.1.0\" \u0026\u0026 git push origin v1.1.0\n```\n\n## Full details\n\n```bash\ngpg --full-generate-key\n```\n\n```bash\ngit config --global --edit\n```\n\n```ini\n[user]\n    signingkey = \u003c\u003e\n    name = \u003c\u003e\n    email = \u003c\u003e\n```\n\n```bash\ncd ~/path/to/some/repo/you/want/to/sign/commits/for\ngit config --local --edit\n```\n\n```ini\n[commit]\n    gpgsign = true\n```\n\n```bash\ngit config --local user.signingkey \u003c\u003e\n```\n\n\u003e **NOTE**: feel free to add `gpgsign` to global settings if you prefer.\n\nYou need to generate the public key to paste into GitHub. First get the identifier...\n\n```bash\ngpg --list-secret-keys --keyid-format LONG\n\nsec   4096R/\u003cGRAB_THIS\u003e ...\n...\n```\n\nNow you can export your public key...\n\n```bash\ngpg --armor --export \u003cidentifier\u003e | pbcopy\n```\n\nThen go to GitHub \u003e Settings \u003e SSH and GPG keys.\n\n\n\u003e **NOTE**: If using a different email to what your GitHub account is associated with, then go to https://github.com/settings/emails and add the new email so it can be verified (otherwise github won't verify the email in the gpg key).\n\n## macOS Keychain\n\nSee the ~/.gnupg/ files in [my dotfiles repo](https://github.com/integralist/dotfiles).\n\n```bash\nchmod 700 ~/.gnupg\n```\n\n## Changing Commit Author\n\nIf like me you have multiple users (one work, one personal) then you might want to change a personal commit signing with a work identity if you had used your personal one by accident.\n\nTo do that you can use:\n\n```bash\ngit commit --amend --reset-author\n```\n\n## References\n\nI recently stumbled across: https://gist.github.com/troyfontaine/18c9146295168ee9ca2b30c00bd1b41e\n","tags":"#gpg #github #commit #sign #key"},{"id":"975d099da6aad2373b225b7713d20a7c","title":"Export Private GPG Key ","content":"# reference:\n# man gpg\n\nKEY_ID=$(gpg --list-keys Pass | head -n 2 | tail -n 1 | cut -d ' ' -f 7)\n\ngpg --list-secret-keys Pass\ngpg --export-secret-keys \u003cKEY_ID\u003e \u003e private.key\ngpg --armor --export-secret-keys \u003cKEY_ID\u003e \u003e private.key.asc\ngpg --output fullbackup.pgp --armor --export-secret-keys --export-options export-backup Pass\n\n# if you're not comfortable with the security of your chose passphrase\n# then consider making a paper backup which can be stored in a fireproof safe\n# https://www.jabberwocky.com/software/paperkey/\n","tags":"#gpg #keys #backup"},{"id":"636314c080a3b88ada95a68a03068a52","title":"Interface Value vs Interface Type ","content":"**Rereference**:\n- https://tour.golang.org/methods/11 (interface values)\n- https://tour.golang.org/methods/12 (interface values with nil underlying values)\n- https://tour.golang.org/methods/13 (nil interface values)\n- https://tour.golang.org/methods/14 (empty interface)\n- https://tour.golang.org/methods/15 (type assertions)\n- https://tour.golang.org/methods/16 (type switches)\n\nUnder the hood, interface values can be thought of as a tuple of a value and a concrete type: \n\n```\n(value, type)\n```\n\n Calling a method on an interface value executes the method of the same name on its underlying type. \n \n```go\npackage main\n\nimport (\n\t\"fmt\"\n\t\"math\"\n\t\"reflect\"\n)\n\ntype I interface {\n\tM()\n}\n\ntype T struct {\n\tS string\n}\n\nfunc (t *T) M() {\n\t//fmt.Println(t.S)\n}\n\ntype F float64\n\nfunc (f F) M() {\n\t//fmt.Println(f)\n}\n\nfunc main() {\n\tvar i I\n\n\ti = \u0026T{\"Hello\"}\n\tdescribe(i) // \u0026{S:Hello}, *main.T\n\ti.M()\n\n\t// \u0026{S:Hello}, *main.T\n\tfmt.Printf(\"%+v, %+v\\n\\n\", reflect.ValueOf(i), reflect.TypeOf(i))\n\n\ti = F(math.Pi)\n\tdescribe(i) // 3.141592653589793, main.F\n\ti.M()\n\n\t// 3.141592653589793, main.F\n\tfmt.Printf(\"%+v, %+v\\n\", reflect.ValueOf(i), reflect.TypeOf(i))\n}\n\nfunc describe(i I) {\n\tfmt.Printf(\"%+v, %T\\n\", i, i)\n}\n```\n\nWhen we assign to `i` which is the interface `I`, we'll find that `i` ultimately holds the expected value (e.g. either a struct `T` or a float `F`) but the 'type' associated with the `i` variable _isn't_ actually the `I` interface (which you _might_ have expected) it's actually the type of the value that was assigned.\n","tags":"#go"},{"id":"05e5415de6743e66b112574a1a5c1970","title":"Laptop: Configuration Summary ","content":"## Backup\n\n```bash\ncd ~/\nmkdir /tmp/keys\ngpg --export-secret-keys --armor \u003cNAME\u003e \u003e /tmp/keys/\u003cNAME\u003e.asc\ngpg --symmetric /tmp/keys/\u003cNAME\u003e.asc\ngpg --export-ownertrust \u003e /tmp/keys/trustdb.txt \n\nzip -r /tmp/sshbackup ~/.ssh/\nunzip -l /tmp/sshbackup.zip\n```\n\n## Restore\n\n```bash\nmkdir /tmp/keys\ncd /tmp/keys\n\ngpg --symmetric --decrypt /tmp/keys/\u003cNAME\u003e.gpg\ngpg —-import /tmp/keys/\u003cNAME\u003e.asc\n\nrm ~/.gnupg/trustdb.gpg\ngpg --import-ownertrust \u003c /tmp/keys/trustdb.txt\n\ngpg --symmetric --decrypt /tmp/keys/sshbackup.zip.gpg\nunzip /tmp/keys/sshbackup.zip\nmv /tmp/keys/.ssh/ ~/\n\nrm -rf /tmp/keys\n```\n\n## Steps\n\n- OS Settings\n    - Dock (Automatically hide and show the Dock)\n    - Keyboard (Key Repeat = Fast, Delay Until Repeat = Short)\n    - Accessibility \u003e Zoom (Use keyboard shortcuts to zoom)\n    - Date \u0026 Time \u003e Clock (Show date + Display the time with seconds)\n    - Mission Control (disable \"Automatically rearrange Spaces based on most recent use\")\n    - Terminal Developer Mode (`spctl developer-mode enable-terminal`)\n    - Wake up from sleep (`sudo pmset -a standbydelay 7200`)\n- Firefox\n\t- https://www.mozilla.org/en-GB/firefox/new/\n    - Preferences\n        - General \u003e Startup (Restore previous session + Warn you when quitting the browser)\n        - Search \u003e Default Search Engine (DuckDuckGo)\n        - Privacy \u0026 Security\n            - Enhanced Tracking Protection (Strict + Do Not Track = Always)\n            - Firefox Data Collection and Use (disable all options)\n        - Firefox Sync\n        - Extensions\n            - https://addons.mozilla.org/en-US/firefox/addon/duckduckgo-for-firefox/\n            - https://addons.mozilla.org/en-GB/firefox/addon/privacy-badger17/\n            - https://addons.mozilla.org/en-GB/firefox/addon/ublock-origin/\n            - https://addons.mozilla.org/en-GB/firefox/addon/darkreader/\n            - https://addons.mozilla.org/en-GB/firefox/addon/expressvpn/\n            - https://addons.mozilla.org/en-GB/firefox/addon/multi-account-containers/\n            - https://addons.mozilla.org/en-GB/firefox/addon/facebook-container/\n            - https://addons.mozilla.org/en-US/firefox/addon/temporary-containers/\n- Homebrew\n\t- https://brew.sh \n    - `brew bundle install`\n- Shell\n    - `echo /usr/local/bin/bash | sudo tee -a /etc/shells`\n    - `chsh -s /usr/local/bin/bash`\n- GitHub Access\n    - `mkdir ~/.ssh`\n    - `cd ~/.ssh \u0026\u0026 ssh-keygen -t rsa -b 4096 -C '\u003cyour@email.com\u003e'`\n    - `eval \"$(ssh-agent -s)\"`\n    - `ssh-add -K ~/.ssh/github`\n      - `ssh-add --apple-use-keychain ~/.ssh/github` (`-K` looks to be deprecated).\n    - `pbcopy \u003c ~/.ssh/github.pub`\n    - https://github.com/settings/keys \n- Tools\n\t- https://github.com/integralist/dotfiles\n    - `git clone git@github.com:Integralist/dotfiles.git`\n    - `mv ...` files into `~/`\n- Terminal\n\t- https://github.com/alacritty/alacritty/blob/master/INSTALL.md#macos\n- Password Store\n\t- https://www.passwordstore.org/\n    - `gpg --import \u003c/path/to/private/key\u003e`\n    - `keyid=$(gpg --list-keys \u003cyour@email.com\u003e | head -n 2 | tail -n 1 | cut -d ' ' -f 7)`\n    - `pass init $keyid`\n    - `pass git init`\n    - `pass git remote add origin git@github.com:\u003cprivate/repo\u003e`\n    - `pass git pull`\n    - `gpg --edit-key $keyid` (type `trust`)\n\n\u003e **NOTE**: \n\u003e\n\u003e Encrypt/Decrypt files...\n\u003e\n\u003e Encrypt: `gpg --encrypt -r Pass --output ~/encrypted.png.gpg ~/example.png`  \n\u003e Decrypt: `gpg --decrypt --output ~/example.png ~/encrypted.png.gpg`\n\u003e  \n\u003e OTP...\n\u003e  \n\u003e Generate from QRCode image: `zbarimg -q --raw example.png | pass otp insert Foo/otp/example`  \n\u003e Usage: `pass otp -c Foo/otp/example`\n\n- Vim\n    - `mkdir -p ~/Code/ \u0026\u0026 cd ~/Code`\n    - `git clone https://github.com/vim/vim.git`\n    - `cd vim`\n    - `make clean distclean`\n    - `./configure --with-features=huge --enable-multibyte --enable-rubyinterp=yes --enable-python3interp=yes --with-python3-command=/Users/integralist/.pyenv/shims/python --enable-perlinterp=yes --enable-luainterp=yes --enable-gui=gtk2 --enable-cscope --prefix=/usr/local`\n    - `make \u0026\u0026 make install`\n    - `curl -sfLo ~/.vim/autoload/plug.vim --create-dirs https://raw.githubusercontent.com/junegunn/vim-plug/master/plug.vim`\n    - `:PlugInstall`\n","tags":"#new #laptop #configuration #macos"},{"id":"bd46b6673376ceee7f029cfb576438b5","title":"Generic Status Handler Abstraction ","content":"type StatusHandler int\n\nfunc (s StatusHandler) ServeHTTP(w http.ResponseWriter, r *http.Request) {\n\tcode := int(s)\n\tw.WriteHeader(code)\n\tio.WriteString(w, http.StatusText(code))\n}\n\nvar (\n\tNotFoundHandler = StatusHandler(404)\n\tNotImplementedHandler = StatusHandler(501)\n\tNotLegalHandler = StatusHandler(451)\n)\n","tags":"#go #http"},{"id":"e9e2b3c27a9556d92ba5782bcc9e316f","title":"Pointer Dereferencing ","content":"**Reference**: \n- https://tour.golang.org/methods/6\n- https://tour.golang.org/methods/6\n\nIf a method defines its receiver as being a pointer, then the caller of the method _ideally_ should pass a pointer as the receiver:\n\n```go\npackage main\n\nimport (\n\t\"fmt\"\n)\n\ntype foo struct{}\n\nfunc (f *foo) bar() {\n\tfmt.Printf(\"bar called on %T\\n\", f)\n}\n\nfunc main() {\n\tf := \u0026foo{}\n\tf.bar() // bar called on *main.foo\n}\n```\n\n\u003e Notice that we see `*main.foo` as the receiver was a pointer.\n\nBut as a convenience, the go compiler will automatically handle the passing of a pointer on behalf of the caller (in the case where they pass a value instead):\n\n```go\npackage main\n\nimport (\n\t\"fmt\"\n)\n\ntype foo struct{}\n\nfunc (f *foo) bar() {\n\tfmt.Printf(\"bar called on %T\\n\", f)\n}\n\nfunc main() {\n\tf := \u0026foo{}\n    (*f).bar() // bar called on *main.foo\n}\n```\n\nIn order to demonstrate the point, I first had to 'dereference' the pointer `(*f)` to get at the 'value' before calling `.bar()` on the struct.\n\nThe compiler thus saw `(*f).bar()` and interpreted it as `f.bar()`.\n\nRemember that `f` was already a pointer because when we created `foo` we assigned the memory address location to `f` using `\u0026foo{}`.\n\nSo this is why we still see the message `bar called on *main.foo`.\n\nThe same principle happens in _reverse_ (i.e. when you have a method whose receiver is a value and not a pointer). \n\nSo if a method defines its receiver as being a value, then the caller of the method _ideally_ should pass a value as the receiver:\n\n```go\npackage main\n\nimport (\n\t\"fmt\"\n)\n\ntype foo struct{}\n\nfunc (f foo) bar() {\n\tfmt.Printf(\"bar called on %T\\n\", f)\n}\n\nfunc main() {\n\tf := foo{}\n\n\tf.bar() // bar called on main.foo\n}\n```\n\n\u003e Notice now that instead of `*main.foo` we get `main.foo` as the receiver was a value and not a pointer. \n\nBut as a convenience, the go compiler will automatically handle the passing of a value on behalf of the caller (in the case where they pass a pointer instead):\n\n```go\npackage main\n\nimport (\n\t\"fmt\"\n)\n\ntype foo struct{}\n\nfunc (f foo) bar() {\n\tfmt.Printf(\"bar called on %T\\n\", f)\n}\n\nfunc main() {\n\tf := foo{}\n\n\t(\u0026f).bar() // bar called on main.foo\n}\n```\n\nIn order to demonstrate the point, I first had to call `(\u0026f)` to get a 'pointer' before calling `.bar()` on the struct.\n\nThe compiler thus saw `(\u0026f).bar()` and interpreted it as `f.bar()`.\n\nRemember that `f` was already a 'value', because when we created `foo` we _didn't_ assign the memory address like we did earlier (`\u0026foo{}`).\n\nSo this is why we still see the message `bar called on main.foo`.\n\n\u003e **Note**: this 'convenience' does not apply when dealing with functions, only methods.\n\n---\n\nIn reality the confusion about what's happening is greater, due to the more subtle differences.\n\nFor example, in the following code snippet the method expects a pointer receiver but when we create an instance of `foo` we create a value and not a pointer. So when we call `f.bar()` this is interpreted as `(\u0026f).bar()`:\n\n```go\npackage main\n\nimport (\n\t\"fmt\"\n)\n\ntype foo struct{}\n\nfunc (f *foo) bar() {\n\tfmt.Printf(\"bar called on %T\\n\", f)\n}\n\nfunc main() {\n\tf := foo{}\n\tf.bar() // bar called on *main.foo\n}\n```\n\nOr how about that same snippet but in reverse, so the method expects a value receiver but when we create an instance of `foo` we create a pointer. So when we call `f.bar()` this is interpreted as `(*f).bar()`:\n\n```go\npackage main\n\nimport (\n\t\"fmt\"\n)\n\ntype foo struct{}\n\nfunc (f foo) bar() {\n\tfmt.Printf(\"bar called on %T\\n\", f)\n}\n\nfunc main() {\n\tf := \u0026foo{}\n\tf.bar() // bar called on main.foo\n}\n```\n\n---\n\nSometimes you're dealing with a type that isn't a struct, like a slice, and so accessing the elements (for example to modify them) requires additional steps, and in some cases extra parentheses (as demonstrated/commented below)...\n\n```go\npackage main\n\nimport (\n\t\"fmt\"\n)\n\ntype foo []int\n\nfunc (f *foo) pop() int {\n    // notice when we want to grab the length of the slice,\n  \t// and also when we want to grab a specific element from the slice,\n    // we have to first dereference the pointer to get at the underlying value.\n  \t//\n\tv := (*f)[len(*f)-1]\n  \n  \t// also notice to reassign a modified slice we again have to\n  \t// first dereference the pointer to get at the underlying value.\n  \t//\n\t*f = (*f)[:len(*f)-1]\n\treturn v\n}\n\nfunc main() {\n\tf := foo{9, 1, 6, 7, 0}\n\t\n\tfmt.Println(f)       // [9 1 6 7 0]\n\tfmt.Println(f.pop()) // 0\n\t\n\tfmt.Println(f)       // [9 1 6 7]\n\tfmt.Println(f.pop()) // 7\n\t\n\tfmt.Println(f)       // [9 1 6]\n}\n```\n","tags":"#go"},{"id":"bf1e155f13102e254f6b541c410fbb74","title":"Datadog Structured Logging Abstraction with Logrus ","content":"package logging\n\nimport (\n\t\"fmt\"\n\t\"math/rand\"\n\t\"runtime/debug\"\n\n\t\"github.com/sirupsen/logrus\"\n\t\"github.com/sirupsen/logrus/hooks/test\"\n)\n\nconst (\n\t// TimestampFormat is the default timestamp format for log records:\n\t// https://golang.org/pkg/time/#Time.Format\n\tTimestampFormat = \"2006-01-02 15:04:05.123\"\n\n\t// Map these constants to logrus for the sake of SetLevel() function.\n\tPanicLevel = logrus.PanicLevel\n\tFatalLevel = logrus.FatalLevel\n\tErrorLevel = logrus.ErrorLevel\n\tWarnLevel  = logrus.WarnLevel\n\tInfoLevel  = logrus.InfoLevel\n\tDebugLevel = logrus.DebugLevel\n\tTraceLevel = logrus.TraceLevel\n)\n\n// Fields is an alias for a set of key-value pairs to be logged\ntype Fields map[string]interface{}\n\n// extend updates a set of Fields using only the values in \"fields\" which are also in \"fieldNames\"\nfunc (s Fields) extend(fieldNames []string, fields Fields) {\n\tfor _, fieldName := range fieldNames {\n\t\tif val, ok := fields[fieldName]; ok {\n\t\t\ts[fieldName] = val\n\t\t}\n\t}\n}\n\n// Logger is a logrus entry wrapped with functions to support structured logging\ntype Logger struct {\n\traw    *logrus.Logger\n\tlogger *logrus.Entry\n\tRate   int\n}\n\n// NewLogger creates a new Logger instance\nfunc NewLogger(service string, optFuncs ...func(*logrus.Logger)) *Logger {\n\tlogger := logrus.New()\n\tlogger.SetFormatter(\u0026logrus.JSONFormatter{})\n\n\tfor _, f := range optFuncs {\n\t\tf(logger)\n\t}\n\n\tentry := logger.WithField(\"service\", service)\n\n\t// initialize logging\n\treturn \u0026Logger{\n\t\traw:    logger,\n\t\tlogger: entry,\n\t\tRate:   10,\n\t}\n}\n\n// TestLogger returns a logger that can be used for testing\nfunc TestLogger(service string, optFuncs ...func(*logrus.Logger)) (*Logger, *test.Hook) {\n\tlogger, hook := test.NewNullLogger()\n\tlogger.SetFormatter(\u0026logrus.JSONFormatter{})\n\n\tentry := logger.WithField(\"service\", service)\n\n\treturn \u0026Logger{\n\t\tlogger: entry,\n\t\tRate:   10,\n\t}, hook\n}\n\n// getField returns a single field in the logs\nfunc (l *Logger) getField(key string) (interface{}, bool) {\n\tif field, ok := l.logger.Data[key]; ok {\n\t\treturn field, ok\n\t}\n\treturn nil, false\n}\n\n// updateFields sets fields in a named set of fields, reusing existing values if possible\nfunc (l *Logger) updateFields(key string, fieldNames []string, fields Fields) *Logger {\n\tvar fieldSet Fields\n\n\t// get the existing set of fields or create a new one\n\tfieldSet, ok := l.Fields(key)\n\tif !ok {\n\t\tfieldSet = Fields{}\n\t}\n\n\t// update the set of fields\n\tfieldSet.extend(fieldNames, fields)\n\treturn \u0026Logger{\n\t\tlogger: l.logger.WithField(key, fieldSet),\n\t\tRate:   l.Rate,\n\t}\n}\n\n// appendFields appends a Fields object to an array of Fields objects\nfunc (l *Logger) appendFields(key string, fieldNames []string, fields Fields) *Logger {\n\tvar fieldsArray []Fields\n\tfiltered := Fields{}\n\n\t// get the existing array or create a new one\n\tif field, ok := l.getField(key); ok {\n\t\tfieldsArray, ok = field.([]Fields)\n\t\tif !ok {\n\t\t\tfieldsArray = []Fields{}\n\t\t}\n\t}\n\n\tfiltered.extend(fieldNames, fields)\n\n\t// append the stanza to the array\n\tfieldsArray = append(fieldsArray, filtered)\n\treturn \u0026Logger{\n\t\tlogger: l.logger.WithField(key, fieldsArray),\n\t\tRate:   l.Rate,\n\t}\n}\n\n// Fields returns a set of fields in the logger if it exists\nfunc (l *Logger) Fields(key string) (Fields, bool) {\n\tvar fields Fields\n\tvar data interface{}\n\tvar ok bool\n\n\t// make sure the set exists\n\tif data, ok = l.getField(key); !ok {\n\t\treturn nil, false\n\t}\n\n\t// make sure the set isn't malformed\n\tfields, ok = data.(Fields)\n\tif !ok {\n\t\treturn nil, false\n\t}\n\treturn fields, true\n}\n\n// Data returns the raw structured logging data from the logrus logger\nfunc (l *Logger) Data() map[string]interface{} {\n\treturn l.logger.Data\n}\n\n// sample returns True randomly at a percentage of the time\nfunc sample(percent int) bool {\n\treturn rand.Intn(100) \u003c= percent\n}\n\n// Wrappers around logging actions\n\n// InfoSampled wraps the logrus Info function and samples the logs\nfunc (l *Logger) InfoSampled(args ...interface{}) {\n\t// we check the Rate==100 first to avoid the more expensive call to the sample rand function\n\t// the global rand is probably fine, but just to note that using it could slow things\n\t// down a bit since every call to it locks a mutex\n\tif l.Rate == 100 || l.logger.Level \u003e= logrus.DebugLevel || sample(l.Rate) { // shhhh\n\t\tl.logger.Info(args...)\n\t}\n}\n\n// Info wraps the logrus Info function\nfunc (l *Logger) Info(args ...interface{}) {\n\tl.logger.Info(args...)\n}\n\n// Warn logs a message at warning level\nfunc (l *Logger) Warn(args ...interface{}) *Logger {\n\tl.logger.Warn(args...)\n\treturn l\n}\n\n// Error logs a message at error level\nfunc (l *Logger) Error(args ...interface{}) *Logger {\n\tl.logger.Error(args...)\n\treturn l\n}\n\n// Fatal wraps the logrus Fatal function\nfunc (l *Logger) Fatal(args ...interface{}) *Logger {\n\tl.logger.Fatal(args...)\n\treturn l\n}\n\n// Debug wraps the logrus Debug function\nfunc (l *Logger) Debug(args ...interface{}) *Logger {\n\tl.logger.Debug(args...)\n\treturn l\n}\n\n// Panic wraps the logrus Panic function\nfunc (l *Logger) Panic(args ...interface{}) *Logger {\n\tl.logger.Panic(args...)\n\treturn l\n}\n\n// Printf wraps the logrus Printf function\nfunc (l *Logger) Printf(format string, args ...interface{}) {\n\tl.logger.Printf(format, args...)\n}\n\n// Wrappers for common fields\n\n// WithError adds error information to the logging record\nfunc (l *Logger) WithError(err error) *Logger {\n\treturn l.WithErrorFields(Fields{\n\t\t\"message\": err.Error(),\n\t\t\"kind\":    fmt.Sprintf(\"%T\", err),\n\t})\n}\n\n// WithStack adds a stack trace to the logging record\nfunc (l *Logger) WithStack() *Logger {\n\treturn l.WithErrorFields(Fields{\n\t\t\"stack\": debug.Stack(),\n\t})\n}\n\n// WithFields sets key-value pairs in the \"meta\" set. Use `l.logger.WithField`\n// in order to set a field directly in the logrus.Entry.\nfunc (l *Logger) WithFields(fields Fields) *Logger {\n\t// get the existing set of fields or create a new one\n\tmetaFields, ok := l.Fields(\"meta\")\n\tif !ok {\n\t\tmetaFields = Fields{}\n\t}\n\n\t// we skip the filtering check in withFields because anything goes\n\t// in the \"meta\" fields\n\tfor key, val := range fields {\n\t\tmetaFields[key] = val\n\t}\n\n\treturn \u0026Logger{\n\t\tlogger: l.logger.WithField(\"meta\", metaFields),\n\t\tRate:   l.Rate,\n\t}\n}\n\n// WithField is a helper to add a single field to the meta set\nfunc (l *Logger) WithField(key string, value interface{}) *Logger {\n\treturn l.WithFields(Fields{key: value})\n}\n\n// WithBasicFields is a helper to set top level fields like timestamps\n// This matches the `RootFieldSet` in `bf_storage.logging` py lib,\n// however it has not been renamed yet since some go instrumentation relies on it already.\nfunc (l *Logger) WithBasicFields(fields Fields) *Logger {\n\tvar raw map[string]interface{}\n\tbasicFields := Fields{}\n\tfieldNames := []string{\n\t\t\"cluster\",\n\t\t\"level\",\n\t\t\"message\",\n\t\t\"region\",\n\t\t\"service\",\n\t\t\"source\",\n\t}\n\n\tbasicFields.extend(fieldNames, fields)\n\traw = basicFields\n\treturn \u0026Logger{\n\t\tlogger: l.logger.WithFields(raw),\n\t\tRate:   l.Rate,\n\t}\n}\n\n// WithDatabaseFields replicates the `bf_storage.logging` DatabaseFieldSet.\n// This is in line with the BuzzFeed established standard.\nfunc (l *Logger) WithDatabaseFields(fields Fields) *Logger {\n\tfieldNames := []string{\n\t\t\"instance\",\n\t\t\"statement\",\n\t\t\"operation\",\n\t\t\"user\",\n\t}\n\treturn l.updateFields(\"database\", fieldNames, fields)\n}\n\n// WithErrorFields sets fields in the \"error\" set.\n// We use Datadog's recommendation of \"stack\", \"message\", and \"field\".\nfunc (l *Logger) WithErrorFields(fields Fields) *Logger {\n\tfieldNames := []string{\n\t\t\"stack\",\n\t\t\"message\",\n\t\t\"kind\",\n\t}\n\treturn l.updateFields(\"error\", fieldNames, fields)\n}\n\n// WithHTTPFields sets fields in the \"http\" set\n// This fieldset uses the DataDog standard naming conventions\n// https://docs.datadoghq.com/logs/processing/attributes_naming_convention/#http-requests\nfunc (l *Logger) WithHTTPFields(fields Fields) *Logger {\n\tfieldNames := []string{\n\t\t\"url\",\n\t\t\"method\",\n\t\t\"status_code\",\n\t\t\"referer\",\n\t\t\"request_id\",\n\t\t\"useragent\",\n\t\t\"request_time\",\n\t\t\"duration\",\n\t}\n\treturn l.updateFields(\"http\", fieldNames, fields)\n}\n\n// WithLoggerFields supplies the standard logger fieldset.\n// See DataDog docs here for naming conventions:\n// https://docs.datadoghq.com/logs/processing/attributes_naming_convention/#source-code\nfunc (l *Logger) WithLoggerFields(fields Fields) *Logger {\n\tfieldNames := []string{\n\t\t\"name\",\n\t\t\"thread_name\",\n\t\t\"path_name\",\n\t\t\"method_name\",\n\t\t\"module\",\n\t\t\"line\",\n\t\t\"level_name\",\n\t\t\"version\",\n\t}\n\treturn l.updateFields(\"logger\", fieldNames, fields)\n}\n\n// WithRigFields sets fields in the \"rig\" set\n// This is used internally to add rig env data to each entry.\nfunc (l *Logger) WithRigFields(fields Fields) *Logger {\n\tfieldNames := []string{\n\t\t\"service\",\n\t\t\"cluster\",\n\t\t\"version\",\n\t\t\"pid\",\n\t\t\"region\",\n\t}\n\treturn l.updateFields(\"rig\", fieldNames, fields)\n}\n\n// WithStorageFields replicates the `bf_storage.logging` StorageFieldSet.\n// This is in line with the BuzzFeed established standard.\nfunc (l *Logger) WithStorageFields(fields Fields) *Logger {\n\tfieldNames := []string{\n\t\t\"bucket_name\",\n\t\t\"redis_hostname\",\n\t\t\"redis_isolated_hostname\",\n\t\t\"redis_shared_hostname\",\n\t\t\"max_thread_count\",\n\t\t\"mysql_database_name\",\n\t\t\"mysql_port\",\n\t\t\"mysql_port\",\n\t\t\"mysql_hostname\",\n\t\t\"mysql_isolated_hostname\",\n\t\t\"mysql_shared_hostname\",\n\t\t\"mysql_isolated_hostname\",\n\t\t\"mysql_username\",\n\t\t\"mysql_isolated_database_name\",\n\t\t\"mysql_shared_database_name\",\n\t\t\"environment_type\",\n\t\t\"version\",\n\t}\n\treturn l.updateFields(\"storage\", fieldNames, fields)\n}\n\n// WithUpstreamFields replicates `UpstreamFieldSet` in `bf_storage.logging`.\n// This brings the upstream fieldset inline with the BuzzFeed convention.\nfunc (l *Logger) WithUpstreamFields(fields Fields) *Logger {\n\tfieldNames := []string{\n\t\t\"service\",\n\t\t\"request_url\",\n\t\t\"status_code\",\n\t\t\"response_time\",\n\t}\n\treturn l.updateFields(\"upstream\", fieldNames, fields)\n}\n\n// SetLevel sets the default log level on the underlying logrus instance.\n//\nfunc (l *Logger) SetLevel(level logrus.Level) {\n\tl.raw.Level = level\n}\npackage logging\n\nimport (\n\t\"bytes\"\n\t\"testing\"\n\n\t\"github.com/sirupsen/logrus\"\n)\n\ntype modifier func(*logrus.Logger)\n\nfunc modifyLogrusOutput(b *bytes.Buffer) modifier {\n\treturn func(l *logrus.Logger) {\n\t\tl.SetOutput(b)\n\t}\n}\n\nfunc modifyLogrusLevel(l *logrus.Logger) {\n\tl.Level = logrus.DebugLevel\n}\n\n// TestDebugLogLevelSetDirectly validates that a consumer can change settings\n// directly on the underlying logrus instance, such as the debug log level.\n//\n// NOTE: this requires the consumer to import the logrus package as a\n// dependency inside their service.\n//\nfunc TestDebugLogLevelSetDirectly(t *testing.T) {\n\tvar b bytes.Buffer\n\n\tlog := NewLogger(\"golang_logging\", modifyLogrusOutput(\u0026b), modifyLogrusLevel)\n\tlog.Debug(\"debug!\")\n\tlog.Info(\"info!\")\n\n\tif !bytes.Contains(b.Bytes(), []byte(\"debug!\")) {\n\t\tt.Error(\"debug level wasn't set\")\n\t}\n\n\tif !bytes.Contains(b.Bytes(), []byte(\"info!\")) {\n\t\tt.Error(\"info level wasn't set\")\n\t}\n}\n\n// TestDebugLogLevelSetIndirectly validates that a consumer of the logging\n// library doesn't have to add logrus as a dependency if they only need to set\n// the log level (which is a standard feature consumers are likely to use).\n//\n// NOTE: for the sake of the test environment I still need to import logrus and\n// modify it 'directly' in order for it to send log output to a buffer instead\n// of to stdout, but I should be able to still set the log level 'indirectly'.\n//\nfunc TestDebugLogLevelSetIndirectly(t *testing.T) {\n\tvar b bytes.Buffer\n\n\tlog := NewLogger(\"golang_logging\", modifyLogrusOutput(\u0026b))\n\tlog.SetLevel(DebugLevel)\n\n\tlog.Debug(\"debug!\")\n\tlog.Info(\"info!\")\n\n\tif !bytes.Contains(b.Bytes(), []byte(\"debug!\")) {\n\t\tt.Error(\"debug level wasn't set\")\n\t}\n\n\tif !bytes.Contains(b.Bytes(), []byte(\"info!\")) {\n\t\tt.Error(\"info level wasn't set\")\n\t}\n}\n","tags":"#go #logs"},{"id":"0c9feb43f65d3abfa5e64be4e118440d","title":"Dynamically Create Struct ","content":"// https://play.golang.org/p/iIf7OF_lPBG\n//\n// all this good work is done by https://github.com/Ompluscator/dynamic-struct\n// which offers much more functionality than I had stripped out from that library\n//\n// I was working on something where I wanted only standard library implementation code\n// so I decided to just strip out the code I needed\n//\npackage main\n\nimport (\n\t\"encoding/json\"\n\t\"fmt\"\n\t\"reflect\"\n)\n\n// DynamicStruct contains defined dynamic struct.\n// This definition can't be changed anymore, once is built.\n// It provides a method for creating new instances of same defintion.\ntype DynamicStruct interface {\n\t// New provides new instance of defined dynamic struct.\n\t//\n\t// value := dStruct.New()\n\t//\n\tNew() interface{}\n}\n\n// Builder holds all fields' definitions for desired structs.\ntype Builder interface {\n\t// AddField creates new struct's field.\n\t// It expects field's name, type and string.\n\t// Type is provided as an instance of some golang type.\n\t// Tag is provided as classical golang field tag.\n\t//\n\t// builder.AddField(\"SomeFloatField\", 0.0, `json:\"boolean\" validate:\"gte=10\"`)\n\t//\n\tAddField(name string, typ interface{}, tag string) Builder\n\n\t// Build returns definition for dynamic struct.\n\t// Definition can be used to create new instances.\n\t//\n\t// dStruct := builder.Build()\n\t//\n\tBuild() DynamicStruct\n}\n\ntype dynamicStructImpl struct {\n\tdefinition reflect.Type\n}\n\ntype fieldConfigImpl struct {\n\ttyp interface{}\n\ttag string\n}\n\ntype builderImpl struct {\n\tfields map[string]*fieldConfigImpl\n}\n\nfunc (b *builderImpl) AddField(name string, typ interface{}, tag string) Builder {\n\tb.fields[name] = \u0026fieldConfigImpl{\n\t\ttyp: typ,\n\t\ttag: tag,\n\t}\n\n\treturn b\n}\n\nfunc (b *builderImpl) Build() DynamicStruct {\n\tvar structFields []reflect.StructField\n\n\tfor name, field := range b.fields {\n\t\tstructFields = append(structFields, reflect.StructField{\n\t\t\tName: name,\n\t\t\tType: reflect.TypeOf(field.typ),\n\t\t\tTag:  reflect.StructTag(field.tag),\n\t\t})\n\t}\n\n\treturn \u0026dynamicStructImpl{\n\t\tdefinition: reflect.StructOf(structFields),\n\t}\n}\n\nfunc (ds *dynamicStructImpl) New() interface{} {\n\treturn reflect.New(ds.definition).Interface()\n}\n\n// NewStruct returns new clean instance of Builder interface\n// for defining fresh dynamic struct.\n//\n// builder := NewStruct()\n//\nfunc NewStruct() Builder {\n\treturn \u0026builderImpl{\n\t\tfields: map[string]*fieldConfigImpl{},\n\t}\n}\n\nfunc main() {\n\tinstance := NewStruct().\n\t\tAddField(\"Integer\", 0, `json:\"int\"`).\n\t\tAddField(\"Text\", \"\", `json:\"someText\"`).\n\t\tAddField(\"Float\", 0.0, `json:\"double\"`).\n\t\tAddField(\"Boolean\", false, \"\").\n\t\tAddField(\"Slice\", []int{}, \"\").\n\t\tAddField(\"Anonymous\", \"\", `json:\"-\"`).\n\t\tBuild().\n\t\tNew()\n\n\tfmt.Printf(\"empty struct instance:\\n%+v\\n\\n\", instance)\n\n\tdata := []byte(`\n{\n    \"int\": 123,\n    \"someText\": \"example\",\n    \"double\": 123.45,\n    \"Boolean\": true,\n    \"Slice\": [1, 2, 3],\n    \"Anonymous\": \"avoid to read\"\n}\n`)\n\n\tjson.Unmarshal(data, \u0026instance)\n\n\tfmt.Printf(\"struct data:\\n%+v\\n\", instance)\n}\n// https://play.golang.org/p/0cfY0LZ0NdL\n//\n// all this good work is done by https://github.com/Ompluscator/dynamic-struct\n// which offers much more functionality than I had stripped out from that library\n//\n// I was working on something where I wanted only standard library implementation code\n// so I decided to just strip out the code I needed\n//\npackage main\n\nimport (\n\t\"encoding/json\"\n\t\"fmt\"\n\t\"reflect\"\n)\n\n// DynamicStruct contains defined dynamic struct.\n// This definition can't be changed anymore, once is built.\n// It provides a method for creating new instances of same defintion.\ntype DynamicStruct interface {\n\t// New provides new instance of defined dynamic struct.\n\t//\n\t// value := dStruct.New()\n\t//\n\tNew() interface{}\n}\n\n// Builder holds all fields' definitions for desired structs.\ntype Builder interface {\n\t// AddField creates new struct's field.\n\t// It expects field's name, type and string.\n\t// Type is provided as an instance of some golang type.\n\t// Tag is provided as classical golang field tag.\n\t//\n\t// builder.AddField(\"SomeFloatField\", 0.0, `json:\"boolean\" validate:\"gte=10\"`)\n\t//\n\tAddField(name string, typ interface{}, tag string) Builder\n\n\t// Build returns definition for dynamic struct.\n\t// Definition can be used to create new instances.\n\t//\n\t// dStruct := builder.Build()\n\t//\n\tBuild() DynamicStruct\n}\n\ntype dynamicStructImpl struct {\n\tdefinition reflect.Type\n}\n\ntype fieldConfigImpl struct {\n\ttyp interface{}\n\ttag string\n}\n\ntype builderImpl struct {\n\tfields map[string]*fieldConfigImpl\n}\n\nfunc (b *builderImpl) AddField(name string, typ interface{}, tag string) Builder {\n\tb.fields[name] = \u0026fieldConfigImpl{\n\t\ttyp: typ,\n\t\ttag: tag,\n\t}\n\n\treturn b\n}\n\nfunc (b *builderImpl) Build() DynamicStruct {\n\tvar structFields []reflect.StructField\n\n\tfor name, field := range b.fields {\n\t\tstructFields = append(structFields, reflect.StructField{\n\t\t\tName: name,\n\t\t\tType: reflect.TypeOf(field.typ),\n\t\t\tTag:  reflect.StructTag(field.tag),\n\t\t})\n\t}\n\n\treturn \u0026dynamicStructImpl{\n\t\tdefinition: reflect.StructOf(structFields),\n\t}\n}\n\nfunc (ds *dynamicStructImpl) New() interface{} {\n\treturn reflect.New(ds.definition).Interface()\n}\n\n// NewStruct returns new clean instance of Builder interface\n// for defining fresh dynamic struct.\n//\n// builder := NewStruct()\n//\nfunc NewStruct() Builder {\n\treturn \u0026builderImpl{\n\t\tfields: map[string]*fieldConfigImpl{},\n\t}\n}\n\nfunc main() {\n\tinstance := NewStruct()\n\n\t// now you can loop a data structure to generate these calls...\n\tinstance.AddField(\"Integer\", 0, `json:\"int\"`)\n\tinstance.AddField(\"Text\", \"\", `json:\"someText\"`)\n\tinstance.AddField(\"Float\", 0.0, `json:\"double\"`)\n\tinstance.AddField(\"Boolean\", false, \"\")\n\tinstance.AddField(\"Slice\", []int{}, \"\")\n\tinstance.AddField(\"Anonymous\", \"\", `json:\"-\"`)\n\n\tvalue := instance.Build().New()\n\n\tdata := []byte(`\n{\n    \"int\": 123,\n    \"someText\": \"example\",\n    \"double\": 123.45,\n    \"Boolean\": true,\n    \"Slice\": [1, 2, 3],\n    \"Anonymous\": \"avoid to read\"\n}\n`)\n\n\tjson.Unmarshal(data, \u0026value)\n\n\tfmt.Printf(\"struct data:\\n%+v\\n\", value)\n}\n// READ THIS FOR MANY MORE EXAMPLES!\n// https://medium.com/capital-one-tech/learning-to-use-go-reflection-822a0aed74b7\n\npackage main\n\nimport (\n\t\"fmt\"\n\t\"reflect\"\n)\n\ntype Foo struct {\n\tA int `tag1:\"First Tag\" tag2:\"Second Tag\"`\n\tB string\n}\n\nfunc main() {\n\tgreeting := \"hello\"\n\tf := Foo{A: 10, B: \"Salutations\"}\n\n\tgVal := reflect.ValueOf(greeting)\n\t// not a pointer so all we can do is read it\n\tfmt.Println(\"ORIGINAL GREETING:\", gVal.Interface())\n\n\tgpVal := reflect.ValueOf(\u0026greeting)\n\t// it’s a pointer, so we can change it, and it changes the underlying variable\n\tgpVal.Elem().SetString(\"goodbye\")\n\tfmt.Println(\"NEW GREETING:\", greeting)\n\n\tfType := reflect.TypeOf(f)\n\tfVal := reflect.New(fType)\n\tfVal.Elem().Field(0).SetInt(20)\n\tfVal.Elem().Field(1).SetString(\"Greetings\")\n\tf2 := fVal.Elem().Interface().(Foo)\n\t\n\t\n\tfmt.Printf(\"ORIGINAL struct: %+v, %d, %s\\n\", f, f.A, f.B)\n\tfmt.Printf(\"NEW struct: %+v, %d, %s\\n\", f2, f2.A, f2.B)\n}\n","tags":"#go"},{"id":"d0d2e08152858944249ce8bbfd646851","title":"Stack and Queue Implementation ","content":"package main\n\nimport (\n\t\"fmt\"\n)\n\ntype Stack []int\n\nfunc (s Stack) Empty() bool {\n\treturn len(s) == 0\n}\n\nfunc (s *Stack) Push(v int) {\n\t*s = append(*s, v)\n}\n\nfunc (s *Stack) Pop() int {\n\tv := (*s)[len(*s)-1]\n\t*s = (*s)[:len(*s)-1]\n\treturn v\n  \n}\n\ntype Queue []int\n\nfunc (q Queue) Empty() bool {\n\treturn len(q) == 0\n}\n\nfunc (q *Queue) Enqueue(v int) {\n\t// the wrapping parentheses are not necessary\n\t//\n\t(*q) = append((*q), v)\n}\n\nfunc (q *Queue) Dequeue() int {\n\tv := (*q)[0]\n\t\n\t// the parentheses is needed for the indexing but not the assignment\n\t// otherwise you'd get an error stating: cannot slice q (type *Queue)\n\t// because you can't slice a pointer to something, \n\t// you need the actual 'thing' dereferenced\n\t//\n\t*q = (*q)[1:len(*q)]\n\treturn v\n}\n\nfunc main() {\n\ts := Stack{}\n\ts.Push(1)\n\tfmt.Printf(\"push %+v (%T)\\n\", s, s)\n\ts.Push(2)\n\tfmt.Printf(\"push %+v (%T)\\n\", s, s)\n\tfmt.Println(s.Pop())\n\tfmt.Println(s.Pop())\n\tfmt.Println(s.Empty())\n\t// Output:\n\t// 2\n\t// 1\n\t// true\n\n\tq := Queue{}\n\tq.Enqueue(1)\n\tq.Enqueue(2)\n\tfmt.Println(q.Dequeue())\n\tfmt.Println(q.Dequeue())\n\tfmt.Println(q.Empty())\n\t// Output:\n\t// 1\n\t// 2\n\t// true\n}\n","tags":"#go"},{"id":"af502e7a592fbf07a10433111cefd10f","title":"Writing a HTTP Response ","content":"\u003e Copied verbatim from https://stackoverflow.com/a/37872799\n\n## io.Writer\n\nAn output stream represents a target to which you can write sequence(s) of bytes. In Go this is captured by the general `io.Writer` interface:\n\n```go\ntype Writer interface {\n    Write(p []byte) (n int, err error)\n}\n```\n\nEverything that has this single `Write()` method can be used as an output, for example a file on your disk (`os.File`), a network connection (`net.Conn`) or an in-memory buffer (`bytes.Buffer`).\n\nThe `http.ResponseWriter` that is used to configure the HTTP response and send the data to the client is also such an `io.Writer`, the data you want to send (the response body) is assembled by calling (not necessarily just once) `ResponseWriter.Write()` (which is to implement the general `io.Writer`). This is the only guarantee you have about the implementation of the `http.ResponseWriter` interface (regarding sending the body).\n\n## WriteString()\n\nNow on to `WriteString()`. Often we want to write textual data to an `io.Writer`. Yes, we can do that simply by converting the string to a `[]byte`, e.g.\n\n```go\nw.Write([]byte(\"Hello\"))\n```\n\nwhich works as expected. However this is a very frequent operation and so there is a \"generally\" accepted method for this captured by the `io.StringWriter` interface (available since Go 1.12, prior to that it was unexported):\n\n```go\ntype StringWriter interface {\n    WriteString(s string) (n int, err error)\n}\n```\n\nThis method gives the possibility to write a string value instead of a `[]byte`. So if something (that also implements `io.Writer`) implements this method, you can simply pass string values without `[]byte` conversion. This seems like a minor simplification in code, but it's more than that. Converting a string to []byte has to make a copy of the string content (because string values are immutable in Go, read more about it here: [golang: `[]byte(string)` vs `[]byte(*string)`](https://stackoverflow.com/questions/43470284/golang-bytestring-vs-bytestring/43470344#43470344)), so there is some overhead which becomes noticeable if the string is \"bigger\" and/or you have to do this many times.\n\nDepending on the nature and implementation details of an `io.Writer`, it may be possible to write the content of a string without converting it to `[]byte` and thus avoiding the above mentioned overhead.\n\nAs an example, if an `io.Writer` is something that writes to an in-memory buffer (`bytes.Buffer` is such an example), it may utilize the builtin `copy()` function:\n\n\u003e The copy built-in function copies elements from a source slice into a destination slice. (As a special case, it also will copy bytes from a string to a slice of bytes.)\n\nThe `copy()` may be used to copy the content (bytes) of a string into a `[]byte` without converting the string to `[]byte`, e.g.:\n\n```go\nbuf := make([]byte, 100)\ncopy(buf, \"Hello\")\n```\n\nNow there is a \"utility\" function `io.WriteString()` that writes a string into an `io.Writer`. But it does this by first checking if the (dynamic type of the) passed `io.Writer` has a `WriteString()` method, and if so, that will be used (whose implementation is likely more efficient). If the passed `io.Writer` has no such method, then the general convert-to-byte-slice-and-write-that method will be used as a \"fallback\".\n\nYou might think that this `WriteString()` will only prevail in case of in-memory buffers, but that is not true. Responses of web requests are also often buffered (using an in-memory buffer), so it may improve performance in case of `http.ResponseWriter` too. And if you look at the implementation of `http.ResponseWriter`: it's the unexported type `http.response` ([`server.go`](https://golang.org/src/net/http/server.go) currently line `#308`) which does implement `WriteString()` (currently line `#1212`) so it does imply improvement.\n\nAll in all, whenever you write string values, recommended to use `io.WriteString()` as it may be more efficient (faster).\n\n## fmt.Fprintf()\n\nYou should look at this as a convenient and easy way to add more formatting to the data you want to write, in exchange for being somewhat less performant.\n\nSo use `fmt.Fprintf()` if you want formatted string created in the easy way, e.g.:\n\n```go\nname := \"Bob\"\nage := 23\nfmt.Fprintf(w, \"Hi, my name is %s and I'm %d years old.\", name, age)\n```\n\nWhich will result in the following string to be written:\n\n```\nHi, my name is Bob and I'm 23 years old.\n```\n\nOne thing you must not forget: `fmt.Fprintf()` expects a format string, so it will be preprocessed and not written as-is to the output. As a quick example:\n\n```go\nfmt.Fprintf(w, \"100 %%\")\n```\n\nYou'd expect that \"100 %%\" would be written to the output (with 2 % characters), but only one will be sent as in the format string % is a special character and %% will only result in one % in the output.\n\nIf you just want to write a string using the `fmt` package, use `fmt.Fprint()` which does not require a format string:\n\n```go\nfmt.Fprint(w, \"Hello\")\n```\n\nAnother benefit of using the fmt package is that you can write values of other types too, not just strings, e.g.\n\n```go\nfmt.Fprint(w, 23, time.Now())\n```\n\n(Of course the rules how to convert any value to a string–and to series of bytes eventually–is well defined, in the doc of the `fmt` package.)\n\nFor \"simple\" formatted outputs the `fmt` package might be OK. For complex output documents do consider using the text/template (for general text) and html/template (whenever the output is HTML).\n\n## Passing / handing over http.ResponseWriter\n\nFor completeness, we should mention that often the content you want to send as the web response is generated by \"something\" that supports \"streaming\" the result. An example may be a JSON response, which is generated from a `struct` or `map`.\n\nIn such cases it's often more efficient to pass / hand over your `http.ResponseWriter` which is an `io.Writer` to this something if it supports writing the result to an `io.Writer` on-the-fly.\n\nA good example of this is generating JSON responses. Sure, you could marshal an object into JSON with `json.Marshal()`, which returns you a byte slice, which you can simply send by calling `ResponseWriter.Write()`.\n\nHowever, it is more efficient to let the json package know that you have an `io.Writer`, and ultimately you want to send the result to that. That way it is unnecessary to first generate the JSON text in a buffer, which you just write into your response and then discard. You can create a new `json.Encoder` by calling `json.NewEncoder()` to which you can pass your `http.ResponseWriter` as an `io.Writer`, and calling `Encoder.Encode()` after that will directly write the JSON result into your response writer.\n\nOne disadvantage here is that if generating the JSON response fails, you might have a partially sent / committed response which you cannot take back. If this is a problem for you, you don't really have a choice other than generating the response in a buffer, and if marshaling succeeds, then you may write the complete response at once.\n\n","tags":"#go #http"},{"id":"2ad28a16f303b13dd58e41b3831961e3","title":"Module Error: malformed module path ... missing dot in first path element ","content":"When using go modules I've stumbled across this error a few times, but it's infrequent enough for me to spend hours _each_ time trying to recall how to fix it.\n\n```\nmalformed module path ... missing dot in first path element\n```\n\nThis occurs when I'm using the `replace` directive in a go.mod file to tell the go compiler that anytime it sees a custom import like `foo/bar` to actually lookup that code from somewhere locally available to the application.\n\ne.g.\n\n```\nmodule github.com/buzzfeed/mono/rate_control\n\ngo 1.14\n\nrequire (\n\tbuzzfeed/instrumentation v0.0.0\n\tbuzzfeed/settings v0.0.0\n\tgithub.com/go-redis/redis v6.15.7+incompatible\n\tgithub.com/go-redis/redis/v7 v7.2.0\n\tgithub.com/sirupsen/logrus v1.4.1\n)\n\nreplace (\n\tbuzzfeed/instrumentation =\u003e ./shared/lib/instrumentation\n\tbuzzfeed/settings =\u003e ./shared/lib/settings\n)\n```\n\nSo the problem with the above is that I import `buzzfeed/instrumentation` and that itself is a go module that imports `buzzfeed/logging` and `buzzfeed/metrics`.\n\nIn `buzzfeed/instrumentation`'s go.mod file it also uses `replace` to change the lookup of those dependencies.\n\nThe source of the `malformed module path` error is actually misleading.\n\nThe actual problem is documented in the golang wiki: https://github.com/golang/go/wiki/Modules#when-should-i-use-the-replace-directive (specifically the first paragraph under the linked section):\n\n\u003e As described in the 'go.mod' concepts section above, replace directives provide additional control in the top-level go.mod for what is actually used to satisfy a dependency found in the Go source or go.mod files, **_while replace directives in modules other than the main module are ignored when building the main module_**.\n\nThis means that my top-level go.mod file, although it doesn't directly use `buzzfeed/logging` or `buzzfeed/metrics`, still needs the 'replace' directives to be added.\n\nFor example, the following fixes it...\n\n```diff\nmodule github.com/buzzfeed/mono/rate_control\n\ngo 1.14\n\nrequire (\n\tbuzzfeed/instrumentation v0.0.0\n\tbuzzfeed/logging v0.0.0\n\tbuzzfeed/metrics v0.0.0\n\tbuzzfeed/settings v0.0.0\n\tgithub.com/go-redis/redis v6.15.7+incompatible\n\tgithub.com/go-redis/redis/v7 v7.2.0\n\tgithub.com/sirupsen/logrus v1.4.1\n)\n\nreplace (\n\tbuzzfeed/instrumentation =\u003e ./shared/lib/instrumentation\n+\tbuzzfeed/logging =\u003e ./shared/lib/logging\n+\tbuzzfeed/metrics =\u003e ./shared/lib/metrics\n\tbuzzfeed/settings =\u003e ./shared/lib/settings\n)\n```\n","tags":"#go"},{"id":"3dd0e5c9e9dca246025462035db2868d","title":"json.Decoder vs json.Unmarshal ","content":"## General Rule of Thumb\n\n- Use `json.Unmarshal` when the JSON data is already in memory (like a string or `[]byte`) and you know the data is small or moderate in size.\n- Use `json.NewDecoder` for large JSON files, streaming data (such as from network requests), or when you need to handle data incrementally.\n\n`json.Unmarshal` reads the entire JSON into memory and decodes it directly into a Go variable, where as `json.NewDecoder` reads JSON data incrementally, parsing one token at a time, which is more memory-efficient with large JSON payloads.\n\nIn summary, use `json.Unmarshal` for _simplicity_ with smaller data, and `json.NewDecoder` for _efficiency_ with large or streaming data.\n\n## Terminology\n\n- `json.Marshal`: encode data structure as JSON.\n- `json.Unmarshal`: decode JSON into data structure.\n\n\u003e [!NOTE] \n\u003e This is also sometimes referred to as 'serialize' and 'deserialize`.\n\n## Differences in `json.Decoder`\n\n1. `json.Decoder` is for JSON streams.\n2. `json.Decoder` silently ignores invalid syntax.\n3. `json.Decoder` does not drain HTTP connections properly.\n\n\u003e [!NOTE]\n\u003e The issues with `json.Decoder` are summarized from https://ahmet.im/blog/golang-json-decoder-pitfalls/\n\n### JSON Streams\n\n`json.Decoder` is for JSON _streams_ (which are just concatenated/or new-line separated JSON values).\n\nExample of a JSON stream:\n\n```json\n{\"Name\": \"Ed\"}{\"Name\": \"Sam\"}{\"Name\": \"Bob\"}\n```\n\n\u003e Note: the entire content of that stream is not valid JSON (it should be inside a `[ ]` to be a valid JSON value), BUT it is a valid JSON _stream_!\n\n### Ignores Invalid Syntax\n\nLots of people have reported unexpected things happening because of how `Decoder` just silently ignores malformed JSON syntax. But I've not had an issue because I don't really use `Decoder` so I can't give a _good_ example of how things can go wrong.\n\nA _poor_ example (which isn't the same thing actually as silently ignoring malformed JSON syntax) would be that you expect each object in the stream to have an `int` field, but if it's missing then to omit the field from the data structure. With `Decoder` it will utilize the zero value instead of just dropping the field altogether like you can with `Unmarshal` when using struct tags...\n\n```go\n// Field is ignored by this package.\nField int `json:\"-\"`\n\n// Field appears in JSON as key \"myName\".\nField int `json:\"myName\"`\n\n// Field appears in JSON as key \"myName\" and\n// the field is omitted from the object if its value is empty,\n// as defined above.\nField int `json:\"myName,omitempty\"`\n\n// Field appears in JSON as key \"Field\" (the default), but\n// the field is skipped if empty.\n// Note the leading comma.\nField int `json:\",omitempty\"`\n```\n\n### Fails to drain HTTP connections\n\nThis can slows down HTTP requests up to ~4x (although this is fixed by the time of Go 1.7).\n\nIf the HTTP endpoint is responding with a single JSON object and you are calling `json.Decoder#Decode()` only once (in which case you should be using `json.Unmarshal()` instead!), it means you are not getting `io.EOF` returned yet. Therefore you are not terminating `json.Decoder` by seeing that `io.EOF` and the response body remains open and therefore the TCP connection (or another `Transport` used) cannot be returned to the connection pool even though you are done with it. \n","tags":"#go #json #serialization"},{"id":"c92a7e1e47477650ed528726fa1a0c73","title":"Comparison Matrix Table Properties ","content":"# Comparing Software Tools\n\nWhen choosing a software tool you should compare the value of each individual tool that is under consideration.\n\nWe typically do this by creating a comparative table matrix.\n\n## Comparison Matrix\n\nA comparison matrix table should take into consideration the following properties:\n\n- **Activeness**: is the repo/source code actively maintained (e.g. features, bug fixes etc).\n- **Dependencies**: how large is the dependency graph.\n- **Design**: does the interface follow golang syntax/language best patterns.\n- **Documentation**: is there sufficient documentation to support the code.\n- **Extensibility**: is it part of a larger ecosystem and is it easy to extend.\n- **Performance**: which implementation is more performant.\n- **Popularity**: which tool is more popular (based on GitHub stars, so not scientific!).\n- **Stability**: how buggy is the software (based on GitHub issues, so not scientific!). †\n- **Suitability**: how effective is it (e.g. what core APIs/features does it provide).\n- **Usability**: how easy to use it is (warning: this is subjective).\n\n\u003e † stability: we can't really judge the quality of issues raised, nor can we suggest that more issues is an indicator of poorly written software (e.g. a more popular tool is likely to have a larger number of issues raised compared to a tool with very few users).\n\u003e\n\u003e But we can at least compare the number of issues that have been closed vs those that are left open and stale (e.g. a code base may be very active and still have poor user engagement by ignoring opened issues).\n\u003e\n\u003e Although again, this is flawed because a code base with a much higher number of users (and thus a much higher number of issues raised) may not be able to review issues as quickly as a code base with very few users.\n\n## Emoji Key\n\nWe will use the following emojis to identify comparative outcomes:\n\n- ✅: clear winner\n- ❌: clear loser\n- ⚖️: balanced results\n- 🗑: no winner/no loser\n\n\u003e **Note**: I will sometimes mark both tools as neither ‘winner’ or ‘loser’ due to the comparative value not necessarily being indicative of either. For example, the data point might just be ‘of interest’ (such as the date of when the project started).\n\n## Example\n\n||Tool A|Tool B|\n|---|---|---|\n|Property A|✅|❌|\n|Property B|⚖️|⚖️|\n|Property C|🗑|🗑|\n","tags":"#project"},{"id":"7ae8445d3179926be127c11dfe962f95","title":"Closure Example ","content":"package main\n\nimport \"fmt\"\n\nfunc foo(x int) func(int) int {\n\treturn func(y int) int {\n\t\treturn x + y\n\t}\n}\n\nfunc main() {\n\tf := foo(1)\n\tfmt.Println(f(2)) // 3\n}\n\n","tags":"#go"},{"id":"b4d7c15ef7501d863d146530ff1ff22f","title":"Merge two structs ","content":"package main\n\nimport (\n\t\"fmt\"\n)\n\ntype foo struct {\n\tf int\n}\n\ntype bar struct {\n\tb int\n}\n\ntype baz struct {\n\t*foo\n\t*bar\n}\n\ntype qux struct {\n\tf *foo\n\tb *bar\n}\n\ntype combined struct {\n\t*baz\n}\n\nfunc acceptsFoo(f *foo) {\n\tfmt.Printf(\"accepted foo: %+v\\n\", f)\n}\n\nfunc acceptsAnything(f *foo, x interface{}) {\n\tfmt.Printf(\"f: %+v\\n\", f)\n\tfmt.Printf(\"x: %+v\\n\", x)\n}\n\nfunc main() {\n\tf := \u0026foo{1}\n\tb := \u0026bar{2}\n\tz := \u0026baz{f, b}\n\tq := \u0026baz{foo: f, bar: b}\n\tc := \u0026combined{z}\n\n\tfmt.Printf(\"%+v\\n\", f)\n\tfmt.Printf(\"%+v\\n\", b)\n\tfmt.Printf(\"%+v\\n\", z)\n\tfmt.Printf(\"%+v\\n\", q)\n\n\tfmt.Printf(\"z.f %+v\\n\", z.f)\n\tfmt.Printf(\"z.b %+v\\n\", z.b)\n\tfmt.Printf(\"z.foo.f %+v\\n\", z.foo.f)\n\tfmt.Printf(\"z.bar.b %+v\\n\", z.bar.b)\n\n\tfmt.Printf(\"q.f %+v\\n\", q.f)\n\tfmt.Printf(\"q.b %+v\\n\", q.b)\n\tfmt.Printf(\"q.foo.f %+v\\n\", q.foo.f)\n\tfmt.Printf(\"q.bar.b %+v\\n\", q.bar.b)\n\n\tfmt.Printf(\"c.f %+v\\n\", c.f)\n\tfmt.Printf(\"c.b %+v\\n\", c.b)\n\tfmt.Printf(\"c.foo.f %+v\\n\", c.foo.f)\n\tfmt.Printf(\"c.bar.b %+v\\n\", c.bar.b)\n\tfmt.Printf(\"c.baz.foo.f %+v\\n\", c.baz.foo.f)\n\tfmt.Printf(\"c.baz.bar.b %+v\\n\", c.baz.bar.b)\n\n\tacceptsFoo(f)\n\tacceptsAnything(f, b)\n}\n","tags":"#go"},{"id":"106c2f1b806f80f04e00cd9d43e1c971","title":"IP Transit ","content":"\u003e See also:  \n\u003e https://www.connetu.com/blog/articles/How-IP-transit-works-on-the-Internet  \n\u003e https://blog.equinix.com/blog/2018/12/10/networking-for-nerds-do-you-know-the-difference-between-ip-peering-vs-ip-transit-for-enterprise-internet-interconnection/\n\n# What is IP Transit? - Genesis Adaptive Blog\n\nIf your business utilizes the Internet in any capacity, then you are undoubtedly familiar with the end result of IP Transit. However, having a more in-depth understanding of IP Transit will allow you to make better decisions about how your business accesses the Internet and how your customers reach your applications and services. In order to fully understand what IP Transit is and how it effects your business, we first need a better understanding of what the Internet is. We know that the Internet is a global set of interconnected networks that speak common protocols to exchange information. However, for the purpose of this article, we will go further into how these networks function and how IP Transit ties them all together.\n\n## Traffic Though the Internet\n\nOur websites, applications, and databases reside on servers. Through the magic of The Internet, we expect anyone, anywhere in the world to be able to find us. However, we often overlook the fact that our products are made up of millions of ones and zeros that live on a physical server in a physical location. Anyone who wants to access your data, needs to move a copy of those ones and zeros from your physical server to their physical device.\n\nIn order for a device to access the Internet, it needs an IP address. An IP address is a numeric identifier that allows a device to be accessible to other devices on the Internet. When a customer visits your URL, or launches your web-connected app, they are requesting information from your server's IP address through their router. Your IP address helps their router determine where it needs to go to collect the requested information using both static and dynamic routing protocols.\n\n### Networks\n\nA server that hosts a website or product rarely exists in isolation. Instead, servers will typically will be part of a broader network. Simply put, a **network** is any number of devices that are interconnected and can share information. A router acts as a virtual connectivity hub so that devices on a network can communicate without being directly connected. Large networks will often include servers that act as central repositories of information and other servers that distribute that information.\n\n### Peering\n\nThe Internet can be thought of as a network of networks. Just as two computers on the same network can exchange information, two networks can also be connected to share data. This relationship is called **peering**. When two networks establish a peering relationship, it allows devices across both networks to freely communicate by sharing common routes. This helps to eliminate the need for further connectivity costs. When this relationship is established across a shared peering fabric, such as LINX or AMS-IX, and for no financial consideration, this is known as **settlement-free interconnection** (SFI).\n\n### Processing a Request\n\nWhen a network router receives a request, it references its routing table to determine the shortest path to the information. It first looks on its own network to determine if it hosts the target information. If it isn't the host, it will attempt to connect to another router to search the \"full routing table\" using information sourced from the Border Gateway Protocol (BGP). This allows the router to determine the best route – either through a direct peering relationship or access to a larger Tier 1 Network ([see below][1]). If no such connection exists, the router will have at minimum a \"default route\" which provides a pathway of last resort if a local route cannot be found. After a suitable route has been determined, the request is forwarded to the next router in the path towards its destination.\n\n## IP Transit Defined\n\nWhen you want to send or receive information across the Internet, you need to pass through, or \"transit\", one or more third-party networks in order to reach your final destination. **IP Transit** is a service where an Internet Service Provider (ISP) allows traffic to travel through their network to its final destination. Regardless of how your business or product accesses the Internet, you will need to utilize IP transit in some capacity.\n\n### Tiers of IP Transit Providers\n\nIP Transit providers are broken up into three tiers:\n\nTier 1 providers have an expansive global reach. These providers peer with each other and act as the global conduit to all networks – thus forming the \"backbone\" of the Internet. There are roughly six total Tier 1 networks that connect the globe. These networks have one-hop latency to one another by design, and subsequently to the smaller networks underneath them. Tier 1 providers freely peer with each other, but charge lower tiers a fee in order to access their network. The combined reach of these Tier 1 providers allows for expansive routing tables that can route requests to _anywhere_ on the Internet. Examples of these providers include AT\u0026T, Century Link (Qwest), and Level3.\n\nTier 2 providers have large networks with multiple physical locations and data centers. These ISPs will typically peer freely with each other in order to expand the breadth of their content delivery capability and to avoid the usage costs of accessing a Tier 1 network. Examples of Tier 2 ISPs include Amazon, Netflix, and [Genesis Adaptive][2].\n\nTier 3 providers are generally local providers with smaller client lists. They will typically purchase a smaller portion of IP Transit through a Tier 2 provider to avoid the higher costs of going directly to a Tier 1 ISP.\n\n### Which IP Transit Tier is Best?\n\nAs a rule, the more stops a request needs to make in its journey from client to server, the more latency and throttling will become an issue. Each \"hop\" to another location requires processing time to achieve the desired routing. Often larger networks will provide fewer hops to fulfill the same request.\n\nHowever, just because an ISP is a higher tier, doesn't necessarily mean that they will provide the most direct route. Tier 1 ISPs have an expansive reach, but their size often causes inefficiency in the number of hops needed to fulfill a request. Often, a Tier 2 provider can provide a more direct path to a desired destination, or better route stability, because of their direct peering relationships and more concentrated network footprint.\n\n## Summary\n\nIP Transit provides the connectivity needed to fuel the Internet. Within each tier of IP Transit, there are varying quality levels that depend on how well your ISP is connected. As a Tier 2 provider, Genesis Adaptive ensures that your data is readily accessible with the lowest latency available on the globe. Our peering network consists of over 40 partners including Facebook, Netflix, and Amazon, among others. These peers, combined with our internal network and Tier 1 provider relationships, ensure you the shortest transit route available.\n\nIt is imperative that your IP Transit provider has robust offerings and reliable support that is able to scale with your company's growth. \n\n[1]: #tiers-of-ip-transit-providers\n[2]: https://www.genesisadaptive.com/ip-transit\n","tags":"#network"},{"id":"9537a46eea1b731dfa331f850ff8b8b0","title":"Valid URL Paths ","content":"A [path segment](http://tools.ietf.org/html/rfc3986#section-3.3) (the parts in a path separated by `/`) in an absolute URI path can contain zero or more of _pchar_ that is defined as follows:\n\n```\npchar       = unreserved / pct-encoded / sub-delims / \":\" / \"@\"\nunreserved  = ALPHA / DIGIT / \"-\" / \".\" / \"_\" / \"~\"\npct-encoded = \"%\" HEXDIG HEXDIG\nsub-delims  = \"!\" / \"$\" / \"\u0026\" / \"'\" / \"(\" / \")\" / \"*\" / \"+\" / \",\" / \";\" / \"=\"\n```\n\nSo it’s basically `A–Z`, `a–z`, `0–9`, `-`, `.`, `_`, `~`, `!`, `$`, `\u0026`, `'`, `(`, `)`, `*`, `+`, `,`, `;`, `=`, `:`, `@`, as well as `%` which must be followed by two hexadecimal digits (`0-9` and `A-F`). Any other character/byte needs to be encoded using the percent-encoding.\n","tags":"#http #rfc"},{"id":"fb0f263c624280eb3bca291ee8f0ed6b","title":"Simple Log Example with Configuration Overrides ","content":"package main\n\nimport (\n\t\"fmt\"\n\t\"log\"\n\t\"os\"\n)\n\ntype LogOption func(*Log)\n\ntype Log struct {\n\tlogger *log.Logger\n\trate   int\n}\n\nfunc NewLog(logger *log.Logger, opts ...LogOption) *Log {\n\tl := \u0026Log{\n\t\tlogger: logger,\n\t\trate:   100,\n\t}\n\n\tfor _, opt := range opts {\n\t\topt(l)\n\t}\n\n\treturn l\n}\n\nfunc ModifyLoggerConfiguration(l *Log) {\n\tl.rate = 20\n}\n\nfunc main() {\n\tlogger := log.New(os.Stdout, \"SOME_PREFIX: \", log.Ldate|log.Ltime|log.Lshortfile)\n\tl := NewLog(logger)\n\n\tfmt.Printf(\"l = %+v\\n\\n\", l)\n\n\tl.logger.Print(\"foo\") // SOME_PREFIX: 2009/11/10 23:00:00 prog.go:33: foo\n\tl.logger.Print(\"bar\") // SOME_PREFIX: 2009/11/10 23:00:00 prog.go:34: bar\n\tl.logger.Print(\"baz\") // SOME_PREFIX: 2009/11/10 23:00:00 prog.go:35: baz\n\n\tl2 := NewLog(logger, ModifyLoggerConfiguration)\n\n\tfmt.Printf(\"\\nl = %+v\\n\\n\", l2)\n}\n","tags":"#go #logs"},{"id":"0bfa1c1ab84ef06a657cd6aa6b2ce25e","title":"Embed empty interface{} into explicit struct and then reflect the containing struct ","content":"package main\n\nimport (\n\t\"fmt\"\n\t\"os\"\n\t\"reflect\"\n)\n\ntype random struct {\n\tFoo int    `json_env:\"FOO\"`\n\tBar string `json_env:\"BAR\"`\n\tBaz bool   `json_env:\"BAZ\"`\n}\n\ntype defaults struct {\n\tRandom interface{}\n\tBeep   string `json_env:\"BEEP\"`\n\tBoop   string `json_env:\"BOOP\"`\n}\n\nfunc inspect(i interface{}) {\n\tfmt.Printf(\"inspect func:\\n%+v\\n\\n\", i)\n\n\tv := reflect.ValueOf(i)\n\ts := v.Elem()\n\tt := s.Type()\n\n\tfmt.Printf(\"v:\\n%+v\\n\\n\", v)\n\tfmt.Printf(\"s:\\n%+v\\n\\n\", s)\n\tfmt.Printf(\"t:\\n%+v\\n\\n\", t)\n\n\tfmt.Printf(\"number of top level fields:\\n%+v\\n\\n\", s.NumField())\n\n\tfor i := 0; i \u003c s.NumField(); i++ {\n\t\tsf := s.Field(i)\n\t\ttf := t.Field(i)\n\n\t\tfmt.Printf(\"sf:\\n%+v\\n\\n\", sf)\n\t\tfmt.Printf(\"tf:\\n%+v\\n\\n\", tf)\n\n\t\tif tf.Name == \"Random\" \u0026\u0026 tf.Type.Kind() == reflect.Interface {\n\t\t\tfmt.Printf(\"we got a random interface: %+v\\n\\n\", tf.Type.Kind())\n\n\t\t\tv := reflect.ValueOf(sf)\n\t\t\t\n\t\t\t/*\n\t\t\tI GET HERE AND THEN I GET STUCK 😬\n\t\t\t*/\n\n\t\t\t// create new pointer\n\t\t\tptr := reflect.New(reflect.TypeOf(i))\n\n\t\t\t// create variable to value of pointer\n\t\t\ts := ptr.Elem()\n\n\t\t\t//s := v.Elem()\n\t\t\t//t := s.Type()\n\n\t\t\tfmt.Printf(\"nested v:\\n%+v\\n\\n\", v)\n\t\t\tfmt.Printf(\"nested s:\\n%+v\\n\\n\", s)\n\t\t\t//fmt.Printf(\"nested t:\\n%+v\\n\\n\", t)\n\t\t}\n\n\t\tenvName := tf.Tag.Get(\"json_env\")\n\t\tif len(envName) == 0 {\n\t\t\tfmt.Println(\"skipping!\")\n\t\t\tcontinue\n\t\t}\n\n\t\tval := []byte(os.Getenv(envName))\n\n\t\tfmt.Printf(\"\\nenvName:\\n%+v\\n\", val)\n\n\t\tfptr := sf.Addr().Interface()\n\n\t\tfmt.Printf(\"fptr:\\n%+v\\n\", fptr)\n\t}\n}\n\nfunc accept(r interface{}) {\n\td := defaults{Random: r, Beep: \"X\", Boop: \"Y\"}\n\n\tvar i interface{}\n\ti = \u0026defaults{Random: r, Beep: \"X\", Boop: \"Y\"}\n\n\tfmt.Printf(\"random user struct:\\n%+v\\n\\ndefault struct with user struct embedded:\\n%+v\\n\\ni:\\n%+v\\n\\n\", r, d, i)\n\n\tinspect(i)\n}\n\nfunc main() {\n\tos.Setenv(\"BEEP\", \"1\")\n\tos.Setenv(\"BOOP\", \"2\")\n\tos.Setenv(\"FOO\", \"3\")\n\tos.Setenv(\"BAR\", \"4\")\n\tos.Setenv(\"BAZ\", \"5\")\n\n\tr := \u0026random{}\n\taccept(r)\n\n}\n\n","tags":"#go"},{"id":"1048649a5c00fae8d7f9841d07c728db","title":"Compile Curl ","content":"FROM python:3.8-slim\n\n# libbrotli from debian apt, and build tools\nRUN apt-get update \u0026\u0026 apt-get install -y git build-essential autoconf automake libtool brotli libbrotli-dev zlib1g-dev pkg-config cmake golang\n\n# nghttp2 dev libraries - curl http2 support\nRUN git clone https://github.com/tatsuhiro-t/nghttp2.git /tmp/nghttp2\nWORKDIR /tmp/nghttp2\nRUN autoreconf -i \u0026\u0026 automake \u0026\u0026 autoconf\nRUN ./configure\nRUN make\nRUN make install\n\n# rust (incl cargo), to install quiche\n# the irony of the next command is not lost on me\nRUN apt-get install -y curl \n# installs cargo to /root/.cargo/bin/cargo (for lack of an env)\nRUN curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh -s -- -y\n# remove our trojan horse version\nRUN apt-get remove -y curl\n\n# cloudflare quiche dev libraries with pkg-config for cURL build - http3 support\nRUN git clone https://github.com/cloudflare/quiche --recursive /tmp/quiche\n\n# compile boringssl with SSL headers for cURL to use (--with-ssl)\nWORKDIR /tmp/quiche/deps/boringssl\nRUN mkdir build\nWORKDIR /tmp/quiche/deps/boringssl/build\nRUN cmake -DCMAKE_POSITION_INDEPENDENT_CODE=on ..\nRUN make\nWORKDIR /tmp/quiche/deps/boringssl\nRUN mkdir -p .openssl/lib\nRUN cp build/crypto/libcrypto.a build/ssl/libssl.a .openssl/lib\nRUN ln -s $PWD/include .openssl\n\n# compile quiche\nWORKDIR /tmp/quiche/\nRUN QUICHE_BSSL_PATH=$PWD/deps/boringssl /root/.cargo/bin/cargo build --release --features pkg-config-meta\nRUN cp /tmp/quiche/target/release/libquiche.so /usr/lib\n\n# finally, build cURL. are you excited? I am.\nRUN git clone https://github.com/curl/curl /tmp/curl\nWORKDIR /tmp/curl\nRUN ./buildconf\nRUN ./configure LDFLAGS=\"-Wl,-rpath,/tmp/quiche/target/release\" --prefix=/usr --with-ssl=/tmp/quiche/deps/boringssl/.openssl --libdir=/usr/lib/x86_64-linux-gnu --with-brotli --with-zlib --with-nghttp2 --with-quiche=/tmp/quiche/target/release --enable-alt-svc\n\n# Expected: \n  # Host setup:       x86_64-pc-linux-gnu\n  # Install prefix:   /usr\n  # Compiler:         gcc\n  #  CFLAGS:          -Werror-implicit-function-declaration -O2 -Wno-system-headers -pthread\n  #  CPPFLAGS:        -isystem /tmp/quiche/deps/boringssl/.openssl/include -isystem /tmp/quiche/deps/boringssl/.openssl/include/openssl -isystem /usr/local/include -isystem /tmp/quiche/include\n  #  LDFLAGS:         -Wl,-rpath,/tmp/quiche/target/release -L/tmp/quiche/deps/boringssl/.openssl/lib -L/usr/local/lib -L/tmp/quiche/target/release\n  #  LIBS:            -lquiche -lnghttp2 -lssl -lbrotlidec -lbrotlidec -lz -lcrypto -ldl -lpthread\n\n  # curl version:     7.71.0-DEV\n  # SSL:              enabled (BoringSSL)\n  # SSH:              no      (--with-{libssh,libssh2})\n  # zlib:             enabled\n  # brotli:           enabled (libbrotlidec)\n  # GSS-API:          no      (--with-gssapi)\n  # TLS-SRP:          no      (--enable-tls-srp)\n  # resolver:         POSIX threaded\n  # IPv6:             enabled\n  # Unix sockets:     enabled\n  # IDN:              no      (--with-{libidn2,winidn})\n  # Build libcurl:    Shared=yes, Static=yes\n  # Built-in manual:  no      (--enable-manual)\n  # --libcurl option: enabled (--disable-libcurl-option)\n  # Verbose errors:   enabled (--disable-verbose)\n  # Code coverage:    disabled\n  # SSPI:             no      (--enable-sspi)\n  # ca cert bundle:   /etc/ssl/certs/ca-certificates.crt\n  # ca cert path:     no\n  # ca fallback:      no\n  # LDAP:             no      (--enable-ldap / --with-ldap-lib / --with-lber-lib)\n  # LDAPS:            no      (--enable-ldaps)\n  # RTSP:             enabled\n  # RTMP:             no      (--with-librtmp)\n  # Metalink:         no      (--with-libmetalink)\n  # PSL:              no      (libpsl not found)\n  # Alt-svc:          enabled\n  # HTTP2:            enabled (nghttp2)\n  # HTTP3:            enabled (quiche)\n  # ESNI:             no      (--enable-esni)\n  # Protocols:        DICT FILE FTP FTPS GOPHER HTTP HTTPS IMAP IMAPS POP3 POP3S RTSP SMB SMBS SMTP SMTPS TELNET TFTP\n  # Features:         SSL IPv6 UnixSockets libz brotli AsynchDNS alt-svc NTLM NTLM_WB HTTP2 HTTP3 HTTPS-proxy\n\n  # WARNING:  HTTP3 alt-svc enabled but marked EXPERIMENTAL. Use with caution!\n\nRUN make\nRUN make install\n\n# clean up after ourselves\nRUN rm -rf /tmp/curl /tmp/quiche /tmp/nghttp2\nRUN apt-get remove -y git build-essential autoconf automake libtool zlib1g-dev pkg-config cmake golang\nRUN apt-get autoremove -y\n\n# try our shiny new cURL out\n# brotli\nCMD [\"curl\", \"--compressed\", \"https://httpbin.org/brotli\"]\nCheck OS:\n\n```bash\n$ uname -a\nLinux bcf344edf35e 4.19.76-linuxkit #1 SMP Fri Apr 3 15:53:26 UTC 2020 x86_64 GNU/Linux\n\n$ cat /etc/os-release\nPRETTY_NAME=\"Debian GNU/Linux 10 (buster)\"\nNAME=\"Debian GNU/Linux\"\nVERSION_ID=\"10\"\nVERSION=\"10 (buster)\"\nVERSION_CODENAME=buster\nID=debian\nHOME_URL=\"https://www.debian.org/\"\nSUPPORT_URL=\"https://www.debian.org/support\"\nBUG_REPORT_URL=\"https://bugs.debian.org/\"\n```\n\nGet curl source code and compile it:\n\n```bash\n$ apt-get update \u0026\u0026 apt-get install -y git build-essential autoconf automake libtool brotli libbrotli-dev\n\n$ git clone https://github.com/curl/curl /tmp/curl\n$ cd /tmp/curl/\n$ ./buildconf\n$ ./configure \n$ make\n$ make install\n```\n\nCheck curl information:\n\n```bash\n$ which curl\n/usr/local/bin/curl\n\n$ ldd $(which curl)\nconfigure: Configured to build curl/libcurl:\n\n  Host setup:       x86_64-pc-linux-gnu\n  Install prefix:   /usr/local\n  Compiler:         gcc\n   CFLAGS:          -Werror-implicit-function-declaration -O2 -Wno-system-headers -pthread\n   CPPFLAGS:\n   LDFLAGS:\n   LIBS:            -lidn2 -lssl -lcrypto -lbrotlidec -lz\n\n  curl version:     7.71.0-DEV\n  SSL:              enabled (OpenSSL)\n  SSH:              no      (--with-{libssh,libssh2})\n  zlib:             enabled\n  brotli:           enabled (libbrotlidec)\n  GSS-API:          no      (--with-gssapi)\n  TLS-SRP:          enabled\n  resolver:         POSIX threaded\n  IPv6:             enabled\n  Unix sockets:     enabled\n  IDN:              enabled (libidn2)\n  Build libcurl:    Shared=yes, Static=yes\n  Built-in manual:  no      (--enable-manual)\n  --libcurl option: enabled (--disable-libcurl-option)\n  Verbose errors:   enabled (--disable-verbose)\n  Code coverage:    disabled\n  SSPI:             no      (--enable-sspi)\n  ca cert bundle:   /etc/ssl/certs/ca-certificates.crt\n  ca cert path:     no\n  ca fallback:      no\n  LDAP:             no      (--enable-ldap / --with-ldap-lib / --with-lber-lib)\n  LDAPS:            no      (--enable-ldaps)\n  RTSP:             enabled\n  RTMP:             no      (--with-librtmp)\n  Metalink:         no      (--with-libmetalink)\n  PSL:              no      (libpsl not found)\n  Alt-svc:          no      (--enable-alt-svc)\n  HTTP2:            disabled (--with-nghttp2)\n  HTTP3:            disabled (--with-ngtcp2, --with-quiche)\n  ESNI:             no      (--enable-esni)\n  Protocols:        DICT FILE FTP FTPS GOPHER HTTP HTTPS IMAP IMAPS POP3 POP3S RTSP SMB SMBS SMTP SMTPS TELNET TFTP\n  Features:         SSL IPv6 UnixSockets libz brotli AsynchDNS IDN NTLM NTLM_WB TLS-SRP HTTPS-proxy\n```\n\nUse curl:\n\n```bash\n$ curl --version\n$ curl --compressed https://httpbin.org/brotli\n```\n\n\u003e `./configure --help` provides list of all flag options.\n","tags":"#shell"},{"id":"2ecc27597cc609fcb7e4c13c8b9a1dae","title":"Fuzz Testing","content":"# https://github.com/ffuf/ffuf\n#\n# FUZZ is replaced with symbol in fuzz.txt\nffuf -t 40 -r -w ./fuzz.txt -u \"https://example.com/FUZZ\" -maxtime 60 -v -c\n!.gitignore\n!.htaccess\n!.htpasswd\n%20../\n%2e%2e//google.com\n%2e%2e;/test\n%3f/\n%C0%AE%C0%AE%C0%AF\n%ff/\n+CSCOU+/../+CSCOE+/files/file_list.json\n..;/\n.7z\n.access\n.addressbook\n.adm\n.admin\n.apdisk\n.AppleDB\n.AppleDesktop\n.AppleDouble\n.apt_generated/\n.architect\n.aws/credentials\n.axoCover/\n.babelrc\n.bak\n.bash_history\n.bash_logout\n.bash_profile\n.bashrc\n.bower-cache\n.bower-registry\n.bower-tmp\n.bower.json\n.build/\n.buildpacks\n.buildpath\n.buildpath/\n.builds\n.bundle\n.bundle/\n.byebug_history\n.bz2\n.bzr/\n.bzr/README\n.c9/\n.c9revisions/\n.cabal-sandbox/\n.cache\n.cache/\n.capistrano\n.capistrano/\n.capistrano/metrics\n.capistrano/metrics/\n.cask\n.cc-ban.txt\n.cc-ban.txt.bak\n.cfg\n.cfignore\n.checkstyle\n.circleci/config.yml\n.classpath\n.cobalt\n.codeclimate.yml\n.codeintel\n.codekit-cache\n.codio\n.coffee_history\n.compile\n.composer\n.concrete/DEV_MODE\n.conf\n.config\n.config.php.swp\n.config/\n.config/filezilla/sitemanager.xml.xml\n.config/psi+/profiles/default/accounts.xml\n.configuration.php.swp\n.consulo/\n.contracts\n.coq-native/\n.core\n.coverage\n.cpan\n.cpanel/\n.cpcache/\n.cproject\n.cr/\n.csdp.cache\n.cshrc\n.CSV\n.csv\n.CVS\n.cvs\n.cvsignore\n.dart_tool/\n.dat\n.deployignore\n.dev/\n.directory\n.dockerignore\n.drone.yml\n.DS_Store\n.dub\n.dump\n.eclipse\n.editorconfig\n.eggs/\n.elasticbeanstalk/\n.elb\n.elc\n.emacs.desktop\n.emacs.desktop.lock\n.empty-folder\n.env\n.env.dev\n.env.development.sample\n.env.docker.dev\n.env.php\n.env.prod\n.env.sample.php\n.env.test.sample\n.environment\n.error_log\n.eslintcache\n.eslintignore\n.eslintrc\n.espressostorage\n.eunit\n.external/\n.external/data\n.externalNativeBuild\n.externalToolBuilders/\n.fake/\n.FBCIndex\n.fetch\n.fhp\n.filemgr-tmp\n.filezilla/\n.filezilla/sitemanager.xml.xml\n.fishsrv.pl\n.flac\n.flowconfig\n.fontconfig/\n.fontcustom-manifest.json\n.forward\n.ftp-access\n.ftppass\n.ftpquota\n.gem\n.gfclient/\n.gfclient/pass\n.git\n.git-credentials\n.git-rewrite/\n.git/\n.git/config\n.git/HEAD\n.git/index\n.git/logs/\n.git/logs/HEAD\n.git/logs/refs\n.git2/\n.git_release\n.gitattributes\n.gitconfig\n.gitignore\n.gitignore.swp\n.gitignore_global\n.gitignore~\n.gitk\n.gitkeep\n.gitlab\n.gitlab-ci.yml\n.gitlab/issue_templates\n.gitlab/merge_request_templates\n.gitlab/route-map.yml\n.gitmodules\n.gitreview\n.gradle\n.gradle/\n.gradletasknamecache\n.grunt\n.grunt/\n.guile_history\n.gwt-tmp/\n.gwt/\n.gz\n.hash\n.hg\n.hg/\n.hg/dirstate\n.hg/requires\n.hg/store/data/\n.hg/store/undo\n.hg/undo.dirstate\n.hgignore\n.hgignore.global\n.hgrc\n.histfile\n.history\n.hpc\n.hsenv\n.ht_wsr.txt\n.hta\n.htaccess\n.htaccess-dev\n.htaccess-local\n.htaccess-marco\n.htaccess.BAK\n.htaccess.bak\n.htaccess.bak1\n.htaccess.old\n.htaccess.orig\n.htaccess.sample\n.htaccess.save\n.htaccess.txt\n.htaccess_extra\n.htaccess_orig\n.htaccess_sc\n.htaccessBAK\n.htaccessOLD\n.htaccessOLD2\n.htaccess~\n.HTF/\n.htgroup\n.htpasswd\n.htpasswd-old\n.htpasswd_test\n.htpasswds\n.httr-oauth\n.htusers\n.hypothesis/\n.idea\n.idea/\n.idea/.name\n.idea/caches\n.idea/compiler.xml\n.idea/copyright/profiles_settings.xml\n.idea/dataSources.ids\n.idea/dataSources.local.xml\n.idea/dataSources.xml\n.idea/deployment.xml\n.idea/dictionaries\n.idea/drush_stats.iml\n.idea/encodings.xml\n.idea/gradle.xml\n.idea/libraries\n.idea/misc.xml\n.idea/modules.xml\n.idea/scopes/scope_settings.xml\n.idea/Sites.iml\n.idea/sqlDataSources.xml\n.idea/tasks.xml\n.idea/uiDesigner.xml\n.idea/vcs.xml\n.idea/woaWordpress.iml\n.idea/workspace(2).xml\n.idea/workspace(3).xml\n.idea/workspace(4).xml\n.idea/workspace(5).xml\n.idea/workspace(6).xml\n.idea/workspace(7).xml\n.idea/workspace.xml\n.idea0/\n.idea_modules/\n.ignore\n.ignored/\n.import/\n.influx_history\n.ini\n.inst/\n.install/\n.install/composer.phar\n.installed.cfg\n.ipynb_checkpoints\n.jekyll-cache/\n.jekyll-metadata\n.joe_state\n.jscsrc\n.jshintignore\n.jshintrc\n.JustCode\n.keep\n.kitchen.local.yml\n.kitchen.yml\n.kitchen/\n.komodotools\n.komodotools/\n.ksh_history\n.last_cover_stats\n.lein-deps-sum\n.lein-failures\n.lein-plugins/\n.lein-repl-history\n.lesshst\n.lia.cache\n.libs/\n.lighttpd.conf\n.listing\n.listings\n.loadpath\n.LOCAL\n.local\n.localcache/\n.localeapp/\n.localsettings.php.swp\n.lock-wscript\n.log\n.log.txt\n.login\n.login_conf\n.LSOverride\n.lynx_cookies\n.magentointel-cache/\n.mail_aliases\n.mailrc\n.maintenance\n.maintenance2\n.mc\n.mc/\n.memdump\n.mergesources.yml\n.merlin\n.meta\n.metadata\n.metadata/\n.metrics\n.modgit/\n.modman\n.modman/\n.modules\n.mono/\n.mr.developer.cfg\n.msi\n.mtj.tmp/\n.mvn/timing.properties\n.mweval_history\n.mwsql_history\n.mypy_cache/\n.mysql_history\n.nano_history\n.navigation/\n.nbproject/\n.netrc\n.netrwhist\n.next\n.nia.cache\n.nlia.cache\n.node_repl_history\n.nodelete\n.npm\n.npmignore\n.npmrc\n.nra.cache\n.nrepl-port\n.nsconfig\n.ntvs_analysis.dat\n.nuget/\n.nuget/packages.config\n.nyc_output\n.old\n.oldsnippets\n.oldstatic\n.org-id-locations\n.ost\n.packages\n.paket/\n.passwd\n.patches/\n.pdf\n.perf\n.pgadmin3\n.pgpass\n.pgsql_history\n.php-ini\n.php-version\n.php_history\n.phpintel\n.phpstorm.meta.php\n.phptidy-cache\n.phpversion\n.pki\n.placeholder\n.powenv\n.procmailrc\n.profile\n.project\n.project.xml\n.project/\n.projectOptions\n.properties\n.psci\n.psci_modules\n.psql_history\n.psqlrc\n.pst\n.pub/\n.pydevproject\n.pytest_cache/\n.Python\n.python-eggs\n.python-history\n.python-version\n.qmake.cache\n.qmake.stash\n.qqestore/\n.Rapp.history\n.rar\n.raw\n.rbtp\n.RData\n.rdsTempFiles\n.rebar\n.rediscli_history\n.reek\n.remote-sync.json\n.repl_history\n.revision\n.Rhistory\n.rhosts\n.robots.txt\n.rocketeer/\n.ropeproject\n.Rproj.user/\n.rspec\n.rsync-filter\n.rsync_cache\n.rsync_cache/\n.rubocop.yml\n.rubocop_todo.yml\n.ruby-gemset\n.ruby-version\n.rvmrc\n.s3backupstatus\n.sass-cache/\n.scala_history\n.sconsign.dblite\n.scrapy\n.scrutinizer.yml\n.selected_editor\n.settings\n.settings.php.swp\n.settings/\n.settings/.jsdtscope\n.settings/org.eclipse.core.resources.prefs\n.settings/org.eclipse.php.core.prefs\n.settings/org.eclipse.wst.common.project.facet.core.xml\n.settings/org.eclipse.wst.jsdt.ui.superType.container\n.settings/org.eclipse.wst.jsdt.ui.superType.name\n.sh\n.sh_history\n.shrc\n.sln\n.smushit-status\n.spamassassin\n.spyderproject\n.spyproject\n.sql\n.sql.bz2\n.sql.gz\n.sqlite_history\n.src/app.js\n.src/index.js\n.src/server.js\n.ssh\n.ssh.asp\n.ssh.php\n.ssh/\n.ssh/authorized_keys\n.ssh/id_dsa\n.ssh/id_rsa\n.ssh/id_rsa.key\n.ssh/id_rsa.key~\n.ssh/id_rsa.priv\n.ssh/id_rsa.priv~\n.ssh/id_rsa.pub\n.ssh/id_rsa.pub~\n.ssh/id_rsa~\n.ssh/know_hosts\n.ssh/know_hosts~\n.ssh/known_host\n.ssh/known_hosts\n.st_cache/\n.stack-work/\n.stylelintrc\n.sublime-gulp.cache\n.sublime-project\n.sublime-workspace\n.subversion\n.sucuriquarantine/\n.sunw\n.svn\n.svn/\n.svn/all-wcprops\n.svn/entries\n.svn/text-base/\n.svn/text-base/index.php.svn-base\n.svnignore\n.sw\n.swf\n.swo\n.swp\n.SyncID\n.SyncIgnore\n.synthquota\n.system/\n.tags\n.tar\n.tar.bz2\n.tar.gz\n.tconn/\n.tconn/tconn.conf\n.temp\n.temp/\n.texpadtmp\n.tfignore\n.tgitconfig\n.thumbs\n.tmp\n.tmp_versions/\n.tmproj\n.tox\n.tox/\n.transients_purge.log\n.Trash\n.Trashes\n.travis.yml\n.tx/\n.user.ini\n.vacation.cache\n.vagrant\n.venv\n.version\n.vgextensions/\n.viminfo\n.vimrc\n.vs/\n.web\n.web-server-pid\n.webassets-cache\n.workspace/\n.wp-config.php.swp\n.www_acl\n.wwwacl\n.yardoc/\n.yarn-integrity\n.yo-rc.json\n.zeus.sock\n.zfs/\n.zip\n.zsh_history\n/app/__pycache__/\n/apps/__pycache__/\n0.htpasswd\n0.php\n0admin/\n0manager/\n1.htaccess\n1.htpasswd\n1.php\n1.sql\n1.tar.gz\n1.txt\n1.zip\n123.php\n123.txt\n1c/\n2.php\n2.sql\n2.txt\n2010.sql\n2010.tar\n2010.tar.gz\n2010.tgz\n2010.zip\n2011.sql\n2011.tar\n2011.tar.gz\n2011.tgz\n2011.zip\n2012.sql\n2012.tar\n2012.tar.gz\n2012.tgz\n2012.zip\n2013.sql\n2013.tar\n2013.tar.gz\n2013.tgz\n2013.zip\n2014.sql\n2014.tar\n2014.tar.gz\n2014.tgz\n2014.zip\n2015.sql\n2015.tar\n2015.tar.gz\n2015.tgz\n2015.zip\n2016.sql\n2016.tar\n2016.tar.gz\n2016.tgz\n2016.zip\n2017.sql\n2017.tar\n2017.tar.gz\n2017.tgz\n2017.zip\n2018.sql\n2018.tar\n2018.tar.gz\n2018.tgz\n2018.zip\n2phpmyadmin/\n3.php\n4.php\n5.php\n6.php\n7.php\n7788.php\n8.php\n8899.php\n9.php\n9678.php\n\\..\\..\\..\\..\\..\\..\\..\\..\\..\\etc\\passwd\n_.htpasswd\n__cache/\n__dummy.html\n__history/\n__index.php\n__init__.py\n__MACOSX\n__pma___\n__pycache__/\n__recovery/\n__SQL\n__test.php\n_adm\n_admin\n_book\n_build\n_build/\n_cache/\n_common.xsl\n_config.inc\n_data/\n_data/error_log\n_Dockerfile\n_errors\n_eumm/\n_files\n_h5ai/\n_include\n_index.php\n_install\n_layouts\n_layouts/\n_layouts/alllibs.htm\n_layouts/settings.htm\n_layouts/userinfo.htm\n_log/\n_log/access-log\n_log/access.log\n_log/access_log\n_log/error-log\n_log/error.log\n_log/error_log\n_logs\n_logs/\n_logs/access-log\n_logs/access.log\n_logs/access_log\n_logs/err.log\n_logs/error-log\n_logs/error.log\n_logs/error_log\n_LPHPMYADMIN/\n_mmServerScripts/\n_mmServerScripts/MMHTTPDB.asp\n_mmServerScripts/MMHTTPDB.php\n_notes/\n_notes/dwsync.xml\n_novo/\n_novo/composer.lock\n_old\n_pages\n_phpmyadmin/\n_pkginfo.txt\n_private\n_Pvt_Extensions\n_site/\n_source\n_SQL\n_sqladm\n_src\n_TeamCity\n_test\n_thumbs/\n_tracks\n_UpgradeReport_Files/\n_vti_bin/\n_vti_bin/_vti_adm/admin.dll\n_vti_bin/_vti_aut/author.dll\n_vti_bin/shtml.dll\n_vti_pvt/\n_vti_pvt/service.pwt\n_vti_pvt/users.pwt\n_WEB_INF/\n_wpeprivate\n_wpeprivate/\n_wpeprivate/config.json\n_www\n_yardoc/\na%5c.aspx\na.out\naadmin/\nacceptance_config.yml\nacceso\nacceso.php\naccess\naccess-log\naccess-log.1\naccess.1\naccess.log\naccess.php\naccess/\naccess_.log\naccess_log\naccess_log.1\naccesslog\naccount.html\naccount.php\naccounts\naccounts.php\naccounts.txt\naccounts.xml\naccounts/\nacct_login/\nactivity.log\nad_login\nad_manage\nadd.php\nadd_admin\nadm\nadm.html\nadm.php\nadm/\nadm/admloginuser.php\nadm/index.html\nadm/index.php\nadm_auth\nadm_auth.php\nadmin\nadmin%20/\nadmin-console\nadmin-console/\nadmin-database\nadmin-database.php\nadmin-database/\nadmin-dev/\nadmin-dev/autoupgrade/\nadmin-dev/backups/\nadmin-dev/export/\nadmin-dev/import/\nadmin-login\nadmin-login.html\nadmin-login.php\nadmin-serv/\nadmin-serv/config/admpw\nadmin.asp\nadmin.aspx\nadmin.cfm\nadmin.cgi\nadmin.conf\nadmin.conf.default\nadmin.dat\nadmin.do\nadmin.htm\nadmin.htm.php\nadmin.html\nadmin.html.php\nadmin.jsp\nadmin.mdb\nadmin.passwd\nadmin.php\nadmin.php3\nadmin.pl\nadmin/\nadmin/.config\nadmin/.htaccess\nadmin/_logs/access-log\nadmin/_logs/access.log\nadmin/_logs/access_log\nadmin/_logs/err.log\nadmin/_logs/error-log\nadmin/_logs/error.log\nadmin/_logs/error_log\nadmin/_logs/login.txt\nadmin/access.log\nadmin/access.txt\nadmin/access_log\nadmin/account\nadmin/account.html\nadmin/account.php\nadmin/admin\nadmin/admin-login\nadmin/admin-login.html\nadmin/admin-login.php\nadmin/admin.html\nadmin/admin.php\nadmin/admin_login\nadmin/admin_login.html\nadmin/admin_login.php\nadmin/adminLogin\nadmin/adminLogin.htm\nadmin/adminLogin.html\nadmin/adminLogin.php\nadmin/backup/\nadmin/backups/\nadmin/config.php\nadmin/controlpanel\nadmin/controlpanel.htm\nadmin/controlpanel.html\nadmin/controlpanel.php\nadmin/cp\nadmin/cp.html\nadmin/cp.php\nadmin/db/\nadmin/default\nadmin/default.asp\nadmin/default/admin.asp\nadmin/default/login.asp\nadmin/download.php\nadmin/dumper/\nadmin/error.log\nadmin/error.txt\nadmin/error_log\nadmin/export.php\nadmin/FCKeditor\nadmin/fckeditor/editor/filemanager/browser/default/connectors/asp/connector.asp\nadmin/fckeditor/editor/filemanager/browser/default/connectors/aspx/connector.aspx\nadmin/fckeditor/editor/filemanager/browser/default/connectors/php/connector.php\nadmin/fckeditor/editor/filemanager/connectors/asp/connector.asp\nadmin/fckeditor/editor/filemanager/connectors/asp/upload.asp\nadmin/fckeditor/editor/filemanager/connectors/aspx/connector.aspx\nadmin/fckeditor/editor/filemanager/connectors/aspx/upload.aspx\nadmin/fckeditor/editor/filemanager/connectors/php/connector.php\nadmin/fckeditor/editor/filemanager/connectors/php/upload.php\nadmin/fckeditor/editor/filemanager/upload/asp/upload.asp\nadmin/fckeditor/editor/filemanager/upload/aspx/upload.aspx\nadmin/fckeditor/editor/filemanager/upload/php/upload.php\nadmin/file.php\nadmin/files.php\nadmin/home\nadmin/home.html\nadmin/home.php\nadmin/includes/configure.php~\nadmin/index\nadmin/index.asp\nadmin/index.html\nadmin/index.php\nadmin/js/tiny_mce/\nadmin/js/tinymce/\nadmin/log\nadmin/login\nadmin/login.asp\nadmin/login.htm\nadmin/login.html\nadmin/login.php\nadmin/logs/\nadmin/logs/access-log\nadmin/logs/access.log\nadmin/logs/access_log\nadmin/logs/err.log\nadmin/logs/error-log\nadmin/logs/error.log\nadmin/logs/error_log\nadmin/logs/login.txt\nadmin/manage\nadmin/manage.asp\nadmin/manage/admin.asp\nadmin/manage/login.asp\nadmin/mysql/\nadmin/mysql/index.php\nadmin/mysql2/index.php\nadmin/phpMyAdmin\nadmin/phpMyAdmin/\nadmin/phpmyadmin/\nadmin/phpMyAdmin/index.php\nadmin/phpmyadmin/index.php\nadmin/phpmyadmin2/index.php\nadmin/pMA/\nadmin/pma/\nadmin/PMA/index.php\nadmin/pma/index.php\nadmin/pol_log.txt\nadmin/private/logs\nadmin/sqladmin/\nadmin/sxd/\nadmin/sysadmin/\nadmin/upload.php\nadmin/uploads.php\nadmin/user_count.txt\nadmin/web/\nadmin0\nadmin1\nadmin1.htm\nadmin1.html\nadmin1.php\nadmin1/\nadmin2\nadmin2.asp\nadmin2.html\nadmin2.old/\nadmin2.php\nadmin2/\nadmin2/index.php\nadmin2/login.php\nadmin3/\nadmin4/\nadmin4_account/\nadmin4_colon/\nadmin5/\nadmin_\nadmin_/\nadmin_admin\nadmin_area\nadmin_area.php\nadmin_area/\nadmin_area/admin\nadmin_area/admin.html\nadmin_area/admin.php\nadmin_area/index.html\nadmin_area/index.php\nadmin_area/login\nadmin_area/login.html\nadmin_area/login.php\nadmin_files\nadmin_index\nadmin_index.asp\nadmin_login\nadmin_login.html\nadmin_login.php\nadmin_login/\nadmin_login/admin.asp\nadmin_login/login.asp\nadmin_logon\nadmin_logon/\nadmin_main\nadmin_pass\nadmin_tools/\nadminarea/\nadminarea/admin.html\nadminarea/admin.php\nadminarea/index.html\nadminarea/index.php\nadminarea/login.html\nadminarea/login.php\nadminconsole\nadmincontrol\nadmincontrol.html\nadmincontrol.php\nadmincontrol/\nadmincontrol/login.html\nadmincontrol/login.php\nadmincp/\nadmincp/index.asp\nadmincp/index.html\nadmincp/js/kindeditor/\nadmincp/login\nadmincp/login.asp\nadmincp/upload/\nadminedit\nadminer-4.0.3-mysql.php\nadminer-4.0.3.php\nadminer-4.1.0-mysql.php\nadminer-4.1.0.php\nadminer-4.2.0-mysql.php\nadminer-4.2.0.php\nadminer.php\nadminer/\nadminer/adminer.php\nadminer_coverage.ser\nadminis.php\nadminister/\nadministr8\nadministr8.php\nadministr8/\nadministracao.php\nadministracion.php\nadministracion/\nadministrador/\nadministrateur.php\nadministrateur/\nadministratie/\nadministration\nadministration.php\nadministration/\nadministration/Sym.php\nadministrative/\nadministrative/login_history\nadministrator\nadministrator-login/\nadministrator.html\nadministrator.php\nadministrator/\nadministrator/.htaccess\nadministrator/account\nadministrator/account.html\nadministrator/account.php\nadministrator/admin.asp\nadministrator/admin/\nadministrator/cache/\nadministrator/db/\nadministrator/includes/\nadministrator/index.html\nadministrator/index.php\nadministrator/login\nadministrator/login.asp\nadministrator/login.html\nadministrator/login.php\nadministrator/logs\nadministrator/logs/\nadministrator/phpMyAdmin/\nadministrator/phpmyadmin/\nadministrator/PMA/\nadministrator/pma/\nadministrator/web/\nadministratoraccounts/\nadministratorlogin\nadministratorlogin.php\nadministratorlogin/\nadministrators\nadministrators.php\nadministrators.pwd\nadministrators/\nadministrivia/\nadminitem\nadminitem/\nadminitems\nadminitems.php\nadminitems/\nadminlogin\nadminLogin.html\nadminLogin.php\nadminlogin.php\nadminLogin/\nadminlogon/\nadminpanel\nadminpanel.html\nadminpanel.php\nadminpanel/\nadminpro/\nadmins\nadmins.asp\nadmins.php\nadmins/\nadmins/backup/\nadmins/log.txt\nadminsite/\nAdminTools/\nadminuser\nadmloginuser.php\nadmpar/\nadmpar/.ftppass\nadmrev/\nadmrev/.ftppass\nadmrev/_files/\naffiliate\naffiliate.php\naffiliates.sql\nak47.php\nakeeba.backend.log\nall/\nall/modules/ogdi_field/plugins/dataTables/extras/TableTools/media/swf/ZeroClipboard.swf\namad.php\namministratore.php\nanalog.html\nanchor/errors.log\nanswers/\nanswers/error_log\napache/\napache/logs/access.log\napache/logs/access_log\napache/logs/error.log\napache/logs/error_log\napc-nrp.php\napc.php\napc/\napc/apc.php\napc/index.php\napi\napi.log\napi/\napi/error_log\napibuild.pyc\napp.config\napp.js\napp.php\napp/\napp/.htaccess\napp/bin\napp/bootstrap.php.cache\napp/cache/\napp/composer.json\napp/composer.lock\napp/config/adminConf.json\napp/Config/core.php\napp/Config/database.php\napp/config/database.yml\napp/config/database.yml.pgsql\napp/config/database.yml.sqlite3\napp/config/database.yml_original\napp/config/database.yml~\napp/config/databases.yml\napp/config/global.json\napp/config/parameters.ini\napp/config/parameters.yml\napp/config/routes.cfg\napp/config/schema.yml\napp/dev\napp/docs\napp/etc/config.xml\napp/etc/enterprise.xml\napp/etc/fpc.xml\napp/etc/local.additional\napp/etc/local.xml\napp/etc/local.xml.additional\napp/etc/local.xml.bak\napp/etc/local.xml.live\napp/etc/local.xml.localRemote\napp/etc/local.xml.phpunit\napp/etc/local.xml.template\napp/etc/local.xml.vmachine\napp/etc/local.xml.vmachine.rm\napp/languages\napp/log/\napp/logs/\napp/phpunit.xml\napp/src\napp/storage/\napp/sys\napp/testing\napp/tmp/\napp/unschedule.bat\napp/vendor\napp/vendor-\napp/vendor-src\napp_dev.php\nappcache.manifest\nappengine-generated/\napplet\napplication.log\napplication.wadl\napplication/\napplication/cache/\napplication/configs/application.ini\napplication/logs/\nAppPackages/\napps/\napps/frontend/config/app.yml\napps/frontend/config/databases.yml\nappveyor.yml\nAptfile\nar-lib\narchaius\narchaius.json\narchive.rar\narchive.sql\narchive.tar\narchive.tar.gz\narchive.zip\narticle/\narticle/admin\narticle/admin/admin.asp\nartifacts/\nASALocalRun/\nasp.aspx\naspnet_webadmin\naspwpadmin\naspxspy.aspx\nasset..\nassets/\nassets/fckeditor\nassets/js/fckeditor\nassets/npm-debug.log\nasterisk.log\nAT-admin.cgi\natlassian-ide-plugin.xml\nauditevents\nauditevents.json\nauth\nauth.inc\nauth.php\nauth_user_file.txt\nauthadmin\nauthadmin.php\nauthadmin/\nauthenticate\nauthenticate.php\nauthentication\nauthentication.php\nauthorization.config\nauthorize.php\nauthorized_keys\nauthorizenet.log\nauthuser\nauthuser.php\nauto/\nautoconfig\nautoconfig.json\nautologin\nautologin.php\nautologin/\nautom4te.cache\nautoscan.log\nAutoTest.Net/\nawstats\nawstats.conf\nawstats.pl\nawstats/\nazureadmin/\nb2badmin/\nback.sql\nbackup\nbackup.7z\nbackup.htpasswd\nbackup.inc\nbackup.inc.old\nbackup.old\nbackup.rar\nbackup.sql\nbackup.sql.old\nbackup.tar\nbackup.tar.bz2\nbackup.tar.gz\nbackup.tgz\nbackup.zip\nBackup/\nbackup/\nbackup0/\nbackup1/\nbackup123/\nbackup2/\nbackups\nbackups.7z\nbackups.inc\nbackups.inc.old\nbackups.old\nbackups.rar\nbackups.sql\nbackups.sql.old\nbackups.tar\nbackups.tar.bz2\nbackups.tar.gz\nbackups.tgz\nbackups.zip\nbackups/\nbak/\nbanner.swf\nbanneradmin/\nbase/\nbb-admin/\nbb-admin/admin\nbb-admin/admin.html\nbb-admin/admin.php\nbb-admin/index.html\nbb-admin/index.php\nbb-admin/login\nbb-admin/login.html\nbb-admin/login.php\nbbadmin/\nbbs/\nbbs/admin/login\nbbs/admin_index.asp\nbeans\nbeans.json\nbehat.yml\nBenchmarkDotNet.Artifacts/\nBerksfile\nbigadmin/\nbigdump.php\nbilling\nbilling/\nbilling/killer.php\nbin-debug/\nbin-release/\nbin/\nbin/config.sh\nbin/libs\nbin/reset-db-prod.sh\nbin/reset-db.sh\nbin/RhoBundle\nbin/target\nbin/tmp\nBinaries/\nbitrix/\nbitrix/admin/help.php\nbitrix/admin/index.php\nbitrix/authorization.config\nbitrix/backup/\nbitrix/dumper/\nbitrix/error.log\nbitrix/import/\nbitrix/import/files\nbitrix/import/import\nbitrix/import/m_import\nbitrix/logs/\nbitrix/modules/error.log\nbitrix/modules/error.log.old\nbitrix/modules/main/admin/restore.php\nbitrix/modules/main/classes/mysql/agent.php\nbitrix/modules/smtpd.log\nbitrix/modules/updater.log\nbitrix/modules/updater_partner.log\nbitrix/otp/\nbitrix/php_interface/dbconn.php2\nbitrix/web.config\nbitrix_server_test.log\nbitrix_server_test.php\nbiy/\nbiy/upload/\nBlack.php\nblacklist.dat\nbld/\nblib/\nblockchain.json\nblog/\nblog/error_log\nblog/wp-content/backup-db/\nblog/wp-content/backups/\nblog/wp-login\nblog/wp-login.php\nblogindex/\nbookContent.swf\nboot.php\nbootstrap/data\nbootstrap/tmp\nbot.txt\nbower.json\nbower_components\nbower_components/\nbox.json\nBrocfile.coffee\nBrocfile.js\nbrowser/\nbrunch-config.coffee\nbrunch-config.js\nbuck.sql\nBuild\nbuild\nbuild-iPhoneOS/\nbuild-iPhoneSimulator/\nBuild.bat\nbuild.local.xml\nbuild.log\nbuild.properties\nbuild.sh\nbuild.xml\nbuild/\nbuild/build.properties\nbuild/buildinfo.properties\nbuild/Release\nbuild_config_private.ini\nbuild_isolated/\nbuildNumber.properties\nBundleArtifacts/\nbx_1c_import.php\nc-h.v2.php\nc100.php\nc22.php\nc99.php\nc99shell.php\ncabal-dev\ncabal.project.local\ncabal.project.local~\ncabal.sandbox.config\ncache\ncache-downloads\ncache/\ncache/sql_error_latest.cgi\ncachemgr.cgi\ncadmins/\nCakefile\nCapfile\ncaptures/\nCargo.lock\nCarthage/Build\ncatalog.wci\nCATKIN_IGNORE\ncbx-portal/\ncbx-portal/js/zeroclipboard/ZeroClipboard.swf\ncc-errors.txt\ncc-log.txt\nccbill.log\nccp14admin/\ncelerybeat-schedule\ncell.xml\ncert/\ncfexec.cfm\ncfg/\ncfg/cpp/\nCFIDE/\nCFIDE/administrator/\ncgi-bin/\ncgi-bin/awstats.pl\ncgi-bin/logi.php\ncgi-bin/login\ncgi-bin/login.cgi\ncgi-bin/php.ini\ncgi-bin/printenv.pl\ncgi-bin/test-cgi\ncgi-bin/test.cgi\ncgi-sys/\ncgi-sys/realsignup.cgi\ncgi.pl/\ncgi/\ncgi/common.cg\ncgi/common.cgi\nCgishell.pl\nchange.log\nchangeall.php\nCHANGELOG\nChangeLog\nChangelog\nchangelog\nCHANGELOG.HTML\nCHANGELOG.html\nChangeLog.html\nChangelog.html\nchangelog.html\nCHANGELOG.MD\nCHANGELOG.md\nChangeLog.md\nChangelog.md\nchangelog.md\nCHANGELOG.TXT\nCHANGELOG.txt\nChangeLog.txt\nChangelog.txt\nchangelog.txt\nCHANGES.html\nCHANGES.md\nchanges.txt\ncheck\ncheck.php\ncheckadmin\ncheckadmin.php\nchecked_accounts.txt\nchecklogin\nchecklogin.php\ncheckouts/\ncheckuser\ncheckuser.php\nCheffile\nchefignore\nchkadmin\nchklogin\nchubb.xml\ncidr.txt\ncircle.yml\nCitrix/\ncitrix/\nCitrix/PNAgent/config.xml\ncitydesk.xml\nckeditor\nckeditor/\nckeditor/ckfinder/ckfinder.html\nckeditor/ckfinder/core/connector/asp/connector.asp\nckeditor/ckfinder/core/connector/aspx/connector.aspx\nckeditor/ckfinder/core/connector/php/connector.php\nckfinder/\nckfinder/ckfinder.html\nclaroline/phpMyAdmin/index.php\nclasses/\nclasses/cookie.txt\nclasses_gen\nclassic.json\nclassic.jsonp\ncleanup.log\ncli/\nclient_secret.json\nclient_secrets.json\nClientAccessPolicy.xml\nClientBin/\ncliente/\ncliente/downloads/h4xor.php\nclients.mdb\nclients.sql\nclients.sqlite\nclients.zip\ncmake_install.cmake\nCMakeCache.txt\nCMakeFiles\nCMakeLists.txt\nCMakeLists.txt.user\nCMakeScripts\ncmd-asp-5.1.asp\ncmdasp.asp\ncmdasp.aspx\ncmdjsp.jsp\ncms-admin\ncms.csproj\ncms/\ncms/cms.csproj\ncms/Web.config\ncmsadmin\ncmsadmin.php\ncmsadmin/\ncodeception.yml\ncommand.php\ncommon.inc\ncommon.xml\ncommon/\ncommon/config/api.ini\ncommon/config/db.ini\ncompass.rb\ncompile\ncompile_commands.json\ncomponents/\ncomposer.json\ncomposer.lock\ncomposer.phar\ncomposer/installed.json\nconf/\nconf/Catalina\nconf/catalina.policy\nconf/catalina.properties\nconf/context.xml\nconf/logging.properties\nconf/server.xml\nconf/tomcat-users.xml\nconf/tomcat8.conf\nconf/web.xml\nconfig.bak\nconfig.codekit\nconfig.codekit3\nconfig.core\nconfig.dat\nconfig.guess\nconfig.h.in\nconfig.inc\nconfig.inc.bak\nconfig.inc.old\nconfig.inc.php\nconfig.inc.php.txt\nconfig.inc.php~\nconfig.inc.txt\nconfig.inc~\nconfig.ini\nconfig.ini.bak\nconfig.ini.old\nconfig.ini.txt\nconfig.json\nconfig.json.cfm\nconfig.local\nconfig.old\nconfig.php\nconfig.php-eb\nconfig.php.bak\nconfig.php.dist\nconfig.php.inc\nconfig.php.inc~\nconfig.php.new\nconfig.php.old\nconfig.php.save\nconfig.php.swp\nconfig.php.txt\nconfig.php~\nconfig.rb\nconfig.ru\nconfig.sub\nconfig.txt\nconfig.xml\nconfig.yml\nConfig/\nconfig/\nconfig/apc.php\nconfig/app.php\nconfig/app.yml\nconfig/AppData.config\nconfig/autoload/\nconfig/aws.yml\nconfig/banned_words.txt\nconfig/config.ini\nconfig/database.yml\nconfig/database.yml.pgsql\nconfig/database.yml.sqlite3\nconfig/database.yml_original\nconfig/database.yml~\nconfig/databases.yml\nconfig/development/\nconfig/initializers/secret_token.rb\nconfig/master.key\nconfig/monkcheckout.ini\nconfig/monkdonate.ini\nconfig/monkid.ini\nconfig/producao.ini\nconfig/routes.yml\nconfig/settings.inc\nconfig/settings.ini\nconfig/settings.ini.cfm\nconfig/settings.local.yml\nconfig/settings/production.yml\nconfig/site.php\nconfig/xml/\nconfig_override.php\nconfigprops\nconfigs/\nconfigs/conf_bdd.ini\nconfigs/conf_zepass.ini\nconfiguration.ini\nconfiguration.php\nconfiguration.php.bak\nconfiguration.php.dist\nconfiguration.php.old\nconfiguration.php.save\nconfiguration.php.swp\nconfiguration.php.txt\nconfiguration.php~\nconfiguration/\nconfigure\nconfigure.scan\nconflg.php\nconfluence/\nconn.asp\nconnect.inc\nconsole/\nconsole/base/config.json\nconsole/payments/config.json\ncontent/\ncontent/debug.log\nCONTRIBUTING.md\ncontributing.md\ncontributors.txt\ncontrol\ncontrol.php\ncontrol/\ncontroller.php\ncontrollers/\ncontrolpanel\ncontrolpanel.html\ncontrolpanel.php\ncontrolpanel/\ncookbooks\ncookie\ncookie.php\nCOPYING\nCOPYRIGHT.txt\ncount_admin\ncover\ncover_db/\ncoverage\ncoverage.data\ncoverage.xml\ncoverage/\ncp\ncp.html\ncp.php\ncp/\ncpanel\nCpanel.php\ncpanel.php\ncpanel/\ncpanel_file/\ncpbackup-exclude.conf\ncpbt.php\ncpn.php\ncraft/\ncrash.log\ncredentials.xml\ncredentials/\ncredentials/gcloud.json\nCREDITS\ncrm/\ncron.log\ncron.php\ncron.sh\ncron/\ncron/cron.sh\ncron_import.log\ncron_sku.log\ncrond/\ncrond/logs/\ncronlog.txt\ncsdp.cache\ncss.php\ncsx/\nCTestTestfile.cmake\nculeadora.txt\ncustom/\ncustom/db.ini\ncustomer_login/\ncustomers.csv\ncustomers.log\ncustomers.mdb\ncustomers.sql\ncustomers.sql.gz\ncustomers.sqlite\ncustomers.txt\ncustomers.xls\nCVS/\ncvs/\nCVS/Root\nd.php\nd0main.php\nd0maine.php\nd0mains.php\ndam.php\ndata-nseries.tsv\ndata.mdb\ndata.sql\ndata.sqlite\ndata.tsv\ndata.txt\ndata/\ndata/backups/\ndata/cache/\ndata/debug/\ndata/DoctrineORMModule/cache/\ndata/DoctrineORMModule/Proxy/\ndata/files/\ndata/logs/\ndata/sessions/\ndata/tmp/\ndatabase\ndatabase.csv\ndatabase.inc\ndatabase.log\ndatabase.mdb\ndatabase.php\ndatabase.sql\ndatabase.sqlite\ndatabase.txt\ndatabase.yml\ndatabase.yml.pgsql\ndatabase.yml.sqlite3\ndatabase.yml_original\ndatabase.yml~\ndatabase/\ndatabase/database/\ndatabase/phpMyAdmin/\ndatabase/phpmyadmin/\ndatabase/phpMyAdmin2/\ndatabase/phpmyadmin2/\ndatabase_admin\nDatabase_Administration/\nDatabase_Backup/\ndatabase_credentials.inc\ndatabases.yml\ndataobject.ini\ndavmail.log\nDB\ndb\ndb-admin\ndb-admin/\ndb-full.mysql\ndb.csv\ndb.inc\ndb.ini\ndb.log\ndb.mdb\nDb.properties\nDb.script\ndb.sql\ndb.sqlite\ndb.sqlite3\ndb/\ndb/db-admin/\ndb/dbadmin/\ndb/dbweb/\ndb/index.php\ndb/main.mdb\ndb/myadmin/\ndb/phpMyAdmin-2/\ndb/phpMyAdmin-3/\ndb/phpMyAdmin/\ndb/phpmyadmin/\ndb/phpMyAdmin2/\ndb/phpmyadmin2/\ndb/phpMyAdmin3/\ndb/phpmyadmin3/\ndb/sql\ndb/webadmin/\ndb/webdb/\ndb/websql/\ndb1.mdb\ndb1.sqlite\ndb2\ndb__.init.php\ndb_admin\ndb_backups/\ndb_session.init.php\ndb_status.php\ndbaccess.log\ndbadmin.php\ndbadmin/\ndbadmin/index.php\ndbase\ndbbackup/\ndbdump.sql\ndbfix/\ndbweb/\ndead.letter\ndebug\ndebug-output.txt\ndebug.inc\ndebug.log\ndebug.php\ndebug.py\ndebug.txt\ndebug.xml\ndebug/\ndebug_error.jsp\ndelete.php\ndemo.php\ndemo/\ndemo/ejb/index.html\ndemo/sql/index.jsp\ndemos/\ndenglu\ndenglu/\ndenglu/admin.asp\ndepcomp\ndependency-reduced-pom.xml\ndeploy\ndeploy.env\ndeploy.rb\ndeps\ndeps/deps.jl\nDerivedData/\nDerivedDataCache/\nDesktop.ini\ndesktop/\ndesktop/index_framed.htm\ndev.php\ndev/\ndevdata.db\ndevel/\ndevel_isolated/\ndevelop-eggs/\ndevelopment-parts/\ndevelopment.esproj/\ndevelopment.log\ndevelopment/\ndf_main.sql\ndfshealth.jsp\ndir-login/\ndir.php\ndirectadmin/\ndist\ndist/\ndkms.conf\ndlldata.c\ndoc\ndoc/\ndoc/api/\ndocker-compose-dev.yml\ndocker-compose.yml\nDockerfile\nDocProject/buildhelp/\nDocProject/Help/html\nDocProject/Help/Html2\ndocs.json\ndocs/\ndocs/_build/\ndoctrine/\ndoctrine/schema/eirec.yml\ndoctrine/schema/tmx.yml\ndocumentation/\ndocumentation/config.yml\ndom.php\ndomcfg.nsf\ndown/\ndown/login\ndownload/\ndownload/history.csv\ndownload/users.csv\ndownloader/\ndownloader/cache.cfg\ndownloader/connect.cfg\ndownloads/\ndownloads/dom.php\ndra.php\ndummy\ndummy.php\ndump\ndump.7z\ndump.inc\ndump.inc.old\ndump.json\ndump.log\ndump.old\ndump.rar\ndump.rdb\ndump.sql\ndump.sql.old\ndump.sqlite\ndump.tar\ndump.tar.bz2\ndump.tar.gz\ndump.tgz\ndump.zip\ndump/\ndumper.php\ndumper/\ndumps/\ndwsync.xml\ndz.php\ndz0.php\ndz1.php\neagle.epf\necf/\necosystem.json\nedit.php\neditor.php\neditor/\neditor/FCKeditor\neditor/stats/\neditor/tiny_mce/\neditor/tinymce/\neditors/\neditors/FCKeditor\neggs/\nehthumbs.db\nelfinder/\nelfinder/elfinder.php\nelm-stuff\nelmah.axd\nengine/\nengine/classes/swfupload/swfupload.swf\nengine/classes/swfupload/swfupload_f9.swf\nengine/log.txt\nenv\nenv.bak/\nenv.js\nenv.json\nENV/\nenv/\nenvironment.rb\nerl_crash.dump\nerr\nerr.log\nerr.txt\nerror\nerror-log\nerror-log.txt\nerror.asp\nerror.cpp\nerror.ctp\nerror.html\nerror.ini\nerror.log\nerror.log.0\nerror.tmpl\nerror.tpl\nerror.txt\nerror.xml\nerror/\nerror_import\nerror_log\nerror_log.gz\nerror_log.txt\nerrorlog\nerrorPages\nerrors.asp\nerrors.log\nerrors.tpl\nerrors.txt\nerrors/\nerrors/creation\nerrors/local.xml\netc/\netc/config.ini\netc/database.xml\netc/hosts\netc/lib/pChart2/examples/imageMap/index.php\netc/passwd\neudora.ini\neula.txt\neula_en.txt\nexample.php\nexamples/\nexamples/jsp/%252e%252e/%252e%252e/manager/html/\nexamples/jsp/snp/snoop.jsp\nexamples/servlet/SnoopServlet\nexamples/servlets/servlet/CookieExample\nexamples/servlets/servlet/RequestHeaderExample\nexception.log\nexploded-archives/\nexplore\nexplore/repos\nexport\nexport.cfg\nexport/\nexport_presets.cfg\nExportedObj/\next/\next/.deps\next/build/\next/config\next/install-sh\next/libtool\next/ltmain.sh\next/Makefile\next/missing\next/mkinstalldirs\next/modules/\next/run-tests.php\nextjs/\nextjs/resources//charts.swf\nextras/documentation\nezsqliteadmin/\nfake-eggs/\nFakesAssemblies/\nFAQ\nfastlane/Preview.html\nfastlane/readme.md\nfastlane/report.xml\nfastlane/screenshots\nfastlane/test_output\nFCKeditor\nfckeditor\nFCKeditor/\nfckeditor/\nfckeditor/editor/filemanager/browser/default/connectors/asp/connector.asp\nfckeditor/editor/filemanager/browser/default/connectors/aspx/connector.aspx\nfckeditor/editor/filemanager/browser/default/connectors/php/connector.php\nfckeditor/editor/filemanager/connectors/asp/connector.asp\nfckeditor/editor/filemanager/connectors/asp/upload.asp\nfckeditor/editor/filemanager/connectors/aspx/connector.aspx\nfckeditor/editor/filemanager/connectors/aspx/upload.aspx\nfckeditor/editor/filemanager/connectors/php/connector.php\nfckeditor/editor/filemanager/connectors/php/upload.php\nfckeditor/editor/filemanager/upload/asp/upload.asp\nfckeditor/editor/filemanager/upload/aspx/upload.aspx\nfckeditor/editor/filemanager/upload/php/upload.php\nFCKeditor2.0/\nFCKeditor2.1/\nFCKeditor2.2/\nFCKeditor2.3/\nFCKeditor2.4/\nFCKeditor2/\nFCKeditor20/\nFCKeditor21/\nFCKeditor22/\nFCKeditor23/\nFCKeditor24/\nfeatures\nfeatures.json\nfeixiang.php\nfile.php\nfile_manager/\nfile_upload.asp\nfile_upload.aspx\nfile_upload.cfm\nfile_upload.htm\nfile_upload.html\nfile_upload.php\nfile_upload.php3\nfile_upload.shtm\nfile_upload/\nfileadmin\nfileadmin.php\nfileadmin/\nfileadmin/_processed_/\nfileadmin/_temp_/\nfileadmin/user_upload/\nfiledump/\nfilemanager\nfilemanager/\nfilemanager/views/js/ZeroClipboard.swf\nfiles.md5\nfiles.php\nfiles/\nFiles/binder.autosave\nFiles/binder.backup\nfiles/cache/\nFiles/Docs/docs.checksum\nFiles/search.indexes\nfiles/tmp/\nFiles/user.lock\nfileupload/\nfilezilla.xml\nflash/\nflash/ZeroClipboard.swf\nflashFXP.ini\nfluent.conf\nfluent_aggregator.conf\nformslogin/\nforum.rar\nforum.sql\nforum.tar\nforum.tar.gz\nforum.zip\nforum/\nforum/install/install.php\nforums/\nforums/cache/db_update.lock\nfpadmin\nfpadmin/\nfreeline.py\nfreeline/\nfreeline_project_description.json\nftp.txt\nfuel/app/cache/\nfuel/app/config/\nfuel/app/logs/\nfunction.require\nfunctions/\ngaza.php\ngbpass.pl\nGemfile\nGemfile.lock\nGEMINI/\ngen/\nGenerated_Code/\nget.php\ngetFile.cfm\ngit-service\ngithub-cache\ngithub-recovery-codes.txt\ngitlab/\ngitlog\nglobal\nglobal.asa\nglobal.asa.bak\nglobal.asa.old\nglobal.asa.orig\nglobal.asa.temp\nglobal.asa.tmp\nglobal.asax\nglobal.asax.bak\nglobal.asax.old\nglobal.asax.orig\nglobal.asax.temp\nglobal.asax.tmp\nglobals\nglobals.inc\nglobes_admin/\ngoogle-services.json\ngrabbed.html\ngradle-app.setting\ngrappelli/\nGruntFile.coffee\nGruntfile.coffee\nGruntfile.js\ngruntFile.js\nguanli\nguanli/\nguanli/admin.asp\nGuardfile\nGulpfile.coffee\ngulpfile.coffee\nGulpfile.js\ngulpfile.js\ngwt-unitCache/\nh2console\nhealth\nhealth.json\nheapdump\nheapdump.json\nHISTORY\nHISTORY.txt\nHNAP1/\nhndUnblock.cgi\nhome.html\nhome.php\nhome.rar\nhome.tar\nhome.tar.gz\nhome.zip\nHomestead.json\nHomestead.yaml\nhost-manager/\nhost-manager/html\nhosts\nhoutai\nhoutai/\nhoutai/admin.asp\nhpwebjetadmin/\nhs_err_pid.log\nhtaccess.backup\nhtaccess.bak\nhtaccess.dist\nhtaccess.old\nhtaccess.txt\nhtdocs\nhtgroup\nhtml/\nhtml/config.rb\nhtml/js/misc/swfupload/swfupload.swf\nhtml/js/misc/swfupload/swfupload_f9.swf\nhtmlcov/\nhtpasswd\nhtpasswd.bak\nhtpasswd/\nhtpasswd/htpasswd.bak\nHttp/\nHttp/DataLayCfg.xml\nhttp_access.log\nhttpd.conf\nhttpd.conf.backup\nhttpd.conf.default\nhttpd.core\nhttpd.ini\nhttpd/\nhttpd/logs/access.log\nhttpd/logs/access_log\nhttpd/logs/error.log\nhttpd/logs/error_log\nhudson/\nhudson/login\nhystrix\ni.php\nid_dsa\nid_dsa.ppk\nid_rsa\nid_rsa.pub\niiasdmpwd/\niisadmin/\nimages/\nimages/c99.php\nimages/Sym.php\nimport.php\nimport/\nimport_error.log\nin/\ninc/\ninc/config.inc\ninc/fckeditor/\ninc/tiny_mce/\ninc/tinymce/\ninclude\ninclude/\ninclude/fckeditor/\nincludes\nincludes/\nincludes/adovbs.inc\nincludes/bootstrap.inc\nincludes/configure.php~\nincludes/fckeditor/editor/filemanager/browser/default/connectors/asp/connector.asp\nincludes/fckeditor/editor/filemanager/browser/default/connectors/aspx/connector.aspx\nincludes/fckeditor/editor/filemanager/browser/default/connectors/php/connector.php\nincludes/fckeditor/editor/filemanager/connectors/asp/connector.asp\nincludes/fckeditor/editor/filemanager/connectors/asp/upload.asp\nincludes/fckeditor/editor/filemanager/connectors/aspx/connector.aspx\nincludes/fckeditor/editor/filemanager/connectors/aspx/upload.aspx\nincludes/fckeditor/editor/filemanager/connectors/php/connector.php\nincludes/fckeditor/editor/filemanager/connectors/php/upload.php\nincludes/fckeditor/editor/filemanager/upload/asp/upload.asp\nincludes/fckeditor/editor/filemanager/upload/aspx/upload.aspx\nincludes/fckeditor/editor/filemanager/upload/php/upload.php\nincludes/js/tiny_mce/\nincludes/swfupload/swfupload.swf\nincludes/swfupload/swfupload_f9.swf\nincludes/tiny_mce/\nincludes/tinymce/\nindex-bak\nindex-test.php\nindex.htm\nindex.html\nindex.php\nindex.php-bak\nindex.php.bak\nindex.php3\nindex.php4\nindex.php5\nindex.php~\nindex.xml\nindex2.php\nindex3.php\nindex_manage\nIndy_admin/\ninfo\ninfo.json\ninfo.php\ninfo.txt\ninfos.php\ninit/\ninspector\ninstadmin/\nINSTALL\nInstall\ninstall\ninstall-log.txt\ninstall-sh\ninstall.asp\ninstall.aspx\ninstall.bak\ninstall.htm\nINSTALL.HTML\nINSTALL.html\nInstall.html\ninstall.html\ninstall.inc\nINSTALL.MD\nINSTALL.md\nInstall.md\ninstall.md\nINSTALL.mysql\ninstall.mysql\nINSTALL.mysql.txt\ninstall.mysql.txt\nINSTALL.pgsql\ninstall.pgsql\nINSTALL.pgsql.txt\ninstall.pgsql.txt\ninstall.php\ninstall.rdf\ninstall.sql\ninstall.tpl\nINSTALL.TXT\nINSTALL.txt\nInstall.txt\ninstall.txt\ninstall/\ninstall/index.php?upgrade/\ninstall/update.log\ninstall_\nINSTALL_admin\ninstall_manifest.txt\ninstall_mgr.log\ninstallation.php\ninstallation/\ninstalled.json\nInstalledFiles\ninstaller\ninstaller-log.txt\ninstaller.php\ninstaller_files/\ninstall~/\ninstance/\nIntermediate/\ninvoker/\ninvoker/JMXInvokerServlet\ninvoker/readonly/JMXInvokerServlet\ninvoker/restricted/JMXInvokerServlet\nio.swf\niOSInjectionProject/\nipch/\nirc-macadmin/\nirequest/\nisadmin\nisadmin.php\nispmgr/\nj2ee/servlet/SnoopServlet\nJakefile\njavascripts/bundles\njavax.faces.resource.../\njavax.faces.resource.../WEB-INF/web.xml.jsf\njboss/server/all/deploy/project.ext\njboss/server/all/log/\njboss/server/default/deploy/project.ext\njboss/server/default/log/\njboss/server/minimal/deploy/project.ext\njbossws/services\njdbc\nJenkinsfile\njira/\njmx-console\njmx-console/\njmx-console/HtmlAdaptor?action=inspectMBean\u0026name=jboss.system:type=ServerInfo\njo.php\njoomla.rar\njoomla.xml\njoomla.zip\njoomla/\njoomla/administrator\njs/\njs/elfinder/elfinder.php\njs/FCKeditor\njs/routing\njs/swfupload/swfupload.swf\njs/swfupload/swfupload_f9.swf\njs/tiny_mce/\njs/tinymce/\njs/yui/uploader/assets/uploader.swf\njs/ZeroClipboard.swf\njs/ZeroClipboard10.swf\njscripts/\njscripts/tiny_mce/\njscripts/tiny_mce/plugins/ajaxfilemanager/ajaxfilemanager.php\njscripts/tinymce/\njsp-examples/\njsp-reverse.jsp\njsp/viewer/snoop.jsp\njspm_packages/\njssresource/\nkarma.conf.js\nkcfinder/\nkcfinder/browse.php\nkeys.json\nkiller.php\nkpanel/\nl0gs.txt\nL3b.php\nlander.logs\nlatest/meta-data/hostname\nlatest/user-data\nlayouts/\nldap.prop\nldap.prop.sample\nletmein\nletmein.php\nletmein/\nlg/\nlg/lg.conf\nlia.cache\nlib-cov\nlib/\nlib/bundler/man/\nlib/fckeditor/\nlib/flex/uploader/.actionScriptProperties\nlib/flex/uploader/.flexProperties\nlib/flex/uploader/.project\nlib/flex/uploader/.settings\nlib/flex/varien/.actionScriptProperties\nlib/flex/varien/.flexLibProperties\nlib/flex/varien/.project\nlib/flex/varien/.settings\nlib/tiny_mce/\nlib/tinymce/\nlib64/\nlibraries/\nlibraries/phpmailer/\nlibraries/tiny_mce/\nlibraries/tinymce/\nlibrepag.log\nLICENSE\nlicense.php\nLICENSE.txt\nlicense.txt\nliferay.log\nlighttpd.access.log\nlighttpd.error.log\nlilo.conf\nlindex.php\nlinkhub/\nlinkhub/linkhub.log\nlinktous.html\nlinusadmin-phpinfo.php\nlist_emails\nlistener.log\nlists/\nlists/config\nLiveUser_Admin/\nlk/\nload.php\nlocal.config.rb\nlocal.properties\nlocal.xml.additional\nlocal.xml.template\nlocal/\nlocal/composer.lock\nlocal/composer.phar\nlocal_bd_new.txt\nlocal_bd_old.txt\nlocal_settings.py\nlocalhost.sql\nlocalsettings.php.bak\nlocalsettings.php.dist\nlocalsettings.php.old\nlocalsettings.php.save\nlocalsettings.php.swp\nlocalsettings.php.txt\nlocalsettings.php~\nlog\nlog-in\nlog-in.php\nlog-in/\nlog.htm\nlog.html\nlog.mdb\nlog.php\nlog.sqlite\nlog.txt\nlog/\nlog/access.log\nlog/access_log\nlog/authorizenet.log\nlog/development.log\nlog/error.log\nlog/error_log\nlog/exception.log\nlog/librepag.log\nlog/log.log\nlog/log.txt\nlog/old\nlog/payment.log\nlog/payment_authorizenet.log\nlog/payment_paypal_express.log\nlog/production.log\nlog/server.log\nlog/test.log\nlog/www-error.log\nlog_1.txt\nlog_errors.txt\nlog_in\nlog_in.php\nlog_in/\nlogexpcus.txt\nlogfile\nlogfile.txt\nlogfiles\nloggers\nloggers.json\nloggers/\nlogi.php\nlogin\nlogin-redirect/\nlogin-us/\nlogin.asp\nlogin.cgi\nlogin.htm\nlogin.html\nlogin.php\nlogin/\nlogin/admin/admin.asp\nlogin/index\nlogin/login\nlogin/super\nlogin1\nlogin1/\nlogin_admi\nlogin_admin\nlogin_admin/\nlogin_db/\nlogin_ou.php\nlogin_out\nlogin_out/\nlogin_use.php\nlogin_user\nloginerror/\nloginflat/\nloginok/\nlogins.txt\nloginsave/\nloginsupe.php\nloginsuper\nloginsuper/\nlogo_sysadmin/\nlogou.php\nlogout\nlogout.asp\nlogout/\nlogs\nlogs.htm\nlogs.html\nlogs.mdb\nlogs.pl\nlogs.sqlite\nlogs.txt\nLogs/\nlogs/\nlogs/access.log\nlogs/access_log\nlogs/error.log\nlogs/error_log\nlogs/liferay.log\nlogs/mail.log\nlogs/wsadmin.traceout\nlogs/www-error.log\nlogs_backup/\nlogs_console/\nlol.php\nLotus_Domino_Admin/\nltmain.sh\nluac.out\nm4/libtool.m4\nm4/ltoptions.m4\nm4/ltsugar.m4\nm4/ltversion.m4\nm4/lt~obsolete.m4\nmacadmin/\nmadspot.php\nmadspotshell.php\nmagic.default\nmagmi/\nmagmi/conf/magmi.ini\nmail\nmail.log\nmailer/.env\nmailman/\nmailman/listinfo\nmain.mdb\nmain/\nmain/login\nmaint/\nMAINTAINERS.txt\nmaintenance.flag\nmaintenance.flag.bak\nmaintenance.flag2\nmaintenance.html\nmaintenance.php\nmaintenance/\nmaintenance/test.php\nmaintenance/test2.php\nMakefile\nMakefile.in\nMakefile.old\nmanage\nmanage.php\nmanage.py\nmanage/\nmanage/admin.asp\nmanage/login.asp\nmanage_index\nmanagement\nmanagement.php\nmanagement/\nmanager\nmanager.php\nmanager/\nmanager/admin.asp\nmanager/html\nmanager/login\nmanager/login.asp\nmanager/status/all\nMANIFEST\nMANIFEST.bak\nMANIFEST.MF\nmanifest.mf\nmanifest.yml\nmanifest/cache/\nmanifest/logs/\nmanifest/tmp/\nmanuallogin/\nmappings\nmappings.json\nmaster.passwd\nmaster/\nmaster/portquotes_new/admin.log\nmbox\nmdate-sh\nmedia/\nmedia/export-criteo.xml\nmember\nmember.php\nmember/\nmember/admin.asp\nmember/login.asp\nmemberadmin\nmemberadmin.php\nmemberadmin/\nmemberlist\nmembers\nmembers.csv\nmembers.log\nmembers.mdb\nmembers.php\nmembers.sql\nmembers.sql.gz\nmembers.sqlite\nmembers.txt\nmembers.xls\nmembers/\nmembersonly\nmemlogin/\nmercurial.ini\nMercury.modules\nMercury/\nMETA-INF/\nMETA-INF/context.xml\nMETA.json\nMETA.yml\nmeta_login/\nmetadata.rb\nmetric_tracking\nmetric_tracking.json\nmetrics\nmetrics.json\nmetrics/\nmetrics/*.json\nmimosa-config.coffee\nmimosa-config.js\nmisc\nmissing\nMkfile.old\nmoadmin.php\nmoadmin/\nmock/\nmodelsearch/\nmodelsearch/admin.html\nmodelsearch/admin.php\nmodelsearch/index.html\nmodelsearch/index.php\nmodelsearch/login\nmodelsearch/login.html\nmodelsearch/login.php\nmoderator\nmoderator.html\nmoderator.php\nmoderator/\nmoderator/admin\nmoderator/admin.html\nmoderator/admin.php\nmoderator/login\nmoderator/login.html\nmoderator/login.php\nmodern.json\nmodern.jsonp\nModule.symvers\nmodules.order\nmodules/\nmodules/admin/\nmonitor/\nmonitoring\nmonitoring/\nmoving.page\nmrtg.cfg\nmsg/\nmsg_gen/\nmsql/\nmssql/\nmt-check.cgi\nmunin/\nmuracms.esproj\nmw-config/\nmx.php\nmyadm/\nMyAdmin/\nmyadmin/\nmyadmin/index.php\nMyAdmin/scripts/setup.php\nmyadmin/scripts/setup.php\nmyadmin2/index.php\nmyadminscripts/\nmyadminscripts/setup.php\nmysql-admin/\nmysql-admin/index.php\nmysql.err\nmysql.log\nmysql.php\nmysql/\nmysql/admin/\nmysql/db/\nmysql/dbadmin/\nmysql/index.php\nmysql/mysqlmanager/\nmysql/pMA/\nmysql/pma/\nmysql/scripts/setup.php\nmysql/sqlmanager/\nmysql/web/\nmysql_debug.sql\nmysqladmin/\nmysqladmin/index.php\nmysqladmin/scripts/setup.php\nmysqldumper/\nmysqlitedb.db\nmysqlmanager/\nnagios/\nnano.save\nnative_stderr.log\nnative_stdout.log\nnavSiteAdmin/\nnb-configuration.xml\nnbactions.xml\nnbproject/\nnbproject/private/private.properties\nnbproject/private/private.xml\nnbproject/project.properties\nnbproject/project.xml\nNew%20Folder\nNew%20folder%20(2)\nnew.php\nnewbbs/\nnewbbs/login\nnewsadmin/\nnginx-access.log\nnginx-error.log\nnginx-ssl.access.log\nnginx-ssl.error.log\nnginx-status/\nnginx.conf\nnginx_status\nngx_pagespeed_beacon/\nnia.cache\nnimcache/\nnlia.cache\nnode_modules\nnode_modules/\nnohup.out\nnosetests.xml\nnpm-debug.log\nnra.cache\nnst.php\nnstview.php\nnsw/\nnsw/admin/login.php\nnwp-content/\nnwp-content/plugins/disqus-comment-system/disqus.php\nnytprof.out\nobj/\nodbc\nOffice/\nOffice/graph.php#xxe\nolap/\nold\nold.htaccess\nold.htpasswd\nold/\nold_files\nold_site/\noldfiles\nopa-debug-js\nopen-flash-chart.swf?get-data=(function(){alert(document.domain)})()\nOpenCover/\nopenvpnadmin/\noperador/\noperator/\nops/\noracle\norder.log\norder.txt\norder_add_log.txt\norder_log\norders\norders.csv\norders.log\norders.sql\norders.sql.gz\norders.txt\norders.xls\norders_log\norleans.codegen.cs\nospfd.conf\nout.txt\nout/\noutput\noutput-build.txt\noutput/\nOWA/\np.php\np/\np/m/a/\npackage-cache\npackage-lock.json\npackage.json\nPackage.StoreAssociation.xml\npacker_cache/\npages/\npages/admin/\npages/admin/admin-login\npages/admin/admin-login.html\npages/admin/admin-login.php\npainel/\npainel/config/config.php.example\npaket-files/\npanel\npanel-administracion/\npanel-administracion/admin.html\npanel-administracion/admin.php\npanel-administracion/index.html\npanel-administracion/index.php\npanel-administracion/login\npanel-administracion/login.html\npanel-administracion/login.php\npanel.php\npanel/\nparts/\npass\npass.dat\npass.txt\npasses.txt\npasslist\npasslist.txt\npasswd\npasswd.adjunct\npasswd.bak\npasswd.txt\nPassword\npassword\npassword.html\npassword.log\npassword.mdb\npassword.sqlite\npassword.txt\npasswords\npasswords.html\npasswords.mdb\npasswords.sqlite\npasswords.txt\npath/\npath/dataTables/extras/TableTools/media/swf/ZeroClipboard.swf\npause\npause.json\npayment.log\npayment_authorizenet.log\npayment_paypal_express.log\npbmadmin/\npentaho/\nperl-reverse-shell.pl\nperlcmd.cgi\npersonal\npersonal.mdb\npersonal.sqlite\npg_hba.conf\npgadmin\npgadmin.log\npgadmin/\nPharoDebug.log\nphinx.yml\nphp\nphp-backdoor.php\nphp-cgi.core\nphp-cli.ini\nphp-cs-fixer.phar\nphp-error.log\nphp-error.txt\nphp-errors.log\nphp-errors.txt\nphp-findsock-shell.php\nphp-fpm/\nphp-fpm/error.log\nphp-fpm/www-error.log\nphp-info.php\nphp-my-admin/\nphp-myadmin/\nphp-reverse-shell.php\nphp-tiny-shell.php\nphp.core\nphp.ini\nphp.ini-orig.txt\nphp.ini.sample\nphp.ini_\nphp.ini~\nphp.lnk\nphp.log\nphp.php\nphp/\nphp/dev/\nphp/php.cgi\nphp4.ini\nphp5.fcgi\nphp5.ini\nphp_cli_errors.log\nphp_error.log\nphp_error_log\nphp_errorlog\nphp_errors.log\nphpadmin/\nphpadmin/index.php\nphpadminmy/\nphperrors.log\nphpinfo\nphpinfo.php\nphpinfo.php3\nphpinfo.php4\nphpinfo.php5\nphpinfos.php\nphpini.bak\nphpldapadmin\nphpldapadmin/\nphpliteadmin.php\nphpm/\nphpma/\nphpma/index.php\nphpmanager/\nphpmem/\nphpmemcachedadmin/\nphpMoAdmin/\nphpmoadmin/\nphpmy-admin/\nphpMy/\nphpmy/\nphpMyA/\nphpmyad-sys/\nphpmyad/\nphpMyAdmi/\nphpMyAdmin-2.10.0/\nphpMyAdmin-2.10.1/\nphpMyAdmin-2.10.2/\nphpMyAdmin-2.10.3/\nphpMyAdmin-2.11.0/\nphpMyAdmin-2.11.1/\nphpMyAdmin-2.11.10/\nphpMyAdmin-2.11.2/\nphpMyAdmin-2.11.3/\nphpMyAdmin-2.11.4/\nphpMyAdmin-2.11.5.1-all-languages/\nphpMyAdmin-2.11.5/\nphpMyAdmin-2.11.6-all-languages/\nphpMyAdmin-2.11.6/\nphpMyAdmin-2.11.7.1-all-languages-utf-8-only/\nphpMyAdmin-2.11.7.1-all-languages/\nphpMyAdmin-2.11.7/\nphpMyAdmin-2.11.8.1-all-languages-utf-8-only/\nphpMyAdmin-2.11.8.1-all-languages/\nphpMyAdmin-2.11.8.1/\nphpMyAdmin-2.11.9/\nphpMyAdmin-2.2.3/\nphpMyAdmin-2.2.6/\nphpMyAdmin-2.5.1/\nphpMyAdmin-2.5.4/\nphpMyAdmin-2.5.5-pl1/\nphpMyAdmin-2.5.5-rc1/\nphpMyAdmin-2.5.5-rc2/\nphpMyAdmin-2.5.5/\nphpMyAdmin-2.5.6-rc1/\nphpMyAdmin-2.5.6-rc2/\nphpMyAdmin-2.5.6/\nphpMyAdmin-2.5.7-pl1/\nphpMyAdmin-2.5.7/\nphpMyAdmin-2.6.0-alpha/\nphpMyAdmin-2.6.0-alpha2/\nphpMyAdmin-2.6.0-beta1/\nphpMyAdmin-2.6.0-beta2/\nphpMyAdmin-2.6.0-pl1/\nphpMyAdmin-2.6.0-pl2/\nphpMyAdmin-2.6.0-pl3/\nphpMyAdmin-2.6.0-rc1/\nphpMyAdmin-2.6.0-rc2/\nphpMyAdmin-2.6.0-rc3/\nphpMyAdmin-2.6.0/\nphpMyAdmin-2.6.1-pl1/\nphpMyAdmin-2.6.1-pl2/\nphpMyAdmin-2.6.1-pl3/\nphpMyAdmin-2.6.1-rc1/\nphpMyAdmin-2.6.1-rc2/\nphpMyAdmin-2.6.1/\nphpMyAdmin-2.6.2-beta1/\nphpMyAdmin-2.6.2-pl1/\nphpMyAdmin-2.6.2-rc1/\nphpMyAdmin-2.6.2/\nphpMyAdmin-2.6.3-pl1/\nphpMyAdmin-2.6.3-rc1/\nphpMyAdmin-2.6.3/\nphpMyAdmin-2.6.4-pl1/\nphpMyAdmin-2.6.4-pl2/\nphpMyAdmin-2.6.4-pl3/\nphpMyAdmin-2.6.4-pl4/\nphpMyAdmin-2.6.4-rc1/\nphpMyAdmin-2.6.4/\nphpMyAdmin-2.7.0-beta1/\nphpMyAdmin-2.7.0-pl1/\nphpMyAdmin-2.7.0-pl2/\nphpMyAdmin-2.7.0-rc1/\nphpMyAdmin-2.7.0/\nphpMyAdmin-2.8.0-beta1/\nphpMyAdmin-2.8.0-rc1/\nphpMyAdmin-2.8.0-rc2/\nphpMyAdmin-2.8.0.1/\nphpMyAdmin-2.8.0.2/\nphpMyAdmin-2.8.0.3/\nphpMyAdmin-2.8.0.4/\nphpMyAdmin-2.8.0/\nphpMyAdmin-2.8.1-rc1/\nphpMyAdmin-2.8.1/\nphpMyAdmin-2.8.2/\nphpMyAdmin-2/\nphpMyAdmin-3.0.0/\nphpMyAdmin-3.0.1/\nphpMyAdmin-3.1.0/\nphpMyAdmin-3.1.1/\nphpMyAdmin-3.1.2/\nphpMyAdmin-3.1.3/\nphpMyAdmin-3.1.4/\nphpMyAdmin-3.1.5/\nphpMyAdmin-3.2.0/\nphpMyAdmin-3.2.1/\nphpMyAdmin-3.2.2/\nphpMyAdmin-3.2.3/\nphpMyAdmin-3.2.4/\nphpMyAdmin-3.2.5/\nphpMyAdmin-3.3.0/\nphpMyAdmin-3.3.1/\nphpMyAdmin-3.3.2-rc1/\nphpMyAdmin-3.3.2/\nphpMyAdmin-3.3.3-rc1/\nphpMyAdmin-3.3.3/\nphpMyAdmin-3.3.4-rc1/\nphpMyAdmin-3.3.4/\nphpMyAdmin-3/\nphpMyAdmin-4/\nphpmyadmin-old/index.php\nphpMyAdmin.old/index.php\nphpMyAdmin/\nphpMyadmin/\nphpmyAdmin/\nphpmyadmin/\nphpMyAdmin/index.php\nphpmyadmin/index.php\nphpMyAdmin/phpMyAdmin/index.php\nphpmyadmin/phpmyadmin/index.php\nphpMyAdmin/scripts/setup.php\nphpmyadmin/scripts/setup.php\nphpMyAdmin0/\nphpmyadmin0/\nphpmyadmin0/index.php\nphpMyAdmin1/\nphpmyadmin1/\nphpmyadmin1/index.php\nphpMyAdmin2/\nphpmyadmin2/\nphpmyadmin2/index.php\nphpmyadmin2011/\nphpmyadmin2012/\nphpmyadmin2013/\nphpmyadmin2014/\nphpmyadmin2015/\nphpmyadmin2016/\nphpmyadmin2017/\nphpmyadmin2018/\nphpMyAdmin3/\nphpmyadmin3/\nphpMyAdmin4/\nphpmyadmin4/\nphpMyadmin_bak/index.php\nphpMyAdminBackup/\nphpMyAdminold/index.php\nphpMyAds/\nphppgadmin\nphpPgAdmin/\nphppgadmin/\nphppma/\nphpRedisAdmin/\nphpredmin/\nphproad/\nphpsecinfo/\nphpspec.yml\nphpSQLiteAdmin/\nphpstudy.php\nphpsysinfo/\nphptest.php\nphpThumb.php\nphpThumb/\nphpunit.phar\nphpunit.xml\nphpunit.xml.dist\nphymyadmin/\npi.php\npi.php5\npids\npinfo.php\npip-delete-this-directory.txt\npip-log.txt\npiwigo/\npiwigo/extensions/UserCollections/template/ZeroClipboard.swf\npkg/\nplanning/cfg\nplanning/docs\nplanning/src\nplatz_login/\nplay-cache\nplay-stash\nplayer.swf\nplayground.xcworkspace\nplugin.xml\nplugins.log\nplugins/\nplugins/editors/fckeditor\nplugins/fckeditor\nplugins/sfSWFUploadPlugin/web/sfSWFUploadPlugin/swf/swfupload.swf\nplugins/sfSWFUploadPlugin/web/sfSWFUploadPlugin/swf/swfupload_f9.swf\nplugins/tiny_mce/\nplugins/tinymce/\nplugins/upload.php\nplugins/web.config\nplupload\npm_to_blib\npma-old/index.php\nPMA/\npma/\nPMA/index.php\npma/index.php\npma/scripts/setup.php\nPMA2/index.php\nPMA2005/\npma2005/\nPMA2009/\npma2009/\nPMA2011/\npma2011/\nPMA2012/\npma2012/\nPMA2013/\npma2013/\nPMA2014/\npma2014/\nPMA2015/\npma2015/\nPMA2016/\npma2016/\nPMA2017/\npma2017/\nPMA2018/\npma2018/\npma4/\npmadmin/\npmamy/index.php\npmamy2/index.php\npmd/index.php\npmyadmin/\npom.xml\npom.xml.asc\npom.xml.next\npom.xml.releaseBackup\npom.xml.tag\npom.xml.versionsBackup\nportal/\npostgresql.conf\npower_user/\nprintenv\nprintenv.tmp\npriv8.php\nprivate.key\nprivate.mdb\nprivate.sqlite\nprocesslogin\nprocesslogin.php\nProcfile\nProcfile.dev\nProcfile.offline\nproduct.json\nproduction.log\nprofiles\nprofiles.xml\nprogram/\nproguard/\nproject-admins/\nproject.fragment.lock.json\nproject.lock.json\nproject.xml\nproject/project\nproject/target\nprometheus\npropel.ini\nprotected/data/\nprotected/runtime/\nproviders.json\nproxy.pac\nproxy.stream?origin=https://google.com\nprv/\nPSUser/\npublic\npublic..\npublic/hot\npublic/storage\npublic/system\npublication_list.xml\npublish/\nPublishScripts/\npubspec.lock\npureadmin/\nputty.reg\npw.txt\npwd.db\npws.txt\npy-compile\nqa/\nqq.php\nqql/\nqsd-php-backdoor.php\nquery.log\nQuickLook/\nquikstore.cfg\nr.php\nr00t.php\nr57.php\nr57eng.php\nr57shell.php\nr58.php\nr99.php\nradmind-1/\nradmind/\nrails/info/properties\nRakefile\nrcf/\nrcjakar/\nrcjakar/admin/login.php\nrcLogin/\nrdoc/\nRead\nRead%20Me.txt\nread.me\nRead_Me.txt\nREADME\nReadMe\nReadme\nreadme\nREADME.htm\nREADME.HTML\nREADME.html\nReadMe.html\nReadme.html\nreadme.html\nREADME.MD\nREADME.md\nReadMe.md\nReadme.md\nreadme.md\nreadme.php\nREADME.TXT\nREADME.txt\nReadMe.txt\nReadme.txt\nreadme.txt\nrecentservers.xml\nredmine/\nrefresh\nrefresh.json\nregister.php\nregistration/\nrel/example_project\nrelease.properties\nRELEASE_NOTES.txt\nrelogin\nrelogin.htm\nrelogin.html\nrelogin.php\nrequest.log\nrerun.txt\nreseller\nresources.xml\nresources/\nresources/.arch-internal-preview.css\nresources/fckeditor\nresources/sass/.sass-cache/\nresources/tmp/\nrest-api/\nrest-auth/\nrest/\nrestart\nrestart.json\nrestore.php\nrestricted\nresume\nresume.json\nrevision.inc\nrevision.txt\nrobot.txt\nrobots.txt.dist\nroot/\nRootCA.crt\nrpc/\nrsconnect/\nrst.php\nRushSite.xml\ns.php\nsa.php\nsa2.php\nsales.csv\nsales.log\nsales.sql\nsales.sql.gz\nsales.txt\nsales.xls\nsalesforce.schema\nsample.txt\nsample.txt~\nSaved/\nschema.sql\nschema.yml\nscript/\nscript/jqueryplugins/dataTables/extras/TableTools/media/swf/ZeroClipboard.swf\nscripts\nscripts/\nscripts/ckeditor/ckfinder/core/connector/asp/connector.asp\nscripts/ckeditor/ckfinder/core/connector/aspx/connector.aspx\nscripts/ckeditor/ckfinder/core/connector/php/connector.php\nscripts/setup.php\nsdb.php\nsdist/\nsearchreplacedb2.php\nsearchreplacedb2cli.php\nSecret/\nsecret/\nsecrets/\nsecring.bak\nsecring.pgp\nsecring.skr\nsecure/\nsecurity/\nsendgrid.env\nsentemails.log\nserv-u.ini\nServer\nserver-info\nserver-status/\nserver.cfg\nserver.js\nserver.log\nServer.php\nserver.pid\nserver.xml\nServer/\nserver/config.json\nserver/server.js\nserver_admin_small/\nserver_stats\nServerAdministrator/\nServerList.cfg\nServerList.xml\nservers.xml\nserverStatus.log\nservice-registry/instance-status\nservice-registry/instance-status.json\nservice.asmx\nServiceFabricBackup/\nservices\nservices/\nservices/config/databases.yml\nservlet/\nservlet/%C0%AE%C0%AE%C0%AF\nservlet/Oracle.xml.xsql.XSQLServlet/soapdocs/webapps/soap/WEB-INF/config/soapConfig.xml\nservlet/oracle.xml.xsql.XSQLServlet/soapdocs/webapps/soap/WEB-INF/config/soapConfig.xml\nservlet/Oracle.xml.xsql.XSQLServlet/xsql/lib/XSQLConfig.xml\nservlet/oracle.xml.xsql.XSQLServlet/xsql/lib/XSQLConfig.xml\nservlet/SnoopServlet\nsession/\nsessions/\nsettings.php\nsettings.php.bak\nsettings.php.dist\nsettings.php.old\nsettings.php.save\nsettings.php.swp\nsettings.php.txt\nsettings.php~\nsettings.py\nsettings.xml\nsettings/\nSettings/ui.plist\nsetup\nsetup.data\nsetup.log\nsetup.php\nsetup.sql\nsetup/\nsftp-config.json\nSh3ll.php\nsheep.php\nshell.php\nshell.sh\nshell/\nshellz.php\nshopdb/\nshowcode.asp\nshowlogin/\nsidekiq_monitor\nsign-in\nsign-in/\nsign_in\nsign_in/\nsignin\nsignin.php\nsignin/\nsignup.action\nsimple-backdoor.php\nsimpleLogin/\nsite\nsite.rar\nsite.sql\nsite.tar.gz\nsite.txt\nsite/\nsite/common.xml\nsite_admin\nsiteadmin\nsiteadmin.php\nsiteadmin/\nsiteadmin/index.php\nsiteadmin/login.html\nsiteadmin/login.php\nsitemanager.xml\nsites.ini\nsites.xml\nsites/all/libraries/README.txt\nsites/all/modules/README.txt\nsites/all/themes/README.txt\nsites/example.sites.php\nsites/README.txt\nsized/\nslapd.conf\nsmblogin/\nsnoop.jsp\nsoap/\nsoapdocs/\nsoapdocs/webapps/soap/WEB-INF/config/soapConfig.xml\nsoapserver/\nsource\nsource.php\nsource/\nsource/inspector.html\nsource_gen\nsource_gen.caches\nSourceArt/\nspamlog.log\nspec/\nspec/examples.txt\nspec/lib/database.yml\nspec/lib/settings.local.yml\nspec/reports/\nspec/tmp\nspwd.db\nspy.aspx\nsql-admin/\nsql.inc\nsql.php\nsql.sql\nsql.tar\nsql.tgz\nsql.txt\nsql.zip\nsql/\nsql/index.php\nsql/myadmin/\nsql/php-myadmin/\nsql/phpmanager/\nsql/phpmy-admin/\nsql/phpMyAdmin/\nsql/phpMyAdmin2/\nsql/phpmyadmin2/\nsql/sql-admin/\nsql/sql/\nsql/sqladmin/\nsql/sqlweb/\nsql/webadmin/\nsql/webdb/\nsql/websql/\nsql_dumps\nsql_error.log\nsqladm\nsqladmin\nsqladmin/\nsqlbuddy\nsqlbuddy/\nsqlbuddy/login.php\nsqlmanager/\nsqlmigrate.php\nsqlnet.log\nsqlweb/\nSQLyogTunnel.php\nSqueakDebug.log\nsrc/\nsrc/app.js\nsrc/index.js\nsrc/server.js\nsrv/\nsrv_gen/\nss_vms_admin_sm/\nssh/\nsshadmin/\nst.php\nstacktrace.log\nstaff/\nstamp-h1\nstaradmin/\nstart.html\nstartServer.log\nstat/\nstatic..\nstatic/dump.sql\nstatistics\nstatistics/\nstats\nstats/\nstatus.xsl\nstatus/\nstatus?full=true\nstatusicon/\nstorage/\nstorage/logs/laravel.log\nStreamingStatistics\nstronghold-info\nstronghold-status\nstssys.htm\nStyleCopReport.xml\nstylesheets/bundles\nsub-login/\nsugarcrm.log\nsupe.php\nsuper\nSuper-Admin/\nsuper.php\nsuper1\nsuper1/\nsuper_inde.php\nsuper_index\nsuper_logi.php\nsuper_login\nsuperma.php\nsuperman\nsuperman/\nsupermanage.php\nsupermanager\nsuperuse.php\nsuperuser\nsuperuser.php\nsuperuser/\nsupervise/\nsupervise/Logi.php\nsupervise/Login\nsupervisor/\nsupport_login/\nsurgemail/\nsurgemail/mtemp/surgeweb/tpl/shared/modules/swfupload.swf\nsurgemail/mtemp/surgeweb/tpl/shared/modules/swfupload_f9.swf\nsuspended.page\nsvn.revision\nSVN/\nsvn/\nswagger-resources\nswagger-ui.html\nswagger.json\nswagger.yaml\nswagger/index.html\nswfobject.js\nswfupload\nswfupload.swf\nsxd/\nsxd/backup/\nSym.php\nsYm.php\nsym/\nsym/root/home/\nsymfony/\nsymfony/apps/frontend/config/routing.yml\nsymfony/apps/frontend/config/settings.yml\nsymfony/config/databases.yml\nSymlink.php\nSymlink.pl\nsymphony/\nsymphony/apps/frontend/config/app.yml\nsymphony/apps/frontend/config/databases.yml\nsymphony/config/app.yml\nsymphony/config/databases.yml\nsyncNode.log\nsys-admin/\nsysadm\nsysadm.php\nsysadm/\nsysadmin\nsysadmin.php\nSysAdmin/\nsysadmin/\nSysAdmin2/\nsysadmins\nsysadmins/\nsysbackup\nsysinfo.txt\nsyslog/\nsystem-administration/\nsystem.log\nsystem/\nsystem/cache/\nsystem/cron/cron.txt\nsystem/error.txt\nsystem/expressionengine/config/config.php\nsystem/expressionengine/config/database.php\nsystem/log/\nsystem/logs/\nsystem/storage/\nsystem_administration/\nSystemErr.log\nSystemOut.log\nt00.php\ntar\ntar.bz2\ntar.gz\ntarget\ntarget/\ntconn.conf\ntechnico.txt\ntelephone\ntelphin.log\ntemp-testng-customsuite.xml\ntemp.php\nTEMP/\ntemp/\ntemplate/\ntemplates/\ntemplates/beez/index.php\ntemplates/beez3/\ntemplates/index.html\ntemplates/ja-helio-farsi/index.php\ntemplates/protostar/\ntemplates/rhuk_milkyway/index.php\ntemplates/system/\ntemplates_c/\ntest\ntest-build/\ntest-driver\ntest-output/\ntest-report/\ntest-result\ntest.asp\ntest.aspx\ntest.chm\ntest.htm\ntest.html\ntest.jsp\ntest.mdb\ntest.php\ntest.sqlite\ntest.txt\ntest/\ntest/reports\ntest/tmp/\ntest/version_tmp/\ntest0.php\ntest1\ntest1.php\ntest123.php\ntest2\ntest2.php\ntest3.php\ntest4.php\ntest5.php\ntest6.php\ntest7.php\ntest8.php\ntest9.php\ntest_\ntest_gen\ntest_gen.caches\ntest_ip.php\nTesting\ntestproxy.php\nTestResult.xml\ntests\ntests/\ntests/phpunit_report.xml\ntexinfo.tex\ntextpattern/\nthemes\nthemes/\nthemes/default/htdocs/flash/ZeroClipboard.swf\nThorfile\nThumbs.db\nthumbs.db\nthumbs/\ntimeline.xctimeline\ntiny_mce/\ntiny_mce/plugins/filemanager/examples.html\ntiny_mce/plugins/imagemanager/pages/im/index.html\ntinymce/\nTMP\ntmp\ntmp/\ntmp/2.php\ntmp/access.log\ntmp/access_log\ntmp/admin.php\ntmp/cache/models/\ntmp/cache/persistent/\ntmp/cache/views/\ntmp/cgi.pl\ntmp/Cgishell.pl\ntmp/changeall.php\ntmp/cpn.php\ntmp/d.php\ntmp/d0maine.php\ntmp/domaine.php\ntmp/domaine.pl\ntmp/dz.php\ntmp/dz1.php\ntmp/error.log\ntmp/error_log\ntmp/index.php\ntmp/killer.php\ntmp/L3b.php\ntmp/madspotshell.php\ntmp/nanoc/\ntmp/priv8.php\ntmp/root.php\ntmp/sessions/\ntmp/sql.php\ntmp/Sym.php\ntmp/tests/\ntmp/up.php\ntmp/upload.php\ntmp/uploads.php\ntmp/user.php\ntmp/vaga.php\ntmp/whmcs.php\ntmp/xd.php\nTODO\ntomcat-docs/appdev/sample/web/hello.jsp\ntools\ntools/\ntools/_backups/\ntools/phpMyAdmin/index.php\ntrace\nTrace.axd\nTrace.axd::$DATA\ntrace.json\ntrivia/\ntst\ntwitter/.env\ntxt/\ntypings/\ntypo3\ntypo3/\ntypo3/phpmyadmin/\ntypo3/phpmyadmin/index.php\ntypo3/phpmyadmin/scripts/setup.php\ntypo3_src\ntypo3conf/AdditionalConfiguration.php\ntypo3conf/temp_fieldInfo.php\ntypo3temp/\nuber/\nuber/phpMemcachedAdmin/\nuber/phpMyAdmin/\nuber/phpMyAdminBackup/\nunattend.txt\nup.php\nupdate\nupdate.php\nUPDATE.txt\nupdates\nupfile.php\nUPGRADE\nupgrade.php\nupgrade.readme\nUPGRADE.txt\nUpgradeLog.XML\nupl.php\nUpload\nupload.asp\nupload.aspx\nupload.cfm\nupload.htm\nupload.html\nupload.php\nupload.php3\nupload.shtm\nupload/\nupload/1.php\nupload/2.php\nupload/b_user.csv\nupload/b_user.xls\nupload/loginIxje.php\nupload/test.php\nupload/test.txt\nupload/upload.php\nupload2.php\nupload_backup/\nupload_file.php\nuploaded/\nuploader.php\nuploader/\nuploadfile.asp\nuploadfile.php\nuploadfiles.php\nuploadify.php\nuploadify/\nuploads.php\nuploads/\nuploads/dump.sql\nupstream_conf\nur-admin\nur-admin.php\nur-admin/\nusage/\nuser\nuser.asp\nuser.html\nuser.php\nuser.txt\nuser/\nuser/admin\nuser/admin.php\nuser_guide\nuser_guide_src/build/\nuser_guide_src/cilexer/build/\nuser_guide_src/cilexer/dist/\nuser_guide_src/cilexer/pycilexer.egg-info/\nuser_uploads\nuseradmin\nuseradmin/\nUserFile\nUserFiles\nuserfiles\nuserlogin\nuserlogin.php\nUserLogin/\nusernames.txt\nusers\nusers.csv\nusers.db\nusers.ini\nusers.json\nusers.log\nusers.mdb\nusers.php\nusers.sql\nusers.sql.gz\nusers.sqlite\nusers.txt\nusers.xls\nusers/\nusers/admin\nusers/admin.php\nusr/\nusuario/\nusuarios/\nusuarios/login.php\nutility_login/\nuvpanel/\nuwsgi.ini\nv2/keys/?recursive=true\nvadmind/\nvagrant-spec.config.rb\nVagrantfile\nVagrantfile.backup\nvalidator.php\nvar/\nvar/backups/\nvar/bootstrap.php.cache\nvar/cache/\nvar/log\nvar/log/\nvar/log/authorizenet.log\nvar/log/exception.log\nvar/log/librepag.log\nvar/log/old\nvar/log/payment.log\nvar/log/payment_authorizenet.log\nvar/log/payment_paypal_express.log\nvar/logs/\nvar/package/\nvar/sessions/\nvb.rar\nvb.sql\nvb.zip\nvendor/\nvendor/assets/bower_components\nvendor/bundle\nvendor/composer/installed.json\nvendors/\nvenv.bak/\nvenv/\nversion\nVERSION.txt\nversion.txt\nversion/\nvideo-js.swf\nview-source\nview.php\nvignettes/\nvmailadmin/\nvorod\nvorod.php\nvorod/\nvorud\nvorud.php\nvorud/\nvpn/\nvqmod/checked.cache\nvqmod/logs/\nvqmod/mods.cache\nvqmod/vqcache/\nvtiger/\nvtund.conf\nw.php\nwallet.json\nwar/gwt_bree/\nwar/WEB-INF/classes/\nwar/WEB-INF/deploy/\nwc.php\nwcx_ftp.ini\nweb-app/plugins\nweb-app/WEB-INF/classes\nweb-console/\nweb-console/Invoker\nweb-console/ServerInfo.jsp\nweb-console/status?full=true\nWEB-INF./\nWEB-INF./web.xml\nWEB-INF/\nWEB-INF/config.xml\nWEB-INF/web.xml\nweb.7z\nweb.config\nweb.config.bak\nweb.config.bakup\nweb.config.old\nweb.config.temp\nweb.config.tmp\nweb.config.txt\nweb.config::$DATA\nweb.Debug.config\nweb.rar\nweb.Release.config\nweb.sql\nweb.tar\nweb.tar.bz2\nweb.tar.gz\nweb.tgz\nweb.xml\nweb.zip\nweb/\nweb/bundles/\nweb/phpMyAdmin/\nweb/phpMyAdmin/index.php\nweb/phpMyAdmin/scripts/setup.php\nweb/scripts/setup.php\nweb/uploads/\nwebadmin\nwebadmin.html\nwebadmin.php\nwebadmin/\nwebadmin/admin.html\nwebadmin/admin.php\nwebadmin/index.html\nwebadmin/index.php\nwebadmin/login.html\nwebadmin/login.php\nwebdav.password\nwebdav/\nwebdav/index.html\nwebdav/servlet/webdav/\nwebdb/\nwebgrind\nwebmail/\nwebmail/src/configtest.php\nwebmaster\nwebmaster.php\nwebmaster/\nwebmin/\nwebpack.config.js\nwebsite.git\nwebsql/\nwebstat/\nwebstats.html\nwebstats/\nweixiao.php\nwenzhang\nwheels/\nwhmcs.php\nwhmcs/\nwhmcs/downloads/dz.php\nwiki/\nwizmysqladmin/\nwordpress/\nwordpress/wp-login.php\nworkspace.xml\nworkspace/uploads/\nwp-admin/\nwp-admin/c99.php\nwp-admin/install.php\nwp-admin/setup-config.php\nwp-app.log\nwp-cli.yml\nwp-config.inc\nwp-config.old\nwp-config.php\nwp-config.php.bak\nwp-config.php.dist\nwp-config.php.inc\nwp-config.php.old\nwp-config.php.save\nwp-config.php.swp\nwp-config.php.txt\nwp-config.php~\nwp-content/\nwp-content/backup-db/\nwp-content/backups/\nwp-content/blogs.dir/\nwp-content/cache/\nwp-content/debug.log\nwp-content/mu-plugins/\nwp-content/plugins/adminer/inc/editor/index.php\nwp-content/plugins/count-per-day/js/yc/d00.php\nwp-content/plugins/hello.php\nwp-content/upgrade/\nwp-content/uploads/\nwp-content/uploads/dump.sql\nwp-includes/\nwp-includes/rss-functions.php\nwp-json/\nwp-json/wp/v2/users/\nwp-login.php\nwp-login/\nwp-register.php\nwp.php\nwp.rar/\nwp.zip\nwp/\nwp/wp-login.php\nwpad.dat\nws.php\nws_ftp.ini\nWS_FTP.LOG\nWS_FTP/\nWS_FTP/Sites/ws_ftp.ini\nwsadmin.traceout\nwsadmin.valout\nwsadminListener.out\nwshell.php\nWSO.php\nwso.php\nwso2.5.1.php\nwso2.php\nwstats\nwuwu11.php\nwvdial.conf\nwww-error.log\nwww-test/\nwww.rar\nwww.sql\nwww.tar\nwww.tar.gz\nwww.tgz\nwww.zip\nwww/phpMyAdmin/index.php\nwwwboard/\nwwwboard/passwd.txt\nwwwroot.7z\nwwwroot.rar\nwwwroot.sql\nwwwroot.tar\nwwwroot.tar.bz2\nwwwroot.tar.gz\nwwwroot.tgz\nwwwroot.zip\nwwwstats.htm\nx.php\nxampp/\nxampp/phpmyadmin/\nxampp/phpmyadmin/index.php\nxampp/phpmyadmin/scripts/setup.php\nxcuserdata/\nxd.php\nxferlog\nxiaoma.php\nxlogin/\nxls/\nxml/\nxml/_common.xml\nxml/common.xml\nxmlrpc.php\nxmlrpc_server.php\nxphperrors.log\nxphpMyAdmin/\nxshell.php\nxsl/\nxsl/_common.xsl\nxsl/common.xsl\nxslt/\nxsql/\nxsql/lib/XSQLConfig.xml\nxw.php\nxw1.php\nxx.php\nyaml.log\nyaml_cron.log\nyarn-debug.log\nyarn-error.log\nyarn.lock\nylwrap\nyonetici\nyonetici.html\nyonetici.php\nyonetim\nyonetim.html\nyonetim.php\nyum.log\nzabbix/\nzebra.conf\nzehir.php\nzeroclipboard.swf\nzf_backend.php\nzimbra/\nzone-h.php\n~/\n~admin/\n","tags":""},{"id":"a66a29561f6544297a5ad41a8208193c","title":"Simple XHR function ","content":"function request(url, params, callback) {\n  /*\n  var params = 'pass=' + encodeURIComponent(password.value) +\n               '\u0026encval=' + encodeURIComponent(encval.value) +\n               '\u0026code=' + encodeURIComponent(code.value) +\n               '\u0026username=' + encodeURIComponent(username.value) +\n               '\u0026_xsrf=' + encodeURIComponent(xsrf);\n  */\n  \n  var xhr = new XMLHttpRequest();\n\n  xhr.open('POST', url, true);\n  xhr.setRequestHeader('content-type', 'application/x-www-form-urlencoded');\n\n  xhr.onreadystatechange = function() {\n    if (xhr.readyState == 4) {\n      if (xhr.status == 500) {\n        return callback({\n          'state': 'error',\n          'message': 'There was a problem processing this request.'\n        });\n      }\n      var response = JSON.parse(xhr.responseText);\n      return callback(response);\n    }\n  };\n\n  xhr.send(params);\n}\n","tags":"#js"},{"id":"c88f6dca57f3bc327403c9e042e11ff2","title":"NSQ Questions ","content":"Below is my response to a colleague who was new to NSQ and had some questions about an application he was building.\n\n\u003e Note: bf_nsq is an internal BuzzFeed abstraction on top of pynsq.\n\n---\n\nHeya 👋🏻\n\n\u003e Are there any limits I should be aware of when using BF NSQ? ie. queue size, message size, requeues/max tries, response times, etc.\n\nThe NSQ defaults are (these are IMHO the more important parameters to be aware of)\n\n- topic/channel names have a size restriction of \u003c= 64 characters (used to be 32, see [tcp spec here](https://nsq.io/clients/tcp_protocol_spec.html)).\n- message size 1mb (see `-max-msg-size` in [nsqd docs here](https://nsq.io/components/nsqd.html)).\n- message queue size 1000 (see `-mem-queue-size` in [nsqd docs here](https://nsq.io/components/nsqd.html)).\n\nThe BuzzFeed defaults are effectively the same. You'll find this information in our Ansible configuration (i.e. `ansible/roles/nsqd/templates/nsqd_bootstrap.sh.j2` and the values: `ansible/roles/nsqd/defaults/main.yml`).\n\nAs far as reading/writing of NSQ messages I would suggest reading through the [pynsq docs](https://pynsq.readthedocs.io/en/latest/) (specifically the Reader/Writer classes). I know that bf_nsq is an abstraction on top of pynsq but it's worth getting a bit familiar with what bf_nsq is using 'under the covers'. Hence knowing what you can configure within `nsq.Reader` will help you.\n\n**As an example**: bf_nsq provides `bf_nsq.MultiReader` which is an abstraction for pynsq's `nsq.Reader` class, and any additional keyword args you provide to `bf_nsq.MultiReader` will be passed into the constructor for `nsq.Reader`).Hence knowing what you can configure within `nsq.Reader` will help you.\n\nOne important thing to be aware of is that bf_nsq uses `nsq.Reader` but not `nsq.Writer`. My understanding is that bf_nsq's `publish` method is designed to support batch publishing of messages (something `nsq.Writer` doesn't support). So although you can read the pynsq docs to understand the `nsq.Reader` and `nsq.Writer` classes, you'll only really be able to configure the _reading_ of messages when using bf_nsq.\n\nAlso, bf_nsq doesn't set any reader parameters when creating instances of `nsq.Reader`, so you'll need to check pynsq to see what those defaults are. Although in most cases the defaults are mentioned in the documentation itself, I typically will go directly to the pynsq GitHub code repository to see what the defaults are as I like to get familiar with the code I'm ultimately going to be using, and possibly debugging if things don't work how I expect them to (you'll find the [defaults set here](https://github.com/nsqio/pynsq/blob/master/nsq/reader.py#L138-L154)).\n\nSpecifically you'll find:\n\n- `max_tries`: 5 (the maximum number of attempts the reader will make to process a message after which messages will be automatically discarded)\n- `max_in_flight`: 1 (the maximum number of messages this reader will pipeline for processing.this value will be divided evenly amongst the configured/discovered nsqd producers)\n- `msg_timeout`: None (the amount of time (in seconds) that nsqd will wait before considering messages that have been delivered to this consumer timed out)\n\n\u003e **NOTE**: `msg_timeout` is slightly misleading. In nearly all examples of `nsq.Reader` you'll see `msg_timeout` being provided as a parameter but in fact it will be proxied down into `nsq.AsyncConn` which means you have to look at a different code file to find its default value (you'll find the [default set here](https://github.com/nsqio/pynsq/blob/master/nsq/conn.py#L141)).\n\n\u003e Say a user uploads their Twitter history and a batch of NSQ messages are sent off to trigger tweet deletions. How can I tell when all messages have been processed successfully and ensure that none were dropped or failed?\n\nSo there's two things to consider here:\n\n1. instrumentation\n2. message contents\n\nAs far as I'm aware there is no built-in callback mechanism with either `nsq.Writer` or `bf_nsq.publish` and so you'll want to utilize instrumentation (e.g. bf_metrics) in your application that's reading the messages from NSQ and processing them. That way you'll be able to report whether a message was processed completely or if it needed to be requeued (or maybe even dropped).\n\nNow what I'm about to mention I don't think will affect you as your design is different to what I'm about to describe but I want to say it anyway as it could be a useful thought experiment. If you're using `bf_nsq.publish` to send batched messages to NSQ and some of those messages fail to publish, then you'll get back a list of failed messages. \n\nYou can then decide if you want to try sending those failed messages again, but you'll want to build in some logic that short-circuits the retries after a set threshold has been exceeded (e.g. you don't want to retry the failed messages for the rest of time!) especially if there's some kind of formatting error that would mean they would never succeed.\n\nI brought this up as I had a service (qr_plan_z) that would be given messages that contained log files. I would parse individual log lines from the message contents and then group each log line up into a list to be batch published to NSQ via the `bf_nsq.publish` method. \n\nIf any of those log lines failed and I wanted to requeue them I would be in an awkward situation because I ultimately would have to requeue the entire message and that would mean when my queue reader service (qr_plan_z) received the requeued message, then I'd have to parse the log lines again (even those that were already successfully published). \n\nA queue reader service needs to be performant and so if I didn't just requeue the message (and I kept retrying the failing messages over and over) it would have resulted in my service not being able to context switch to another ioloop task (i.e. handling another incoming message). Not without writing extra logic for forcing a context switch, which would have been a non-trivial piece of work (especially considering the queue reader was using a tornado ioloop that was hidden away inside of pynsq so it's not like I had direct access to it because of how pynsq is designed to be used).\n\nUltimately it was better/easier for me to just requeue the message and suffer the consequence of re-publishing URLs that would have already been published successfully in the hope that the failed messages would go through successfully the second time around. \n\nThis made it even more important for a service upstream of mine that would be consuming these messages to have some form of deduplication logic in place.\n\n\u003e What are some good strategies for handling duplicate requests and avoiding redundant API calls? I saw in your blog that you’ve used Redis to track duplicate requests and rate limit yourself. Can you talk more about this or do you have any examples that I can take a look at?\n\nYou can see examples of using redis for deduplication in qr_plan_z (e.g. `qr_plan_z/app/handler.py#L160-L185`) and you can see examples of using redis for rate limiting in qr_static_fallback_s3 (e.g. `qr_static_fallback_s3/app/ratelimit.py`).\n\nIt's good that you're thinking about deduplicating entries (as tolerance is useful when designing resilient systems) but I wouldn't necessarily worry about my specific implementation, as it's not only old (and not very good) but it's also not going to align with the design of your own service.\n\nYou could (depending on the number of tweets that are expected to be purged) use a simple in-memory data structure to hold state about tweets that have already been seen. Maybe see how far that approach gets you first before spinning up a redis instance. \n\nAdditionally I used redis because there was an expectation (in my use case at least) for messages to 'eventually' need to be reprocessed. What I mean by that was my messages were log files and so those log files might have a URL such as `https://www.buzzfeed.com/videos` multiple times (because multiple users visited that page). I only want to handle the URL once as I was going to grab a static copy of that page and store it into S3 (no point in doing that multiple times right). BUT that page will be updated at some point and I want the latest version of it. So when storing a key into redis I would have a TTL set so that it would auto-expire at a point in future. So let's say the next day I'll get a new bunch of messages and they might include the same `https://www.buzzfeed.com/videos` URL, my queue reader will now check redis, find no key there and reprocess the URL.\n\nDoesn't sound like you have to worry about that sort of set-up because a tweet is a unique entity and so once it has been deleted, you're unlikely to see it pop up again. Unless due to your UI you allow someone to upload a bunch of past tweets, then that way someone might upload the same set of tweets multiple times accidentally (admittedly it wouldn't be the end of the world though if that happened as your logic could account for that by checking the twitter API response so that if it came back with a message like \"tweet not found\" then you can happily just drop that message. Sure it would be an extra API call to twitter, and so that might be important enough to protect by using deduplication in your application).\n\n\u003e If the QR hits a Twitter API rate limit, I think it would make the most sense to save the current user’s remaining deletion requests for later and move onto the next user’s deletion requests since deletion rate limits are per user rather than per app. Should I just keep requeueing that user's remaining requests until their rate limit window refreshes or is there a better way of handling this?\n\nIf you know what the refresh window is, then I believe you could configure NSQ to use a pause duration to match. The `nsq.AsyncConn` class has a `requeue_delay` parameter which you can configure by passing it into the `nsq.Reader` class (as the parameter will be passed down into `nsq.AsyncConn` on your behalf). \n\nLooks like the default value for that is `90` (see [code here](https://github.com/nsqio/pynsq/blob/master/nsq/conn.py#L130)). But be aware the value you provide is not a time period (e.g. it's not 90 seconds). According to the code they describe this feature as...\n\n\u003e When a message on this connection is requeued and the requeue delay has not been specified, it calculates the delay automatically by an increasing multiple of `requeue_delay`.\n\nIf you [look at the code](https://github.com/nsqio/pynsq/blob/master/nsq/conn.py#L514) you can see the calculation it uses.\n\n\u003e Is there a way to ensure that Twitter API requests can only be triggered by trusted sources (UI, job) via NSQ? For example, restricting which services are able to publish to a given topic?\n\nI don't believe there is a built-in mechanism for this, but I could be wrong. I don't know enough about our BuzzFeed 'pixie dust' implementation (which iirc is the abstraction platform layer we've built around NSQ here at BuzzFeed).\n\nI would suggest adding some form of shared secret key, or just contextual data to your message contents such that the service processing the NSQ messages can check if the value is present and if it is you know the message was published from a trusted source.\n\n\u003e I don’t fully understand how to use the max in flight setting. Is there a good rule of thumb for figuring out what that should be for my service?\n\nThe answer will depend on your application throughput. I don't think there's an exact calculation. You'll need to start with a small number, let's say 10, and then monitor your application (message processing latency, observing memory and cpu consumption etc) and then if all looks well then maybe try increasing the value incrementally.\n\nYou should also look at the nsqadmin UI service (and subsequent metrics reported into Datadog) to gauge performance of NSQ such as message depth over time.\n\nPs, there's some \"Design and Theory\" + \"pynsq\" questions in the NSQ FAQ which might be of interest to you as someone new to NSQ (see [FAQ here](https://nsq.io/overview/faq.html#design-and-theory)).\n","tags":"#queues"},{"id":"b097d008e86699ec990bd5f5dfd2e672","title":"Copying Files and Directories ","content":"A trailing slash == copy all files\\\nNo trailing slash == copy the directory\n# copy src directory into the destination directory\n# i.e. you'll end up with compute/src/...\ncp -r src ~/Code/rust/compute/\n\n# copy the 'files' from the src directory into the destination directory\n# i.e. you'll end up with compute/...\n#\n# NOTICE the subtle difference! a trailing slash on src/ will \n# copy the files within that directory rather than the directory as a whole.\ncp -r src/ ~/Code/rust/compute/\n","tags":"#shell"},{"id":"4d3e41b2bd9b69b5732494da1dda2fe3","title":"Go: return a sample (random bool) based on percentage ","content":"// sample returns True randomly at a percentage of the time\nfunc sample(percent int) bool {\n\treturn rand.Intn(100) \u003c percent\n}\n","tags":"#go"},{"id":"7571b0da0ca3da25f1cd170b1030f4a0","title":"Enum Example ","content":"\"\"\"\nthe 'inherit from enum' class approach helps give structure to otherwise\nmuch more verbose constants.\n\nfor example...\n\nRenderMode.HUMAN_READABLE\nRenderMode.STRUCTURED_JSON\n\nvs\n\nRENDER_MODE_HUMAN_READABLE\nRENDER_MODE_STRUCTURED_JSON\n\"\"\"\n\nclass RenderMode(Enum):\n    HUMAN_READABLE = 1\n    STRUCTURED_JSON = 2\n    \nrender_mode = RenderMode.STRUCTURED_JSON if settings.get('PRINT_STRUCTURED_JSON') else RenderMode.HUMAN_READABLE\n    \nif render_mode == RenderMode.HUMAN_READABLE:\n  # print data in human readable format\nelse:\n  # print data for machine consumption\n","tags":"#python"},{"id":"e70714efb70cb2a19ee494c1f252e977","title":"Virtual Environment with venv ","content":"dir := foobar\nroot := $(shell git rev-parse --show-toplevel)\n\n# NOTE:\n# activating the venv via `source` doesn't work so we use the . synonym instead.\nvenv:\n\t@python3 -m venv .venv/rate_control; \\\n\t. .venv/$(dir)/bin/activate; \\\n\tpython3 -m pip install --quiet --upgrade pip; \\\n\tpython3 -m pip install --quiet -r $(root)/$(dir)/scripts/requirements.txt\n\npurge: venv\n\t@. .venv/$(dir)/bin/activate; \\\n\tpython3 $(root)/$(dir)/scripts/...\n\npython3 --version # Python 3.11.3\nls /opt/homebrew/Cellar/python@3.11\nls /opt/homebrew/Cellar/python@3.11/3.11.3/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages\nls /opt/homebrew/lib/python3.11/site-packages # above is an alias to this\n\npython3 -m pip list\n\npython3 -m venv testing-fastly-py-tls-bulk-cert # actually creates a subfolder you need to work within\ncd testing-fastly-py-tls-bulk-cert\nsource bin/activate\npython3 -m pip list\n# from here you can create files in this directory\n# or maybe you want to create them in another directory and just use the currently active venv\ndeactivate\n\n","tags":"#python"},{"id":"ee66b956869784137e54e6e865cfe4ef","title":"Searching files and contents ","content":"The following are native vim solutions to finding files and also searching multiple files for content.\n\nThey require no plugins to be installed.\n\n\u003e Note: at the end of this gist I'll demonstrate some plugins that remove the need to use the native solutions, and in fact I use these plugins for day-to-day vim'ing instead.\n\n- [Finding a single file](#finding-a-single-file)\n- [Finding content within one or more files](#finding-content-within-one-or-more-files)\n  - [Example basic vim configuration](#example-basic-vim-configuration)\n- [Plugins](#plugins)\n\n## Finding a single file\n\nTo find a _single_ file you can use the `:find` Ex command and pass it a wildcard glob character to help search recursively for the specified file pattern.\n\nExample: we want to find a file called `next.config.js`:\n\n```viml\n:find **/next.*.js \n```\n\n\u003e Note: we could have just done `**/next.config.js` but in case you weren't familiar with the filename this helps to narrow things down.\n\n## Finding content within one or more files\n\nYou have two options for locating a string within a file (or multiple files) and that's the following Ex commands...\n\n1. `:vimgrep`\n2. `:lvimgrep`\n\nThe difference is that `lvimgrep` opens the results in a 'location' window and every open split window can have its own location window, while `vimgrep` opens the results in a 'quickfix' window and there can only be one of those shown.\n\nMeaning if you ran `vimgrep` in one split window and then ran it again (e.g. you're looking for something different now) from another window, then your first set of results would be replaced with the latter results. If you instead used `lvimgrep` then you could have multiple search results displayed (one for each split window).\n\nExample: you're looking for every file that has the contents `module.` (e.g. `module.foo`, `module.bar` etc):\n\n```viml\n:lvimgrep 'module\\.' **/*\n```\n\n\u003e Note: I have found that lvimgrep has an empty location window of results which I _think_ is caused by something else in my `.vimrc` file. If you notice a similar issue then you can debug by running vim without your vim configuration (e.g. `vim -u /Users/integralist/.vimrc_basic`).\n\n### Example basic vim configuration\n\n```viml\nset nocompatible number cursorline expandtab hlsearch visualbell tabstop=2 shiftwidth=2\n```\n\n## Plugins\n\nWhile in my day-to-day vim usage I'll use `:FZF` to find files or `:Ack! '\u003cregex\u003e' \u003cpath\u003e` to find files that contain a particular string.\n\n\u003e Note: Although I use the Ack vim plugin I configure it to use the `ag` '[Silver Searcher](https://github.com/ggreer/the_silver_searcher)' shell command.\n\n```viml\n\" Plugin Managment\n\" https://github.com/junegunn/vim-plug#example\n\"\n\" Reload .vimrc and :PlugInstall to install plugins.\n\" Use single quotes as requested by vim-plug.\n\"\n\" Specify a directory for plugins\ncall plug#begin('~/.vim/plugged')\n\nPlug 'junegunn/fzf', { 'dir': '~/.fzf', 'do': './install --all' }\nPlug 'junegunn/fzf.vim' \" Tab to select multiple results\nPlug 'mileszs/ack.vim'\n\n\" Initialize plugin system\ncall plug#end()\n\n\" PLUGIN CONFIGURATION...\n\n\" FZF (search files)\n\"\n\" Shift-Tab to select multiple files\n\"\n\" Ctrl-t = tab\n\" Ctrl-x = split\n\" Ctrl-v = vertical\n\"\n\" We can also set FZF_DEFAULT_COMMAND in ~/.bashrc\n\" Also we can use --ignore-dir multiple times\n\"\n\" Note use :map command to see current mappings (also :vmap, :nmap, :omap).\n\" Can also restrict to specific mapping `:map \u003cLeader\u003ew`\n\" https://vi.stackexchange.com/questions/7722/how-to-debug-a-mapping\nmap \u003cleader\u003ef :FZF\u003cCR\u003e\nmap \u003cleader\u003eb :Buffers\u003cCR\u003e\nset wildignore+=*/.git/*,*/node_modules/*,*/.hg/*,*/.svn/*.,*/.DS_Store \" Files matched are ignored when expanding wildcards\nset wildmode=list:longest,list:full\n\n\" Ack\nlet g:ackprg = 'ag --vimgrep --smart-case --ignore-dir=node_modules'\n```\n","tags":"#vim"},{"id":"38ab8030b353a93105eeb46672cfdf87","title":"Logging Message Format ","content":"`NOUN_STATE` or `NOUN_VERB_STATE`\n","tags":"#logs"},{"id":"4db9ec39ff22ec823ce51eef9dcd2460","title":"gnu sed alternation ","content":"# I wanted to strip lines ending with . followed by five possible values\n# I couldn't do this with macOS BSD sed so used gnu sed\n# But also needed to do some weird unexpected things like...\n#\n# 1. escape the capture group parentheses\n# 2. escape the alternator pipe character\n\ngsed 's/\\.\\(avg\\|count\\|median\\|95percentile\\|max\\)$//'\n","tags":"#shell"},{"id":"97f8b86ebde43a33b27289d7b87ffc0d","title":"Integer precision accuracy vs float ","content":"package main\n\nimport (\n\t\"fmt\"\n\t\"time\"\n)\n\n// nsToMs converts time duration to milliseconds with greater precision than\n// calling .Millisecond() which would only yield integer precision.\nfunc nsToMs(d time.Duration) float64 {\n\treturn float64(d.Nanoseconds()) * float64(1e-6)\n}\n\nfunc main() {\n\t// Define example that demonstrates integer precision\n\ts := time.Now()\n\ttime.Sleep(3 * time.Second)\n\te := time.Now().Sub(s)\n\tfmt.Printf(\"%+v (%T) %+v\\n\\n\", e, e, e.Milliseconds())\n\n\t// Define a float value and see which of the two approachs is more accurate\n\tu, _ := time.ParseDuration(\"3.7ms\")\n\n\t// Approach 1.\n\tfmt.Printf(\"3.7ms parsed value in nanoseconds: %d\\n\", u.Nanoseconds())\n\tfmt.Printf(\"3.7ms parsed value in milliseconds (integer precision): %d\\n\", u.Milliseconds())\n\n\t// Approach 2.\n\tmilliseconds := float64(u.Nanoseconds()) * float64(1e-6)\n\tfmt.Printf(\"3.7ms parsed value in milliseconds (using float): %+v\\n\", milliseconds)\n\n  \t// abstraction for above float precision conversion\n\tfmt.Printf(\"%+v\\n\", nsToMs(u))\n}\n","tags":"#go"},{"id":"bc211ad7f831ecc5e6aee532d7306340","title":"argparse cli flag examples ","content":"import argparse\n\n\ndef main():\n    \"\"\"ArgumentParser adds -h/--help default (add_help=True).\n\n    Documentation:\n        https://docs.python.org/3.8/library/argparse.html#add-help\n\n    Example:\n        in the following example we'll see we must provide the -f/--foo flag,\n        while provided value for -b/--bar flag is stored as integer and not a\n        string (which would otherwise be the default behaviour). we see the\n        -fb/--foobar flag is omitted and so it is assigned a default value,\n        while -z/--baz is omitted and so the default value is None. finally the\n        -bl/--boolean flag demonstrates the correct way to handle values that\n        should be stored as True or False bool types (i.e. if the flag is\n        provided, no value needed, then using action=\"store_true\" will result\n        in the value to be stored as True).\n\n        $ python3 app.py -f 123 --bar 456 --boolean\n        Namespace(bar=456, baz=None, boolean=True, foo='123', foobar='foobar')\n    \"\"\"\n\n    parser = argparse.ArgumentParser(description=\"Example CLI\")\n\n    # mandatory flag + all value types are converted to string\n    parser.add_argument('-f', '--foo', required=True)\n\n    # provide a default value for omitted flag\n    parser.add_argument('-fb', '--foobar', default=\"foobar\")\n\n    # value type converted to integer\n    parser.add_argument('-b', '--bar', type=int)\n\n    # value type always converted to truthy boolean (unlikely what you want)\n    parser.add_argument('-z', '--baz', type=bool, help=\"custom help\")\n\n    # properly handle storing of value as boolean (i.e. stores either True or False)\n    #\n    # the principle is to use either the store_true or store_false actions.\n    #\n    # if you use store_true, then when flag is omitted it's stored as False\n    # if you use store_false, then when flag is omitted it's stored as True\n    parser.add_argument('-bl', '--boolean', action=\"store_true\")\n\n    # parse the script's given arguments\n    args = parser.parse_args()\n\n    print(args)\n\n\nmain()\n","tags":"#python"},{"id":"aa43fe5318318f77a3ae1c4b81c4cf6a","title":"run a macro multiple times ","content":"\" Example 6 line file...\n\"\n\"./foo/requirements.txt\n\"./foo/requirements-to-freeze.txt.txt\n\"./bar/requirements.txt\n\"./bar/requirements-to-freeze.txt.txt\n\"./baz/requirements.txt\n\"./baz/requirements-to-freeze.txt.txt\n\"\n\" We want to swap each line, so it becomes...\n\"\n\"./foo/requirements-to-freeze.txt.txt\n\"./foo/requirements.txt\n\"./bar/requirements-to-freeze.txt.txt\n\"./bar/requirements.txt\n\"./baz/requirements-to-freeze.txt.txt\n\"./baz/requirements.txt\n\"\n\" Steps...\n\"\n\" - record macro (changes are: ddpj), qqddpjq (q starts macro recording, into q register, and end q stops the recording).\n\" - repeat macro a number of times that matches the number of lines we have\n\n6@q\n","tags":"#vim"},{"id":"1efc8dcfc0b1e9e8e8b89a4b2019f3af","title":"Coroutine comparison functions ","content":"\"\"\"the results aren't what you might expect.\"\"\"\n\nimport asyncio\n\n@asyncio.coroutine\ndef old_style_coroutine():\n    yield from asyncio.sleep(1)\n\nasync def main():\n    await old_style_coroutine()\n\nasyncio.iscoroutine(old_style_coroutine)\nFalse\n\nasyncio.iscoroutine(main)\nFalse\n\nasyncio.iscoroutinefunction(old_style_coroutine)\nTrue\n\nasyncio.iscoroutinefunction(main)\nTrue\n\nimport inspect\n\ninspect.iscoroutine(old_style_coroutine)\nFalse\n\ninspect.iscoroutine(main)\nFalse\n\ninspect.iscoroutinefunction(old_style_coroutine)\nFalse\n\ninspect.iscoroutinefunction(main)\nTrue\n\ninspect.isawaitable(old_style_coroutine)\nFalse\n\ninspect.isawaitable(main)\nFalse\n\nasync def foobar():\n    await asyncio.sleep(1)\n\ninspect.isawaitable(foobar)\nFalse\n\ninspect.isawaitable(asyncio.sleep)\nFalse\n","tags":"#python"},{"id":"296bbce573c9dbaed943048f7441154e","title":"Function Timer Decorator ","content":"import functools\nimport time\n\n\ndef timer(func):\n    \"\"\"calculate run time of decorated function.\"\"\"\n\n    @functools.wraps(func)\n    def wrap_timer(*args, **kwargs):\n        start_time = time.perf_counter()  # could also use perf_counter_ns()\n        result = func(*args, **kwargs)\n\n        end_time = time.perf_counter()\n        run_time = end_time - start_time\n        print(run_time)\n        return result\n\n    return wrap_timer\n\n\n@timer\ndef slow_op():\n    print(\"start\")\n    time.sleep(5)\n    print(\"end\")\n    return \"done\"\n\n\nprint(slow_op())\nimport asyncio  # NEW: import asyncio module\nimport functools\nimport time\n\n\ndef timer(func):\n    \"\"\"calculate run time of decorated function.\"\"\"\n\n    @functools.wraps(func)\n    async def wrap_timer(*args, **kwargs):  # NEW: async\n        start_time = time.perf_counter_ns()\n        result = await func(*args, **kwargs)  # NEW: await\n\n        end_time = time.perf_counter_ns()\n        run_time = end_time - start_time\n        print(run_time)\n        return result\n\n    return wrap_timer\n\n\n@timer\nasync def slow_op():  # NEW: async\n    print(\"start\")\n    time.sleep(5)\n    print(\"end\")\n\n\nasyncio.run(slow_op())  # NEW: run async function on event loop\nimport asyncio\nimport functools\nimport time\n\n\ndef timer(metric_name):  # NEW: we're now accepting an argument\n    \"\"\"calculate run time of decorated function.\"\"\"\n\n    def nested_timer(func):  # NEW: basically the wrapping parent function is new and all other code was indented\n        @functools.wraps(func)\n        async def wrap_timer(*args, **kwargs):\n            print(f\"metric_name: {metric_name}\")\n\n            start_time = time.perf_counter_ns()\n            result = await func(*args, **kwargs)\n            end_time = time.perf_counter_ns()\n\n            run_time = end_time - start_time\n            print(run_time)\n\n            return result\n\n        return wrap_timer\n\n    return nested_timer\n\n\n@timer(\"foo.bar\")  # NEW: passing in an argument\nasync def slow_op():\n    print(\"start\")\n    time.sleep(5)\n    print(\"end\")\n\n\nasyncio.run(slow_op())\nimport asyncio\nimport functools\nimport time\n\n\ndef timer(metric_name):\n    \"\"\"calculate run time of decorated function.\"\"\"\n\n    def nested_timer(func):\n        if asyncio.iscoroutinefunction(func):\n            @functools.wraps(func)\n            async def wrap_timer(*args, **kwargs):\n                print(\"async call\")\n                print(f\"metric_name: {metric_name}\")\n\n                start_time = time.perf_counter_ns()\n                result = await func(*args, **kwargs)\n                end_time = time.perf_counter_ns()\n\n                run_time = end_time - start_time\n                print(run_time)\n\n                return result\n        else:\n            @functools.wraps(func)\n            def wrap_timer(*args, **kwargs):\n                print(\"non-async call\")\n                print(f\"metric_name: {metric_name}\")\n\n                start_time = time.perf_counter_ns()\n                result = func(*args, **kwargs)\n                end_time = time.perf_counter_ns()\n\n                run_time = end_time - start_time\n                print(run_time)\n\n                return result\n\n        return wrap_timer\n\n    return nested_timer\n\n\n@timer(\"foo.bar\")\nasync def slow_op(a, b, c):\n    print(a, b, c)\n    print(\"start\")\n    time.sleep(5)\n    print(\"end\")\n\n\nasyncio.run(slow_op(\"A\", \"B\", \"C\"))\n\n\n@timer(\"foo.bar\")\ndef another_slow_op():\n    print(\"start another\")\n    time.sleep(3)\n    print(\"end another\")\n\n\nanother_slow_op()\nimport asyncio\nimport functools\nimport time\n\n\nclass Timer():\n    def __init__(self, metric_name):\n        self.metric_name = metric_name\n\n    def __call__(self, func):\n        \"\"\"decorator implementation.\"\"\"\n\n        if asyncio.iscoroutinefunction(func):\n            @functools.wraps(func)\n            async def wrap_timer(*args, **kwargs):\n                print(\"async call\")\n                print(f\"metric_name: {self.metric_name}\")\n\n                start_time = time.perf_counter_ns()\n                result = await func(*args, **kwargs)\n                end_time = time.perf_counter_ns()\n\n                run_time = end_time - start_time\n                print(run_time)\n\n                return result\n        else:\n            @functools.wraps(func)\n            def wrap_timer(*args, **kwargs):\n                print(\"non-async call\")\n                print(f\"metric_name: {self.metric_name}\")\n\n                start_time = time.perf_counter_ns()\n                result = func(*args, **kwargs)\n                end_time = time.perf_counter_ns()\n\n                run_time = end_time - start_time\n                print(run_time)\n\n                return result\n\n        return wrap_timer\n\n    def __enter__(self):\n        self.start_time = time.perf_counter_ns()\n        return self\n\n    def __exit__(self, *args):\n        end_time = time.perf_counter_ns()\n        run_time = end_time - self.start_time\n        print(run_time)\n\n\ndef timer(metric_name):\n    return Timer(metric_name)\n\n\n@timer(\"foo.bar\")\nasync def slow_op(a, b, c):\n    print(a, b, c)\n    print(\"start\")\n    time.sleep(5)\n    print(\"end\")\n\n\nasyncio.run(slow_op(\"A\", \"B\", \"C\"))\n\n\n@timer(\"foo.bar\")\ndef another_slow_op():\n    print(\"start another\")\n    time.sleep(3)\n    print(\"end another\")\n\n\nanother_slow_op()\n\nwith timer(\"foo.bar\"):\n    print(\"context manager start\")\n    time.sleep(10)\n    print(\"context manager finished\")\n","tags":"#python"},{"id":"69dc115cc31d253961645c8139f25269","title":"Search, filter, cut, sort and get uniques + tee contents ","content":"$ search -- \"bf[_-]metrics\" ./ | cut -d ':' -f 1 | tee /tmp/original_files_list.txt | cut -d '/' -f 1 | sort | uniq \u003e /tmp/services.txt \u0026\u0026 cat /tmp/original_files_list.txt | grep -iE '^packages' | cut -d '/' -f 3 | sort | uniq \u003e /tmp/packages.txt \u0026\u0026 rm /tmp/original_files_list.txt\n","tags":"#shell"},{"id":"752e8620783d7507af9130e1954cf6f7","title":"Python: Asyncio built-in Socket Server ","content":"import asyncio\n\nasync def handle_request(reader, writer):\n    writer.write(\"hello world\".encode())  # needs to be bytes not string\n    writer.close()\n\n\nasync def main():\n    srv = await asyncio.start_server(handle_request, '127.0.0.1', 8081)\n\n    async with srv:\n        await srv.serve_forever()\n\nasyncio.run(main())\n","tags":"#python #python3 #asyncio #server #socket #web #http"},{"id":"354e1267bef43961dd678679f5823669","title":"find and replace content across multiple files ","content":"gsed -i 's/metrics.NewWriter(/metrics.NewLegacyWriter(/' **/*.go\n\n# UPDATE: glob/wildcard doesn't appear to work any more, needs to be individual file streams\n\nfind . -type f -name *.go -exec gsed -i 's/foo/bar/' {} \\;\n\n# You'll need both -e (extended regex support) and -r (allow backreferences like \\1 \\2 etc) for more complex examples:\n\nfind . -type f -name *.go -exec gsed -i -r -e 's/, ErrMissing(.+)/, NewFieldError(\"\\1\")/' {} \\;\nfind . -type f -name *.go -exec gsed -i -r -e 's/(github.com\\/)fastly(\\/customcli\\/)/\\1integralist\\2/' {} \\;\n:argdo %s/metrics.NewWriter(/metrics.NewLegacyWriter(/ge | update\n\n# If I'm working with a file type (like go) that messes with the quickfix window I'll typically pipe the list of files into Vim with no vimrc set.\n# https://comby.dev/\n# https://comby.dev/docs/syntax-reference\n#\n# -match-only -stdout to see what matches it found\n# -newline-separated -stdout to see what replacements it will write\n# -i to modify the files in-place.\n\nCOMBY_M=\"$(cat \u003c\u003c\"MATCH\"\nfmt.Println(:[arguments])\nMATCH\n)\"\n\nCOMBY_R=\"$(cat \u003c\u003c\"REWRITE\"\nfmt.Println(fmt.Sprintf(\"comby says %s\", :[arguments]))\nREWRITE\n)\"\n\ncomby \"$COMBY_M\"  \"$COMBY_R\" -stats -match-newline-at-toplevel -i\n","tags":"#shell #tools"},{"id":"0647b5947005d1faeb2d78f79e5b688d","title":"use control key in norm Ex command ","content":"\" https://vimhelp.org/intro.txt.html#keycodes\n\" https://vimhelp.org/various.txt.html#:norm\n\"\n\" Example: join every two lines\n\"          \n\"          foo\n\"          bar\n\"          baz\n\"          qux\n\"\n\"          becomes:\n\"\n\"          foo bar\n\"          baz qux\n:g/^/exe \"norm \\\u003cs-j\u003e\"\n","tags":"#vim"},{"id":"12610900a78d0880580bb96ac8fb0170","title":"Datadog Python API ","content":"import argparse\nimport concurrent.futures\nimport json\nimport operator\nimport re\n\nfrom datadog import api, initialize\n\noptions = {\n    \"api_key\": \"foo\",\n    \"app_key\": \"foo\"\n}\n\ninitialize(**options)\n\n\ndef pprint(o):\n    \"\"\"pretty print data structures.\"\"\"\n    print(json.dumps(o, indent=2, default=str), \"\\n\")\n\n\ndef format_title(t):\n    \"\"\"print title in a format that makes it stand out visually.\n    example: \"my title\" \u003e \"\\n########\\nMY TITLE\\n########\\n\"\n    \"\"\"\n    hashes = \"#\" * len(t)\n    print(f\"\\n{hashes}\\n{t.upper()}\\n{hashes}\\n\")\n\n\nparser = argparse.ArgumentParser(\n    description=\"Datadog Metric Searcher (searches dashboards and monitors)\")\n\nparser.add_argument(\n    \"-p\", \"--pattern\", default=\".\",\n    help=\"regex pattern for filtering dashboard/monitor by name\")\n\nparser.add_argument(\n    \"-m\",\n    \"--metrics\",\n    help=\"comma-separated list of metrics\",\n    required=True)\n\nparser.add_argument(\n    \"-u\",\n    \"--unused\",\n    help=\"only display unused metrics\",\n    action=\"store_true\")\n\nargs = parser.parse_args()\n\nmetrics = [{\"name\": metric, \"count\": 0}\n           for metric in args.metrics.split(\",\") if metric]\n\n\ndef find_graphs(\n        widgets,\n        dashboard_title,\n        dashboard_url,\n        metrics,\n        matches=None):\n    \"\"\"recursively search dashboard graphs for those referencing our metrics.\n\n    Note: widgets can be nested multiple times, so this is a recursive function.\n\n    because this function is run in isolation within its own process we pass in\n    the dashboard title/url so we can report back within the main/parent process\n    which dashboard the graphs are associated with (as the results are received\n    based on which process is quickest to complete). we also pass in a list of\n    metrics to be looked up in the dashboards/graphs, as we can't manipulate the\n    metric list (defined in the parent process) from within a child process.\n    \"\"\"\n\n    if not matches:\n        matches = {}\n\n    for widget in widgets:\n        definition = widget.get(\"definition\")\n\n        if definition[\"type\"] != \"note\":\n            requests = definition.get(\"requests\")\n\n            \"\"\"\n            example data:\n            {\n              \"style\": {\n                \"palette\": \"green_to_orange\",\n                \"palette_flip\": false\n              },\n              \"group\": [],\n              \"title\": \"Hosts\",\n              \"node_type\": \"container\",\n              \"no_metric_hosts\": true,\n              \"scope\": [\n                \"$cluster\",\n                \"rig.service:user_auth_proxy\"\n              ],\n              \"requests\": {\n                \"fill\": {\n                  \"q\": \"avg:process.stat.container.io.wbps{$cluster,rig.service:user_auth_proxy} by {host}\"\n                }\n              },\n              \"no_group_hosts\": true,\n              \"type\": \"hostmap\"\n            }\n            \"\"\"\n\n            if requests:\n                for request in requests:\n                    metric_query = None\n                    log_query = None\n                    process_query = None\n\n                    \"\"\"\n                    the following if statement catches 'hostmap' graphs\n                    whose requests key is a dict, not list[dict]\n                          \"requests\": {\n                            \"fill\": {\n                              \"q\": \"...\"\n                            }\n                          }\n                    \"\"\"\n                    if isinstance(requests, dict) and request == \"fill\":\n                        metric_query = requests.get(request, {}).get(\"q\")\n                    else:\n                        try:\n                            metric_query = request.get(\"q\")\n                        except AttributeError as err:\n                            continue\n\n                        log_query = request.get(\n                            \"log_query\", {}).get(\n                            \"search\", {}).get(\"query\")\n                        process_query = request.get(\n                            \"process_query\", {}).get(\"metric\")\n\n                    if metric_query:\n                        query = metric_query\n                    elif log_query:\n                        query = log_query\n                    elif process_query:\n                        query = process_query\n                    else:\n                        query = None\n\n                    if not query:\n                        continue\n\n                    for metric in metrics:\n                        if metric[\"name\"] in query:\n                            metric[\"count\"] += 1\n\n                            graph_title = definition.get(\"title\", \"N/A\")\n                            match = matches.get(graph_title)\n\n                            if not match:\n                                matches[graph_title] = []\n                                match = matches[graph_title]\n\n                            match.append({\n                                \"metric\": query,\n                                \"type\": definition[\"type\"],\n                            })\n            else:\n                nested_widgets = definition.get(\"widgets\", [])\n\n                # recurse and ignore the dashboard title/url and metrics\n                # as from this stage of the function we don't care about them\n                _, _, _, d = find_graphs(\n                    nested_widgets,\n                    dashboard_title,\n                    dashboard_url,\n                    metrics,\n                    matches\n                )\n\n                matches.update(d)\n\n    return dashboard_title, dashboard_url, metrics, matches\n\n\ndef all_dashboards():\n    \"\"\"acquire all dashboards.\"\"\"\n\n    return api.Dashboard.get_all()\n\n\ndef all_monitors():\n    \"\"\"acquire all monitors.\"\"\"\n\n    return api.Monitor.get_all()\n\n\ndef dashboard_get(dashboard: dict):\n    \"\"\"acquire dashboard by the given ID.\"\"\"\n\n    return api.Dashboard.get(dashboard[\"id\"])\n\n\ndef filter_dashboards(dashboards):\n    \"\"\"filter dashboards by pattern provided by -p/--pattern flag.\"\"\"\n\n    filtered_dashboards = []\n\n    for dashboard in dashboards[\"dashboards\"]:\n        if re.search(args.pattern, dashboard[\"title\"], flags=re.IGNORECASE):\n            filtered_dashboards.append(\n                {\n                    \"title\": dashboard[\"title\"],\n                    \"id\": dashboard[\"id\"],\n                    \"url\": dashboard[\"url\"],\n                }\n            )\n\n    return sorted(filtered_dashboards, key=operator.itemgetter(\"title\"))\n\n\ndef filter_monitors(monitors):\n    \"\"\"filter monitors by pattern provided by -p/--pattern flag.\"\"\"\n\n    filtered_monitors = []\n\n    for monitor in monitors:\n        if re.search(args.pattern, monitor[\"name\"], flags=re.IGNORECASE):\n            filtered_monitors.append(\n                {\"name\": monitor[\"name\"],\n                 \"url\": f\"https://\u003cYOUR_ORG\u003e.datadoghq.com/monitors/{monitor['id']}\",\n                 \"query\": monitor[\"query\"], })\n\n    return sorted(filtered_monitors, key=operator.itemgetter(\"name\"))\n\n\ndef process():\n    \"\"\"asynchronously acquire dashboards and update metric count.\n\n    Note: the Datadog API is not asynchronous, so we must run API operations\n    within a threadpool, while also running the metric 'searching' algorithm\n    (a cpu heavy operation) within a processpool to help speed up the overall\n    program execution time.\n    \"\"\"\n\n    if not args.unused:\n        format_title(\"metrics to find\")\n        pprint(metrics)\n\n    dashboards = None\n    monitors = None\n\n    with concurrent.futures.ThreadPoolExecutor() as executor:\n        wait_for = [\n            executor.submit(all_dashboards),\n            executor.submit(all_monitors)\n        ]\n\n        for f in concurrent.futures.as_completed(wait_for):\n            \"\"\"identify which api finished first and assign to correct variable.\n            dashboard api returns a dictionary, while monitors returns a list.\n            \"\"\"\n\n            results = f.result()\n\n            if isinstance(results, dict):\n                dashboards = results\n            else:\n                monitors = results\n\n    if args.pattern == \".\":\n        ld = len(dashboards['dashboards'])\n        lm = len(monitors)\n        d = f\"{ld} dashboards\"\n        m = f\"{lm} monitors\"\n        msg = f\"\\nno search pattern provided, meaning we'll search ALL {d} and {m}!\\n\"\n        print(msg)\n\n    filtered_dashboards = filter_dashboards(dashboards)\n    filtered_monitors = filter_monitors(monitors)\n\n    dashboards_metadata = []\n    track_dashboard_metrics = {}\n\n    with concurrent.futures.ThreadPoolExecutor() as executor:\n        wait_for = [\n            executor.submit(dashboard_get, dashboard)\n            for dashboard in filtered_dashboards\n        ]\n\n        for f in concurrent.futures.as_completed(wait_for):\n            dashboards_metadata.append(f.result())\n\n    if not args.unused:\n        format_title(\"dashboards\")\n\n    with concurrent.futures.ProcessPoolExecutor() as executor:\n        metrics_copy = metrics.copy()  # avoid accidental mutation\n        wait_for = [\n            executor.submit(\n                find_graphs,\n                dashboard[\"widgets\"],\n                dashboard[\"title\"],\n                dashboard[\"url\"],\n                metrics_copy) for dashboard in dashboards_metadata]\n\n        for f in concurrent.futures.as_completed(wait_for):\n            title, url, metrics_mod, matches = f.result()\n            if matches:\n                if not args.unused:\n                    print(title, \"\\n\")\n                    print(f\"https://\u003cYOUR_ORG\u003e.datadoghq.com{url}\\n\")\n                    pprint(matches)\n                    print(\"---------\\n\")\n\n            for metric in metrics_mod:\n                if not track_dashboard_metrics.get(metric[\"name\"]):\n                    track_dashboard_metrics.update({metric[\"name\"]:\n                                                    metric[\"count\"]})\n                else:\n                    track_dashboard_metrics[metric[\"name\"]] += metric[\"count\"]\n\n    unused_dashboard_metrics = set()\n    unused_monitor_metrics = set()\n    used_monitor_metrics = set()\n\n    if not args.unused:\n        format_title(\"unused metrics in dashboards\")\n\n    for metric, count in track_dashboard_metrics.items():\n        if count == 0:\n            unused_dashboard_metrics.add(metric)\n            print(metric)\n\n    if not args.unused:\n        format_title(\"monitors\")\n\n    for monitor in filtered_monitors:\n        for metric in metrics:\n            if metric[\"name\"] in monitor[\"query\"]:\n                if not args.unused:\n                    print(monitor[\"name\"], \"\\n\")\n                    print(monitor[\"url\"], \"\\n\")\n                    print(monitor[\"query\"], \"\\n\")\n                    print(\"---------\\n\")\n\n                used_monitor_metrics.add(metric[\"name\"])\n            else:\n                unused_monitor_metrics.add(metric[\"name\"])\n\n    # avoid scenario where one monitor does reference the metric\n    # but a latter monitor DOES NOT reference it. when that happens\n    # we want to ensure we remove the metric name so it doesn't\n    # accidentally get marked later as being unused.\n    for metric in used_monitor_metrics:\n        try:\n            unused_monitor_metrics.remove(metric)\n        except KeyError:\n            pass\n\n    if not args.unused:\n        format_title(\"unused metrics in monitors\")\n\n        for m in unused_monitor_metrics:\n            print(m)\n\n    format_title(\"unused metrics in monitors and dashboards\")\n\n    unused_metrics = unused_dashboard_metrics.intersection(\n        unused_monitor_metrics)\n\n    for m in unused_metrics:\n        print(m)\n\n    print(f\"\\n{len(unused_metrics)} out of {len(metrics)} metrics are unused.\")\n\n\nif __name__ == '__main__':\n    process()\nfrom datadog import api, initialize\n\noptions = {\n    \"api_key\": \"foo\",\n    \"app_key\": \"bar\"\n}\n\ninitialize(**options)\n\nresult = api.Dashboard.get_all()\n\ndate_ordered = sorted(result[\"dashboards\"], key=lambda d: d[\"modified_at\"])\n\nfor dashboard in date_ordered:\n    print(f'{dashboard[\"title\"]}: {dashboard[\"modified_at\"]}')\n\n","tags":"#python"},{"id":"4e2f323f29ceb624f7fd540687d8e74f","title":"Python: Context and ContextVars ","content":"import contextvars\n\n\"\"\"\nImportant: Context Variables should be created at the top module level and never in closures. \nContext objects (we'll see in the next file) hold strong references to context variables.\nScoped ContextVars prevents those context variables from being properly garbage collected.\n\"\"\"\n\nvar = contextvars.ContextVar(\"foo\")\n\nvar.get(\"foo\")  # 'foo' (no value is set, so we just get the 'name' of the variable back)\n\n\"\"\"\nNOTE:\n\nNaming the variable `var` is actually a bit confusing/misleading. \nIt should really be named after the value it will contain.\nA more practical example would be `id = contextvars.ContextVar(\"id\")`.\nThen you would do `id.set(\"123\")`\n\nBut for the sake of testing this code in a REPL, I opted for just naming it `var` instead.\n\"\"\"\n\ntoken = var.set(\"bar\")\ntoken.old_value  # \u003cToken.MISSING\u003e\n\nvar.get(\"foo\")  # 'bar'\n\ntoken2 = var.set(\"baz\")\ntoken.old_value  # 'bar'\n\nvar.get(\"foo\")  # 'baz'\n\nvar.reset(token2)\nvar.get(\"foo\")  # 'bar'\n\nvar.reset(token)\nvar.get(\"foo\")  # 'foo' (i.e. no value)\n\n\"\"\"\nNOTE:\n\nI could have reset `var` in a different order.\nI didn't have to reset using `token2` then `token`.\nI could have reset using `token` first, then `token2`.\nDoing that would have meant `var` would still have a value set of 'bar' (as per `token2.old_value`)\n\nThe following code presumes the latter was done (i.e. `token2` was used as the last `var.reset()` token)\n\"\"\"\n\"\"\"\nIn the following code we look at the contextvars.Context object, which is a mapping of ContextVars to their values.\n\nWhenever you import the contextvars module you'll find that there is 'default' Context created.\n\nIf you set a ContextVar in any modules that have imported the contextvars module, then you'll discover the\ndefault Context is shared between modules and so it'll show the same ContextVar across all modules.\n\nYou can access the default Context by taking a copy of it (see below).\n\nIt's important to realize that defining a ContextVar will not mean it shows up in the Context _unless_ \nyou set a value onto the ContextVar. Because the following code presumes the earlier code in file 1. \nwas executed, it means we can see the 'foo' ContextVar that was set.\n\"\"\"\n\nctx = contextvars.copy_context()  # \u003cContext at 0x106e23840\u003e\n\nlist(ctx.keys())  # [\u003cContextVar name='foo' at 0x106f52590\u003e]\nlist(ctx.items())  # [(\u003cContextVar name='foo' at 0x106f52590\u003e, 'bar')]\n\n\"\"\"\nContext() creates an empty context with no values in it.\n\"\"\"\n\nnewctx = contextvars.Context()  # \u003cContext at 0x106fa2ac0\u003e\n\nlist(newctx.items())  # []\n\n\"\"\"\nChanges can be made to a Context's ContextVar(s) if modified via the contextvars.Context().run() method\n\nThe following code snippet presumes a fresh environment (no previous Context or ContextVars)...\n\"\"\"\n\nvar = contextvars.ContextVar('foo')\nvar.set('bar')\n\ndef scope():\n    var.set('baz')\n    print(var.get('foo'))  # 'baz'\n    print(ctx.get(var))  # 'baz'\n    return \"finished\"\n\nctx = contextvars.copy_context()\n\nlist(ctx.items())  # [(\u003cContextVar name='foo' at 0x1025a1450\u003e, 'bar')]\n\nresult = ctx.run(scope)  # 'finished'\n\n\"\"\"\nNOTE:\n\nIf you're just doing a WRITE operation then pass the `.set()` method to `.run()`\n\ne.g. ctx.run(var.set, 'baz')\n\"\"\"\n\nlist(ctx.items())  # [(\u003cContextVar name='foo' at 0x1025a1450\u003e, 'baz')]\n\nvar.get('foo')  # 'bar'\n\n\"\"\"\nUnforunately the object model is a bit crappy and so it's not easy to get at the internal ContextVars a Context holds.\n\nI wrote a quick lookup function to help with that...\n\"\"\"\n\nimport contextvars\nfrom typing import Optional\n\n\ndef lookup(ctx: contextvars.Context, key: str) -\u003e Optional[str]:\n    for i, v in list(ctx.items()):\n        if i.name == key:\n            return v\n    return None\n  \nlookup(ctx, \"foo\")  # 'bar'\n\"\"\"\nI wanted to try and mimick something like golang's context.Context \nwhich is built-in to their http server by default.\n\nI'm sort of surprised Python hasn't tried to copy that approach?\n\nWe've got three files in this example...\n\n1. ctx.py: abstraction for contextvars module\n2. foo.py: random module for generating an ID\n3. app.py: web server module using asyncio\n\"\"\"\n\n# ctx.py\n#\nimport contextvars\nfrom typing import Optional\n\n\ndef lookup(ctx: contextvars.Context, key: str) -\u003e Optional[str]:\n    for i, v in list(ctx.items()):\n        if i.name == key:\n            return v\n    return None\n\n\ndef new() -\u003e contextvars.Context:\n    return contextvars.Context()\n\n\n# foo.py\n#\nimport asyncio\nimport contextvars\nimport os\nimport random\n\nid: contextvars.ContextVar = contextvars.ContextVar('id')\n\n\ndef gen_id():\n    uid = str(os.urandom(15))\n    print(\"uid:\", uid)\n    id.set(uid)\n\n\nasync def bar(ctx: contextvars.Context):\n    ctx.run(gen_id)\n    r = random.randint(5, 10)\n    print(f\"sleep for: {r} seconds\")\n    await asyncio.sleep(r)\n\n\n# app.py\n#\nimport asyncio\n\nimport ctx\nimport foo\n\n\nasync def handle_request(reader, writer):\n    c = ctx.new()\n    await foo.bar(c)\n    writer.write(f\"result: {ctx.lookup(c, 'id')}\".encode())\n    writer.close()\n\n\nasync def main():\n    srv = await asyncio.start_server(handle_request, '127.0.0.1', 8081)\n\n    async with srv:\n        await srv.serve_forever()\n\nasyncio.run(main())\n\u003e Context variables are variables that can have different values depending on their context. They are similar to Thread-Local Storage in which each execution thread may have a different value for a variable. However, with context variables, there may be several contexts in one execution thread. The main use case for context variables is keeping track of variables in concurrent asynchronous tasks. -- https://realpython.com/python37-new-features/#context-variables\n\n```python\n\"\"\"Example copied verbatim from Real Python.\"\"\"\n\nimport contextvars\n\nname = contextvars.ContextVar(\"name\")\ncontexts = list()\n\ndef greet():\n    print(f\"Hello {name.get()}\")\n\n# Construct contexts and set the context variable name\nfor first_name in [\"Steve\", \"Dina\", \"Harry\"]:\n    ctx = contextvars.copy_context()\n    ctx.run(name.set, first_name)\n    contexts.append(ctx)\n\n# Run greet function inside each context\nfor ctx in reversed(contexts):\n    ctx.run(greet)\n```\n","tags":"#python #python3 #context #contextvars"},{"id":"ff4d3d93d2ff71ea5ab33a091713c053","title":"Go: Developing local golang module ","content":"\u003e Copied verbatim from https://brokencode.io/how-to-use-local-go-modules-with-golang-with-examples/ so all credit goes to that author. I'm just gisting this content for my own future reference so I don't have to go locate it again.\n\n## Importing local modules in main.go\n\nSo first we simply have to convert all of our directories into go modules. For that we need to add a go.mod at the root of every directories.\nThen inside of that go.mod give them whatever name that we want as module name. but bear in mind that it has to be an url. In my example I put this:\n\n`module example.org/hello` in the go.mod for the hello directory\n`module example.org/utils` in the go.mod for the utils directory\n\nThe import makes a bit more sense now huh ? but we are not done yet.\n\n## The replace keyword\n\nThis is where the magic happens, go.mod files have a few keywords that can be very useful, one of them is replace what replace does is that it takes a module path (eg : example.org/hello) and replaces it with a direct or relative path.\n\nhere’s the syntax for the replace keyword :\n\n```\nreplace url.com/of/the/module =\u003e /direct/path/to/files\n```\n\nNote that replace also works with relative paths.\n\n## The main go.mod\n\n```\nmodule example.com/localmodexample\n\ngo 1.13\n\nrequire (\n   example.org/hello v0.0.0\n   example.org/utils v0.0.0\n\n)\n\nreplace (\n   example.org/hello =\u003e ./hello\n   example.org/utils =\u003e ./utils\n)\n```\n\nUsually go module dependencies work with versions, so to use local go modules with golang you have to set v0.0.0\n\nFinally after the require, I just tell the compiler that those urls are local and can be found in the same directory under ./hello and ./utils. The great thing about this main go.mod file is that now even the utils module will know where to find the hello module because the url have been replaced.\n","tags":"#go #dependencies"},{"id":"8d01300efcd2006c69e8b9492c0eada8","title":"Vim: search and replace content using native vim cdo and cfdo commands ","content":"There are two 'types' to be aware of with a quickfix window:\n\n1. entry: the actual _line_ content (e.g. `:grep foo` will show a specific line that matched within a file).\n2. file: the actual _file_ itself (e.g. the path to the file that contained the match).\n\nTo replace content using vim (via the quickfix window) you need to choose whether you want to apply the change via the quickfix 'entry' or via the 'file' as a whole.\n\nIf you use `cdo`, then your 'action' (i.e. how you're going to _replace_ content) will be applied to every _entry_ in the quickfix window.\n\nIf you use `cfdo`, then your action will be applied to each _file_ in the quickfix window. \n\n## tl;dr\n\nUsing `cdo` is more straight forward, but `cfdo` is probably more efficient/performant.\n\n## Difference?\n\nTo understand the difference, let's consider an example scenario:\n\nWe have quickfix window that has two files:\n\n1. `example1.txt`\n2. `example2.txt` \n\nThe file `example1.txt` shows up multiple times, while `example2.txt` only shows up once. \n\nThe file `example1.txt` shows up multiple times because we searched for a phrase such as `foo` and that phrase happened to appear multiple times within `example1.txt`, while it only appeared once within `example2.txt`.\n\nIf you wanted to replace `foo` with `bar` using a subtitution like `s/foo/bar/`, and you used `cdo`, then all occurences of `foo` would be replaced because the substitution would be executed across each _entry_ in the quickfix window. But if you used `cfdo` then the substitution would only be applied once to the _file_ because you didn't use `%` (e.g. `:%s/foo/bar/` meaning apply the substitution across the entire buffer) so only the first line of the file would have the substitution applied. \n\nYou could still use `cfdo` but you would need to specify `%`.\n\n\u003e **NOTE**: I've found that my quickfix window is updated frequently/dynamically when using certain build tools (e.g. vim-go with gopls), in this case I'm better off using `cfdo` with `%s/foo/bar/e | update` which will write the buffer once, rather than the multiple times compared to `cdo` with `s/foo/bar/e | update`. It's also much more efficient using `cfdo` as it won't write the buffer multiple times.\n\n## Examples\n\nTo execute a substitution for every 'entry' listed in the quickfix window use `cdo`:\n\n```\n:cdo s/v2/v3/ | update\n```\n\nTo execute a macro for every 'file' listed in the quickfix window, you would still use `cdo` and not `cfdo`! This is interesting because you might expect the macro to execute across the entire file, but remember that macros only execute once and if you need them to be executed multiple times then you need to tell them to execute across a 'range' (e.g. the entire buffer or a section of lines). So by using `cdo` instead it means you can rely on the macro being executed against every _instance_ of the thing you're searching for (even if it appears multiple times within a file).\n\n```\n:cdo execute \"norm @q\" | update\n```\n","tags":"#vim #replace #macro #quickfix"},{"id":"a694cd1c562debbe1521dfadfc8be428","title":"Go: Deleting go package tagged versions from pkg.go.dev ","content":"There are various issues open about this:\n\n- https://github.com/golang/go/issues/38848#issuecomment-669945306\n- https://github.com/golang/go/issues/37106#issuecomment-690419151\n- https://github.com/golang/go/issues/36811#issuecomment-579404726\n\nIt seems the process is to get information about your package (e.g. go-fastly) from an endpoint like the following:\n\nhttps://proxy.golang.org/github.com/fastly/go-fastly/@v/master.info\n\n```\n{\"Version\":\"v1.15.1-0.20200611145936-5f794c8e3c37\",\"Time\":\"2020-06-11T14:59:36Z\"}\n```\n\nThen use the 'Version' in the following endpoint:\n\nhttps://pkg.go.dev/github.com/fastly/go-fastly/master@v1.15.1-0.20200611145936-5f794c8e3c37\n\nBut that didn't work for me. I then noticed they suggest visiting:\n\n```\npkg.go.dev/\u003cimport-path\u003e@\u003csemantic-version\u003e\n```\n\nSo something like:\n\nhttps://pkg.go.dev/github.com/fastly/go-fastly/v2@v2.1.0\n\nBut that just shows me the existing tagged version, where as we're trying to remove deleted tagged versions from pkg.go.dev.\n","tags":"#go"},{"id":"47e0f8f848ea67f93fc29b754f02cca7","title":"Go: Named Return Zero Value ","content":"Go's return values may be named. If so, they are treated as variables defined at the top of the function.\n\nThese names should be used to document the meaning of the return values.\n\nA return statement without arguments returns the named return values. This is known as a \"naked\" return.\n\nNaked return statements should be used only in short functions. They can harm readability in longer functions.\n\n```go\npackage main\n\nimport \"fmt\"\n\nfunc do() (b bool) {\n    // var b bool \u003c\u003c imagine the compiler added this\n\treturn\n}\n\nfunc main() {\n\tfmt.Println(do()) // false\n}\n```\n\nHere's a real example of using the 'zero' value properties of named returns.\n\nIn this example we have a `GetString` which will return a default value if a key isn't found. It does this by internally calling `GetStringDefault` and passing it the named return variable `val` that `GetString` has defined.\n\n```go\npackage main\n\nimport (\n\t\"fmt\"\n)\n\nfunc GetString(key string) (val string) {\n\t// 'named' return value are initialized to their zero value\n\t// meaning we can proxy the zero value through to a nested function\n\t//\n\treturn GetStringDefault(key, val)\n}\n\nfunc GetStringDefault(key string, defaultValue string) string {\n\tm := map[string]string{\n\t\t\"foo\": \"bar\",\n\t\t\"abc\": \"xyz\",\n\t}\n\n\tv, ok := m[key]\n\tif !ok {\n\t\treturn defaultValue\n\t}\n\treturn v\n}\n\nfunc main() {\n\tdefaultValue := \"no key found\"\n\t\n\t// if you care about getting a default value back\n\t// then use the GetStringDefault function\n\t//\n\tfmt.Println(GetStringDefault(\"foo\", defaultValue)) // bar\n\tfmt.Println(GetStringDefault(\"abc\", defaultValue)) // xyz\n\tfmt.Println(GetStringDefault(\"xxx\", defaultValue)) // no key found\n\n\t// if you don't care about getting a default value back\n\t// then use the GetString function, and you'll now get back a zero value\n\t//\n\tfmt.Println(GetString(\"foo\")) // \"bar\"\n\tfmt.Println(GetString(\"abc\")) // \"xyz\"\n\tfmt.Println(GetString(\"xxx\")) // \"\" \u003c\u003c zero value for type string\n}\n```\n","tags":"#go"},{"id":"9a3027470353be5e89c385f4d6954680","title":"Make: environment variables and passing values to make target ","content":"In the following example the value of `beep` will only be used when there is no existing `TF_LOG` data anywhere.\n\n```makefile\nTF_LOG ?= \"beep\"\nrun:\n\techo $(TF_LOG)\n\tenv | grep -i tf_log\n```\n\nExample run:\n\n```bash\n$ export TF_LOG=test # set TF_LOG in the parent shell\n                     # make will copy this when spinning up a new shell (when running a makefile target) \n\n$ make run\necho test\ntest\nenv | grep -i tf_log\nTF_LOG=test # value of 'beep' was overridden by the parent shell environment\n                                                                                                                                                                                           $ make run -e TF_LOG=trace\necho trace\ntrace\nenv | grep -i tf_log\nMAKEFLAGS=e -- TF_LOG=trace\nTF_LOG=trace # value of 'beep' AND parent shell environment was overridden by make's -e flag (which sets env var within the child shell process it spins up)\n                                                                                                                                                                                          \n$ make run TF_LOG=trace\necho trace\ntrace\nenv | grep -i tf_log\nMAKEFLAGS=TF_LOG=trace\nTF_LOG=trace # value of 'beep' AND parent shell environment was overridden by passing TF_LOG=trace as a makefile 'argument'.\n                                                                                                                                                                                           $ TF_LOG=trace make run\necho trace\ntrace\nenv | grep -i tf_log\nTF_LOG=trace # value of 'beep' AND parent shell environment was overridden by passing TF_LOG=trace as command scoped environment var.\n                                                                                                                                                                                           $ unset TF_LOG  # to demonstrate when 'beep' will be used\n                # as TF_LOG doesn't exist in current shell (so Makefile can't copy it)\n                # nor do we pass in TF_LOG via -e flag or pre/post make target itself\n\n$ make run\necho \"beep\"\nbeep\nenv | grep -i tf_log\nmake: *** [run] Error 1\n```\n","tags":"#make #makefile #args #env #vars"},{"id":"ed24ece9ee958b873b5cedb28ce8aa84","title":"Terminal: Colors ","content":"# Problem\n\nVim in terminal mode must be used with a terminal emulator theme in order to work properly with some vim themes!\n\nVim in terminal mode uses the 16 color codes provided by the terminal emulator.\n\nThis will result in different styles than those defined by the Vim theme you're using and could make it appear that there is a problem with the Vim theme while the actual problem are missing colors coming from the terminal theme.\n\n# Terminal Colors\n\nThere exists common confusion about terminal colors. This is what we have right now:\n\n- Plain ASCII\n- ANSI escape codes: 16 color codes with bold/italic and background\n- 256 color palette: 216 colors + 16 ANSI + 24 gray (colors are 24-bit)\n- 24-bit true color: \"888\" colors (aka 16 milion)\n\n```bash\nprintf \"\\x1b[${bg};2;${red};${green};${blue}m\\n\"\n```\n\nThe 256-color palette is configured at start and is a 666-cube of colors,\neach of them defined as a 24-bit (888 rgb) color.\n\nThis means that current support can only display 256 different colors in the\nterminal while \"true color\" means that you can display 16 million different\ncolors at the same time.\n\nTruecolor escape codes do not use a color palette. They just specify the\ncolor itself.\n\nThis is a good test case:\n\n```bash\nprintf \"\\x1b[38;2;255;100;0mTRUECOLOR\\x1b[0m\\n\"\n```\n\n- or\n  https://raw.githubusercontent.com/JohnMorales/dotfiles/master/colors/24-bit-color.sh\n- or http://github.com/robertknight/konsole/tree/master/tests/color-spaces.pl\n- or https://git.gnome.org/browse/vte/tree/perf/img.sh\n- or just run this:\n\n```sh\nawk 'BEGIN{\n    s=\"/\\\\/\\\\/\\\\/\\\\/\\\\\"; s=s s s s s s s s;\n    for (colnum = 0; colnum\u003c77; colnum++) {\n        r = 255-(colnum*255/76);\n        g = (colnum*510/76);\n        b = (colnum*255/76);\n        if (g\u003e255) g = 510-g;\n        printf \"\\033[48;2;%d;%d;%dm\", r,g,b;\n        printf \"\\033[38;2;%d;%d;%dm\", 255-r,255-g,255-b;\n        printf \"%s\\033[0m\", substr(s,colnum+1,1);\n    }\n    printf \"\\n\";\n}'\n```\n\nKeep in mind that it is possible to use both ';' and ':' as Control Sequence\nIntroducer delimiters.\n\nAccording to Wikipedia[1], this behavior is only supported by xterm and konsole.\n\n[1] https://en.wikipedia.org/wiki/ANSI_color\n\nSince\n[ncurses-6.0-20180121](http://lists.gnu.org/archive/html/bug-ncurses/2018-01/msg00045.html),\nterminfo began to support the 24-bit True Color capability under the name of\n\"RGB\". You need to use the \"setaf\" and \"setab\" commands to set the foreground\nand background respectively.\n\n# True Color Detection\n\nThere will be no reliable way to detect the \"RGB\" flag until the new release of\nterminfo/ncurses. S-Lang author added a check for $COLORTERM containing either\n\"truecolor\" or \"24bit\" (case sensitive). In addition,\n[VTE](https://bugzilla.gnome.org/show_bug.cgi?id=754521),\n[Konsole](https://bugs.kde.org/show_bug.cgi?id=371919) and\n[iTerm2](https://gitlab.com/gnachman/iterm2/issues/5294) set this variable to\n\"truecolor\". It has been in VTE for a while and but is relatively new, being\nstill git-only in Konsole and iTerm2).\n\nThis is obviously not a reliable method, and is not forwarded via sudo, SSH etc.\nHowever, whenever it errs, it errs on the safe side. It does not advertise\nsupport when it is actually supported. App developers can freely choose to\ncheck for this same variable, or introduce their own method (e.g. an option in\ntheir config file). They should use whichever method best matches the overall\ndesign of their app. Checking $COLORTERM is recommended though since it will\nlead to a more seamless desktop experience where only one variable needs to be\nset. This would be system-wide so that the user would not need to set it\nseparately for each app.\n\n## Querying The Terminal\n\nA more reliable method in an interactive program which can read terminal\nresponses, and one that is transparent to things like sudo, SSH, etc.. is to\nsimply try setting a truecolor value and then query the terminal to ask what\ncolor it currently has. If the response replies the same color that was set\nthen it indicates truecolor is supported.\n\n```bash\n$ (echo -e '\\e[48:2:1:2:3m\\eP$qm\\e\\\\' ; xxd)\n\n^[P1$r48:2:1:2:3m^[\\\n00000000: 1b50 3124 7234 383a 323a 313a 323a 336d  .P1$r48:2:1:2:3m\n```\n\nHere we ask to set the background color to `RGB(1,2,3)` - an unlikely default\nchoice - and request the value that we just set. The response comes back that\nthe request was understood (`1`), and that the color is indeed `48:2:1:2:3`.\nThis tells us also that the terminal supports the colon delimiter. If instead,\nthe terminal did not support truecolor we might see a response like\n\n```\n^[P1$r40m^[\\\n00000000: 1b50 3124 7234 306d 1b5c 0a              .P1$r40m.\\.\n```\n\nThis terminal replied the color is `40` - it has not accepted our request to\nset `48:2:1:2:3`.\n\n```\n^[P0$r^[\\\n00000000: 1b50 3024 721b 5c0a                      .P0$r.\\.\n```\n\nThis terminal did not even understand the DECRQSS request - its response was\n`0$r`. We do not learn if it managed to set the color, but since it doesn't\nunderstand how to reply to our request it is unlikely to support truecolor\neither.\n\n# Terminals + True Color\n\n## Now **Supporting** True Color\n\n- [st](http://st.suckless.org/) (from suckless) [delimeter: semicolon] -\n  http://lists.suckless.org/dev/1307/16688.html\n- [xst](https://github.com/gnotclub/xst/) - fork of st\n- [konsole](http://kde.org/applications/system/konsole/) [delimeter: colon,\n  semicolon] - https://bugs.kde.org/show_bug.cgi?id=107487\n- [iTerm2](http://www.iterm2.com/) [delimeter: colon, semicolon] - since v3\n  version\n- [Therm](https://github.com/trufae/Therm) [delimeter: colon, semicolon] - fork\n  of iTerm2\n- [qterminal](https://github.com/lxqt/qterminal) [delimeter: semicolon] -\n  https://github.com/qterminal/qterminal/issues/78\n- [alacritty](https://github.com/jwilm/alacritty) [delimeter: semicolon] -\n  written in Rust\n- [kitty](https://github.com/kovidgoyal/kitty) [delimeter: colon,semicolon] -\n  uses OpenGL\n- [cool-retro-term](https://github.com/Swordfish90/cool-retro-term) [delimeter:\n  semicolon]\n- [mosh](https://mosh.org/) (Mobile SHell) [delimeter: semicolon] - since commit\n  https://github.com/mobile-shell/mosh/commit/6cfa4aef598146cfbde7f7a4a83438c3769a2835\n- [pangoterm](http://www.leonerd.org.uk/code/pangoterm/) [delimeter:\n  colon, semicolon]\n- [Termux](https://termux.com/) [delimeter: semicolon] - **Android platform**\n- [ConnectBot](https://connectbot.org/) - **Android platform** - since\n  https://github.com/connectbot/connectbot/commit/3bcc75ccedaf2136b04c5932c81a5155f29dc3b5\n- [Black Screen](https://github.com/shockone/black-screen) [delimeter:\n  semicolon] - crossplatform, HTML/CSS/JS-based\n- [hterm](https://chromium.googlesource.com/apps/libapps/+/master/hterm) -\n  HTML/CSS/JS-based (ChromeOS)\n- [PuTTY](http://www.chiark.greenend.org.uk/~sgtatham/putty/) -\n  [landed](https://git.tartarus.org/?p=simon/putty.git;a=commit;h=a4cbd3dfdb71d258e83bbf5b03a874c06d0b3106)\n  in git (patched version [3] {xterm-like approximation to 256 colors} and [4]\n  {real true colors} available) - **Windows platform**\n- [Tera Term](http://en.sourceforge.jp/projects/ttssh2/) [delimeter: colon,\n  semicolon] - **Windows platform**\n- [ConEmu](https://github.com/Maximus5/ConEmu) [delimeter: semicolon] -\n  **Windows platform**\n- [Windows\n  Powershell](https://en.wikipedia.org/wiki/PowerShell#PowerShell_5.1)\n  [delimeter: semicolon] - aka Powershell 5.x and below **Windows 10**\n- [Powershell Core](https://github.com/PowerShell/PowerShell) [delimeter:\n  semicolon] aka Powershell 6+ **Windows 10**\n- [cmd.exe](https://en.wikipedia.org/wiki/Cmd.exe) [delimeter:\n  semicolon] Builtin Windows shell that is mostly unchanged since DOS **Windows 10**\n- [FinalTerm](http://finalterm.org/) [delimeter: semicolon] -\n  **[abandoned](http://worldwidemann.com/finally-terminated/)**, iTerm2\n  [borrowing it's ideas and features](http://iterm2.com/shell_integration.html).\n- [MacTerm](https://github.com/kmgrant/macterm) [delimeter: semicolon] - **Mac\n  OS X platform**\n- [mintty](https://mintty.github.io/) [delimeter: semicolon] **Cygwin and\n  MSYS/MSYS2** since commit\n  https://github.com/mintty/mintty/commit/43f0ed8a46c6549cb9a3ea27abc057b5abe13bdb\n  (2.0.1 release) - **Windows platform**\n- [MobaXterm](http://mobaxterm.mobatek.net/) **Windows platform** - closed\n  source (run `lscolors` to see a truecolor test)\n- [ZOC](https://www.emtec.com/zoc/index.html) **Windows/OS X platform** - closed\n  source since\n  [7.19.0 version](http://www.emtec.com/downloads/zoc/zoc_changes.txt)\n- [upterm](https://github.com/railsware/upterm) *Windows/Macos/Linux Electron* -\n  A terminal emulator for the 21st century.\n- Windows 10 bash console, since\n  [Windows Insiders build 14931](https://blogs.msdn.microsoft.com/commandline/2016/09/22/24-bit-color-in-the-windows-console/)\n- all [libvte](http://ftp.gnome.org/pub/GNOME/sources/vte/) based terminals\n  (since 0.36 version) [delimeter: colon, semicolon] -\n  https://bugzilla.gnome.org/show_bug.cgi?id=704449\n  - **libvte**-based\n    [Gnome Terminal](https://help.gnome.org/users/gnome-terminal/stable/)\n  - **libvte**-based [sakura](http://www.pleyades.net/david/projects/sakura)\n  - **libvte**-based\n    [xfce4-terminal](http://docs.xfce.org/apps/terminal/start) - since\n    [0.6.90](https://github.com/xfce-mirror/xfce4-terminal/releases/tag/xfce4-terminal-0.6.90)\n    release, if compiled with GTK+3\n  - **libvte**-based\n    [Terminator](http://gnometerminator.blogspot.com/p/introduction.html) -\n    since [1.90](https://launchpad.net/terminator/+announcement/14358) release\n  - **libvte**-based [Tilix](https://github.com/gnunn1/tilix) - written in D.\n    Similar user interface as for Terminator.\n  - **libvte**-based [Lilyterm](http://lilyterm.luna.com.tw/) - since commit\n    https://github.com/Tetralet/LilyTerm/commit/72536e7ba448ad9ef1126ce45fbde3a3407a271b\n  - **libvte**-based [ROXTerm](http://roxterm.sourceforge.net/)\n  - **libvte**-based [evilvte](http://www.calno.com/evilvte/) - no release yet,\n    version from git https://github.com/caleb-/evilvte\n  - **libvte**-based [Termit](https://github.com/nonstop/termit)\n  - **libvte**-based [Termite](https://github.com/thestinger/termite)\n  - **libvte**-based [Tilda](https://github.com/lanoxx/tilda)\n  - **libvte**-based [tinyterm](https://code.google.com/p/tinyterm)\n  - **libvte**-based\n    [Pantheon Terminal](https://launchpad.net/pantheon-terminal)\n  - **libvte**-based [lxterminal](http://sourceforge.net/projects/lxde) - with\n    **--enable-gtk3** configure flag.\n  - **libvte**-based [guake](http://guake-project.org/) - A top-down terminal for GNOME\n\nThere are a bunch of libvte-based terminals for GTK2, so they are listed in the\nanother section.\n\nAlso, while this one is not a terminal, but a terminal replayer, it is\nstill worth mentioning:\n\n- [asciinema](http://asciinema.org) player:\n  https://github.com/asciinema/asciinema-player\n\n## Improper Support for True Color\n\n- [mlterm](http://mlterm.sourceforge.net) - built with **--with-gtk=3.0**\n  configure flag. Approximates colors to 512 embedded palette\n  (https://sourceforge.net/p/mlterm/bugs/74/)\n\n## Terminals that parse ANSI color sequences, but approximate them to 256 palette\n\n- xterm (but doing it wrong: \"it uses nearest color in RGB color space,\n  with a usual false assumption about orthogonal axes\")\n- [urxvt aka rxvt-unicode](http://software.schmorp.de/pkg/rxvt-unicode.html) -\n  since\n  [Revision 1.570](http://cvs.schmorp.de/rxvt-unicode/src/command.C?revision=1.570\u0026view=markup\u0026sortby=log\u0026sortdir=down)\n  http://lists.schmorp.de/pipermail/rxvt-unicode/2016q2/002261.html (Note there\n  is a restriction of colors count still)\n- linux console (since v3.16):\n  https://github.com/torvalds/linux/commit/cec5b2a97a11ade56a701e83044d0a2a984c67b4\n\nNote about color differences:\na) RGB axes are not orthogonal, so you cannot use\nsqrt(R^2+G^2+B^2) formula\nb) for color differences there is more correct (but\nmuch more complex)\n[CIEDE2000](http://en.wikipedia.org/wiki/Color_difference#CIEDE2000) formula\n(which may easily blow up performance if used blindly) [2].\n\n[2] https://github.com/neovim/neovim/issues/793#issuecomment-48106948\n\n## Terminal multiplexers\n\n- [tmux](http://tmux.github.io/) - starting from version 2.2 (support since\n  [427b820...](https://github.com/tmux/tmux/commit/427b8204268af5548d09b830e101c59daa095df9))\n- [screen](http://git.savannah.gnu.org/cgit/screen.git/) - has support in\n  'master' branch, need to be enabled (see 'truecolor' option)\n- [pymux](https://github.com/jonathanslenders/pymux) - tmux clone in pure Python\n  (to enable truecolor run pymux with `--truecolor` option)\n- [dvtm](https://github.com/martanne/dvtm) - not yet supporting True Color\n  https://github.com/martanne/dvtm/issues/10\n\n## **NOT Supporting** True Color\n\n- [Terminal.app](https://en.wikipedia.org/wiki/Terminal_(macOS)): Macos Terminal builtin\n- [Terminology](https://www.enlightenment.org/about-terminology)\n  (Enlightenment) - https://phab.enlightenment.org/T746\n- [Hyper.app](https://hyper.is/) [delimeter: semicolon] - crossplatform,\n  HTML/CSS/JS-based (Electron) https://github.com/zeit/hyper/issues/2294\n- [Cmder](https://cmder.net/): Portable console emulator for Windows,\n  based on ConEmu.\n- [Terminus](https://github.com/Eugeny/terminus):\n  highly configurable terminal emulator for Windows, macOS and Linux\n- [mrxvt](https://sourceforge.net/projects/materm) (looks abandoned) -\n  https://sourceforge.net/p/materm/feature-requests/41/\n- [aterm](http://www.afterstep.org/aterm.php) (looks abandoned) -\n  https://sourceforge.net/p/aterm/feature-requests/23/\n- [fbcon](https://www.kernel.org/doc/Documentation/fb/fbcon.txt) (from linux\n  kernel) - https://bugzilla.kernel.org/show_bug.cgi?id=79551\n- FreeBSD console - https://bugs.freebsd.org/bugzilla/show_bug.cgi?id=191652\n- [yaft](https://github.com/uobikiemukot/yaft) framebuffer terminal -\n  https://github.com/uobikiemukot/yaft/issues/12\n- [KiTTY](http://www.9bis.net/kitty/) - **Windows platform**\n- [MTPuTTY](ttyplus.com) - **Windows platform**\n- [mRemoteNG](https://mremoteng.org/) - **Windows platform** -\n  https://github.com/mRemoteNG/mRemoteNG/issues/717\n- [JuiceSSH](https://juicessh.com/) - **Adroid platform**, closed source\n- [Termius](https://www.termius.com/) - **Linux, Windows, OS X platforms**,\n  closed source\n- [SmarTTY](http://smartty.sysprogs.com/) - **Windows platform** - closed source\n  (sent them a request)\n- [Netsarang XShell](https://www.netsarang.com/products/xsh_overview.html) -\n  closed source (sent them an email)\n- libvte and GTK2 - based:\n  - **libvte**-based [GTKTerm2](http://gtkterm.feige.net/)\n  - **libvte**-based [stjerm](https://github.com/stjerm/stjerm) (looks\n    abandoned) - https://github.com/stjerm/stjerm/issues/39\n\n# Console Programs + True Color\n\n## Console Programs Supporting True Color\n\n- [s-lang](http://lists.jedsoft.org/lists/slang-users/2015/0000020.html)\n  library - (since pre2.3.1-35, for 64bit systems)\n- [ncurses](https://www.gnu.org/software/ncurses/) library - since 6.1 version\n- [Eternal Terminal](https://mistertea.github.io/EternalTCP/) - automatically\n  reconnecting shell\n- [mc](http://www.midnight-commander.org) - since\n  [682a5...](http://www.midnight-commander.org/changeset/682a5116edd20b8ba81743a1f7495c883b0ce644).\n  See also [ticket #3724](http://www.midnight-commander.org/ticket/3724) for\n  truecolor themes.\n- [irssi](https://github.com/irssi/irssi) - since\n  [PR #48](https://github.com/irssi/irssi/pull/48)\n- [neovim](https://github.com/neovim/neovim) - since commit\n  [8dd415e887923f99ab5daaeba9f0303e173dd1aa](https://github.com/neovim/neovim/commit/8dd415e887923f99ab5daaeba9f0303e173dd1aa);\n  need to set\n  [termguicolors](https://neovim.io/doc/user/options.html#%27termguicolors) to\n  enable true color.\n- [vim](https://github.com/vim/vim) - (from 7.4.1770); need to set\n  [termguicolors](https://github.com/vim/vim/blob/master/runtime/doc/version8.txt#L202)\n  to enable true color.\n- [joe](https://sf.net/p/joe-editor) - (from\n  [4.5](https://sourceforge.net/p/joe-editor/news/2017/09/joe-45-released/)\n  version)\n- [emacs](https://www.gnu.org/software/emacs/) - since\n  [26.1 release](https://lists.gnu.org/archive/html/emacs-devel/2018-05/msg00765.html)\n- [micro editor](https://micro-editor.github.io/)\n- [elinks](http://repo.or.cz/w/elinks.git) -\n  [configure.in:1410](http://repo.or.cz/w/elinks.git/blob/HEAD:/configure.in#l1410)\n  (./configure --enable-true-color)\n- [tcell](https://github.com/gdamore/tcell) library for Go language\n- [timg](https://github.com/hzeller/timg) - Terminal Image Viewer\n- [tv](https://github.com/daleroberts/tv) - tool to quickly view high-resolution\n  multi-band imagery directly in terminal\n- [termimage](https://github.com/nabijaczleweli/termimage) - terminal image\n  viewer\n- [explosion](https://github.com/Tenzer/explosion) - terminal image viewer\n- [ls-icons](https://github.com/sebastiencs/ls-icons) - fork of coreutils with\n  `ls` program that supports icons\n- [mpv](https://github.com/mpv-player/mpv) - video player with support of\n  console-only output (since 0.22 version)\n- [radare2](https://github.com/radare/radare2) - reverse engineering franework;\n  since 0.9.6 version.\n\n## Console Programs Not Supporting True Color\n\n- mutt (email client) - http://dev.mutt.org/trac/ticket/3674\n- neomutt (email client) - https://github.com/neomutt/neomutt/issues/85\n- termbox library - https://github.com/nsf/termbox/issues/37\n- mcabber (jabber client) -\n  https://bitbucket.org/McKael/mcabber-crew/issue/126/support-for-true-color-16-millions-colors\n- tig (git TUI) - https://github.com/jonas/tig/issues/227\n- cmus (music player) - https://github.com/cmus/cmus/issues/799\n- weechat (chat client) - https://github.com/weechat/weechat/issues/1364\n- scim (spreadsheet program) - https://github.com/andmarti1424/sc-im/issues/306\n- [gui.cs](https://github.com/migueldeicaza/gui.cs) Terminal UI toolkit for .NET\n  (curses-like) - https://github.com/migueldeicaza/gui.cs/issues/48\n","tags":"#terminal #colors"},{"id":"9975d87f2aef9bd1f3e6fcfdf23f75dd","title":"Python: install package directly for the interpreter Vim is using ","content":"Sometimes Vim's Python binary can't find a package you've installed.\n\n- in vim  \n  `:py3 import sys; print(sys.path)`\n\n- navigate to that location and find the python binary, in my case:  \n  `cd /usr/local/opt/python@3.8/Frameworks/Python.framework/Versions/3.8/bin`\n\n- install isort using this binary  \n  `./python3.8 -m pip install isort`\n","tags":"#vim #python"},{"id":"d6e750eb89d4a3e97bed37b80abe6e4d","title":"Shell: Curl to JSON ","content":"# https://daniel.haxx.se/blog/2020/03/17/curl-write-out-json/\n#\ncurl --write-out '%{json}' https://example.com -svo /dev/null | jq\n\n{\n    \"url_effective\": \"https://example.com/\",\n    \"method\": \"GET\",\n    \"http_code\": 200,\n    \"response_code\": 200,\n    \"http_connect\": 0,\n    \"time_total\": 0.365787,\n    \"time_namelookup\": 0.001746,\n    \"time_connect\": 0.002049,\n    \"time_appconnect\": 0.27916,\n    \"time_pretransfer\": 0.279358,\n    \"time_starttransfer\": 0.365528,\n    \"size_header\": 351,\n    \"size_request\": 75,\n    \"size_download\": 1256,\n    \"size_upload\": 0,\n    \"speed_download\": 3441,\n    \"speed_upload\": 0,\n    \"content_type\": \"text/html; charset=UTF-8\",\n    \"num_connects\": 1,\n    \"time_redirect\": 0.0,\n    \"num_redirects\": 0,\n    \"ssl_verify_result\": 0,\n    \"proxy_ssl_verify_result\": 0,\n    \"filename_effective\": \"/dev/null\",\n    \"remote_ip\": \"93.184.216.34\",\n    \"remote_port\": 443,\n    \"local_ip\": \"127.0.0.1\",\n    \"local_port\": 61028,\n    \"http_version\": \"1.1\",\n    \"scheme\": \"HTTPS\",\n    \"curl_version\": \"libcurl/7.72.0 SecureTransport zlib/1.2.11\"\n}\n","tags":"#curl #bash #shell #json"},{"id":"7e6342f53056257d375a8f525120802b","title":"Shell: Google Doc Code Syntax Highlighting ","content":"```bash\nbrew install highlight\n```\n\nNow copy some code to your clipboard, followed by running:\n\n```bash\npbpaste | highlight --syntax=go -O rtf | pbcopy\n```\n\n\u003e Note: don't 'copy' the above bash code, manually type it, otherwise you'll end up trying to syntax highlight the line of bash! lulz on me for doing exactly that :facepalm:\n\nNow paste your clipboard into your Google doc.\n","tags":"#google #doc #code #syntax #brew #highlight"},{"id":"428cb45b94290c72adc5c9e5af27a58f","title":"Python: tornado logging when request has completed ","content":"\"\"\"\nThat Application.log_request approach uses very explicit naming, \nand yet the tornado docs for RequestHandler.on_finish says...\n\n\u003e Override this method to perform cleanup, logging, etc.\n\nSo there’s two ways to essentially do the same thing 🤔\n\nMy understanding for the difference would be log_request is useful for \ngeneric logging behaviour, while on_finish could be customized per \nrequest handler.\n\nNOTE: log_request completes first, then on_finish\n\"\"\"\n\nimport asyncio\n\nimport tornado.ioloop\nimport tornado.web\n\n\nclass MainHandler(tornado.web.RequestHandler):\n    def initialize(self, *args, **kwargs):\n        print(\"initialize:\", args, kwargs)\n\n    def prepare(self):\n        self.ctx = {}\n        print(\"prepare:\", self.ctx)\n\n    async def get(self):\n        self.write(\"Hello, world\")\n        self.ctx[\"abc\"] = 123\n        await asyncio.sleep(2)\n        print(\"get:\", self.ctx)\n\n    def on_finish(self):\n        self.ctx[\"xyz\"] = 456\n        print(\"finish:\", self.ctx)\n\n\ndef make_app():\n    class App(tornado.web.Application):\n\t\t\"\"\"subclass tornado web application so we can override log_request.\n        \n        DOCUMENTATION:\n        https://www.tornadoweb.org/en/stable/web.html#tornado.web.Application.log_request\n        \"\"\"\n        \n        def log_request(self, handler: tornado.web.RequestHandler) -\u003e None:\n            print(\"log stuff\")\n\n    # return tornado.web.Application([\n    #     (r'/', MainHandler, {\"beep\": 123, \"boop\": 456}),\n    # ])\n\n    return App([\n        (r'/', MainHandler, {\"beep\": 123, \"boop\": 456}),\n    ])\n\n\nif __name__ == '__main__':\n    app = make_app()\n    app.listen(9000)\n    tornado.ioloop.IOLoop.current().start()\n","tags":"#python #logs"},{"id":"48d35050d5342bb7568f04183b81ca29","title":"[go struct with mutex to encapsulate data from users and help hide required lock implementation] ","content":"package proxy\n\nimport (\n\t\"fmt\"\n\t\"io/ioutil\"\n\t\"log\"\n\t\"os\"\n\t\"path/filepath\"\n\t\"strconv\"\n\t\"strings\"\n\t\"sync\"\n)\n\n// ErrorCodes defines status codes as keys for custom error pages.\ntype ErrorCodes map[int][]byte\n\n// ErrorHosts defines hosts as keys for supported error codes.\ntype ErrorHosts map[string]ErrorCodes\n\n// ErrorPages contains custom error pages for host domains by status code.\ntype ErrorPages struct {\n\tmu    sync.RWMutex\n\tpages ErrorHosts\n}\n\n// Store sets a given HTML string within the pages map by host/status code.\nfunc (ep *ErrorPages) Store(host string, status int, buf []byte) {\n\tep.mu.Lock()\n\tdefer ep.mu.Unlock()\n\n\tif !ep.HasHost(host) {\n\t\tep.pages[host] = make(ErrorCodes)\n\t}\n\n\tep.pages[host][status] = buf\n}\n\n// Get retrieves HTML string associated with the given host/status code.\nfunc (ep *ErrorPages) Get(host string, status int) ([]byte, bool) {\n\tep.mu.RLock()\n\tdefer ep.mu.RUnlock()\n\n\tif !ep.HasHost(host) {\n\t\treturn nil, false\n\t}\n\n\tif _, ok := ep.pages[host][status]; !ok {\n\t\treturn nil, false\n\t}\n\n\treturn ep.pages[host][status], true\n}\n\n// HasHost returns true/false to indicate if pages map contains the given host.\nfunc (ep *ErrorPages) HasHost(host string) bool {\n\t_, ok := ep.pages[host]\n\treturn ok\n}\n\n// newErrorPages reads the file system and stores the contents of each custom\n// error page into an in-memory cache.\n//\n// example directory structure:\n//\n// static/\n//   foo.com/\n//     400.html\n//     404.html\n//     410.html\n//     500.html\n//   bar.com/\n//     404.html\n//     500.html\n//   baz.com/\n//     404.html\n//     500.html\nfunc newErrorPages(parentDir string) *ErrorPages {\n\tvar host string\n\n\tep := new(ErrorPages)\n\tep.pages = make(ErrorHosts)\n\n\troot := \"/app/static/\"\n\tskip := \"static\"\n\n\tfilepath.Walk(root, func(path string, info os.FileInfo, err error) error {\n\t\tif info.IsDir() \u0026\u0026 info.Name() == skip {\n\t\t\treturn nil\n\t\t}\n\n\t\t// track the host so we can ensure the following files are added under it.\n\t\tif info.IsDir() {\n\t\t\thost = info.Name()\n\t\t\treturn nil\n\t\t}\n\n\t\t// at this point we know we're dealing with a file and not a directory\n\t\tcontent, err := ioutil.ReadFile(path)\n\t\tif err != nil {\n\t\t\tlog.Fatal(err)\n\t\t}\n\n\t\t// extract status code from filename and populate pages map with file contents.\n\t\tstatusKey, _ := strconv.Atoi(strings.Split(info.Name(), \".html\")[0])\n\n\t\tfmt.Println(host, path, statusKey)\n\t\tep.Store(host, statusKey, content)\n\n\t\treturn nil\n\t})\n\n\treturn ep\n}\ntype A struct {\n    mu sync.Mutex\n}\n\na := \u0026A{}\n\na.mu.Lock()\ndefer a.mu.Unlock()\n\na.Something()\n\n// VS\n\nvar hits struct {\n    sync.Mutex\n    n int\n}\n\nhits.Lock()\nhits.n++\nhits.Unlock()\n","tags":"#go #golang #struct #mutex #concurrency #encapsulation"},{"id":"7cb06ccb8a06b774f0f65ae2dfe8cb65","title":"[Python standard library HTTP request example] ","content":"# https://docs.python.org/3/library/http.client.html#examples\n\nurl = \"https://www.example.com/foo?id=123\"\nu = urllib.parse.urlparse(url)\nconn = http.client.HTTPSConnection(u.netloc)\nconn.request(\"GET\", f\"{u.path}?{u.query}\")\nresp = conn.getresponse()\nprint(resp.read())\n\n","tags":"#python3 #standard #library #stdlib #http #client #request"},{"id":"8a2aaf1d8b1706a10049c52c15d305f0","title":"linefeed and carriage return ","content":"\u003e The term **CRLF** refers to Carriage Return (ASCII 13, `\\r`) Line Feed (ASCII 10, `\\n`). They're used to note the termination of a line, however, dealt with differently in today's popular Operating Systems.\n\n- Windows: CRLF (`\\r\\n`)\n- Linux/Unix: LF (`\\n`)\n\nImagine in vim you have a buffer like:\n\n```\na\nb\nc\nd\n```\n\nIf you wanted to add an extra line space between each line, so it looked like:\n\n```\na\n\nb\n\nc\n\nd\n\n\n```\n\n\u003e Note: my example is based on me running Vim on macOS.\n\nYou would need to use a substitution like:\n\n```viml\n:%s/\\n/\\r\\r/\n```\n\nNotice you're looking for a 'line feed' `\\n` (because that's how macOS denotes a new line), while to get Vim to insert a line break I need it to _insert_ two separate 'carriage returns' `\\r`.\n","tags":"#vim"},{"id":"1191d4fa185f43d67f03500100bae5c3","title":"Runtime Profiler ","content":"package main\n\nimport (\n\t\"runtime\"\n\t\"time\"\n\n\t\"buzzfeed/metrics\"\n)\n\ntype starter interface {\n\tStart() error\n}\n\ntype stopper interface {\n\tStop() error\n}\n\n// Profiler is a type which emits metrics to a metrics.Writer for memory metrics\n// relating to the garbage collector and overall resource usage.\ntype Profiler interface {\n\tstarter\n\tstopper\n}\n\n// NewProfiler creates a new Profiler that records metrics on an interval\nfunc NewProfiler(metricWriter metrics.Writer, interval time.Duration) Profiler {\n\treturn \u0026profiler{\n\t\tmetricWriter: metricWriter,\n\t\tinterval:     interval,\n\t\tch:           make(chan struct{}),\n\t}\n}\n\ntype profiler struct {\n\tmetricWriter metrics.Writer\n\tinterval     time.Duration\n\tch           chan struct{}\n}\n\nfunc (p *profiler) Start() error {\n\tgo p.profilerLoop()\n\treturn nil\n}\n\nfunc (p *profiler) Stop() error {\n\tclose(p.ch)\n\treturn nil\n}\n\nfunc (p *profiler) profilerLoop() {\n\tticker := time.NewTicker(p.interval)\n\n\tfor {\n\t\tselect {\n\t\tcase \u003c-p.ch:\n\t\t\tticker.Stop()\n\t\t\treturn\n\t\tcase \u003c-ticker.C:\n\t\t\tp.emitStats()\n\t\t}\n\t}\n}\n\nfunc (p *profiler) emitStats() {\n\t// See the MemStats docs for the meaning of the various stats recorded\n\t// below:\n\t//\n\t// https://golang.org/pkg/runtime/#MemStats\n\n\tm := \u0026runtime.MemStats{}\n\truntime.ReadMemStats(m)\n\n\tp.gauge(\"runtime.goroutines\", uint64(runtime.NumGoroutine()))\n\tp.gauge(\"runtime.cgo_calls\", uint64(runtime.NumCgoCall()))\n\n\t// General\n\tp.gauge(\"runtime.mem.alloc_bytes\", m.Alloc)\n\tp.gauge(\"runtime.mem.alloc_bytes_total\", m.TotalAlloc)\n\tp.gauge(\"runtime.mem.sys_bytes\", m.Sys)\n\tp.gauge(\"runtime.mem.pointer_lookup_count\", m.Lookups)\n\tp.gauge(\"runtime.mem.malloc_count_total\", m.Mallocs)\n\tp.gauge(\"runtime.mem.free_count_total\", m.Frees)\n\n\t// Heap\n\tp.gauge(\"runtime.mem.heap.alloc_bytes\", m.HeapAlloc)\n\tp.gauge(\"runtime.mem.heap.sys_bytes\", m.HeapSys)\n\tp.gauge(\"runtime.mem.heap.idle_bytes\", m.HeapIdle)\n\tp.gauge(\"runtime.mem.heap.inuse_bytes\", m.HeapInuse)\n\tp.gauge(\"runtime.mem.heap.released_bytes\", m.HeapReleased)\n\tp.gauge(\"runtime.mem.heap.object_count\", m.HeapObjects)\n\n\t// Stack\n\tp.gauge(\"runtime.mem.stack.inuse_bytes\", m.StackInuse)\n\tp.gauge(\"runtime.mem.stack.sys_bytes\", m.StackSys)\n\tp.gauge(\"runtime.mem.stack.mspan_inuse_bytes\", m.MSpanInuse)\n\tp.gauge(\"runtime.mem.stack.mspan_sys_bytes\", m.MSpanSys)\n\tp.gauge(\"runtime.mem.stack.mcache_inuse_bytes\", m.MCacheInuse)\n\tp.gauge(\"runtime.mem.stack.mcache_sys_bytes\", m.MCacheSys)\n\n\t// Garbage Collection\n\tp.gauge(\"runtime.gc.sys_metadata_bytes\", m.GCSys)\n\tp.gauge(\"runtime.gc.next_target_heap_bytes\", m.NextGC)\n\tp.gauge(\"runtime.gc.last_finished_ts\", m.LastGC)\n\tp.gauge(\"runtime.gc.pause_total_ns\", m.PauseTotalNs)\n\tp.gauge(\"runtime.gc.pause_ns\", m.PauseNs[(m.NumGC+255)%256])\n\tp.gauge(\"runtime.gc.count\", uint64(m.NumGC))\n\tp.metricWriter.Gauge(\"runtime.gc.cpu_use\", m.GCCPUFraction)\n}\n\nfunc (p *profiler) gauge(key string, val uint64) {\n\tp.metricWriter.Gauge(key, float64(val))\n}\n","tags":"#go #performance"},{"id":"939c894e7e888fce66968eb5b1a807de","title":"Go: Logrus JSON Example ","content":"// https://play.golang.org/p/5H9ZV7Hqc6D\n\npackage main\n\nimport (\n\t\"github.com/sirupsen/logrus\"\n)\n\nfunc main() {\n\tlogger := logrus.New()\n\tlogger.SetFormatter(\u0026logrus.JSONFormatter{\n\t\tFieldMap: logrus.FieldMap{\n\t\t\tlogrus.FieldKeyMsg: \"message\", // uses `message` instead of `msg` field\n\t\t},\n\t})\n    logger.SetLevel(logrus.InfoLevel)\n\n\tbaselineLogger := logger.WithFields(logrus.Fields{\n\t\t\"foo\": logrus.Fields{\n\t\t\t\"bar\": 123,\n\t\t\t\"baz\": \"abc\",\n\t\t},\n\t}).WithFields(logrus.Fields{\n\t\t\"bar\": logrus.Fields{\n\t\t\t\"baz\": 456,\n\t\t\t\"qux\": \"xyz\",\n\t\t},\n\t})\n\n\tbaselineLogger.WithFields(logrus.Fields{\"beep\": \"boop\"}).Info(\"HERE\")\n  \n  \t// {\"bar\":{\"baz\":456,\"qux\":\"xyz\"},\"beep\":\"boop\",\"foo\":{\"bar\":123,\"baz\":\"abc\"},\"level\":\"info\",\"message\":\"HERE\",\"time\":\"2009-11-10T23:00:00Z\"}\n}\n","tags":"#go #json #logs"},{"id":"3b6aa81b784b37cf90d177933b5791f7","title":"IO Packages ","content":"# Sections\n\n- [Package io](#package-io)\n- [Package ioutil](#package-ioutil)\n- [Package bufio](#package-bufio)\n- [Package os](#package-os)\n- [Miscellaneous Notes](#miscellaneous-notes)\n- [Other Examples](#examples)\n\n## Package io\n\n\u003e Package io provides basic interfaces to I/O primitives. Its primary job is to wrap existing implementations of such primitives, such as those in package os, into shared public interfaces that abstract the functionality, plus some other related primitives.\n\u003e\n\u003e Because these interfaces and primitives wrap lower-level operations with various implementations, unless otherwise informed clients should not assume they are safe for parallel execution.\n\nExample functionality: read section of a file into memory\n\n```go\npackage main\n\nimport (\n\t\"fmt\"\n\t\"io\"\n\t\"log\"\n\t\"strings\"\n)\n\nfunc main() {\n\tr := strings.NewReader(\"some io.Reader stream to be read\\n\")\n\n\tbuf := make([]byte, 4)\n\tif _, err := io.ReadFull(r, buf); err != nil {\n\t\tlog.Fatal(err)\n\t}\n\tfmt.Printf(\"%s\\n\", buf) // \"some\"\n}\n```\n\n## Package ioutil\n\n\u003e Package ioutil implements some I/O utility functions.\n\nExample functionality: read entire file into memory\n\n```go\nimport \"io/ioutil\"\n\nfunc main() {\n\tdat, err := ioutil.ReadFile(\"/tmp/dat\")\n\tif err != nil {\n        panic(err)\n    }\n}\n```\n\n## Package bufio\n\n\u003e Package bufio implements buffered I/O. It wraps an io.Reader or io.Writer object, creating another object (Reader or Writer) that also implements the interface but provides buffering and some help for textual I/O.\n\nExample functionality: scan a file line-by-line, but grab the text from the 3rd line\n\n```go\nfunc parseNodes(input io.Reader) (string, error) {\n\tvar txt string\n    \n\tcount := 0\n\tline := 3\n\n\tscanner := bufio.NewScanner(input)\n\tfor scanner.Scan() {\n\t\tcount++\n\t\tif count == line {\n\t\t\ttxt = scanner.Text()\n\t\t}\n\t\tif scanner.Text() == \"END\" {\n\t\t\tbreak\n\t\t}\n\t}\n\n\tif err := scanner.Err(); err != nil {\n\t\tlogger.Println(\"Scanner Error: \", err.Error())\n\t\treturn \"\", err\n\t}\n\n\treturn txt, nil\n}\n```\n\nThe bufio package implements a buffered reader that may be useful both for its efficiency with many small reads and because of the additional reading methods it provides.\n\n## Package os\n\n\u003e Package os provides a platform-independent interface to operating system functionality. The design is Unix-like, although the error handling is Go-like; failing calls return values of type error rather than error numbers. Often, more information is available within the error. For example, if a call that takes a file name fails, such as Open or Stat, the error will include the failing file name when printed and will be of type *PathError, which may be unpacked for more information.\n\nExample functionality: opening a file with very granular control over how, and what parts, are read\n\n```go\nfile, err := os.Open(\"file.go\") // read access\nif err != nil {\n\tlog.Fatal(err)\n}\n\n// the file's data can then be read into a slice of bytes...\ndata := make([]byte, 100)\ncount, err := file.Read(data)\nif err != nil {\n\tlog.Fatal(err)\n}\nfmt.Printf(\"read %d bytes: %q\\n\", count, data[:count])\n```\n\n## Miscellaneous Notes\n\nType `os.File` represents a file on the local system. It implements both `io.Reader` and `io.Writer` and, therefore, can be used in any streaming IO contexts.\n\nThe `os` package exposes three variables, `os.Stdout`, `os.Stdin`, and `os.Stderr`, that are of type `*os.File` to represent file handles for the OS's standard output, input, and error respectively.\n\nFunction `io.Copy()` makes it easy to stream data from a source reader to a target writer. It abstracts out the for-loop pattern (we've seen so far) and properly handle `io.EOF` and byte counts.\n\n`io.WriteString` provides the convenience of writing a string value into a specified writer.\n\t\nTypes `io.PipeWriter` and `io.PipeReader` model IO operations as in memory pipes. Data is written to the pipe’s writer-end and is read on the pipe’s reader-end using separate go routines.\n\t\nGo supports buffered IO via package `bufio` which makes it easy to work with textual content. For example, we could use `bufio.Reader.ReadString` to read the content of a file line-by-line but using a specific delimeter like `'\\n'`.\n\t\nPackage `ioutil`, a sub-package of `io`, offers several convenience functions for IO. For example, the function `io/ioutil.ReadFile` can load the content of a file into a `[]byte`.\n\nPackage `httputil` provides HTTP utility functions and interfaces, some of which relate to IO and buffers. For example, `httputil.BufferPool` is an interface for getting and returning temporary byte slices for use by `io.CopyBuffer` (`CopyBuffer` is identical to `Copy` except that it stages through the provided buffer, if one is required, rather than allocating a temporary one. If `buf` is `nil`, one is allocated; otherwise if it has zero length, `CopyBuffer` panics). This can also be tied back into resources such as `net/http/httputil.ReverseProxy` which provides a `BufferPool` field such that it can help with copying HTTP response bodies in a more efficient way.\n\n## Examples\n\n\u003e Examples grouped together on Play... https://play.golang.org/p/4gtvoCJENwr\n\n### Reading\n\n```go\nreader := strings.NewReader(\"Clear is better than     clever\")\np := make([]byte, 4)\n\nfor {\n  n, err := reader.Read(p)\n  if err != nil {\n    if err == io.EOF {\n      fmt.Println(string(p[:n])) //should handle any remainding bytes.\n      break\n    }\n    fmt.Println(err)\n    os.Exit(1)\n  }\n  fmt.Println(string(p[:n]))\n}\n```\n\n### Writing\n\n```go\nproverbs := []string{\n  \"Channels orchestrate mutexes serialize\",\n  \"Cgo is not Go\",\n  \"Errors are values\",\n  \"Don't panic\",\n}\nvar writer bytes.Buffer\n\nfor _, p := range proverbs {\n  n, err := writer.Write([]byte(p))\n  if err != nil {\n    fmt.Println(err)\n    os.Exit(1)\n  }\n\n  if n != len(p) {\n    fmt.Println(\"failed to write data\")\n    os.Exit(1)\n  }\n\n  writer.Write([]byte(\", \")) // just so we can read the output a bit better\n}\n\nfmt.Println(writer.String())\n```\n\n### Simplified write/read using `Copy` and `ReadFile`\n\n```go\npverbs := new(bytes.Buffer)\npverbs.WriteString(\"Channels orchestrate mutexes serialize\\n\")\npverbs.WriteString(\"Cgo is not Go\\n\")\npverbs.WriteString(\"Errors are values\\n\")\npverbs.WriteString(\"Don't panic\\n\")\n\nfile, err := os.Create(\"./proverbs.txt\")\nif err != nil {\n  fmt.Println(err)\n  os.Exit(1)\n}\ndefer file.Close()\n\n// copy from reader data into writer file\nif _, err := io.Copy(file, pverbs); err != nil {\n  fmt.Println(err)\n  os.Exit(1)\n}\ndat, _ := ioutil.ReadFile(\"./proverbs.txt\")\nfmt.Print(\"\\n\", string(dat))\n```\n\n### Simplified read from `os.File`, and write to `os.Stdout` using `Copy`\n\n```go\nfile1, err := os.Open(\"./proverbs.txt\")\nif err != nil {\n  fmt.Println(err)\n  os.Exit(1)\n}\ndefer file1.Close()\n\n// Copy to Stdout is going to cause output to be immediately displayed (e.g. no need for fmt.Print style functions)\nif _, err := io.Copy(os.Stdout, file1); err != nil {\n  fmt.Println(err)\n  os.Exit(1)\n}\n```\n","tags":"#go"},{"id":"4a7b9efe971c416ee56b4e0025174e9c","title":"Redis Install and Examples ","content":"$ redis-server --port 7777 # OVERRIDING DEFAULT PORT 6379\n60717:C 05 Mar 2020 12:54:01.873 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo\n60717:C 05 Mar 2020 12:54:01.873 # Redis version=5.0.7, bits=64, commit=00000000, modified=0, pid=60717, just started\n60717:C 05 Mar 2020 12:54:01.873 # Configuration loaded\n60717:M 05 Mar 2020 12:54:01.874 * Increased maximum number of open files to 10032 (it was originally set to 256).\n                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 5.0.7 (00000000/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 7777\n |    `-._   `._    /     _.-'    |     PID: 60717\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n60717:M 05 Mar 2020 12:54:01.875 # Server initialized\n60717:M 05 Mar 2020 12:54:01.875 * Ready to accept connections\n# https://redis.io/commands\n$ redis-cli -p 7777\n\n# NOTE: If you need to connect to a remote Redis instance (e.g. via Kubernetes pod)\n# redis-cli -h example-redis-us-east-2.aws.whatever.net -p 6379 --pass whatever_password PING\n\n# If your application code needs an auth token (e.g. send `AUTH some_password`)\n# https://redis.io/commands/auth/\n# Then you can set that up locally using:\nconfig set requirepass SECRET_SQUIRREL\n\n# Also for the above you could do it this way using a Makefile:\n#\n#.PHONY: check-local-redis\n#check-local-redis:\n#\t@# If redis isn't running locally, then we start it, find the config and make sure a password is set.\n#\t@# We then need to restart redis for the config changes to take effect (just in case the requirepass wasn't already set)\n#\t@if ! lsof -i \":6379\" | grep -qi \"redis-ser\"; then \\\n#\t\tbrew services start redis; \\\n#\t\tredis-cli INFO | grep config_file | cut -d : -f 2 | tr -d '\\r' | xargs -I % sed -i '' 's/# requirepass foobared/requirepass SECRET_SQUIRREL/' %; \\\n#\t\tbrew services restart redis; \\\n#\tfi\n\n# health check\n127.0.0.1:7777\u003e ping\nPONG\n\n# list all keys\n127.0.0.1:7777\u003e keys *\n(empty list or set)\n\n# scan iteratively (using a cursor)\n127.0.0.1:7777\u003e scan 0 MATCH foo*\n1) \"26\"\n2) 1) \"foo008\"\n   2) \"foo005\"\n   3) \"foo4\"\n   4) \"foo001\"\n   5) \"foo006\"\n   6) \"foo003\"\n   7) \"foo7\"\n   8) \"foo5\"\n127.0.0.1:7777\u003e scan 26 MATCH foo*\n1) \"19\"\n2) 1) \"foo9\"\n   2) \"foo3\"\n   3) \"foo bar\"\n   4) \"foo8\"\n   5) \"foo1\"\n   6) \"foo009\"\n   7) \"foo004\"\n   8) \"foo2\"\n   9) \"foo6\"\n127.0.0.1:7777\u003e scan 19 MATCH foo*\n1) \"0\"\n2) 1) \"foo002\"\n   2) \"foo007\"\n\n# set a simple key with 30s TTL\n# https://redis.io/commands/set\n127.0.0.1:7777\u003e set foo bar EX 30\nOK\n127.0.0.1:7777\u003e get foo\n\"bar\"\n# ...wait for 30s...\n127.0.0.1:7777\u003e get foo\n(nil)\n\n# show the number of keys currently in redis (better than `keys *`)\n127.0.0.1:7777\u003e info keyspace\n# Keyspace\ndb0:keys=5,expires=0,avg_ttl=0\n\n# increment a simple counter\n127.0.0.1:7777\u003e set hits 0\nOK\n127.0.0.1:7777\u003e get hits\n\"0\"\n127.0.0.1:7777\u003e incr hits\n(integer) 1\n127.0.0.1:7777\u003e incr hits\n(integer) 2\n127.0.0.1:7777\u003e incrby hits 2\n(integer) 4\n\n# NOTE: \n# in Redis 4+ hmset is deprecated for hset (which is now variadic)\n#\n# hget = return single field value\n# hmget = return multiple field values\n\n# set hashmap (key, field, field-value)\n127.0.0.1:7777\u003e hmset client1 counter 1\nOK\n127.0.0.1:7777\u003e hmget client1 counter\n1) \"1\"\n127.0.0.1:7777\u003e hmset client1 foo bar\nOK\n127.0.0.1:7777\u003e hmget client1 foo\n1) \"bar\"\n\n# when creating a key and assigning a string you can set a ttl\n# that will automatically delete the key when the ttl expires\n# you can't set a ttl in the same set command when using a hashmap\n# so to expire a key without a ttl already set you need to use\n# the EXPIRE command (which automatically deletes the key)\n127.0.0.1:7777\u003e EXPIRE client2 10\n(integer) 1                \n127.0.0.1:7777\u003e TTL client2\n(integer) 5                \n127.0.0.1:7777\u003e TTL client2\n(integer) 4                \n127.0.0.1:7777\u003e TTL client2\n(integer) 3                \n127.0.0.1:7777\u003e TTL client2\n(integer) 2                          \n127.0.0.1:7777\u003e TTL client2\n(integer) 1                          \n127.0.0.1:7777\u003e TTL client2\n(integer) 0                      \n127.0.0.1:7777\u003e TTL client2\n(integer) -2 \n127.0.0.1:7777\u003e type client2\n(nil)\n\n# get all hashmap fields at once\n127.0.0.1:7777\u003e hgetall client1\n1) \"counter\"\n2) \"2\"\n3) \"foo\"\n4) \"bar\"\n5) \"restrict\"\n6) \"false\"\n127.0.0.1:7777\u003e hgetall client2\n(empty list or set)\n\n# delete a specific field from a hashmap\n# 1=OK, 0=FAIL\n127.0.0.1:7777\u003e hdel client1 foo\n(integer) 1\n127.0.0.1:7777\u003e hgetall client1\n1) \"counter\"\n2) \"2\"\n3) \"restrict\"\n4) \"false\"\n\n# increment hashkey field\n127.0.0.1:7777\u003e hincrby client1 counter 2\n(integer) 4\n127.0.0.1:7777\u003e hgetall client1\n1) \"counter\"\n2) \"4\"\n3) \"restrict\"\n4) \"false\"\n127.0.0.1:7777\u003e\nbrew install redis\nbrew services start redis\n","tags":"#shell"},{"id":"009340829a377fbe350931400d2a82bc","title":"CPU Speed","content":"# Central Processing Unit (CPU)\n\nA central processing unit (CPU) is the electronic circuitry within a computer that executes instructions that make up a computer program.\n\n- [Clock Speed](#clock-speed)\n- [Cores](#cores)\n- [Cache](#cache)\n\n## Clock Speed\n\nCPUs can only carry out one instruction at a time.\n\nIt might seem like CPUs can perform many instructions simultaneously, since it is possible for you to do homework, read instant messages and listen to music at the same time. However, the CPU is able to carry out instructions at such speed that it can seem like it is simultaneous.\n\nThe speed at which the CPU can carry out instructions is called the clock speed. This is controlled by a clock. With every tick of the clock, the CPU fetches and executes one instruction. The clock speed is measured in cycles per second, and one cycle per second is known as 1 hertz. This means that a CPU with a clock speed of 2 gigahertz (GHz) can carry out two thousand million (or two billion) cycles per second. \n\nThe higher the clock speed a CPU has, the faster it can process instructions.\n\n\u003e **Note**: When referring to a computer processor or CPU, GHz is a clock frequency, also known as a clock rate or clock speed, representing a cycle of time. An oscillator circuit supplies a small amount of electricity to a crystal each second that is measured in kHz, MHz, or GHz. \"Hz\" is an abbreviation of Hertz, and \"k\" represents Kilo (thousand), \"M\" represents Mega (million), and \"G\" represents Giga (thousand million).\n\n## Cores\n\nA CPU is traditionally made up of a processor with a single core. Most modern CPUs have two, four or even more cores. \n\nA CPU with two cores, called a dual core processor, is like having two processors in one. A dual core processor can fetch and execute two instructions in the same time it takes a single core processor to fetch and execute just one instruction. A quad core processor has four cores and can carry out even more instructions in the same period of time.\n\nWhen dealing with multiple cores, instructions have to be split up to decide which core will execute them and the results have to be merged together again at the end, which slows the processor down a little.\n\n## Cache\n\nA cache (pronounced 'cash') is a tiny block of memory built right onto the processor. The most commonly used instructions and data are stored in the cache so that they are close at hand. The bigger the cache is, the more quickly the commonly used instructions and data can be brought into the processor and used.\n","tags":""},{"id":"04a3895be2c428219a28c3b3dd77bfed","title":"Context package ","content":"package main\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"time\"\n)\n\nfunc slow(ctx context.Context) {\n\tgo func() {\n\t\t\u003c-ctx.Done()\n\t\tfmt.Println(\"CONTEXT CANCELLED!\", time.Now())\n\t}()\n\ttime.Sleep(10 * time.Second)\n\tfmt.Println(\"FINISHED\", time.Now())\n}\n\nfunc main() {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Duration(5)*time.Second)\n\tdefer cancel()\n\n\tslow(ctx)\n\n\tfmt.Println(\"DONE\", time.Now())\n}\npackage main\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"time\"\n)\n\nfunc main() {\n\tfmt.Println(createAContext())\n}\n\nfunc createAContext() string {\n\tctx, cancel := context.WithTimeout(context.Background(), 1*time.Second)\n\tdefer cancel()\n\treturn useTheContext(ctx)\n}\n\nfunc useTheContext(parentCtx context.Context) string {\n\t// fmt.Println(\"sleeping long enough for parentCtx timeout to be reached\")\n\t// time.Sleep(2 * time.Second)\n\tselect {\n\tcase \u003c-parentCtx.Done():\n\t\tfmt.Println(\"Context canceled before doing stuff 1\")\n\t\treturn \"canceled\"\n\tdefault:\n\t\tchildCtx, cancel := context.WithCancel(parentCtx)\n\t\tcancel()\n\t\tuseChildContext(childCtx, parentCtx)\n\t\treturn \"done\"\n\t}\n}\n\nfunc useChildContext(childCtx, parentCtx context.Context) {\n\tselect {\n\tcase \u003c-parentCtx.Done():\n\t\tfmt.Println(\"Parent context cancelled\")\n\tcase \u003c-childCtx.Done():\n\t\tfmt.Println(\"Child context cancelled\")\n\tdefault:\n\t\tfmt.Printf(\"using child context: %#v\\n\", childCtx)\n\t}\n}\n","tags":"#go"},{"id":"9822f59cbb60f5de0f79a6cbd79ad9ab","title":"GitHub Open-Source Pull Request Flow ","content":"1. Fork open-source project.\n2. Create branch and make changes.\n3. Push branch to your fork.\n4. Visit open-source project and open a pull-request (select your fork's branch).\n5. Wait for your PR branch to be merged into the open-source project's `master`.\n6. Once merged, add the open-source project as a 'remote' (`git remote add upstream \u003cgithub.com/user/repo.git\u003e`).\n7. `git checkout master`\n8. `git fetch upstream` (convention states we use 'upstream' as the name of the remote).\n9. `git rebase upstream/master` (alternative to fetch/rebase, is `git pull --rebase upstream master`).\n10. `git push origin master`.\n11. `git branch -d \u003cyour-pr-branch\u003e` (the PR branch is no longer needed).\n12. `git push origin --delete \u003cyour-pr-branch\u003e`.\n","tags":"#git #github"},{"id":"124d0de60213742030999e98527ae47c","title":"Don't follow 301 redirect ","content":"```go\nclient: \u0026http.Client{\n    CheckRedirect: func(req *http.Request, via []*http.Request) error {\n        return http.ErrUseLastResponse\n    },\n}\n```\n\n\u003e if `CheckRedirect` returns `http.ErrUseLastResponse`, then the most recent response is returned with its body unclosed, along with a `nil` error.\n","tags":"#go #http"},{"id":"ec0b1f17d7b0b8f365293048d0d79197","title":"[Python copy file with permissions + add additional perms] ","content":"\"\"\"\nnote if you just need to ensure that you keep the original permissions \nthen using the horrifically named `shutil.copy2` will work for you.\n\njust replace the last two lines (`os.stat` and `os.chmod`) with:\n`shutil.copy2(src_file, dst_file)`\n\"\"\"\n\nsrc_file = f\"{src}{path}/{file}\"\ndst_file = f\"{dst}/{file}\"\n\nshutil.copyfile(src_file, dst_file)\n\n# we lose the execute permissions when copying a file with Python,\n# where as it seems that's not a problem when we were using Bash.\n#\n# if we don't add execute perms to the copied file, then when the docker\n# container is run we would get an \"OCI runtime create failed\" error.\n#\n# our code uses os.stat() to get the current file permissions, then uses\n# the pipe operator | to do a bitwise OR operation which ensures we get\n# both the current perms + the new perms (i.e. +x execute).\n#\n# Bitwise OR reference:\n# https://en.wikipedia.org/wiki/Logical_disjunction\nst = os.stat(src_file)\nos.chmod(dst_file, st.st_mode | stat.S_IEXEC)\n","tags":"#python3 #permissions #chmod"},{"id":"f5bd41c0bfeaf9d4e37e434d3a6af5c4","title":"[Continuous Integration vs Delivery] ","content":"- **Continuous Integration**: testing every commit\n- **Continuous Delivery**: every change is shippable on demand\n- **Continuous Deployment**: shipping every change automatically\n\nDelivery and Deployment are two terms that often are confused with each other. The 'delivery' variation requires a human to press a button that triggers the deployment, while the 'deployment' variation removes the need for human interaction and will automatically deploy the software once it is merged (e.g. once the 'integration' step has passed successfully).\n","tags":"#ci #cd #continous #integration #delivery"},{"id":"50833024cf073e804e1243baa0c690e8","title":"Simple Fastly CDN Rate Limiting Logic using Vary behaviour for cacheable GET requests ","content":"# Example:\n# https://fiddle.fastlydemo.net/fiddle/4ac44faf\n#\n# the principle of this design is that we want \n# requests to be cached using a key that varies\n# on the \"Fastly-Client-IP\" and \"User-Agent\" headers\n# but only for responses that indicate \"429 Too Many Requests\"\n#\n# whenever we get a \"429 Too Many Requests\" response, we'll\n# we'll ensure it is cacheable, and that will result in the Vary headers\n# being applied as part of the cache lookup process (because a different\n# client request will provide a different value for the IP and User-Agent headers\n# which are used for the varying logic. and so they'll have empty values and \n# this will result in (hopefully) a cached \"200 OK\". or at the very least they'll \n# get a cache MISS and go to origin to fetch the content which will then be cached).\n#\n# caveat:\n# this example doesn't work with POST requests.\n# the solution to that is to `return(lookup)` in vcl_recv for POST|PUT|DELETE methods\n# then skip caching for anything other than the 429 status code (e.g. if '200 OK' then don't cache)\n# as we only want to cache a 429 with Vary behaviour\n# \n# see this fiddle: https://fiddle.fastlydemo.net/fiddle/47871720\n# which fixes the issue and implements the following changes \n# + additional changes to support otherwise uncacheable method types\n#\n# the code for that latter fiddle is also copied at the bottom of this gist\n# just in case the fastly fiddle url is no longer available.\n#\n# one caveat to this approach (according to fastly)...\n#\n# \u003e As far as the caveat is considered, Fastly have told me…\n# \u003e POST requests are also ineligible for clustering, ie transferring the request to a consistently-hashed storage node.  \n# \u003e Since we don’t expect POSTs to be cached, this is an optimisation and we unfortunately don’t provide a way for you to override it.\n# \u003e The effect of this is that even if you do enable POSTs to be cached, your cache hit ratio will be poor.\n# \u003e This may be fine if your intention is just to use it for rate limiting.\n#\n# So yeah it’s not the end of the world, but the fact we lose fastly’s clustering behaviour isn’t ideal either.\nif (req.restarts == 0) {\n  # the User-Agent isn't provided by all clients (e.g. pentesting tools)\n  # so we'll provide a genericized value if no header is found\n  if (!req.http.User-Agent) {\n    set req.http.UserAgent = \"Foo-Bar\";\n  }\n}\n# at this point we've gone to the origin and we've received a 429\n# and so we set the 429 to be cacheable and we give it a TTL via Cache-Control header\n# and we state this content needs to utilize Vary so that other clients don't get the cached 429\n# if no caching directives are provided, then we'll set a default of one hour\nif (beresp.status == 429) {\n  # ensure all responses have the required Vary header values\n  # for the sake of this test fiddle we simply hardcode the value\n  # but in our real service we would check the Vary header and append to it\n  if (!beresp.http.Vary) {\n    set beresp.http.Vary = \"Fastly-Client-IP, User-Agent\";\n  }\n\n  set beresp.cacheable = true;\n  if (!beresp.http.Surrogate-Control \u0026\u0026 !beresp.http.Cache-Control) {\n    set beresp.ttl = 1h; # 1 hour\n  }\n}\nsub vcl_recv {\n  if (req.restarts == 0) {\n    if (!req.http.User-Agent) {\n      set req.http.UserAgent = \"Fallback\";\n    }\n  }\n\n  // force caching for methods that are otherwise normally uncached\n  // and mimic the standard behaviour of disabling 'request collapsing'\n  if (req.method ~ \"(POST|PUT|DELETE)\") {\n    set req.http.X-PassMethod = \"true\";\n    set req.hash_ignore_busy = true;\n    return(lookup);\n  }\n}\n    \nsub vcl_fetch {\n  // this conditional is used for testing the logic\n  // and isn't required for actual implementation\n  if (req.http.X-429) {\n    set beresp.status = 429;\n  }\n\n  declare local var.vary STRING;\n  set var.vary = \"Fastly-Client-IP, User-Agent\";\n\n  if (beresp.status == 429) {\n    if (!beresp.http.Vary) {\n      set beresp.http.Vary = var.vary;\n    } else {\n      set beresp.http.Vary = beresp.http.Vary + \", \" + var.vary;\n    }\n\n    set beresp.cacheable = true;\n    if (!beresp.http.Surrogate-Control:max-age \u0026\u0026 !beresp.http.Cache-Control:max-age) {\n      set beresp.ttl = 1m; // 1 minute\n    }\n  }\n\n  if (req.http.X-PassMethod) {\n    if (beresp.status != 429) {\n      set beresp.cacheable = false;\n    }\n  }\n}\n","tags":"#fastly #cdn"},{"id":"8719fed37c7e1ac27d5f739926bac584","title":"[Curl Redirect Output and Grep] ","content":"curl -svo /dev/null -H 'Fastly-Debug:1' https://www.buzzfeednews.com/article/johnpaczkowski/apple-arcade-iphone-pro-appletv 2\u003e\u00261 | sort | grep -iE '^\u003c ((cache|surrogate)-control|surrogate-key|cache|fastly)'\n","tags":"#curl #redirect #stdout #grep"},{"id":"f7a6abdd946ad5b3b06907069f79cc48","title":"[Fastly Varnish Serve Stale Testing] ","content":"include \"serve_stale_verification\" \n\nsub vcl_fetch {\n  #FASTLY fetch\n  \n  ...\n  \n  call serve_stale_verification;\n  \n  if (beresp.status \u003e= 500 \u0026\u0026 beresp.status \u003c 600) {\n    if (stale.exists) {\n      return(deliver_stale);\n    }\n  }\n  \n  ...\n      \n  return(deliver);\n}\n# ensure this subroutine is called _before_ any checks for stale.exists\nsub serve_stale_verification {\n  if (req.http.X-ModifyDirectives == \"shorten\") {\n    set beresp.ttl = 10s;\n    set beresp.stale_while_revalidate = 20s;\n    set beresp.stale_if_error = 30s;\n\n    # a '304 Not Modified' from origin will not cause vcl_fetch to be executed.\n    # so to prevent that scenario from occuring, and thus causing confusion around\n    # serve stale expectations, we'll strip any ETag/Last-Modified headers so that\n    # we should always cause vcl_fetch to execute (as the cached object won't have\n    # any ETag or Last-Modified headers to compare against).\n    unset beresp.http.ETag;\n    unset beresp.http.Last-Modified;\n  }\n\n  if (req.http.X-ModifyDirectives == \"fail\") {\n    set beresp.status = 500;\n    set beresp.cacheable = false;\n  }\n}\n\"\"\" Run this script using: time poetry run python verify_stale/stale.py \"\"\"\n\n# standard library modules\n\nimport os\nimport re\nimport sys\nimport time\nfrom datetime import datetime\n\n# third-party modules\n\nfrom tornado.gen import coroutine\nfrom tornado.httpclient import AsyncHTTPClient, HTTPResponse\nfrom tornado.ioloop import IOLoop\nfrom tornado.simple_httpclient import HTTPTimeoutError\n\nAsyncHTTPClient.configure(None, defaults=dict(user_agent=\"IntegralistTesting\"))\nhttp_client = AsyncHTTPClient()\n\n\ndef get_urls(cachebust: float = 0.0, fail: bool = False) -\u003e HTTPResponse:\n    \"\"\"requests list of URLs concurrently.\n    \n    this example code presumes a staging environment is used and \n    that this staging environment is protected with BasicAuth.\n    \"\"\"\n\n    user = os.environ[\"AUTH_USER\"]\n    password = os.environ[\"AUTH_PASS\"]\n    creds = f\"{user}:{password}@\"\n    subdomain = f\"{creds}stage\"\n    host = f\"{subdomain}.example.com\"\n    query = f\"?cachebust={cachebust}\"\n\n    paths = [\n        \"/foo\",\n        \"/bar\",\n        \"/baz\",\n    ]\n\n    responses = []\n\n    state = \"fail\" if fail else \"shorten\"\n    headers = {\"X-BF-Debug\": \"1\", \"X-ModifyDirectives\": state}\n\n    for path in paths:\n        url = f\"https://{host}{path}{query}\"\n        print(f\"request: {url}\\n\\t{headers}\")\n\n        responses.append(\n            # we don't need to `await` these 'fetch' calls because the function\n            # returns a Future and so we collect a group of futures and return\n            # those to the caller.\n            #\n            # tornado is then able to 'yield' multiple Futures within a list.\n            http_client.fetch(url, headers=headers, raise_error=False)\n        )\n\n    return responses\n\n\n@coroutine\ndef validate(\n    timestamp: float, expected: str, then_sleep: int = 0, fail: bool = False\n):\n    \"\"\"validate should confirm if responses are as expected.\n\n    we use a map data structure (`m`) to translate the `then_sleep` value into\n    a descriptive value for the purposes of debugging when a validation check\n    fails.\n\n    the `then_sleep` value indicates how long the program will 'sleep' for\n    before continuing. this means the next batch of requests will be blocked\n    for that period of time.\n\n    for example, if `then_sleep` is set to 5, then this means we'll request the\n    various pages and then we'll stop the program for five seconds. when the\n    next batch of requests are made we should find that they yield cache HITs\n    because the max-age of our cached objects are set to 10s.\n\n    remember: in the CDN/VCL we are using a request header to control the\n    caching directives and also whether we want the origin response to look\n    like a failure or not...\n\n    sub serve_stale_verification {\n      if (req.http.X-ModifyDirectives == \"shorten\") {\n        set beresp.ttl = 10s;\n        set beresp.stale_while_revalidate = 20s;\n        set beresp.stale_if_error = 30s;\n        \n        unset beresp.http.ETag;\n\t    unset beresp.http.Last-Modified;\n      }\n\n      if (req.http.X-ModifyDirectives == \"fail\") {\n        set beresp.status = 500;\n        set beresp.cacheable = false;\n      }\n    }\n    \"\"\"\n\n    m = {\n        5: \"\u003e\u003e make requests, expect misses (as fresh content cached for first time), then sleep for 5s\",  # noqa\n        6: \"\u003e\u003e make requests, expect hits (as same content requested), then sleep for 6s\",  # noqa\n        32: \"\u003e\u003e make requests, expect stale-while-revalidate (as max-age ttl expired), cache object updated and ttls reset, then sleep for 32s\",  # noqa\n        35: \"\u003e\u003e make requests, expect stale-if-error (as max-age+stale-while-revalidate ttls expired), then sleep for 35s\",  # noqa\n        0: \"\u003e\u003e make requests, expect misses (as stale-if-error ttl expired)\",  # noqa\n    }\n\n    print(f\"\\n\\n{m[then_sleep]}\\n\\n\")\n\n    filter_headers = r\"^(Age|Date|Etag|Fastly)\"\n\n    try:\n        a, b, c, d, e, f, g, h, i, j = yield get_urls(\n            cachebust=timestamp, fail=fail\n        )\n    except HTTPTimeoutError as err:\n        print(f\"\\n\\ntornado HTTPTimeoutError: {err}\\n\\n\")\n        sys.exit(1)\n\n    for k, v in locals().items():\n        if re.search(\n            \"^(timestamp|expected|then_sleep|fail|m|filter_headers)\", k\n        ):\n            # ignore function arguments and other variables\n            # yes, this list gets tedious to update as the code changes :-/\n            continue\n\n        state = v.headers[\"Fastly-State\"]\n        url = v.effective_url\n\n        details = \"\\n\\t\".join(\n            [\n                f\"{h}: {hv}\"\n                for h, hv in v.headers.items()\n                if re.search(filter_headers, h)\n            ]\n        )\n\n        if not re.search(expected, state, flags=re.IGNORECASE):\n            try:\n                print(\"\\nvalidation check failed\")\n                print(\n                    f\"convert response to 500: {fail}\\n\\t{url}\\n\\t{state} != {expected}\\n\\n\\t{details}\"  # noqa\n                )\n            except KeyError as err:\n                print(\"\\nvalidation check failed: KeyError!\")\n                print(\n                    f\"convert response to 500: {fail}\\n\\t{url}\\n\\tKeyError: {err}\\n\"  # noqa\n                )  # noqa\n        else:\n            print(f\"\\n√ no validation errors\\n\\t{url}\\n\\t{details}\")\n\n    time.sleep(then_sleep)\n\n\n@coroutine\ndef process_urls():\n    \"\"\"make multiple async requests to validate responses.\n\n    because we're using tornado's own `@coroutine` syntax instead of the\n    native async/await, it means we need to `yield` and ensure any async\n    functions we call are also decorated with `@coroutine`.\n    \"\"\"\n\n    ts = datetime.now().timestamp()\n    miss = \"^MISS(?:-CLUSTER)?\"\n    hit = \"^HIT(?:-CLUSTER)?\"\n    stale = \"^HIT-STALE(?:-CLUSTER)?\"\n\n    # fresh content cached for the first time\n    yield validate(ts, expected=miss, then_sleep=5)\n\n    # expect hits from recently cached resources\n    yield validate(ts, expected=hit, then_sleep=6)\n\n    # at this point we would have slept for a total of 11 seconds, meaning our\n    # max-age should have expired and we should now serve\n    # stale-while-revalidate.\n    #\n    # we now find that although we've been served stale content, a new request\n    # to the origin has been made and the object in the cache has been reset\n    # using the cache control headers from the original request (which in our\n    # case is the shortened directives that we tweaked in our vcl override).\n    #\n    # because our origins are setting an ETag, it means we'd normally get a\n    # '304 Not Modified' response from origin, and thus vcl_fetch would not get\n    # executed. to avoid that scenario in vcl_fetch when we first tweak the\n    # cache control directives we also strip ETag/Last-Modified from the\n    # origin's response so that there can be no 'conditional request' made and\n    # thus we have to do a full request to the origin.\n    #\n    # the updated object means we shouldn't try to sleep for 21s (which is the\n    # stale-while-revalidate TTL) but sleep for 31s (which is the combination\n    # of the max-age and stale-while-revalidate TTLs).\n    #\n    # we actually sleep for 32s just to give a bit of extra padding.\n    yield validate(ts, expected=stale, then_sleep=32)\n\n    # stale-while-revalidate expired, so serve stale-if-error\n    #\n    # note: at this point the age of the object is 32 and so we have 8 seconds\n    # before stale-if-error TTL expires.\n    yield validate(ts, fail=True, expected=stale, then_sleep=35)\n\n    # stale-if-error expired, so expect cache misses again\n    yield validate(ts, expected=miss)\n\n\nio_loop = IOLoop.current()\nio_loop.run_sync(process_urls)\n","tags":"#fastly #varnish #vcl #cdn #cache #stale #stale-while-revalidate #stale-if-error"},{"id":"e2be6c6cc8a2e23219e07682fc038bca","title":"Simple retry logic for HTTP request ","content":"// report indicates the failing test and the host it is associated with.\nfunc report(host, msg string, err error) {\n\tlog.Printf(\"%s, %s: %v\\n\", host, msg, err)\n}\n\n// TestStatusCode verifies the given status code will return a corresponding\n// custom error page. If a status code that has no custom error page is\n// provided, then we'll allow for an override to verify that a default custom\n// error page was returned.\n//\n// We allow for an optional variadic parameter to be provided so a caller can\n// specify a default status code to verify against in case the given status\n// code is expected to return a different status code.\nfunc TestStatusCode(statusCode int, host, needle string, config *settings.Config, defaultStatusCode ...int) {\n\tclient := \u0026http.Client{\n\t\tTimeout: time.Second * time.Duration(config.Timeout),\n\t}\n\n\tpath := fmt.Sprintf(\"/httpbin/status/%d\", statusCode)\n\tmethod := \"GET\"\n\tuuid := time.Now().UnixNano()\n\n\turl := fmt.Sprintf(\"https://%s%s?cachebust=%d\", host, path, uuid)\n\n\treq, err := http.NewRequest(method, url, nil)\n\tif err != nil {\n\t\tmsg := fmt.Sprintf(\"test%d: failed to create new request\", statusCode)\n\t\treport(host, msg, err)\n\t\treturn\n\t}\n\n\tif config.Environment == \"stage\" {\n\t\treq.SetBasicAuth(config.BasicAuthUser, config.BasicAuthPass)\n\n\t\t// not all services use the same stage auth credentials\n\t\tif creds, ok := config.BasicAuthOverride[host]; ok {\n\t\t\treq.SetBasicAuth(creds[\"user\"], creds[\"pass\"])\n\t\t}\n\t}\n\n\t// set debug flag so we can inspect Surrogate-Control.\n\treq.Header.Set(\"Fastly-Debug\", \"true\")\n\n\t// set header to allow request through to HTTPBin\n\treq.Header.Set(\"X-Origin-HTTPBin\", config.SecretHash)\n\n\t// implement retry logic around our http request...\n\tvar resp *http.Response\n\t{\n\t\tattempts := 0\n\n\t\tfor attempts \u003c 2 {\n\t\t\tattempts++\n\n\t\t\tresp, err = client.Do(req)\n\t\t\tif err != nil {\n\t\t\t\tif config.Debug {\n\t\t\t\t\tmsg := fmt.Sprintf(\"test%d: failed to make http request\", statusCode)\n\t\t\t\t\treport(host, msg, err)\n\t\t\t\t}\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\tdefer resp.Body.Close()\n\t\t\tbreak\n\t\t}\n\n\t\tif attempts == 2 \u0026\u0026 resp == nil {\n\t\t\tmsg := fmt.Sprintf(\"test%d: failed to make http request after two attempts\", statusCode)\n\t\t\treport(host, msg, err)\n\t\t\treturn\n\t\t}\n\t}\n\n\t// in case the provided status code doesn't have a custom error page of its\n\t// own but uses a different status code, then enable the caller to provide\n\t// the correct status code that was expected to be handled for that code.\n\t//\n\t// for example, 503 should really return a 500 as there is currently no\n\t// custom error page for a 503 so we return the custom 500 instead.\n\tstatusToVerify := statusCode\n\tif len(defaultStatusCode) == 1 {\n\t\tstatusToVerify = defaultStatusCode[0]\n\t}\n\n\tif resp.StatusCode != statusToVerify {\n\t\terr := fmt.Errorf(resp.Status)\n\t\tmsg := fmt.Sprintf(\"test%d: unexpected response status code\", statusCode)\n\t\treport(host, msg, err)\n\t\tlog.Printf(\"%#v\\n\", resp)\n\t\treturn\n\t}\n\n\tbody, err := ioutil.ReadAll(resp.Body)\n\tif err != nil {\n\t\tmsg := fmt.Sprintf(\"test%d: failed to read response body\", statusCode)\n\t\treport(host, msg, err)\n\t\tlog.Printf(\"%#v\\n\", resp)\n\t\treturn\n\t}\n\n\tif !strings.Contains(string(body), needle) {\n\t\terr := fmt.Errorf(\"missing error message in body\")\n\t\tmsg := fmt.Sprintf(\"test%d: failed to load correct error page\", statusCode)\n\t\treport(host, msg, err)\n\t\tlog.Printf(\"%#v\\n\", resp)\n\t\treturn\n\t}\n\n\tif config.Debug {\n\t\tmsg := fmt.Sprintf(\"test%d: passed\", statusCode)\n\t\tlog.Println(host, msg)\n\t}\n}\n// report indicates the failing test and the host it is associated with.\nfunc report(host, msg string, err error) {\n\tlog.Printf(\"%s, %s: %v\\n\", host, msg, err)\n}\n\n// requestWithRetry will attempt to make a HTTP request multiple times before\n// failing the given test scenario\nfunc requestWithRetry(client *http.Client,\n\treq *http.Request,\n\tresp *http.Response,\n\tretries int,\n\tdebug bool,\n\tmsg, host string) (*http.Response, error) {\n\n\tattempts := 0\n\tvar err error\n\n\tfor attempts \u003c retries {\n\t\tattempts++\n\n\t\tresp, err = client.Do(req)\n\t\tif debug {\n\t\t\tif err != nil {\n\t\t\t\treport(host, msg, err)\n\t\t\t}\n\t\t\tcontinue\n\t\t}\n\n\t\tbreak\n\t}\n\n\tif attempts == retries \u0026\u0026 resp == nil {\n\t\treport(host, fmt.Sprintf(\"%s after two attempts\", msg), err)\n\t\treturn resp, err\n\t}\n\n\treturn resp, nil\n}\n\n// TestStatusCode verifies the given status code will return a corresponding\n// custom error page. If a status code that has no custom error page is\n// provided, then we'll allow for an override to verify that a default custom\n// error page was returned.\n//\n// We allow for an optional variadic parameter to be provided so a caller can\n// specify a default status code to verify against in case the given status\n// code is expected to return a different status code.\nfunc TestStatusCode(statusCode int, host, needle string, config *settings.Config, defaultStatusCode ...int) {\n\tclient := \u0026http.Client{\n\t\tTimeout: time.Second * time.Duration(config.Timeout),\n\t}\n\n\tpath := fmt.Sprintf(\"/httpbin/status/%d\", statusCode)\n\tmethod := \"GET\"\n\tuuid := time.Now().UnixNano()\n\n\turl := fmt.Sprintf(\"https://%s%s?cachebust=%d\", host, path, uuid)\n\n\treq, err := http.NewRequest(method, url, nil)\n\tif err != nil {\n\t\tmsg := fmt.Sprintf(\"test%d: failed to create new request\", statusCode)\n\t\treport(host, msg, err)\n\t\treturn\n\t}\n\n\tif config.Environment == \"stage\" {\n\t\treq.SetBasicAuth(config.BasicAuthUser, config.BasicAuthPass)\n\n\t\t// not all services use the same stage auth credentials\n\t\tif creds, ok := config.BasicAuthOverride[host]; ok {\n\t\t\treq.SetBasicAuth(creds[\"user\"], creds[\"pass\"])\n\t\t}\n\t}\n\n\t// set debug flag so we can inspect Surrogate-Control.\n\treq.Header.Set(\"Fastly-Debug\", \"true\")\n\n\t// set header to allow request through to HTTPBin\n\treq.Header.Set(\"X-Origin-HTTPBin\", config.SecretHash)\n\n\tvar resp *http.Response\n\tmsg := fmt.Sprintf(\"test%d: failed to make http request\", statusCode)\n\n\tresp, err = requestWithRetry(client, req, resp, config.Retries, config.Debug, msg, host)\n\tif err != nil {\n\t\treturn\n\t}\n\tdefer resp.Body.Close()\n\n\t// in case the provided status code doesn't have a custom error page of its\n\t// own but uses a different status code, then enable the caller to provide\n\t// the correct status code that was expected to be handled for that code.\n\t//\n\t// for example, 503 should really return a 500 as there is currently no\n\t// custom error page for a 503 so we return the custom 500 instead.\n\tstatusToVerify := statusCode\n\tif len(defaultStatusCode) == 1 {\n\t\tstatusToVerify = defaultStatusCode[0]\n\t}\n\n\tif resp.StatusCode != statusToVerify {\n\t\terr := fmt.Errorf(resp.Status)\n\t\tmsg := fmt.Sprintf(\"test%d: unexpected response status code\", statusCode)\n\t\treport(host, msg, err)\n\t\tlog.Printf(\"%#v\\n\", resp)\n\t\treturn\n\t}\n\n\tbody, err := ioutil.ReadAll(resp.Body)\n\tif err != nil {\n\t\tmsg := fmt.Sprintf(\"test%d: failed to read response body\", statusCode)\n\t\treport(host, msg, err)\n\t\tlog.Printf(\"%#v\\n\", resp)\n\t\treturn\n\t}\n\n\tif !strings.Contains(string(body), needle) {\n\t\terr := fmt.Errorf(\"missing error message in body\")\n\t\tmsg := fmt.Sprintf(\"test%d: failed to load correct error page\", statusCode)\n\t\treport(host, msg, err)\n\t\tlog.Printf(\"%#v\\n\", resp)\n\t\treturn\n\t}\n\n\tif config.Debug {\n\t\tmsg := fmt.Sprintf(\"test%d: passed\", statusCode)\n\t\tlog.Println(host, msg)\n\t}\n}\n// retry accepts a function and retries it up to n times before returning an error\nfunc retry(n int, metricWriter metrics.Writer, kind string, cb func() error) error {\n\tvar err error\n\tif err = cb(); err == nil {\n\t\treturn nil\n\t}\n\n\tfor i := 0; i \u003c n; i++ {\n\t\tmetricWriter.Incr(\"api_gateway.retry\", 1.0, metrics.Tag{Key: \"kind\", Value: kind}, metrics.Tag{Key: \"error\", Value: err.Error()})\n\t\t// Full Jitter from https://aws.amazon.com/blogs/architecture/exponential-backoff-and-jitter/\n\t\t// backoff = random_between(0, baseBackoff * 2 ** attempt)\n\t\tmaxBackoff := float64(50*time.Millisecond) * math.Exp2(float64(i))\n\t\tbackoff := time.Duration(rand.Float64() * maxBackoff)\n\n\t\tlog.WithFields(log.Fields{\"retry_kind\": kind, \"count\": i, \"backoff\": backoff, \"error\": err}).Info(\"retrying, backing off.\")\n\n\t\ttime.Sleep(backoff)\n\n\t\terr = cb()\n\t\tif err == nil {\n\t\t\treturn nil\n\t\t}\n\t}\n\n\treturn err\n}\n","tags":"#go #http"},{"id":"89e39ecdd3fb2afc26ea898814689da7","title":"[Python print python version information] ","content":"#!/usr/bin/env python\n\nimport platform\nimport sys\n\nprint(platform.python_version())\nprint(sys.version)\n\n\"\"\"\nOutput:\n\n2.7.10\n2.7.10 (default, Feb 22 2019, 21:55:15) \n[GCC 4.2.1 Compatible Apple LLVM 10.0.1 (clang-1001.0.37.14)]\n\"\"\"\nimport sys\n\nif not sys.version_info \u003e= (3, 6, 0):\n    print(\"this script requires the use of Python 3.6+\")\n    sys.exit(1)\npython_version_check=$(python -c 'import sys; print(1 if sys.version_info \u003e= (3, 7, 0) else 0)')\nif [[ \"$python_version_check\" == \"1\" ]]; then\n  echo \"🐍  you have at least the minimum version of Python required.\"\nelse\n  printf \"\\n ❗️  your python version is below the minimum required - 3.7.0\\n\\n\"\n\n  read -p \"👉  Would you like to continue anyway? (y/N) \" -r\n  echo\n  if [[ $REPLY =~ ^[Nn]$ ]]; then\n    echo \"❌  Stopping setup. Please install or run the appropriate version of Python, then re-run this script.\"\n    exit 1\n  fi\nfi\n","tags":"#python #script #shell #version"},{"id":"df411140a5596abefa05f27647a4f25f","title":"[Bash default variable value for script arguments] ","content":"VAR=${1:-DEFAULTVALUE}  # assign either $1 or \"DEFAULTVALUE\" to $VAR\n\n#!/bin/bash\nn=3\necho ${!n}\n\n# ./args.sh apple banana cantaloupe dates\n#\n# would echo \"cantaloupe\"\n\n#!/bin/bash\nn=3\necho ${!n:=foo}\n\n# ./args.sh\n#\n# would echo \"foo\"\n","tags":"#bash #shell #scripting #cli #terminal #defaults"},{"id":"1f07858ef4c827a50c7edb164e0107c8","title":"[Python3 Virtual Environment with Pyenv] ","content":"- have Python 3 interpreter available (e.g. python3).\n- create a virtual environment (python3 -m venv /foo/bar)\n- activate the virtual environment (source /foo/bar/bin/activate)\n- manually(†) install dependencies (pip install j2cli pyyaml boto3)\n- have terraform version 0.10.7 installed (or use switcher: https://github.com/warrensbox/terraform-switcher)\n\n\u003e † for the project I was working on they did suggest I could also use the `-e, --editable` flag to install multiple deps required (this basically installs the deps locally and symlinks up the main imported package such that any changes made to the package code would be immediately reflected wherever you were importing that code).\n\nTo get different Python interpreters install `python-build` and `pyenv` (installing the latter should install both anyway).\n\ne.g. `brew install pyenv`\n\nThen you can check Python versions available with `python-build --definitions` and install them using (for example) `pyenv install 3.8-dev`.\n\nMake sure you add `eval \"$(pyenv init -)\"` to your bashrc so that when you go to a directory with `.python-version` file the shell will immediately activate the specified Python version (as long as it's installed that is).\n\nNow you can use `pyenv local 3.8-dev` to enable a Python version (which itself will create a `.python-version` file in that directory).\n\nFrom there you can install dependencies using `python -m pip install ...` or you can create a virtual environment to install them like so `mkdir ProjectA \u0026\u0026 pyenv virtualenv testing-a` (which requires `brew install pyenv-virtualenv`) and then activate it using `pyenv activate testing-a`.\n","tags":"#python3 #pip #deps #dependencies #venv #virtualenvironment #env #tfswitch #tf #terraform"},{"id":"d1c839f78041a64acd0113fdbaa2a3f1","title":"[Python Tornado Initialization and Multi-Process Mode] ","content":"from tornado.httpserver import HTTPServer\nfrom tornado.web import Application\n\nclass App(Application):\n    def __init__(self):\n        app_handlers = [\n            (r'/health', HealthHandler),\n            (r'/site-component/v{}/{}'.format(VERSION, COMPONENT), ComponentHandler),\n        ]\n        super().__init__(app_handlers, **app_settings)\n\n- App().listen(app_settings['port'])\n+ server = HTTPServer(App())\n+ server.listen(app_settings['port'])\nimport logging\n\nfrom tornado.process import cpu_count  # helps with logging available cpu\n\nlogging.info('Starting in forked mode on %s cpus', cpu_count())\n\nserver = HTTPServer(App())\nserver.bind(app_settings['port'])\nserver.start(0)  # multi process mode (one process per cpu)\n","tags":"#python #tornado #parallelization #multi-process #processes #cpu"},{"id":"b39b53e7f33970223eca5fb814c6add6","title":"[Golang HTTP Web Server Parallel Tee Goroutine per Request] ","content":"package main\n\nimport (\n    \"encoding/json\"\n    \"io/ioutil\"\n    \"net/http\"\n)\n\nvar largePool chan func()\nvar smallPool chan func()\n\nfunc main() {\n    // Start two different sized worker pools (e.g., for different workloads).\n    // Cancelation and graceful shutdown omited for brevity.\n\n    largePool = make(chan func(), 100)\n    smallPool = make(chan func(), 10)\n\n    for i := 0; i \u003c 100; i++ {\n            go func() {\n                    for f := range largePool {\n                            f()\n                    }\n            }()\n    }\n\n    for i := 0; i \u003c 10; i++ {\n            go func() {\n                    for f := range smallPool {\n                            f()\n                    }\n            }()\n    }\n\n    http.HandleFunc(\"/endpoint-1\", handler1)\n    http.HandleFunc(\"/endpoint-2\", handler2) // naming things is hard, okay?\n\n    http.ListenAndServe(\":8080\", nil)\n}\n\nfunc handler1(w http.ResponseWriter, r *http.Request) {\n    // Imagine a JSON body containing a URL that we are expected to fetch.\n    // Light work that doesn't consume many of *our* resources and can be done\n    // in bulk, so we put in in the large pool.\n    var job struct{ URL string }\n\n    if err := json.NewDecoder(r.Body).Decode(\u0026job); err != nil {\n            http.Error(w, err.Error(), http.StatusBadRequest)\n            return\n    }\n\n    go func() {\n            largePool \u003c- func() {\n                    http.Get(job.URL)\n                    // Do something with the response\n            }\n    }()\n\n    w.WriteHeader(http.StatusAccepted)\n}\n\nfunc handler2(w http.ResponseWriter, r *http.Request) {\n    // The request body is an image that we want to do some fancy processing\n    // on. That's hard work; we don't want to do too many of them at once, so\n    // so we put those jobs in the small pool.\n\n    b, err := ioutil.ReadAll(r.Body)\n    if err != nil {\n            http.Error(w, err.Error(), http.StatusInternalServerError)\n            return\n    }\n\n    go func() {\n            smallPool \u003c- func() {\n                    processImage(b)\n            }\n    }()\n    w.WriteHeader(http.StatusAccepted)\n}\n\nfunc processImage(b []byte) {}\n","tags":"#go #golang #tee #parallel #http #web #server #request #pool #concurrency"},{"id":"b81f2dd872f4dc3176ba1ce63dd68ce6","title":"[Golang Fastly Purge by URL and by Key] ","content":"// purgeByKey purges the Fastly edge cache by Surrogate-Key\nfunc purgeByKey(key, testCase string, config *settings.Config) {\n\tserviceID := config.FastlyIDProd\n\tif config.Environment == \"stage\" {\n\t\tserviceID = config.FastlyIDStage\n\t}\n\n\thost := \"https://api.fastly.com\"\n\tpath := fmt.Sprintf(\"/service/%s/purge/%s\", serviceID, key)\n\tpurgeURL := fmt.Sprintf(\"%s%s\", host, path)\n\n\treq, err := http.NewRequest(\"POST\", purgeURL, nil)\n\tif err != nil {\n\t\tmsg := fmt.Sprintf(\"test - %s: failed to create new 'purge key' request\", testCase)\n\t\treport(host, msg, err)\n\t}\n\n\tif config.Environment == \"stage\" {\n\t\treq.Header.Set(\"Fastly-Key\", config.FastlyTokenStage)\n\t} else {\n\t\treq.Header.Set(\"Fastly-Key\", config.FastlyTokenProd)\n\t}\n\n\tresp, err := http.DefaultClient.Do(req)\n\tif err != nil {\n\t\tmsg := fmt.Sprintf(\"test - %s: failed to make http 'purge key' request\", testCase)\n\t\treport(host, msg, err)\n\t}\n\tdefer resp.Body.Close()\n\n\tbody, err := ioutil.ReadAll(resp.Body)\n\tif err != nil {\n\t\tmsg := fmt.Sprintf(\"test - %s: failed to read 'purge key' response body\", testCase)\n\t\treport(host, msg, err)\n\t}\n\n\tif config.Debug {\n\t\tfmt.Printf(\"\\t'%s': %s\\n\\t\\t%s\", testCase, purgeURL, string(body))\n\t}\n}\n\n// purgeByURL purges the Fastly edge cache by URL\nfunc purgeByURL(host, path, testCase string, config *settings.Config) {\n\tpurgeURL := fmt.Sprintf(\"https://%s%s\", host, path)\n\n\treq, err := http.NewRequest(\"PURGE\", purgeURL, nil)\n\tif err != nil {\n\t\tmsg := fmt.Sprintf(\"test - %s: failed to create new 'purge url' request\", testCase)\n\t\treport(host, msg, err)\n\t}\n\n\tif config.Environment == \"stage\" {\n\t\treq.SetBasicAuth(config.BasicAuthUser, config.BasicAuthPass)\n\n\t\t// not all services use the same stage auth credentials\n\t\tif creds, ok := config.BasicAuthOverride[host]; ok {\n\t\t\treq.SetBasicAuth(creds[\"user\"], creds[\"pass\"])\n\t\t}\n\t}\n\n\t// headers required for purging Fastly's cached content\n\tif config.Environment == \"stage\" {\n\t\treq.Header.Set(\"Fastly-Key\", config.FastlyTokenStage)\n\t} else {\n\t\treq.Header.Set(\"Fastly-Key\", config.FastlyTokenProd)\n\t}\n\n\tresp, err := http.DefaultClient.Do(req)\n\tif err != nil {\n\t\tmsg := fmt.Sprintf(\"test - %s: failed to make http 'purge url' request\", testCase)\n\t\treport(host, msg, err)\n\t}\n\tdefer resp.Body.Close()\n\n\tbody, err := ioutil.ReadAll(resp.Body)\n\tif err != nil {\n\t\tmsg := fmt.Sprintf(\"test - %s: failed to read 'purge url' response body\", testCase)\n\t\treport(host, msg, err)\n\t}\n\n\tif config.Debug {\n\t\tfmt.Printf(\"\\t'%s': %s\\n\\t\\t%s\", testCase, purgeURL, string(body))\n\t}\n}\n","tags":"#fastly #go #golang #purge #cdn #cache"},{"id":"1ac45cfeab44d917d28c062346363684","title":"[Golang convert code into Assembly] ","content":"go tool compile -S main.go\n","tags":"#assembly #go #golang"},{"id":"96ef2d239c1743cf8cc7f9baec93404d","title":"[Security: Zero Trust Platform] ","content":"A zero trust platform means that (in theory), we'd be able to run malicious code _inside_ our platform with no risk – the code wouldn't be able to interact with anything dangerous without being granted special access by the platform's own security/infrastructure team.\n\nThe idea is that we don't want to trust just anything simply because it's inside our platform. Instead, we want individual services to be trusted based on a short and deliberate list of which other services they're allowed to interact with. This makes an attack substantially more difficult.\n","tags":"#security #zerotrust #zero #trust #platform"},{"id":"88d9a8ba3f33ce801ead28f04bbb65d3","title":"[Fakes vs Stubs vs Mocks] ","content":"## Fakes\n\nFake objects actually have working implementations, but usually take some shortcut which makes them not suitable for production (e.g. a working version of a datastore that has a get and set method but writes to local disk rather than actually writing to a database).\n\n## Stubs\n\nStubs provide canned answers to calls made during the test, usually not responding at all to anything outside what's programmed in for the test. Stubs may also record information about calls, such as an email gateway stub that remembers the messages it 'sent', or maybe only how many messages it 'sent'.\n\n## Mocks\n\nMocks are what we are talking about here: objects pre-programmed with expectations which form a specification of the calls they are expected to receive.\n\nAdditionally, mocks are seen as a thing that we will assert validations against. They have the responsiblity of recording how it was, or wasn't, used (e.g. \"assert that an API were called with xyz values\", \"assert that an endpoint was not called\", etc).\n","tags":"#fakes #stubs #mocks #testing"},{"id":"53e926c454e34cb76445c228ded41e95","title":"[Python Tornado Graceful Shutdown] ","content":"- Things tried and explanation of the problem/solution.\n- OLD CODE TESTING SCRATCH PAD -- Python Tornado Graceful Shutdown.py\n- Working Example -- Python 3.7 Tornado 5+ Example with tests.md\nWorking code (Python 3.7+)...\n\n```py\ndef sig_handler(server, sig, frame):\n    io_loop = IOLoop.current()\n    \n    def stop_loop(deadline):\n        now = time.time()\n        if now \u003c deadline and len(asyncio.all_tasks()) \u003e 0:\n            logging.info('waiting for next event loop tick')\n            io_loop.add_timeout(now + 1, stop_loop, deadline)\n        else:\n            io_loop.stop()\n            logging.info('event loop stopped')\n            \n    async def shutdown():\n        logging.info('stop listening for new connections')\n        server.stop()\n        logging.info(f'stopping event loop in {SHUTDOWN_TIMEOUT} seconds')\n        # await server.close_all_connections() \u003c\u003c don't use unless you WANT to kill all client connections immediately\n        stop_loop(time.time() + SHUTDOWN_TIMEOUT)\n        \n    io_loop.add_callback_from_signal(shutdown)\n```\n\nTo recap what we had tried, that failed (iirc)...\n\n- calling `tornado.httpserver.HTTPServer#close_all_connections`:  \n  this wasn't documented, only found via source code  \n  it didn't actually do _anything_ in Python 3.6 (even though its implemented? but it worked in later versions)  \n  i.e. when not using a timeout it still didn't wait for the in-flight requests to complete\n\n- checking timeout deadline and `io_loop._callbacks`/`io_loop._timeouts`:  \n  this would have helped close the event loop sooner  \n  but didn't work once we migrated to latest tornado as internal properties were deprecated  \n  couldn't find alternative properties to rely on  \n  either way I don't think we should rely on really old tornado versions\n\n- use asyncio's event loop with `run_until_complete` and `shutdown_asyncgens`:  \n  didn't work and I'm now not quite sure why.  \n  at first it seemed like it was because tornado wraps the asyncio loop  \n  and that maybe it was not exposing these methods directly  \n  but the following calls all look to return the _same_ event loop instance...\n    - `tornado.ioloop.IOLoop.current()`\n    - `tornado.ioloop.IOLoop.current().asyncio_loop` \u003c\u003c internally where asyncio loop is stored\n    - `asyncio.get_event_loop()`\n\n- I also tried updating to Python 3.8 so I could use `asyncio.all_tasks(loop=io_loop)`  \n  this function should return all running tasks on the event loop.  \n  each http request is a unique event loop 'task'  \n  so if we shutdown while there are running tasks, they should be returned  \n  unfortunately this just yielded an empty set data structure  \n  the `io_loop` variable we pass to the constructor is a tornado event loop (which itself should be the underlying asyncio event loop)\n  \n- `all_tasks` works! but only if you omit the `loop` argument  \n  this lets asyncio use `get_running_loop` to acquire the event loop\n#!/usr/bin/env python\n\n\"\"\"\nHow to use it:\n1. Just `kill -2 PROCESS_ID` or `kill -15 PROCESS_ID`,\n   The Tornado Web Server Will shutdown after process all the request.\n2. When you run it behind Nginx, it can graceful reboot your production server.\n\n\u003e Note: the original version of this code didn't account for closing in-flight requests. There is a method (not documented other than sifting through the tornado source code for its HTTPServer class) that supposedly handles this, called `close_all_connections` but that doesn't seem to work when I tested it (not sure why :shrugs:). But the below version does try and account for checking internal properties `_callbacks` or `_timeouts` (which are only available for older versions of tornado, so the code doesn't work for version 5+).\n\nSee alternative approach (uses tornado.gen.sleep instead of ioloop ticks):\nhttps://github.com/tornadoweb/tornado/issues/1791#issuecomment-409258371\n\n    async def shutdown():\n        logging.info('Stopping http server')\n        server.stop()\n        await server.close_all_connections()\n        logging.info('Will shutdown in %s seconds ...', SHUTDOWN_TIMEOUT)\n        await tornado.gen.sleep(SHUTDOWN_TIMEOUT)\n        ioloop.IOLoop.current().stop()\n        \n\u003e Note: a lot of these examples are problematic or don't quite work due to the incompatible nature of tornado's IOLoop vs asyncio's. In Tornado version 5.0+ their IOLoop became a wrapper around asyncio's but even then they only expose a small number of methods that proxy to the underlying IOLoop, so methods like `run_until_complete` and `shutdown_asyncgens` (see below example) just don't work.\n\n    def shutdown():\n        logging.info('Stopping http server')\n        server.stop()\n        io_loop.run_until_complete(io_loop.shutdown_asyncgens())\n        io_loop.close()\n\nThe following are all the same event loop instance...\n\n- tornado.ioloop.IOLoop.current()\n- tornado.ioloop.IOLoop.current().asyncio_loop\n- asyncio.get_event_loop()\n\n## UPDATE\n\nThe best I've been able to achieve with latest tornado (6.0.3) is...\n\ndef sig_handler(server, sig, frame):\n    io_loop = IOLoop.current()\n\n    async def shutdown():\n        logging.info('stop listening for new connections')\n        server.stop()\n        logging.info(f'stopping event loop in {SHUTDOWN_TIMEOUT} seconds')\n        await tornado.gen.sleep(SHUTDOWN_TIMEOUT)\n        io_loop.stop()\n        logging.info('event loop stopped')\n\n    io_loop.add_callback_from_signal(shutdown)\n    \n## UPDATE 2 -- BETTER SOLUTION\n\ndef sig_handler(server, sig, frame):\n    io_loop = IOLoop.current()\n\n    def stop_loop(deadline):\n        now = time.time()\n        logging.info(f'len(asyncio.all_tasks()): {len(asyncio.all_tasks())}')\n        if now \u003c deadline and len(asyncio.all_tasks()) \u003e 0:\n            logging.info('waiting for next event loop tick')\n            io_loop.add_timeout(now + 1, stop_loop, deadline)\n        else:\n            io_loop.stop()\n            logging.info('event loop stopped')\n\n    async def shutdown():\n        logging.info('stop listening for new connections')\n        server.stop()\n        logging.info(f'stopping event loop in {SHUTDOWN_TIMEOUT} seconds')\n        # await server.close_all_connections() \u003c\u003c don't use unless you WANT to kill all client connections immediately\n        stop_loop(time.time() + SHUTDOWN_TIMEOUT)\n\n    io_loop.add_callback_from_signal(shutdown)\n\"\"\"\n\nimport time\nimport signal\nimport logging\nfrom functools import partial\n\nimport tornado.httpserver\nimport tornado.ioloop\nimport tornado.options\nimport tornado.web\n\nfrom tornado.options import define, options\n\ndefine(\"port\", default=8888, help=\"run on the given port\", type=int)\n\nMAX_WAIT_SECONDS_BEFORE_SHUTDOWN = 3\n\n\nclass MainHandler(tornado.web.RequestHandler):\n    def get(self):\n        self.write(\"Hello, world\")\n\n\ndef sig_handler(server, sig, frame):\n    io_loop = tornado.ioloop.IOLoop.instance()\n\n    def stop_loop(deadline):\n        now = time.time()\n        if now \u003c deadline and (io_loop._callbacks or io_loop._timeouts):\n            logging.info('Waiting for next tick')\n            io_loop.add_timeout(now + 1, stop_loop, deadline)\n        else:\n            io_loop.stop()\n            logging.info('Shutdown finally')\n\n    async def shutdown():\n        logging.info('Stopping http server')\n        server.stop()\n        logging.info('Will shutdown in %s seconds ...',\n                     MAX_WAIT_SECONDS_BEFORE_SHUTDOWN)\n        await server.close_all_connections()\n        stop_loop(time.time() + MAX_WAIT_SECONDS_BEFORE_SHUTDOWN)\n\n    logging.warning('Caught signal: %s', sig)\n    io_loop.add_callback_from_signal(shutdown)\n\n\ndef main():\n    tornado.options.parse_command_line()\n    application = tornado.web.Application([\n        (r\"/\", MainHandler),\n    ])\n\n    server = tornado.httpserver.HTTPServer(application)\n    server.listen(options.port)\n\n    signal.signal(signal.SIGTERM, partial(sig_handler, server))\n    signal.signal(signal.SIGINT, partial(sig_handler, server))\n\n    tornado.ioloop.IOLoop.instance().start()\n\n    logging.info(\"Exit...\")\n\n\nif __name__ == \"__main__\":\n    main()\n## Code\n\n\u003e `bf_tornado.signals` module\n\n```python\n\"\"\"signals module provides helper functions for tornado graceful shutdown.\"\"\"\n\nimport asyncio\nimport functools\nimport signal\nimport time\n\nfrom tornado.httpserver import HTTPServer\nfrom tornado.ioloop import IOLoop\n\nSHUTDOWN_TIMEOUT = 30\n\n\nasync def shutdown(server: HTTPServer, timeout: int, io_loop: IOLoop):\n    \"\"\"Stop HTTPServer and schedule stopping of ioloop.\"\"\"\n\n    # stop listening for new connections\n    server.stop()\n\n    # schedule ioloop shutdown\n    deadline = time.time() + timeout\n    graceful_shutdown(deadline, io_loop)\n\n\ndef graceful_shutdown(deadline: float, io_loop: IOLoop):\n    \"\"\"Gracefully shutdown ioloop by allowing tasks to complete by deadline.\"\"\"\n\n    now = time.time()\n    tasks = asyncio.all_tasks()\n\n    if now \u003c deadline and len(tasks) \u003e 0:\n        # defer shutdown until all tasks have a chance to complete\n        io_loop.add_timeout(now + 1, graceful_shutdown, deadline, io_loop)\n    else:\n        stop_loop(io_loop)\n\n\ndef stop_loop(io_loop: IOLoop):\n    \"\"\"Stop the ioloop.\n\n    This oneline function isn't inlined as it allows for simpler mocking within\n    our bf_tornado test suite.\n    \"\"\"\n\n    io_loop.stop()\n\n\ndef sig_handler(server: HTTPServer, timeout: int, sig, frame):\n    \"\"\"Schedules ioloop shutdown after specified timeout when TERM/INT signals received.\n\n    In-flights tasks running on the asyncio event loop will be given the\n    opportunity to finish before the loop is shutdown after specified timeout.\n\n    Expects to be initiated using partial application:\n        functools.partial(sig_handler, HTTPServer())\n    This partial application is typically handled by signals.sig_listener.\n    \"\"\"\n\n    io_loop = IOLoop.current()\n\n    # execute callback on next event loop tick\n    io_loop.add_callback_from_signal(shutdown, server, timeout, io_loop)\n\n\ndef sig_listener(server: HTTPServer, timeout: int = 0):\n    \"\"\"Configures listeners for TERM/INT signals.\n\n    Timeout should be a positive integer, otherwise a default will be provided.\n    \"\"\"\n\n    if not timeout:\n        timeout = SHUTDOWN_TIMEOUT\n\n    p = functools.partial(sig_handler, server, timeout)\n\n    signal.signal(signal.SIGTERM, p)\n    signal.signal(signal.SIGINT, p)\n```\n\n## Tests\n\n```python\nimport asyncio\nimport os\nimport signal\nimport threading\nimport time\nfrom unittest import mock\n\nimport bf_metrics\n\nimport bf_tornado.handlers\nimport bf_tornado.signals\n\nimport tornado.gen\nimport tornado.ioloop\nimport tornado.testing\nimport tornado.util\nimport tornado.web\n\n\nclass TestGracefulShutdown(tornado.testing.AsyncHTTPTestCase):\n    \"\"\"Verify server allows in-flight requests to complete before shutdown.\n\n    Note: we're using tornado's `yield` abstraction instead of proper\n    async/await syntax because of the use of `gen_test` decorator to work\n    around fact the ioloop isn't running when running the test suite.\n\n    This also means we need to use the `get_url` abstraction function to\n    convert the requested path into a fully qualified path to the locally\n    running web server.\n    \"\"\"\n    def get_app(self):\n        class FooHandler(bf_tornado.handlers.BaseHandler):\n            metrics = bf_metrics.Metrics(namespace='foo', host='localhost')\n\n            async def get(self):\n                await asyncio.sleep(3)\n                self.finish('OK')\n\n        return tornado.web.Application([\n            (r'/', FooHandler)\n        ])\n\n    def tearDown(self):\n        \"\"\"Ensure we verify the `stop_loop` mock was called.\"\"\"\n\n        try:\n            self.mock_stop_loop.assert_called()\n        except AssertionError:\n            self.fail(\"mock_stop_loop assertion failed\")\n\n    @mock.patch(\"bf_tornado.signals.stop_loop\")\n    @tornado.testing.gen_test\n    def test_inflight_completed(self, mock_stop_loop):\n        \"\"\"verify in-flight request completes after SIGINT is received.\n\n        The test flow is:\n\n            - make network request\n            - issue interrupt signal (via separate thread)\n            - network request completes before ioloop shutdown timeout\n\n        We mock the `stop_loop` function which is what would normally trigger\n        the ioloop to be stopped. So although we issue a SIGINT it won't\n        actually stop the ioloop that is running this test.\n\n        The request flow means the web server request will complete BEFORE the\n        mocked `stop_loop` function has been called. This is a problem because\n        the test function will finish executing and thus the assertion check at\n        that time is likely to fail.\n\n        To solve this problem, we sleep to enable enough time for the\n        `stop_loop` function to be called, then we assign the mock to the class\n        so that we can reference it within the tearDown function. That gives\n        our asynchronous task time to be called.\n        \"\"\"\n\n        # ensure ioloop waits long enough for request to complete\n        shutdown_timeout = 10\n        bf_tornado.signals.sig_listener(self.http_server, shutdown_timeout)\n\n        pid = os.getpid()\n\n        def trigger_signal():\n            # defer SIGNINT long enough to allow HTTP request to tornado server\n            time.sleep(1)\n            os.kill(pid, signal.SIGINT)\n\n        thread = threading.Thread(target=trigger_signal)\n        thread.daemon = True\n        thread.start()\n\n        resp = yield self.http_client.fetch(self.get_url('/'))\n        assert resp.code == 200\n\n        # this sleep causes tornado's ioloop to context switch back to active\n        # when this test function finishes (and before the tearDown) is\n        # triggered, thus allowing the async task to call the stop_loop mock.\n        time.sleep(1)\n\n        # we can't assert the mock was called from this test function as the\n        # test function itself is blocking the ioloop background task.\n        #\n        # the reason it blocks is because the http request is designed to\n        # finish before the shutdown timeout and so once we're back inside the\n        # test function we cannot context switch back to the asyncio task that\n        # is trying to verify if it should call `stop_loop`.\n        #\n        # this means we must assert against the mock within a tearDown function.\n        self.mock_stop_loop = mock_stop_loop\n\n    @mock.patch(\"bf_tornado.signals.stop_loop\")\n    @tornado.testing.gen_test\n    def test_inflight_dropped(self, mock_stop_loop):\n        \"\"\"verify in-flight request is dropped after SIGINT is received.\n\n        The test flow is:\n\n            - make network request\n            - issue interrupt signal (via separate thread)\n            - ioloop shuts down before network request completes\n\n        We mock the `stop_loop` function which is what would normally trigger\n        the ioloop to be stopped. So although we issue a SIGINT it won't\n        actually stop the ioloop that is running this test.\n\n        The request flow means the web server request will NOT complete before\n        the mocked `stop_loop` function has been called.\n        \"\"\"\n\n        # reset mock property\n        self.mock_stop_loop = mock_stop_loop\n\n        # ensure ioloop does NOT wait long enough for request to complete\n        shutdown_timeout = 1\n        bf_tornado.signals.sig_listener(self.http_server, shutdown_timeout)\n\n        pid = os.getpid()\n\n        def trigger_signal():\n            # defer SIGNINT long enough to allow HTTP request to tornado server\n            time.sleep(1)\n            os.kill(pid, signal.SIGINT)\n\n        thread = threading.Thread(target=trigger_signal)\n        thread.daemon = True\n        thread.start()\n\n        resp = yield self.http_client.fetch(self.get_url('/'))\n        assert resp.code == 200\n\n        # we can assert the mock was called here because the background asyncio\n        # task has completed (i.e. called `stop_loop`) by the time the http\n        # request has completed.\n        mock_stop_loop.assert_called()\n```\n","tags":"#python #python3 #tornado #graceful #shutdown #signals #sigterm #sigint"},{"id":"c08b1ab3e9dd508b1ccc5fe768d1a9b0","title":"[Fastly Clustering and Shielding Example] ","content":"The below VCL snippets are expected to be run on https://fiddle.fastlydemo.net/\n\n\u003e Note: they are copied verbatim from https://fiddle.fastlydemo.net/fiddle/72e0d619\n\n## vcl_recv\n\n```vcl\nif (req.backend.is_shield)\n{\n  set req.http.shield = \"This is on the Edge PoP (req.backend.is_shield)\";\n}\nelse {\n  set req.http.shield = \"This is on the shield PoP(!req.backend.is_shield)\";\n}\nif(req.backend.is_cluster)\n{\n  set req.http.cluster = \"this is in a clustering state (hit/miss-cluster)(req.backend.is_cluster)\";\n}\nelse {\n set req.http.cluster = \"this is not in a clustering state (hit/miss-cluster)(!req.backend.is_cluster)\";\n}\nif (!req.http.Fastly-FF) {\n  set req.http.x-status = \"edge node(!req.http.Fastly-FF)\";\n}\nelse {\n  set req.http.x-status = \"fetch/cluster node(req.http.Fastly-FF)\";\n}\n\nif (req.http.Fastly-FF) {\n  set req.http.x-otherstatus = \"fetch/cluster node(req.http.Fastly-FF)\";\n}\nelse {\n  set req.http.x-otherstatus = \"edge node(!req.http.Fastly-FF)\";\n}\n\nlog req.http.shield;\nlog req.http.cluster;\nlog req.http.x-status;\nlog req.http.x-otherstatus;\n```\n\n## vcl_hit\n\n```vcl\nif (req.backend.is_shield)\n{\n  set req.http.shield = \"This is on the Edge PoP (req.backend.is_shield)\";\n}\nelse {\n  set req.http.shield = \"This is on the shield PoP(!req.backend.is_shield)\";\n}\nif(req.backend.is_cluster)\n{\n  set req.http.cluster = \"this is in a clustering state (hit/miss-cluster)(req.backend.is_cluster)\";\n}\nelse {\n set req.http.cluster = \"this is not in a clustering state (hit/miss-cluster)(!req.backend.is_cluster)\";\n}\nif (!req.http.Fastly-FF) {\n  set req.http.x-status = \"edge node(!req.http.Fastly-FF)\";\n}\nelse {\n  set req.http.x-status = \"fetch/cluster node(req.http.Fastly-FF)\";\n}\n\nif (req.http.Fastly-FF) {\n  set req.http.x-otherstatus = \"fetch/cluster node(req.http.Fastly-FF)\";\n}\nelse {\n  set req.http.x-otherstatus = \"edge node(!req.http.Fastly-FF)\";\n}\n\nlog req.http.shield;\nlog req.http.cluster;\nlog req.http.x-status;\nlog req.http.x-otherstatus;\n```\n\n## vcl_miss\n\n```vcl\nif(req.backend.is_origin){\n  set req.http.origin = \"I am fetching the origin's contents(req.backend.is_origin)\";\n}\nelse{\n set req.http.origin = \"I am not fetching the origin's contents(!req.backend.is_origin)\";\n}\n\nif (req.backend.is_shield)\n{\n  set req.http.shield = \"This is on the Edge PoP (req.backend.is_shield)\";\n}\nelse {\n  set req.http.shield = \"This is on the shield PoP(!req.backend.is_shield)\";\n}\nif(req.backend.is_cluster)\n{\n  set req.http.cluster = \"this is in a clustering state (hit/miss-cluster)(req.backend.is_cluster)\";\n}\nelse {\n set req.http.cluster = \"this is not in a clustering state (hit/miss-cluster)(!req.backend.is_cluster)\";\n}\nif (!req.http.Fastly-FF) {\n  set req.http.x-status = \"edge node(!req.http.Fastly-FF)\";\n}\nelse {\n  set req.http.x-status = \"fetch/cluster node(req.http.Fastly-FF)\";\n}\n\nif (req.http.Fastly-FF) {\n  set req.http.x-otherstatus = \"fetch/cluster node(req.http.Fastly-FF)\";\n}\nelse {\n  set req.http.x-otherstatus = \"edge node(!req.http.Fastly-FF)\";\n}\n\nlog req.http.shield;\nlog req.http.cluster;\nlog req.http.origin;\nlog req.http.x-status;\nlog req.http.x-otherstatus;\n```\n\n## vcl_fetch\n\n```vcl\nif (req.backend.is_shield)\n{\n  set req.http.shield = \"This is on the Edge PoP (req.backend.is_shield)\";\n}\nelse {\n  set req.http.shield = \"This is on the shield PoP(!req.backend.is_shield)\";\n}\nif(req.backend.is_cluster)\n{\n  set req.http.cluster = \"this is in a clustering state (hit/miss-cluster)(req.backend.is_cluster)\";\n}\nelse {\n set req.http.cluster = \"this is not in a clustering state (hit/miss-cluster)(!req.backend.is_cluster)\";\n}\nif (!req.http.Fastly-FF) {\n  set req.http.x-status = \"edge node(!req.http.Fastly-FF)\";\n}\nelse {\n  set req.http.x-status = \"fetch/cluster node(req.http.Fastly-FF)\";\n}\n\nif (req.http.Fastly-FF) {\n  set req.http.x-otherstatus = \"fetch/cluster node(req.http.Fastly-FF)\";\n}\nelse {\n  set req.http.x-otherstatus = \"edge node(!req.http.Fastly-FF)\";\n}\n\nlog req.http.shield;\nlog req.http.cluster;\nlog req.http.x-status;\nlog req.http.x-otherstatus;\n```\n\n## vcl_deliver\n\n```vcl\nif (req.backend.is_shield)\n{\n  set req.http.shield = \"This is on the Edge PoP (req.backend.is_shield)\";\n}\nelse {\n  set req.http.shield = \"This is on the shield PoP(!req.backend.is_shield)\";\n}\nif(req.backend.is_cluster)\n{\n  set req.http.cluster = \"this is in a clustering state (hit/miss-cluster)(req.backend.is_cluster)\";\n}\nelse {\n set req.http.cluster = \"this is not clustering(!req.backend.is_cluster)\";\n}\nif (!req.http.Fastly-FF) {\n  set req.http.x-status = \"edge node(!req.http.Fastly-FF)\";\n}\nelse {\n  set req.http.x-status = \"fetch/cluster node(req.http.Fastly-FF)\";\n}\n\nif (req.http.Fastly-FF) {\n  set req.http.x-otherstatus = \"fetch/cluster node(req.http.Fastly-FF)\";\n}\nelse {\n  set req.http.x-otherstatus = \"edge node(!req.http.Fastly-FF)\";\n}\n\nlog req.http.shield;\nlog req.http.cluster;\nlog req.http.x-status;\nlog req.http.x-otherstatus;\n\nif (req.restarts == 0) {\n  log \"return(restart) once to see if edge nodes now show is_cluster:1\";\n  set req.url = \"/status/201\";\n  set req.http.Fastly-Force-Shield = \"1\";\n  return(restart);\n}\n```\n","tags":"#fastly #varnish #vcl #clustering #shielding #cluster #shield"},{"id":"d16924d70b14502cbe5bb443ac62a09b","title":"[Bash string wildcard glob conains example] ","content":"#!/bin/bash\n\n# our CDN was serving stale content for a request that shouldn't be\n# so we wrote a quick script to verify the behaviour wasn't happening\n# more often than it should.\n\nfunction get {\n  local id=$1\n  local url=\"https://www.example.com/?id=$id\"\n\n  local response=$(curl -D - -so /dev/null -H 'X-Debug:1' \"$url\")\n  local state=$(echo \"$response\" | grep 'Foo-State')\n\n  echo \"$state\"\n}\n\nfor i in {1..50}\ndo\n  uid=\"attempt-$i-$(uuidgen)\"\n\n  result1=$(get \"$uid\")\n  result2=$(get \"$uid\")\n\n  if [[ \"$result2\" == *\"HIT-STALE\"* ]]; then\n    echo \"$uid: got stale :-(\"\n  elif [[ \"$result2\" == *\"HIT-\"* ]]; then\n    echo \"$uid: was fine :-)\"\n  fi\ndone\n","tags":"#bash #wildcard #glob #contains"},{"id":"66a3723e5a69fe355f2cade31a1070e8","title":"[Bash Hash Bang] ","content":"A typical bash script will identify where its interpreter can be found...\n\n```bash\n#!/bin/bash\n```\n\nBut this doesn't always work because bash might be installed in a different location.\n\nFor example, macOS has an old version of bash (or in more modern releases it has swapped bash completely for zsh) and so a user might manually install an updated version of bash which will go into a different directory...\n\n```bash\n#!/usr/local/bin/bash\n```\n\nTo make your scripts portable across different systems you should reference the `env` executable and pass it the command you want it to locate (i.e. `bash` in this case)...\n\n```bash\n#!/usr/bin/env bash\n```\n\nThe `env` executable will use whatever bash executable appears first in the running user's `$PATH` variable. \n\nIf you have two version of bash installed (bash1 in `/bin` and bash2 in `/usr/local/bin`) and your PATH was set like so: `/home/foo/bin:/usr/local/bin:/usr/bin:/bin` than bash2 would execute the script.\n\nYou can use either `type env` or `command -V env` to locate where the `env` command is installed.\n","tags":"#bash #hash #bang"},{"id":"831298624d7171b155dd58b45341c576","title":"[Develop Streamlink Locally] ","content":"# clone streamlink\ngit pull https://github.com/streamlink/streamlink.git\ncd streamlink/\n\n# install virtual environment\npython3 -m venv venv\nsource venv/bin/activate\n\n# update virtual environment\npython -m pip install -U pip setuptools\npip install -U -r dev-requirements.txt\npip install -U -r docs-requirements.txt\n\n# install dev streamlink\npip install -e .\n\n# streamlink should now work with every change you make\nstreamlink\n\n# you can also run the test files locally\npytest tests/\n\n# or for a plugin\npytest tests/plugins/test_youtube.py\n","tags":"#streamlink #video #download #stream"},{"id":"c662fe35041e9a66facce222cba32643","title":"[Golang http.Request.Context] ","content":"// https://goplay.tools/snippet/YB3_8gerQ-U\npackage main\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"net/http\"\n)\n\nconst beepboop = \"whatever\"\n\ntype User struct {\n\tName string\n}\n\nfunc main() {\n\tfmt.Printf(\"beepboop: %#v\\n\\n\", beepboop)\n\tr := new(http.Request)\n\tfmt.Printf(\"r: %#v\\n\\n\", r)\n\tc := r.Context()\n\tfmt.Printf(\"c: %#v\\n\\n\", c)\n\tnc := context.WithValue(c, \"foo\", \"bar\")\n\tfmt.Printf(\"nc: %#v\\n\\n\", nc)\n\tif v := nc.Value(\"foo\"); v != nil {\n\t\tfmt.Printf(\"found value in nc context: %#v (%T)\\n\\n\", v, v)\n\t}\n\tnc2 := context.WithValue(nc, beepboop, 123)\n\tfmt.Printf(\"nc2: %#v\\n\\n\", nc2)\n\tif v := nc2.Value(beepboop); v != nil {\n\t\tfmt.Printf(\"found value in nc2 context: %#v (%T)\\n\\n\", v, v)\n\t}\n\tu := User{Name: \"integralist\"}\n\tnc3 := context.WithValue(nc2, \"some_other_key\", \u0026u)\n\tfmt.Printf(\"nc3: %#v\\n\\n\", nc3)\n\tif v := nc3.Value(\"some_other_key\"); v != nil {\n\t\tfmt.Printf(\"found value in nc3 context: %#v (%T)\\n\\n\", v, v)\n        // IMPORTANT: Although Printf looks to show the type it's not concrete.\n        // We're actually dealing with any empty interface{}/any type.\n        // So we have to coerce it. There's no type saftey.\n\t\tu, ok := v.(*User)\n\t\tif ok {\n\t\t\tfmt.Println(u.Name)\n\t\t}\n\t}\n}\n\n/*\nbeepboop: \"whatever\"\n\nr: \u0026http.Request{Method:\"\", URL:(*url.URL)(nil), Proto:\"\", ProtoMajor:0, ProtoMinor:0, Header:http.Header(nil), Body:io.ReadCloser(nil), GetBody:(func() (io.ReadCloser, error))(nil), ContentLength:0, TransferEncoding:[]string(nil), Close:false, Host:\"\", Form:url.Values(nil), PostForm:url.Values(nil), MultipartForm:(*multipart.Form)(nil), Trailer:http.Header(nil), RemoteAddr:\"\", RequestURI:\"\", TLS:(*tls.ConnectionState)(nil), Cancel:(\u003c-chan struct {})(nil), Response:(*http.Response)(nil), Pattern:\"\", ctx:context.Context(nil), pat:(*http.pattern)(nil), matches:[]string(nil), otherValues:map[string]string(nil)}\n\nc: context.backgroundCtx{emptyCtx:context.emptyCtx{}}\n\nnc: \u0026context.valueCtx{Context:context.backgroundCtx{emptyCtx:context.emptyCtx{}}, key:\"foo\", val:\"bar\"}\n\nfound value in nc context: \"bar\" (string)\n\nnc2: \u0026context.valueCtx{Context:(*context.valueCtx)(0xc00011a840), key:\"whatever\", val:123}\n\nfound value in nc2 context: 123 (int)\n\nnc3: \u0026context.valueCtx{Context:(*context.valueCtx)(0xc00011a8a0), key:\"some_other_key\", val:(*main.User)(0xc000106100)}\n\nfound value in nc3 context: \u0026main.User{Name:\"integralist\"} (*main.User)\n\nintegralist\n*/\n\n","tags":"#go #golang #http #request #context"},{"id":"41a1e77cd7e55439ca66d2591d772beb","title":"[SQL get unique values using BigQuery] ","content":"SELECT\n  http.status_code\nFROM\n  `foo-bar.baz.qux`\nGROUP BY\n  http.status_code\nLIMIT\n  20\n  \n/*\nProject: foo-bar\nDataset: baz\nTable: qux\n\nBecause the datasource includes hyphens we need to wrap it in backticks.\n*/\n","tags":"#bigquery #google #data #sql #unique"},{"id":"0068812f12b4c72ee8e9d10ce38a1ed9","title":"[Golang Read HTTP Response Body TWICE!] ","content":"// ReadBody reads the provided http.Response#Body and resets it to a type that\n// would result in a additional read of the body to not trigger an error.\n//\n// this is to side-step the default behaviour, which for attempting to read a\n// response body twice, is to error with: `http: read on closed response body`.\n//\n// the reason we have to do this is because when\n// httputil.ReverseProxy#ModifyResponse returns an error, the internal\n// implementation calls `r.Body.Close()` automatically before calling\n// httputil.ReverseProxy#ErrorHandler.\n//\n// source code reference:\n// https://github.com/golang/go/blob/18107ed9fbdb0d2ae1006857e21a8a66882e12dd/src/net/http/httputil/reverseproxy.go#L170\nfunc ReadBody(r *http.Response) []byte {\n\tbody, err := ioutil.ReadAll(r.Body)\n\tif err != nil {\n\t\tbody = []byte(http.StatusText(r.StatusCode))\n\t}\n\n\tr.Body.Close()\n\tr.Body = ioutil.NopCloser(bytes.NewBuffer(body))\n\n\treturn body\n}\n\n// PROBABLY BETTER TO USE bytes.NewReader instead of bytes.NewBuffer\n","tags":"#go #golang #http #response #body #read"},{"id":"524be67b0b33e8087dd67a5a6af9b3c5","title":"[Example System Contract for Caching Behaviours] ","content":"## Caching\n\n- `Cache-Control`: used if provided, otherwise default will be set.\n- `Surrogate-Control`: augmented if provided, otherwise default will be set.\n\n### Augmentation\n\nPerimeter will augment the provided `Surrogate-Control` by appending `stale-while-revalidate` and `stale-if-error` directives if they are not defined.\n\n\u003e See also \"[Extensions](#extensions)\" section below.\n\n### Defaults\n\nIf no `Cache-Control` nor `Surrogate-Control` is provided, Perimeter will use the following default caching/stale directives:\n\n- `Cache-Control`: `no-store`\n- `Surrogate-Control`: `max-age=%d, stale-while-revalidate=%d, stale-if-error=%d`\n\n\u003e Note: `%d` is a placeholder for the actual value set in Perimeter's `config.yml`\n\n### Exceptions\n\nThere are a few exceptions to the [defaults](#defaults) defined above:\n\n- Static file requests (i.e. proxied to AWS S3) will have a longer `max-age` (it uses the `stale-if-error` value).\n- Smoke requests (see `smoke_path` in `config.yml`) disables all caching.\n\n### Extensions\n\nBoth `Cache-Control` and `Surrogate-Control` have additional directives related to serving stale content, which are not part of the core HTTP caching standards document. These are `stale-while-revalidate` and `stale-if-error`.\n\nFastly CDN supports both of these extension directives via `Surrogate-Control`, but client compatibility (i.e. web browser support) via `Cache-Control` is less consistent.\n\nPerimeter will only augment `Surrogate-Control`, it will _not_ augment `Cache-Control`.\n\n### Status Codes\n\nThe CDN will only cache the following status code responses:\n\n- `200 OK`\n- `203 Non-Authoritative Information`\n- `300 Multiple Choices`\n- `301 Moved Permanently`\n- `302 Moved Temporarily`\n- `404 Not Found`\n- `410 Gone`\n","tags":"#system #contract #architecture #design #interface #SLA #fastly #cdn"},{"id":"1ca0b1acb0d65af19df9d38618b5058f","title":"[Safe Tech Terminology] ","content":"- `Blacklist`/`Whitelist` \u003e `Denylist`/`Allowlist`\n- `Master`/`Slave` \u003e `Primary`/`Replica`\n\n\u003e Note: we specifically choose to use 'denylist' instead of 'blocklist' as it is harder to be misheard (depending on the accent of the person speaking).\n","tags":"#safe #terminology #tech"},{"id":"644f8794ff272734d12ffaa77e05f51a","title":"[Go Time Formating + Conversions and Comparisons + Stale] ","content":"package check\n\nimport \"time\"\n\n// Stale validates if the given time is older than the given duration.\n//\n// EXAMPLE:\n// dur is a string like \"24h\", \"10m\" or \"5s\".\nfunc Stale(lastVersionCheck string, dur string) bool {\n    // Notice we prefix with a minute. \n    // This means we can use the `.Add()` function \n    // and it'll still work because it'll just _subtract_ the specified duration.\n\td, err := time.ParseDuration(\"-\" + dur)\n\tif err != nil {\n\t\treturn false\n\t}\n\n\tif t, _ := time.Parse(time.RFC3339, lastVersionCheck); !t.Before(time.Now().Add(d)) {\n\t\treturn false\n\t}\n\treturn true\n}\n\npackage main\n\nimport (\n\t\"fmt\"\n\t\"log\"\n\t\"os\"\n\t\"time\"\n\n\t\"github.com/theckman/yacspin\"\n)\n\nfunc main() {\n\tspinner, err := yacspin.New(yacspin.Config{\n\t\tCharSet:           yacspin.CharSets[9],\n\t\tFrequency:         100 * time.Millisecond,\n\t\tStopCharacter:     \"✓\",\n\t\tStopColors:        []string{\"fgGreen\"},\n\t\tStopFailCharacter: \"✗\",\n\t\tStopFailColors:    []string{\"fgRed\"},\n\t\tSuffix:            \" \",\n\t\tWriter:            os.Stdout,\n\t})\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\n\tsecs := 10\n\tdur := time.Duration(secs) * time.Second\n\tend := time.Now().Add(dur)\n\ttimeout := time.After(dur)\n\tticker := time.NewTicker(1 * time.Second)\n\n\terr = spinner.Start()\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\tmsg := \"Checking service availability\"\n\tspinner.Message(msg + generateTimeout(time.Until(end)))\n\n\tfor {\n\t\tselect {\n\t\tcase \u003c-timeout:\n\t\t\tspinner.StopFailMessage(msg)\n\t\t\tspinErr := spinner.StopFail()\n\t\t\tif spinErr != nil {\n\t\t\t\tlog.Fatal(spinErr)\n\t\t\t}\n\t\t\treturn\n\t\tcase t := \u003c-ticker.C:\n\t\t\tspinner.Message(msg + generateTimeout(end.Sub(t)))\n\t\t}\n\t}\n}\n\nfunc generateTimeout(d time.Duration) string {\n\tremaining := fmt.Sprintf(\"timeout countdown: %v\", d.Round(time.Second))\n\treturn fmt.Sprintf(\" (app is being deployed across Fastly's global network | %s)...\", remaining)\n}\n// reference time 'layout': Mon Jan 2 15:04:05 -0700 MST 2006\n//\n// Note:\n// - `Jan` : 'first'  position\n// - `2`   : 'second' position\n// - `15`  : 'third'  position\n// - `04`  : 'fourth' position\n// - `05`  : 'fifth'  position\n// - `2006`: 'sixth'  position\n// - `0700`: 'seventh' position\n//\n// yes, as far as the display of the 'layout' (Mon Jan 2 15:04:05 -0700 MST 2006)\n// is concerned, the 'seventh' layout 'position' value (-0700) is shown _before_ the 'sixth' (i.e. 2006)\n// \n// Documentation:\n// https://golang.org/pkg/time/#Time.Format\n//\n// Examples:\n// https://gobyexample.com/time-formatting-parsing\n// https://play.golang.org/p/T_4Kn9BkSDh\n\nnow := time.Now()\ntimestamp := now.Format(\"20060102_150405\")\nfmt.Printf(\"%s_%s\", \"integralist\", timestamp) // integralist_20091110_230000\n\n// integralist_20091110_230000\n//\n// - `2009`: current year\n// - `11`: current month\n// - `10`: current day\n// - `230000`: current time (11pm/23:00:00)\npackage main\n\nimport (\n\t\"fmt\"\n\t\"time\"\n)\n\nfunc main() {\n\tthen := time.Date(2009, 01, 17, 20, 34, 58, 651387237, time.UTC).Unix()\n\tnow := time.Now().Unix() // same as time.Unix(now, 0)\n\t\n\tfmt.Println(then) // 1232224498\n\tfmt.Println(now) // 1257894000\n\t\n\tthen2 := time.Unix(then, 0)\n\tnow2 := time.Unix(now, 0)\n  \tnow3 := time.Now()\n\t\n\tfmt.Println(then2) // 2009-01-17 20:34:58 +0000 UTC\n\tfmt.Println(now2) // 2009-11-10 23:00:00 +0000 UTC\n\tfmt.Println(now3) // 2009-11-10 23:00:00 +0000 UTC m=+0.000000001\n\t\n\tfmt.Println(then2.Before(now2)) // true\n\tfmt.Println(now2.After(then2)) // true\n\tfmt.Println(now2.Equal(then2)) // false\n\tfmt.Println(now2.Equal(now2)) // true\n\tfmt.Println(now2.Equal(now3)) // true (even though the object has additional m=+0.000000001\n  \n    // compare negative time.Duration (e.g. -1s) requires converting to int64\n    example := time.Duration(-1*time.Second)\n    fmt.Printf(\"%+v\\n\", int64(example))\n  \tif (int64(example) \u003c 0) {\n      // do something\n    }\n}\npackage main\n\nimport (\n\t\"fmt\"\n\t\"time\"\n)\n\nfunc main() {\n\tp := fmt.Println\n\n\tnow := time.Now() // in play.golang.org this is always 2009-11-10 23:00:00 +0000 UTC m=+0.000000001\n\tp(\"now:\", now)\n\n    // I purposely set first 'time' event to be 90 seconds (1.5 minutes) ago\n\tthen := time.Date(2009, 11, 10, 23, 01, 30, 00, time.UTC)\n\tp(\"then:\", then)\n\n\tdiff := then.Sub(now)\n\tp(\"diff:\", diff)\n\n\tp(\"diff hours:\", diff.Hours())\n\tp(\"diff mins:\", diff.Minutes()) // yes! the current time is over a minute ago from the original time\n\tp(\"diff secs:\", diff.Seconds())\n\tp(\"diff ns:\", diff.Nanoseconds())\n}\n\n// Another way using unix timestamps instead of a date time...\n\npackage main\n\nimport (\n\t\"fmt\"\n\t\"time\"\n)\n\nfunc main() {\n\tcreated := time.Date(2023, 9, 5, 11, 46, 0, 0, time.Local).Unix()\n\n\t// Run program when time is 11:51 (so 5 minutes after 11:46) == token expired\n\tttl := time.Duration(300) * time.Second // 5 minutes\n\tdiff := time.Now().Add(-ttl).Unix()\n\n\tif created \u003c diff {\n\t\tfmt.Println(\"The token has expired\")\n\t} else {\n\t\tfmt.Println(\"The token has not expired\")\n\t}\n}\n\n","tags":"#go #golang #time #formatting #layout #comparison #conversion #stale"},{"id":"2e4a78fe92ec70d2e2709ff7be660669","title":"[fastly default vcl, no custom vcl] ","content":"pragma optional_param geoip_opt_in true;\npragma optional_param default_ssl_check_cert 1;\npragma optional_param max_backends 5;\npragma optional_param customer_id \"...\";\nC!\nW!\n# Backends\nsub vcl_recv {\n#--FASTLY RECV BEGIN\n  if (req.restarts == 0) {\n    if (!req.http.X-Timer) {\n      set req.http.X-Timer = \"S\" time.start.sec \".\" time.start.usec_frac;\n    }\n    set req.http.X-Timer = req.http.X-Timer \",VS0\";\n  }\n  # default conditions\n    # end default conditions\n#--FASTLY RECV END\n    if (req.request != \"HEAD\" \u0026\u0026 req.request != \"GET\" \u0026\u0026 req.request != \"FASTLYPURGE\") {\n      return(pass);\n    }\n    return(lookup);\n}\nsub vcl_fetch {\n#--FASTLY FETCH BEGIN\n# record which cache ran vcl_fetch for this object and when\n  set beresp.http.Fastly-Debug-Path = \"(F \" server.identity \" \" now.sec \") \" if(beresp.http.Fastly-Debug-Path, beresp.http.Fastly-Debug-Path, \"\");\n# generic mechanism to vary on something\n  if (req.http.Fastly-Vary-String) {\n    if (beresp.http.Vary) {\n      set beresp.http.Vary = \"Fastly-Vary-String, \"  beresp.http.Vary;\n    } else {\n      set beresp.http.Vary = \"Fastly-Vary-String, \";\n    }\n  }\n#--FASTLY FETCH END\n  if ((beresp.status == 500 || beresp.status == 503) \u0026\u0026 req.restarts \u003c 1 \u0026\u0026 (req.request == \"GET\" || req.request == \"HEAD\")) {\n    restart;\n  }\n  if(req.restarts \u003e 0 ) {\n    set beresp.http.Fastly-Restarts = req.restarts;\n  }\n  if (beresp.http.Set-Cookie) {\n    set req.http.Fastly-Cachetype = \"SETCOOKIE\";\n    return (pass);\n  }\n  if (beresp.http.Cache-Control ~ \"private\") {\n    set req.http.Fastly-Cachetype = \"PRIVATE\";\n    return (pass);\n  }\n  if (beresp.status == 500 || beresp.status == 503) {\n    set req.http.Fastly-Cachetype = \"ERROR\";\n    set beresp.ttl = 1s;\n    set beresp.grace = 5s;\n    return (deliver);\n  }\n  if (beresp.http.Expires || beresp.http.Surrogate-Control ~ \"max-age\" || beresp.http.Cache-Control ~\"(s-maxage|max-age)\") {\n    # keep the ttl here\n  } else {\n        # apply the default ttl\n    set beresp.ttl = 3600s;\n  }\n  return(deliver);\n}\nsub vcl_hit {\n#--FASTLY HIT BEGIN\n# we cannot reach obj.ttl and obj.grace in deliver, save them when we can in vcl_hit\n  set req.http.Fastly-Tmp-Obj-TTL = obj.ttl;\n  set req.http.Fastly-Tmp-Obj-Grace = obj.grace;\n  {\n    set req.http.Fastly-Cachetype = \"HIT\";\n  }\n#--FASTLY HIT END\n  if (!obj.cacheable) {\n    return(pass);\n  }\n  return(deliver);\n}\nsub vcl_miss {\n#--FASTLY MISS BEGIN\n# this is not a hit after all, clean up these set in vcl_hit\n  unset req.http.Fastly-Tmp-Obj-TTL;\n  unset req.http.Fastly-Tmp-Obj-Grace;\n  {\n    if (req.http.Fastly-Check-SHA1) {\n       error 550 \"Doesnt exist\";\n    }\n#--FASTLY BEREQ BEGIN\n    {\n      {\n        if (req.http.Fastly-FF) {\n          set bereq.http.Fastly-Client = \"1\";\n        }\n      }\n      {\n        # do not send this to the backend\n        unset bereq.http.Fastly-Original-Cookie;\n        unset bereq.http.Fastly-Original-URL;\n        unset bereq.http.Fastly-Vary-String;\n        unset bereq.http.X-Varnish-Client;\n      }\n      if (req.http.Fastly-Temp-XFF) {\n         if (req.http.Fastly-Temp-XFF == \"\") {\n           unset bereq.http.X-Forwarded-For;\n         } else {\n           set bereq.http.X-Forwarded-For = req.http.Fastly-Temp-XFF;\n         }\n         # unset bereq.http.Fastly-Temp-XFF;\n      }\n    }\n#--FASTLY BEREQ END\n #;\n    set req.http.Fastly-Cachetype = \"MISS\";\n  }\n#--FASTLY MISS END\n  return(fetch);\n}\nsub vcl_deliver {\n#--FASTLY DELIVER BEGIN\n# record the journey of the object, expose it only if req.http.Fastly-Debug.\n  if (req.http.Fastly-Debug || req.http.Fastly-FF) {\n    set resp.http.Fastly-Debug-Path = \"(D \" server.identity \" \" now.sec \") \"\n       if(resp.http.Fastly-Debug-Path, resp.http.Fastly-Debug-Path, \"\");\n    set resp.http.Fastly-Debug-TTL = if(obj.hits \u003e 0, \"(H \", \"(M \")\n       server.identity\n       if(req.http.Fastly-Tmp-Obj-TTL \u0026\u0026 req.http.Fastly-Tmp-Obj-Grace, \" \" req.http.Fastly-Tmp-Obj-TTL \" \" req.http.Fastly-Tmp-Obj-Grace \" \", \" - - \")\n       if(resp.http.Age, resp.http.Age, \"-\")\n       \") \"\n       if(resp.http.Fastly-Debug-TTL, resp.http.Fastly-Debug-TTL, \"\");\n    set resp.http.Fastly-Debug-Digest = digest.hash_sha256(req.digest);\n  } else {\n    unset resp.http.Fastly-Debug-Path;\n    unset resp.http.Fastly-Debug-TTL;\n    unset resp.http.Fastly-Debug-Digest;\n  }\n  # add or append X-Served-By/X-Cache(-Hits)\n  {\n    if(!resp.http.X-Served-By) {\n      set resp.http.X-Served-By  = server.identity;\n    } else {\n      set resp.http.X-Served-By = resp.http.X-Served-By \", \" server.identity;\n    }\n    set resp.http.X-Cache = if(resp.http.X-Cache, resp.http.X-Cache \", \",\"\") if(fastly_info.state ~ \"HIT($|-)\", \"HIT\", \"MISS\");\n    if(!resp.http.X-Cache-Hits) {\n      set resp.http.X-Cache-Hits = obj.hits;\n    } else {\n      set resp.http.X-Cache-Hits = resp.http.X-Cache-Hits \", \" obj.hits;\n    }\n  }\n  if (req.http.X-Timer) {\n    set resp.http.X-Timer = req.http.X-Timer \",VE\" time.elapsed.msec;\n  }\n  # VARY FIXUP\n  {\n    # remove before sending to client\n    set resp.http.Vary = regsub(resp.http.Vary, \"Fastly-Vary-String, \", \"\");\n    if (resp.http.Vary ~ \"^\\s*$\") {\n      unset resp.http.Vary;\n    }\n  }\n  unset resp.http.X-Varnish;\n  # Pop the surrogate headers into the request object so we can reference them later\n  set req.http.Surrogate-Key = resp.http.Surrogate-Key;\n  set req.http.Surrogate-Control = resp.http.Surrogate-Control;\n  # If we are not forwarding or debugging unset the surrogate headers so they are not present in the response\n  if (!req.http.Fastly-FF \u0026\u0026 !req.http.Fastly-Debug) {\n    unset resp.http.Surrogate-Key;\n    unset resp.http.Surrogate-Control;\n  }\n  if(resp.status == 550) {\n    return(deliver);\n  }\n  #default response conditions\n#--FASTLY DELIVER END\n  return(deliver);\n}\nsub vcl_error {\n#--FASTLY ERROR BEGIN\n  if (obj.status == 801) {\n     set obj.status = 301;\n     set obj.response = \"Moved Permanently\";\n     set obj.http.Location = \"https://\" req.http.host req.url;\n     synthetic {\"\"};\n     return (deliver);\n  }\n  if (req.http.Fastly-Restart-On-Error) {\n    if (obj.status == 503 \u0026\u0026 req.restarts == 0) {\n      restart;\n    }\n  }\n  {\n    if (obj.status == 550) {\n      return(deliver);\n    }\n  }\n#--FASTLY ERROR END\n}\nsub vcl_pipe {\n#--FASTLY PIPE BEGIN\n  {\n#--FASTLY BEREQ BEGIN\n    {\n      {\n        if (req.http.Fastly-FF) {\n          set bereq.http.Fastly-Client = \"1\";\n        }\n      }\n      {\n        # do not send this to the backend\n        unset bereq.http.Fastly-Original-Cookie;\n        unset bereq.http.Fastly-Original-URL;\n        unset bereq.http.Fastly-Vary-String;\n        unset bereq.http.X-Varnish-Client;\n      }\n      if (req.http.Fastly-Temp-XFF) {\n         if (req.http.Fastly-Temp-XFF == \"\") {\n           unset bereq.http.X-Forwarded-For;\n         } else {\n           set bereq.http.X-Forwarded-For = req.http.Fastly-Temp-XFF;\n         }\n         # unset bereq.http.Fastly-Temp-XFF;\n      }\n    }\n#--FASTLY BEREQ END\n    #;\n    set req.http.Fastly-Cachetype = \"PIPE\";\n    set bereq.http.connection = \"close\";\n  }\n#--FASTLY PIPE END\n}\nsub vcl_pass {\n#--FASTLY PASS BEGIN\n  {\n#--FASTLY BEREQ BEGIN\n    {\n      {\n        if (req.http.Fastly-FF) {\n          set bereq.http.Fastly-Client = \"1\";\n        }\n      }\n      {\n        # do not send this to the backend\n        unset bereq.http.Fastly-Original-Cookie;\n        unset bereq.http.Fastly-Original-URL;\n        unset bereq.http.Fastly-Vary-String;\n        unset bereq.http.X-Varnish-Client;\n      }\n      if (req.http.Fastly-Temp-XFF) {\n         if (req.http.Fastly-Temp-XFF == \"\") {\n           unset bereq.http.X-Forwarded-For;\n         } else {\n           set bereq.http.X-Forwarded-For = req.http.Fastly-Temp-XFF;\n         }\n         # unset bereq.http.Fastly-Temp-XFF;\n      }\n    }\n#--FASTLY BEREQ END\n #;\n    set req.http.Fastly-Cachetype = \"PASS\";\n  }\n#--FASTLY PASS END\n}\nsub vcl_log {\n#--FASTLY LOG BEGIN\n  # default response conditions\n#--FASTLY LOG END\n}\nsub vcl_hash {\n#--FASTLY HASH BEGIN\n  #if unspecified fall back to normal\n  {\n    set req.hash += req.url;\n    set req.hash += req.http.host;\n    set req.hash += \"#####GENERATION#####\";\n    return (hash);\n  }\n#--FASTLY HASH END\n}\n","tags":"#fastly #varnish #vcl"},{"id":"b2e87acad7fdf354ade3250dcb31c168","title":"[Go embedding interface types] ","content":"Embedding an interface into a struct means that field will need to be assigned a value that fulfils the interface.\n\nThis forces the struct to implement the given methods because when you assign a type to that field it needs to have those methods available.\n\nThis is especially useful when you want to re-implement only a single method of the interface for testing purposes as noted here...\n\nhttps://dmv.myhatchpad.com/insight/mocking-techniques-for-go/\n\n\u003e Use when you need to mock out a small set of methods defined in a large interface.\n\u003e\n\u003e A great example of this situation comes from the DynamoDB documentation.\n\u003e\n\u003e When working with the aws-sdk, they provide interfaces for all of their major services that are quite large since they contain all of the calls that can be made for each particular client. Take a look at the dynamodbiface.DynamoDBAPI interface from the link. Rather than pass around the concrete client type, you should pass around this interface to other functions. But then, when testing some of your code that calls one particular function of the interface, how do you mock out that call only without mocking every other function in an attempt to satisfy the interface?\n\n**WARNING**: assigning `nil` breaks this compile time safety!\n\nThis is best demonstrated by way of an example (https://play.golang.org/p/i8q0gv4WgkQ)\n\n```go\npackage main\n\nimport (\n\t\"fmt\"\n\t\"io\"\n)\n\n// Foo needs to implement io.Reader\ntype Foo struct {\n\tio.Reader\n\tBar int\n}\n\n// Bar doesn't implement io.Reader\ntype Bar struct{}\n\n// Baz DOES implement io.Reader\ntype Baz struct{}\n\nfunc (b Baz) Read(p []byte) (n int, err error) {\n\tfmt.Println(\"Bar.Read was called\")\n\treturn 0, nil\n}\n\nfunc main() {\n\t// we can assign Foo{Reader: Baz{}} to r\n\t// as it fulfils the io.Reader interface\n\t//\n\tvar r io.Reader\n\tr = Foo{Reader: Baz{}}\n\tfmt.Printf(\"%+v\\n\", r) // {Reader:{} Bar:0}\n\n\t// WARNING: this compiles but then fails at runtime ❌\n\t// i.e. a nil value breaks compile time safety!\n\t//\n\tr = Foo{}\n\tfmt.Printf(\"%+v\\n\", r) // {Reader:\u003cnil\u003e Bar:0}\n\n\tb := []byte{}\n\tr.Read(b)\n\t//\n\t// panic: runtime error: invalid memory address or nil pointer dereference\n\n    // What's much better (of course) is getting a COMPILE TIME error!\n\t//\n    // if we tried to assign `Foo{Reader: Bar{}}` to r variable then we'd get compiler error.\n\t// because we cannot use Bar literal (type Bar) as type io.Reader in field value\n\t// as Bar does not implement io.Reader (it's missing the Read method)\n\t//\n\tfmt.Printf(\"%+v\\n\", Foo{Reader: Bar{}})\n\n}\n```\n\nWhen not embedding an interface we can use an underscore as a 'compile time check' trick...\n\n```go\npackage main\n\nimport (\n\t\"net/http\"\n)\n\ntype RW struct {}\n\n/*\nfunc (rw RW) Header() http.Header {\n\treturn make(http.Header)\n}\n*/\n\nfunc (rw RW) Write([]byte) (int, error) {\n\treturn 0, nil\n}\n\nfunc (rw RW) WriteHeader(statusCode int) {}\n\n// ./prog.go:21:5: cannot use RW literal (type RW) as type http.ResponseWriter in assignment:\n//  \tRW does not implement http.ResponseWriter (missing Header method)\nvar _ http.ResponseWriter = RW{}\n\nfunc main() {\n\t// ...\n}\n```\n\nBut as mentioned earlier be aware that the above example code would fail compilation because we didn't embed the interface! Once you embed the interface the compile time error doesn't occur!\n\nThis is because when embedding the interface you're providing a `nil` value for the `ResponseWriter` field and that's fine, as far as the compiler is concerned when it comes to saying have you provided something to satisfy this field's requirements. But of course `nil` has no methods!\n\nSo be careful because you can run into issues like the following code which compiles fine but then fails at runtime with a panic!\n\n```go\npackage main\n\nimport (\n\t\"fmt\"\n\t\"net/http\"\n)\n\nvar _ http.ResponseWriter = RW{}\n\ntype RW struct {\n\thttp.ResponseWriter\n}\n\n/*\nfunc (rw RW) Header() http.Header {\n\treturn make(http.Header)\n}\n*/\n\nfunc (rw RW) Write([]byte) (int, error) {\n\treturn 0, nil\n}\n\nfunc (rw RW) WriteHeader(statusCode int) {\n\tfmt.Println(statusCode)\n}\n\nfunc main() {\n\tvar rw http.ResponseWriter\n\trw = RW{}\n\tfmt.Printf(\"%+v\\n\", rw) // {ResponseWriter:\u003cnil\u003e}\n\n\twritten, err := rw.Write([]byte(\"ABC\"))\n\tfmt.Printf(\"%+v %+v\\n\", written, err)\n\n\trw.WriteHeader(123)\n\n\tfmt.Printf(\"%+v\\n\", rw.Header())\n}\n```\n// Package middleware provides wrapper functions around the http.Handler\n// interface, allowing for an incoming HTTP request to be modified or analysed.\npackage middleware\n\nimport (\n\t\"fmt\"\n\t\"net/http\"\n\t\"time\"\n)\n\n// This is a compile-time check to ensure that `Handler` meets\n// the interface definition for `http.ResponseWriter`.\n//\n// We throw away the result because anything other than an error means the check\n// passes, and an error will prevent compiling.\n//\n// Not defining the underlying `ResponseWriter` field in the Handler struct\n// will effectively be the same as passing `http.ResponseWriter(nil)`. Which is\n// enough to associate the relevant methods with the Handler struct so it may\n// satisfy the http.ResponseWriter interface.\nvar (\n\t_ http.ResponseWriter = \u0026Handler{}\n)\n\n// Handler provides an interface composed of an `http.ResponseWriter`\n// to satisfy the http handler interface to allow us to expose a request\n// to our logger.\ntype Handler struct {\n\thttp.ResponseWriter\n\tstatus int\n\tlength int\n}\n\n// WriteHeader writes status field as the response status via the underlying\n// ResponseWriter instance created at the time of the request construction.\nfunc (h *Handler) WriteHeader(status int) {\n\th.status = status\n\th.ResponseWriter.WriteHeader(status)\n}\n\n// Write writes `statusOK` for any handler passed in that has the status\n// (represented by an int) of 0. Any other status code will be left as is,\n// and then the status will be handed off to the ResponseWriter.\nfunc (h *Handler) Write(b []byte) (int, error) {\n\tif h.status == 0 {\n\t\th.status = http.StatusOK\n\t}\n\n\tn, err := h.ResponseWriter.Write(b)\n\th.length += n\n\n\treturn n, err\n}\n\n// Foo is using the traditional golang middleware pattern for handling web server requests.\nfunc Foo(handler http.Handler) http.HandlerFunc {\n\t\n\treturn func(w http.ResponseWriter, r *http.Request) {\n\t\th := \u0026Handler{ResponseWriter: w}\n\t\thandler.ServeHTTP(h, r)\n\t\tfmt.Println(h.status) // should now have a value as it's passed through the various middleware\n\t}\n}\ntype baz interface {\n\t...\n}\n\ntype X struct {\n\tfoo int\n\tbar baz\n}\n\nconvertThingThatImplementsBazIntoInterfaceType := interface{}(ThingThatImplementsBaz{})\nrealTypeReturned := convertThingThatImplementsBazIntoInterfaceType.(baz)\n\nx.bar = realTypeReturned\n","tags":"#go #golang #interface #struct #field #type #assertion #embed #override #template #pattern"},{"id":"b123e4a98bcf232d09216577c29f34a3","title":"[golang avoid promoted field in literal struct error] ","content":"package main\n\nimport (\n\t\"fmt\"\n)\n\ntype A struct {\n\tenabled bool\n}\n\nfunc (a *A) isEnabled() bool {\n\tfmt.Println(\"A isEnabled\")\n\treturn a.enabled\n}\n\ntype B struct {\n\tA\n}\n\nfunc (b *B) isEnabled() bool {\n\tfmt.Println(\"B isEnabled\")\n\treturn b.A.isEnabled()\n}\n\nfunc main() {\n\t/*\n\t\ta := \u0026A{enabled: true}\n\t\tb := \u0026B{enabled: false}\n\n\t\tfmt.Printf(\"a: %#v\\n\", a.isEnabled())\n\t\tfmt.Printf(\"b: %#v\\n\", b.isEnabled())\n\n\t\t// cannot use promoted field A.enabled in struct literal of type B\n\t*/\n\n\tvar a A\n\ta.enabled = true\n\n\tvar b B\n\tb.enabled = false\n\n\tfmt.Printf(\"a: %#v\\n\", a.isEnabled())\n\tfmt.Printf(\"b: %#v\\n\", b.isEnabled())\n  \n  \t/*\n\t\tA isEnabled\n\t\ta: true\n\t\tB isEnabled\n\t\tA isEnabled\n\t\tb: false\n\t*/\n}\n\n","tags":"#go #golang #struct #promoted #field #error"},{"id":"d84389ff35687f7c9d89d5246338fa38","title":"[Go Access Underlying Slice Array] ","content":"package main\n\nimport (\n\t\"fmt\"\n\t\"reflect\"\n\t\"unsafe\"\n)\n\nfunc main() {\n\t// define a slice\n\ts := []int{1, 2, 3, 4}\n\n\t// access the underlying array of the slice\n\thdr := (*reflect.SliceHeader)(unsafe.Pointer(\u0026s))\n\tdata := *(*[4]int)(unsafe.Pointer(hdr.Data))\n\n\t// display the slice internals\n\tfmt.Printf(\"s: %#v\\n\", s)\n\tfmt.Printf(\"hdr: %#v\\n\", hdr)\n\tfmt.Printf(\"data %#v\\n\", data)\n\n\t// create a new zero-value slice based on same proportions as the original slice\n\tnewSlice := make([]int, len(s), cap(s))\n\tfmt.Printf(\"\\nnewSlice: %#v\\n\", newSlice)\n\n\t// copy the original slice into the new slice\n\tcopy(newSlice, s)\n\tfmt.Printf(\"newSlice: %#v\\n\", newSlice)\n\n\t// access the underlying array of the new slice\n\thdrNew := (*reflect.SliceHeader)(unsafe.Pointer(\u0026newSlice))\n\tdataNew := *(*[4]int)(unsafe.Pointer(hdr.Data))\n\n\t// display the new slice internals (notice there's a different underlying array!)\n\tfmt.Printf(\"\\nnewSlice: %#v\\n\", newSlice)\n\tfmt.Printf(\"hdrNew: %#v\\n\", hdrNew)\n\tfmt.Printf(\"dataNew %#v\\n\", dataNew)\n\n\t// now modify the new slice contents (which should change the underlying array)\n\tnewSlice[0] = 123\n\tfmt.Printf(\"\\nnewSlice modified: %#v\\n\", newSlice)\n\n\t// reacquire the underlying array of the original slice (just so we can be sure we've not modified things)\n\thdrOriginal := (*reflect.SliceHeader)(unsafe.Pointer(\u0026s))\n\tdataOriginal := *(*[4]int)(unsafe.Pointer(hdr.Data))\n\n\t// display the original slice internals (again, for the sake of comparison -- notice the memory address is the same still)\n\tfmt.Printf(\"\\noriginal s: %#v\\n\", s)\n\tfmt.Printf(\"hdrOriginal: %#v\\n\", hdrOriginal)\n\tfmt.Printf(\"dataOriginal %#v\\n\", dataOriginal)\n}\n\n/*\ns: []int{1, 2, 3, 4}\nhdr: \u0026reflect.SliceHeader{Data:0x414020, Len:4, Cap:4}\ndata [4]int{1, 2, 3, 4}\n\nnewSlice: []int{0, 0, 0, 0}\nnewSlice: []int{1, 2, 3, 4}\n\nnewSlice: []int{1, 2, 3, 4}\nhdrNew: \u0026reflect.SliceHeader{Data:0x414090, Len:4, Cap:4}\ndataNew [4]int{1, 2, 3, 4}\n\nnewSlice modified: []int{123, 2, 3, 4}\n\noriginal s: []int{1, 2, 3, 4}\nhdrOriginal: \u0026reflect.SliceHeader{Data:0x414020, Len:4, Cap:4}\ndataOriginal [4]int{1, 2, 3, 4}\n*/\n","tags":"#go #golang #slice #array #unsafe #reflect #header"},{"id":"78677b6179f0ce46fd3fe62b1694f349","title":"[Vim highlighting words] ","content":"Vim can highlight certain words inside of code comments, such as...\n\n- `BUG` (Golang)\n- `FIXME`\n- `NOTE`\n- `NOTES` (Python)\n- `TODO`\n- `XXX`\n\n\u003e The `NOTE` works in both Go and Python files and yet it's not defined in the Go syntax file, which means it's likely inherited from a default syntax file.\n\nSee the syntax files for...\n\n- [Python](https://github.com/vim/vim/blob/a87b72cc316e065d66dcbcf7ec1cde330adef3a3/runtime/syntax/python.vim#L134)\n- [Go](https://github.com/vim/vim/blob/a87b72cc316e065d66dcbcf7ec1cde330adef3a3/runtime/syntax/go.vim#L95)\n\nYou can add your own, see [this StackOverflow post](https://vi.stackexchange.com/a/15531) for the full details, but in summary it looks something like:\n\n```vim\naugroup myTodo\n  autocmd!\n  autocmd Syntax * syntax match myTodo /\\v\\_.\u003c(TODO|FIXME).*/hs=s+1 containedin=.*Comment\naugroup END\n\nhighlight link myTodo Todo\n```\n","tags":"#vim #highlight #code #comments"},{"id":"a2e407afe89be6039001535c09f782fc","title":"Type check object is an instance of a specific struct ","content":"package main\n\nimport \"fmt\"\n\ntype Test struct {\n\tfoo int\n}\n\ntype Foo struct {\n}\n\n// we need a function to wrap the switch statement as it only works with interface types, \n// and so we trick the switch statement into thinking it got an interface type by\n// having the function accept anything via the empty interface{} type.\n//\n// NOTE: it's important to realize that if you have a pointer to a struct, \n// then you'll need to define a pointer version case statement to catch it.\nfunc isType(t interface{}) bool {\n\tswitch t.(type) {\n\tcase Test:\n\t\treturn true\n\tcase Foo:\n\t\treturn true\n\tcase *Foo:\n\t\treturn true\n\tdefault:\n\t\treturn false\n\t}\n}\n\nfunc main() {\n\tt := Test{5}\n\tfmt.Println(isType(t))\n\n  \t// non-pointer version\n\ts := Foo{}\n\tfmt.Println(isType(s))\n\n  \t// pointer version\n\ts2 := \u0026Foo{}\n\tfmt.Println(isType(s2))\n}\npackage main\n\nimport \"fmt\"\n\ntype Test struct {\n\tfoo int\n}\n\ntype TestA struct {\n\tTest\n}\n\ntype TestB struct {\n\tTest\n}\n\nfunc isTest(t interface{}) string {\n\tswitch t.(type) {\n\tcase TestA:\n\t\treturn \"A\"\n\tcase TestB:\n\t\treturn \"B\"\n\tdefault:\n\t\treturn \"NA\"\n\t}\n}\n\nfunc main() {\n\tta := TestA{}\n\ttb := TestB{}\n\n\t// by not setting 'foo' property as part of TestA/TestB instantiation\n    // we avoid the \"cannot use promoted field\" compiler error\n    // see: https://gist.github.com/Integralist/b123e4a98bcf232d09216577c29f34a3\n\tta.foo = 1\n\ttb.foo = 2\n  \n    /*\n     a better approach to avoid the \"cannot use promoted field\" compiler error\n     would be to do this...\n     \n     t := Test{foo: 123}\n     ta := TestA{t}\n     tb := TestB{t}\n    */\n\n\tfmt.Printf(\"%+v\\n\", ta)\n\tfmt.Printf(\"%+v\\n\", tb)\n\n\tfmt.Println(isTest(ta)) // A\n\tfmt.Println(isTest(tb)) // B\n}\n","tags":"#go"},{"id":"e538e3831c6a0f228eee8545b6f5dc95","title":"[How to write an introduction well Inbox] ","content":"A _hook_ is any half-told story:\n\n- **Questions**: Pose an intriguing question, but don’t give the answer.\n- **Narratives**: Share the beginning of a narrative, but withhold the conclusion.\n- **Discoveries**: Highlight new findings, but only a portion.\n- **Arguments**: Present your case, but not how you arrived at it.\n","tags":"#documentation #docs #guides #tutorials #reference #explanation #writing"},{"id":"dc05d8b18c8d793ad347f92623075535","title":"[ffmpeg examples] ","content":"# https://superuser.com/questions/681885/how-can-i-remove-multiple-segments-from-a-video-using-ffmpeg\n#\n# the following command will generate three new videos (a.tvshow, c.tvshow, e.tvshow) from the single abcdef.tvshow\n#\n# we can then use the `concat` filter (shown earlier) to rejoin them together.\nffmpeg -i abcdef.tvshow -t 5 a.tvshow -ss 10 -t 5 c.tvshow -ss 20 -t 5 e.tvshow\nffmpeg -i example.mov -vf \"scale=2200:-1\" resized.mov\n# see the individual 'extract' and 'concat' examples below to understand this 'one liner' version.\n\nffmpeg -i 1989.02.20\\ -\\ Chi-Town\\ Rumble\\ 1989.mp4 -to 00:00:30 1.mp4 -ss 00:02:53 -to 00:05:07 2.mp4 -ss 00:26:53 -to 00:47:55 3.mp4 -ss 01:10:04 -to 01:11:46 4.mp4 -ss 01:29:09 -to 01:42:13 5.mp4 -ss 01:43:53 6.mp4 \u0026\u0026 printf \"file '1.mp4'\\nfile '2.mp4'\\nfile '3.mp4'\\nfile '4.mp4'\\nfile '5.mp4'\\nfile '6.mp4'\" \u003e concat.txt \u0026\u0026 ffmpeg -f concat -safe 0 -i concat.txt -c copy 1989.02.20\\ -\\ Chi-Town\\ Rumble\\ 1989--new.mp4 \u0026\u0026 rm {1,2,3,4,5,6}.mp4 \u0026\u0026 rm concat.txt \u0026\u0026 say all done\n# https://unix.stackexchange.com/questions/1670/how-can-i-use-ffmpeg-to-split-mpeg-video-into-10-minute-chunks\n#\nffmpeg -i input.mp4 -c copy -map 0 -segment_time 00:20:00 -f segment -reset_timestamps 1 output%03d.mp4\n\n# https://ffmpeg.org/ffmpeg-formats.html#concat-1\n\ncat mylist.txt\nfile '/path/to/file1'\nfile '/path/to/file2'\nfile '/path/to/file3'\n\nffmpeg -f concat -safe 0 -i mylist.txt -c copy output.mp4\nffmpeg -i input.mp4 -ss 00:00:10 -to 00:00:20 -vf \"fps=15,scale=480:-1:flags=lanczos\" output.gif\nffmpeg -i 2019-hack-week-vol1.mp4 -ss 00:05:36 -t 00:11:18 -async 1 cut.mp4\n\n# note: -t represents the duration you want the new video crop to last for\n#\n#       we can also use -to to specify a specific finish time (which is much more practical to use)\n#       $ ffmpeg -i foo.mp4 -ss 00:26:42 -to 00:32:11 -async 1 cut.mp4\n","tags":"#ffmpeg #crop #video #concat #split #resize"},{"id":"632892f6ee2556e5a2f44789f93ddbd8","title":"[Go Array Element Removal] ","content":"package main\n\nimport (\n\t\"fmt\"\n)\n\n// Task represents an on-call TODO item.\ntype Task struct {\n\tDesc    string\n\tDone    bool\n\tSkipped bool\n}\n\n// Tasks is a collection of tasks for a specific incident\ntype Tasks []Task\n\n// Incident is a unique incident consisting of list of checklist tasks.\ntype Incident struct {\n\tName      string\n\tChecklist Tasks\n}\n\n// Incidents is a list of individual incidents that are being monitored.\ntype Incidents []Incident\n\n// removeIncident resplices the given list of incidents so the index is\n// removed by taking individual slices of the data and combining them without\n// the specified element index.\nfunc removeIncident(i int, incidents Incidents) Incidents {\n\tincidentName := incidents[i].Name\n\tincidents = append(incidents[:i], incidents[i+1:]...)\n\tfmt.Printf(\"incident '%s' removed successfully\\n\", incidentName)\n\treturn incidents\n}\n\n// ALTERNATIVE VERSION...\n//\n// removeIncident resplices the given list of incidents so the index is\n// removed. This uses the most performant approach possible, which causes the\n// ordering of the slice to change.\n//func removeIncident(i int, incidents Incidents) Incidents {\n//\tincidents[i] = incidents[len(incidents)-1] // Copy last element to index i.\n//\tincidents[len(incidents)-1] = Incident{}   // Erase last element (write zero value).\n//\tincidents = incidents[:len(incidents)-1]   // Truncate slice.\n//\treturn incidents\n//}\n\nfunc main() {\n\ticd := []Incident{\n\t\t{Name: \"foo\", Checklist: []Task{{Desc: \"foo happened\"}}},\n\t\t{Name: \"bar\", Checklist: []Task{{Desc: \"bar happened\"}}},\n\t\t{Name: \"baz\", Checklist: []Task{{Desc: \"baz happened\"}}},\n\t}\n\n\t// remove \"bar\"\n\ticd = removeIncident(1, icd)\n\tfmt.Printf(\"%v (%d)\\n\", icd, len(icd))\n\n\t// remove \"baz\"\n\ticd = removeIncident(1, icd)\n\tfmt.Printf(\"%v (%d)\\n\", icd, len(icd))\n\n\t// remove \"foo\"\n\ticd = removeIncident(0, icd)\n\tfmt.Printf(\"%v (%d)\\n\", icd, len(icd))\n}\n","tags":"#go #golang #array #slice #splice #remove #element #item"},{"id":"de9773dc041b2dc3997096817a827d71","title":"[Golang Struct and Interface Embedding Examples] ","content":"package main\n\nimport (\n\t\"fmt\"\n)\n\ntype foo struct {\n\tbar string\n}\n\nfunc (f *foo) baz() {\n\tfmt.Println(\"baz called and bar =\", f.bar)\n}\n\ntype x interface {\n\tbaz()\n}\n\n/*\n// struct embedding example\ntype bar struct {\n\t*foo\n}\n*/\n\n// interface embedding example\ntype bar struct {\n\tx\n}\n\nfunc newBar() *bar {\n\treturn \u0026bar{\u0026foo{\"abc\"}}\n  \t\n  \t// you can also be explicit and specify the 'field', which is x\n  \t//\n  \t// e.g.\n  \t// return \u0026bar{x: \u0026foo{\"abc\"}}\n  \t//\n  \t// typically the field is the last segment of the struct/interface\n  \t//\n  \t// e.g.\n  \t// *redis.Client (struct: the field would be Client)\n\t// io.Writer (interface: the field would be Writer)\n  \t//\n  \t// with either a struct embedded or an interface embedded \n  \t// you can call the embedded functions directly AND indirectly\n  \t//\n    // e.g. example where we embedded *redis.Client we can call its TTL() function like so...\n\t// b.TTL()\n  \t// b.Client.TTL()\n  \t//\n    // e.g. example where we embedded x interface we can call its baz() function like so...\n\t// b.baz()\n  \t// b.x.baz()\n}\n\nfunc doSomething(a x) {\n\tfmt.Println(\"doSomething called\")\n\ta.baz()\n}\n\nfunc main() {\n\tb := newBar()\n\tb.baz()\n\t// b.foo.baz() // only works when a struct is embedded inside a struct, not when an interface is embedded\n  \t// b.x.baz() // works when interface is embedded inside a struct as 'x' is the name of the interface\n\tfmt.Printf(\"%+v\\n\", b)\n\tdoSomething(b)\n}\npackage main\n\nimport (\n\t\"compress/gzip\"\n\t\"fmt\"\n\t\"os\"\n)\n\ntype gzipWriterWrapper struct {\n\t*gzip.Writer // what identifier is this exposed as? see below!\n\tfoo string\n}\n\ntype writerThing struct {\n\tio.Writer\n\tfoo string\n}\n\nfunc main() {\n\tg := gzipWriterWrapper{gzip.NewWriter(os.Stdout), \"bar\"}\n\tfmt.Printf(\"%+v\\n\", g) // {Writer:0x448460 foo:bar}\n  \n  \twt := writerThing{foo: \"bar\"}\n\tfmt.Printf(\"%+v\\n\", g) // {Writer:nil foo:bar}\n  \t\t\t\t\t\t   // notice you still need to provide an _implementation_ of io.Writer\n}\n\n/*\ngzip.Writer methods can be accessed either directly or indirectly...\n\n- indirectly: g.Write(...)\n- directly:   g.Writer.Write(...)\n*/\npackage main\n\nimport (\n\t\"fmt\"\n)\n\ntype foo struct {\n\tbar string\n}\n\nfunc (f *foo) baz() {\n\tfmt.Println(\"baz called and bar =\", f.bar)\n}\n\ntype mock struct {\n\t*bar\n}\n\nfunc (m *mock) mocker() {\n\tfmt.Println(\"mocker called\")\n}\n\n// struct embedding example\ntype bar struct {\n\t*foo\n}\n\ntype basicRequirements interface {\n\tbaz()\n}\n\nfunc newBar(mocked bool) basicRequirements {\n\tif mocked {\n\t\tfmt.Println(\"create instance of bar that has mock method\")\n\t\treturn \u0026mock{\u0026bar{\u0026foo{\"abc\"}}}\n\t}\n\n\tfmt.Println(\"create instance of bar that does NOT have mock method\")\n\treturn \u0026bar{\u0026foo{\"abc\"}}\n}\n\nfunc main() {\n\tb := newBar(true)\n\tb.baz()\n\n\t// careful if calling newBar(false) as this assertion will break\n\tbasserted := b.(*mock)\n\tbasserted.mocker()\n\n\tfmt.Printf(\"%+v\\n\", b)\n}\n## 1. simplified 'reduced' examples\n\nThis shows struct and interface embedding with basic custom objects to hopefully more easily explain how things work.\n\nSee https://gist.github.com/Integralist/b2e87acad7fdf354ade3250dcb31c168#file-1-md for an explanation.\n\n## 2. real example with gzip.NewWriter\n\nThis shows struct and interface embedding with real golang stdlib object.\n\n## 3. we want to return two different objects (with different methods)\n\nThis is so in a 'dev' environment we can return an object that calls a 'mock' method, while in production the returned object will be different and so it won't call that method.\n","tags":"#go #golang #struct #embedding #embed"},{"id":"348c70ab1d1dafc9f455d715d93ba3dd","title":"[AWS Active-Active Patterns Presentation (link to PDF)] ","content":"https://d1.awsstatic.com/events/reinvent/2019/REPEAT_2_Architecture_patterns_for_multi-region_active-active_ARC213-R2.pdf\n","tags":"#aws #pdf #presentation #resilience #multiregion #activeactive #pattern #ha #availability"},{"id":"06bddcd3a5506e46e98c2dfa9a3f5167","title":"[Types of Documentation] ","content":"1. [Tutorials](#tutorials)\n2. [How-to guides](#how-to-guides)\n3. [Explanation](#explanation)\n4. [Reference](#reference)\n\n## Tutorials\n\nA tutorial:\n\n- is learning-oriented\n- allows the newcomer to get started\n- is a lesson\n\n\u003e Analogy: teaching a small child how to cook\n\n## How-to guides\n\nA how-to guide:\n\n- is goal-oriented\n- shows how to solve a specific problem\n- is a series of steps\n\n\u003e Analogy: a recipe in a cookery book\n\n## Explanation\n\nAn explanation:\n\n- is understanding-oriented\n- explains\n- provides background and context\n\n\u003e Analogy: an article on culinary social history\n\n## Reference\n\nA reference guide:\n\n- is information-oriented\n- describes the machinery\n- is accurate and complete\n\n\u003e Analogy: a reference encyclopaedia article\n","tags":"#documentation #docs #guides #tutorials #reference #explanation"},{"id":"2a316428696daccd66e5df8df02abb3f","title":"[Golang Custom Error Abstraction] ","content":"- https://peter.bourgon.org/blog/2019/09/11/programming-with-errors.html\n// inside directory: our.custom to help distinguish from stdlib package of the same name\npackage errors\n\nimport (\n    \"fmt\"\n    \"runtime\"\n    \"strings\"\n)\n\nconst maxStackLength = 50\n\ntype Error struct {\n    Err        error\n    StackTrace string\n}\n\nfunc (m Error) Error() string {\n    return m.Err.Error() + m.StackTrace\n}\n\nfunc Wrap(err error) Error {\n    return Error{Err: err, StackTrace: getStackTrace()}\n}\n\nfunc getStackTrace() string {\n    stackBuf := make([]uintptr, maxStackLength)\n    length := runtime.Callers(3, stackBuf[:])\n    stack := stackBuf[:length]\n\n    trace := \"\"\n    frames := runtime.CallersFrames(stack)\n    for {\n        frame, more := frames.Next()\n        if !strings.Contains(frame.File, \"runtime/\") {\n            trace = trace + fmt.Sprintf(\"\\n\\tFile: %s, Line: %d. Function: %s\", frame.File, frame.Line, frame.Function)\n        }\n        if !more {\n            break\n        }\n    }\n    return trace\n}\npackage main\n\nimport (\n    \"fmt\"\n    \"strconv\"\n    \"our.custom/errors\" \n)\n\nfunc atoi() (int, error) {\n\ti, err := strconv.Atoi(\"f42\")\n\tif err != nil {\n\t\treturn 0, errors.Wrap(err) \n\t}\n\treturn i, nil\n\n}\n\nfunc main() {\n\t_, err := atoi()\n\tif err != nil {\n\t\tfmt.Println(err)\n\n\t}\n}\nstrconv.Atoi: parsing \"f42\": invalid syntax\n    File: /tmp/code/main.go, Line: 50. Function: main.atoi\n    File: /tmp/code/main.go, Line: 57. Function: main.main\n","tags":"#go #golang #error #errorhandling #abstraction"},{"id":"c13c30dcad137e93b38f7f8e0581945a","title":"[nginx rate limiting is weird] ","content":"nginx rate limiting is weird\n\nit takes input in requests per second\n\nbut that’s not how it rate limits\n\ninstead it divides your limit into tenth of a second chunks\n\nso a rate limit of 10 req/s is actually 1 req / 0.1 s\n\nwhich means if you get 2 requests within 0.1 s, the second one will be rejected\n\nthe best way to mitigate this is to allow a burst (this is what we do on webapp_waf) where you allow a burst of e.g. 10 reqs - meaning the first 10 requests wont be limited, but then if that rate is sustained future ones will be limited based on the tenth of a second bucketing\n","tags":"#nginx #ratelimit"},{"id":"71142e37f4f24ad1a37e1fb94e4e6d90","title":"[Go channel closing] ","content":"A common pattern for indicating something is done is to create an unbuffered channel of type `struct{}` and then `close` the channel will unblock anything trying to retrieve a value from the channel.\n\n\u003e Note: the reason for using `struct{}` type is because it's the smallest sized type in Go (no allocations are made).\n\nBelow is an example that demonstrates how closing a channel means you can still take values from the channel, but that they'll be the default value of the given type.\n\n```go\npackage main\n\nimport \"fmt\"\n\nfunc main() {\n\tc := make(chan bool)\n\n\tgo func() {\n\t\tc \u003c- true // blocks until someone takes value\n\t}()\n\n\tfmt.Println(\u003c-c) // true pulled from channel\n\tclose(c)\n\tfmt.Println(\u003c-c) // false which is default value of bool type\n}\n```\n","tags":"#go #golang #channel #close"},{"id":"8a1c597fe18e703282b33020adb71507","title":"[Python3 pass vs ...]","content":"## Summary\n\n- `pass`: use to indicate no-op.\n- `...`: use to indicate code not yet implemented.\n\n## Examples\n\nIf you had a function you were still in the process of writing, you might choose to use `...`\n\n```python\ndef foo():\n\t...\n```\n\nIf you were handling an exception and didn't want to do anything with it:\n\n```python\ndeadline = time.time() + 10\ndeadline_passed = time.time() \u003c deadline\n\nwhile not deadline_passed:\n    try:\n        a_mock_object.assert_called()\n        return\n    except AssertionError:\n        pass\n```\n","tags":""},{"id":"f0ab51316127c7d118e87bc62f5008af","title":"[Golang io.Pipe and io.TeeReader combined] ","content":"Two of my favour features in Go are:\n\n1. `io.TeeReader(r, w)`\n2. `pr, pw := io.Pipe()`\n\nTeeReader will write to `w` every time there is a read from `r`.\n\nPipe will read from `pr` every time there is a write to `pw`.\n\nTo consume from a single reader twice:\n\n```go\nio.TeeReader(r, pw)\n```\n\nFor example, when we pass the `io.TeeReader` to a function expecting an `io.Reader`, the function will read the data, and while it's reading the data it will simultaneously write the read data to `pw`, and when that happens the `pr` will read the data from `pw`.\n\nSometimes you need an `io.ReadCloser` but `io.TeeReader` only returns an `io.Reader`, so to fix that you need a custom type and constructor:\n\n```go\n// By embedding the two interfaces into the struct,\n// it means our struct instance must fulfill the interfaces.\ntype readCloser struct {\n\tio.Reader\n\tio.Closer\n}\n\n// We create a new instance of readCloser.\n// The Reader field is set to the io.TeeReader.\n// While the Closer field is set to the original io.ReadCloser.\nfunc newTeeReadCloser(rc io.ReadCloser, w io.Writer) io.ReadCloser {\n\treturn \u0026readCloser{\n\t\tReader: io.TeeReader(rc, w),\n\t\tCloser: rc,\n\t}\n}\n```\npackage main\n\nimport (\n\t\"fmt\"\n\t\"io\"\n\t\"strings\"\n\t\"sync\"\n)\n\nfunc main() {\n\twg := sync.WaitGroup{}\n\twg.Add(1)\n\n\tr := strings.NewReader(\"Test\")\n\tpr, pw := io.Pipe()\n\ttee := io.TeeReader(r, pw)\n\n\tgo func() {\n\t\tdefer wg.Done()\n\n\t\tfmt.Println(\"about to block thread waiting for a write to io.Pipe's reader\")\n\t\tcontent, _ := io.ReadAll(pr)\n\t\tfmt.Println(\"1: \", content)\n\t}()\n\n\tfmt.Println(\"about to block main thread until write to io.TeeReader's configured writer is complete\")\n\tcontent, _ := io.ReadAll(tee) // this will force a write to io.TeeReader's writer\n\tfmt.Println(\"2: \", content)\n\n\tpw.Close() // close the io.Pipe first before waiting for thread to complete (otherwise get a deadlock)\n\n\twg.Wait()\n}\npackage main\n\nimport (\n\t\"fmt\"\n\t\"io\"\n\t\"sync\"\n)\n\nfunc readFrom(pr *io.PipeReader, wg *sync.WaitGroup) {\n\tdefer wg.Done()\n\tb, _ := io.ReadAll(pr)\n\tfmt.Println(string(b), \".\")\n}\n\nfunc main() {\n\twg := sync.WaitGroup{}\n\twg.Add(2)\n\n\tpr, pw := io.Pipe()\n\n\tgo readFrom(pr, \u0026wg) // this will consume all three writes in one single read.\n  \tgo readFrom(pr, \u0026wg) // this secondary read needs pw.Close() to unblock it!\n  \t\t\t\t\t\t // specifically, the pipe reader will keep going util the\n  \t\t\t\t\t\t // writer has signified an EOF, which wont happen without\n\t\t\t\t\t\t // the call to Close(). \n  \t\t\t\t\t\t //\n  \t\t\t\t\t\t // this problem wouldn't exist if we had used a different\n  \t\t\t\t\t\t // read method, but as we used ioutil.ReadAll it is designed\n  \t\t\t\t\t\t // around the expectation of an EOF.\n\n\tpw.Write([]byte(\"foo\"))\n\tpw.Write([]byte(\"-\"))\n\tpw.Write([]byte(\"bar\"))\n\n  \tpw.Close() // do before Wait() otherwise deadlock (see comment above)\n\n\twg.Wait()\n}\n","tags":"#go #golang #io #pipe #tee #reader #writer"},{"id":"977efa8e748623ded3b164f8180e66f8","title":"[Golang change function signature without breaking existing consumers] ","content":"package main\n\nimport (\n\t\"fmt\"\n)\n\ntype Options struct {\n\ttimeout int\n}\n\nfunc foo(opts ...Options) {\n    // we're able to provide a default value for the original consumers!\n\ttimeout := 30\n\n\tfor _, o := range opts {\n\t\ttimeout = o.timeout\n\t\tbreak\n\t}\n\n\tfmt.Println(timeout)\n}\n\nfunc main() {\n    // original code had no args for foo() so consumer shouldn't break.\n\tfoo()\n  \n    // if more than one arg provided, then it'll be ignored within foo()\n\tfoo(Options{123}, Options{456})\n}\n","tags":"#go #golang #default #variadic #interface #api"},{"id":"16f406bcbb3e591901b88a81438ee704","title":"[Python Tox Explanation] ","content":"Tox is a tool that creates virtual environments, and installs the configured dependencies for those environments, for the purpose of testing a Python package (i.e. something that will be shared via PyPi, and so it only works with code that defines a `setup.py`).\n\nThe file that you use to configure tox can be one of the following...\n\n\u003e Note: these are all [ini file](https://en.wikipedia.org/wiki/INI_file) formats.\n\n- `tox.ini`\n- `pyproject.toml` (see [PEP 518](https://www.python.org/dev/peps/pep-0518/))\n- `setup.cfg` (see [official guide to distributing packages](https://packaging.python.org/guides/distributing-packages-using-setuptools/))\n\nAll configuration options for tox can be found here:\n[tox.readthedocs.io/en/latest/config.html](https://tox.readthedocs.io/en/latest/config.html)\n\n## Example tox.ini\n\n\u003e Note: the name after `testenv:` is the _name_ of the virtual environment that will be created (e.g. `testenv:foo` will create a \"foo\" virtual environment).\n\n```ini\n[tox]\nenvlist = \n    py37, lint\ntoxworkdir = \n    {env:TOX_WORK_DIR}\n\n[testenv]\nsetenv =\n    PYTHONDONTWRITEBYTECODE = 1\nwhitelist_externals =\n    /bin/bash\ndeps = \n    -rrequirements-dev.txt\ncommands =\n    py.test --cov={envsitepackagesdir}/bf_tornado -m \"not integration\"\n\n[testenv:dev]\nusedevelop=True\nrecreate = False\ncommands =\n    # to run arbitrary commands: tox -e dev -- bash\n    {posargs:py.test --cov=bf_tornado}\n\n[testenv:lint]\ndeps = flake8==3.7.9\ncommands =\n    flake8 bf_tornado\n```\n\n## Configuring _other_ packages\n\nA `tox.ini` file can be used to configure different types of packages, which is confusing at first because the tox home page suggests that tox is used to test _your own_ packages you plan on distributing to PyPi.\n\nWhat is meant by that is the `tox` command itself is used to handle testing your packages, while the `tox.ini` _configuration file_ is just one such file that can be used to contain configuration information.\n\nThis is why other packages, such as [Flake8](https://flake8.pycqa.org/en/latest/index.html) allow you to [configure it](https://flake8.pycqa.org/en/latest/user/configuration.html) using the `tox.ini` file (or alternatively either `setup.cfg` or `.flake8` files can be used). \n\nThe key to understanding why this works is as so: each of these files conforms to the [ini file](https://en.wikipedia.org/wiki/INI_file) format. So you're free to use whatever file 'name' you feel best suits your project, while the format of the file will stay consistent to what is expected of an `.ini` file.\n\nBelow is an example that shows various Python packages being configured within a `tox.ini` file.\n\nIn case it's unclear, the configuration inside of the `tox.ini` file is used instead of having to pass those configuration values via the command line. So in the case of a tool such as `flake8`, instead of using `flake8 --max-line-length=120` you could just call `flake8` and the flag value is extracted from the configuration file.\n\n```ini\n[flake8]\nmax_line_length = 120\nignore = E261,E265,E402  # http://pep8.readthedocs.org/en/latest/intro.html#error-codes\n\n[coverage:run]\nbranch = True\n\n[coverage:report]\nshow_missing = True\nexclude_lines =\n    raise NotImplementedError\n    return NotImplemented\n    def __repr__\nomit = bf_tornado/testing.py\n\n[pytest]\naddopts = \n    --strict -p no:cacheprovider --showlocals\nmarkers =\n    integration: mark a test as an integration test that makes http calls.\n```\n","tags":"#python #tox #testing"},{"id":"50f13472cfd1bc044f1364cc3517cecf","title":"[Python CLI Example Boilerplate with dependency validation] ","content":"#!/usr/bin/env python3\n\n\"\"\"\ndescription:\nallows engineers to ...\n\ndependencies:\ntornado \u003e= 6.0\n\nusage:\n./scripts/foo --debug\n\"\"\"\n\nimport argparse\nimport sys\n\ntry:\n    import tornado\nexcept ImportError as e:\n    print(\"this script requires tornado \u003e= 6.0\")\n    sys.exit(1)\n\nif not sys.version_info \u003e= (3, 7, 0):\n    print(\"this script requires the use of Python 3.7+\")\n    sys.exit(1)\n\nparser = argparse.ArgumentParser(description=\"DR www-west.buzzfeed.com\")\nparser.add_argument(\"-d\", \"--debug\", help=\"Show failure details\", action=\"store_true\")\nargs = parser.parse_args()\n\nprint(args.debug)\n\n","tags":"#python3 #cli #flags #example #boilerplate #validation #dependencies"},{"id":"f59ecde0baf7083c6fb047f24bd35f64","title":"[Python Fastly API Edge Dictionary Example] ","content":"#!/usr/bin/env python3\n\n\"\"\"\ndescription:\nallows engineers to cause requests to failover.example.com to skip\nauthentication (we use 'Basic' scheme https://tools.ietf.org/html/rfc7617).\n\ndependencies:\ntornado \u003e= 6.0\n\nusage:\nGET\n    FASTLY_API_KEY=123 ./scripts/dr_west\nSET\n    FASTLY_API_KEY=123 ./scripts/dr_west --set --skip-auth=\u003ctrue|false\u003e\n\"\"\"\n\nimport argparse\nimport json\nimport os\nimport re\nimport sys\n\n# required dependencies\n\ntry:\n    from tornado.httpclient import AsyncHTTPClient\n    from tornado.ioloop import IOLoop\nexcept ImportError:\n    print(\"this script requires tornado \u003e= 6.0\")\n    sys.exit(1)\n\nif not sys.version_info \u003e= (3, 7, 0):\n    print(\"this script requires the use of Python 3.7+\")\n    sys.exit(1)\n\n# cli flags\n\nparser = argparse.ArgumentParser(description=\"DR failover.example.com\")\nparser.add_argument(\"--set\", help=\"Set operation\", action=\"store_true\")\nparser.add_argument(\"--skip-auth\", help=\"Allow all requests to failover.example.com\", default=\"false\")\nargs = parser.parse_args()\n\n# constants\n\nSKIP_AUTH = bool(re.match(\"true\", args.skip_auth, flags=re.IGNORECASE))\nEDGE_DICT_ID = \"123\"\nEDGE_DICT_KEY = \"skip_auth\"\nFASTLY_API_KEY = os.environ.get(\"FASTLY_API_KEY\")\nFASTLY_SERVICE_ID = \"456\"\n\nif not FASTLY_API_KEY:\n    print(\"Fastly API token is missing. Set in env var `FASTLY_API_KEY`\")\n    sys.exit(1)\n\n# configuration\n\nAsyncHTTPClient.configure(None, defaults=dict(user_agent=\"Your-Organization\"))\nhttp_client = AsyncHTTPClient()\n\n\nasync def api_request(method=\"GET\", body=None):\n    content_type = {}\n\n    if method == \"PUT\":\n        content_type = {\"Content-Type\": \"application/x-www-form-urlencoded\"}\n\n    headers = {\"Fastly-Key\": FASTLY_API_KEY, **content_type}\n\n    host = \"https://api.fastly.com\"\n    path = f\"service/{FASTLY_SERVICE_ID}/dictionary/{EDGE_DICT_ID}/item/{EDGE_DICT_KEY}\"\n    url = f\"{host}/{path}\"\n\n    resp = await http_client.fetch(url, method=method, headers=headers, body=body, raise_error=False)\n    data = json.loads(resp.body)\n    key = data['item_value']\n\n    print(f\"{method} skip_auth: {key}\")\n\n\nasync def edge_key():\n    \"\"\"retrieves edge dictionary (foo_dict) key (skip_auth) value.\"\"\"\n\n    await api_request()\n\n\nasync def edge_key_update():\n    \"\"\"updates edge dictionary (foo_dict) with new key (skip_auth) value.\"\"\"\n\n    value = \"true\" if SKIP_AUTH else \"false\"\n    body = f\"item_value={value}\"\n\n    await api_request(method=\"PUT\", body=body)\n\n\nasync def main():\n    if args.set:\n        await edge_key_update()\n    else:\n        await edge_key()\n\nio_loop = IOLoop.current()\nio_loop.run_sync(main)\n","tags":"#python3 #fastly #api #edge #dictionary #example #cdn"},{"id":"6085917235753cad79388cad1ee73d0c","title":"[git edit hunk] ","content":"# https://stackoverflow.com/a/6508925\n\n# CODE BEFORE CHANGES\n37 argument = super(QueryArgumentMixin, self).get_query_argument(\n38     name, default=default, strip=strip\n39 )\n40 logging.warn(f\"argument: {argument}\")\n41 logging.warn(f\"default: {type(default)}\")\n42 logging.warn(f\"_ARG_DEFAULT: {type(_ARG_DEFAULT)}\")\n43 if not argument and default is self._ARG_DEFAULT:\n44     logging.warn(\"raise missing arg error\")\n45     raise tornado.web.MissingArgumentError(name)\n46 return argument\n47   \n\n# CODE AFTER CHANGES\n37 argument = super(QueryArgumentMixin, self).get_query_argument(\n38     name, default=default, strip=strip\n39 )\n40 if not argument and default is _ARG_DEFAULT:\n41     raise tornado.web.MissingArgumentError(name)\n42 return argument\n43   \n\n\"\"\"\n-37,11 \n-37 represents the file before the changes, and it says the hunk is starting from line 40 minus three (for extra context)\n,11 represents the number of lines in this hunk before the changes\n\n+36,7\n+36 represents the starting point after ALL changes (not just this hunk) are applied.\n,7  represents the number of lines in this hunk after the changes\n\nSo to modify the hunk as shown we'll need to modify the hunk header to:\n-37,7 +36,7\n\nNOTE: why the number +36 ??? it worked but I don't understand why?\n\"\"\"\n# Manual hunk edit mode -- see bottom for a quick guide.\n@@ -37,11 +36,7 @@ class QueryArgumentMixin(object):\n         argument = super(QueryArgumentMixin, self).get_query_argument(\n             name, default=default, strip=strip\n         )\n-        logging.warn(f\"argument: {argument}\")\n-        logging.warn(f\"default: {type(default)}\")\n-        logging.warn(f\"_ARG_DEFAULT: {type(_ARG_DEFAULT)}\")\n-        if not argument and default is self._ARG_DEFAULT:\n-            logging.warn(\"raise missing arg error\")\n+        if not argument and default is _ARG_DEFAULT:\n             raise tornado.web.MissingArgumentError(name)\n         return argument\n \n# ---\n# To remove '-' lines, make them ' ' lines (context).\n# To remove '+' lines, delete them.\n# Lines starting with # will be removed.\n# \n# If the patch applies cleanly, the edited hunk will immediately be\n# marked for staging.\n# If it does not apply cleanly, you will be given an opportunity to\n# edit again.  If all lines of the hunk are removed, then the edit is\n# aborted and the hunk is left unchanged.\n\n# Manual hunk edit mode -- see bottom for a quick guide.\n@@ -37,7 +37,7 @@ class QueryArgumentMixin(object):\n         argument = super(QueryArgumentMixin, self).get_query_argument(\n             name, default=default, strip=strip\n         )\n+        if not argument and default is _ARG_DEFAULT:\n             raise tornado.web.MissingArgumentError(name)\n         return argument\n \n# ---\n# To remove '-' lines, make them ' ' lines (context).\n# To remove '+' lines, delete them.\n# Lines starting with # will be removed.\n# \n# If the patch applies cleanly, the edited hunk will immediately be\n# marked for staging.\n# If it does not apply cleanly, you will be given an opportunity to\n# edit again.  If all lines of the hunk are removed, then the edit is\n# aborted and the hunk is left unchanged.\n\n$ git diff\ndiff --git a/foo b/foo\nindex b1e6722..d9a85ba 100644\n--- a/foo\n+++ b/foo\n@@ -1,3 +1,3 @@\n A\n-B\n C\n+D\n# Manual hunk edit mode -- see bottom for a quick guide.\n@@ -1,3 +1,4 @@\n A\n B\n C\n+D\n# ---\n# To remove '-' lines, make them ' ' lines (context).\n# To remove '+' lines, delete them.\n# Lines starting with # will be removed.\n# \n# If the patch applies cleanly, the edited hunk will immediately be\n# marked for staging.\n# If it does not apply cleanly, you will be given an opportunity to\n# edit again.  If all lines of the hunk are removed, then the edit is\n# aborted and the hunk is left unchanged.\n","tags":"#git #edit #hunk #patch #diff"},{"id":"b42349c1f20782484d837118f9fb7ad8","title":"[Python Print Parent Class] ","content":"import tornado.web\n\nclass App(tornado.web.Application):\n\tpass\n    \ntype(App()).__bases__  # (tornado.web.Application,)\ntype({}).__bases__  # (object,)\n","tags":"#python #class #hierarchy"},{"id":"340306f1938606a84667c9cc56af13f7","title":"[Bash find git repo root] ","content":"# /scripts/foo (this file) relies on /scripts/bar\n#\n# we want to be able to run this script from either:\n#\n# /scripts/foo or / (e.g. the root of the repo)\n#\n# e.g. \n# \t./scripts/foo\n#\n#   or\n#\n# \tcd ./scripts \u0026\u0026 ./foo\n#\n# but the sourcing of another script within foo means we need\n# an absolute path otherwise it won't find the sourced script\n\nREPO_ROOT=\"$(cd \"$(dirname \"${BASH_SOURCE[0]}\")/..\" \u0026\u0026 pwd)\"\nsource \"$REPO_ROOT/scripts/bar\"\n","tags":"#bash #git #repo #root"},{"id":"3fb9a8d8e52d1f0725bf4026491e6f49","title":"[golang cidr ip inspection] ","content":"package main\n\nimport (\n\t\"fmt\"\n\t\"log\"\n\t\"net\"\n)\n\nfunc main() {\n\tipv4Addr, ipv4Net, err := net.ParseCIDR(\"10.0.0.0/8\")\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\tfmt.Printf(\"%#v %s (%T)\\n\", ipv4Addr, ipv4Addr, ipv4Addr)\n\tfmt.Println(ipv4Net)\n\tfmt.Println(ipv4Net.Contains(net.ParseIP(\"10.255.255.0\")))\n}\n\n","tags":"#cidr #ip #network #go #golang"},{"id":"256c445d1d56369632e43d49056b60cf","title":"[Golang Array and Slices] ","content":"I'll explain how 'slices' work as best I can, but it might be worth also reading this official go post on the subject: https://blog.golang.org/go-slices-usage-and-internals (it has some nice visual aids too).\n\nA 'slice' is a data structure abstraction around the 'Array' [composite](https://www.integralist.co.uk/posts/data-types-and-data-structures/#data-types) data type.\n\nAn array is a fixed size and can't be resized once it is full. A slice also cannot dynamically grow larger at runtime, we must create a new slice, and this requires the use of the appropriate builtin functions.\n\nThe reason we have to use the builtin `append` function is because the [slice data structure](https://golang.org/pkg/reflect/#SliceHeader) includes a pointer to an array in memory. When appending more data than can be fit into the underlying array, the slice will copy the original array data to a _new_ array and will return a _new_ slice with an updated pointer.\n\nSo if you tried to append the values \"a\", \"b\" and \"c\" to a slice `s` like so: `append(s, \"a\", \"b\", \"c\")` then this would return a new slice, but the original slice `s` would not be changed (i.e. it would still reference the original underlying/untouched array). Hence we overwrite `s` to ensure it is the updated slice with a potentially updated internal array pointer.\n\nIt's worth noting that if the underlying array has enough capacity, then although append will still return a new slice, the underlying array will be the same (as no new array needed to be allocated to hold the extra data). This can mean that updates happen to the underlying array when maybe you didn't intend them to.\n\nThere is also the `...` syntax which is similar to rest/splat syntax in Python in that it unpacks the provided array/slice (e.g. `append(s, anotherSlice...)`).\n\nThere's also a gotcha which is worth being aware of, and is related to the fact that slices point to the same underlying array if the slice modifications didn't change the array's capacity: https://yourbasic.org/golang/gotcha-append/\n\n","tags":"#go #golang #slice #slices #array #internal #pointers"},{"id":"6ca9251adf682be55d387474b46998b6","title":"[vim open multiple files from a grep/sift search] ","content":"# where \"foo\" is your search pattern\nvim $(sift -l --err-skip-line-length foo)\n\n# from there you can do:\n# argdo %s/{search}/{replace}/ge | update\n","tags":"#vim #open #files #multiple #sift #grep #replace #search"},{"id":"7816083906903bf4c24140e7228c7ad2","title":"[Git Commit Frequency] ","content":"```\ngit log --author=\"Integralist\" --date=iso | perl -nalE 'if (/^Date:\\s+[\\d-]{10}\\s(\\d{2})/) { say $1+0 }' | sort | uniq -c|perl -MList::Util=max -nalE '$h{$F[1]} = $F[0]; }{ $m = max values %h; foreach (0..23) { $h{$_} = 0 if not exist\ns $h{$_} } foreach (sort {$a \u003c=\u003e $b } keys %h) { say sprintf \"%02d - %4d %s\", $_, $h{$_}, \"*\"x ($h{$_} / $m * 50); }'\n```\n\nOn the BuzzFeed mono repo...\n\n```\n00 -    0\n01 -    0\n02 -    0\n03 -    0\n04 -    0\n05 -    0\n06 -    0\n07 -    0\n08 -    5 **\n09 -   29 *************\n10 -   57 **************************\n11 -   82 **************************************\n12 -   85 ****************************************\n13 -   70 *********************************\n14 -  103 ************************************************\n15 -   79 *************************************\n16 -  106 **************************************************\n17 -   63 *****************************\n18 -   42 *******************\n19 -    9 ****\n20 -    2\n21 -    4 *\n22 -    4 *\n23 -    0\n```\n","tags":"#git #commit #frequency #bash #perl"},{"id":"1ceb9258b03ee4bc3a610582ea989412","title":"[BGP IP Hijack] ","content":"\u003e Reference:  \n\u003e https://www.wired.com/2008/08/revealed-the-in/\n\nThere is an issue with BGP (Border Gateway Protocol). The issue exists because BGP's architecture is based on trust. \n\nAs an example, for e-mail from Sprint customers in California to reach Telefonica customers in Spain, networks for these companies and others communicate through BGP routers to indicate when they're the quickest, most efficient route for the data to reach its destination. But BGP assumes that when a router says it's the best path, it's telling the truth. That gullibility makes it easy for eavesdroppers to fool routers into sending them traffic.\n\nHere's how it works. When a user types a website name into his browser or clicks \"send\" to launch an e-mail, a Domain Name System server produces an IP address for the destination. A router belonging to the user's ISP then consults a BGP table for the best route. That table is built from announcements, or \"advertisements,\" issued by ISPs and other networks – also known as Autonomous Systems, or ASes – declaring the range of IP addresses, or IP prefixes, to which they'll deliver traffic.\n\nThe routing table searches for the destination IP address among those prefixes. If two ASes deliver to the address, the one with the more specific prefix \"wins\" the traffic. For example, one AS may advertise that it delivers to a group of 90,000 IP addresses, while another delivers to a subset of 24,000 of those addresses. If the destination IP address falls within both announcements, BGP will send data to the narrower, more specific one.\n\nTo intercept data, an eavesdropper would advertise a range of IP addresses he wished to target that was narrower than the chunk advertised by other networks. The advertisement would take just minutes to propagate worldwide, before data headed to those addresses would begin arriving to his network.\n\nThe attack is called an IP hijack and, on its face, isn't new.\n\nBut in the past, known IP hijacks have created outages, which, because they were so obvious, were quickly noticed and fixed. That's what occurred earlier this year when Pakistan Telecom inadvertently hijacked YouTube traffic from around the world. The traffic hit a dead-end in Pakistan, so it was apparent to everyone trying to visit YouTube that something was amiss.\n\nPilosov's innovation is to forward the intercepted data silently to the actual destination, so that no outage occurs.\n\nOrdinarily, this shouldn't work – the data would boomerang back to the eavesdropper. But Pilosov and Kapela use a method called AS path prepending that causes a select number of BGP routers to reject their deceptive advertisement. They then use these ASes to forward the stolen data to its rightful recipients.\n","tags":"#bgp #route #routing #as #autonomous #systems #network #networking #internet"},{"id":"0ce27db1d7294f3af9896c0807ccfeed","title":"[Flake8 Import Order] ","content":"```ini\n; tox.ini\n\n[flake8]\nmax-line-length = 120\nimport-order-style = cryptography\napplication-import-names = foo\n```\n\n\u003e Note: _don't_ try and put `flake8-import-order` configuration under its own section (e.g. `[flake8-import-order]`) as Flake8 doesn't look at values outside of its own block (i.e. `[flake8]`) -- see explanation [here](https://github.com/PyCQA/flake8-import-order/issues/169#issuecomment-570936313).\n\n```python\n# standard library packages/modules\n\nimport asyncio\nimport time\n\n# third-party packages/modules\n\nfrom tornado.httpclient import AsyncHTTPClient\nfrom tornado.ioloop import IOLoop\n\n# application packages/modules\n\nfrom foo.bar import baz\n\nAsyncHTTPClient.configure(None, defaults=dict(user_agent=\"MyUserAgent\"))\nhttp_client = AsyncHTTPClient()\n\n\nasync def do_thing():\n    await asyncio.sleep(1)\n    time.sleep(1)\n    response = await http_client.fetch(\"https://www.integralist.co.uk\")\n    print(response.code)\n    baz()\n\nio_loop = IOLoop.current()\nio_loop.run_sync(do_thing)\n```\n\n\u003e Note: to ensure `foo` package isn't identified as \"Third-Party\" we have to specify it as \"Application\" via configuration with `application-import-names`, which is a comma-separated list of your own application packages/modules.\n","tags":"#python #flake8 #import #order"},{"id":"92e09f273c42ded3d3c2521972eb092e","title":"[dev deployment workflow process] ","content":"Make the changes\n\n    Create a new branch in git\n    Make the changes behind a feature flag\n    Run unit tests to validate your changes with the feature flag both on and off\n\nPull request\n\n    Commit the changes\n    Push the changes to a remote on github\n    Make a pull request\n    CI build runs automatically in the background\n    Code review\n    Repeat this step a few times perhaps\n    Merge the changes into git master\n\nCI runs on master\n\n    Install frontend dependencies via npm\n    Build/optimize HTML+CSS+JS assets\n    Run frontend unit/functional tests\n    Install Python dependencies from PyPI\n    Run backend unit/functional tests\n    Run integration tests against both assets\n    Push frontend assets to a CDN\n    Build a container for the Python program\n    Push container to registry\n    Update kubernetes manifest\n\nReplace old code with new code\n\n    Kubernetes spins up some instances of the new container\n    Kubernetes waits for those instances to become healthy\n    Kubernetes add those instances to the HTTP load balancer\n    Kubernetes waits for old instances to become unused\n    Kubernetes spins down old instances\n    Kubernetes repeats until all old instances have been replaced with new ones\n\nEnable new feature flag\n\n    Enable the new code for just yourself, gain confidence\n    Enable the new code for 10% of your users, watch operational and business metrics\n    Enable the new code for 50% of your users, watch operational and business metrics\n    Enable the new code for 100% of your users, watch operational and business metrics\n    Finally, go through the entire process again to remove the old code and the feature flag\n","tags":"#workflow #process #deployment #ci #cd"},{"id":"e5310d1082b0ff8307e39b71a6f9bae5","title":"[Python Comprehensions] ","content":"## Comprehensions\n\nA comprehension is a fancy way of saying: \"a more compact way of looping over, as well as filtering, a collection and generating a new collection from that process\".\n\nThere are three types of 'comprehensions' in Python to align with the various 'collection' types:\n\n1. List\n2. Dict\n3. Set\n\nThey all work the same but differ in the type that is generated at the end.\n\nThe syntax structure for each type looks like this:\n\n```\n# List\n(values) = [ (expression) for (item) in (collection) if condition ]\n\n# Dict/Set\n(values) = { (expression) for (item) in (collection) if condition }\n```\n\n\u003e Note: yes the Dict and Set syntax structure is the same but the output type will be different (as we'll see in the following examples) because the Dict will output key/value pairs, while the Set will output individual element values.\n\nHere are examples of each...\n\n```\n# List Output:\n# [0, 4, 16, 36, 64]\n[x * x for x in range(10) if x % 2 == 0]\n\n# Set Output\n# {0, 4, 16, 36, 64}\n{x * x for x in range(10) if x % 2 == 0}\n\n# Dict Output\n# {0: 0, 2: 4, 4: 16, 6: 36, 8: 64}\n{x: x * x for x in range(10) if x % 2 == 0}\n```\n\n\u003e Note: I've used the full syntax structure, but you don't have to. You could just use `for (item) in (collection)` and not include the `if condition` part.\n\nIf we were to write this code without comprehensions, then it would look like the following (yes it is a lot more verbose, but ultimately just a multi-lined version):\n\n```\n# List\n\noutput = []\nfor x in range(10):\n    if x % 2 == 0:\n        output.append(x * x)\n\n# Set \n\noutput = set()\nfor x in range(10):\n    if x % 2 == 0:\n        output.add(x * x)\n\n# Dict\n\noutput = dict()\nfor x in range(10):\n    if x % 2 == 0:\n        output.update({x: x * x})\n```\n","tags":"#python3 #comprehensions"},{"id":"45d979cacde4d65e2c6c3298211f2719","title":"[Golang Reduce Function Signature with Struct] ","content":"Instead of a long list of function arguments, consider using a struct.\n\nBecause types are initialized with a zero value, it means we can easily _omit_ a field if we want.\n\n```go\ntype FooOptions struct { \n  beep string \n  boop string\n  bing int\n} \n\nf, err := foo(FooOptions{ \n  beep: \"hello\", \n  bing: 123, \n})\n\n// notice `boop` field was omitted.\n```\n","tags":"#go #golang #struct #options #arguments #parameters #function #signature"},{"id":"898d40f51024c46d9660b92f5191f5e5","title":"[CPU bound vs I/O bound] ","content":"\u003e Note: the following is credited to [yaoyao.codes](http://yaoyao.codes/os/2017/03/20/cpu-bound-vs-io-bound).\n\n- **CPU bound**: the rate at which a process progresses is limited by the speed of the CPU. \n- **I/O bound**: the rate at which a process progresses is limited by the speed of the I/O subsystem.\n\nThis means a task that performs calculations on a small set of numbers, for example multiplying small matrices, is likely to be CPU bound. While a task that processes data from disk, for example, counting the number of lines in a file is likely to be I/O bound.\n\nA program is CPU bound if it would go faster if the CPU were faster.\n\nA program is I/O bound if it would go faster if the I/O subsystem was faster.\n","tags":"#cpu #io #bound"},{"id":"568a866aa64c6c6df092601e75b98def","title":"[transmission torrent alias] ","content":"alias tmd='transmission-daemon'\nalias tmr='transmission-remote'\nalias tmrw='watch -n 0.5 transmission-remote -l'\nalias tmrsp='transmission-remote --torrent all --stop'\nalias tmrst='transmission-remote --torrent all --start'\n","tags":"#transmission #torrent"},{"id":"2cc935fc5eb571cf937c17755ecc0952","title":"[Good Naming Strategy] ","content":"\u003e Reference: http://journal.stuffwithstuff.com/2016/06/16/long-names-are-long/\n\n## Choosing a Good Name\n\nA name has two goals:\n\n1. It needs to be _clear_: you need to know what the name refers to.\n2. It needs to be _precise_: you need to know what it does not refer to.\n\nAfter a name has accomplished those goals, any additional characters are dead weight.\n\n## Tips\n\nHere are some tips to help you...\n\n- Omit words that are obvious given the type (e.g. ❌ `var fooString string`).\n- Omit words that don't disambiguate the name (e.g. ❌ `finalMostDangerousMonster` vs ✅ `boss`).\n- Omit words that are known from the surrounding context (e.g. ❌ `class HolidaySale: _HolidayRebate = 123`).\n- Omit words that don't mean much of anything (e.g. ❌ `class WaffleObject` vs ✅ `class Waffle`).\n\n## Golang Tips\n\nhttps://talks.golang.org/2014/names.slide\n","tags":"#documentation #docs #guides #tutorials #reference #explanation #writing #naming #go #golang"},{"id":"5d9c79a740d744744b026616421708df","title":"[Python Boto3 S3 Example] ","content":"import boto3\n\naws_access_key_id = \"123\"\naws_secret_access_key = \"456\"\n\nsession = boto3.session.Session(\n    aws_access_key_id=aws_access_key_id,\n    aws_secret_access_key=aws_secret_access_key,\n)\n\ns3_resource = session.resource(\"s3\")\ns3_obj = s3_resource.Object(\"foo\", \"bar/baz\")\ns3_obj.get()\n\n\"\"\"\nRESPONSE...\n\n{'ResponseMetadata': {'RequestId': '123',\n  'HostId': '456',\n  'HTTPStatusCode': 200,\n  'HTTPHeaders': {'x-amz-id-2': '789',\n   'x-amz-request-id': '123',\n   'date': 'Wed, 05 Feb 2020 19:03:29 GMT',\n   'x-amz-replication-status': 'COMPLETED',\n   'last-modified': 'Wed, 27 Sep 2017 18:45:35 GMT',\n   'etag': '\"456\"',\n   'x-amz-storage-class': 'STANDARD_IA',\n   'x-amz-version-id': '789',\n   'accept-ranges': 'bytes',\n   'content-type': 'text/html',\n   'content-length': '283986',\n   'server': 'AmazonS3'},\n  'RetryAttempts': 0},\n 'AcceptRanges': 'bytes',\n 'LastModified': datetime.datetime(2017, 9, 27, 18, 45, 35, tzinfo=tzutc()),\n 'ContentLength': 283986,\n 'ETag': '\"123\"',\n 'VersionId': '456',\n 'ContentType': 'text/html',\n 'Metadata': {},\n 'StorageClass': 'STANDARD_IA',\n 'ReplicationStatus': 'COMPLETED',\n 'Body': \u003cbotocore.response.StreamingBody at 0x111f9a9d0\u003e}\n\"\"\"\n","tags":"#python3 #boto3 #aws #s3"},{"id":"cda12bf32cb622859512f4c666e0cbb0","title":"[Tornado configure AsyncHTTPClient to use Curl] ","content":"## Linux \n\nInstall OS dependencies...\n\n```bash\napt-get update \u0026\u0026 apt-get install -y libpq-dev build-essential libcurl4-openssl-dev libssl-dev\n```\n\nInstall Python dependencies...\n\n```\ntornado\npycurl\n```\n\nConfigure Tornado...\n\n```python\nAsyncHTTPClient.configure(\"tornado.curl_httpclient.CurlAsyncHTTPClient\", defaults=dict(user_agent=\"your_app\"))\nhttp_client = AsyncHTTPClient()\nhttp_client.fetch(\"https://www.integralist.co.uk/\")\n```\n\n## Notes on macOS\n\nI was getting the following error:\n\n```\nImportError: pycurl: libcurl link-time ssl backend (openssl) is different from compile-time ssl backend (none/other)\n```\n\nResolution:\n\n```\nexport PYCURL_SSL_LIBRARY=openssl\n\npip install --no-cache-dir --global-option=build_ext --global-option=\"-L/usr/local/opt/openssl/lib\" --global-option=\"-I/usr/local/opt/openssl/include\"  pycurl\n```\n","tags":"#python3 #tornado #configure #async #httpclient #curl #libcurl"},{"id":"94474b1d73deeb832f1f22f080f50c8a","title":"[ADR Architecture Decision Record] ","content":"# 1. Title\n\nDate: YYYY-MM-DD\n\n## Status\n\nAccepted|Deprecated|Proposed|Superseded\n\nA decision may be \"proposed\" if the project stakeholders haven't agreed with it yet, or \"accepted\" once it is agreed. If a later ADR changes or reverses a decision, it may be marked as \"deprecated\" or \"superseded\" with a reference to its replacement. \n\n## Context\n\nThis section describes the forces at play, including technological, political, social, and project local. These forces are probably in tension, and should be called out as such. The language in this section is value-neutral. It is simply describing facts. Describe the facts in the 'present tense' (i.e. don't detail the facts as if the problems they describe have been solved already).\n\n## Decision\n\nThis section describes our response to these forces. It is stated in full sentences, with active voice. \"We will ...\"\n\n## Consequences\n\nThis section describes the resulting context, after applying the decision. All consequences should be listed here, not just the \"positive\" ones. A particular decision may have positive, negative, and neutral consequences, but all of them affect the team and project in the future.\n\n","tags":"#architecture #decision #record #adr"},{"id":"c61346248e1f6c5c494fec98cb7be75c","title":"[File Permissions with Octal Notation Explanation] ","content":"A file can be accessed by different user types:\n\n- Owner\n- Group\n- Other\n\nAny one of these groups might be allowed to:\n\n- Read (`r`)\n- Write (`w`)\n- Execute (`x`)\n\nThese typically are displayed with a hyphen followed by the permissions for the user type (e.g. `-rwx-rwx-rwx`):\n\n```\n$ ls -l\n\n-rw-r--r--  1 integralist  staff      2  5 Feb 11:08 foo.txt\n```\n\n\u003e Note: in the above example the 'owner' can read/write, while the 'group' and 'other' users can only read the file.\n\nTo set these permissions you can use `chmod` with a 'octal permission' value:\n\n```\nchmod 777 foo.txt\n```\n\n\u003e Note: this would mean all user types (owner, group, other) can all read/write/execute the file.\n\nSo what do these octal numbers mean?\n\n```\nx (execute) - 1\nw (write)   - 2\nr (read)    - 4 \n```\n\nWe need to combine these numbers for _each_ user type:\n\nTo have read and write permissions would require a value of `6` (e.g. `2 (write) + 4 (read) = 6`).\n\nIf we only wanted the owner to have both read and write, but the others can only read the file, then we'd use:\n\n```\nchmod 644 foo.txt\n```\n\nBecause `6` == read/write for owner, while `4` == read for group/other.\n","tags":"#file #permissions #octal"},{"id":"81055fee04f5953d84cd4c0800e098e9","title":"[Markdown syntax for links in bottom of document] ","content":"blah blah [something][] here.\n\n...other content...\n\nyada yada [beepboop][foobar] goes here. \n\n\u003e Notice parentheses aren't used like a normal link `[text](link)` but two square brackets `[text][ref]`.\n\nThe below link references won't be visible in the generated markdown so you'll have to click on 'edit' (or 'view raw') to see it.\n\n[something]: ../relative/link\n[foobar]: https://absolute.link.com\n","tags":"#markdown #links #reference"},{"id":"339893af379763cf96bc73eb08376759","title":"[Python Atomic Counter] ","content":"import threading\n\n\nclass AtomicCounter(object):\n    \"\"\"An atomic, thread-safe counter\"\"\"\n    \n    def __init__(self, initial=0):\n        \"\"\"Initialize a new atomic counter to given initial value\"\"\"\n        self._value = initial\n        self._lock = threading.Lock()\n    \n    def inc(self, num=1):\n        \"\"\"Atomically increment the counter by num and return the new value\"\"\"\n        with self._lock:\n            self._value += num\n            return self._value\n    \n    def dec(self, num=1):\n        \"\"\"Atomically decrement the counter by num and return the new value\"\"\"\n        with self._lock:\n            self._value -= num\n            return self._value\n    \n    @property\n    def value(self):\n        return self._value\n      \ncounter = AtomicCounter()\ncounter.value  # 0\ncounter.inc()  # 1\ncounter.inc()  # 2\ncounter.dec()  # 1\ncounter.dec()  # 0\ncounter.dec()  # -1\n","tags":"#python3 #concurrency #threadsafe #lock #atomic #counter"},{"id":"b45518d16a7bc075e9c0c5a225027ad6","title":"[High Availability Content and Resilient Systems with Redundancy] ","content":"- Encourage greater use of existing shared software libraries (e.g. those that implement 'graceful shutdown' for in-flight requests).\n- Create shared libs supporting resilience patterns (e.g. circuit breakers, back-off, retries).\n- Monitor dependencies and identify new releases, notifying service owners/channels (allow frequency control).\n- More flexible canary deployments and introduce [blue-green deployments](https://martinfowler.com/bliki/BlueGreenDeployment.html).\n- Utilize tools such as [Chaos Monkey](https://netflix.github.io/chaosmonkey/) or [Gremlin](https://www.gremlin.com/).\n- Improve our synthetic testing (e.g. smoke testing).\n- Better service isolation (e.g. prevent problems propagating to other parts of our system). \n- Create feature flags to help disable broken features within a service quickly.\n- Automatic failover to multiple regions † (remove the manual process for app-west).\n- Implement some form of ‘adaptive capacity’ adjustment (software and infrastructure).\n- [Prioritized load shedding](https://www.google.com/url?q=https://cloud.google.com/blog/products/gcp/using-load-shedding-to-survive-a-success-disaster-cre-life-lessons\u0026sa=D\u0026ust=1578937508830000\u0026usg=AFQjCNE3hdPlc8GprCexIrXHOXKL-Mq7gA) (effective caching might be simpler/easier).\n- Setup 'traffic mirroring' (which can help verify service performance for dark launches).\n\n\u003e † Software libraries might need updating to reflect the dynamic nature of the regions they're interacting with.\n","tags":"#availability #resilience #tolerance #redundancy"},{"id":"c88a09dbe96af8715cf954e040e1a4f2","title":"[Create a simple Pip Python Repository] ","content":"\u003e Note: summarized from [this post](https://jpmens.net/2020/01/16/creating-a-simple-python-pip-repository/).\n\nThe simplest way to have `pip install foo` run successfully against your own Pip repository (instead of using the official PyPi) is to:\n\n1. Run a web server that exposes the directory listing (e.g. use [nginx](https://nginx.org/en/docs/http/ngx_http_autoindex_module.html)).\n2. Have the packages you need installed as individual directories on the web server.\n3. Setup a `/etc/pip.conf` file locally that is configured to your web server.\n\nFor step 2, the directory structure might look something like:\n\n```\n.\n├── airports\n│   └── airports-0.2.tar.gz\n└── paho-mqtt\n    └── paho-mqtt-1.5.0.tar.gz\n```\n\nFor step 3, the `/etc/pip.conf` file could look something like:\n\n```ini\n[global]\nindex = http://10.53.1.1/pip/\nindex-url = http://10.53.1.1/pip/\ntrusted-host = 10.53.1.1\n```\n\n\u003e Note: `10.53.1.1` should be replaced with your own web server IP.\n\nIt's worth noting that you don't _need_ a `/etc/pip.conf` file, as those options can be provided on the command line (e.g. `pip install --index-url=\u003cyour_webserver_address\u003e \u003cpackage(s)\u003e`).\n\nNow you should be able to install from your own Python repository:\n\n```bash\n$ python3.7 -m venv test_custom_pip\n$ source test_custom_pip/bin/activate\n$ pip install airports\n```\n\nIn order to backup the packages your project depends on (e.g. have them installed on your web server in a format that `pip install` will recognize) is to use a tool such as [pip2pi](https://pypi.org/project/pip2pi/).\n\nThe `pip2pi` package can be installed via `pip`. It can also use (although optional) a `requirements.txt` file for specifying the packages you want it to download.\n","tags":"#python3 #pip #repository #pypi"},{"id":"6ccedba3b2e13b10a1afb66ced0891ff","title":"[Check Python Tornado version] ","content":"if tornado.version_info \u003c (6, 0, 0, 0):\n    print(\"version is less than 6\")\n","tags":"#python3 #tornado #version"},{"id":"c03ddba75fec77d06f0d4eb34651f679","title":"[Parsing HTML with Python standard library] ","content":"from html.parser import HTMLParser\n\n\nclass MyHTMLParser(HTMLParser):\n    def handle_starttag(self, tag, attrs):\n        print(\"Encountered a start tag:\", tag)\n\n    def handle_data(self, data):\n        print(\"Encountered some data  :\", data)\n\n\nparser = MyHTMLParser()\nparser.feed(\n    \"\u003chtml\u003e\u003chead\u003e\u003ctitle\u003eTest\u003c/title\u003e\u003c/head\u003e\"\n    \"\u003cbody\u003e\u003ch1\u003eParse me!\u003c/h1\u003e\u003cdiv class='d1__episodes'\u003e\"\n    \"\u003ca href='/foo'\u003efoo\u003c/a\u003e\u003ca href='/bar'\u003ebar\u003c/a\u003e\u003c/div\u003e\u003c/body\u003e\u003c/html\u003e\"\n)\n","tags":"#python3 #html #parse #ast"},{"id":"cca9599decab873373aad6d8ebff61ac","title":"[Vim arg list and Search Replacement] ","content":"Imagine we have a file containing...\n\n```python\nfrom foo import Bar\n```\n\nWe want `Bar` to be `bar`.\n\nWe could do that across all files like so:\n\n```viml\n:args\n:args **/*.py\n:argdo %s/\\v(from foo import )B(ar)/\\1b\\2/e | update\n```\n\n\u003e `e` flag tells Vim to ignore any errors\n\nAlternatively instead of hardcoding the lowercase `b` we could have done this dynamically using either `\\l` which lowercases the first character inside of a backreference or `\\L` which lowercases the entire backreference ([Reference](https://vim.fandom.com/wiki/Changing_case_with_regular_expressions)).\n\nExamples...\n\n```viml\n:argdo %s/\\v(from foo import Bar)/\\L\\1/e | update\n:argdo %s/\\vfrom foo import (B)ar/\\l\\1/e | update\n:argdo %s/\\vfrom foo import (*+)/\\l\\1/e | update\n```\n","tags":"#vim #search #replace #args #case #lower #upper"},{"id":"fcc7c1705f9210bf58b9391b842c8450","title":"[transmission torrent tracker add script] ","content":"# It's a good idea to add as many 'trackers' as you can for a specific torrent.\n#\n# With transmission cli you use:\n# --tracker-add \"\u003curl_of_tracker\u003e\"\n#\n# Don't forget to make sure you add the tracker to the correct torrent:\n# -t \u003ctorrent_number\u003e\n#\n# Usage:\n# ./tracker.sh \u003ctorrent_number\u003e\n#\n# Documentation:\n# https://cli-ck.io/transmission-cli-user-guide/\n#\n# Trackers:\n# http://www.torrenttrackerlist.com/torrent-tracker-list/\n# \n# Tracker Cleanup:\n# cat trackers.txt | sort | uniq \u003e cleaned.txt\n\ninput=\"/tmp/trackers.txt\"\nwhile IFS= read -r line\ndo\n  transmission-remote -t \"$1\" --tracker-add \"$line\"\ndone \u003c \"$input\"\nhttp://104.28.1.30:8080/announce\nhttp://104.28.16.69/announce\nhttp://107.150.14.110:6969/announce\nhttp://109.121.134.121:1337/announce\nhttp://114.55.113.60:6969/announce\nhttp://125.227.35.196:6969/announce\nhttp://128.199.70.66:5944/announce\nhttp://157.7.202.64:8080/announce\nhttp://158.69.146.212:7777/announce\nhttp://173.254.204.71:1096/announce\nhttp://178.175.143.27/announce\nhttp://178.33.73.26:2710/announce\nhttp://182.176.139.129:6969/announce\nhttp://185.5.97.139:8089/announce\nhttp://188.165.253.109:1337/announce\nhttp://194.106.216.222/announce\nhttp://195.123.209.37:1337/announce\nhttp://210.244.71.25:6969/announce\nhttp://210.244.71.26:6969/announce\nhttp://213.159.215.198:6970/announce\nhttp://213.163.67.56:1337/announce\nhttp://37.19.5.139:6969/announce\nhttp://37.19.5.155:6881/announce\nhttp://46.4.109.148:6969/announce\nhttp://5.79.249.77:6969/announce\nhttp://5.79.83.193:2710/announce\nhttp://51.254.244.161:6969/announce\nhttp://59.36.96.77:6969/announce\nhttp://74.82.52.209:6969/announce\nhttp://80.246.243.18:6969/announce\nhttp://81.200.2.231/announce\nhttp://85.17.19.180/announce\nhttp://87.248.186.252:8080/announce\nhttp://87.253.152.137/announce\nhttp://91.216.110.47/announce\nhttp://91.217.91.21:3218/announce\nhttp://91.218.230.81:6969/announce\nhttp://93.92.64.5/announce\nhttp://agusiq-torrents.pl:6969/announce\nhttp://asnet.pw:2710/announce\nhttp://atrack.pow7.com/announce\nhttp://bt.henbt.com:2710/announce\nhttp://bt.pusacg.org:8080/announce\nhttp://bt1.xxxxbt.cc:6969/announce\nhttp://bt2.careland.com.cn:6969/announce\nhttp://explodie.org:6969/announce\nhttp://fxtt.ru:80/announce\nhttp://grifon.info:80/announce\nhttp://mgtracker.org:2710/announce\nhttp://mgtracker.org:6969/announce\nhttp://ns349743.ip-91-121-106.eu:80/announce\nhttp://open.acgtracker.com:1096/announce\nhttp://open.lolicon.eu:7777/announce\nhttp://open.touki.ru/announce.php\nhttp://open.trackerlist.xyz:80/announce\nhttp://p4p.arenabg.ch:1337/announce\nhttp://p4p.arenabg.com:1337/announce\nhttp://pow7.com:80/announce\nhttp://pt.lax.mx:80/announce\nhttp://retracker.bashtel.ru:80/announce\nhttp://retracker.goodline.info:80/announce\nhttp://retracker.gorcomnet.ru/announce\nhttp://retracker.krs-ix.ru/announce\nhttp://retracker.krs-ix.ru:80/announce\nhttp://retracker.mgts.by:80/announce\nhttp://retracker.spark-rostov.ru:80/announce\nhttp://retracker.telecom.by:80/announce\nhttp://secure.pow7.com/announce\nhttp://share.camoe.cn:8080/announce\nhttp://t.nyaatracker.com:80/announce\nhttp://t1.pow7.com/announce\nhttp://t2.pow7.com/announce\nhttp://thetracker.org:80/announce\nhttp://torrent.gresille.org/announce\nhttp://torrent.nwps.ws:80/announce\nhttp://torrentsmd.com:8080/announce\nhttp://torrentsmd.eu:8080/announce\nhttp://torrentsmd.me:8080/announce\nhttp://tr.kxmp.cf:80/announce\nhttp://tracker.aletorrenty.pl:2710/announce\nhttp://tracker.baravik.org:6970/announce\nhttp://tracker.bittor.pw:1337/announce\nhttp://tracker.bittorrent.am/announce\nhttp://tracker.bt4g.com:2095/announce\nhttp://tracker.calculate.ru:6969/announce\nhttp://tracker.city9x.com:2710/announce\nhttp://tracker.devil-torrents.pl:80/announce\nhttp://tracker.dler.org:6969/announce\nhttp://tracker.dutchtracking.com/announce\nhttp://tracker.dutchtracking.com:80/announce\nhttp://tracker.dutchtracking.nl/announce\nhttp://tracker.dutchtracking.nl:80/announce\nhttp://tracker.edoardocolombo.eu:6969/announce\nhttp://tracker.electro-torrent.pl:80/announce\nhttp://tracker.ex.ua/announce\nhttp://tracker.ex.ua:80/announce\nhttp://tracker.files.fm:6969/announce\nhttp://tracker.filetracker.pl:8089/announce\nhttp://tracker.flashtorrents.org:6969/announce\nhttp://tracker.gbitt.info:80/announce\nhttp://tracker.grepler.com:6969/announce\nhttp://tracker.internetwarriors.net:1337/announce\nhttp://tracker.kicks-ass.net/announce\nhttp://tracker.kicks-ass.net:80/announce\nhttp://tracker.kuroy.me:5944/announce\nhttp://tracker.mg64.net:6881/announce\nhttp://tracker.opentrackr.org:1337/announce\nhttp://tracker.skyts.net:6969/announce\nhttp://tracker.tfile.co:80/announce\nhttp://tracker.tfile.me/announce\nhttp://tracker.tfile.me:80/announce\nhttp://tracker.tiny-vps.com:6969/announce\nhttp://tracker.tvunderground.org.ru:3218/announce\nhttp://tracker.yoshi210.com:6969/announce\nhttp://tracker1.itzmx.com:8080/announce\nhttp://tracker1.wasabii.com.tw:6969/announce\nhttp://tracker2.itzmx.com:6961/announce\nhttp://tracker2.wasabii.com.tw:6969/announce\nhttp://tracker3.itzmx.com:6961/announce\nhttp://tracker4.itzmx.com:2710/announce\nhttp://www.wareztorrent.com/announce\nhttp://www.wareztorrent.com:80/announce\nhttps://104.28.17.69/announce\nhttps://open.kickasstracker.com:443/announce\nhttps://opentracker.xyz:443/announce\nhttps://t.quic.ws:443/announce\nhttps://tracker.bt-hash.com:443/announce\nhttps://tracker.fastdownload.xyz:443/announce\nhttps://tracker.nanoha.org:443/announce\nhttps://tracker.vectahosting.eu:2053/announce\nhttps://tracker6.lelux.fi:443/announce\nhttps://www.wareztorrent.com/announce\nudp://107.150.14.110:6969/announce\nudp://109.121.134.121:1337/announce\nudp://114.55.113.60:6969/announce\nudp://128.199.70.66:5944/announce\nudp://151.80.120.114:2710/announce\nudp://168.235.67.63:6969/announce\nudp://178.33.73.26:2710/announce\nudp://182.176.139.129:6969/announce\nudp://185.5.97.139:8089/announce\nudp://185.86.149.205:1337/announce\nudp://188.165.253.109:1337/announce\nudp://191.101.229.236:1337/announce\nudp://194.106.216.222:80/announce\nudp://195.123.209.37:1337/announce\nudp://195.123.209.40:80/announce\nudp://208.67.16.113:8000/announce\nudp://213.163.67.56:1337/announce\nudp://37.19.5.155:2710/announce\nudp://46.4.109.148:6969/announce\nudp://5.79.249.77:6969/announce\nudp://5.79.83.193:6969/announce\nudp://51.254.244.161:6969/announce\nudp://62.138.0.158:6969/announce\nudp://62.212.85.66:2710/announce\nudp://74.82.52.209:6969/announce\nudp://85.17.19.180:80/announce\nudp://89.234.156.205:80/announce\nudp://9.rarbg.com:2710/announce\nudp://9.rarbg.me:2710/announce\nudp://9.rarbg.me:2780/announce\nudp://9.rarbg.to:2710/announce\nudp://9.rarbg.to:2730/announce\nudp://91.218.230.81:6969/announce\nudp://94.23.183.33:6969/announce\nudp://amigacity.xyz:6969/announce\nudp://bt.aoeex.com:8000/announce\nudp://bt.dy20188.com:80/announce\nudp://bt.xxx-tracker.com:2710/announce\nudp://denis.stalker.upeer.me:6969/announce\nudp://eddie4.nl:6969/announce\nudp://exodus.desync.com:6969/announce\nudp://explodie.org:6969\nudp://explodie.org:6969/announce\nudp://inferno.demonoid.pw:3418/announce\nudp://ipv4.tracker.harry.lu:80/announce\nudp://ipv6.tracker.harry.lu:80/announce\nudp://mgtracker.org:2710/announce\nudp://open.demonii.si:1337/announce\nudp://open.stealth.si:80/announce\nudp://opentor.org:2710/announce\nudp://p4p.arenabg.com:1337/announce\nudp://peerfect.org:6969/announce\nudp://public.popcorn-tracker.org:6969/announce\nudp://retracker.akado-ural.ru:80/announce\nudp://retracker.baikal-telecom.net:2710/announce\nudp://retracker.hotplug.ru:2710/announce\nudp://retracker.lanta-net.ru:2710/announce\nudp://retracker.netbynet.ru:2710/announce\nudp://retracker.nts.su:2710/announce\nudp://santost12.xyz:6969/announce\nudp://shadowshq.eddie4.nl:6969/announce\nudp://shadowshq.yi.org:6969/announce\nudp://tc.animereactor.ru:8082/announce\nudp://thetracker.org:80/announce\nudp://torrent.gresille.org:80/announce\nudp://tracker-udp.gbitt.info:80/announce\nudp://tracker.aletorrenty.pl:2710/announce\nudp://tracker.birkenwald.de:6969/announce\nudp://tracker.bittor.pw:1337/announce\nudp://tracker.coppersurfer.tk:6969/announce\nudp://tracker.cyberia.is:6969/announce\nudp://tracker.cypherpunks.ru:6969/announce\nudp://tracker.doko.moe:6969/announce\nudp://tracker.dutchtracking.com:6969/announce\nudp://tracker.eddie4.nl:6969/announce\nudp://tracker.ex.ua:80/announce\nudp://tracker.filemail.com:6969/announce\nudp://tracker.filetracker.pl:8089/announce\nudp://tracker.fixr.pro:6969/announce\nudp://tracker.flashtorrents.org:6969/announce\nudp://tracker.grepler.com:6969/announce\nudp://tracker.halfchub.club:6969/announce\nudp://tracker.iamhansen.xyz:2000/announce\nudp://tracker.ilibr.org:80/announce\nudp://tracker.internetwarriors.net:1337/announce\nudp://tracker.justseed.it:1337/announce\nudp://tracker.kicks-ass.net:80/announce\nudp://tracker.kuroy.me:5944/announce\nudp://tracker.leechers-paradise.org:6969/announce\nudp://tracker.lelux.fi:6969/announce\nudp://tracker.mg64.net:2710/announce\nudp://tracker.mg64.net:6969/announce\nudp://tracker.moeking.me:6969/announce\nudp://tracker.nibba.trade:1337/announce\nudp://tracker.nyaa.uk:6969/announce\nudp://tracker.open-internet.nl:6969/announce\nudp://tracker.openbittorrent.com:80/announce\nudp://tracker.opentrackr.org:1337/announce\nudp://tracker.piratepublic.com:1337/announce\nudp://tracker.sktorrent.net:6969\nudp://tracker.sktorrent.net:6969/announce\nudp://tracker.skyts.net:6969/announce\nudp://tracker.supertracker.net:1337/announce\nudp://tracker.swateam.org.uk:2710/announce\nudp://tracker.tiny-vps.com:6969/announce\nudp://tracker.torrent.eu.org:451/announce\nudp://tracker.tvunderground.org.ru:3218/announce\nudp://tracker.uw0.xyz:6969/announce\nudp://tracker.vanitycore.co:6969/announce\nudp://tracker.yoshi210.com:6969/announce\nudp://tracker01.loveapp.com:6789/announce\nudp://tracker2.christianbro.pw:6969/announce\nudp://tracker2.indowebster.com:6969/announce\nudp://tracker2.itzmx.com:6961/announce\nudp://tracker4.piratux.com:6969/announce\nudp://ulfbrueggemann.no-ip.org:6969/announce\nudp://wambo.club:1337/announce\nudp://zephir.monocul.us:6969/announce\nudp://zer0day.ch:1337/announce\nudp://zer0day.to:1337/announce\n","tags":"#tracker #torrent #client #transmission #bash #cli"},{"id":"1ed04781e04cef5d12354b1761b4a580","title":"[Golang Gzip] ","content":"package main\n\nimport (\n\t\"bytes\"\n\t\"compress/gzip\"\n  \t\"encoding/base64\"\n\t\"fmt\"\n\t\"io/ioutil\"\n    \"math/rand\"\n)\n\nfunc main() {\n\tvar b bytes.Buffer\n\tw := gzip.NewWriter(\u0026b)\n\tw.Write(bytes.Repeat([]byte(\"x\"), 800))\n\tw.Flush()\n\tw.Close()\n\n\tb1 := bytes.NewReader(b.Bytes())\n\tfmt.Printf(\"%+v (%T)\\n\", b1, b1)\n\n\tr, _ := gzip.NewReader(\u0026b)\n\tdefer r.Close()\n\trawData, err := ioutil.ReadAll(r)\n\tprintln(string(rawData))\n\tif err != nil {\n\t\tpanic(err.Error())\n\t}\n\n  \t// use \"math/rand\"'s rand.Read to populate []byte with random data of specified length\n  \tgenBytes := make([]byte, 800)\n\trand.Read(genBytes) // generally won't be readable so might _look_ compressed even when decompressed\n\t\t\t\t\t\t// so maybe write encoded data to the gzip writer (see below for example).\n\n\tvar mockWriter bytes.Buffer\n\tw := gzip.NewWriter(\u0026mockWriter)\n\tw.Write(genBytes)\n\tw.Flush()\n\tw.Close()\n\t\n  \tdebugReadCloser := ioutil.NopCloser(bytes.NewReader(mockWriter.Bytes()))\n  \n  \t// encoded example\n  \n  \tgenBytes := make([]byte, 406715)\n\trand.Read(genBytes)\n\n\tencoded := make([]byte, 542288)\n\tbase64.StdEncoding.Encode(encoded, genBytes)\n\n\tvar mockWriter bytes.Buffer\n\tw := gzip.NewWriter(\u0026mockWriter)\n\tw.Write(encoded)\n\tw.Flush()\n\tw.Close()\n\n\tdebugReadCloser := ioutil.NopCloser(bytes.NewReader(mockWriter.Bytes()))\n}\npackage main\n\nimport (\n\t\"compress/gzip\"\n\t\"io\"\n\t\"log\"\n\t\"net/http\"\n\t\"os\"\n\t\"time\"\n)\n\nfunc main() {\n\tclient := \u0026http.Client{\n\t\tTimeout: time.Second * time.Duration(5*time.Second),\n\t}\n\n\treq, err := http.NewRequest(\"GET\", \"https://httpbin.org/gzip\", nil)\n\tif err != nil {\n\t\tlog.Fatalf(\"http new request error: %s\", err)\n\t}\n  \n \t// NOTE: If Accept-Encoding isn't presented to httpbin server, it won't send gzip response.\n\treq.Header.Add(\"Accept-Encoding\", \"gzip, deflate, br\")\n\n\tresp, err := client.Do(req)\n\tif err != nil {\n\t\tlog.Fatalf(\"http error: %s\", err)\n\t}\n\n\tr, err := gzip.NewReader(resp.Body)\n\tif err != nil {\n\t\tlog.Fatalf(\"new reader error: %s\", err)\n\t}\n\tdefer r.Close()\n\n\tio.Copy(os.Stdout, r)\n}\npackage main\n\nimport (\n\t\"bytes\"\n\t\"compress/gzip\"\n\t\"io/ioutil\"\n)\n\nfunc main() {\n\tdata := []byte(\"HelloWorld\")\n\n\tvar b bytes.Buffer\n\tw := gzip.NewWriter(\u0026b)\n\tw.Write(data)\n\tw.Flush()\n\tw.Close()\n\n\tr, _ := gzip.NewReader(\u0026b)\n\tdefer r.Close()\n\trawData, err := ioutil.ReadAll(r)\n\tprintln(string(rawData))\n\tif err != nil {\n\t\tpanic(err.Error())\n\t}\n\n}\npackage main\n\nimport (\n        \"net/http\"\n        \"compress/gzip\"\n        \"io/ioutil\"\n        \"strings\"\n        \"sync\"\n        \"io\"\n)\n\nvar gzPool = sync.Pool {\n        New: func() interface{} {\n                w := gzip.NewWriter(ioutil.Discard)\n                return w\n        },\n}\n\ntype gzipResponseWriter struct {\n        io.Writer\n        http.ResponseWriter\n}\n\nfunc (w *gzipResponseWriter) WriteHeader(status int) {\n        w.Header().Del(\"Content-Length\")\n        w.ResponseWriter.WriteHeader(status)\n}\n\nfunc (w *gzipResponseWriter) Write(b []byte) (int, error) {\n        return w.Writer.Write(b)\n}\n\nfunc Gzip(next http.Handler) http.Handler {\n        return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n                if !strings.Contains(r.Header.Get(\"Accept-Encoding\"), \"gzip\") {\n                        next.ServeHTTP(w, r)\n                        return\n                }\n\n                w.Header().Set(\"Content-Encoding\", \"gzip\")\n\n                gz := gzPool.Get().(*gzip.Writer)\n                defer gzPool.Put(gz)\n\n                gz.Reset(w)\n                defer gz.Close()\n\n                next.ServeHTTP(\u0026gzipResponseWriter{ResponseWriter: w, Writer: gz}, r)\n        })\n}\n// https://github.com/golang/go/issues/14975\n// slightly broken in the sense of not handling gz.Close()\n//\n// https://gist.github.com/erikdubbelboer/7df2b2b9f34f9f839a84\n// updated fork with fix + other refactorings + tests\n\npackage main\n\nimport (\n    \"compress/gzip\"\n    \"fmt\"\n    \"io\"\n    \"io/ioutil\"\n    \"net/http\"\n    \"net/http/httputil\"\n    \"net/url\"\n    \"strings\"\n    \"time\"\n)\n\n// Gzip from https://gist.github.com/the42/1956518\ntype gzipResponseWriter struct {\n    io.Writer\n    http.ResponseWriter\n}\n\nfunc (w gzipResponseWriter) Write(b []byte) (int, error) {\n    return w.Writer.Write(b)\n}\n\nfunc (w gzipResponseWriter) WriteHeader(code int) {\n    fmt.Printf(\"Writing header: %v\\n\", code)\n    w.Header().Del(\"Content-Length\")\n    w.ResponseWriter.WriteHeader(code)\n}\n\nfunc makeGzipHandler(fn http.HandlerFunc) http.HandlerFunc {\n    return func(w http.ResponseWriter, r *http.Request) {\n        if !strings.Contains(r.Header.Get(\"Accept-Encoding\"), \"gzip\") {\n            fn(w, r)\n            return\n        }\n        w.Header().Set(\"Content-Encoding\", \"gzip\")\n        gz := gzip.NewWriter(w)\n        defer func() {\n            err := gz.Close()\n            if err != nil {\n                fmt.Printf(\"Error closing gzip: %+v\\n\", err)\n            }\n        }()\n        gzr := gzipResponseWriter{Writer: gz, ResponseWriter: w}\n        fn(gzr, r)\n    }\n}\n\n// Handler that does not set a content length, so, golang uses chunking.\nfunc handler(w http.ResponseWriter, r *http.Request) {\n    message := \"Hello, world!\"\n    w.Header().Set(\"Content-Type\", \"text/plain\")\n    w.Write([]byte(message))\n}\n\n// Constructs a reverse proxy to the given port.\nfunc reverseProxy(port string) func(http.ResponseWriter, *http.Request) {\n    url, err := url.Parse(\"http://127.0.0.1\" + port)\n    if err != nil {\n        panic(err)\n    }\n    return httputil.NewSingleHostReverseProxy(url).ServeHTTP\n}\n\n// Gets the content from the given server, then returns the error from reading the body.\nfunc get(server http.Server) error {\n    resp, err := http.Get(\"http://127.0.0.1\" + server.Addr)\n    if err != nil {\n        panic(err)\n    }\n    defer resp.Body.Close()\n    _, err = ioutil.ReadAll(resp.Body)\n    return err\n}\n\nfunc main() {\n    server := http.Server{\n        Addr:    \":2000\",\n        Handler: http.HandlerFunc(handler),\n    }\n    go server.ListenAndServe()\n\n    proxyServer := http.Server{\n        Addr:    \":4000\",\n        Handler: makeGzipHandler(reverseProxy(server.Addr)),\n    }\n    go proxyServer.ListenAndServe()\n\n    time.Sleep(10 * time.Millisecond)\n\n    fmt.Printf(\"Server err: %v\\n\", get(server))\n    fmt.Printf(\"Proxy server err: %v\\n\", get(proxyServer))\n}\n","tags":"#golang #go #gzip #proxy"},{"id":"a6afdbaf8a3801171e7429a6fefb1c53","title":"[CHANGELOG] ","content":"\u003e https://keepachangelog.com/\n\nGuiding Principles\n\n- Changelogs are for humans, not machines.\n- There should be an entry for every single version.\n- The same types of changes should be grouped.\n- Versions and sections should be linkable.\n- The latest version comes first.\n- The release date of each version is displayed.\n- Mention whether you follow Semantic Versioning.\n\nTypes of changes\n\n- `Added` for new features.\n- `Changed` for changes in existing functionality.\n- `Deprecated` for soon-to-be removed features.\n- `Removed` for now removed features.\n- `Fixed` for any bug fixes.\n- `Security` in case of vulnerabilities.\n\n## Example\n\n```\n# Change Log\nAll notable changes to this project will be documented in this file.\n\nThe format is based on [Keep a Changelog](http://keepachangelog.com/)\nand this project adheres to [Semantic Versioning](http://semver.org/).\n\n## [[2.0.0] - 2019-11-19](https://github.com/foo/bar/pull/4)\n### Added\n- New breaking API.\n\n## [[1.1.1] - 2019-03-21](https://github.com/foo/bar/pull/3)\n### Fixed\n- Hotfix for bug.\n\n## [[1.1.0] - 2016-08-01](https://github.com/foo/bar/pull/2)\n### Added\n- New non-breaking feature.\n\n## [[1.0.0] - 2015-04-29](https://github.com/foo/bar/pull/1)\n### Added\n- Initial thing.\n```\n","tags":"#changelog"},{"id":"583e9ebf461fe23d1718288a73aac484","title":"[Python3 Stream Server] ","content":"import asyncio\nimport contextvars\n\nclient_addr_var = contextvars.ContextVar('client_addr')  # type:ignore\n\n\ndef render_goodbye():\n    # The address of the currently handled client can be accessed\n    # without passing it explicitly to this function.\n\n    client_addr = client_addr_var.get()\n    return f'Good bye, client @ {client_addr}\\n'.encode()\n\n\n# https://docs.python.org/3/library/asyncio-stream.html#asyncio.StreamReader\nasync def handle_request(reader, writer):\n    addr = writer.transport.get_extra_info('socket').getpeername()\n    client_addr_var.set(addr)\n\n    # In any code that we call is now possible to get\n    # client's address by calling 'client_addr_var.get()'.\n\n    while True:\n        line = await reader.readline()\n        print(line)\n        writer.write(render_goodbye())\n        writer.close()\n        if reader.at_eof():\n            print('BREAK')\n            break\n\n\nasync def main():\n    # https://docs.python.org/3/library/asyncio-eventloop.html#asyncio.Server\n    srv = await asyncio.start_server(handle_request, '127.0.0.1', 8081)\n\n    async with srv:\n        await srv.serve_forever()\n\nasyncio.run(main())\n\n","tags":"#python3 #asyncio #stream #server"},{"id":"09d8caa41656d8e8447c4c6d315cb99d","title":"[Go Test Mocking Package Function] ","content":"## Build Tags\n\nFile: `a/a.go`\n\n```go\n// +build !mock\n\npackage a\nfunc DoSomething() {\n    return \"done\"\n}\n```\n\nFile: `a/a_mock.go`\n\n```go\n// +build mock\n\npackage a\nfunc DoSomething() {  // Insert fake implementation here\n    return \"complete\"\n}\n```\n\nExecute tests using build tag:\n\n```bash\n$ go test -tags mock\n```\n","tags":"#go #golang #mock #stub #testing #unittests #test"},{"id":"242cb31de57b33066c26ab366de5aacc","title":"[Mature Engineers] ","content":"The following is copied verbatim from https://www.kitchensoap.com/2012/10/25/on-being-a-senior-engineer/ -- this gist is merely a partial backup of that excellent article.\n\nFor my own thoughts on the subject (which I still agree with having now read the above link) see my post called \"The Perfect Developer Qualities\": https://www.integralist.co.uk/posts/the-perfect-developer-qualities/\n\n**Mature engineers seek out constructive criticism of their designs.**\n\nEvery successful engineer I’ve met, upon finishing up a design or getting ready for a project, will continually ask their peers questions along the lines of:\n\n- “What could I be missing?”\n- “How will this not work?”\n- “Will you please shoot as many holes as possible into my thinking on this?”\n- “Even if it’s technically sound, is it understandable enough for the rest of the organization to operate, troubleshoot, and extend it?”\n\nThis is because they know that nothing they make will ever only be in their hands, and that good peer review is what makes better design decisions. As it’s been said elsewhere, they “beg for the bad news.”\n\n**Mature engineers understand the non-technical areas of how they are perceived.**\n\nBeing able to write a Bloom Filter in Erlang, or write multi-threaded C in your sleep is insufficient. None of that matters if no one wants to work with you. Mature engineers know that no matter how complete, elegant, or superior their designs are, it won’t matter if no one wants to work alongside them because they are assholes. Condescension, belittling, narcissism, and ego-boosting behavior send the message to other engineers (maybe tacitly) to stay away. Part of being happy in engineering comes from enjoying the company of the people you work with while designing and building things. An engineer who is quick to call someone a moron is someone destined to stunt his or her career.\n\nThis also means that mature engineers have self-awareness when it comes to their communication. This isn’t to say that every mature engineer communicates perfectly, only that they have some notion about where they could be better, and continually ask for a gut-check from peers and managers on how they’re doing. They aim to be assertive, not passive or aggressive in how they get their ideas across.\n\nI’ve mentioned it elsewhere, but I must emphasize the point more: the degree to which other people want to work with you is a direct indication on how successful you’ll be in your career as an engineer. Be the engineer that everyone wants to work with.\n\nNow this isn’t to say that you should shy away from giving (or getting) constructive criticism on the work produced by engineering (as opposed to the engineer personally), for fear of pissing someone off. There’s a difference between calling someone a moron and pointing out faults in their code or product.\n\n**Mature engineers do not shy away from making estimates, and are always trying to get better at it.**\n\nAvoiding responsibility for estimates is another way of saying, “I’m not ready to be relied upon for building critical pieces of infrastructure.” All businesses rely on estimates, and all engineers working on a project are involved in Joint Activity, which means that they have a responsibility to others to make themselves interpredictable. In general, mature engineers are comfortable with working within some nonzero amount of uncertainty and risk.\n\n**Mature engineers have an innate sense of anticipation, even if they don’t know they do.**\n\nThis code looks good, I’m proud of myself. I’ve asked other people to review it, and I’ve taken their feedback. Now: how long will it last before it’s rewritten? Once it’s in production, how will its execution affect resource usage? How much so I expect CPU/memory/disk/network to increase or decrease? Will others be able to understand this code? Am I making it as easy as I can for others to extend or introspect this work?\n\n**Mature engineers understand that not all of their projects are filled with rockstar-on-stage work.**\n\nGetting things done means doing things you might not be interested in. No matter how sexy a project is, there are always boring tasks. Tedious tasks. Tasks that a less mature engineer may deem beneath their dignity or their job title.\n\n**Mature engineers lift the skills and expertise of those around them.**\n\nThey recognize that at some point, their individual contribution and potential cannot be exercised singularly. They recognize that there is only so much that can be produced by a single person, and the world’s best engineering feats are executed by teams, not singularly brilliant and lone engineers.\n\n**Mature engineers make their trade-offs explicit when making judgements and decisions.**\n\nThey realize all engineering decisions, implementations, and designs exist within a spectrum; we do not live in a binary world. They can quickly point out contexts where one successful approach or solution could work and where it could not. They know that one cannot be both efficient and thorough at the same time (The ETTO Principle), that most projects engineers work on exist on an axis of optimality and brittleness, and that whether the problems they are solving are acute or chronic.\n\nThey know that they work within a spectrum of ideal and non-ideal, and are OK with that. They are comfortable with it because they strive to make the ideal and non-ideal in a design explicit. Later on in the lifecycle of a design, when the original design is not scaling anymore or needs to be replaced or rewritten, they can look back not with a perspective of how short-sighted those earlier decisions were, but instead say “yep, we made it this far with it and knew we’d have to extend or change it at some point. Looks like that time is now, let’s get to work!” instead of responding with a cranky-pants, passive-aggressive Hindsight Bias-filled remark with counterfactuals (e.g.. “those idiots didn’t do it right the first time!”, “they cut corners!”, “I TOLD them this wouldn’t work!”)\n\nThe tl;dr on trade-offs is that everyone cuts corners, in every project. Immature engineers discover them in hindsight, disgusted. Mature engineers spell them out at the onset of a project, accept them and recognize them as part of good engineering.\n\n**Mature engineers don’t practice CYAE (“Cover Your Ass Engineering”)**\n\nThe scenario where someone will stand on ceremony as an excuse for not attempting to understand how his or her code (or infrastructure) could be touched by other parts of the system or business is a losing proposition. Covering your ass sends the implicit message that you are someone willing to throw others (on your team? in your company? in your community?) under the proverbial bus at the mere hint that your work had any flaw. Mature engineers stand up and accept the responsibility given to them. If they find they don’t have the requisite authority to be held accountable for their work, they seek out ways to rectify that.\n\nAn example of CYAE is “It’s not my fault. They broke it, they used it wrong. I built it to spec, I can’t be held responsible for their mistakes or improper specification.”\n\n**Mature engineers are empathetic.**\n\nIn complex projects, there are usually a number of stakeholders. In any project, the designers, product managers, operations engineers, developers, and business development folks all have goals and perspectives, and mature engineers realize that those goals and views may be different. They understand this so that they can navigate effectively in the work that they do. Being empathetic in this sense means having the ability to view the project from another person’s perspective and to take that into consideration into your own work.\n\nGoal conflicts are inherent in all engineering work, and complaining about them (instead of embracing them as requirements for success) is a sign of a less mature engineer.\n\n**They don’t make empty complaints.**\n\nInstead, they express judgements based on empirical evidence and bring with those judgements options for solving the problem which they’ve identified. A great manager of mine said to never go to your boss with a complaint about anything without at least one (ideally more than one) suggestion for a solution. Even demonstrating that you’ve tried working the problem on your own and came up empty-handed is better than an empty complaint.\n\n**Mature engineers are aware of cognitive biases**\n\nThis isn’t to say that every mature engineer needs to have a degree in psychology, but cognitive biases are what can limit the growth of an engineer’s career at a certain point. Even if they’re not aware of the details of how they appear or how these biases can be guarded against, most mature engineers I know have a level of self-awareness to at least recognize they (like everyone) are susceptible to them.\n\nCulturally, engineers work day-to-day in empirical evidence in research. Basically: show me the data. The issue with cognitive biases is that we can be blissfully unaware of when we are interpreting data with our own brains in ways that defy empirical data, and can have a surprising effect on how we get work done and work on teams.\n\n- Self-Serving Bias: basically, if something is good, it’s probably because of something I did or thought of. If it’s bad, it’s probably the doing of someone else.\n\n- Fundamental Attribution Error: basically: the bad results that someone else got from his work must have something to do with how he is, personally (stupid, clumsy, sloppy, etc.) whereas if I get bad results, it’s because of the context that I was in, the pressure I was under, the situation I was in, etc.\n\n- Hindsight Bias: (it is said that this is the most-studied phenomenon in the history of modern psychology) basically: after an untoward or negative event (a severe bug, an outage, etc.) “I knew it all along!”. It is the very strong tendency to view the past more simply than it was in reality. You can tell there is Hindsight Bias going on when descriptions involve counterfactuals, or “…they should have…”, or “…how did they not see that, it’s so obvious!”.\n\n- Outcome Bias: like above, this comes up after a surprising or negative event. If the event was very damaging, expensive to clean up, or severe, then the decisions or actions that contributed to that event are judged to be very stupid, reckless, or negligent. The judgement is proportional to how severe the event was.\n\n- Planning Fallacy: (related to the point about making estimates under uncertainty, above) basically: being more optimistic about forecasting the time a particular project will take.\n\n\u003e “It is amazing what you can accomplish if you do not care who gets credit.” -- This quote is commonly attributed to Harry S. Truman, but it looks like it might have first been said by a Jesuit priest in a different form. In any case, this is another indication you’re working with a mature engineer: they hold the success of the project much higher than the potential praise they may get personally for working on it.\n","tags":"#mature #senior #developer #qualities #engineer"},{"id":"414fc20834cf953ee725f930e74d8acf","title":"[Deployment Types] ","content":"## Background\nThere are two common techniques for implementing slow, controlled deployments, namely canary deployments and blue-green deployments. Both techniques are effective if used properly. This document makes no effort to argue for/against either of these methods.\n\n## Canary Deployments\nCanary deployments are a technique to reduce the risk of introducing new software versions into production by slowly rolling out the change to a small subset of traffic before rolling it out to the entire infrastructure. As the operator gains confidence in the new version, they can start releasing it to more servers/instances in your infrastructure, and thus routing more traffic to it.  Canary deployments last until all traffic has been routed to the new version. If the operator finds any problems with the new version, the rollback strategy is simply to redeploy the old version on the small subset of services/instances until the problem has been resolved.\n\n## Blue Green Deployments\nBlue-green deployments approach slow and controlled releases by ensuring the operator has two nearly identical environments, blue and green. At any time, one of the environments is “live” and receiving traffic. For the sake of example, let’s assume we have a “live” blue environment. In order to release a new software version, the operator deploys the new version to the non-live green environment. Afterwards, the operator re-routes traffic from the blue environment to the green environment. Once complete, the green environment is now “live” receiving all traffic, while the blue environment is now idle.  Blue-green deployments also give a means of rapid rollback - if anything goes wrong, the operator can switch back to the previous environment.\n\n","tags":"#deploy #rollout #types #deployment #bluegreen #canary"},{"id":"94136fe04af40f5e9c53f0f746d4fb6e","title":"[Golang Range and Binary Search] ","content":"package main\n\nimport (\n\t\"fmt\"\n\t\"sort\"\n)\n\nfunc main() {\n\tdata := makeRange(200, 399)\n\tfmt.Println(data)\n\n\tneedle := 299\n\tindex := sort.Search(len(data), func(i int) bool { return data[i] \u003e= needle })\n\n\tif index \u003e= len(data) {\n\t\tfmt.Printf(\"index %d means the needle is not in data\\n\\n\", index)\n\t} else {\n\t\tfmt.Println(\"needle was found at index:\", index)\t\n\t}\n\t\n\t// alternative checking conditional\n\n\tif index \u003c len(data) \u0026\u0026 data[index] == needle {\n\t\t// needle is present at data[index]\n\t\tfmt.Println(\"needle found:\", data[index])\n\t} else {\n\t\t// needle is not present in data,\n\t\t// but 'index' is the index where it would be inserted.\n\t\tfmt.Printf(\"needle %d is not present in data, index is where it would be inserted: %d\\n\", needle, index)\n\t}\n}\n\nfunc makeRange(min, max int) []int {\n\ta := make([]int, max-min+1)\n\tfor i := range a {\n\t\ta[i] = min + i\n\t}\n\treturn a\n}\n","tags":"#binarysearch #search #sort #go #golang #range"},{"id":"c6ca97498a25911d17ca93a39d723dcc","title":"[Simple Tornado] ","content":"import tornado.ioloop\nimport tornado.web\n\n\nclass MainHandler(tornado.web.RequestHandler):\n    def get(self):\n        self.set_cookie('foo', 'bar')\n        print(self.request.headers)\n        self.render('form.html')\n\n    def post(self):\n        print(self.request.headers)\n        cookie = self.get_cookie('foo')\n        self.finish({'state': 'success', 'foo_cookie': cookie})\n\ndef make_app():\n    return tornado.web.Application([\n        (r'/', MainHandler),\n    ])\n\n\nif __name__ == '__main__':\n    app = make_app()\n    app.listen(9000)\n    tornado.ioloop.IOLoop.current().start()\n\u003chtml\u003e\n\u003chead\u003e\n  \u003cscript\u003e\n    function request(url, params, callback) {\n      var xhr = new XMLHttpRequest();\n\n      xhr.open('POST', url, true);\n      xhr.setRequestHeader('content-type', 'application/x-www-form-urlencoded');\n\n      xhr.onreadystatechange = function() {\n        if (xhr.readyState == 4) {\n          if (xhr.status == 500) {\n            return callback({\n              'state': 'error',\n              'message': 'There was a problem processing this request.'\n            });\n          }\n          var response = JSON.parse(xhr.responseText);\n          return callback(response);\n        }\n      };\n\n      xhr.send(params);\n    }\n\n\n    document.addEventListener('DOMContentLoaded', (event) =\u003e {\n      var submit = document.getElementById('myform');\n      submit.addEventListener('submit', function(e){\n        e.preventDefault();\n\n        var url = '/';\n        var params = 'beep=boop\u0026tokens=blah\u0026_xsrf=123';\n        var callback = function(response){\n          console.log(response);\n        };\n\n        request(url, params, callback);\n      });\n    });\n  \u003c/script\u003e\n\u003c/head\u003e\n\u003cbody\u003e\n  \u003cform id=\"myform\"\u003e\n    \u003cinput type=\"submit\"\u003e\n  \u003c/form\u003e\n\u003c/body\u003e\n\u003c/html\u003e\n","tags":"#python #python3 #tornado #example #basic #simple"},{"id":"68d208605633e3167df4d78f8371f3bf","title":"CDN Logs Sampling Rates ","content":"# CDN Uncached Request Log Sampling\n\n## Why?\n\nWhen we began passing Fastly logs through to Datadog, we were concerned with the volume of requests that we'd be logging. To cut down on this volume we decided to only pass through requests that were not satisfied by the cache. While this has reduced the log volume to a great degree, at times of high traffic we've seen millions of log events still passed through. To remain cost conscious while using Datadog to get visibility into these logs a sampling strategy should be implemented.\n\n## Proposed Sampling Rates\n\n| Fastly Status | Meaning of Status | Sample Rate | Justification |\n|---|---|---|---|\n| `PASS` | serving uncached content and do not intend to cache response | 100% | `PASS` requests are frequently just administrative, however having them easily available is useful for debugging. As there were 66k events for this category total in the sample time period chosen, sending 100% of them to Datadog seems like a reasonable approach. |\n| `MISS` | serving uncached content | 10% | `MISS` is the vanilla \"uncached content\" response and these logs reflect expected behavior. We can sample this category quite conservatively. Rather than relying on logs to expose major changes to this, we should ensure appropriate metrics are taken, and use full logs pulled from S3 when deeper insight is needed. |\n| `MISS-WAIT`| serving uncached content and had to wait an unusual amount of time for a highly contested object | 100% | In the sample time period chosen, over 3m events were shipped. 2 of them had the cache response status of `MISS-WAIT` and both cases returned a `400`. These are useful logs to have in completeness for debugging issues with the CDN. |\n| `MISS-CLUSTER` | serving uncached content, object will be served from another node in the PoP | 10% | This is the largest category of logs, and for the sample time period chosen, 3.37m log events contained this cache status. Of those, all were successful request fills, with 3.2m of those returning `200`. This is a \"healthy\" request with an expected behavior and thus can be sampled quite conservatively. Rather than relying on logs to expose major changes to this, we should ensure appropriate metrics are taken, and use full logs pulled from S3 when deeper insight is needed. |\n| `MISS-WAIT-CLUSTER` | serving uncached content, object will be served from another node in the pop, waited an unusual amount of time for a highly contested object. | 100% | In the sample time period chosen, over 3m events were shipped. 24 of them had the cache response status of `MISS-CLUSTER-WAIT`. These logs reveal objects that are in high demand and are uncached for whatever reason, which can be a clue in debugging CDN issues and would be good to have easily available.|\n\n## Pricing\n\nQuick napkin math says that adopting this sampling strategy will generate ~ 375k log events/hr, and cost roughly $6.21/day (@ 0.69/1m events) for a total of $187/mo (rounded up).\n","tags":"#cdn #logs #maths #performance #costs"},{"id":"050debbb72e596c882ce609187fd3d52","title":"[AWS Security Group Rule - Ingress vs Egress] ","content":"The ever wonderful [twitter.com/sweetpavement](https://twitter.com/sweetpavement) gave me the following analogy to help me understand the difference between ingress and egress with regards to defining them on 'rules' assigned to Security Groups.\n\n---\n\nMy understanding was helped here when I started thinking of ingress and egress as two separate doors to a building.\n\nIngress needs to be told where things are coming from, even if they're coming from the service, because they are entering the \"in\" door, which faces an open street. Specifying the source on these rules is like having an ID badge that lets you through that in door, instead of having to send you to the desk. Even if the request comes from \"inside the service\", to the perspective of the service it's coming in the in door and so explicitly needs to know whether it has a badge (i.e. is from the 'source' security group).\n\nEgress on the other hand is an out door. The service already knows who is \"inside\" the building, and it's just trying to send them out the door and to the correct place. Since it knows who is in the building (what traffic is coming from itself towards the \"out\" door) it only needs rules about where that door should lead, so it's not dumping VIPs into a dark alley where they'll be mugged.\n","tags":"#aws #security #sg #sgr #rule"},{"id":"98b5f2822e17ba97b58639ba91335527","title":"[Python Poetry] ","content":"[tool.poetry]\nname = \"2.7.15\"\nversion = \"0.1.0\"\ndescription = \"\"\nauthors = [\"Integralist \u003cmark.mcdx@gmail.com\u003e\"]\n\n[tool.poetry.dependencies]\npython = \"^2.7\"\nboto3 = \"^1.9\"\npytest = \"^4.4\"\nstructlog = \"^19.1\"\ntornado = \"^4.0\" # specified explicitly (others were latest versions) as latest didn't support Python 2.7\n\n[tool.poetry.dev-dependencies]\nflake8 = \"^3.7\"\nflake8-import-order = \"^0.18.1\"\nipython = \"^5.0\"\n\n[build-system]\nrequires = [\"poetry\u003e=0.12\"]\nbuild-backend = \"poetry.masonry.api\"\n# install\ncurl -sSL https://raw.githubusercontent.com/sdispater/poetry/master/get-poetry.py | python\n\n# reload .bash_profile and check poetry version\npoetry --version\n\n# update poetry to latest version\npoetry self:update\n\n# generate auto-complete for Homebrew installed version of bash\npoetry completions bash \u003e $(brew --prefix)/etc/bash_completion.d/poetry.bash-completion\n\n# install python version\npyenv install 2.7.15\n\n# check help for poetry init (which generates a `pyproject.toml`)\n# poetry doesn't allow installing packages via cli (they need to be specified in toml)\npoetry init -h\n\n# create pyproject.toml interactively (see below for generated `pyproject.toml`)\n# \n# notice [tool.poetry.dependencies] specifies the Python version used (this is required!).\npoetry init\n\n# install dependencies\npoetry install\n\n# add additional dependencies (use --dev for dev dependency)\npoetry add requests \u003c...\u003e\npoetry add --dev requests \u003c...\u003e\n\n# execute commands within the virtual environment (e.g. dev dependency ipython was installed)\npoetry run ipython\n\n# load virtual environment permanently for the current shell (e.g. now python version will be the expected environment, not the OS version)\npoetry shell\npython --version\n\n# here is a shortened Python3 example, as the above uses the OS default of Python2 for installing `2.7.15`\n# where as if you tried to set the Python version in the `pyproject.toml` to `^3.7` it would fail as that Python version wouldn't be available\n# it means whenever you want to setup a new Python3 environment, you'll need a compatible Python interpreter running first.\n# e.g. if you want to install 3.7.1 you'll need 3.7.3 running first to execute Poetry (this isn't necessary with Python2 as we already had 2.7 available by the OS)\npyenv install 3.7.3\npyenv local 3.7.3\npoetry add boto3 pytest structlog tornado\npoetry add --dev flake8 flake8-import-order mypy tox ipython\n\n","tags":"#python3 #poetry"},{"id":"57a5dc349137990a01d6947b359c80fc","title":"[Go Range List and Goroutine Async Processing with Errors] ","content":"package main\n\nimport (\n\t\"errors\"\n\t\"fmt\"\n\t\"sync\"\n)\n\nvar count400 int = 1\nvar count404 int = 1\nvar count410 int = 1\nvar count500 int = 1\n\nvar mapping map[int]interface{} = map[int]interface{}{\n\t400: count400,\n\t404: count404,\n\t410: count410,\n\t500: count500,\n}\n\nfunc getPage(statusCode int) (string, error) {\n\tfmt.Println(\"statusCode:\", statusCode, \"count:\", mapping[statusCode])\n\n\ttypeAssertCountToInt := mapping[statusCode].(int)\n\n\tif mapping[statusCode] == 1 {\n\t\tmapping[statusCode] = typeAssertCountToInt + 1\n\t\treturn \"\", errors.New(\"whoops 1\")\n\t} else if mapping[statusCode] == 2 {\n\t\tmapping[statusCode] = typeAssertCountToInt + 1\n\t\treturn \"\", errors.New(\"whoops 2\")\n\n\t} else {\n\t\treturn \"yay\", nil\n\t}\n}\n\nfunc preWarm(statusCode int, wg *sync.WaitGroup) string {\n\tpage, err := getPage(statusCode)\n\tif err != nil {\n\t\tfmt.Println(\"error from get page:\", statusCode , err)\n\t\treturn preWarm(statusCode, wg)\n\t}\n\n\tfmt.Println(\"SUCCESS (\", statusCode, \")\", page)\n\tfmt.Println(\"now cache page\", statusCode)\n\twg.Done()\n\treturn page\n\n}\n\nfunc main() {\n\tstatusCodes := []int{400, 404, 410, 500}\n\n\twg := \u0026sync.WaitGroup{}\n\twg.Add(len(statusCodes))\n\n\tfor _, statusCode := range statusCodes {\n\t\tgo preWarm(statusCode, wg)\n\t}\n\n\twg.Wait()\n}\n\n/* OUTPUT: I think https://play.golang.org/p/ckWSx7yJEJE sequentializes the goroutines?\n\n\nstatusCode: 500 count: 1\nerror from get page: 500 whoops 1\nstatusCode: 500 count: 2\nerror from get page: 500 whoops 2\nstatusCode: 500 count: 3\nSUCCESS ( 500 ) yay\nnow cache page 500\n\nstatusCode: 400 count: 1\nerror from get page: 400 whoops 1\nstatusCode: 400 count: 2\nerror from get page: 400 whoops 2\nstatusCode: 400 count: 3\nSUCCESS ( 400 ) yay\nnow cache page 400\n\nstatusCode: 404 count: 1\nerror from get page: 404 whoops 1\nstatusCode: 404 count: 2\nerror from get page: 404 whoops 2\nstatusCode: 404 count: 3\nSUCCESS ( 404 ) yay\nnow cache page 404\n\nstatusCode: 410 count: 1\nerror from get page: 410 whoops 1\nstatusCode: 410 count: 2\nerror from get page: 410 whoops 2\nstatusCode: 410 count: 3\nSUCCESS ( 410 ) yay\nnow cache page 410\n*/\n","tags":"#go #golang #concurrency #goroutines #thread #map"},{"id":"4b5c0cb47657e0a80d25ab6369174c72","title":"[Golang ReverseProxy] ","content":"package main\n\nimport (\n\t\"fmt\"\n\t\"log\"\n\t\"net/http\"\n\t\"net/http/httputil\"\n)\n\nfunc main() {\n\thttp.HandleFunc(\"/\", proxyFunc)\n\tlog.Fatal(http.ListenAndServe(\":8888\", nil))\n}\n\nfunc proxyFunc(w http.ResponseWriter, r *http.Request) {\n\tif r.URL.Scheme == \"\" {\n\t\tr.URL.Scheme = \"https\"\n\t}\n\tif r.URL.Host == \"\" {\n\t\tr.URL.Host = \"httpbin.org\"\n\t\tr.Host = \"httpbin.org\"\n\t}\n\tfmt.Printf(\"url: %+v\\n\", r.URL)\n\tproxy := httputil.NewSingleHostReverseProxy(r.URL)\n\tproxy.ServeHTTP(w, r)\n}\n// https://play.golang.org/p/pk1FOh563jJ\n\npackage main\n\nimport (\n\t\"errors\"\n\t\"fmt\"\n\t\"io/ioutil\"\n\t\"log\"\n\t\"net\"\n\t\"net/http\"\n\t\"net/http/httptest\"\n\t\"net/http/httputil\"\n\t\"net/url\"\n\t\"strings\"\n\t\"time\"\n)\n\n// copied from https://golang.org/src/net/http/httputil/reverseproxy.go?s=3330:3391#L98\nfunc singleJoiningSlash(a, b string) string {\n\taslash := strings.HasSuffix(a, \"/\")\n\tbslash := strings.HasPrefix(b, \"/\")\n\tswitch {\n\tcase aslash \u0026\u0026 bslash:\n\t\treturn a + b[1:]\n\tcase !aslash \u0026\u0026 !bslash:\n\t\treturn a + \"/\" + b\n\t}\n\treturn a + b\n}\n\nfunc main() {\n\tbackendServer := httptest.NewServer(http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tfmt.Fprintln(w, \"backend server handled the request!\")\n\t}))\n\tdefer backendServer.Close()\n\n\tbackendServerURL, err := url.Parse(backendServer.URL)\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\n\tproxy := \u0026httputil.ReverseProxy{\n\t\tDirector: func(r *http.Request) {\n\t\t\tr.URL.Scheme = backendServerURL.Scheme\n\t\t\tr.URL.Host = backendServerURL.Host\n\t\t\tr.URL.Path = singleJoiningSlash(backendServerURL.Path, r.URL.Path)\n\t\t},\n\t\tTransport: \u0026http.Transport{\n\t\t\tDial: (\u0026net.Dialer{\n\t\t\t\tTimeout: 10 * time.Second,\n\t\t\t}).Dial,\n\t\t},\n\t\tModifyResponse: func(r *http.Response) error {\n\t\t\t// return nil\n\t\t\t//\n\t\t\t// purposefully return an error so ErrorHandler gets called\n\t\t\treturn errors.New(\"uh-oh\")\n\t\t},\n\t\tErrorHandler: func(rw http.ResponseWriter, r *http.Request, err error) {\n\t\t\tfmt.Printf(\"error was: %+v (going to 302 redirect to google now)\", err)\n\t\t\thttp.Redirect(rw, r, \"http://www.google.com\", 302)\n\t\t},\n\t}\n\n\tfrontendServer := httptest.NewServer(proxy)\n\tdefer frontendServer.Close()\n\n\tresp, err := http.Get(frontendServer.URL)\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\n\tb, err := ioutil.ReadAll(resp.Body)\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\n\tfmt.Printf(\"%s\", b)\n}\n","tags":"#go #golang #reverseproxy"},{"id":"84d319238f95f28c680a789204fb57b4","title":"[How Vary HTTP header works] ","content":"## Vary Behaviour\n\nTo understand HTTP's [Vary](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Vary) behaviour we first must understand how the CDN works in the traditional sense of caching and looking up resources.\n\n\u003e Note: at the bottom of this page is a sequence diagram which visually illustrates how Vary works (if you prefer a more visual aid).\n\nThe CDN caches requests based on a given pair of Host and Path values. So when the CDN accepts a request, as an example, for the resource `https://www.buzzfeed.com/videos` the CDN will take the Host (e.g. `www.buzzfeed.com`) and the Path (e.g. `/videos`) and generate a hash of those values which will become the 'cache key'. Later when the CDN receives the same request from a different client it'll generate the same hash and lookup the resource in its cache using the hash as the key.\n\nDepending on the client, the origin server that generates response content (which will be cached in the CDN) may well want to serve _different_ content for different clients (e.g. serve a German language version of the page for German users vs an English language version for users from the UK or US).\n\nThe problem with serving different content for the same resource (e.g. imagine `www.example.com/foo` is able to return German _or_ English depending on the client) is that whoever makes the request _first_ will have that version of the content cached by the CDN.\n\nFor example if `www.example.com/foo` is able to return German _or_ English based on my web browser's built-in value for the HTTP request header [`Accept-Language`](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Accept-Language) (which for me would be set to `en-uk`), then imagine someone from Germany making a request for that uncached resource _first_ (whose browser users the value `de-de`).\n\nWhat will happen in that instance is that the German language version of the response content will be cached using `hash(Host + Path) = cache_key` and so when I make my request for the same resource, I'll end up getting the cached German version of the page (which I won't be able to read).\n\nThis is where the HTTP Vary response header comes in to help solve the problem. The origin server generating the content should be setup to send a Vary header with the value `Accept-Language`. The CDN will look at the Vary header's value and will subsequently cache the content using the same `hash(Host + Path) = cache_key` approach, but it'll add another 'key' (known as the 'vary key') to the object which will indicate the value that the browser provided.\n\nSo if we go back to the example of a German user making a request for the same resource as myself (and they make the request first), then the vary key assigned to the cached German version of the page will be `de-de`, and so although when I make my request the cache lookup key will be the same, I'll get a cache MISS (and the CDN will make a fresh request to the origin) because the value my browser is providing for `Accept-Language` is `en-uk` and that doesn't match the cached object's vary key value of `de-de`.\n\nNow when the origin sends back the English version of the page, the CDN will cache the content again using `hash(Host + Path) = cache_key` as the cache lookup key, but will set a _different_ 'vary key' value of `en-en`. So we now have _two_ objects in the cache for the same resource: one German and one English.\n\n\u003e Note: read [this article](https://www.fastly.com/blog/getting-most-out-vary-fastly) to understand how to make the most of the Vary response header.\ntitle Vary on Access-Control-Request-Method\n\nnote over Client: More details:\\nhttps://www.fastly.com/blog/getting-most-out-vary-fastly\n\n== request image without **Access-Control-Request-Method** header ==#pink\n\nClient-\u003eFastly: GET /thumbnailer-prod-us-east-1/video-api/assets/107836.jpg\\n**Host**: img.buzzfeed.com\n\nFastly--\u003eFastly: generate cache key...\\nhash(host + path) = 123\n\nnote over Fastly: CACHE MISS\n\nFastly-\u003eOrigin: proxy request\n\nOrigin-\u003eFastly: image content\n\nFastly--\u003eFastly: set `Vary: Access-Control-Request-Method`\\nVary is like a secondary cache key.\n\nFastly--\u003eFastly: cache response object (this inc. headers)\n\nnote over Fastly: **CACHE_KEY**: 123\\n**VARY_KEY**: \\\"\\\"\\n\\nnote: vary key is empty as no\\nAccess-Control-Request-Method was provided by the client\n\nFastly-\u003eClient: image content\n\n== same request again ==#pink\n\nClient-\u003eFastly: GET /thumbnailer-prod-us-east-1/video-api/assets/107836.jpg\\n**Host**: img.buzzfeed.com\n\nFastly--\u003eFastly: generate cache key...\\nhash(host + path) = 123\n\nnote over Fastly: CACHE HIT\\n\\nbecause there was an object matching...\\n\\n**CACHE_KEY**: 123\\n**VARY_KEY**: \\\"\\\"\n\nFastly-\u003eClient: image content\n\n== similar request but with **Access-Control-Request-Method** request header ==#lightgreen\n\nClient-\u003eFastly: GET /thumbnailer-prod-us-east-1/video-api/assets/107836.jpg\\n**Host**: img.buzzfeed.com\\n**Access-Control-Request-Method**: GET\n\nFastly--\u003eFastly: generate cache key...\\nhash(host + path) = 123\n\nnote over Fastly: CACHE MISS\\n\\nbecause there was no object matching...\\n\\n**CACHE_KEY**: 123\\n**VARY_KEY**: \\\"GET\\\"\n\nFastly-\u003eOrigin: proxy request\n\nnote over Origin: adds access control headers\n\nOrigin-\u003eFastly: image content\\n+ access-control-\u003c...\u003e headers\n\nFastly--\u003eFastly: set `Vary: Access-Control-Request-Method`\n\nFastly--\u003eFastly: cache response object (this inc. headers)\n\nnote over Fastly: **CACHE_KEY**: 123\\n**VARY_KEY**: \\\"GET\\\"\\n\\nnote: vary key is no longer empty, as the\\nAccess-Control-Request-Method was provided by the client\n\nFastly-\u003eClient: image content\n\n== same request again ==#lightgreen\n\nClient-\u003eFastly: GET /thumbnailer-prod-us-east-1/video-api/assets/107836.jpg\\n**Host**: img.buzzfeed.com\\n**Access-Control-Request-Method**: GET\n\nFastly--\u003eFastly: generate cache key...\\nhash(host + path) = 123\n\nnote over Fastly: CACHE HIT\\n\\nbecause there was an object matching...\\n\\n**CACHE_KEY**: 123\\n**VARY_KEY**: \\\"GET\\\"\n\nFastly-\u003eClient: image content\n","tags":"#fastly #vcl #cdn #vary"},{"id":"b904c5b29f050fd4936a7f04dba043ae","title":"[Fastly VCL Multiplication] ","content":"// generate nanoseconds from microseconds\n\ndeclare local var.start-nano INTEGER;\nset var.start-nano = std.strtol(time.start.usec, 10);\nset var.start-nano *= 1000;\nlog var.start-nano;\nset req.http.X-Start-in-Nanoseconds = var.start-nano;\n\n","tags":"#fastly #vcl #cdn #multiplication"},{"id":"3e835b07842cfab4dfd11d2047ffd7dd","title":"[Bash script with dynamic values for inputs using Expect] ","content":"A bash script that will expect input from the user (e.g. we are going to be the user in this example):\n\n```bash\n#!/bin/bash\n \necho \"Hello, who are you?\"\n \nread $REPLY\n \necho \"Can I ask you some questions?\"\n \nread $REPLY\n \necho \"What is your favorite topic?\"\n \nread $REPLY\n```\n\nWe can write our own script (e.g. `chmod +x ./answerbot`) to use `expect` to respond with pre-canned responses:\n\n```bash\n#!/usr/bin/expect -f\n \nset timeout -1 # disable the timeout\n \nspawn ./questions # start our script using spawn command\n \nexpect \"Hello, who are you?\\r\"\n \nsend -- \"Im Adam\\r\"\n \nexpect \"Can I ask you some questions?\\r\"\n \nsend -- \"Sure\\r\"\n \nexpect \"What is your favorite topic?\\r\"\n \nsend -- \"Technology\\r\"\n \nexpect eof\n```\n\n\u003e Note: discovered `autoexpect ./some_script.sh` which will look at `some_script.sh` and will dynamically generate an 'expect' script for you\n","tags":"#bash #shell #expect #dynamic #script #input #password"},{"id":"8a2e256c20708f6fcb0d1e3a5eda799a","title":"[Go Unit Table Test Example] ","content":"// Explanation of `tc := tc` https://gist.github.com/posener/92a55c4cd441fc5e5e85f27bca008721\n\nfor _, tc := range testCases {\n    tc := tc // necessary to avoid closure issues where last iteration data is used for all parallel tests\n    t.Run(tc.Name, func(t *testing.T) {\n        t.Parallel()\n      \n      \t// execute code and assert behaviour\n    })\n}\n// Split slices s into all substrings separated by sep and\n// returns a slice of the substrings between those separators.\nfunc Split(s, sep string) []string {\n    var result []string\n    i := strings.Index(s, sep)\n    for i \u003e -1 {\n        result = append(result, s[:i])\n        s = s[i+len(sep):]\n        i = strings.Index(s, sep)\n    }\n    return append(result, s)\n}\nfunc TestSplit(t *testing.T) {\n    tests := map[string]struct {\n        input string\n        sep   string\n        want  []string\n    }{\n        \"simple\":       {input: \"a/b/c\", sep: \"/\", want: []string{\"a\", \"b\", \"c\"}},\n        \"wrong sep\":    {input: \"a/b/c\", sep: \",\", want: []string{\"a/b/c\"}},\n        \"no sep\":       {input: \"abc\", sep: \"/\", want: []string{\"abc\"}},\n        \"trailing sep\": {input: \"a/b/c/\", sep: \"/\", want: []string{\"a\", \"b\", \"c\"}},\n    }\n\n    for name, tc := range tests {\n        t.Run(name, func(t *testing.T) {\n            got := Split(tc.input, tc.sep)\n            if !reflect.DeepEqual(tc.want, got) {\n                t.Fatalf(\"expected: %v, got: %v\", tc.want, got)\n            }\n        })\n    }\n}\n\n/*\nWhen comparing values using reflect.DeepEqual we could opt for %#v for more code structured output,\nbut that doesn't always work, so we can instead use https://github.com/google/go-cmp\n\nFor example:\n\nfunc main() {\n    type T struct {\n        I int\n    }\n    x := []*T{{1}, {2}, {3}}\n    y := []*T{{1}, {2}, {4}}\n    fmt.Println(cmp.Equal(x, y)) // false\n}\n*/\n% go test\n--- FAIL: TestSplit (0.00s)\n    --- FAIL: TestSplit/trailing_sep (0.00s)\n        split_test.go:25: expected: [a b c], got: [a b c ]\n% go test -run=.*/trailing -v\n=== RUN   TestSplit\n=== RUN   TestSplit/trailing_sep\n--- FAIL: TestSplit (0.00s)\n    --- FAIL: TestSplit/trailing_sep (0.00s)\n        split_test.go:25: expected: [a b c], got: [a b c ]\n","tags":"#go #golang #tests #testing #unittest #parallel #async #table #matrix"},{"id":"321700af51f3735766efe05756a88bec","title":"[Symlinking] ","content":"# ln -s \u003creal_path\u003e \u003cfake_path\u003e\n\n# for example, if we want ./lib to point to the real directory in ../../lib/go\nln -s ../../lib/go ./lib\n\n# IMPORTANT!\n#\n# Don't add trailing / to the fake_path \n# otherwise the shell will tell you fake_path doesn't exist.\n\n# REAL EXAMPLE\n#\n# I have the directory ~/Code/Go in which I've created a directory called \"go-flags\"\n# Any time someone goes to lookup ~/go/src/github.com/integralist/go-flags (such as when go code imports a package!)\n# Then I want them to be directed to ~/Code/Go/go-flags\ncd ~/go/src/github.com/integralist\nln -s ~/Code/Go/go-flags ./go-flags\nls -laGpFHh\n\n# go-flags@ -\u003e /Users/markmcdonnell/Code/\n","tags":"#terminal #command #symlink"},{"id":"00387caeb4d68bb0c0ef862c3de3459d","title":"[Lightline Status Line Tweaks] ","content":"\" Lightline Status Line Tweaks\n\"\n\" See documentation for details: https://github.com/itchyny/lightline.vim#advanced-configuration\n\"\n\" We use vim-fugitive to get git branch\nfunction! UpdateWordCount()\n  let lnum = 1\n  let n = 0\n  while lnum \u003c= line('$')\n    let n = n + len(split(getline(lnum)))\n    let lnum = lnum + 1\n  endwhile\n  let g:word_count = n . \" words\"\n  return \u0026filetype ==# 'markdown' ? g:word_count : ''\nendfunction\n\n\" notice we specify `gitbranch` and `wordcount` functions, and then define where they come from...\n\nlet g:lightline = {\n      \\ 'colorscheme': 'default',\n      \\ 'active': {\n      \\   'left': [ [ 'mode', 'paste' ],\n      \\             [ 'gitbranch', 'wordcount', 'readonly', 'filename', 'modified' ] ]\n      \\ },\n      \\ 'component_function': {\n      \\   'gitbranch': 'fugitive#head',\n      \\   'wordcount': 'UpdateWordCount',\n      \\ },\n      \\ }\n","tags":"#vim #lightline #powerline #statusline"},{"id":"a368e3e3d4693652b67ea6199cb42c2b","title":"Python: AWS Lambda sending S3 Fastly streamed logs to Datadog ","content":"'''\nThis script is a modified/simplified version of a Python2 script provided by\nDatadog for getting log data from S3 into their log aggregation pipeline.\n\nThe original script can be found here:\nhttps://github.com/DataDog/datadog-serverless-functions/tree/master/aws/logs_monitoring\n\nWe've removed any code that wasn't relevant for our requirements, and have also\nupdated it to work with Python3.\n'''\n\n#!/usr/bin/env python3\n\n# standard library modules\n\nimport gzip\nimport json\nimport logging\nimport os\nimport re\nimport socket\nimport ssl\nimport urllib\nfrom io import BufferedReader, BytesIO\n\n# third party modules\n\nimport boto3\n\n\n# configuration\n\nCLUSTER = os.environ['CLUSTER']\nDD_URL = os.getenv('DD_URL', default='lambda-intake.logs.datadoghq.com')\nDD_PORT = os.getenv('DD_PORT', default=10516)\nIP_REGEX = re.compile(r'\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}', re.I)\nSECRETS_MANAGER_ID = os.environ['SECRETS_MANAGER_ID']\n\n# service clients configuration\n\ns3 = boto3.client('s3')\nsecretsmanager = boto3.client('secretsmanager')\n\ntry:\n    aws_secret_response = secretsmanager.get_secret_value(SecretId=SECRETS_MANAGER_ID)\n    DD_API_KEY = aws_secret_response.get('SecretString')\nexcept Exception:\n    raise Exception('unable to acquire datadog secret api key')\n\n\nclass DatadogConnection(object):\n    def __init__(self, host, port, ddApiKey):\n        self.host = host\n        self.port = port\n        self.api_key = ddApiKey\n        self._sock = None\n\n    def _connect(self):\n        s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        s = ssl.wrap_socket(s)\n        s.connect((self.host, self.port))\n        return s\n\n    def safe_submit_log(self, log_entry, context):\n        try:\n            self.send_entry(log_entry, context)\n        except Exception:\n            # retry once\n            self._sock = self._connect()\n            self.send_entry(log_entry, context)\n        return self\n\n    def send_entry(self, log_entry, context):\n        if not isinstance(log_entry, dict):\n            raise Exception(f'log entry needs to be of type: dict: {log_entry}')\n\n        # ensure rig metadata is passed through\n        log_entry.update({'rig': {'cluster': CLUSTER, 'service': 'rig_cdn_logs_to_datadog'}})\n\n        # datadog expects log to be wrapped in a 'message' field\n        if 'message' not in log_entry:\n            log_entry = {'message': log_entry}\n\n        # documentation:\n        # https://docs.aws.amazon.com/lambda/latest/dg/python-context-object.html\n        tags = {\n            'functionName': context.function_name.lower(),\n            'functionVersion': context.function_version,\n            'memorysize': context.memory_limit_in_mb\n        }\n\n        log_entry.update({\n            'ddtags': ', '.join([f'{k}:{v}' for k, v in tags.items()]),\n            'ddsource': 'aws',\n            'source': 'fastly'\n        })\n\n        str_entry = json.dumps(log_entry)\n\n        if os.getenv('REDACT_IP'):\n            try:\n                str_entry = IP_REGEX.sub('xxx.xxx.xxx.xx', str_entry)\n            except Exception as e:\n                print(f'Unexpected exception while scrubbing logs: {str(e)} for event {str_entry}')\n\n        message = f'{self.api_key} {str_entry}\\n'.encode('UTF-8')\n\n        return self._sock.send(message)\n\n    def __enter__(self):\n        self._sock = self._connect()\n        return self\n\n    def __exit__(self, ex_type, ex_value, traceback):\n        if self._sock:\n            self._sock.close()\n        if ex_type is not None:\n            print('DatadogConnection exit: ', ex_type, ex_value, traceback)\n\n\ndef parse_cdn_logs(body, key):\n    data = body.read()\n\n    # all s3 objects from fastly should be streamed compressed as gzip, but\n    # it's a good safety precaution just in case to check the extension.\n    if key[-3:] == '.gz':\n        with gzip.GzipFile(fileobj=BytesIO(data)) as decompress_stream:\n            stream = BufferedReader(decompress_stream)\n            for raw_line in stream:\n                try:\n                    line = json.loads(raw_line)\n                except Exception:\n                    logging.error(f'error parsing JSON. raw_line: {raw_line}')\n\n                    # allow execution to continue, but the set fastlyState will\n                    # result in the log not being sent to Datadog.\n                    line = {'network': {'server': {'state': 'FORMAT_ERROR'}}}\n\n                # we check if the request's final state was uncached and, if so, we'll\n                # send those request log lines to Datadog.\n                #\n                # the reason we only send 'uncached' requests is because we need to\n                # avoid running over our current Datadog limits (which can be costly).\n                #\n                # all available states for fastly_info.state can be found here:\n                # https://support.fastly.com/hc/en-us/community/posts/360040168391-Useful-variables-to-log\n                if re.search('^(MISS|PASS)', line.get('network', {}).get('server', {}).get('state', '')):\n                    # any other coercion we want to do on the logline before sending\n                    yield line\n\n\ndef lambda_handler(event, context):\n    records = event.get('Records', [])\n\n    with DatadogConnection(DD_URL, DD_PORT, DD_API_KEY) as dd_conn:\n        for record in records:\n            s3_event = record.get('s3', {})\n\n            if not s3_event:\n                return\n\n            s3_bucket = s3_event['bucket']['name']\n            s3_object = urllib.parse.unquote(s3_event['object']['key'])\n\n            response = s3.get_object(Bucket=s3_bucket, Key=s3_object)\n            try:\n                body = response['Body']\n            except Exception as e:\n                raise(f'Unexpected exception while parsing cdn_logs: {str(e)}')\n\n            cdn_log_parser = parse_cdn_logs(body, s3_object)\n            for log_line in cdn_log_parser:\n                dd_conn.safe_submit_log(log_line, context)\n{\n  \"Records\": [\n    {\n      \"eventVersion\": \"2.1\",\n      \"eventSource\": \"aws:s3\",\n      \"awsRegion\": \"us-east-1\",\n      \"eventTime\": \"2019-04-08T13:00:00.964Z\",\n      \"eventName\": \"ObjectCreated:CompleteMultipartUpload\",\n      \"userIdentity\": {\n        \"principalId\": \"AWS:123\"\n      },\n      \"requestParameters\": {\n        \"sourceIPAddress\": \"199.27.72.31\"\n      },\n      \"responseElements\": {\n        \"x-amz-request-id\": \"456\",\n        \"x-amz-id-2\": \"789\"\n      },\n      \"s3\": {\n        \"s3SchemaVersion\": \"1.0\",\n        \"configurationId\": \"tf-s3-lambda-20190408124645838400000001\",\n        \"bucket\": {\n          \"name\": \"\u003cyour_bucket\u003e\",\n          \"ownerIdentity\": {\n            \"principalId\": \"123\"\n          },\n          \"arn\": \"arn:aws:s3:::\u003cyour_bucket\u003e\"\n        },\n        \"object\": {\n          \"key\": \"fastly/json/\u003cyour_domain\u003e/dt=2019-04-16/2019-04-16T09:45:00.000-_9Hq9QX5I8nj3FZQPsPH.log.gz\",\n          \"size\": 8921,\n          \"eTag\": \"456\",\n          \"sequencer\": \"789\"\n        }\n      }\n    }\n  ]\n}\n","tags":"#aws #python #logs"},{"id":"5106e8af59c780826faf5ad04a116184","title":"[Backup Private GPG Key] ","content":"```bash\ngpg --list-secret-keys\ngpg --export-secret-keys \u003ckey_id\u003e \u003e my-private-key.asc\ngpg --import my-private-key.asc\n```\n\n\u003e Also `--armor` option outputs ASCII: `gpg --export-secret-keys --armor \u003ckey_id\u003e`\n","tags":"#gpg #backup #private #key"},{"id":"769d16edbc7791ab4e6a61983162b964","title":"[Fastly Create Users + API tokens for Auditing purposes] ","content":"Create a new user (using an API token that has 'superuser' permissions):\n\n\n```bash\ncurl -v -H \"Fastly-Key: $FASTLY_API_TOKEN_SUPERUSER\" -X POST -d \"name=Foo Bar\u0026login=foo.bar%40example.com\" https://api.fastly.com/user\n```\n\nResponse (notice no 2FA, no password, no force password reset etc):\n\n```json\n{\n  \"id\":\"001\",\n  \"created_at\":\"2019-04-16T13:32:41Z\",\n  \"updated_at\":\"2019-04-16T13:32:41Z\",\n  \"name\":\"Foo Bar\",\n  \"customer_id\":\"123\",\n  \"require_new_password\":false,\n  \"role\":\"user\",\n  \"login\":\"foo.bar@example.com\",\n  \"deleted_at\":null,\n  \"locked\":false,\n  \"two_factor_auth_enabled\":false,\n  \"limit_services\":false,\n  \"email_hash\":\"456\",\n  \"two_factor_setup_required\":true\n}\n```\n\nSet our own initial password for the user:\n\n```bash\ncurl -v -H \"Fastly-Key: $FASTLY_API_TOKEN_SUPERUSER\" -X POST -d \"new_password=foobar\" https://api.fastly.com/user/\u003cid\u003e/password\n```\n\nResponse (notice `require_new_password` is set to `true` now we've set a password for the user):\n\n```json\n{\n  \"id\":\"001\",\n  \"created_at\":\"2019-04-16T13:32:41Z\",\n  \"updated_at\":\"2019-04-16T13:51:38Z\",\n  \"name\":\"Foo Bar\",\n  \"customer_id\":\"123\",\n  \"require_new_password\":true,\n  \"role\":\"user\",\n  \"login\":\"foo.bar@example.com\",\n  \"deleted_at\":null,\n  \"locked\":false,\n  \"two_factor_auth_enabled\":false,\n  \"limit_services\":false,\n  \"email_hash\":\"456\",\n  \"two_factor_setup_required\":true\n}\n```\n\nWhen signing in with this user, they are forced to setup 2FA. The concern at this point, is that this user is able to log into the Fastly UI and start creating both READ and WRITE API tokens for _any service_. Meaning, we should probably create the user but never set a password and see if we can still create API tokens for that user's account and have them be usable to query the Fastly API.\n\nIn order to create a new token for a user account, we first need to call a `/sudo` endpoint:\n\n```bash\n# don't forget to escape any special characters with a backslash \\\nexport ADMIN_PASS=123456\n\ncurl -v -H \"Fastly-Key: $FASTLY_API_TOKEN_SUPERUSER\" -H \"Fastly-OTP: 123456\" -X POST -d \"username=admin@example.com\u0026password=$ADMIN_PASS\" https://api.fastly.com/sudo\n```\n\nYou can then request the token creation:\n\n```bash\ncurl -H \"Fastly-Key: $FASTLY_API_TOKEN_SUPERUSER\" -X POST -d \"username=\u003cuser\u003e\u0026password=\u003cpass\u003e\u0026services[]=\u003cservice\u003e\" https://api.fastly.com/tokens\n```\n\nResponse:\n\n```json\n{\n  \"id\":\"000\",\n  \"name\":\"Fastly API Token\",\n  \"user_id\":\"123\",\n  \"service_id\":\"456\",\n  \"expires_at\":null,\n  \"created_at\":\"2019-04-16T15:10:16Z\",\n  \"updated_at\":\"2019-04-16T15:10:16Z\",\n  \"scope\":\"global\",\n  \"services\":[\"\u003cservice_id\u003e\"],\n  \"access_token\":\"\u003ca_new_token\u003e\"\n}\n```\n\n\u003e Note: this token is generated for the superuser, and unfortunately not the specified username in the post formdata (which is what we wanted). Doesn't matter what creds you provide at this point. As you used the superuser account for `/sudo` it means the token will be setup for that user. This means as don't _know_ anything about our user's or their creds (or OTP codes), we won't be able to create API tokens on their behalf.\n\u003e Note: the following was a brief 'step-by-step' provided by Fastly.\n\nFirst, we create the user: \n\n```\nhttps://docs.fastly.com/api/account#user_00b606002596bac1c652614de98bd260\n``` \n\nBecause we can’t create the user with an specific password, we manually update the recently created user’s password with this API call:\n\n```\nPOST /user/\u003cuser-id\u003e/password\nAuthentication: Using the API key of a superuser. Send that API key using the Fastly-Key header.\nContent-Type: application/x-www-form-urlencoded\nPayload: The new password should be sent as formdata within the field new_password\n```\n\nThen, knowing the user and password, we can create a personal token: \n\n```\nhttps://docs.fastly.com/api/auth#tokens_db4655a45a0107448eb0676577446e40\n```\n\nI’d also finish by requesting a password reset for the user, so they can set whatever they want: \n\n```\nhttps://docs.fastly.com/api/account#user_cee4dbb44c07d9ed078424cbbd353e1a\n```\n","tags":"#fastly #cli #auth #api"},{"id":"67b3cff501cbeef421113c39bd86b5c5","title":"[Vim Highlight Current Line] ","content":"\" Note: this can be quite noisy, where as just looking at line number highlighted can be sufficient enough\n\nfun! SetCursorLine()\n  \" http://misc.flogisoft.com/_media/bash/colors_format/256_colors_bg.png\n  highlight CursorLine cterm=NONE ctermbg=214 ctermfg=darkred\nendfun\n\" autocmd VimEnter * call SetCursorLine() \" We have to use a last minute event (VimEnter)\n                                          \" Otherwise the colourscheme overrides our CursorLine\n","tags":"#vim #highlight #line"},{"id":"4eb10817e06a69bd511f14d2370e2d45","title":"[Vim open current line in GitHub UI] ","content":"`~/.gitconfig`\n\n```\nurl =! bash -c 'git config --get remote.origin.url | sed -E \"s/.+:\\\\(.+\\\\)\\\\.git$/https:\\\\\\\\/\\\\\\\\/github\\\\\\\\.com\\\\\\\\/\\\\\\\\1/g\"'\n```\n\n`~/.vimrc`\n\n```vim\n\" Use git alias inside ~/.gitconfig to open current file line in GitHub\nnnoremap \u003cleader\u003ef :!echo `git url`/blob/`git rev-parse --abbrev-ref HEAD`/%\\#L\u003cC-R\u003e=line('.')\u003cCR\u003e \\| xargs open\u003cCR\u003e\u003cCR\u003e\n```\n","tags":"#github #git #vim"},{"id":"edda7d0af6a26f2413433003a10fceb5","title":"[Generate SSH Key] ","content":"alias sshkey=\"cd ~/.ssh \u0026\u0026 ssh-keygen -t rsa -b 4096 -C 'your.email@domain.com'\"\n","tags":"#generate #ssh #key"},{"id":"024582e886a039a022cc7359dfc6f8e3","title":"Generate UUID (Universally Unique Identifier) ","content":"# uuidgen is installed on macOS by default\nalias uid='echo $(uuidgen)'\n","tags":"#uuid"},{"id":"27d19b9f1fd50699264e40bc1be89247","title":"[Lazy Load NVM] ","content":"# lazyload nvm\n# all props goes to http://broken-by.me/lazy-load-nvm/\n# grabbed from reddit @ https://www.reddit.com/r/node/comments/4tg5jg/lazy_load_nvm_for_faster_shell_start/\n#\n# NOTE: this will cause some confusing behaviour when opening fresh terminal prompt\n#       in that a previously installed command (e.g. npm install -g dockly) won't exist\n#       e.g. executing the `dockly` command will fail unless you execute `nvm` first\n#       this is because we're lazy loading nvm and so it won't auto-load its default node version\n\nlazynvm() {\n  unset -f nvm node npm\n  export NVM_DIR=~/.nvm\n  # shellcheck source=/dev/null\n  [ -s \"$NVM_DIR/nvm.sh\" ] \u0026\u0026 . \"$NVM_DIR/nvm.sh\"  # This loads nvm\n}\n\nnvm() {\n  lazynvm\n  nvm \"$@\"\n}\n\nnode() {\n  lazynvm\n  node \"$@\"\n}\n\nnpm() {\n  lazynvm\n  npm \"$@\"\n}\n\n# UPDATE:\n#\n# the following was added dynamically to .bashrc but I move it to .localrc instead\n# note: manually added --no-use to prevent it loading nvm on each shell load\n#       so to load npm/node, execute: nvm use node\n#\nexport NVM_DIR=\"$HOME/.nvm\"\n[ -s \"$NVM_DIR/nvm.sh\" ] \u0026\u0026 \\. \"$NVM_DIR/nvm.sh\" --no-use\n[ -s \"$NVM_DIR/bash_completion\" ] \u0026\u0026 \\. \"$NVM_DIR/bash_completion\"\n","tags":"#lazy #load #nvm #node"},{"id":"df829fd78bda3d593fa00e67e10f8436","title":"[Simple Vim TODO list] ","content":"alias did=\"vim +'normal Go' +'r!date' ~/did.txt\"\n\n# executing `did` in a shell will open the file `~/did.txt` in vim,\n# while prefixing the current line with a date/time.\n#\n# Example...\n#\n# Tue Jul 31 17:31:35 BST 2018\n# - i manually typed this line\n# - and this one\n# - i use it to demonstrate multiple things I did\n#\n# Wed Aug  1 11:30:00 BST 2018\n# I did only one thing today\n","tags":"#vim #gtd #todo"},{"id":"1d3030ef6ef539de9d873d19b98cc38f","title":"[Python -m cli flag] ","content":"Install package using pip that's associated with the currently running Python interpreter:\n\n```python\npython3 -m pip install -e rig\n```\n\nCreate simple virtual environments for the currently running Python interpreter using [`venv`](https://docs.python.org/3/library/venv.html):\n\n```python\n# create the virtual environment\npython3 -m venv /path/to/new/virtual/environment\n\n# activate the virtual environment\nsource /path/to/new/virtual/environment/bin/activate\n```\n\nFor a great breakdown of virtual environments and how they work, read: [https://spurin.com/2019/03/12/Python-Virtual-Environments/](https://spurin.com/2019/03/12/Python-Virtual-Environments/). In short, the `activate` command simply prefixes `/path/to/new/virtual/environment/bin` to your `$PATH` environment variable so it'll look there for `pip` and for installing/importing modules.\n\n\u003e Note: subset was built into Python 3.3+ as `venv` module, otherwise use [virtualenv.pypa.io](https://virtualenv.pypa.io/en/stable/) for more features.\n\nUse existing Python packages with `-m` to do processing, like JSON formatting:\n\n```python\ncurl -sL http://j.mp/1IuxaLD | python -m json.tool\n```\n\n\u003e See also: [http://pythonwise.blogspot.com/2015/01/python-m.html](http://pythonwise.blogspot.com/2015/01/python-m.html)\n","tags":"#python #cli #flag"},{"id":"63d0318b9f9b38ccd1afea947a76a9a2","title":"[Docker Cleanup Remove Prune] ","content":"# the following command is a 'scorched earth' approach and could make the other commands redundant\ndocker system prune -a\n\n# stop and Remove all containers\nalias drf='docker stop $(docker ps -a -q) \u0026\u0026 docker rm $(docker ps -a -q)'\n\n# remove all images\ndri() { docker rmi -f $(docker images -q); }\n\n# remove all \u003cnone\u003e images\ndrn() { docker rmi -f $(docker images --filter \"dangling=true\" -q); }\n","tags":"#docker #remove #cleanup #prune"},{"id":"b0f4c62d38761babfd8616694a852024","title":"[Bash Print All Alias'] ","content":"bold=$(tput bold)\nnormal=$(tput sgr0)\n\n# list out all custom defined alias'\nalias list='cat ~/.bashrc | grep \"^alias\" | gsed -En \"s/alias (\\w+)=(.+)/${bold}\\1\\n  ${normal}\\2\\n/p\"'\n","tags":"#bash #alias #list"},{"id":"4500e029ee24d160da944039274f7003","title":"[Python VirtualEnv Dockerized] ","content":"Python 3 has two ways of handling Virtual Environments:\n\n1. python3 -m venv /path/to/new/virtual/environment (builtin module)\n2. `virtualenv` (which `venv` module is a subset of)\n\nThe downside of option 1 is that it only works for the version of the Python 3 interpreter that's running. For example, if your Python 3 version is `3.6` then you can't run a virtual environment of packages using Python 3.7\n\nAt least with `virtualenv` you have the option of specifying the Python interpreter you want to use: `virtualenv --python=/opt/python-3.3/bin/python`.\n\n\u003e [Source Reference](https://pythonspeed.com/articles/activate-virtualenv-dockerfile/)\n\nOnce the virtual environment is created you'll need to activate it: `source \u003cpath/to/venv\u003e/bin/activate`\n\nIt’s easy to think of `activate` as some mysterious magic, a pentacle drawn in blood to keep Python safely trapped. But it’s just software, and fairly simple software at that. [The virtualenv documentation](https://virtualenv.readthedocs.io/en/latest/userguide/#activate-script) will even tell you that `activate` is \"purely a convenience.\"\n\nIf you go and read the code for `activate`, it does a number of things:\n\n- It figures out what shell you’re running.\n- It adds a `deactivate` function to your shell, and messes around with `pydoc`.\n- It changes the shell prompt to include the virtualenv name.\n- It unsets the `PYTHONHOME` environment variable, if someone happened to set it.\n- It sets two environment variables: `VIRTUAL_ENV` and `PATH`.\n\nThe first four are basically irrelevant to Docker usage, so that just leaves the last item. The most important part is setting `PATH: PATH` is a list of directories which are searched for commands to run. `activate` simply adds the virtualenv’s `bin/` directory to the start of the list.\n\nWe can replace `activate` by setting the appropriate environment variables: Docker’s `ENV` command applies both subsequent `RUN`s as well as to the `CMD`.\n\nThe result is the following Dockerfile:\n\n```Dockerfile\nFROM ubuntu:18.04\nRUN apt-get update \u0026\u0026 apt-get install \\\n  -y --no-install-recommends python3 python3-virtualenv\n\nENV VIRTUAL_ENV=/opt/venv\nRUN python3 -m virtualenv --python=/usr/bin/python3 $VIRTUAL_ENV\nENV PATH=\"$VIRTUAL_ENV/bin:$PATH\"\n\n# Install dependencies:\nCOPY requirements.txt .\nRUN pip install -r requirements.txt\n\n# Run the application:\nCOPY myapp.py .\nCMD [\"python\", \"myapp.py\"]\n```\n","tags":"#python #virtualenv #docker #venv"},{"id":"35c2190befc0229771367397be20c98e","title":"Fastly JSON Logging ","content":"\u003e note: variables such as beresp are only available in vcl_fetch\n\n```vcl\nset var.json = \"{\" + \n  \"%22host%22: %22\" + req.http.host + \"%22,\" + \n  \"%22backend%22: %22\" + req.backend + \"%22,\" + \n  \"%22contentType%22: %22\" + beresp.http.Content-Type + \"%22,\" + \n  \"%22cacheType%22: %22\" + fastly_info.state + \"%22,\" + \n  \"%22pageSize%22: %22\" + beresp.http.Content-Length + \"%22,\" + \n  \"%22bot%22: %22\" + req.http.User-Agent + \"%22\" + \n\"}\";\n```\n// this is what's possible in vcl_error but might not be possible in our own subroutines...\nsynthetic {\"{\n  \"geo\": {\n    \"gmt_offset\":\"} json.escape(client.geo.gmt_offset) {\",\n    \"city\": \"\"} json.escape(client.geo.city) {\"\",\n    \"country_name\": \"\"} json.escape(client.geo.country_name) {\"\",\n    \"ip_override\": \"\"} json.escape(client.geo.ip_override) {\"\"\n  },\n  \"as\": {\n    \"name\": \"\"} json.escape(client.as.name) {\"\"\n  }\n}\"};\n\u003e Note: original log format that Fastly translates into VCL:\n\u003e `%h [%{%Y-%m-%d %H:%M:%S}t.%{msec_frac}t] \"%r\" %\u003es %B %{tls.client.protocol}V %{fastly_info.state}V  ` \n\n## Simple\n\n```vcl\n# double quoted strings support percent escapes\n# https://docs.fastly.com/vcl/types/string/\n\ndeclare local var.json STRING;\n\nset var.json = \"{\" + \n  \"%22foo%22: %22bar%22,\" + \n  \"%22boop%22: %22beep%22,\" + \n  \"%22city%22: %22\"+ json.escape(client.geo.city.utf8) + \"%22\" + \n\"}\";\n\nset req.http.X-JSON = var.json;\n\n# output:\n# x-json: {\"foo\": \"bar\",\"boop\": \"beep\",\"city\": \"bristol\"}\n```\n\n\u003e Note: `%22` is the HTML encoding for `\"` (see [docs](https://docs.fastly.com/vcl/functions/json-escape/)).\n\nTrying without encoding works, but is complicated to get working across multiple lines:\n\n```vcl\n# what it would be nice to use...\n{\n  \"timestamp\":\"%{begin:%Y-%m-%dT%H:%M:%S}t\",\n  \"time_elapsed\":%{time.elapsed.usec}V,\n  \"is_tls\":%{if(req.is_ssl, \"true\", \"false\")}V,\n  \"client_ip\":\"%{req.http.Fastly-Client-IP}V\",\n  \"geo_city\":\"%{client.geo.city}V\",\n  \"geo_country_code\":\"%{client.geo.country_code}V\",\n  \"request\":\"%{req.method}V\",\n  \"host\":\"%{req.http.Fastly-Orig-Host}V\",\n  \"url\":\"%{json.escape(req.url)}V\",\n  \"request_referer\":\"%{json.escape(req.http.Referer)}V\",\n  \"request_user_agent\":\"%{json.escape(req.http.User-Agent)}V\",\n  \"request_accept_language\":\"%{json.escape(req.http.Accept-Language)}V\",\n  \"request_accept_charset\":\"%{json.escape(req.http.Accept-Charset)}V\",\n  \"cache_status\":\"%{regsub(fastly_info.state, \"^(HIT-(SYNTH)|(HITPASS|HIT|MISS|PASS|ERROR|PIPE)).*\", \"\\\\2\\\\3\") }V\"\n}\n\n# what we end up using...\n# this is done via the long string format {\"...\"}\n#\n# simple example:\n# {\"{  \"foo\":\"\"} req.http.X-Foo {\"\",  \"bar\":\"} req.http.X-Bar {\" }\"};\n#\n# which gets fugly quick, when made longer, as in real-world examples (also has to be all on one line!)\n#\n# https://docs.fastly.com/vcl/types/string/\nset req.http.X-JSON2 = {\"{   \"timestamp\":\"\"} strftime({\"%Y-%m-%dT%H:%M:%S\"}, time.start) {\"\",   \"time_elapsed\":\"} time.elapsed.usec {\",   \"is_tls\":\"} if(req.is_ssl, \"true\", \"false\") {\",   \"client_ip\":\"\"} req.http.Fastly-Client-IP {\"\",   \"geo_city\":\"\"} client.geo.city {\"\",   \"geo_country_code\":\"\"} client.geo.country_code {\"\",   \"request\":\"\"} req.method {\"\",   \"host\":\"\"} req.http.Fastly-Orig-Host {\"\",   \"url\":\"\"} json.escape(req.url) {\"\",   \"request_referer\":\"\"} json.escape(req.http.Referer) {\"\",   \"request_user_agent\":\"\"} json.escape(req.http.User-Agent) {\"\",   \"request_accept_language\":\"\"} json.escape(req.http.Accept-Language) {\"\",   \"request_accept_charset\":\"\"} json.escape(req.http.Accept-Charset) {\"\",   \"cache_status\":\"\"} regsub(fastly_info.state, \"^(HIT-(SYNTH)|(HITPASS|HIT|MISS|PASS|ERROR|PIPE)).*\", \"\\2\\3\")  {\"\" }\"};\n```\n\n\u003e Note: both approaches will require [`blank` to be set](https://docs.fastly.com/guides/streaming-logs/changing-log-line-formats#available-message-formats)\n\u003e\n\u003e ```blank means no prefix. Just your log message. Useful when writing to JSON and CSV files.```\n\n## Advanced (and performance costly)\n\n[https://github.com/fastly/vcl-json-generate](https://github.com/fastly/vcl-json-generate)\n","tags":"#fastly #cdn #logs #json"},{"id":"e73a5f698058493e25eb301c4bcbf972","title":"[AWS Athena SQL] ","content":"\u003e Note: [reference article](https://medium.com/@samparkinson_/query-fastly-logs-using-amazon-athena-f262bc58d27c)\n\nBasic query example:\n\n```sql\nSELECT status_code,\n         COUNT(status_code) AS requests\nFROM fastly_logs.example_com\nGROUP BY  requests\nORDER BY  requests DESC\n```\n\nCreate a table:\n\n```sql\nCREATE EXTERNAL TABLE `www_buzzfeed_com`(\n  `client_ip` string COMMENT '', \n  `timestamp` timestamp COMMENT '', \n  `method` string COMMENT '', \n  `path` string COMMENT '', \n  `http_protocol` string COMMENT '', \n  `status_code` smallint COMMENT '', \n  `response_size` int COMMENT '', \n  `tls_version` string COMMENT '', \n  `cache_status` string COMMENT '')\nPARTITIONED BY ( \n  `dt` string)\nROW FORMAT SERDE \n  'org.apache.hadoop.hive.serde2.RegexSerDe' \nWITH SERDEPROPERTIES ( \n  'input.regex'='(\\\\S+) \\\\[(.+)\\\\] \\\\\\\"(\\\\S+) (\\\\S+) (\\\\S+)\\\\\\\" (\\\\d{3}) (\\\\d+) (\\\\S+) (\\\\S+)$') \nSTORED AS INPUTFORMAT \n  'org.apache.hadoop.mapred.TextInputFormat' \nOUTPUTFORMAT \n  'org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat'\nLOCATION\n  's3://bf-logs-archive/Fastly/www.buzzfeed.com'\nTBLPROPERTIES (\n  'has_encrypted_data'='false', \n  'transient_lastDdlTime'='1512424557')\n```\n\n\u003e Note: the `input.regex` matches the following log format from Fastly:\n\u003e\n\u003e ```12.345.678.90 [2019-04-01 00:00:01.544] \"GET /foo/bar HTTP/1.1\" 200 1212 TLSv1.2 HIT-CLUSTER```\n\u003e\n\u003e ```%h [%{%Y-%m-%d %H:%M:%S}t.%{msec_frac}t] \"%r\" %\u003es %B %{tls.client.protocol}V %{fastly_info.state}V```\n\nRebuild indices (e.g. Athena doesn't know about _new_ content otherwise):\n\n\n```sql\nMSCK REPAIR TABLE www_buzzfeed_com\n```\n\nSelect requests based on a specific timestamp value:\n\n```sql\nSELECT * FROM www_buzzfeed_com WHERE timestamp = timestamp '2017-12-04 21:50:01.646' AND cache_status LIKE 'HIT%'\n```\n\nSelect requests based on datetime partition field:\n\n```sql\nSELECT * FROM www_buzzfeed_com WHERE dt='2019-04-02'\n```\n\nSelect requests based on a specific date range:\n\n```sql\nSELECT * FROM www_buzzfeed_com WHERE dt\u003e='2019-04-02' AND dt\u003c='2019-04-03' AND cache_status LIKE 'MISS%'\n```\n\nFaster than LIKE statement:\n\n```sql\nSELECT * FROM www_buzzfeed_com WHERE dt\u003e='2019-04-02' AND dt\u003c='2019-04-03' AND regexp_like(cache_status, '^(MISS|PASS)')\n```\n\nOrder data so the most recent appears at the top and only the most recent 10 records:\n\n```sql\nSELECT * FROM www_buzzfeed_com WHERE dt='2019-04-02' ORDER BY timestamp DESC limit 10\n```\n\n\u003e Note: see peformance tricks [here](https://aws.amazon.com/blogs/big-data/top-10-performance-tuning-tips-for-amazon-athena/)\n\nTo drop a table:\n\n```sql\nDROP TABLE `www_stage_buzzfeed_com_json`;\n```\n\n## JSON Format\n\n[https://docs.aws.amazon.com/athena/latest/ug/querying-JSON.html](https://docs.aws.amazon.com/athena/latest/ug/querying-JSON.html)\n\n```sql\nCREATE EXTERNAL TABLE `www_stage_buzzfeed_com_json`(\n  `backend` string,\n  `bodySize` int,\n  `contentType` string,\n  `fastlyState` string,\n  `host` string,\n  `ip` string,\n  `method` string,\n  `protocol` string,\n  `statusCode` smallint,\n  `timestamp` timestamp,\n  `tlsVersion` string,\n  `url` string,\n  `userAgent` string)\nPARTITIONED BY ( \n  `dt` string)\nROW FORMAT SERDE \n  'org.openx.data.jsonserde.JsonSerDe'\nWITH SERDEPROPERTIES (\n  'ignore.malformed.json' = 'true')\nLOCATION\n  's3://bf-logs-archive/Fastly/json/www-stage.buzzfeed.com'\nTBLPROPERTIES (\n  'has_encrypted_data'='false')\n```\n\nNotice that camelCase fields are lowercased (e.g. fastlyState becomes fastlystate):\n\n```sql\nSELECT url, statuscode, fastlystate FROM www_stage_buzzfeed_com_json WHERE dt='2019-04-04' AND backend = '' ORDER BY timestamp DESC LIMIT 10\n```\n\nTo format output from command line:\n\n```bash\ncat ~/Downloads/2019-04-04T11_55_00.000-EKBlIHaTVrnIxJ7EPna7.log | tail -n 1 | python -m json.tool\n\n{\n    \"backend\": \"\",\n    \"bodySize\": \"240\",\n    \"contentType\": \"application/json\",\n    \"fastlyState\": \"HIT\",\n    \"host\": \"www.buzzfeed.com\",\n    \"ip\": \"70.50.102.167\",\n    \"method\": \"GET\",\n    \"protocol\": \"HTTP/1.1\",\n    \"statusCode\": \"200\",\n    \"timestamp\": \"2019-04-04 11:59:59.650\",\n    \"tlsVersion\": \"TLSv1.2\",\n    \"url\": \"/manifest.json\",\n    \"userAgent\": \"Mozilla/5.0 (Linux; Android 9; SAMSUNG SM-G960W Build/PPR1.180610.011) AppleWebKit/537.36 (KHTML, like Gecko) SamsungBrowser/9.2 Chrome/67.0.3396.87 Mobile Safari/537.36\"\n}\n```\n\n## Caution!\n\nIf you set a field to have a field of type `int` and it's sent as an empty string \"\" by default by the provider of the data, then expect Hive DB to complain loudly when trying to search for data.\n","tags":"#aws #athena #s3 #sql"},{"id":"8d0e9896b31a7145dd84f3093974404c","title":"[Fastly Purge with Python] ","content":"#!/usr/bin/env python\n\n# standard library modules\n\nimport argparse\nimport re\nimport sys\nfrom urllib.parse import urlparse\n\n# external modules\n\nfrom bf_rig import settings\n\n# third party modules\n\nfrom tornado.httpclient import AsyncHTTPClient\nfrom tornado.ioloop import IOLoop\n\nAsyncHTTPClient.configure(None, defaults=dict(user_agent='BuzzFeedSiteAdminUI'))\nhttp_client = AsyncHTTPClient()\n\n# mapping of subdomain to fastly key\nenvs = {'stage': 'www_stage',\n        'www-stage': 'www_stage',\n        'www': 'www_prod'}\n\n\ndef stage_creds():\n    username = settings.get('stage_username')\n    password = settings.get('stage_password')\n    return f'{username}:{password}@'\n\n\ndef headers(subdomain):\n    service = envs[subdomain]\n    fastly_key = settings.get(f'fastly_api_{service}_token')\n\n    return {'Fastly-Key': fastly_key,\n            'Content-Type': 'application/x-www-form-urlencoded'}\n\n\nasync def purge_url(url_to_purge):\n    '''Purge given URL for the buzzfeed.com host.'''\n\n    print_url = url_to_purge  # we might mutate the original value with stage creds\n    parsed_url = urlparse(url_to_purge)\n    match = re.match('^([^.]+).buzzfeed.com', parsed_url.netloc, flags=re.IGNORECASE)\n    subdomain = match.group(1)\n\n    if not subdomain:\n        subdomain = 'stage'\n\n    if re.search('^(?:www-)?stage', subdomain):\n        # reconstruct url to include stage credentials\n        url_to_purge = f'{parsed_url.scheme}://{stage_creds()}{parsed_url.netloc}{parsed_url.path}'\n\n    print(f'url to purge: {print_url}')\n\n    response = await http_client.fetch(url_to_purge,\n                                       method='PURGE',\n                                       headers=headers(subdomain),\n                                       allow_nonstandard_methods=True,\n                                       raise_error=False)\n\n    body_decoded = response.body.decode('utf-8')\n\n    if response.code != 200:\n        print(f'something went wrong: ({response.code}) {body_decoded}')\n        return\n\n    print(body_decoded)\n\n\nparser = argparse.ArgumentParser(description='Purge CDN')\nparser.add_argument('-u', '--url', help='buzzfeed.com url to be purged', type=str)\nargs = parser.parse_args()\n\nif not args.url:\n    print('-u, --url flag missing. see -h, --help for more information.')\n    sys.exit(1)\n\nio_loop = IOLoop.current()\nio_loop.run_sync(lambda: purge_url(args.url))\n","tags":"#python #tornado #cli #purge #cache #fastly #cdn"},{"id":"5e2cfb0b3f7dcd9ff0eda4ee974e6fb1","title":"[Python Security Hashing] ","content":"# see also: https://docs.python.org/3.7/library/crypto.html\n\nfrom hashlib import blake2b\n\nh = blake2b(key=b'pseudorandom key', digest_size=16)\nh.update(b'message data')\nh.hexdigest()  # '3d363ff7401e02026f4a4687d4863ced'\n","tags":"#python #security #hashing #hash"},{"id":"4396c5b9d3466800da85405c4b57866a","title":"[Golang Line Counter Alternative] ","content":"// Alternative line counter that benefits from assembly optimized functions\n// offered by the bytes package to search characters in a byte slice.\nfunc lineCounter(r io.Reader) (int, error) {\n\t// my file 'lines' are ~80 bytes in length\n\tbuf := make([]byte, 80*1024)\n\tcount := 0\n\tlineSep := []byte{'\\n'}\n\n\tfor {\n\t\tc, err := r.Read(buf)\n\t\tcount += bytes.Count(buf[:c], lineSep)\n\n\t\tswitch {\n\t\tcase err == io.EOF:\n\t\t\treturn count, nil\n\n\t\tcase err != nil:\n\t\t\treturn count, err\n\t\t}\n\t}\n}\n\n","tags":"#go #golang #line #counter"},{"id":"ef14e3f674ad2265dbebdfa8bd015f19","title":"[Python Auto-Formatter] ","content":"[pep8]\nmax_line_length = 80\nautopep8 --experimental --verbose --aggressive --aggressive --recursive --diff .\n\n# replace --diff with --in-place to actually apply the changes\n# to install black via poetry use:\n#\n# poetry add --dev --allow-prereleases black\n#\n# which generates:\n#\n# black = {version = \"^18.3-alpha.0\",allows-prereleases = true}\n#\n# but notice the value below is slightly different, which iirc is because we used a different version of Python which needed to be defined?\n#\n# but using the --allow-prereleases flag on the command line worked for me on a fresh project so :shrugs:\n\n[tool.poetry]\nname = \"3.7.3\"\nversion = \"0.1.0\"\ndescription = \"\"\nauthors = [\"Integralist\"]\n\n[tool.poetry.dependencies]\npython = \"^3.7\"\nboto3 = \"^1.9\"\npytest = \"^4.4\"\nstructlog = \"^19.1\"\ntornado = \"^6.0\"\nrequests = \"^2.21\"\n\n[tool.poetry.dev-dependencies]\nblack = { python=\"\u003e3.6\", version=\"\u003e=19.3b0\", allow_prereleases=true}\nflake8 = \"^3.7\"\nflake8-import-order = \"^0.18.1\"\nmypy = \"^0.701.0\"\ntox = \"^3.9\"\nipython = \"^7.5\"\n\n[build-system]\nrequires = [\"poetry\u003e=0.12\"]\nbuild-backend = \"poetry.masonry.api\"\n","tags":"#autopep8 #black #python #format"},{"id":"fb0f19802a7021fbdefae39c6de9fc3b","title":"[Calculating BigO] ","content":"\u003e This is condensed information gleened from the excellent [interactivepython.org](http://interactivepython.org/runestone/static/pythonds/AlgorithmAnalysis/BigONotation.html)\n\n## Algorithm\n\n```py\ndef sumOfN(n):\n   theSum = 0\n   for i in range(1,n+1):\n       theSum = theSum + i\n\n   return theSum\n\nprint(sumOfN(10))  # 55\n```\n\n## Analysis Steps\n\nYou want to quantify the number of operations (or 'steps') in the algorithm.\n\nTo do this:\n\n* Identify the basic unit of computation.\n* Track any operational constants (e.g. `theSum = 0`).\n* Track repeatable operations (e.g. `theSum = theSum + i`).\n* Identify the most 'dominant' portion of `T(n)` (see explanation below).\n\n## Explanation\n\nIf `T(n)` is the 'size of the problem', then we can say...\n\n```\nT(n) == 1+n steps\n```\n\nAs the problem gets larger, some portion of `T(n)` tends to overpower the rest.\n\n\u003e Note: 'order of magnitude' describes part of `T(n)` that increases the _fastest_ as `n` increases.\n\nWe represent order of magnitude in 'Big O' syntax:\n\n```\nO(f(n))\n```\n\nWhere:\n\n```\nf(n) == dominant part of T(n)\n```\n\nAs `n` gets larger, using `T(n) = 1+n` as an example, the 'constant' `1` (i.e. the computation that happened once: `theSum = 0`) becomes less and less significant.\n\nMeaning we can drop `1` from our syntax, resulting in just `O(n)`, and our approximation is just as accurate without it.\n\n## Significant or Insignificant?\n\nI'm going to paste verbatim the original author's comments...\n\n\u003e As another example, suppose that for some algorithm, the exact number of steps is `T(n) = 5n2 + 27n + 1005`. \n\u003e \n\u003e When `n` is small, say `1` or `2`, the constant `1005` seems to be the dominant part of the function. \n\u003e \n\u003e However, as `n` gets larger, the `n2` term becomes the most important. \n\u003e \n\u003e In fact, when `n` is really large, the other two terms become insignificant in the role that they play in determining the final result. \n\u003e \n\u003e Again, to approximate `T(n)` as `n` gets large, we can ignore the other terms and focus on `5n2`. \n\u003e \n\u003e In addition, the coefficient `5` becomes insignificant as `n` gets large. \n\u003e \n\u003e We would say then that the function `T(n)` has an order of magnitude `f(n) = n2`, or simply that it is `O(n2)`.\n\n## Example Analysis\n\n```py\na = 5\nb = 6\nc = 10\n\nfor i in range(n):\n   for j in range(n):\n      x = i * i\n      y = j * j\n      z = i * j\n\nfor k in range(n):\n   w = a*k + 45\n   v = b*b\n\nd = 33\n```\n\nThe above code can be calculated as:\n\n```\nT(n) == 3 + 3n2 + 2n + 1\n```\n\nWhich can be condensed slightly, by combining the singular constants, to:\n\n```\nT(n) == 3n2 + 2n + 4\n```\n\nThe constants `3` and `1` are the top level variable assignments: `a=5`, `b=6`, `c=10` and `d=33`.\n\nThe `3n2` is because there are three constant variable assignments (`x`, `y` and `z`) that are occurring within the first set of `for` statements. The top level `for` statement iterates over `n` items, and then does so _again_ hence the `n2` portion of `3n2`.\n\nThe `2n` is because there are two constant assignments (`w` and `v`) and they happen `n` times due to the last `for` statement iterating over `n` items.\n\nWith this in mind we can say the code is `O(n2)` because when we look at the exponents of each segment of the time analysis (i.e. the condensed version: `3n2 + 2n + 4`) we can see that as `n` grows, the `n2` portion is the most significant.\n\n\u003e Remember: although we write 'Big O' as `O(...)` the underlying principle is `O(f(...))`, where `f(...)` is the dominant part of `T(...)` and when focusing in on the dominant part of the time complexity we drop the constants -- also known as the _coefficient_ -- (e.g. `3n2` thus becomes `n2`). This is because the constants become _insignificant_ as `n` grows.\n","tags":"#bigo #algorithms #analysis"},{"id":"bb12b7c70da37501c62014789c3c0827","title":"[Partial Application in Golang] ","content":"package main\n\nimport (\n\t\"fmt\"\n)\n\nfunc main() {\n\tcrawl := crawl(\"logrus\")\n\tcrawl(\"other args\")\n}\n\ntype crawler func(string)\n\nfunc crawl(logger string) crawler {\n\treturn func(remaining string) {\n\t\tfmt.Println(\"logger:\", logger, \"remaining:\", remaining)\n\t}\n}\n\n","tags":"#go #golang #fp #partialapplication"},{"id":"b2dded9dfa43e7858ec6ccea33ea3dc4","title":"[Business Success] ","content":"## Key Points\n\n- the product direction should drive the type of work that we prioritize.\n- take an 'outside in' approach (`user -\u003e brand/product -\u003e software -\u003e infrastructure`)\n\n## Example\n\nFixing a deployment pipeline might be useful as part of your teams commitment to sustainable (†) software, but does it contribute to the overall impact your team is having on reaching the goal of promoting the business/product?\n\n\u003e † notice we don't refer to \"tech debt\" but the \"sustainability\" of our software.\n\n## Rationale\n\nThinking about the end users and the services we're offering isn't something a lot of engineers worry about. They have their own interests and agendas. Technology and implementation seems to take primary focus.\n\nWe should encourage a Netflix mentality of 'get on board, or get off'. It's not about firing people or pushing good people out the door. It's about ensuring everyone working at the organization is focused on making the business a success and dropping their egos at the door each morning.\n\nIf the business is successful, then YOU will be successful.\n\nIf the business is NOT successful, then you'll have the greatest software and tools in the world that no one uses (and you'll soon find the company goes under).\n","tags":"#business #product #focus #priority #success"},{"id":"dbdd2fc992a934ea3986a8959a10fbb6","title":"[Python Custom Iterator] ","content":"class Foo:\n    def __init__(self):\n        self.current = 0\n        self.limit = 5\n\n    def __iter__(self):\n        return self\n\n    def __next__(self):\n        if self.current \u003e= self.limit:\n            raise StopIteration\n        else:\n            self.current += 1\n            return self.current - 1\n\n\nfor f in Foo():\n    print(f)\n\n","tags":"#python #iterator"},{"id":"5e0008a16da806cac32c7db0e0f6b251","title":"[Golang Design Patterns] ","content":"## types as abstraction layers\n\n```go\ntype Source string\n\nfunc (src Source) CopyTo(dest string) error {\n    return CopyFile(dest, string(src))\n}\n\nfunc main() {\n    var from Source = \"presentation.md\"\n    from.CopyTo(\"/tmp/backup\")\n}\n```\n\n## dependency handling\n\nThere are three approaches...\n\n1. Pass dependencies as arguments to all functions requiring them.\n2. Package exported `Init` functions for configuring internal package level variables.\n3. Pass dependencies stored within a struct to all functions requiring them.\n\n### 1.\n\n```go\nfunc init() {\n\t// configure logger and other stuff\n}\n \nfunc main() {\n\tmyOtherPackage.foo(\"x\", configuredLoggerInstance)\n    myOtherPackage.bar(\"y\", configuredLoggerInstance)\n    myOtherPackage.baz(\"z\", configuredLoggerInstance)\n}\n```\n\n### 2.\n\n```go\nfunc init() {\n\t// configure logger and other stuff\n}\n \nfunc main() {\n\tmyOtherPackage.Init(configuredLoggerInstance)\n}\n```\n\n### 3.\n\n```go\ntype Deps struct{\n    Dep *fooDep\n    OtherDep *barDep\n}\n\nfunc Thing(deps *Deps) {\n    // extract and use dependencies\n}\n```\n\n\u003e Note: if you find you have functions that accept lots of arguments then you could also use variadic args to pass the logger and other generic dependencies, then loop over and type assert for them (but that's a lot of extra code for not a lot of gain). if you do have lots of function args, then try to reduce them by splitting up the code into separate functions and also reduce generic args into a struct so it's just one arg rather than multiple (e.g. a instrumentation struct).\n","tags":"#go #golang #design"},{"id":"c86d2fba3cceddb3afb7b51ebe6a95d5","title":"[Single Sign-On SSO] ","content":"\u003e These are all suggestions from AWS Technical Support\n\n## Initial suggestion\n\n- You have a \"Master\" domain, let's say \"auth.ronan.com\". \n- You have 2 websites, a.com and b.com. Of course, your end user. Let's call him \"Bob\". \n- When Bob makes a request to a.com, we will check if they have sent a token. If not, we will redirect them to auth.ronan.com to handle the auth, then return a token along with a cookie for said domain in the form of a redirect. \n- Next, Bob sends a request to b.com without a token, it again would need to redirect to the \"auth\" website to obtain the token and set the cookie for b.com too. \n- Now, your 2 sites would have a token which can be used to make API calls. \n\n## Follow-up Discussion\n\nI've continued to work with our internal Cognito experts here, where I have the following clarification: \n\n- AWS User Pools does not limit the usage of One User Pool per domain, however the way cookie/local storage works prevents cross site access, which in turn really doesn't work in our favour in this situation.  This isn't something we can work around from an AWS perspective. \n\nIn this case, the handling of this logic needs to be done on the client side. If you build your applications so they do not rely on the cookie and the localStorage, then it's possible to use one user pool to authenticate users for multiple domains applications. \n\nOur internal Cognito SME noted that there are several possible options he could can think of. For example, store the tokens in memory, passing the id_tokens in the http request's header when sending requests to your own applications. \n\nAnother option would be using the User Pool as an Oauth SSO.  Let's consider an ALB as \"the application\".  When we go to the ALB URL, we authenticate with a User Pool Hosted UI. In this case, you can have multiple ALBs using one User Pool as their authoriser. This also requires some application side implementation. \n\nThe auth flow would look something like this, and I hope it improves on my previous illustration:\n\n1. User accesses application A\n2. Application A checks user login status against its own storage/cache. \n3. Redirect user to hosted UI so they can login if step 2 found the user to be in the status of not logged in.\n4. User authenticates in Hosted UI and gets redirected back to application A.\n\n5. User accesses application B\n6. Application B checks user login status against its own storage/cache (like step 2). \n7. Redirect user to hosted UI so they can login if step 5 found the user to be in the status of not logged in.\n   7a. user already signed-in to the User Pool (step3.), directly redirect back to application B with tokens \n\nThe outlined flow provided by our local SME is one using IdP SSO for multiple applications. If you can consider to use the Cognito Hosted UI, I think this would also remove some of the heavy lifting. \n","tags":"#sso #singlesignon #auth #multipledomains #aws"},{"id":"5b4c9489bf307da542d5f087adbbff42","title":"[Golang Print over last line - like a counter] ","content":"package main\n\nimport (\n\t\"fmt\"\n\t\"time\"\n)\n\nfunc main() {\n\tticker := time.Tick(time.Second)\n\tfor i := 1; i \u003c= 10; i++ {\n\t\t\u003c-ticker\n\t\tfmt.Printf(\"\\x0cOn %d/10\", i)\n\t}\n\tfmt.Println(\"\\nAll is said and done.\")\n}\npackage main\n\nimport (\n\t\"fmt\"\n\t\"time\"\n)\n\nfunc main() {\n\tticker := time.Tick(time.Second)\n\tfor i := 1; i \u003c= 10; i++ {\n\t\t\u003c-ticker\n        fmt.Printf(\"\\rOn %d/10\", i) // escape sequence is different in this environment\n\t}\n\tfmt.Println(\"\\nAll is said and done.\")\n}\n","tags":"#go #golang #counter #inplace #print"},{"id":"fee3c008296cb3e0a16ec8fdfcdc371b","title":"[Python Exception Handling Guidelines] ","content":"It's best to raise your exceptions at the point in the code where errors are going to occur.\n\nWhen you have deeply nested code modules, then don't try to handle exceptions in-between, just raise the exception (instrument there too) and then let a _top level_ handler catch generalized exceptions to do its own instrumentation (if necessary).\n\nThis means it's a good idea for the top level handler to catch a generalized parent exception class type, and have your internal code raise subclass exceptions from that parent class.\n","tags":"#python #exceptions #design #guidelines"},{"id":"f6ba7569f055103ca8b602422eb4f994","title":"[Vim Regex] ","content":"A zero-width negative lookaround assertion looks like:\n\n```\nlevel='(?!info)\n```\n\n\u003e Note: this would match `level='error'` or `level='debug'`.\n\nThe equivalent in Vim is:\n\n```\n/level='\\(info\\)\\@!\n```\n\n\u003e Note: this strange syntax is [documented here](http://vimdoc.sourceforge.net/htmldoc/pattern.html#/%5C@!), see `:h \\@!`\n\nhttps://vim.fandom.com/wiki/Regex_lookahead_and_lookbehind\n","tags":"#vim #regex #lookaround #assertions"},{"id":"20ff7427d3df5cc02d5a619ca0cd9695","title":"[Go Guru and Vim-Go] ","content":"## Go Guru\n\n\u003e See official doc: [Using Go Guru](https://docs.google.com/document/d/1_Y9xCEMj5S-7rv2ooHpZNH15JgRT5iM742gJkw5LtmQ/edit#heading=h.7q1t7o2y7td3)\n\n```bash\ngo get golang.org/x/tools/cmd/guru\nguru -help\n```\n\nGuru command line usage:\n\n```bash\nguru \u003cmode\u003e \u003cposition:byte offset\u003e\n```\n---\n\nHere's an example go program:\n\n```go\ntype statusHandler int\n \nfunc (s statusHandler) ServeHTTP(w http.ResponseWriter, r *http.Request) {\n    code := int(s)\n    w.WriteHeader(code)\n    io.WriteString(w, http.StatusText(code))\n}\n```\n\nWith cursor over the `statusHandler` type:\n\n```bash\nguru implements ~/code/go/src/github.com/integralist/http-interface/main.go:#812\n```\n\nThis tells us that it implements the `http.Handler` interface:\n\n```bash\n/Users/markmcdonnell/code/go/src/github.com/integralist/http-interface/main.go:40.6-40.18: basic type statusHandler\n/usr/local/Cellar/go/1.10.3/libexec/src/net/http/server.go:82.6-82.12:  implements net/http.Handler\n```\n\n---\n\nWith cursor over the `ServeHTTP` method:\n\n```bash\nguru implements ~/code/go/src/github.com/integralist/http-interface/main.go:#836\n```\n\nThis tells us that it implements the `http.Handler` interface's signature `ServeHTTP` method:\n\n```bash\n/Users/markmcdonnell/code/go/src/github.com/integralist/http-interface/main.go:42.24-42.32: concrete method func (statusHandler).ServeHTTP(w net/http.ResponseWriter, r *net/http.Request)\n/usr/local/Cellar/go/1.10.3/libexec/src/net/http/server.go:83.2-83.10:  implements method (net/http.Handler).ServeHTTP\n```\n\n\u003e Note: to convert a line into a byte range you can use in Vim `:echo eval(line2byte(line(\".\"))+col(\".\"))`\n\n---\n\n```go\n// this is a duplicate of fmt.Stringer interface\ntype stringit interface {\n    String() string\n}\n \ntype testthing struct{}\n \nfunc (t testthing) String() string {\n    return \"a test thing\"\n}\n```\n\n---\n\nWith cursor over the testhing type:\n\n```bash\nguru implements ~/code/go/src/github.com/integralist/http-interface/main.go:#722\n```\n\nThis tells us that the testthing struct is satisfying multiple interfaces. This helps me to realize that maybe my new interface isn't necessary and that maybe I should consider re-using an existing interface:\n\n```bash\n/Users/markmcdonnell/code/go/src/github.com/integralist/http-interface/main.go:33.6-33.14: struct type testthing\n/usr/local/Cellar/go/1.10.3/libexec/src/fmt/print.go:62.6-62.13:                           implements fmt.Stringer\n/Users/markmcdonnell/code/go/src/github.com/integralist/http-interface/main.go:29.6-29.13: implements stringit\n/usr/local/Cellar/go/1.10.3/libexec/src/runtime/error.go:66.6-66.13:                       implements runtime.stringer\n```\n\n---\n\nWith cursor over the interface itself:\n\n```bash\nguru implements ~/code/go/src/github.com/integralist/http-interface/main.go:#676\n```\n\nThis shows us everything that sastifies this interface:\n\n```bash\nmain.go|29 col 6| interface type stringit\n/usr/local/Cellar/go/1.10.3/libexec/src/bytes/buffer.go|17 col 6|     is implemented by pointer type *bytes.Buffer\n/usr/local/Cellar/go/1.10.3/libexec/src/context/context.go|316 col 6| is implemented by pointer type *context.cancelCtx\n\n...many things satisfy this...\n```\n## Vim-Go integration with Guru\n\nvim-go uses `:GoReferrers` to look up references and `:GoImplements` to show what interface the given type is implementing.\n\n```go\ntype foo interface {\n\tbar(string) string\n}\n\ntype thing struct{}\n\nfunc (t thing) bar(x string) string {\n\tfmt.Println(x)\n\treturn \"y\"\n}\n```\n\nIf I execute `:GoImplements` while cursor is on top of `bar` method, I'll see:\n\n```\nmain.go|35 col 16| concrete method func (thing).bar(x string) string\nmain.go|30 col 2| implements method (foo).bar\n```\n\n- `:GoCallers`: lists callers of this function.\n- `:GoCallees`: lists functions called by this function.\n- `:GoReferrers`: lists every instance where this function is called.\n- `:GoDescribe`: lists selected identifiers definition (inc. method set + struct fields).\n- `:GoImplements`: lists all interfaces the selected identifier satisfies.\n- `:GoWhicherrs`: lists all possible error types returned.\n- `:GoChannelPeers`: lists sends/receives on a `\u003c-` channel.\n\n---\n\n## Vim-Go: Other Features\n\n- `:GoRename`: rename all references to identifier across project.\n- `:GoImpl`: implement stubs for specified interface.\n- `:GoDecls`: list all function and type declarations for the current file.\n- `:GoDef`: takes you to the source of the identifier (i.e. where it's defined).\n- `:GoTest`: run all your tests (can also pass `./...`).\n- `:GoTestFunc`: run the specific test function under your cursor.\n","tags":"#go #golang #guru #interfaces #vim #vim-go"},{"id":"a51d5f876f1ee2259915548ad6d1f963","title":"[Set same cookie on multiple domains] ","content":"Reference: http://subinsb.com/set-same-cookie-on-different-domains/\n\nThe way Google does this is by creating a server-side script that sets the cookie on all the domains. \n\nOn the domain where the login occurs, create a intermediary page that would load the server-side script that sets a cookie on the other two domains. \n\ni.e. the user authenticates, and are redirected to `/processing`\n\nIn that page you would add an `onload` callback onto the `body` tag. \n\nThe document will only load when the images have completely loaded (i.e. the cookies are set on the other two domains). \n\n```\n\u003c!-- https://www.domain1.com/processing --\u003e\n\n\u003chtml\u003e\n \u003chead\u003e\n  \u003cscript\u003e\n   function loadComplete(){\n    window.location=\"https://www.domain1.com/user/settings\"; // page to redirect user once they're authenticated\n   }\n   \u003c/script\u003e\n \u003c/head\u003e\n \u003cbody onload=\"loadComplete()\"\u003e\n \tPlease wait..........\n \t\u003cimg src=\"https://www.domain2.com/setcookie.php?user=jwt\"/\u003e\n \t\u003cimg src=\"https://www.domain3.com/setcookie.php?user=jwt\"/\u003e\n \u003c/body\u003e\n\u003c/html\u003e\n```\n","tags":"#cookie #multiple #domains"},{"id":"6d9444532e5b500942ebc8759c278d2f","title":"[Bash loop files in a directory and check their types] ","content":"#!/bin/bash\n\nproject=~/foo\nservice=bar\nignore=(\"cmd\" \"lib\" \"scripts\")\n\nfor filename in $project/$service/*; do\n  if [[ -d $filename ]]; then\n    echo \"$filename is a directory\"\n\n    f=$(basename \"$filename\")\n\n    if [[ ! \"${ignore[@]}\" =~ $f ]]; then\n      echo \"$filename ($f) is a directory we want to symlink\"\n    fi\n  fi\ndone\n\n###\n\nfor filename in ~/foo/*; do\n  echo \"file name is: $filename\";\n  if [[ -d $filename ]]; then\n      echo \"$filename is a directory\"\n  elif [[ -f $filename ]]; then\n      echo \"$filename is a file\"\n  else\n      echo \"$filename is not valid\"\n  fi\n  \n  # for ((i=0; i\u003c=3; i++)); do\ndone\n","tags":"#bash #directory #file #search"},{"id":"e5316d6b9e4046e07180c821f391de22","title":"[Golang Pretty Print] ","content":"package main\n\nimport (\n\t\"encoding/json\"\n\t\"fmt\"\n)\n\nfunc PrettyPrint(v interface{}) (err error) {\n\tb, err := json.MarshalIndent(v, \"\", \"  \")\n\tif err == nil {\n\t\tfmt.Println(string(b))\n\t}\n\treturn\n}\n\nfunc main() {\n\tx := map[string]string{\"x\": \"y\"}\n\tPrettyPrint(x)\n}\n","tags":"#go #golang #prettyprint"},{"id":"93a64b36c0c029b1d851f70000a551fa","title":"[Python Generic Exception Logging] ","content":"def get_function_name():\n    \"\"\"\n    0: get_function_name()\n    1: log_exception()\n    2: whatever called log_exception()\n    \"\"\"\n    return inspect.stack()[2].function\n\n  \ndef log_exception(exc, msg='exception caught', **kwargs):\n    logger.error(msg,\n                 exc_class=type(exc),\n                 exc_type=exc.__class__.__name__,\n                 exc_msg=str(exc),\n                 fn=get_function_name(),  # foo\n                 **kwargs)\n\ndef foo():\n  try:\n    raise Exception()\n  except Exception as exc:\n    log_exception(exc, 'something happened')\n","tags":"#python #exceptions #error #logging"},{"id":"74f55c0587238536f24644715e0f3325","title":"[Golang Long and Short Flags] ","content":"var myFlagType string\n\nfunc init() {\n    const (\n        flagValue = \"default value is foo\"\n        flagUsage = \"this is my flag explanation\"\n    )\n    flag.StringVar(\u0026myFlagType, \"foo\", flagValue, flagUsage)\n    flag.StringVar(\u0026myFlagType, \"f\", flagValue, flagUsage+\" (shorthand)\")\n    flag.Parse()\n}\n\n// this works by using an alternative flag syntax, which allows you to \n// specify a 'variable' to assign the incoming flag value to.\n// this is different to `flag.String` where the returned type is a pointer.\n//\n// in the above example we can see we specify --foo and -f\n","tags":"#go #golang #flags"},{"id":"1d119f758edb2d8fa3e074fdc209b742","title":"[Python Internals] ","content":"import builtins\n\ndir(builtins)  # lists all objects that are globally available (e.g. builtins.object is available as 'object', no need to import `builtins` explicitly)\n\nhelp(object)  # help(builtins.object) is the same output...\n\n\"\"\"\nHelp on class object in module builtins:\n\nclass object\n |  The most base type\n\"\"\"\n\nhelp(str)  # prints signature, return types, descriptions and all methods.\n","tags":"#python #internals"},{"id":"1140bcd773616ecdae9bb4d2e9e55b34","title":"Python: Dynamic Log Levels via Abstraction ","content":"import inspect\n\nimport logging\nimport structlog\n\n# TODO: configuration of structure logs (see my other gists)\n\ndef extract_status_code(exc):\n    return exc.response['ResponseMetadata']['HTTPStatusCode'] if hasattr(exc, 'response') else 500\n\n\ndef get_function_name(steps=2):\n    \"\"\"\n    The 'steps' indicate how far back in the stack to traverse.\n\n    Example A...\n\n    0: get_function_name()\n    1: log_it()\n    2: whatever called log_it()\n\n    Example B...\n\n    0: get_function_name()\n    1: log_it()\n    2. log_exception()\n    3: whatever called log_exception()\n    \n    It gets tricky when you have a function nested inside of another function\n    and even more tricky when that nested function is called at different\n    levels.\n    \"\"\"\n    return inspect.stack()[steps].function\n\n\ndef log_it(msg, steps=2, level='error', **kwargs):\n    \"\"\"Abstraction to make logging generic information easier to manage.\"\"\"\n    \n    log_level = getattr(logger, level)\n    log_level(msg, fn=get_function_name(steps=steps), **kwargs)\n\n\ndef log_exception(exc, msg='exception caught', steps=3, **kwargs):\n    \"\"\"AWS exceptions don't always have a code. So we protect against that.\"\"\"\n    \n    has_code = hasattr(exc, 'code')\n\n    exc_data = {'exc_class': type(exc),\n                'exc_type': exc.__class__.__name__,\n                'exc_msg': str(exc),\n                'err_code': exc.code if has_code else extract_status_code(exc)}\n\n    log_it(msg, steps=steps, **exc_data, **kwargs)\n    \n\"\"\"\nAlternative version that moves some things around to accommodate needing to record metrics\nand not wanting to have to look back up the stack trace multiple times...\n\ndef log_it(message, steps=2, level='error', fn=False, metric_name='log', **kwargs):\n    \"\"\"Abstraction to make general instrumentation (logs/metrics) easier to manage.\"\"\"\n\n    if not fn:\n        # log_exception will always provide a fn (function name)\n        # meaning log_it was called directly\n        fn = get_function_name(steps=steps)\n\n    metrics.increment(metric_name, tags={'msg': message, 'level': level, 'func': fn, **kwargs})\n\n    # prevent log_level call with func keyword argument from exploding\n    # as func will sometimes be provided via kwargs object\n    kwargs.pop('func', None)\n\n    log_level = getattr(logger, level)\n    log_level(message, func=fn, **kwargs)\n\n\ndef log_exception(exc, msg='exception caught', trigger_type='expected', **kwargs):\n    \"\"\"Abstraction to make exception instrumentation easier to manage.\"\"\"\n\n    fn = get_function_name(steps=2)\n\n    has_code = hasattr(exc, 'code')\n    err_code = exc.code if has_code else extract_status_code(exc)\n\n    exc_data = {'exc_class': type(exc),\n                'exc_type': exc.__class__.__name__,\n                'exc_msg': str(exc),\n                'err_code': err_code}\n\n    metric_tags = {'type': trigger_type,\n                   'func': fn,\n                   'msg': msg,\n                   **exc_data,\n                   **kwargs}\n\n    log_it(msg, fn=fn, metric_name='exception', **metric_tags)\n\"\"\"\n\"\"\"\nThe log abstractions can be used along with tornado to make tracking unhandled exceptions easier\n\"\"\"\n\nclass AuthBaseHandler(BaseHandler):\n    def write_error(self, status_code, **kwargs):\n        if kwargs.get('exc_info'):\n            # we're dealing with an unhandled exception\n\n            stack_trace = '\\n'.join([line for line in traceback.format_exception(*kwargs['exc_info'])])\n            exc = kwargs['exc_info'][1]\n            log_exception(exc, msg='unhandled exception', trigger_type='unexpected', stack=stack_trace)\n\n            self.set_status(status_code)\n            self.write({'state': 'error',\n                        'code': status_code,\n                        'message': 'unknown exception'})\nimport logging\n\ndef log_it(msg, level='error'):\n    fn = getattr(logging, level)\n    fn(msg)\n\nlog_it(1, level='warning')\n# WARNING:root:1\n\nlog_it(1, level='error')\nlog_it(1)\n# ERROR:root:1\n","tags":"#python #logs"},{"id":"0feb183ff45964403b2722f2f37c40cb","title":"[Rollout strategies for large code changes] ","content":"Getting into production _sooner_ should be part of our business plan.\n\nRather than spending lots of time getting _all_ planned features 'finished', we should have a plan for slowly rolling out _incremental_ changes. In doing so we would have more confidence that the features we were releasing would not break something in production and make it difficult to rollback. In effect we want to avoid ending up with a 'big bang' rollout.\n\nThe following steps could be a useful plan of action to take:\n\n1. define code 'boundaries'\n2. filter traffic by 'funnels'\n3. build features, then deploy them within our secured boundaries\n\n\u003e Note: I've since discovered that this approach is a form of [Strangler Pattern](https://www.martinfowler.com/bliki/StranglerApplication.html). I've been using it for years but was unaware that it had a _name_ and that Martin Fowler was responsible for that way back in 2004!\n\n## Boundaries\n\nIdentify areas of the existing code base where new changes (e.g. replacement of existing services) will need to happen, and ensure their are appropriate code branches in place. \n\nIn essence, build a wall around where your new code will end up.\n\n## Funnels\n\nDefine what users (or general traffic) can access the code that sits inside of the defined boundaries. For example, maybe just traffic from your own team should be able to penetrate the code branches (via some form of authentication process: self-signed certs, cookies or a custom header etc).\n\n\u003e **Important!** make sure your funnels are working and then code you place within these new 'boundaries' does not break anything in production (have tests written to ensure this).\n\nAs the project reaches a state where it can be exposed to more uses, you update the 'funnel' to allow more an more throughput. Thus increasing the allowed traffic range (e.g. not only your team can access it, via authentication, but so can multiple teams within your organization; then moving forward you can replace the authentication process with a locality check -- so users in Australia get the new feature, etc).\n\n## Deploy Incrementally\n\nWhile you have the boundaries for your new code defined, and a small funnel in place to control the traffic, you can then start quickly deploying new code without fear of it breaking anything in production.\n","tags":"#rollout #strategy #plans #strangler #pattern"},{"id":"ff7930457efc34134cc982b486f2b4c5","title":"[Python Tornado Generic Exception Handling] ","content":"\"\"\"\nException is still sent to stdout, so if your service is configured\nto send all stdout to a log aggregator you'll get both a load of \nlog noise followed by a single log call that consolidates it all.\n\nSee https://gist.github.com/1140bcd773616ecdae9bb4d2e9e55b34 for a\nlogging/metrics abstraction (+ tornado implementation) that ties \nthis write_error function together nicely.\n\"\"\"\n\nimport tornado\nimport traceback\n\nclass CustomHandler(tornado.web.RequestHandler):\n    def write_error(self, status_code, **kwargs):\n        if kwargs.get('exc_info'):\n            # dealing with an unhandled exception\n            stack_trace = '\\n'.join([line for line in traceback.format_exception(*kwargs[\"exc_info\"])])\n            logger.error('uh-oh', stack=stack_trace)\n            self.set_status(500)\n            self.finish()\n","tags":"#python #tornado #exceptions #handling"},{"id":"ff7065a6c74b7cf8bfd58fcd32dfd9f1","title":"[Sed Replace Pattern with File Contents] ","content":"cd -- \"$(mktemp -d)\" \nprintf '%s\\n' 'nuts' 'bolts' \u003e first_file.txt\nprintf '%s\\n' 'foo' 'bar' 'baz' \u003e second_file.txt\nsed -e '/bar/r ./first_file.txt' second_file.txt\n\n### output...\nfoo\nbar\nnuts\nbolts\nbaz\n### ...notice 'bar' in second_file.txt has the contents from first_file.txt appended after it\n","tags":"#sed #bash #replace"},{"id":"848b13a9be823090e7dfc230d5bcce41","title":"[Python Decorator Order] ","content":"\"\"\"\nDecorators are 'bottom up', meaning:\n\nThe bottom decorator is executed, and its result is\nprovided as input to the decorator above it.\n\nIn the below code this would look something like:\n\nmakebold(makeitalic(hello()))\n\"\"\"\n\ndef makebold(fn):\n    # fn == makeitalic(hello())\n    def wrapped():\n        return \"\u003cb\u003e\" + fn() + \"\u003c/b\u003e\"\n    return wrapped\n\ndef makeitalic(fn):\n    # fn == hello()\n    def wrapped():\n        return \"\u003ci\u003e\" + fn() + \"\u003c/i\u003e\"\n    return wrapped\n\n@makebold\n@makeitalic\ndef hello():\n    return \"hello world\"\n\nprint hello() ## returns \"\u003cb\u003e\u003ci\u003ehello world\u003c/i\u003e\u003c/b\u003e\"\n","tags":"#python #decorator #order"},{"id":"2b01cfdaf9c85efb0de6e2b2085896c3","title":"[Vim handling stdin] ","content":"\u003e Note: for full details, read https://vimways.org/2018/vims-social-life/\n\nVim doesn't handle stdin like other posix commands...\n\n```bash\n$ echo foo | vim\n\nVim: Warning: Input is not from a terminal\nVim: Error reading input, exiting...\nVim: Finished.\n```\n\nIf you pass `-` to vim, then it will accept the stdin and copy it to a new buffer...\n\n```bash\n$ echo foo | vim -\n```\n\nBefore we look ahead at how to handle stdin a bit better, let's consider the `+` flag which tells vim what line to start on (the following example tells vim to jump to line 10):\n\n```bash\n$ vim ~/.vimrc +10\n```\n\nThis will become relevant when we look at two other flags `-e` and `-s` (see `vim -h` for more information on available flags)...\n\n```bash\n$ echo foo | vim - -es +'%p' +'qa!'\n\nVim: Reading from stdin...\nfoo\n```\n\nWhen using the `-e` and `-s` flags, we're able to use `+` to execute Ex mode commands (see `:help -s-ex`).\n\n\u003e Note: if you don't use `+'qa!'` then vim will cause the terminal to hang (you also need the `!` otherwise `qa` would -- if dealing with a traditional vim UI -- show a message saying the buffer has been edited and can't be quite).\n\nTo avoid the `Vim: Reading from stdin...` message we need an additional flag `--not-a-term`:\n\n```bash\n$ echo foo | vim - -es +'%p' +'qa!' --not-a-term\n\nfoo\n```\n\nSo now if we want to manipulate the content (let's say uppercase the word `foo` to `FOO`) we can do:\n\n```\n$ echo foo | vim - -es --not-a-term +'norm VgU' +'%p' +'qa!'\n\nFOO\n```\n\n\u003e Note: `norm` says execute the following characters as if the user is typing them, so `V` selects the entire line and `gU` uppercases the selection. We then print the output to stdout `%p` and then quit without trying to save the modifications.\n","tags":"#vim #stdin"},{"id":"18ef92e020b6dcb074f49d799f4cc67f","title":"[Python Tornado Header Authorization Check] ","content":"\"\"\"\nExplanation:\n    tornado.web.RequestHandler calls an internal `_execute` method before\n    calling any other method such as `get` or `post` etc.\n    \n    we wrap the internal `_execute` method so that it either returns\n    a 403 or 401 exception depending on the situation.\n    \n    note: you can't raise a tornado.web.HTTPError from outside of the handler,\n    otherwise tornado will fail with an unhandled exception. so instead we set\n    the status and simply return the function.\n    \nTutorial:\n    http://kevinsayscode.tumblr.com/post/7362319243/easy-basic-http-authentication-with-tornado\n    \nSee also \"Python Tornado Basic Auth Middleware\":\n    https://gist.github.com/Integralist/911252f81830ff0ed650145c4d52f58e\n\"\"\"\n\nimport tornado.ioloop\nimport tornado.web\n\n\ndef require_basic_auth(handler_class):\n    def wrap_execute(handler_execute):\n        def serve_error(handler, status):\n            handler._transforms = []  # necessary\n            handler.set_status(status)\n            handler.finish()\n\n        def _execute(self, transforms, *args, **kwargs):\n            expected_header = self.request.headers.get('X-User-Auth')\n\n            if expected_header is None:\n                return serve_error(self, 403)\n\n            # beepboop should be pulled from somewhere, not hardcoded!\n            if expected_header != 'beepboop':\n                return serve_error(self, 401)\n\n            return handler_execute(self, transforms, *args, **kwargs)\n\n        return _execute\n\n    handler_class._execute = wrap_execute(handler_class._execute)\n\n    return handler_class\n\n \n@require_basic_auth\nclass MainHandler(tornado.web.RequestHandler):\n    # use !s inside format syntax to control string conversion\n    # https://docs.python.org/3.6/library/string.html#formatstrings\n    def get(self, basicauth_user, basicauth_pass):\n        msg = 'Hi there, {0!s}!  Your password is {1}.'\n        body = msg.format(basicauth_user, basicauth_pass)\n        self.write(body)\n        \n    def post(self, **kwargs):\n        basicauth_user = kwargs['basicauth_user']\n        basicauth_pass = kwargs['basicauth_pass']\n        msg = 'Hi there, {0!s}!  Your password is {1}.'\n        body = msg.format(basicauth_user, basicauth_pass)\n        self.write(body)\n        \ndef make_app():\n    return tornado.web.Application([\n        (r\"/\", MainHandler),\n    ])\n  \nif __name__ == \"__main__\":\n    app = make_app()\n    app.listen(9000)\n    tornado.ioloop.IOLoop.current().start()\n","tags":"#python #tornado #authorization #access"},{"id":"4f0318075092b6d2c3d2624b3f57ebec","title":"[Fastly Edge Dictionaries API Examples] ","content":"#!/usr/bin/env bash\n\n# API documentation here...\n# https://docs.fastly.com/api/config\n#\n# at the end of the day, these are just simple `curl` requests\n# along with a HTTP header that holds our api token.\n#\n# meaning, you could rewrite all of this much more cleanly in\n# a more fully feature language such as Go or Python.\n\nset -e\n\nmyservice=\"123\"\n\napi_token=\"Fastly-Key: $FASTLY_API_TOKEN_ADMIN\"\napi_host=\"https://api.fastly.com\"\n\n#-----------------------------------------------------------------------------------------------\n\n# GET LATEST SERVICE VERSION\n\nservice_latest=$(curl -s -H \"$api_token\" \"$api_host/service/$myservice\" | jq .versions[-1])\nprintf \"\\\\nlatest service:\\\\n\\\\n\"\necho \"$service_latest\" | jq\n\nservice_version=$(echo \"$service_latest\" | jq .number)\n\n#-----------------------------------------------------------------------------------------------\n\n# LIST ALL DICTIONARIES FOR LATEST SERVICE VERSION\n\nprintf \"\\\\nlist of edge dictionaries:\\\\n\\\\n\"\ndict_list=$(curl -s -H \"$api_token\" \"$api_host/service/$myservice/version/$service_version/dictionary\")\necho \"$dict_list\" | jq\n\n#-----------------------------------------------------------------------------------------------\n\n# LIST METADATA FOR A SPECIFIC DICTIONARY (e.g. the foo_bar dictionary already exists)\n\ndict_name=\"foo_bar\"\ndict_id=$(echo \"$dict_list\" | jq -r \".[] | select(.name == \\\"$dict_name\\\") | .id\")\n\nprintf \"\\\\nlist dictionary meta data:\\\\n\\\\n\"\ncurl -s -H \"$api_token\" \"$api_host/service/$myservice/version/$service_version/dictionary/$dict_id/info\" | jq\n\nprintf \"\\\\nlist dictionary content:\\\\n\\\\n\"\ncurl -s -H \"$api_token\" \"$api_host/service/$myservice/dictionary/$dict_id/items\" | jq\n\n#-----------------------------------------------------------------------------------------------\n\n# CREATE NEW DICTIONARY FOR SERVICE\n\nprintf \"\\\\ncreate new service version (required before we can create a new edge dictionary):\\\\n\\\\n\"\nservice_latest=$(curl -s -H \"$api_token\" -X PUT \"$api_host/service/$myservice/version/$service_version/clone\")\necho \"$service_latest\" | jq\nservice_version=$(echo \"$service_latest\" | jq .number)\n\nprintf \"\\\\ncreate new edge dictionary:\\\\n\\\\n\"\ndict_name=\"my_new_edge_dict\"\ncurl -s -H \"$api_token\" -X POST -d \"name=$dict_name\" \"$api_host/service/$myservice/version/$service_version/dictionary\" | jq\n\nprintf \"\\\\nlist of edge dictionaries:\\\\n\\\\n\"\ndict_list=$(curl -s -H \"$api_token\" \"$api_host/service/$myservice/version/$service_version/dictionary\")\necho \"$dict_list\" | jq\n\nprintf \"\\\\nlist of edge dictionaries:\\\\n\\\\n\"\ncurl -s -H \"$api_token\" \"$api_host/service/$myservice/version/$service_version/dictionary\" | jq\n\n#-----------------------------------------------------------------------------------------------\n\n# LIST METADATA FOR A SPECIFIC DICTIONARY (e.g. my_new_edge_dict)\n\ndict_id=$(echo \"$dict_list\" | jq -r \".[] | select(.name == \\\"$dict_name\\\") | .id\")\n\nprintf \"\\\\nlist dictionary meta data:\\\\n\\\\n\"\ncurl -s -H \"$api_token\" \"$api_host/service/$myservice/version/$service_version/dictionary/$dict_id/info\" | jq\n\nprintf \"\\\\nlist dictionary content:\\\\n\\\\n\"\ncurl -s -H \"$api_token\" \"$api_host/service/$myservice/dictionary/$dict_id/items\" | jq\n\n#-----------------------------------------------------------------------------------------------\n\n# CREATE NEW KEY/VALUE FOR NEW DICTIONARY\n\nprintf \"\\\\ncreate new key/value:\\\\n\\\\n\"\ndict_key=\"west\"\ndict_val=\"false\"\ncurl -s -H \"$api_token\" -X POST -d \"item_key=$dict_key\u0026item_value=$dict_val\" \"$api_host/service/$myservice/dictionary/$dict_id/item\" | jq\n\nprintf \"\\\\nlist dictionary content:\\\\n\\\\n\"\ncurl -s -H \"$api_token\" \"$api_host/service/$myservice/dictionary/$dict_id/items\" | jq\n\n#-----------------------------------------------------------------------------------------------\n\n# if you need to delete a dictionary...\n#\n# curl -s -H \"$api_token\" -X DELETE \"$api_host/service/$myservice/version/$service_version/dictionary/www_buzzfeed_com\"\n#\n# if you need to delete a dictionary key/value...\n#\n# curl -s -H \"$api_token\" -X DELETE \"$api_host/service/$myservice/dictionary/$dict_id/item/$dict_key\" | jq\n#\n# if you need to update a dictionary key/value...\n#\n# dict_val=\"true\"\n# curl -s -H \"$api_token\" -X PATCH -d \"item_value=$dict_val\" \"$api_host/service/$myservice/dictionary/$dict_id/item/$dict_key\" | jq\n","tags":"#fastly #api #cdn #edge #dictionaries #bash #shell"},{"id":"120a791c8a8e8170d60cc72d197b5b67","title":"GitHub: Collapsible Drop Down Menus ","content":"## collapsible markdown?\n\nShort version:\n\n```\n\u003cdetails\u003e\u003csummary\u003e...\u003c/summary\u003e\n\u003cp\u003e\n\u003c!-- following line break is intentional otherwise the code block wont render + don't forget to use triple backticks! --\u003e\n\n``bash\n# \n``\n\n\u003c/p\u003e\n\u003c/details\u003e\n```\n\nLong version:\n\n```\n\u003cdetails\u003e\u003csummary\u003eCLICK ME\u003c/summary\u003e\n\u003cp\u003e\n\nThe line break after the paragraph is intentional.\nWithout it the rendering of the below code block fails.\n\n#### yes, even hidden code blocks!\n\nDon't forget to use triple backticks, I've used two for the purposes of rendering this code within a Markdown formatted gist...\n\n``python\nprint(\"hello world!\")\n``\n\n...only using two for sake of displaying nested code block\n\n\u003c/p\u003e\n\u003c/details\u003e\n```\n","tags":"#GitHub #Collapsible #DropDown #Menus"},{"id":"8d2744cf001c689425568e75c3b75ffa","title":"[Modern JS] ","content":"Ensure you have Node/NPM installed, then make a project directory:\n\n```bash\nmkdir modern-js \u0026\u0026 cd modern-js\n```\n\nCreate an empty `package.json` file:\n\n```bash\nnpm init -y\n```\n\nInstall dependencies:\n\n```bash\nnpm install --save-dev webpack \\\n                       webpack-cli \\\n                       webpack-dev-server \\\n                       @babel/core \\\n                       @babel/preset-env \\\n                       \"babel-loader@^8.0.0-beta\" \\\n                       style-loader \\\n                       css-loader \\\n                       sass-loader \\\n                       node-sass \\\n                       eslint@4.x babel-eslint@8\n\nnpm install --save @babel/polyfill\n```\n\n\u003e Note: the dev dependencies need to be installed in the order they're specified, otherwise npm will complain/fail.\n\nYour `package.json` will now have the following dependencies:\n\n```js\n{\n  \"name\": \"modern-js\",\n  \"version\": \"1.0.0\",\n  \"description\": \"\",\n  \"main\": \"index.js\",\n  \"scripts\": {\n    \"test\": \"echo \\\"Error: no test specified\\\" \u0026\u0026 exit 1\"\n  },\n  \"keywords\": [],\n  \"author\": \"\",\n  \"license\": \"ISC\",\n  \"devDependencies\": {\n    \"@babel/core\": \"^7.1.2\",\n    \"@babel/preset-env\": \"^7.1.0\",\n    \"babel-eslint\": \"^8.2.6\",\n    \"babel-loader\": \"^8.0.4\",\n    \"css-loader\": \"^1.0.0\",\n    \"eslint\": \"^4.19.1\",\n    \"node-sass\": \"^4.9.3\",\n    \"sass-loader\": \"^7.1.0\",\n    \"style-loader\": \"^0.23.0\",\n    \"webpack\": \"^4.20.2\",\n    \"webpack-cli\": \"^3.1.2\",\n    \"webpack-dev-server\": \"^3.1.9\"\n  },\n  \"dependencies\": {\n    \"@babel/polyfill\": \"^7.0.0\"\n  }\n}\n```\n\n- **Babel**: transpiler of modern JS into ES5 compatible code\n- **Webpack**: a js module bundler (but also capable of transforming, bundling, packaging just about anything).\n\nNow create a webpack config file:\n\n```bash\nwebpack.config.js\n```\n\n\u003e Note: babel configuration will be placed inside of the `package.json` file, but can also be extracted into its own `.babelrc` file if you prefer.\n\nAdd the following code to your webpack configuration:\n\n```js\nconst path = require('path')\n\nmodule.exports = {\n  entry: './src/index.js',\n  output: {\n    filename: 'bundle.js',\n    path: path.resolve(__dirname, 'dist'),\n    publicPath: '/dist'\n  },\n  module: {\n    rules: [\n      {\n        test: /\\.js$/,\n        exclude: /(node_modules|bower_components)/,\n        use: {\n          loader: 'babel-loader',\n        }\n      }\n    ]\n  }\n}\n```\n\nUpdate your `package.json` to include script commands for webpack:\n\n```js\n{\n  ...\n  \n  \"scripts\": {\n    \"build\": \"webpack --mode production\",\n    \"dev\": \"webpack-dev-server --mode=development --config webpack.config.js\",\n    ...\n  },\n  \n  \"babel\": {\n  \t\"presets\": [\n    \t[\"@babel/env\", {\"modules\": false}]\n    ],\n    \"plugins\": [\"syntax-dynamic-import\"]\n  }\n  \n  ...\n}\n```\n\nThe `webpack` package also supports watching files for changes `--watch` but it doesn't handle 'hot reloading' (i.e. meaning you'll need to manually refresh your service, which if you've got a complex 'single page application' will result in you losing your current state).\n\n\u003e Note: the babel configuration prevents babel from transpiling `import` and `export` statements into ES5, and enables dynamic imports.\n\nNow create a JavaScript file that you want to transpile and bundle:\n\n```bash\nmkdir src dist\ntouch .eslintrc src/index.js src/component.js dist/index.html\n```\n\nHere's the contents of `index.js`:\n\n```js\n/*eslint no-undef: \"error\"*/\n/*eslint-env browser*/\n\nimport '@babel/polyfill';\n\nimport c from './component.js';\n\nconsole.log(c);\n\nlet a = 1;\nlet b = 2;\n[a, b] = [b, a];\nconsole.log(a);\nconsole.log(b);\n\nconst root = document.createElement('div');\nroot.innerHTML = `\u003cp\u003eHello Webpack!\u003c/p\u003e`;\ndocument.body.appendChild(root);\n```\n\n\u003e Note: instead of using `eslint-env browser` you could add a `globals` field to your `.eslintrc` (see below for example). You can also use `eslint-env node` for server-side JS. See the [docs](https://eslint.org/docs/user-guide/configuring) for more information.\n\nHere's the contents of `component.js`:\n\n```js\nconst c = ['x', 'y', 'z'];\n\nexport default c;\n```\n\nHere's the contents of `index.html`:\n\n```html\n\u003c!doctype html\u003e\n\u003chtml\u003e\n  \u003chead\u003e\n    \u003ctitle\u003eHello Webpack\u003c/title\u003e\n  \u003c/head\u003e\n  \u003cbody\u003e\n    \u003cscript src=\"bundle.js\"\u003e\u003c/script\u003e\n  \u003c/body\u003e\n\u003c/html\u003e\n```\n\nHere's the contents of `.eslintrc`:\n\n```\n{\n  \"parser\": \"babel-eslint\",\n  \"globals\": {\n    \"console\": true,\n    \"document\": true,\n    \"window\": true\n  },\n  \"rules\": {\n    'brace-style': [2, '1tbs', {'allowSingleLine': true}],\n    'camelcase': 2,\n    'comma-spacing': 2,\n    'comma-style': 2,\n    'curly': 2,\n    'eol-last': 2,\n    'indent': [2, 2],\n    'key-spacing': 2,\n    'new-cap': 2,\n    'new-parens': 2,\n    'no-lonely-if': 2,\n    'no-multi-spaces': 2,\n    'no-multiple-empty-lines': [2, {'max': 2}],\n    'func-call-spacing': 2,\n    'no-trailing-spaces': 2,\n    'quotes': [2, 'single', {'allowTemplateLiterals': true}],\n    'semi': 2,\n    'semi-spacing': 2,\n    'space-before-blocks': 2,\n    'space-in-parens': 2,\n    'space-infix-ops': 2,\n    'space-unary-ops': 2,\n    'array-callback-return': 2,\n    'block-scoped-var': 2,\n    'consistent-return': 2,\n    'eqeqeq': 2,\n    'guard-for-in': 2,\n    'no-array-constructor': 2,\n    'no-caller': 2,\n    'no-cond-assign': 2,\n    'no-const-assign': 2,\n    'no-control-regex': 2,\n    'no-delete-var': 2,\n    'no-dupe-args': 2,\n    'no-dupe-class-members': 2,\n    'no-dupe-keys': 2,\n    'no-duplicate-case': 2,\n    'no-empty-character-class': 2,\n    'no-empty-pattern': 2,\n    'no-eval': 2,\n    'no-ex-assign': 2,\n    'no-extend-native': 2,\n    'no-extra-bind': 2,\n    'no-fallthrough': 2,\n    'no-func-assign': 2,\n    'no-implied-eval': 2,\n    'no-invalid-regexp': 2,\n    'no-iterator': 2,\n    'no-lone-blocks': 2,\n    'no-loop-func': 2,\n    'no-mixed-operators': [2, {\n      groups: [\n        ['\u0026', '|', '^', '~', '\u003c\u003c', '\u003e\u003e', '\u003e\u003e\u003e'],\n        ['==', '!=', '===', '!==', '\u003e', '\u003e=', '\u003c', '\u003c='],\n        ['\u0026\u0026', '||'],\n        ['in', 'instanceof']\n      ],\n      allowSamePrecedence: false\n    }],\n    'no-multi-str': 2,\n    'no-native-reassign': 2,\n    'no-unneeded-ternary': 2,\n    'no-unsafe-negation': 2,\n    'no-new-func': 2,\n    'no-new-object': 2,\n    'no-new-symbol': 2,\n    'no-new-wrappers': 2,\n    'no-obj-calls': 2,\n    'no-octal': 2,\n    'no-octal-escape': 2,\n    'no-redeclare': 2,\n    'no-regex-spaces': 2,\n    'no-script-url': 2,\n    'no-self-assign': 2,\n    'no-self-compare': 2,\n    'no-sequences': 2,\n    'no-shadow-restricted-names': 2,\n    'no-shadow': 2,\n    'no-sparse-arrays': 2,\n    'no-template-curly-in-string': 2,\n    'no-this-before-super': 2,\n    'no-throw-literal': 2,\n    'no-undef': 2,\n    'no-unexpected-multiline': 2,\n    'no-unreachable': 2,\n    'no-unused-expressions': [2, {\n      'allowShortCircuit': true,\n      'allowTernary': true\n    }],\n    'no-unused-vars': 2,\n    'no-use-before-define': [2, 'nofunc'],\n    'no-useless-computed-key': 2,\n    'no-useless-concat': 2,\n    'no-useless-constructor': 2,\n    'no-useless-escape': 2,\n    'no-useless-rename': 2,\n    'no-with': 2,\n    'radix': 2,\n    'require-yield': 2,\n    'use-isnan': 2,\n    'valid-typeof': 2,\n    'wrap-iife': [2, 'any']\n  }\n}\n```\n","tags":"#javascript #js #modern #tools #transpilers #babel #webpack"},{"id":"7dfb75e058f584761948169a93dd1838","title":"[Python Tornado Decorator with arguments] ","content":"def auth(*args, **kwargs):\n    client = kwargs['client']\n\n    def wrapper(handler_method):\n        \"\"\"input will be, for example, RequestHandler.get or RequestHandler.post\"\"\"\n\n        @wraps(handler_method)\n        async def request_handler_wrapper(*args, **kwargs):\n            \"\"\"input is the request handler class and params from tornado.routing.Rule\"\"\"\n\n            request_handler = args[0]\n            cookie = acquire_cookie(request_handler)\n            if invalid_cookie(cookie):\n                return request_handler.send_error(status_code=401)\n                # raise tornado.web.HTTPError(401)\n\n            tokens = extract_tokens_from_cookie(cookie)\n            if not tokens:\n                return request_handler.send_error(status_code=401)\n                # raise tornado.web.HTTPError(401)\n\n            id_payload = await verify_tokens(tokens, client)\n            if not id_payload:\n                return request_handler.send_error(status_code=401)\n                # raise tornado.web.HTTPError(401)\n\n            kwargs = {\"auth_data\": id_payload, **kwargs}\n\n            return await handler_method(*args, **kwargs)\n        return request_handler_wrapper\n    return wrapper\n\n  \ndef acquire_cookie(request_handler):\n    return request_handler.get_cookie(cookie_name)\n\n\ndef invalid_cookie(cookie):\n    if not cookie:\n        return True\n    if cookie.find('access_token') == -1:\n        return True\n    return False\n\n\ndef extract_tokens_from_cookie(cookie):\n    p = re.compile(r'id_token=(?P\u003cid_token\u003e.+),access_token=(?P\u003caccess_token\u003e.+),refresh_token=(?P\u003crefresh_token\u003e.+)')  # noqa\n    tokens = p.search(cookie)\n    return tokens\n\n\ndef build_endpoint(host, path) -\u003e str:\n    not_prod = settings.get('cluster') != 'prod'\n    buzzfeed = 'buzzfeed.com' in host\n    gateway = re.search('api-(?:public-)?stage.buzzfeed.com', host)\n\n    if not_prod and buzzfeed and not gateway:\n        creds = '{}:{}'.format(webapp_stage_user, webapp_stage_pass)\n        host = '{}@{}'.format(creds, host)\n\n    return 'https://{}{}'.format(host, path)\n\n\nasync def verify_tokens(tokens, api_gateway):\n    if not tokens:\n        return\n\n    api_path = '/bfauth/tokens/verify'\n    endpoint = build_endpoint(api_gateway_host, api_path)\n\n    post_data = {'id_token': tokens.group('id_token'),\n                 'access_token': tokens.group('access_token'),\n                 'refresh_token': tokens.group('refresh_token')}\n\n    body = urllib.parse.urlencode(post_data)\n\n    try:\n        response = await api_gateway.post(endpoint, body=body, debug=debug, request_timeout=10)\n    except bf_api_gateway.errors.BackoffError as err:\n        metrics.incr(\"verify_tokens\", tags={\"service\": service,\n                                            \"status\": \"error\",\n                                            \"context\": \"{}. {}\".format(type(err), str(err))})\n        return\n    except bf_api_gateway.errors.APIGatewayError as err:\n        metrics.incr(\"verify_tokens\", tags={\"service\": service,\n                                            \"status\": \"error\",\n                                            \"context\": \"{}. {}\".format(type(err), str(err))})\n        return\n\n    try:\n        response_data = json.loads(response.body)\n    except Exception as err:\n        metrics.incr(\"verify_tokens\", tags={\"service\": service,\n                                            \"status\": \"error\",\n                                            \"context\": \"{}. {}\".format(type(err), str(err))})\n        return\n\n    if response_data.get('status') == 'error':\n        metrics.incr(\"verify_tokens\", tags={\"service\": service,\n                                            \"status\": \"error\",\n                                            \"context\": \"status returned error\"})\n        return\n\n    return response_data.get('payload')\n\nclass AuthTest(tornado.web.RequestHandler):\n    @auth('get', client=mock_apigateway)\n    async def get(self, *args, **kwargs):\n        \"\"\" kwargs = {\"auth_data\": \"...\", \"path\": \"protected\"} \"\"\"\n        self.finish(kwargs)\n\nreturn tornado.web.Application([\n    (r'/(?P\u003cpath\u003eprotected)', AuthTest),\n])\n\n@mock.patch(\"bf_auth.subject.build_endpoint\")\ndef test_successful_authentication(self, mock_endpoint):\n    \"\"\"Test a cookie is acquired, and the tokens are extracted and verified.\"\"\"\n\n    mock_cookie = 'mycookiename=id_token=1,access_token=2,refresh_token=3;'\n    mock_endpoint.return_value = 'https://example-api.com'\n    mock_apigateway.post.side_effect = mock_verify_tokens_success\n\n    response = self.fetch('/protected', headers={\"Cookie\": mock_cookie})\n    assert response.code == 200\n\n    # Python 3.5 doesn't guarantee dictionary ordering, so we use json sort_keys\n    actual = json.dumps(json.loads(response.body.decode()), sort_keys=True)\n    expected = '{\"auth_data\": \"foobar\", \"path\": \"protected\"}'\n    assert actual == expected\n","tags":"#python #decorator #tornado #dict #compare"},{"id":"66f50ed461f12157419a13152436b5e4","title":"[Distributed Tracing] ","content":"Distributed Tracing is the process of tracking and analyzing what happens to a request (transaction) across all services it touches.\n\n- **Transaction**: request\n- **Trace ID**: unique request identifier\n- **Trace**: entire transaction (across all services)\n- **Span**: logical chunk of work in a given 'Trace'\n\nSpans have parent-child relationships. A parent can have multiple children. The first span is the \"root span\". Each span has an ID and a pointer to its parent span ID.\n\n\u003e Note: this information was found on the [Nike engineering blog](https://medium.com/nikeengineering/hit-the-ground-running-with-distributed-tracing-core-concepts-ff5ad47c7058)\n","tags":"#distributed #tracing"},{"id":"16707fd0b9f1869f479325ea8dab90e6","title":"[Python Exception Handling Attributes] ","content":"import structlog\n\nstructlogger = structlog.getLogger(__name__)\n\ntry:\n    nonexistent()  # NameError\nexcept Exception as err:\n    structlogger.error('exception', \n                       exc_type=err.__class__.__name__, \n                       exc_msg=str(err), \n                       orig_err=err)\n    \n\"\"\"\n2018-08-31 11:46.17 exception exc_msg=name 'nonexistent' is not defined exc_type=NameError orig_err=NameError(\"name 'nonexistent' is not defined\",)\n\"\"\"\n\n#########################\n\nstructlog.configure(cache_logger_on_first_use=True,\n                    context_class=dict,\n                    logger_factory=structlog.stdlib.LoggerFactory(),\n                    processors=[structlog.stdlib.add_logger_name,\n                                structlog.stdlib.add_log_level,\n                                structlog.processors.TimeStamper(fmt=\"%Y-%m-%d %H:%M.%S\"),\n                                structlog.processors.JSONRenderer(sort_keys=True)])\n\ntry:\n    nonexistent()  # NameError\nexcept Exception as err:\n    structlogger.error('exception', \n                       exc_type=err.__class__.__name__, \n                       exc_msg=str(err), \n                       orig_err=err)\n    \n{\n  \"event\": \"exception\", \n  \"exc_msg\": \"name 'nonexistent' is not defined\", \n  \"exc_type\": \"NameError\", \n  \"level\": \"error\", \n  \"logger\": \"__main__\", \n  \"orig_err\": \"NameError(\\\"name 'nonexistent' is not defined\\\",)\", \n  \"timestamp\": \"2018-08-31 10:51.19\"\n}\n","tags":"#python #exceptions"},{"id":"6d0ee04eb68ecfdaab8509b1eccadc98","title":"[Memory Sharing] ","content":"ECS Task has memory allocation of 500mb.\n\nIt's a multi-process tornado service with 4 processes.\n\nEach process is reporting 200+ mb of RSS (resident) memory usage, which would mean total memory should be larger than 500mb.\n\nBut as processes share memory, the total RSS is likely to be the sum of the memory shared across all child processes + the \"unique\" memory used by each child process as they diverge from one another.\n","tags":"#python #rss #resident #virtual #memory"},{"id":"cfd543d2fb68eb2f14c3f02d14f64226","title":"[Sed Ignore Lines] ","content":"# imagine you have multiple lines (non-deterministically generated):\n#\n# server 127.0.0.1; other stuff\n# server 127.2.2.2:2222; other stuff\n#\n# to replace the second line and not the first, you can use the /.../! syntax\n# this says \"as long as the first pattern doesn't match, go ahead and try the substitution\"\n#\n# sed -i '/some_pattern_to_ignore/! s/some_pattern_to_match/the_replacement_for_the_match/g' /nginx.conf\n\nsed -i '/server 127.0.0.1/! s/server [^:]\\+:[^;]\\+/server 127.0.0.1:9000/g' /nginx.conf\n","tags":"#sed #ignore #regex #patterns"},{"id":"8da2dfefd8b41c0d8e4f39be5251ad3d","title":"[Compile NGINX from source, including its dependencies] ","content":"FROM python:3.6.3-slim\n\n# Installing NGINX (open-source):\n# https://docs.nginx.com/nginx/admin-guide/installing-nginx/installing-nginx-open-source/#sources\n#\n# Locating available versions to build:\n# http://nginx.org/download/\n\n# Dependencies:\n#\n# NGINX: pcre, zlib, openssl (+ libssl-dev), build-essential (for c compiler)\nRUN apt-get update \u0026\u0026 apt-get install -y wget libpcre3 libpcre3-dev zlib1g zlib1g-dev openssl libssl-dev build-essential\n\n# Check Python\nRUN python3 --version \u0026\u0026 pip3 --version\nCOPY ./requirements.txt /tmp/\nRUN pip3 install -r /tmp/requirements.txt\n\n# Compile NGINX (open-source)\nWORKDIR /\nENV nginx_version=\"1.15.2\"\nRUN wget https://nginx.org/download/nginx-${nginx_version}.tar.gz\nRUN tar zxf nginx-${nginx_version}.tar.gz\nWORKDIR nginx-${nginx_version}\nRUN ./configure \\\n      --user=www-data \\\n      --group=www-data \\\n      --with-pcre-jit \\\n      --with-debug \\\n      --with-http_ssl_module \\\n      --with-http_stub_status_module \\\n      --with-http_realip_module\n\n# Possible future configuration addition:\n# https://www.nginx.com/blog/thread-pools-boost-performance-9x/\n\nRUN make\nRUN make install\nENV PATH=\"/nginx-${nginx_version}/objs:$PATH\"\n\nWORKDIR /\nCOPY . /app\n\nCMD python /app/template.py nginx.conf.j2 /nginx.conf \u0026\u0026 nginx -c /nginx.conf\nFROM python:3.6.3-slim\n\n# Dependencies\n# NGINX: pcre, zlib, openssl (+ libssl-dev), build-essential (for c compiler)\n# RUN apt-get update \u0026\u0026 apt-get install -y wget libpcre3 libpcre3-dev zlib1g zlib1g-dev openssl libssl-dev build-essential\nRUN apt-get update \u0026\u0026 apt-get install -y wget build-essential\n\n# Check Python\nRUN python3 --version \u0026\u0026 pip3 --version\nCOPY ./requirements.txt /tmp/\nRUN pip3 install -r /tmp/requirements.txt\n\n# Installing NGINX (open-source)\n# https://docs.nginx.com/nginx/admin-guide/installing-nginx/installing-nginx-open-source/#sources\n\n# PCRE\nWORKDIR /\nENV pcre_version=\"8.42\"\nRUN wget ftp://ftp.csx.cam.ac.uk/pub/software/programming/pcre/pcre-${pcre_version}.tar.gz\nRUN tar -zxf pcre-${pcre_version}.tar.gz\nWORKDIR pcre-${pcre_version}\nRUN ./configure\nRUN make\nRUN make install\n\n# zlib\nWORKDIR /\nENV zlib_version=\"1.2.11\"\nRUN wget http://zlib.net/zlib-${zlib_version}.tar.gz\nRUN tar -zxf zlib-${zlib_version}.tar.gz\nWORKDIR zlib-${zlib_version}\nRUN ./configure\nRUN make\nRUN make install\n\n# OpenSSL\nWORKDIR /\nENV openssl_version=\"1.0.2o\"\nRUN wget http://www.openssl.org/source/openssl-${openssl_version}.tar.gz\nRUN tar -zxf openssl-${openssl_version}.tar.gz\nWORKDIR openssl-${openssl_version}\n# RUN ./Configure LIST\nRUN ./Configure linux-x86_64 --prefix=/usr\nRUN make\nRUN make install\n\n# NGINX (open-source) http://nginx.org/download/\nWORKDIR /\nENV nginx_version=\"1.15.2\"\nRUN wget https://nginx.org/download/nginx-${nginx_version}.tar.gz\nRUN tar zxf nginx-${nginx_version}.tar.gz\nWORKDIR nginx-${nginx_version}\nRUN ./configure \\\n      --user=www-data \\\n      --group=www-data \\\n      --with-pcre-jit \\\n      --with-debug \\\n      --with-http_ssl_module \\\n      --with-http_stub_status_module \\\n      --with-http_realip_module\n\n# Possible future configuration addition:\n# https://www.nginx.com/blog/thread-pools-boost-performance-9x/\n\nRUN make\nRUN make install\nENV PATH=\"/nginx-${nginx_version}/objs:$PATH\"\n\nWORKDIR /\nCOPY . /app\n\nCMD nginx -v\n","tags":"#nginx #open-source #compile #build"},{"id":"b7d50026b01e3a2f613a4c263a913ef9","title":"[Python Get Function Name Dynamically At Runtime] ","content":"import inspect\nimport logging\n\ndef logit():\n  # go back once in the stack to find the caller of this function\n  # e.g. either foo or bar\n  logging.warning(inspect.stack()[1].function)\n\ndef foo():\n    print(inspect.stack()[0])\n    print(inspect.stack()[0].function)  # foo\n    logit()\n    \n    def bar():\n        print(\"\\n\\n\", inspect.stack()[0])\n        print(inspect.stack()[0].function)  # bar\n        logit()\n        \n    bar()\n\nfoo() # kick start the call chain\n","tags":"#python #inspect #stack"},{"id":"364ee91f21df42fc0673749966600775","title":"[API Documentation Example] ","content":"# Example Auth API\n\nA standalone HTTP service that handles authenticating users between AWS Cognito and the legacy WebApp.\n\n## Location\n\nThe Example Auth API is available through the API Gateway at these URL prefixes:\n\n - https://api.example.com/auth (production)\n - https://api-stage.example.com/auth (staging)\n\n## Endpoints\n\n- [`/account/confirm`](#accountconfirm)\n- [`/admin/email/change`](#adminemailchange)\n- [`/admin/status/change`](#adminstatuschange)\n- [`/admin/user/create`](#adminusercreate)\n- [`/admin/user/get`](#adminuserget)\n- [`/email/change`](#emailchange)\n- [`/email/confirm`](#emailconfirm)\n- [`/password/change`](#passwordchange)\n- [`/password/confirm`](#passwordconfirm)\n- [`/signin`](#signin)\n- [`/signin/social`](#signinsocial)\n- [`/signout`](#signout)\n- [`/tokens/verify`](#tokensverify)\n- [`/user/signup`](#usersignup)\n- [`/users/filter/email`](#usersfilteremail)\n- [`/users/filter/username`](#usersfilterusername)\n\n### `/account/confirm`\n\nConfirms registration of a user (i.e. they're 'verified').\n\n#### Request\n\n`POST https://api.example.com/auth/account/confirm`\n\n#### Headers\n\n- `Content-Type: application/x-www-form-urlencoded` (required)\n\n#### Body\n\n```\ncode=...\u0026username=...\n```\n\n#### Params\n\n- `code`: verification code (provided by AWS)\n- `username`: user to verify\n\n#### Successful Response\n\n```\n200 OK\n```\n```json\n{\n  \"status\": \"success\"\n}\n```\n\n#### Errors\n\n| Status | Message | Notes |\n|--------|---------|-------|\n| `400`  | `MISSING_PARAMS` | |\n| `400`  | `SIGN_UP_CONFIRMATION_FAILED` | Multiple causes, [see AWS documentation](https://docs.aws.amazon.com/cognito-user-identity-pools/latest/APIReference/API_ConfirmSignUp.html#API_ConfirmSignUp_Errors) |\n| `500`  | `SIGN_UP_CONFIRMATION_FAILED` | AWS has returned an internal server error |\n\n\u003e Note: more specific exception information is logged.\n\nEvery error response takes the form\n\n```json\n{\n  \"status\": \"error\",\n  \"code\": ERROR_STATUS_CODE,\n  \"context\": \"ERROR_MESSAGE\"\n}\n```\n\n### `/admin/email/change`\n\n...\n\n#### Request\n\n`METHOD https://api.example.com/auth/...`\n\n#### Headers\n\n- `Content-Type: application/x-www-form-urlencoded` (required)\n\n#### Body\n\n```\nkey=value\u0026key=value\n```\n\n#### Params\n\n- `...`: ...\n\n#### Successful Response\n\n```\n200 OK\n```\n```json\n{\n  \"status\": \"success\"\n}\n```\n\n#### Errors\n\n| Status | Message | Notes |\n|--------|---------|-------|\n| `400`  | `SOME_THING` | ... |\n| `400`  | `SOME_OTHER_THING` ||\n\n\u003e Note: more specific exception information is logged.\n\nEvery error response takes the form\n\n```json\n{\n  \"status\": \"error\",\n  \"code\": ERROR_STATUS_CODE,\n  \"context\": \"ERROR_MESSAGE\"\n}\n```\n\n### `/admin/status/change`\n\n...\n\n#### Request\n\n`METHOD https://api.example.com/auth/...`\n\n#### Headers\n\n- `Content-Type: application/x-www-form-urlencoded` (required)\n\n#### Body\n\n```\nkey=value\u0026key=value\n```\n\n#### Params\n\n- `...`: ...\n\n#### Successful Response\n\n```\n200 OK\n```\n```json\n{\n  \"status\": \"success\"\n}\n```\n\n#### Errors\n\n| Status | Message | Notes |\n|--------|---------|-------|\n| `400`  | `SOME_THING` | ... |\n| `400`  | `SOME_OTHER_THING` ||\n\n\u003e Note: more specific exception information is logged.\n\nEvery error response takes the form\n\n```json\n{\n  \"status\": \"error\",\n  \"code\": ERROR_STATUS_CODE,\n  \"context\": \"ERROR_MESSAGE\"\n}\n```\n\n### `/admin/user/create`\n\n...\n\n#### Request\n\n`METHOD https://api.example.com/auth/...`\n\n#### Headers\n\n- `Content-Type: application/x-www-form-urlencoded` (required)\n\n#### Body\n\n```\nkey=value\u0026key=value\n```\n\n#### Params\n\n- `...`: ...\n\n#### Successful Response\n\n```\n200 OK\n```\n```json\n{\n  \"status\": \"success\"\n}\n```\n\n#### Errors\n\n| Status | Message | Notes |\n|--------|---------|-------|\n| `400`  | `SOME_THING` | ... |\n| `400`  | `SOME_OTHER_THING` ||\n\n\u003e Note: more specific exception information is logged.\n\nEvery error response takes the form\n\n```json\n{\n  \"status\": \"error\",\n  \"code\": ERROR_STATUS_CODE,\n  \"context\": \"ERROR_MESSAGE\"\n}\n```\n\n### `/admin/user/get`\n\n...\n\n#### Request\n\n`METHOD https://api.example.com/auth/...`\n\n#### Headers\n\n- `Content-Type: application/x-www-form-urlencoded` (required)\n\n#### Body\n\n```\nkey=value\u0026key=value\n```\n\n#### Params\n\n- `...`: ...\n\n#### Successful Response\n\n```\n200 OK\n```\n```json\n{\n  \"status\": \"success\"\n}\n```\n\n#### Errors\n\n| Status | Message | Notes |\n|--------|---------|-------|\n| `400`  | `SOME_THING` | ... |\n| `400`  | `SOME_OTHER_THING` ||\n\n\u003e Note: more specific exception information is logged.\n\nEvery error response takes the form\n\n```json\n{\n  \"status\": \"error\",\n  \"code\": ERROR_STATUS_CODE,\n  \"context\": \"ERROR_MESSAGE\"\n}\n```\n\n### `/email/change`\n\n...\n\n#### Request\n\n`METHOD https://api.example.com/auth/...`\n\n#### Headers\n\n- `Content-Type: application/x-www-form-urlencoded` (required)\n\n#### Body\n\n```\nkey=value\u0026key=value\n```\n\n#### Params\n\n- `...`: ...\n\n#### Successful Response\n\n```\n200 OK\n```\n```json\n{\n  \"status\": \"success\"\n}\n```\n\n#### Errors\n\n| Status | Message | Notes |\n|--------|---------|-------|\n| `400`  | `SOME_THING` | ... |\n| `400`  | `SOME_OTHER_THING` ||\n\n\u003e Note: more specific exception information is logged.\n\nEvery error response takes the form\n\n```json\n{\n  \"status\": \"error\",\n  \"code\": ERROR_STATUS_CODE,\n  \"context\": \"ERROR_MESSAGE\"\n}\n```\n\n### `/email/confirm`\n\n...\n\n#### Request\n\n`METHOD https://api.example.com/auth/...`\n\n#### Headers\n\n- `Content-Type: application/x-www-form-urlencoded` (required)\n\n#### Body\n\n```\nkey=value\u0026key=value\n```\n\n#### Params\n\n- `...`: ...\n\n#### Successful Response\n\n```\n200 OK\n```\n```json\n{\n  \"status\": \"success\"\n}\n```\n\n#### Errors\n\n| Status | Message | Notes |\n|--------|---------|-------|\n| `400`  | `SOME_THING` | ... |\n| `400`  | `SOME_OTHER_THING` ||\n\n\u003e Note: more specific exception information is logged.\n\nEvery error response takes the form\n\n```json\n{\n  \"status\": \"error\",\n  \"code\": ERROR_STATUS_CODE,\n  \"context\": \"ERROR_MESSAGE\"\n}\n```\n\n### `/password/change`\n\n...\n\n#### Request\n\n`METHOD https://api.example.com/auth/...`\n\n#### Headers\n\n- `Content-Type: application/x-www-form-urlencoded` (required)\n\n#### Body\n\n```\nkey=value\u0026key=value\n```\n\n#### Params\n\n- `...`: ...\n\n#### Successful Response\n\n```\n200 OK\n```\n```json\n{\n  \"status\": \"success\"\n}\n```\n\n#### Errors\n\n| Status | Message | Notes |\n|--------|---------|-------|\n| `400`  | `SOME_THING` | ... |\n| `400`  | `SOME_OTHER_THING` ||\n\n\u003e Note: more specific exception information is logged.\n\nEvery error response takes the form\n\n```json\n{\n  \"status\": \"error\",\n  \"code\": ERROR_STATUS_CODE,\n  \"context\": \"ERROR_MESSAGE\"\n}\n```\n\n### `/password/confirm`\n\n...\n\n#### Request\n\n`METHOD https://api.example.com/auth/...`\n\n#### Headers\n\n- `Content-Type: application/x-www-form-urlencoded` (required)\n\n#### Body\n\n```\nkey=value\u0026key=value\n```\n\n#### Params\n\n- `...`: ...\n\n#### Successful Response\n\n```\n200 OK\n```\n```json\n{\n  \"status\": \"success\"\n}\n```\n\n#### Errors\n\n| Status | Message | Notes |\n|--------|---------|-------|\n| `400`  | `SOME_THING` | ... |\n| `400`  | `SOME_OTHER_THING` ||\n\n\u003e Note: more specific exception information is logged.\n\nEvery error response takes the form\n\n```json\n{\n  \"status\": \"error\",\n  \"code\": ERROR_STATUS_CODE,\n  \"context\": \"ERROR_MESSAGE\"\n}\n```\n\n### `/signin`\n\n...\n\n#### Request\n\n`METHOD https://api.example.com/auth/...`\n\n#### Headers\n\n- `Content-Type: application/x-www-form-urlencoded` (required)\n\n#### Body\n\n```\nkey=value\u0026key=value\n```\n\n#### Params\n\n- `...`: ...\n\n#### Successful Response\n\n```\n200 OK\n```\n```json\n{\n  \"status\": \"success\"\n}\n```\n\n#### Errors\n\n| Status | Message | Notes |\n|--------|---------|-------|\n| `400`  | `SOME_THING` | ... |\n| `400`  | `SOME_OTHER_THING` ||\n\n\u003e Note: more specific exception information is logged.\n\nEvery error response takes the form\n\n```json\n{\n  \"status\": \"error\",\n  \"code\": ERROR_STATUS_CODE,\n  \"context\": \"ERROR_MESSAGE\"\n}\n```\n\n### `/signin/social`\n\n...\n\n#### Request\n\n`METHOD https://api.example.com/auth/...`\n\n#### Headers\n\n- `Content-Type: application/x-www-form-urlencoded` (required)\n\n#### Body\n\n```\nkey=value\u0026key=value\n```\n\n#### Params\n\n- `...`: ...\n\n#### Successful Response\n\n```\n200 OK\n```\n```json\n{\n  \"status\": \"success\"\n}\n```\n\n#### Errors\n\n| Status | Message | Notes |\n|--------|---------|-------|\n| `400`  | `SOME_THING` | ... |\n| `400`  | `SOME_OTHER_THING` ||\n\n\u003e Note: more specific exception information is logged.\n\nEvery error response takes the form\n\n```json\n{\n  \"status\": \"error\",\n  \"code\": ERROR_STATUS_CODE,\n  \"context\": \"ERROR_MESSAGE\"\n}\n```\n\n### `/signout`\n\n...\n\n#### Request\n\n`METHOD https://api.example.com/auth/...`\n\n#### Headers\n\n- `Content-Type: application/x-www-form-urlencoded` (required)\n\n#### Body\n\n```\nkey=value\u0026key=value\n```\n\n#### Params\n\n- `...`: ...\n\n#### Successful Response\n\n```\n200 OK\n```\n```json\n{\n  \"status\": \"success\"\n}\n```\n\n#### Errors\n\n| Status | Message | Notes |\n|--------|---------|-------|\n| `400`  | `SOME_THING` | ... |\n| `400`  | `SOME_OTHER_THING` ||\n\n\u003e Note: more specific exception information is logged.\n\nEvery error response takes the form\n\n```json\n{\n  \"status\": \"error\",\n  \"code\": ERROR_STATUS_CODE,\n  \"context\": \"ERROR_MESSAGE\"\n}\n```\n\n### `/tokens/verify`\n\n...\n\n#### Request\n\n`METHOD https://api.example.com/auth/...`\n\n#### Headers\n\n- `Content-Type: application/x-www-form-urlencoded` (required)\n\n#### Body\n\n```\nkey=value\u0026key=value\n```\n\n#### Params\n\n- `...`: ...\n\n#### Successful Response\n\n```\n200 OK\n```\n```json\n{\n  \"status\": \"success\"\n}\n```\n\n#### Errors\n\n| Status | Message | Notes |\n|--------|---------|-------|\n| `400`  | `SOME_THING` | ... |\n| `400`  | `SOME_OTHER_THING` ||\n\n\u003e Note: more specific exception information is logged.\n\nEvery error response takes the form\n\n```json\n{\n  \"status\": \"error\",\n  \"code\": ERROR_STATUS_CODE,\n  \"context\": \"ERROR_MESSAGE\"\n}\n```\n\n### `/user/signup`\n\n...\n\n#### Request\n\n`METHOD https://api.example.com/auth/...`\n\n#### Headers\n\n- `Content-Type: application/x-www-form-urlencoded` (required)\n\n#### Body\n\n```\nkey=value\u0026key=value\n```\n\n#### Params\n\n- `...`: ...\n\n#### Successful Response\n\n```\n200 OK\n```\n```json\n{\n  \"status\": \"success\"\n}\n```\n\n#### Errors\n\n| Status | Message | Notes |\n|--------|---------|-------|\n| `400`  | `SOME_THING` | ... |\n| `400`  | `SOME_OTHER_THING` ||\n\n\u003e Note: more specific exception information is logged.\n\nEvery error response takes the form\n\n```json\n{\n  \"status\": \"error\",\n  \"code\": ERROR_STATUS_CODE,\n  \"context\": \"ERROR_MESSAGE\"\n}\n```\n\n### `/users/filter/email`\n\n...\n\n#### Request\n\n`METHOD https://api.example.com/auth/...`\n\n#### Headers\n\n- `Content-Type: application/x-www-form-urlencoded` (required)\n\n#### Body\n\n```\nkey=value\u0026key=value\n```\n\n#### Params\n\n- `...`: ...\n\n#### Successful Response\n\n```\n200 OK\n```\n```json\n{\n  \"status\": \"success\"\n}\n```\n\n#### Errors\n\n| Status | Message | Notes |\n|--------|---------|-------|\n| `400`  | `SOME_THING` | ... |\n| `400`  | `SOME_OTHER_THING` ||\n\n\u003e Note: more specific exception information is logged.\n\nEvery error response takes the form\n\n```json\n{\n  \"status\": \"error\",\n  \"code\": ERROR_STATUS_CODE,\n  \"context\": \"ERROR_MESSAGE\"\n}\n```\n\n### `/users/filter/username`\n\n...\n\n#### Request\n\n`METHOD https://api.example.com/auth/...`\n\n#### Headers\n\n- `Content-Type: application/x-www-form-urlencoded` (required)\n\n#### Body\n\n```\nkey=value\u0026key=value\n```\n\n#### Params\n\n- `...`: ...\n\n#### Successful Response\n\n```\n200 OK\n```\n```json\n{\n  \"status\": \"success\"\n}\n```\n\n#### Errors\n\n| Status | Message | Notes |\n|--------|---------|-------|\n| `400`  | `SOME_THING` | ... |\n| `400`  | `SOME_OTHER_THING` ||\n\nEvery error response takes the form\n\n```json\n{\n  \"status\": \"error\",\n  \"code\": ERROR_STATUS_CODE,\n  \"context\": \"ERROR_MESSAGE\"\n}\n```\n","tags":"#API #documentation"},{"id":"b9aa8e225ade0f78fcb57e1852627785","title":"[SLI, SLO, SLA] ","content":"## SLI, SLO, SLA ?\n\nWhen building a service, we have a responsibility to define some baseline agreements as to the service’s expected uptime and performance. This document focuses on the various terminology that we use to define these values.\n\n- **Service Level Indicator (SLI)**  \n  What the service owner has chosen to measure progress towards their goal.  \n  e.g. What is good/bad service for your users.\n\n- **Service Level Objective (SLO)**  \n  What the service owner’s goal is for the given indicator.  \n  e.g. A percentage that tells how many SLI errors your service can have in a specific period of time.\n\n- **Service Level Agreement (SLA)**  \n  What the service owner is promising its users (typically the SLO + wiggle room).\n\n### Example\n\n- **Indicator**: request latency.\n- **Objective**: 99.5% of requests will be completed in 5ms.\n- **Agreement**: 99% of requests complete in 5ms or you get a refund.\n\nBelow is an alternative example where we state (via a Datadog graph) that if the average request latency over a 1hr period exceeds one second, then we have a ‘service’ issue and it’ll display with a red background. This will signify that we’ve failed our SLA which is defined as being less than one second.\n\nIf the average request latency over a 1hr period is greater than half a second, then we have a ‘team’ issue and it’ll display with an orange background. This will signify that we’ve failed our SLO which is defined as being less than half a second.\n\nIf the average request latency over a 1hr period is less than half a second, then we have no issues and it’ll display with a green background. This will signify that we’ve reached our SLO which is defined as being less than half a second.\n\n![](https://user-images.githubusercontent.com/180050/58465109-86187180-8126-11e9-94f0-d6e6402a5e47.png)\n","tags":"#SLI #SLO #SLA #Process #Service"},{"id":"095fbd52f488ca295ae9fd408973587a","title":"[Vim Arg List and Searching] ","content":"\u003e Reference: https://vim.fandom.com/wiki/Find_in_files_within_Vim\n\nStart vim:\n\n```bash\nvim\n```\n\nCheck arguments list is empty:\n\n```viml\n:args\n```\n\nAdd files from current directory:\n\n```viml\n:argadd *\n```\n\nClear the arguments list:\n\n```viml\n:argdelete *\n```\n\nAdd different glob of files:\n\n```viml\n:argadd .aws/**\n```\n\nSearch for pattern in files from the arguments list:\n\n```viml\n:vimgrep /^aws/j ##\n```\n\n\u003e Note: `##` represents the arg list + the `j` option isn't documented but apparently means \"don't jump to first match\".\n\nImprove performance of vimgrep using `:noautocmd`:\n\n```viml\n:noautocmd vimgrep /{pattern}/[flags] {file(s)}\n```\n\n\u003e vimgrep uses Vim's procedures to read files, which can involve execution of several autocommands. So disable autocommands.\n\nSearch for pattern in files from result of a backtick expression:\n\n```viml\n:vimgrep /ssh/j `find . -type f -name 'tmux*'`\n```\n\n\u003e Note: `j` tells Vim not to automatically jump to the first match\n\nSearch based on a previous search pattern:\n\n```viml\n:vimgrep /\u003cC-r\u003e// *\n```\n\nTo clarify the above command, imagine you have a complex pattern you want to play around with and test with a single file so you use `/` to get vim to jump into search mode for the current buffer content and then type in your complex pattern.\n\nOnce happy with your pattern, you now want to use it again for multiple files but you don't want to have to type the pattern out again (especially in case it's complex enough to easily include an unexpected typo).\n\nSo you type `:vimgrep /` and after that is where you would typically start typing your search pattern, at this point press `\u003cCtrl-r\u003e` followed by `/` and Vim will automatically insert the last search pattern for you.\n\nImagine `...` was the last search pattern, this would mean the Ex mode command would currently look like `:vimgrep /...` so you would need to finish the command `/ *` (so it's almost like you wrote the command in its entirety).\n\n\u003e Note: if you use another plugin like `:Ack!` then `\u003cC-r\u003e/` works to insert the last search pattern still (e.g. `:Ack! '\u003cC-r\u003e/'`)\n","tags":"#vim #vimgrep #arglist #search #regex"},{"id":"31bd757258a956d49c0504b36903e2d7","title":"[Python String Formatting] ","content":"## f-string\n\n```py\nf'approx pi: {math.pi:.3f}'  # 'approx pi: 3.142'\nf'approx pi: {math.pi:.10f}'  # 'approx pi: 3.1415926536'\n\n# padding...\nfoo = 'bar'\nbaz = 'qux'\n\nf'{foo:10}'  # 'bar       '\nf'{foo:10} =\u003e {baz}'  # 'bar        =\u003e qux'\n```\n\n## string .format()\n\n```py\n'{}'.format('foo')  # 'foo'\n'{1}'.format('foo', 'bar')  # 'bar'\n'{foo} {baz}'.format(foo='bar', baz='qux')  # 'bar qux'\n'{0[foo]} {0[baz]}'.format({'foo': 'bar', 'baz': 'qux'})  # 'bar qux'\n'{0[foo]:f} {0[baz]:f}'.format({'foo': 1.23, 'baz': 4.5})  # '1.230000 4.500000'\n```\n\n\u003e Note: in last example, if you would use the type to trigger an exception if the input didn't match: `'{0[foo]:f} {0[baz]:d}'.format({'foo': 1.23, 'baz': 4.5})` would raise a `ValueError: Unknown format code 'd' for object of type 'float'`.\n\n## traditional sprintf\n\n```py\n'foo%s' % 'bar'  # foobar\n'foo%(bar)s' % {'foo': 'FOO', 'bar': 'BAR'}  # fooBAR\n'num: %f' % 1.2  # 'num: 1.200000'\n'pi: %5.3f' % math.pi  # 'pi: 3.142'\n```\n","tags":"#python #string #formatting"},{"id":"4f7d9498070f530c50d005d16bb019c5","title":"[Python TTL Cache Decorator] ","content":"from datetime import datetime, timedelta\nfrom functools import wraps\nfrom tornado.httpclient import AsyncHTTPClient\n\nAsyncHTTPClient.configure(None, defaults=dict(user_agent=\"YourService\"))\nhttp_client = AsyncHTTPClient()\n\ndef network_cache(fn):\n    \"\"\"Cache asynchronous network requests based on cache-control.\n\n    Expects decorated function to have received an `endpoint` keyword parameter\n    and to return a dict containing the keys `cache_control` and\n    `response_body`.\n    \"\"\"\n\n    _cache = {}\n\n    @wraps(fn)\n    async def wrapper(*args, **kwargs):\n        key = kwargs.get('endpoint')\n\n        if key not in _cache:\n            # call function and cache off the response\n            result = await fn(*args, **kwargs)\n            cache_control = result.get('cache_control', 0)\n            body = result.get('response_body')\n            _cache[key] = {'ttl': cache_control,\n                           'value': body,\n                           'timestamp': datetime.now().timestamp()}\n        else:\n            # check the cached content ttl before returning\n            ts = _cache[key]['timestamp']\n            ts_datetime = datetime.fromtimestamp(ts)\n            delta = datetime.now() - ts_datetime\n\n            # if ttl has expired, make request and cache response\n            ttl = _cache[key]['ttl']\n            if delta.days \u003e timedelta(seconds=ttl).days:\n                del _cache[key]\n                \n                result = await fn(*args, **kwargs)\n                cache_control = result.get('cache_control', 0)\n                body = result.get('response_body')\n                _cache[key] = {'ttl': cache_control,\n                               'value': body,\n                               'timestamp': datetime.now().timestamp()}\n\n        return _cache[key]['value']\n    return wrapper\n  \n@network_cache\nasync def get_keys(endpoint=user_pool_jwk):\n    \"\"\"Retrieve JWK (for verifying tokens).\n\n    If successful we return a dict consisting of the cache-control response\n    header value and the actual list of JWKs.\n\n    If unsuccessful we return the standard dictionary error format.\n    \"\"\"\n\n    response = await http_client.fetch(endpoint)\n    cache_control = response.headers.get('Cache-Control')\n\n    match = re.search(r'max-age=(\\d+)', cache_control)\n    if not match:\n        msg = 'JWK_RESPONSE_INVALID'\n        gen_exc = exceptions.AsyncFetchException(msg, code=response.code)\n        instr_exc(gen_exc, msg, cache_control=cache_control)\n        raise gen_exc\n\n    if response.code != 200:\n        raise exceptions.AsyncFetchException('JWK_RESPONSE_INVALID', code=response.get('code'))\n\n    try:\n        response_data = json.loads(response.body)\n    except Exception as exc:\n        msg = 'JSON_PARSING_FAILED'\n        instr_exc(exc, msg, endpoint=endpoint, body=response.body)\n        return {'state': 'error',\n                'code': 500,\n                'message': msg}\n\n    return {'state': 'success',\n            'cache_control': match,\n            'response_body': response_data.get('keys', [])}\n# standard library modules\n\nimport unittest.mock as mock\nimport sys\n\nfrom collections import namedtuple\nfrom datetime import datetime, timedelta\n\n# external modules\n\nimport tornado.testing\n\n# configuration\n\nsys.path.insert(0, '/app')\n\n# application modules\n\nimport app.aws\nimport app.network\n\n\n# helpers\n\ndef make_coroutine(response):\n    async def coroutine(*args, **kwargs):\n        return response\n    return coroutine\n\n\n# asynchronous tests\n\nclass TestPassword(tornado.testing.AsyncTestCase):\n    @mock.patch('app.network.datetime', wraps=datetime)\n    @mock.patch('app.network.instr')\n    @mock.patch('app.network.http_client')\n    @tornado.testing.gen_test\n    def test_network_cache_decorator(self, mock_http_client, mock_instr, mock_datetime):\n        \"\"\"Verify decorated function caches its network request.\"\"\"\n\n        fetch_body = '{\"keys\":[\"foo\"]}'\n        fetch_code = 200\n        fetch_headers = {'Cache-Control': 'public, max-age=86400'}\n        fetch_response = namedtuple('_', ['body', 'code', 'headers'])(fetch_body, fetch_code, fetch_headers)\n\n        mock_http_client.fetch = make_coroutine(fetch_response)\n\n        endpoint = 'https://example.com/foo'\n        response = yield app.aws.get_keys(endpoint=endpoint)\n\n        assert response == {'state': 'success', 'cache_control': '86400', 'response_body': ['foo']}\n        mock_instr.assert_called_with('JWK_CACHE_MISS', metric_name='jwk.cache', state='miss', key=endpoint)\n\n        response = yield app.aws.get_keys(endpoint=endpoint)\n        assert response == {'state': 'success', 'cache_control': '86400', 'response_body': ['foo']}\n        mock_instr.assert_called_with('JWK_CACHE_HIT', metric_name='jwk.cache', state='hit', key=endpoint)\n\n        # mock datetime.now to return a current date that's actually two months ahead of now\n        mock_datetime.now.return_value = datetime.now() + timedelta(days=60)\n\n        # this request should result with the cache being invalidated (i.e. hit/expiry/population)\n        response = yield app.aws.get_keys(endpoint=endpoint)\n        assert response == {'state': 'success', 'cache_control': '86400', 'response_body': ['foo']}\n\n        # reset the mock datetime.now behaviour to its default behaviour\n        mock_datetime.now.side_effect = datetime.now\n\n        # this request should once again get a cache hit\n        response = yield app.aws.get_keys(endpoint=endpoint)\n        assert response == {'state': 'success', 'cache_control': '86400', 'response_body': ['foo']}\n\n        fields = {'key': 'https://example.com/foo', 'metric_name': 'jwk.cache'}\n        assert mock_instr.call_args_list == [mock.call('JWK_CACHE_MISS', state='miss', **fields),\n                                             mock.call('JWK_CACHE_HIT', state='hit', **fields),\n                                             mock.call('JWK_CACHE_HIT', state='hit', **fields),\n                                             mock.call('JWK_CACHE_EXPIRY', state='expired', **fields),\n                                             mock.call('JWK_CACHE_POPULATION', state='populated', **fields),\n                                             mock.call('JWK_CACHE_HIT', state='hit', **fields)]\n","tags":"#python #decorator #async #ttl #cache"},{"id":"0548b4c9189653854cf4f06d0469c86f","title":"[Python Tornado UVLoop] ","content":"import asyncio\nimport tornado.httpserver\nimport tornado.ioloop\nimport tornado.platform.asyncio as tornado_asyncio\nimport tornado.web\nimport uvloop\n\n\nclass MainHandler(tornado.web.RequestHandler):\n    def get(self):\n        self.finish('hello world')\n\n\ndef make_app():\n    return tornado.web.Application([\n        (r'/', MainHandler),\n    ])\n\n\nif __name__ == '__main__':\n    # configuration for uvloop\n    asyncio.set_event_loop_policy(uvloop.EventLoopPolicy())\n    tornado_asyncio.AsyncIOMainLoop().install()  # not needed for tornado 5.0+\n\n    app = make_app()\n\n    # traditional tornado setup...\n    #\n    # app.listen(9000)\n    # tornado.ioloop.IOLoop.current().start()\n    server = tornado.httpserver.HTTPServer(app, xheaders=True)\n    server.listen(9000)\n\n    # configuration for uvloop\n    asyncio.get_event_loop().run_forever()\n","tags":"#python #tornado #uvloop"},{"id":"cc04c2c34a988be26e56fe2f3ea95aff","title":"[Python Interfaces via Protocols and Abstract Base Classes (with Metaclasses)] ","content":"Python is a strongly typed dynamic language, and so it has no support for the `interface` keyword.\n\n\u003e Note: some languages are weakly typed (JavaScript), some are strongly typed (Python) and some are statically typed (Go, Rust). Being strongly typed means you can't perform operations inappropriate to the type, so for example: in Python you can't add a number typed variable with a string typed variable.\n\nInstead, Python provides 'protocols' which are a bit like the interface support in Go. They're not strictly enforced, but if you implement specific magic methods you'll find a selection of builtin Python functions become available to use on objects they otherwise wouldn't necessarily support.\n\n## Example\n\nThis code doesn't work:\n\n```py\nclass Team:\n     def __init__(self, members):\n         self.members = members\n\nt = Team(['foo', 'bar', 'baz'])\n\nt.members  # ['foo', 'bar', 'baz']\n\nlen(t)  # TypeError: object of type 'Team' has no len()\n```\n\nBut if we implement the `__len__` magic method, we are now telling Python that we support the [`Sized` protocol](https://docs.python.org/3.7/library/collections.abc.html#collections.abc.Sized):\n\n```py\nclass Team:\n     def __init__(self, members):\n         self.members = members\n         \n     def __len__(self):\n         return len(self.members)\n\nt = Team(['foo', 'bar', 'baz'])\n\nt.members  # ['foo', 'bar', 'baz']\n\nlen(t)  # 3\n```\n\nThere are many different protocols, such as: `collections.abc.Iterator` which if we were to implement the `__iter__` and `__next__` magic methods, then we'd be able to use a `for` loop construct on our object:\n\n```py\nclass Team:\n    def __init__(self, members):\n        self.members = members\n\n    def __iter__(self, max=0):\n        self.n = 0\n        return self\n\n    def __next__(self):\n        if self.n \u003c len(self.members):\n            index = self.n\n            self.n += 1\n            return self.members[index]\n        else:\n            raise StopIteration\n\nt = Team(['foo', 'bar', 'baz'])\n\nfor member in t:\n    print(f't member: {member}')\n\nt member: foo\nt member: bar\nt member: baz\n```\n\n## Abstract Base Classes (ABCs)\n\nProtocols are useful but sometimes you require something that does indeed behave more like a traditional 'interface', and that's where ABCs can help us.\n\nThey are best explained by way of an example:\n\n```py\nimport abc\n\nclass Foo(abc.ABC):\n    @abc.abstractmethod\n    def bar(self):\n        pass\n        \nclass Thing(Foo):\n    pass\n    \nt = Thing()  # TypeError: Can't instantiate abstract class Thing with abstract methods bar\n```\n\n\u003e Note: we're subclassing directly from `abc.ABC` where that parent class is setting `abc.ABCMeta` as a [metaclass](https://docs.python.org/3.7/reference/datamodel.html#metaclasses) on itself (e.g. something like `class ABC(metaclass=ABCMeta)`) and so we could do that directly with our `Foo` class like so: `class Foo(metaclass=abc.ABCMeta)`. [Read below](#metaclasses) for more information on metaclasses.\n\nSo we can see from the above example code that we've enforced the `Foo` 'interface' onto the `Thing` object. If we want `Thing` to truly be a type of `Foo`, then it'll need to provide a concrete implementation of the `bar` method that the `Foo` 'interface' has defined, like so:\n\n```py\nimport abc\n\nclass Foo(abc.ABC):\n    @abc.abstractmethod\n    def bar(self):\n        pass\n        \nclass Thing(Foo):\n    def bar(self):\n        print('this is bar, i am a foo type')\n    \nt = Thing()  # no exception raised\n\nt.bar()  # this is bar, i am a foo type\n```\n\nWe can now also compare types using: `isinstance(t, Foo)`. Meaning if you have two classes and both of them implement the `bar` method, it doesn't automatically mean they are compatible types:\n\n```py\nimport abc\n\nclass Foo(abc.ABC):\n    @abc.abstractmethod\n    def bar(self):\n        pass\n\nclass Bar(abc.ABC):\n    @abc.abstractmethod\n    def bar(self):\n        pass\n        \nclass ThingA(Foo):\n    def bar(self):\n        print('this is bar, i am a foo type')\n        \nclass ThingB(Bar):\n    def bar(self):\n        print('this is bar, i am a bar type')\n    \nta = ThingA()\ntb = ThingB()\n\nisinstance(ta, Foo)  # True\nisinstance(ta, Bar)  # False\n\nisinstance(tb, Foo)  # False\nisinstance(tb, Bar)  # True\n```\n\nDo ABCs give us the full benefit of traditional interfaces? No. But they do help us move closer in that direction.\n\n## Metaclasses\n\nMetaclasses define default behaviours for an instance of a class.\n\nDoing this manually would look something like this:\n\n```py\ndef new(cls):\n    x = object.__new__(cls)\n    x.attr = 100\n    return x\n    \nclass Foo:\n    pass\n\nFoo.__new__ = new\n\nf = Foo()\nf.attr  # 100\n```\n\nBut this can also be done using a new 'meta' class and the `metaclass` keyword argument:\n\n```py\nclass Meta(type):\n    def __new__(cls, name, bases, dct):\n        x = super().__new__(cls, name, bases, dct)\n        x.attr = 100\n        return x\n        \nclass Foo(metaclass=Meta):\n    pass\n    \nf = Foo()\nf.attr  # 100\n```\n\nIn the same way that a class functions as a template for the creation of objects, a metaclass functions as a template for the creation of classes. Metaclasses are sometimes referred to as class factories.\n\nDo you need a metaclass for this silly example of ensuring the `attr` attribute is assigned to a unique class type? No. You could just use a class level variable:\n\n```py\nclass Base:\n    attr = 100\n\nclass X(Base):\n    pass\n\nclass Y(Base):\n    pass\n\nclass Z(Base):\n    pass\n    \nX.attr  # 100\nY.attr  # 100\nZ.attr  # 100\n```\n\nBut it's good to know about metaclasses as they underpin the `collections.abc` implementation of `abc.ABCMeta`.\n\n## References\n\n- [`collections.abc`](https://docs.python.org/3.7/library/collections.abc.html)\n- [Masnun Blog Post](http://masnun.rocks/2017/04/15/interfaces-in-python-protocols-and-abcs/)\n- [Metaclasses](https://realpython.com/python-metaclasses/)\n","tags":"#python #interfaces #protocols #design #collections #abc #iterator #sized #metaclasses #abstract"},{"id":"9817c8654a92df0cc887c21549b49356","title":"[Python pytest] ","content":"pytest -svv --color=yes\n\n# https://docs.pytest.org/\n## Exceptions\n\nIf you know a function raises an exception, then you can catch and assert against it by using `pytest.raises`\n\n```python\nwith pytest.raises(exceptions.CognitoException) as exc_info:\n        app.account.confirm(123, 'foo')\n        \nassert exc_info.typename == 'CognitoException'\nassert str(exc_info.value) == 'SIGNUP_CONFIRMATION_FAILED'\n```\n\n## Capturing Output\n\nSome functions (such as a command-line tool) only produce side effects (e.g. _output_) and don't necessarily _return_ a value to the caller. In order to test these types of functions Pytest let's us capture their output.\n\n```python\ndef test_my_function(capsys):\n    my_function()  # function that prints stuff\n    captured = capsys.readouterr()  # Capture output\n    assert f\"Received invalid message ...\" in captured.out  # Test stdout\n    assert f\"Fatal error ...\" in captured.err  # Test stderr\n```\n\nPytest provides a fixture called `capsys`, which captures system output. All you need to use it, is to add it as parameter to your test function. Next, after calling function that is being tested, you capture the outputs in form of tuple `(out, err)`, which you can then use to `assert` against. \n\n\u003e Note: you can't use this on a `tornado.testing.AsyncHTTPTestCase`.\n\n## Parametrize\n\nYou can use a table matrix to cause a test to be re-run multiple times with the same input arguments, but with different input _values_:\n\n```python\n@pytest.mark.parametrize(\"input, output\", [\n    (\"1234\", True),\n    (\"12345\", True),\n    (\"foo/bar1_baz2-qux3.beep\", False),\n    (\"\u003cbad_stuff\u003e\", False),\n    (\"/\u003cbad_stuff\u003e\", False),\n])\ndef test_valid_video_id(input, output):\n    assert valid_video_id(input) is output\n```\n\n\u003e Note: mock decorators come _before_ the pytest decorator (also you can't use parametrize on a `tornado.testing.AsyncHTTPTestCase`).\n","tags":"#pytest"},{"id":"ca30ae8a609f715aadf4f5a2b63ed239","title":"[Go Modules] ","content":"Go 1.11 introduced a new concept of 'Modules' which brings first class support for managing dependency versions and enabling reproducible builds.\n\nA Module is a way to group together a set of packages and give it a version number to mark its existence (state) at a specific point in time.\n\nGo Modules use Semantic Versioning for their numbering scheme.\n\nThink of a 'module' as a project repository. Your project consists of many packages, and a module allows you to adequately group and version them.\n\n## New Project\n\nMake a test project somewhere on your computer:\n\n```\nmkdir ~/code/test-project\n```\n\n\u003e Note: creating it outside of your `$GOPATH` demonstrates the process of using modules more clearly (in my case my `$GOPATH` is actually `~/code/go` and so I'm putting this project just outside of that).\n\nHere is our application, which uses one explicit non-standard library dependency (`logrus`):\n\n```go\npackage main\n\nimport (\n\t\"fmt\"\n\n\t\"github.com/sirupsen/logrus\"\n)\n\nfunc main() {\n\tlogrus.Info(\"a log\")\n\tfmt.Println(\"hello world\")\n}\n```\n\n## Creating Modules\n\nLet's now create a new module:\n\n```bash\n$ go mod init my-test-project\n\ngo: creating new go.mod: module my-test-project\n```\n\n\u003e Note: `my-test-project` is an arbitrary value, but most people use similar structure to what they're used to (e.g. `github.com/your_name/your_project`).\n\nLet's look at the `go.mod` module file that is created:\n\n```bash\n$ cat go.mod \n\nmodule my-test-project\n```\n\n## Build\n\nIf we try and build our application, the `go build` command will recognise we're inside of a module and parse any imports our code is referencing and download those into `$GOPATH/pkg/mod`\n\n```bash\n$ go build\n\ngo: finding github.com/sirupsen/logrus v1.2.0\ngo: downloading github.com/sirupsen/logrus v1.2.0\ngo: finding github.com/pmezard/go-difflib v1.0.0\ngo: finding github.com/konsorten/go-windows-terminal-sequences v1.0.1\ngo: finding github.com/davecgh/go-spew v1.1.1\ngo: finding github.com/stretchr/testify v1.2.2\ngo: finding github.com/stretchr/objx v0.1.1\ngo: finding golang.org/x/sys v0.0.0-20180905080454-ebe1bf3edb33\ngo: finding golang.org/x/crypto v0.0.0-20180904163835-0709b304e793\ngo: downloading golang.org/x/crypto v0.0.0-20180904163835-0709b304e793\ngo: downloading golang.org/x/sys v0.0.0-20180905080454-ebe1bf3edb33\n```\n\n## Dependency Location\n\nIf we check `$GOPATH/pkg/mod` we'll see everything installed:\n\n```bash\n$ tree -L 3 $GOPATH/pkg/mod\n\n/Users/markmcdonnell/code/go/pkg/mod\n├── cache\n│   ├── download\n│   │   ├── github.com\n│   │   └── golang.org\n│   └── vcs\n│       ├── 3b0ce44c45d17d58d917f0d7afa63ad02299664b3d7c8e3b3c6de03178872203\n│       ├── 3b0ce44c45d17d58d917f0d7afa63ad02299664b3d7c8e3b3c6de03178872203.info\n│       ├── 76a8992ccba6d77c6bcf031ff2b6d821cf232e4ad8d1f2362404fbd0a798d846\n│       ├── 76a8992ccba6d77c6bcf031ff2b6d821cf232e4ad8d1f2362404fbd0a798d846.info\n│       ├── 9950c06efbb2d90e85a58f1fbd6f3eb2db497b7c539a93fb5555656c5aba3c13\n│       ├── 9950c06efbb2d90e85a58f1fbd6f3eb2db497b7c539a93fb5555656c5aba3c13.info\n│       ├── b58cd1804573f08b6cfc86bbbad2960dd009cb14e98e8b74221958153f37a31b\n│       ├── b58cd1804573f08b6cfc86bbbad2960dd009cb14e98e8b74221958153f37a31b.info\n│       ├── b9a4b9bbdb4a59723f2348415ad7ffda91568455a1cfd92e97976132bdfbaf57\n│       ├── b9a4b9bbdb4a59723f2348415ad7ffda91568455a1cfd92e97976132bdfbaf57.info\n│       ├── ce05746539f15caa8470a1cb206cefcfc18421bcd2c6e35153546df051d6a96e\n│       ├── ce05746539f15caa8470a1cb206cefcfc18421bcd2c6e35153546df051d6a96e.info\n│       ├── de5fd3af413a4f3f969455ae522b4002fcb7bb4c158f339396dfc77710c9007d\n│       ├── de5fd3af413a4f3f969455ae522b4002fcb7bb4c158f339396dfc77710c9007d.info\n│       ├── ed2f58bca3966d01dc4666baa48276a4fab360938a8d941050d58e371e2bba77\n│       └── ed2f58bca3966d01dc4666baa48276a4fab360938a8d941050d58e371e2bba77.info\n├── github.com\n│   └── sirupsen\n│       └── logrus@v1.2.0\n└── golang.org\n    └── x\n        ├── crypto@v0.0.0-20180904163835-0709b304e793\n        └── sys@v0.0.0-20180905080454-ebe1bf3edb33\n```\n\n## Checksum\n\nIf we look at the `go.sum` file generated we'll see all the specific versions and hashed content:\n\n```bash\n$ cat go.sum\n\ngithub.com/davecgh/go-spew v1.1.1/go.mod h1:J7Y8YcW2NihsgmVo/mv3lAwl/skON4iLHjSsI+c5H38=\ngithub.com/konsorten/go-windows-terminal-sequences v1.0.1/go.mod h1:T0+1ngSBFLxvqU3pZ+m/2kptfBszLMUkC4ZK/EgS/cQ=\ngithub.com/pmezard/go-difflib v1.0.0/go.mod h1:iKH77koFhYxTK1pcRnkKkqfTogsbg7gZNVY4sRDYZ/4=\ngithub.com/sirupsen/logrus v1.2.0 h1:juTguoYk5qI21pwyTXY3B3Y5cOTH3ZUyZCg1v/mihuo=\ngithub.com/sirupsen/logrus v1.2.0/go.mod h1:LxeOpSwHxABJmUn/MG1IvRgCAasNZTLOkJPxbbu5VWo=\ngithub.com/stretchr/objx v0.1.1/go.mod h1:HFkY916IF+rwdDfMAkV7OtwuqBVzrE8GR6GFx+wExME=\ngithub.com/stretchr/testify v1.2.2/go.mod h1:a8OnRcib4nhh0OaRAV+Yts87kKdq0PP7pXfy6kDkUVs=\ngolang.org/x/crypto v0.0.0-20180904163835-0709b304e793 h1:u+LnwYTOOW7Ukr/fppxEb1Nwz0AtPflrblfvUudpo+I=\ngolang.org/x/crypto v0.0.0-20180904163835-0709b304e793/go.mod h1:6SG95UA2DQfeDnfUPMdvaQW0Q7yPrPDi9nlGo2tz2b4=\ngolang.org/x/sys v0.0.0-20180905080454-ebe1bf3edb33 h1:I6FyU15t786LL7oL/hn43zqTuEGr4PN7F4XJ1p4E3Y8=\ngolang.org/x/sys v0.0.0-20180905080454-ebe1bf3edb33/go.mod h1:STP8DvDyc/dI5b8T5hshtkjS+E42TnysNCUPdjciGhY=\n```\n\nIf you change versions of a dependency, then you'll still see the hash from the previous version you used.\n\nThe reason for this is that if you revert _back_ to the previous version you can check the hash hasn't changed.\n\nWhy would you need to check the hashed content hasn't changed, surely reverting to a previous 'version' worked before so it should work now right?\n\nWell, someone could have forced pushed a change to a previous version and so the hash of the content will be different, and you'll now be able to tell. It might be the change that was force pushed over the original 'version' you were using means the behaviour of that dependency _breaks_ your application.\n\nThis is why the file has a `.sum` extension, because this is exactly what a [`checksum`](https://en.wikipedia.org/wiki/Checksum) is.\n\n## Vendoring\n\nYou can have your project support older versions of Go that don't support modules by _also_ vendoring your dependencies:\n\n```bash\n$ go mod vendor\n```\n\nWhich results in a vendor directory being generated:\n\n```bash\n$ tree -L 3 vendor/\n\nvendor/\n├── github.com\n│   ├── konsorten\n│   │   └── go-windows-terminal-sequences\n│   └── sirupsen\n│       └── logrus\n├── golang.org\n│   └── x\n│       ├── crypto\n│       └── sys\n└── modules.txt\n```\n\n## Why?\n\nWe can identify where a specific dependency is used:\n\n```bash\n$ go mod why -m github.com/sirupsen/logrus\n\n# github.com/sirupsen/logrus\nmy-test-project\ngithub.com/sirupsen/logrus\n```\n\nThe `why` command (when used with `-m`) finds a path to any package in each of the modules.\n\n## Example Dockerfile\n\n```Dockerfile\n# =============================================================================\n# build stage\n# =============================================================================\nFROM golang:1.11 AS golang\n\nRUN go get golang.org/x/lint/golint\n\nWORKDIR /app\n\nCOPY go.mod go.sum ./\nADD internal/lib ./internal/lib\nRUN go mod download\nCOPY . .\n\n# Lastly, build our actual application binary\nRUN go build -ldflags=\"-s -w\" -o /bin/app ./cmd/app\n\n# =============================================================================\n# app stage\n# =============================================================================\nFROM debian:stable-slim\n\nRUN apt-get update \u0026\u0026 \\\n    apt-get install -y ca-certificates \u0026\u0026 \\\n    rm -rf /var/lib/apt/lists/*\n\nCOPY scripts/test /app/scripts/test\nCOPY --from=golang /bin/app /bin/\n\nCMD [\"/bin/app\"]\n```\n\n## Replacing Dependencies\n\n```\n// go.mod\nmodule \u003cyour_new_rig_service\u003e\n\nrequire (\n    buzzfeed/settings v0.0.0\n)\n\nreplace (\n    buzzfeed/settings =\u003e ./internal/lib/settings\n)\n```\n\n## References\n\n- [Modules (Golang Wiki)](https://github.com/golang/go/wiki/Modules)\n- [JustForFunc](https://www.youtube.com/watch?v=aeF3l-zmPsY)\n","tags":"#go #golang #modules #dependencies #vendoring"},{"id":"cdb39290c32826b40cd50b59ba7afc22","title":"[Python algorithm to generate single list] ","content":"\"\"\"\nWe need a single list.\n\nThe starting list is `n`.\n\nWe need to intersperse each item in `l` at positions 2 and 4.\n\nWe need to intersperse each item in `u` at positions 3.\n\nBut the list needs to be considered in chunks of six.\n\nMeaning, the following example is wrong (as the positions 2, 3 and 4 aren't applied with chunks of 6 items in mind)...\n\n[1, a, A,\n b, 2, c,\n B, d, 3,\n e, C, f]\n \n\u003e The above is wrong because the interspersing is reset after position 4 (so counting positions 1, 2, 3 ...etc has started again after the position where `b` is found).\n \nBut the following is the correct output...\n\n[1, a, A,\n b, 2, 3,\n 4, c, B,\n d, 5, 6]\n\"\"\"\n\nimport itertools\nimport string\n\nn = list(range(1, 27))\nl = list(string.ascii_lowercase)\nu = list(string.ascii_uppercase)\n\n...\n","tags":"#algorithm #python"},{"id":"af300f602fa4da8cc14863f36a24bd1e","title":"[Build Go from source] ","content":"# Note: doing this requires _a_ version of Go to be installed already (e.g. `brew install go`)\n\n# setup\nmkdir -p ~/code\ncd ~/code\n\n# get source\ngit clone https://go.googlesource.com/go\ncd go\ngit tag\ngit checkout go1.11beta2\n\n# compile\ncd src\n./make.bash\n\n# using the compiled go binary\n\u003copen a new shell\u003e\nexport PATH=~/code/go/bin:$PATH\ngo version\n","tags":"#go #golang #compile #source"},{"id":"bee893792f152e1d5e68fdecffb7e289","title":"[Avoid Negative Language] ","content":"- `Master`/`Slave`❌  \n  `Primary`/`Replica`✅\n- `Whitelist`/`Blacklist`❌  \n  `Allow`/`Deny`✅  \n  `Include`/`Exclude`✅\n","tags":"#language #negative #avoid"},{"id":"ee8e14571d9781cd74f1b1e8052f3c65","title":"[Python API Design] ","content":"## Rules\n\n1. Raise exceptions near to the source of the error.\n2. Raise custom exceptions that are a subclass of a custom parent exception.\n3. Catch the custom parent exception near the top level of your application.\n4. Return `True` if an otherwise impure/side-effect driven operation succeeded.\n5. Send (and document) standardized error messages (e.g. `NOUN_STATE` == `INPUT_INVALID`)\n6. Send appropriate response status codes so callers can handle errors without parsing response structure.\n\n## Example\n\n```py\nclass CustomError(Exception):\n\tdef __init__(self, exc='exception raised', code=500):\n\t\tsuper().__init__(exc)\n\t\tself.code = code\n        \nclass NetworkException(CustomError):\n\tpass\n    \n# example function that raises a subclass exception...\n\ndef call_something_that_will_error() -\u003e bool:\n\t# we catch the exception near the source of where it happened...\n\ttry:\n    \tsome_built_in_network_exception_fires('bad_url')\n    except Exception as exc:\n    \traise NetworkException('whoops!', code=400)\n        \n    # let's pretend this function would otherwise mutate a table record,\n    # in that case we want to know it succeeded\n    return True\n    \n# somewhere near your application's top-level entry point...\n\ndef app_entry_point():\n\ttry:\n\t\tcall_something_that_will_error()\n\texcept CustomError as err:\n\t\t# although NetworkException was raised, \n\t\t# we catch the parent custom exception\n\t\t#\n\t\t# also, we set an appropriate response status code,\n\t\t# which means regardless of our actual body's response structure\n\t\t# the caller of this API only needs to check the status code\n\t\tset_status(500)\n\t\treturn {'state': 'error', code: 500, 'message': GENERIC_MESSAGE}\n        \n   \treturn {'state': 'success'}\n```\n","tags":"#api #design #python"},{"id":"a096c0fae0fc8061eefb17eb79e13717","title":"[APT Search for Packages using Cache command] ","content":"apt-cache search openssl\n","tags":"#apt #cache #packages #search"},{"id":"52b2f7a9fe0c230d310c8a65a7bbf3d6","title":"[Python Mocking] ","content":"- [unittest.mock or mock](#unittestmock-or-mock)\n- [Verify Exceptions](#verify-exceptions)\n- [Clearing lru_cache](#clearing-lru_cache)\n- [Mock Module Level/Global Variables](#mock-module-levelglobal-variables)\n- [Mock Instance Method](#mock-instance-method)\n- [Mock Class Method](#mock-class-method)\n- [Mock Entire Class](#mock-entire-class)\n- [Mock Async Calls](#mock-async-calls)\n- [Mock Instance Types](#mock-instance-types)\n- [Mock return_value vs side_effect](#mock-return_value-vs-side_effect)\n- [Mock Nested Calls](#mock-nested-calls)\n- [Mock builtin `open` function](#mock-builtin-open-function)\n\n## unittest.mock or mock\n\nThe `mock` module is a backwards compatible library you can download from PyPy, where as `unittest.mock` is the same thing but only compatible with the version of Python you're using.\n\nSo in almost all cases you'll want to import it like so:\n\n```py\nimport unittest.mock as mock\n```\n\n\u003e For more examples, see [this reference guide](http://www.voidspace.org.uk/python/mock/examples.html)\n\n## Verify Exceptions\n\nIn the following example our code (in `app.account.confirm(...)`) catches a generic `Exception` and re-raises it as `exceptions.CognitoException`, which we catch and make assertions against:\n\n```py\n@mock.patch('app.aws.sdk.confirm_sign_up', side_effect=Exception('whoops'))\n@mock.patch('app.account.instr_exc')\ndef test_account_confirm_failure(mock_instr_exc, mock_signup):\n    with pytest.raises(exceptions.CognitoException) as exc_info:\n        app.account.confirm(123, 'foo')\n        assert True is True  # this will never be executed!\n        \n    assert exc_info.typename == 'CognitoException'\n    assert str(exc_info.value) == 'SIGNUP_CONFIRMATION_FAILED'\n\n    # we can't have a single assert against call_args_list because in python\n    # two instances of an exception aren't considered equal, and so we have to\n    # assert individual elements of call_args_list.\n    assert type(mock_instr_exc.call_args_list[0][0][0]) == Exception\n    assert str(mock_instr_exc.call_args_list[0][0][0]) == 'whoops'\n    assert mock_instr_exc.call_args_list[0][0][1] == 'SIGNUP_CONFIRMATION_FAILED'\n    assert mock_instr_exc.call_args_list[0][1] == {'code': '123'}\n```\n\n\u003e Note: don't make the mistake of putting any assertions within the `with` context manager. Once the Exception is raised by the function being called within the `with` context manager, all code after it inside the block is not executed.\n\n## Clearing lru_cache\n\nIf a function you wish to test has the `functools.lru_cache` decorator applied, then you'll need to be mindful of mocking the response of that function as it'll be cached in one test and the cached result will be returned when calling the function again to test some other behaviour (and might likely confuse you when you see the unexpected response).\n\nTo fix this issue is very easy because `lru_cache` provides additional functions when decoratoring your functions, it provides:\n\n- `cache_info`\n- `cache_clear`\n\nThe latter (`cache_clear`) is what you call...\n\n```py\n@lru_cache(5)\ndef foo():\n    print('Executing foo...')\n    \nfoo()  # Executing foo...\nfoo()  # \u003cnothing printed as None response was cached and returned\u003e\nfoo.cache_info()  # CacheInfo(hits=1, misses=1, maxsize=5, currsize=1)\nfoo.cache_clear()\nfoo()  # Executing foo... (notice the 'side effect of print is executed again)\n```\n\n\u003e Note: debugging this isn't always obvious. Later on I demonstrate how to [mock the builtin `open` function](#mock-builtin-open-function), and in that scenario I stumbled across this issue, because although I wasn't mocking the top level function itself (I was mocking the call to `open` within), the contents of the file being opened was what was returned and being cached.\n\n## Mock Module Level/Global Variables\n\nWith a module variable you can can either set the value directly or use `mock.patch`.\n\nIn the following example we have the variable `client_id` which is a global variable inside the `app.aws` module which we import to reference elsewhere in our code:\n\n```py\nimport app.aws\n\n\ndef test_account_confirm_successful():\n    app.aws.client_id = 456  # used internally by `confirm()`\n    ...\n    \n@mock.patch('app.aws.client_id', 456)\ndef test_account_confirm_successful():\n    ...\n```\n\nIn the `mock.patch` example, there are two key things to notice: \n\n1. we don't use `return_value`.\n2. there is no mock instance passed to the test function.\n\n## Mock Instance Method\n\nMock the entire class and take advantage of the fact that a mock, when called, returns a new mock:\n\n```python\n@mock.patch(\"foo.bar.SomeClass\")\ndef test_stuff(mock_class):\n    mock_class.return_value.made_up_function.return_value = \"123\"\n```\n\nThe reason this ^^ works is because calling a mock _returns another mock_, and so if you call `mock_class.return_value` you're actually getting another mock object; and because you can call anything you like on a mock object (a function or property you call on a mock doesn't have to exist), means you can set a `return_value` on the mock that's returned by calling `made_up_function`.\n\n## Mock Class Method\n\nSimilar approach to mocking an instance method in that you mock the entire class but you have one less `return_value` to assign to:\n\n```python\nmock_class.ClassMethodName.return_value = \"123\"\n```\n\n## Mock Entire Class\n\nTo mock an entire class you'll need to set the `return_value` to be a new instance of the class.\n\n```py\n@mock.patch('myapp.app.Car')\ndef test_class(self, mock_car):\n\n    class NewCar(object):\n        def get_make(self):\n            return 'Audi'\n\n        @property\n        def wheels(self):\n            return 6\n\n    mock_car.return_value = NewCar()\n    ...\n```\n\n\u003e See other class related mocking tips [here](https://chase-seibert.github.io/blog/2015/06/25/python-mocking-cookbook.html)\n\n## Mock Async Calls\n\nWe can create a coroutine and allow it to be configurable for different types of responses:\n\n```python\ndef make_coroutine(response):\n    \"\"\"You could pass response as a mock or as a raw data structure.\"\"\"\n    \n    async def coroutine(*args, **kwargs):\n        \"\"\"Imagine this coroutine is called with a url as the first argument.\"\"\"\n        \n        if args[0] == '/exception/foo':\n            raise Exception('Whoops Foo')\n        elif args[0] == '/exception/bar':\n            raise Exception('Whoops Bar')\n        return response\n    return coroutine\n    \nclass TestTornado(AsyncHTTPSTestCase):\n    def get_app(self):\n        class FakeHandler(tornado.web.RequestHandler):\n            async def get(self, *args, **kwargs):\n                self.finish('hello')\n                \n        return tornado.web.Application([\n            (r'/fake', FakeHandler),\n        ])\n    \n    @mock.patch('foo.bar.http_client')\n    def test_async thing(self, mock_client):\n        response_body = {'state': 'success', 'payload': 'foobar'}\n        response_mock = mock.MagicMock()\n        response_mock.body = json.dumps(response_body)\n        \n        mock_client.post.side_effect = make_coroutine(response_mock)\n\n        response = self.fetch('/fake')\n        assert response.code == 200\n        assert json.loads(response.body.decode()) == response_body\n```\n\n\u003e Note: you could also create a `MagicMock` and set properties on it like `m = mock.MagicMock(x=1, y=2, z=3)` and then pass that into the `make_coroutine` function. That way, within each `if` statement you can then just call `m.x` or `m.y` etc to get at the actual response you want to return (rather than having to hardcode response objects within the function itself). Mock is also considered `callable` (see below implementation).\n\nWhen dealing with side_effects that need to sometimes trigger an Exception and other times suceed you could use a slightly modified mock implementation that checks if the given response object is callable or not...\n\n```python\ncount = 0\n\ndef make_side_effect_coroutine(side_effect):\n    \"\"\"Side effect friendly mock coroutine.\n\n    In some tests we need to have a mocked coroutine return a different value\n    when it's called multiple times, but a mock side_effect can't trigger a\n    raised exception when given an iterator, and so we have to construct that\n    behaviour ourselves.\n    \"\"\"\n\n    async def coroutine(*args, **kwargs):\n        return side_effect(*args, **kwargs) if callable(side_effect) else side_effect\n    return coroutine\n    \n@mock.patch('app.thing')\ndef test_confirm_email_change_failure(self, mock_thing):\n\n    def side_effects(*args, **kwargs):\n        \"\"\"Use global var to control mock side effects.\"\"\"\n\n        global count\n\n        if count \u003e 0:\n            raise Exception('whoops')\n\n        count += 1\n        return  # don't raise an exception the first time around\n\n    mock_thing.side_effect = make_side_effect_coroutine(side_effects)\n```\n\nAlternatives...\n\n### Monkey Patch\n\n```py\n# allow mock to be used as an await expression...\n\nasync def async_response():\n    return namedtuple('_', ['body'])('{\"state\": \"success\"}')\n\n\ndef mock_async_expression(our_mock):\n    return async_response().__await__()\n\n\nmock.MagicMock.__await__ = mock_async_expression\n```\n\n### MagicMock Subclass\n\n```py\nclass AsyncMock(MagicMock):\n    async def __call__(self, *args, **kwargs):\n        return super(AsyncMock, self).__call__(*args, **kwargs)\n        \nclass TestHandlers(testing.AsyncTestCase):\n    @mock.patch('app.handlers.trigger_soft_cdn_purge', new_callable=AsyncMock)\n    @mock.patch('app.handlers.api')\n    @testing.gen_test\n    async def test_update_cache(self, api_mock, trigger_soft_cdn_purge):\n        response = mock.MagicMock()\n        response.code = 200\n        api_mock.buzz = AsyncMock(return_value=response)\n```\n\n### Async Inline Function\n\n```py\n@mock.patch('app.buzz_api.api_gateway')\n@testing.gen_test\nasync def test_buzz_api(self, client_mock):\n    async def get(url, **kwargs):\n        return\n        \n    client_mock.get.side_effect = get\n```\n\n## Mock Instance Types\n\nThere are two ways to make a mock more like the real object being mocked.\n\n1. `spec`\n2. `wrap`\n\nWe can use mock's `spec` feature to mimic all methods/attributes of the object being mocked. This ensures your mocks have the same api as the objects they are replacing.\n\n\u003e Note: there is a stricter `spec_set` that will raise an `AttributeError`.\n\nThis is best demonstrated with an example:\n\n```py\nimport unittest.mock as mock\nimport tornado.simple_httpclient\n\nfrom tornado.httpclient import AsyncHTTPClient\n\n\nhttp_client = AsyncHTTPClient()\ntype(http_client)  # tornado.simple_httpclient.SimpleAsyncHTTPClient\n\nisinstance(http_client, tornado.simple_httpclient.SimpleAsyncHTTPClient)  # True\n\nisinstance(mock.MagicMock(), tornado.simple_httpclient.SimpleAsyncHTTPClient)  # False\n\nm = mock.MagicMock(spec=tornado.simple_httpclient.SimpleAsyncHTTPClient)\nisinstance(m, tornado.simple_httpclient.SimpleAsyncHTTPClient)  # True\n```\n\nThe `wrap` parameter allows you to 'spy' on the implementation, as wll as affect it's behaviour:\n\n```py\n@pytest.mark.parametrize(\"input_date, input_url, valid\", [\n    (\"2017-06-17T00:00:00.000000Z\", \"foo\", True),\n    (\"2017-06-18T00:00:00.000000Z\", \"bar\", False),\n])\n@mock.patch(\"app.handlers.data.datetime\", wraps=datetime)\ndef test_valid_video(mock_datetime, input_date, input_url, valid):\n    mock_datetime.now.return_value = datetime(2017, 6, 18, 00, 00, 00, 000000)\n    assert valid_video(input_date, input_url) is valid\n```\n\n## Mock return_value vs side_effect\n\nIf your function has a try/except around it, then you can use `side_effect` to cause the calling of the function to trigger an Exception as the returned value:\n\n```py\n@mock.patch('app.aws.sdk.confirm_sign_up', side_effect=Exception('whoops'))\n```\n\n\u003e Note: if you had used `return_value=Exception('whoops')` then the mock would return the string representation of the Exception rather than _raising_ an exception like `side_effect` does.\n\nOtherwise if you just need a _static_ value returned, so it's evaluated at the time it's defined (not when it's called), then you can use `return_value` instead:\n\n```py\n@mock.patch('app.security.secret_hash', return_value='###')\n```\n\n## Mock Nested Calls\n\nCalling a property on a mock returns another mock, so in order to mock very specific properties you'll need to nest your `return_value` or `side_effect`:\n\n```py\nm = mock.MagicMock()\nm.return_value.get.side_effect = [1, 2]\nm.return_value.post.return_value = 'foo'\n\nx = m()\n\nx.get()   # 1\nx.post()  # foo\nx.get()   # 2\n```\n\n## Mock builtin `open` function\n\nPython's mock library provides an abstraction for mocking the builtin `open` function a lot simpler...\n\n```py\ndef test_load_ui_messages_successful():\n    \"\"\"Verify ui message YAML file can be read properly.\"\"\"\n\n    file_content = 'foo: bar'\n\n    with mock.patch('bf_auth.utility.open', mock.mock_open(read_data=file_content), create=True) as mock_builtin_open:\n        assert utils.load_ui_messages('./path/to/non/existing/file.yaml') == {'foo': 'bar'}\n```\n\nThe `create=True` param set on `mock.patch` means that the `mock.MagicMock` returned will automagically create any attributes that are called on the mock (this is because the `open` function will attempt to access lots of different things and it's easier for mock to mock out all of that for you).\n","tags":"#python #mocking #mocks #tornado"},{"id":"75df27f55c1fac0cb52838bffa7638b9","title":"[Python Tornado Queue] ","content":"import logging\nimport time\n\nimport tornado.gen\nimport tornado.ioloop\nimport tornado.queues\nimport tornado.web\n\n\nclass Client():\n    def __init__(self):\n        self.queue = tornado.queues.Queue()\n\n    async def watch_queue(self):\n        while True:\n            task = await self.queue.get()\n            self.run_task(task)\n\n    def run_task(self, task):\n        self.queue.task_done()\n\n\nclient = Client()\n\n\nclass AppHandler(tornado.web.RequestHandler):\n    async def get(self):\n        await client.queue.put(\"%f\" % time.time())\n        logging.warn(f'queue ({client.queue})')\n        self.write(\"Queued a new item\")\n\n\nif __name__ == \"__main__\":\n    tornado.ioloop.IOLoop.instance().add_callback(client.watch_queue)\n\n    application = tornado.web.Application([\n        (r'/', AppHandler),\n    ], debug=True)\n\n    application.listen(8888)\n    tornado.ioloop.IOLoop.instance().start()\n\n","tags":"#python #tornado #queue"},{"id":"822089746ef730a7adfb98c1e230955b","title":"[Python Named Tuples Default Values] ","content":"# Pre-Python 3.7.1\n\nx = namedtuple('_', ['get', 'post'])\nx.__new__.__defaults__ = (1, ) * len(x._fields)\n\ny = x()\ny.get\n1\ny.post\n1\n\n# Python 3.7.1+\n\nfields = ('get', 'post')\nx = namedtuple('_', fields, defaults=(1, ) * len(('get', 'post')))\n\ny = x()\ny.get\n1\ny.post\n1\ndef client_adapter(client):\n    \"\"\"Mimic interface for a specific concrete client implementation.\n    \n    The requirement for the 'fetcher' is that there needs to be 'post' and 'get' methods.\n    \"\"\"\n\n    a = namedtuple('_', ['get', 'post'])\n    a.__new__.__defaults__ = (client.fetch, ) * len(a._fields)\n    return a()\n\n  \nAsyncHTTPClient.configure(None, defaults=dict(user_agent=\"MyCustomAgent\"))\n\nfetcher = configure_fetch(client_adapter(AsyncHTTPClient()))\n\n# fetcher.get(...)\n# fetcher.post(...)\n","tags":"#python #defaults #namedtuple"},{"id":"7aa06d40c58e5d47f25780fda887d142","title":"[Vim Directory Structure, Start-up and Debugging] ","content":"The vim documentation explains all the various steps that are gone through during 'start-up', see `:h startup`.\n\nIn short, Vim executes `:runtime! plugin/**/*.vim` meaning any directories listed in the runtime path (`:h set runtimepath?`) will be searched for a `plugin` sub-directory and all files ending in \".vim\" will be sourced (in alphabetical order per directory).\n\n\u003e Note: if you want to debug the start-up process: `vim --startuptime some_log_filename`.\n\n- `~/.vim/autoload/...` (`:h autoload`)\n- `~/.vim/plugin/...` (`:h plugin`)\n- `~/.vim/ftplugin/...` (`:h ftplugin`)\n- `~/.vim/after/...` (`:h after-directory`)\n\n## the `after` directory\n\nThe `after` directory is used by vim 'users' _and_ by vim 'plugin authors' to override specific plugin configuration (that could be either `~/.vim/plugin/...` or `~/.vim/ftplugin/...`).\n\nFor example, the vim plugin author for `vim-polyglot` adds this file: `~/.vim/plugin/vim-polyglot/after/ftdetect/rspec.vim` which overrides the filetype configuration for `rspec` files.\n\nWhere as a vim user might want to override the behaviour of a plugin they're using (e.g. the FZF plugin) by adding the file `~/.vim/after/plugin/config/fzf.vim`, and due to how vim loads 'after' scripts, that file would get loaded. Although it's important to add a guard into the code to ensure it only executes if the FZF plugin actually is loaded (otherwise this after script could cause an error)...\n\n```viml\n\" include guard; quit if fzf isn't loaded\nif ! exists(':FZF')\n    finish\nendif\n```\n\n## Debugging\n\nTo check a specific setting and who (i.e. which plugin or script) last modified it, use `:verbose set \u003csetting\u003e?`\n\nFor example, `:verbose set shiftwidth?` returns...\n\n```viml\nshiftwidth=2\n      Last set from ~/.vimrc\n```\n\nYou can also see what mappings have been configured using the `map` command.\n\nFor example, to see all mappings with the leader key...\n\n```viml\n:verbose map \u003cleader\u003e\n\nx  \\y            :Buffers\u003cCR\u003e\n        Last set from ~/.vimrc\n   \\t            :FZF\u003cCR\u003e\n        Last set from ~/.vimrc\n        \nn  \\z            :ALEPrevious\u003cCR\u003e\n        Last set from ~/.vimrc\nn  \\x            :ALENext\u003cCR\u003e\n        Last set from ~/.vimrc\n```\n\n\u003e Note: see `:h map-listing` for the various modes (`n` = normal, `x` = visual, etc).\n\nThe same principle works with other mappings like `\u003cCtrl-k\u003e` and `\u003cCtrl-j`...\n\n```viml\n:verbose map \u003cc-k\u003e\n\nn  \u003cC-K\u003e         \u003cPlug\u003eMoveLineUp\n        Last set from ~/.vim/plugged/vim-move/plugin/move.vim\nv  \u003cC-K\u003e         \u003cPlug\u003eMoveBlockUp\n        Last set from ~/.vim/plugged/vim-move/plugin/move.vim\n\n:verbose map \u003cc-j\u003e\n\nn  \u003cNL\u003e          \u003cPlug\u003eMoveLineDown\n        Last set from ~/.vim/plugged/vim-move/plugin/move.vim\nv  \u003cNL\u003e          \u003cPlug\u003eMoveBlockDown\n        Last set from ~/.vim/plugged/vim-move/plugin/move.vim\n```\n\n\u003e Note: vim also has a debugger you can use `vim -D ~/.vimrc` (see reference below for details).\n\nLastly, there is a the `-V\u003cN\u003e` flag that sets the verbosity of vim output when starting up...\n\n```\n\" \u003e= 1  When the viminfo file is read or written.\n\" \u003e= 2  When a file is \":source\"'ed.\n\" \u003e= 5  Every searched tags file and include file.\n\" \u003e= 8  Files for which a group of autocommands is executed.\n\" \u003e= 9  Every executed autocommand.\n\" \u003e= 12 Every executed function.\n\" \u003e= 13 When an exception is thrown, caught, finished, or discarded.\n\" \u003e= 14 Anything pending in a \":finally\" clause.\n\" \u003e= 15 Every executed Ex command (truncated at 200 characters).\n```\n\n\u003e Note: see `:h vbs` for details.\n\nUsage example: `vim -V9 ~/.vimrc`, but you can also write the output to a log file instead (pro tip: use the log file approach) such as `vim -V9foo ~/.vimrc` which will write the output to the log file `foo`.\n\n## Reference\n\n- [Breakdown of vim directories](https://gist.github.com/nelstrom/1056049/784e252c3de653e204e9e128653010e19fbd493f)\n- [Breaking up your .vimrc](https://vimways.org/2018/from-vimrc-to-vim/)\n- [Vim Debugging](http://inlehmansterms.net/2014/10/31/debugging-vim/)\n","tags":"#vim #directory #structure #startup #debugging #debug"},{"id":"07d62f6a55ba42481b23458c15c00e27","title":"[Python Lambda] ","content":"SHELL := /bin/bash\n\nbuild: clean\n\tpipenv run pip install -r \u003c(pipenv lock -r) --target ./\n\tzip -r lambda.zip ./\n\n# We use `@` to prevent Make from displaying the line that was just executed (it's just noise)\n# We also use `\u0026\u003e /dev/null || true` to ensure errors are silenced\n# e.g. trying to remove files that don't exist, would normally trigger an error in Bash\nclean:\n\t@# use double $$ to avoid conflict with builtin $() syntax\n\t@rm -r $$(ls | egrep -v 'Makefile|Pipfile|lambda_function.py') \u0026\u003e /dev/null || true\n\nrun:\n\t@# env vars can be set in the AWS Lambda console\n\tFOO=123 BAR=456 python lambda_function.py\nimport os\nimport requests\n\n\ndef get_host():\n    tld = 'stage.example.com'\n    host = f'https://{tld}'\n\n    webapp_stage_user = os.environ[\"STAGE_USN\"]\n    webapp_stage_pass = os.environ[\"STAGE_PSW\"]\n\n    creds = f'{webapp_stage_user}:{webapp_stage_pass}'\n    host = f'https://{creds}@{tld}'\n\n    return host\n\n\ndef authn_webapp(event):\n    data = {'username': event['userName'],\n            'password': event['request']['password']}\n\n    uri = f'{get_host()}/api/login'\n\n    return requests.post(uri, data=data)\n\n\ndef lambda_handler(event, context):\n    \"\"\"\n    There are two states:\n\n    1. authentication (but before user created in cognito)\n    2. forgotten password\n\n    For authentication we log the user into our webapp and then extract their\n    details and modify the user account that is about to be created in cognito.\n    \n    This allows us to handle migrating users from our data store to cognito.\n    \"\"\"\n    if event['triggerSource'] == \"UserMigration_Authentication\":\n        login_response = authn_webapp(event)\n\n        if login_response.status_code == 200:\n            d = login_response.json()\n\n            user_attr = {'username': d['username'],\n                         'name': d['display_name'],\n                         'email': d['email'],\n                         'email_verified': 'true',\n                         'custom:webapp_id': d['userid']}\n\n            event['response']['userAttributes'] = user_attr\n            event['response']['finalUserStatus'] = \"CONFIRMED\"\n            event['response']['messageAction'] = \"SUPPRESS\"\n\n            return event\n        else:\n            return None\n    else:\n        return None\n\n\nif __name__ == \"__main__\":\n    event = {'triggerSource': 'UserMigration_Authentication',\n             'userName': 'beep',\n             'request': {'password': 'boop'},\n             'response': {}}\n\n    result = lambda_handler(event, {})\n\n    print(f'result: {result}')\n\n# Build package:\n#   make build\n#       pipenv run pip install -r \u003c(pipenv lock -r) --target ./\n#       zip -r lambda.zip ./\n#\n# Test locally:\n#   make run\n#       STAGE_USN=123 STAGE_PSW=456 python lambda_function.py\nThe AWS Python SDK (Boto) is pre-installed with AWS Lambda, so if all we need is the `requests` library, then we can use the following trick to avoid needing to package up our lambda script and its dependencies...\n\n```py\nfrom botocore.vendored import requests\n```\n\n\u003e Note: the following instructions require you to be using [Pipenv](https://gist.github.com/Integralist/9e0c5ee9c2cc2568dd1961bf370716c9) for handling you Python dev environment.\n\nTo generate your dependencies and zip them (+ your lambda script) up for upload to AWS:\n\n- `pipenv run pip install -r \u003c(pipenv lock -r) --target ./`\n- `zip -r lambda.zip ./`\n\nYou need to ensure the dependencies are in the same directory as the lambda script. For example...\n\n```\nrequests/\nurllib3/\nlambda_function.py\n```\n\nYou can (if you're not using pipenv) use `--target` flag to install dependencies to the current directory: `pip install requests --target .`\n\n\u003e `unzip -vl lambda.zip` to check contents of zip\n","tags":"#aws #lambda #makefile #python #cognito"},{"id":"264293f57bd07c302f683aeda4bbe598","title":"[Python Cookies] ","content":"from datetime import datetime, timedelta\nfrom http import cookies\n\ncookie_expires = (datetime.now() + timedelta(days=30)).strftime('%a, %d %b %Y %H:%M:%S')\n\nc = cookies.SimpleCookie()\nc['buzzfeedauth'] = f'id_token={u.id_token};access_token={u.access_token};refresh_token={u.refresh_token}'\nc['buzzfeedauth']['domain'] = 'buzzfeed.io'\nc['buzzfeedauth']['secure'] = True\nc['buzzfeedauth']['httponly'] = True\nc['buzzfeedauth']['expires'] = cookie_expires\n\n#############################################\n\nclass MainHandler(tornado.web.RequestHandler):\n    def get(self):\n        if not self.get_cookie(\"mycookie\"):\n            self.set_cookie(\"mycookie\", \"myvalue\")\n            self.write(\"Your cookie was not set yet!\")\n        else:\n            self.write(\"Your cookie was set!\")\n            \n# http://www.tornadoweb.org/en/stable/web.html#tornado.web.RequestHandler.set_cookie\n            \n#############################################\n            \nclass MainHandler(tornado.web.RequestHandler):\n    def get(self):\n        if not self.get_secure_cookie(\"mycookie\"):\n            self.set_secure_cookie(\"mycookie\", \"myvalue\")\n            self.write(\"Your cookie was not set yet!\")\n        else:\n            self.write(\"Your cookie was set!\")\n            \napplication = tornado.web.Application([\n    (r\"/\", MainHandler),\n], cookie_secret=\"__TODO:_GENERATE_YOUR_OWN_RANDOM_VALUE_HERE__\")\n\n# http://www.tornadoweb.org/en/stable/guide/security.html\n\n#############################################\n\ncookie_name = 'buzzfeedauth'\ncookie_value = f'id_token={u.id_token};access_token={u.access_token};refresh_token={u.refresh_token}'\ncookie_args = {\n  'secure': True,\n  'httponly': True,\n}\nself.set_cookie(cookie_name, cookie_value, domain=settings.get('cookie_domain'), expires_days=30, **cookie_args)\n\n","tags":"#python #cookies"},{"id":"887fd2c395e8096c4030ac056552131d","title":"[Calculate cost of electrical appliances] ","content":"Look at a recent bill for the cost of 1 kilowatt-hour.\n\ne.g. 13p\n\nThere are 1000 watts in a kilowatt.\n\nTo calculate kilowatt of an appliance: `watt / kilowatt`.\n\ne.g. 40 watt fan = `40 ÷ 1000` = 0.04\n\n\u003e If the appliance doesn't include watts, you can multiply the volts by the amps to get watts.\n\nNow multiply that value by 13 (the cost of a kwh)\n\ne.g. 0.04 x 13 = 0.52p an hour (that's half a penny).\n\nMultiply that value by the number of hours you expect the appliance to run.\n\ne.g. 8 hours means 0.52 x 8 = 4.16\n\nThis means: running the appliance for 8hrs will cost you just over 4 pence.\n","tags":"#electrics #cost #money #calculate #home"},{"id":"12806fcbea259edcbc438746b58156af","title":"[list and store every key in a bucket] ","content":"pip install awscli\naws --version\naws configure # you can run this multiple times or add to ~/.aws/credentials and ~/.aws/config\n              # you can also use --profile flag and add new profile (e.g. `[stage]`) to ~/.aws/credentials\n              # e.g. aws --profile=stage s3 ls\n              \naws s3 ls s3://name-of-bucket/ \u003e ./name_of_bucket\n\ntime egrep -i \"^.{31}foobar\" \u003c ./name_of_bucket | tee ./foobar.log | sort | uniq -c\n\n# the reason for skipping first 31 characters is because these aren't the object key name\n# \n# here is an example set of log lines:\n#\n# 2017-07-31 13:01:05      43555 baz\n# 2017-08-01 21:42:28     335392 bar\n# 2017-07-31 23:17:10     327063 foo\n# \n# so in order to filter our just foo keys (which there could be many), you skip the first 31 characters\n\naws s3 cp \"s3://\u003cservice\u003e-\u003cenv\u003e-\u003cregion\u003e/foo?a=1\u0026b=2\u0026c=3\" ./foo.html\n[planz_prod]\naws_access_key_id = beep\naws_secret_access_key = boop\n\n# aws --profile=planz_prod s3 ls s3://example-prod-us-east-1/\n\n[planz_stage]\naws_access_key_id = foo\naws_secret_access_key = bar\n\n# aws --profile=planz_stage s3 ls s3://example-stage-us-east-1/\n","tags":"#aws #cli #s3 #bash #python"},{"id":"042d1d6c93efa390b15b19e2f3f3827a","title":"[Vim substitution examples] ","content":"\" finds any line with `example: ...` and appends `tracker: ''` underneath it\n%s/example:.*\\n/\\0    tracker: ''\\r/g\n\n\" for each line that has content, get the line number and if an even line number, then do a substitution\n:g/./ if getcurpos()[1] % 2 == 0 | s/foo/bar/g | endif\n\n\" alternative approach to above where substitution pattern can be empty as it's part of the global pattern\n:g/foo/ if getcurpos()[1] % 2 == 0 | s//bar/g | endif\n\n\" yet another way using a 'for' loop\nfor i in range(2, line('$'),2)| :exe i.'s/foo/bar/g'|endfor\n","tags":"#vim #substitution #replace #global #viml #forloop #vimscript"},{"id":"865863da8fa5312e75b6a6787578086f","title":"[Bash remove whitelist] ","content":"# Remove files that DON'T match those listed...\n\nrm -r $(ls | egrep -v 'Makefile|Pipfile|lambda_function.py')\n\n# For example ^^ all files would be deleted except:\n#\n# Makefile\n# Pipfile\n# lambda_function.py\n","tags":"#bash #remove #whitelist"},{"id":"ede3fe461213844bb8b8685f1fee44af","title":"[Convert synchronous external Python code into asynchronous code] ","content":"import functools\n\n\ndef force_async(fn):\n    '''\n    turns a sync function to async function using threads\n    '''\n    from concurrent.futures import ThreadPoolExecutor\n    import asyncio\n    pool = ThreadPoolExecutor()\n\n    @functools.wraps(fn)\n    def wrapper(*args, **kwargs):\n        future = pool.submit(fn, *args, **kwargs)\n        return asyncio.wrap_future(future)  # make it awaitable\n\n    return wrapper\n\n\ndef force_sync(fn):\n    '''\n    turn an async function to sync function\n    '''\n    import asyncio\n\n    @functools.wraps(fn)\n    def wrapper(*args, **kwargs):\n        res = fn(*args, **kwargs)\n        if asyncio.iscoroutine(res):\n            return asyncio.get_event_loop().run_until_complete(res)\n        return res\n\n    return wrapper\nThe below code snippets demonstrate how to make synchronous code _asynchronous_ using a threadpool (in this example it's specifically handled within a tornado application).\n\nIf you're using the [requests](http://docs.python-requests.org/en/master/) http client, then this can be made asynchronous using the same threadpool technique, although it can be better to use use an external library (such as [requests-futures](https://github.com/ross/requests-futures/blob/master/README.rst)) if you need to do something a little more complex. For example, being able to utilise the requests library's `Session` feature would need extra work, and so an external library can help with that.\n\nThere are other alternative libraries for working with the requests library too:\n\n- [requests-threads](https://github.com/requests/requests-threads) (uses the [Twisted Framework](https://twistedmatrix.com/trac/))\n- [grequests](https://github.com/kennethreitz/grequests) (uses the [Gevent Framework](http://www.gevent.org/))\n\n\u003e Notes: Grequests appears to be much faster than requests-threads, but brings monkey patching and additional problems with dependencies. Using `ThreadPoolExecutor` appears to be on par with Grequests performance.\n\nBut I feel `requests-futures` is the best option as it uses the Python native `concurrent.futures` for its implementation.\nfrom app.threadpool import run_on_executor\n\ndef fetch_s3_body(s3_resource, bucket, obj_key):\n    \"\"\"\n    Fetch the object from S3 and return it as a byte array\n    \"\"\"\n    try:\n        obj = s3_resource.Object(bucket, obj_key).get()\n        return obj[\"Body\"].read()\n    except ClientError as error:\n        logger.error(\"error fetching s3 object\", key=obj_key, bucket=bucket, error=error)\n        metrics.incr(\"s3_object_fetch\", tags={\"status\": \"failed\"})\n        return None\n\nresponse = await run_on_executor(fetch_s3_body, s3_resource, bucket_name, object_key)\n\"\"\"\nYou don't have to use a threadpool. \n\nIf your use case is simple enough, then just manually co-ordinate some threads.\n\"\"\"\n\nimport threading\nimport urllib.request\n\nthreads = []\nrequests = ['https://www.integralist.co.uk', 'https://google.com']\n\ndef open_url(uri):\n    response = urllib.request.urlopen(uri, timeout=600)\n    print(response.read())\n    \n    \"\"\"\n    import urllib.parse\n    import urllib.request\n\n    url = 'http://www.example.com'\n    values = {'foo' : 'bar'}\n\n    data = urllib.parse.urlencode(values)\n    data = data.encode('ascii') # data should be bytes\n    req = urllib.request.Request(url, data)\n    with urllib.request.urlopen(req) as response:\n\t    the_page = response.read()\n    \"\"\"\n\nfor uri in requests:\n    t = threading.Thread(target=open_url, args=(uri,))\n    t.start()\n    threads.append(t)\n\nfor thread in threads:\n    thread.join()\nfrom concurrent.futures import ThreadPoolExecutor\n\nfrom tornado import gen\nfrom bf_rig import settings\n\n\nTHREAD_POOL = ThreadPoolExecutor(settings.get(\"pool_max_workers\"))\n\n\"\"\"\nUsing the ProcessPoolExecutor can be useful, in cases where memory usage \nper request is very high (large response) and cycling the interpretor \nis required to release memory back to OS.\n\"\"\"\n\n\n@gen.coroutine\ndef run_on_executor(*args, **kwargs):\n    \"\"\"\n    ThreadPoolExecutor doesn't work with native coroutines unfortunately.\n    It will require asyncio.wrap_future which is not much better than using tornado's decorators.\n    \"\"\"\n    result = yield THREAD_POOL.submit(*args, **kwargs)\n    raise gen.Return(result)\n","tags":"#python #tornado #sync #async #requests #urllib"},{"id":"4cd6aed3c58ae99b58e62cf2c76ea836","title":"[Go Standard Lib HTTP Routing] ","content":"package main\n\ntype App struct {\n    // We could use http.Handler as a type here; using the specific type has\n    // the advantage that static analysis tools can link directly from\n    // h.UserHandler.ServeHTTP to the correct definition. The disadvantage is\n    // that we have slightly stronger coupling. Do the tradeoff yourself.\n    UserHandler *UserHandler\n}\n\nfunc (h *App) ServeHTTP(res http.ResponseWriter, req *http.Request) {\n    var head string\n    head, req.URL.Path = ShiftPath(req.URL.Path)\n    if head == \"user\" {\n        h.UserHandler.ServeHTTP(res, req)\n        return\n    }\n    http.Error(res, \"Not Found\", http.StatusNotFound)\n}\n\ntype UserHandler struct {\n}\n\nfunc (h *UserHandler) ServeHTTP(res http.ResponseWriter, req *http.Request) {\n    var head string\n    head, req.URL.Path = ShiftPath(req.URL.Path)\n  \n    id, err := strconv.Atoi(head)\n    if err != nil {\n        http.Error(res, fmt.Sprintf(\"Invalid user id %q\", head), http.StatusBadRequest)\n        return\n    }\n  \n    switch req.Method {\n    case \"GET\":\n        h.handleGet(id)\n    case \"PUT\":\n        h.handlePut(id)\n    default:\n        http.Error(res, \"Only GET and PUT are allowed\", http.StatusMethodNotAllowed)\n    }\n}\n\nfunc main() {\n    a := \u0026App{\n        UserHandler: new(UserHandler),\n    }\n    http.ListenAndServe(\":8000\", a)\n}\n\n///////////////////////////////////////////////////////////////////////////////////////////////\n// ADDITIONAL MODIFICATION FOR NESTED HANDLERS\n///////////////////////////////////////////////////////////////////////////////////////////////\n\ntype UserHandler struct{\n    ProfileHandler *ProfileHandler\n}\n\nfunc (h *UserHandler) ServeHTTP(res http.ResponseWriter, req *http.Request) {\n    var head string\n    head, req.URL.Path = ShiftPath(req.URL.Path)\n    id, err := strconv.Atoi(head)\n    if err != nil {\n        http.Error(res, fmt.Sprintf(\"Invalid user id %q\", head), http.StatusBadRequest)\n        return\n    }\n\n    if req.URL.Path != \"/\" {\n        head, tail := ShiftPath(req.URL.Path)\n        switch head {\n        case \"profile\":\n            // We can't just make ProfileHandler an http.Handler; it needs the\n            // user id. Let's instead…\n            h.ProfileHandler.Handler(id).ServeHTTP(res, req)\n        case \"account\":\n            // Left as an exercise to the reader.\n        default:\n            http.Error(res, \"Not Found\", http.StatusNotFound)\n        }\n        return\n    }\n    // As before\n    ...\n}\n\ntype ProfileHandler struct {\n}\n\nfunc (h *ProfileHandler) Handler(id int) http.Handler {\n    return http.HandlerFunc(func(res http.ResponseWriter, req *http.Request) {\n        // Do whatever\n    })\n}\npackage main\n\nimport (\n\t\"fmt\"\n\t\"io\"\n\t\"net/http\"\n)\n\nfunc indexHandler(w http.ResponseWriter, r *http.Request) {\n\tswitch r.Method {\n\tcase \"GET\":\n\t\t// Serve the resource.\n\t\tfmt.Fprintf(w, \"Hello %s\", r.URL.Path[1:])\n\tcase \"POST\":\n\t\t// Create a new record.\n\t\thttp.Error(w, \"Nope. Method Not Allowed\", http.StatusMethodNotAllowed)\n\tcase \"PUT\":\n\t\t// Update an existing record.\n\t\thttp.Error(w, \"Nope. Method Not Allowed\", http.StatusMethodNotAllowed)\n\tcase \"DELETE\":\n\t\t// Remove the record.\n\t\thttp.Error(w, \"Nope. Method Not Allowed\", http.StatusMethodNotAllowed)\n\tdefault:\n\t\t// Give an error message.\n\t\thttp.Error(w, \"Nope. Method Not Allowed\", http.StatusMethodNotAllowed)\n\t}\n}\n\ntype statusHandler int\n\nfunc (s statusHandler) ServeHTTP(w http.ResponseWriter, r *http.Request) {\n\tcode := int(s)\n\tw.WriteHeader(code)\n\tio.WriteString(w, http.StatusText(code))\n}\n\n// this is functionally equivalent to http.HandleFunc\ntype convertFunctionToHandler func(w http.ResponseWriter, r *http.Request)\n\nfunc (c convertFunctionToHandler) ServeHTTP(w http.ResponseWriter, r *http.Request) {\n\t// calls whatever non-standard function was converted into this type\n\t// e.g. we do that like so: convertFunctionToHandler(randomHandler)\n\tc(w, r)\n}\n\n// normally this function wouldn't valid when used as a handler passed into a\n// http.Handle call, and so we don't do that. Instead we pass this function\n// into convertFunctionToHandler to ensure this function is then converted into\n// a type that would be valid for using with http.Handle\nfunc randomHandler(w http.ResponseWriter, r *http.Request) {\n\t// called by convertFunctionToHandler.ServeHTTP\n\tio.WriteString(w, \"Random World!\")\n}\n\nvar (\n\tnotFoundHandler    = statusHandler(404)\n\tserverErrorHandler = statusHandler(500)\n)\n\n/*\ntypes\ngo doc http.Handler\ngo doc http.HandlerFunc\n\nfuncs\ngo doc http.Handle\ngo doc http.HandleFunc\n\n`go doc` also displays any methods attached to a type, such as with\n`go doc http.Handler` and `go doc http.HandlerFunc`\n*/\nfunc main() {\n\t// HandleFunc is functionally equivalent to convertFunctionToHandler in that\n\t// it internally converts the given non-standard function into something that\n\t// supports the http.Handler interface (required by DefaultServeMux or your\n\t// own custom mux instance). It does this by passing the non-standard\n\t// function into http.HandlerFunc which does have a ServeHTTP method and that\n\t// method calls your original non-standard function.\n\thttp.HandleFunc(\"/\", indexHandler)\n\n\t// http.Handle is similar to http.HandleFunc, but instead it doesn't attempt\n\t// to coerce the given non-standard function into something that supports\n\t// http.Handler, it instead will just fail to compile if it doesn't support\n\t// the right interface.\n\thttp.Handle(\"/beepboop\", convertFunctionToHandler(randomHandler))\n\n\thttp.Handle(\"/notfound\", statusHandler(404))\n\thttp.Handle(\"/notfound2\", notFoundHandler)\n\thttp.Handle(\"/error\", statusHandler(500))\n\thttp.Handle(\"/error2\", serverErrorHandler)\n\n\t// notice we can't use statusHandler with http.HandleFunc because the type is\n\t// an int and not a func type with the expected signature.\n\t//\n\t// http.HandleFunc(\"/error\", statusHandler(500))\n\n\thttp.ListenAndServe(\":9000\", nil)\n}\n\n/*\nhttp.Handler = interface\nyou support http.Handler if you have a `ServeHTTP(w http.ResponseWriter, r *http.Request)` method available.\n\nhttp.Handle(\"/\", \u003cgive me something that supports the http.Handler interface\u003e)\ne.g. an object with a ServeHTTP method\n\nhttp.HandleFunc(\"/\", \u003cgive me any function with the same signature as ServeHTTP \u003e)\ne.g. a function that accepts the arguments `(w http.ResponseWriter, r *http.Request)`\n\nhttp.HandlerFunc = func type used internally by http.HandleFunc\ne.g. it adapts the given function to the http.HandlerFunc type and that has a ServeHTTP method which then calls your given function\n*/\n","tags":"#go #golang #http #routing #mux #http"},{"id":"21819f5dd4ded1ebdf48ea01e882dd01","title":"[Topics to discuss with a new employer] ","content":"## Questions to ask yourself?\n\n- What's _important_ to me (what are my priorities and standards)?\n- What impact can _I_ have here?\n\n## Questions for them?\n\nIt's a good idea, at the start of any conversation, to ask:\n\n\u003e What's the focus of today's conversation?  \n\ni.e. What's important to `\u003cCOMPANY\u003e`, and what insights do _you_ want to take from this?\n\n- **What's `\u003cCOMPANY\u003e`'s story?**  \n  - Give me an insight into the company's history/background and how we've reached this point in time.\n\n- **Presence**  \n  - How many offices do you have and what are their locality?\n\n- **Culture and Diversity**  \n  - The company's \"values\" will help indicate what's _important_ to them.\n\n- **Hierarchy and Organisation Structure**\n  - Are you fairly 'flat and lean' or 'tall and fragmented'?\n\n- **Visibility \u0026 Openness**\n  - How does leadership share and handle critical/internal business topics?\n\n- **Collaboration**\n  - Features across teams (avoiding duplication)\n  - Timezones\n\n- **Community**\n  - How do internal \u0026 external staff interact?\n  - How do teams across offices/locality bond?\n\n- **Process**\n  - New Features\n  - Leadership\n  - Documentation (sharing of information, no silos of knowledge)\n  - Post mortems (blameless retrospection, handling of failures)\n  - Tech Debt\n\n- **Communication**\n  - [SBI: Situation, Behaviour, Impact](https://gist.github.com/Integralist/24c8a9ce570d78d37ed0cf9967594e0e) (Methodology, _The Center for Creative Leadership_)\n  - [Radical Candor](https://www.radicalcandor.com/) (Book, _Kim Scott_)\n  - [Conscious Business](https://www.youtube.com/watch?v=IdMvWLARF1w) (Video, _Fred Kofman_)\n  - [Authentic Communication](https://www.soundstrue.com/store/authentic-communication.html) (Book, _Fred Kofman_)\n\n- **Responsibility and Ownership**\n  - Site Reliability\n  - Operations\n  - On-call rota\n\n- **Job Progression \u0026 Opportunities**\n  - Learning budgets?\n  - Conferences?\n\n- **Remote Working**\n  - How are remotes kept feeling inclusiveness?\n\n- **Work life balance and support**\n  - How do staff balance work-life, when in a multi-region organisation?\n  - e.g. cross-over hours between UK and US?\n\n- **Tech**\n  - Infrastructure\n  - Build System\n  - Deployment Platform\n  - Rollback Processes\n\n- **Vision and Future**\n  - Where is `\u003cCOMPANY\u003e` looking towards?\n  - What are the goals?\n","tags":"#jobs #culture #questions"},{"id":"60267c6185518a8ed8b4dcaff47891a2","title":"[Go Middleware] ","content":"package main\n\nimport (\n\t\"fmt\"\n\t\"log\"\n\t\"net/http\"\n\n\t\"github.com/julienschmidt/httprouter\"\n)\n\nvar securityHeaders = map[string]string{\n\t\"Referrer-Policy\":        \"Same-origin\",\n\t\"X-Content-Type-Options\": \"nosniff\",\n\t\"X-Frame-Options\":        \"SAMEORIGIN\",\n\t\"X-XSS-Protection\":       \"1; mode=block\",\n}\n\nfunc index(w http.ResponseWriter, r *http.Request, _ httprouter.Params) {\n\tfmt.Fprint(w, \"Welcome!\\n\")\n}\n\nfunc middleware(handler httprouter.Handle) httprouter.Handle {\n\treturn func(w http.ResponseWriter, r *http.Request, p httprouter.Params) {\n\t\tfor key, val := range securityHeaders {\n\t\t\tif w.Header().Get(key) == \"\" {\n\t\t\t\tw.Header().Set(key, val)\n\t\t\t}\n\t\t}\n      \n\t\thandler(w, r, p)\n\t}\n}\n\nfunc main() {\n\trouter := httprouter.New()\n\trouter.GET(\"/\", middleware(index))\n\tlog.Fatal(http.ListenAndServe(\":8080\", router))\n}\n$ curl -v http://localhost:8080/\n\n*   Trying ::1...\n* TCP_NODELAY set\n* Connected to localhost (::1) port 8080 (#0)\n\n\u003e GET / HTTP/1.1\n\u003e Host: localhost:8080\n\u003e User-Agent: curl/7.58.0\n\u003e Accept: */*\n\n\u003c HTTP/1.1 200 OK\n\u003c Referrer-Policy: Same-origin\n\u003c X-Content-Type-Options: nosniff\n\u003c X-Frame-Options: SAMEORIGIN\n\u003c X-Xss-Protection: 1; mode=block\n\u003c Date: Tue, 27 Mar 2018 15:46:42 GMT\n\u003c Content-Length: 9\n\u003c Content-Type: text/plain; charset=utf-8\n\nWelcome!\n\n* Connection #0 to host localhost left intact\n","tags":"#golang #go #middleware"},{"id":"8a3cce24fe7a5794eafd445a33b0e03f","title":"[Security Tools] ","content":"- https://www.owasp.org/index.php/OWASP_Zed_Attack_Proxy_Project\n- http://www.arachni-scanner.com/\n- https://securityheaders.io/\n- https://portswigger.net/burp\n\n\u003e See OWASP for a list of [other black box testing tools](https://www.owasp.org/index.php/Appendix_A:_Testing_Tools)\n","tags":"#security #pentesting"},{"id":"e428e20a636b3a9ace3238d8412c7670","title":"[Varnish VCL Basic Authentication] ","content":"## generate a username/password\n\n```bash\necho -n beep:boop | base64\n\nYmVlcDpib29w\n```\n\n\u003e Note: it's important to use `-n` otherwise `echo` will add a line break and that can be a time consuming error to debug when you find your username/password isn't working ;-) if you do find you need to debug, then use `curl` with the `-v` flag and inspect the request headers being sent and make sure your base64 encoded username/password matches what curl generates for the `Authorization` header when using the `--user` flag (see below curl examples)\n\n## vcl code\n\n```vcl\nsub vcl_recv {\n  #FASTLY recv\n  \n  if (!req.http.Authorization ~ \"Basic YmVlcDpib29w\") {\n    error 401 \"Restricted\";\n  }\n\n  return(lookup);\n}\n\nsub vcl_error {\n  #FASTLY error\n  \n  if (obj.status == 401) {\n    set obj.http.Content-Type = \"text/html; charset=utf-8\";\n    set obj.http.WWW-Authenticate = \"Basic realm=Secured\";\n\n    synthetic {\"\n      \u003c!doctype html\u003e\n      \u003chtml\u003e\n        \u003chead\u003e\n          \u003cmeta charset=\"utf-8\"\u003e\n          \u003ctitle\u003eError\u003c/title\u003e\n        \u003c/head\u003e\n        \u003cbody\u003e\n          \u003ch1\u003e401 Unauthorized (varnish)\u003c/h1\u003e\n        \u003c/body\u003e\n      \u003c/html\u003e\n      \"};\n\n    return (deliver);\n  }\n}\n```\n\n## example curl commands\n\n```bash\ncurl --user beep:boop https://www.example.com/auth-me\ncurl -H \"Authorization: Basic YmVlcDpib29w\" https://www.example.com/auth-me\n```\n","tags":"#security #basicauth #authentication #vcl #varnish #fastly #cdn"},{"id":"8f7e646ffa87f0e16ea6ec05974bc5db","title":"[Python Multiple Characters String Replacement] ","content":"\"^foo$\".translate(str.maketrans({'^': '', '$': ''}))\n\n# more structured than...\n\"^foo$\".replace(\"^\", \"\").replace(\"$\", \"\")\n\n# and likely easier abstraction than using a regex replacement\n#\n# although you can do this more 'manually' like so...\n\ndef replace_all(text, dic):\n    for i, j in dic.items():\n        text = text.replace(i, j)\n    return text\n\nd = { \"\\n\": \"\", \"\\r\": \"\"}\nmy_sentence = \"This is my cat\\n\\rand this\\nis\\rmy dog.\"\nreplace_all(my_sentence, d)  # 'This is my catand thisismy dog.'\n\n","tags":"#python #replacement #string #translate"},{"id":"7153194c9183fd54b97a1d5af71947ae","title":"[GPN: Ganners Pipe Notation] ","content":"## GPN: Ganners Pipe Notation\n\n\u003e Designed by Mark Gannaway @BuzzFeed\n\nIt's a way of articulating the design of a system, using unix pipes (and other recognised syntax), without worrying about the concrete implementation.\n\nFor example:\n\n```bash\nrequest_drink\n| open_bottle\n| acknowledge_satisfying_cork_sound\n| pour_generously --tolerance=1\n| tee\n  | \u003e(drink)\n  | \u003e(drink)\n  | \u003e(drink...)\n| hangover_recovery_sequence\n```\n\nBut more seriously...\n\n```bash\ntaxi_dispatcher -f \n    | update_robot_position --id=1\n    | nearby_stations --limit=1 --max-distance=.35km\n    | google_maps_traffic_report\n```\n\nWhich breaks down to:\n\n- **taxi_dispatcher**:  \n  Outputs latitude/longitude with a robot id  \n\n- **update_robot_position**:  \n  Listens for latitude/longitude and moves a robot\n\n- **nearby_stations**:  \n  Listens for latitude/longitude and finds nearby stations\n\n- **google_traffic_report**:  \n  Listens for latitude/longitude and checks traffic\n  \n## Naming things\n\nIn the following example we're defining the requirements for rendering HTML components.\n\n```bash\nshared_components=curl $API/data.json?lang=$lang\n    | tee\n        \u003e(render_metadata --brand=bf)\n        \u003e(render_navbar --lang=$lang --brand=bf)\n        \u003e(jq .subcomponents | render_subcomponents --brand=bf)\n        \u003e(render_subcomponents_js --brand=bf)\n        \u003e(render_subcomponents_css --brand=bf)\n```\n\n\u003e Note: `tee` is a simple command which provides us the primitives to fork a stream concurrently.\n\nWe've given it a name (`shared_components`) in order for us to be able to utilise it in a larger pipeline, like so:\n\n```\nhttp_request | shared_components | render_template\n```\n\n## No behavioural abstractions\n\nWe want to avoid complicating these definitions, so instead of trying to have something like `render_template(foo)` and `render_template(bar)`, we should instead use two separate calls:\n\n```\nhttp_request | shared_components | render_foo_template\nhttp_request | shared_components | render_bar_template\n```\n\n## Complexity reduced to simpler concepts\n\n```\nhttp_request\n  | in_cache || shared_components\n  | render_foobar_template\n  | convert_to_amp\n  | minify_html\n  | validate_html\n  | inline_css --file-pattern=*critical*\n  | inline_images --file-pattern=*static-assets*\n  | gzip\n```\n\n## What details do we lose?\n\n- Fault tolerance and application errors (although possible using stderror redirection).\n- Considerations of the CAP theorem (e.g. defining shared infrastructure).\n- Performance considerations (with respect to network latency).\n- Logical forking (though this can be expressed with added detail).\n\n## Conclusion\n\nthe symbols enable us to further **simplify**, **optimize**, and **describe** a system.\n","tags":"#GPN #design #architecture #systems"},{"id":"9d7d82d9f702ffd4b17d909d3458015e","title":"[Grammar] ","content":"## Quick Grammar Summary/Example\n\n- [Paragraph](https://www.grammar-monster.com/glossary/paragraph.htm): A paragraph is a distinct section of writing covering one topic. A paragraph will usually contain more than one sentence.\n- [Sentence](https://www.grammar-monster.com/glossary/sentences.htm): A sentence is a group of words giving a complete thought. A sentence must contain a subject and a verb (although one may be implied).\n\nConsider the following sentence:\n\n\u003e They were driving a red car down the road before noon, but very slowly.\n\n- They: **pronoun (subject)**\n- were: **verb (linking)**\n- driving: **verb (action)**\n- a: **determiner**\n- red: **adjective**\n- car: **noun**\n- down: **preposition**\n- the: **determiner**\n- road: **noun**\n- before: **preposition**\n- noon: **noun**\n- but: **conjunction**\n- very: **adverb**\n- slowly: **adverb**\n\n---\n\n- **[Noun](https://en.oxforddictionaries.com/grammar/word-classes/nouns)**: identifying a _thing_ (i.e. \"car\", \"road\", \"noon\")\n- **[Pronoun](https://en.oxforddictionaries.com/grammar/pronouns)**: refers to participants (i.e. \"They\", \"it\", \"me\")\n- **[Adjective](https://en.oxforddictionaries.com/grammar/word-classes/adjectives)**: naming an attribute of a noun (i.e. \"red\")\n- **[Verb](https://en.oxforddictionaries.com/grammar/word-classes/verbs)**: describing an action (i.e. \"were\", \"driving\") †\n- **[Adverb](https://en.oxforddictionaries.com/grammar/word-classes/adverbs)**: modifies the meaning of an adjective or verb (i.e. \"very\", \"slowly\")\n- **[Preposition](https://en.oxforddictionaries.com/grammar/prepositions)**: placed in front of nouns or pronouns to show the relationship (i.e. \"down\", \"before\")\n- **[Conjuctions](https://en.oxforddictionaries.com/grammar/conjunctions)**: used to connect [phrases](https://en.oxforddictionaries.com/grammar/phrases), [clauses](https://en.oxforddictionaries.com/grammar/clauses), and [sentences](https://en.oxforddictionaries.com/grammar/sentences) (i.e. \"but\")\n- **[Determiner](https://en.oxforddictionaries.com/grammar/determiners)**: introduces a noun (i.e. \"a\", \"the\")\n  - **Article (Definite)**: refers to a particular thing already mentioned, or uniquely specified (e.g. \"the\")\n    - \"**The children** know **the fastest way** home.\"\n    - \"**Children** know **the fastest ways** home.\"\n    - \"Give me **the book**.\"\n  - **Article (Indefinite)**: refers to something not explicitly specified (e.g. \"a\", \"an\", \"some\")\n    - \"Give me **a book**.\"\n    - \"Give **some books**.\"\n    \n\u003e † there are actually many types of 'verbs'. The most well known are 'action' verbs, but there's also 'modal', 'auxiliary' and 'linking' verbs.\n\n## Tools\n\n- https://parts-of-speech.info/\n\n## Adverbs\n\nAn adverb is a word that modifies a verb, adjective, another adverb, determiner, noun phrase, clause, preposition, or sentence. Adverbs typically express manner, place, time, frequency, degree, level of certainty, etc., answering questions such as how?, in what way?, when?, where?, and to what extent?.\n\n## Verb Types\n\nRead more about verb types [here](https://dictionary.cambridge.org/grammar/british-grammar/about-verbs/verbs-types).\n\n### Main Verbs\n\nMain verbs have meanings related to actions, events and states. Most verbs in English are main verbs: \n\n- We **_went_** home straight after the show.\n- It **_snowed_** a lot that winter.\n- Several different types of volcano **_exist_**.\n\n### Linking Verbs\n\nSome main verbs are called linking verbs (or copular verbs). These verbs are not followed by objects. Instead, they are followed by phrases which give extra information about the subject. These include: appear, feel, look, seem, sound, be, get, remain, smell, taste, become.\n\n- A face **_appeared_** \u003cu\u003eat the window\u003c/u\u003e. It was Pauline. (prepositional phrase)\n- He **_'s_** \u003cu\u003ea cousin of mine\u003c/u\u003e. (noun phrase)\n- This coat **_feels_** \u003cu\u003egood\u003c/u\u003e. (adjective phrase)\n- She **_remained_** \u003cu\u003eoutside\u003c/u\u003e while her sister went into the hospital. (adverb phrase)\n\n\u003e Also: I _**am**_ a teacher. I _**turned**_ green.\n\nIn the original sentence:\n\n\u003e They are driving a red car down the road but very slowly.\n\nThe word \"are\" is a state/linking verb, and \"driving\" is an action verb.\n\nRead more about 'linking' verbs [here](https://www.english-grammar-revolution.com/linking-verbs.html).\n\n### Auxiliary Verbs\n\nThere are three auxiliary verbs in English: be, do and have. Auxiliary verbs come before main verbs.\n\n#### Auxiliary Be\n\nAuxiliary be is used to indicate the continuous and the passive voice:\n\n- I **_’m waiting_** for Sally to come home. (continuous)\n- Her car **_was stolen_** from outside her house. (passive)\n\n#### Auxiliary Do\n\nAuxiliary do is used in interrogative, negative and emphatic structures:\n\n- **_Does_** she live locally? (interrogative)\n- They **_didn’t_** know which house it was. (negative)\n- I **_do_** like your new laptop! (emphatic, with spoken stress on do)\n\n#### Auxiliary Have\n\nAuxiliary have is used to indicate the perfect:\n\n- I **_'ve lost_** my memory stick. **_Have_** you **_seen_** it anywhere? (present perfect)\n- She **_had seen_** my car outside the shop. (past perfect)\n\n### Modal Verbs\n\nModal verbs have meanings connected with degrees of certainty and necessity, such as: can, may, must, should, would, could, might, shall, will.\n\n- We **_'ll_** be there around 7.30. (speaker is quite certain)\n- A new window **_could_** cost around £500. (speaker is less certain)\n- I **_must_** ring the tax office. (speaker considers this very necessary)\n\n## Present Tense\n\n### Continous\n\nThere are some similarities between state/linking verbs and what is known as 'Present Continous Tense', which is a means of describing a _subject_ along with a _present tense_ for the verb to be. For example, \"I am swimming\" (\"I\" is the subject, \"am\" is the present tense for the verb to be, and \"swimming\" is the present verb).\n\nThere are other forms of present continuous tense (verb tense is italicized):\n\n- She _is crying_.\n- We _are visiting_ the museum in the afternoon.\n- You _are not watching_ the movie.\n\nIt can also indicate if something will or will not happen in the near _future_:\n\n- She _is not going_ to the game tonight.\n- _Are_ you _visiting_ your cousin this weekend?\n- I _am not going_ to the meeting after work.\n- _Is_ John _playing_ football today?\n\n\u003e [Reference](http://examples.yourdictionary.com/present-continuous-tense-examples.html)\n\n### Perfect\n\nThe present tense (i.e. not continuous) is a means of describing an event that happened in the past that has present consequences.\n\n- She _has lived_ here all her life.\n- He has finished his homework (_has done_).\n- I _have worked_ here since I graduated school.\n\nPresent perfect tense can be used with expressions that are unspecific in time:\n\n- I have lost my purse.\n- We have seen this movie already.\n- He has broken his leg.\n- There has been an accident.\n\n\u003e [Reference](http://examples.yourdictionary.com/present-perfect-tense-examples.html)\n\n## Inflection\n\nInflection is the name for the extra letter or letters added to nouns, verbs and adjectives in their different grammatical forms. Nouns are inflected in the plural, verbs are inflected in the various tenses, and adjectives are inflected in the comparative/superlative.\n\n### Examples\n\n- bus → buses  \n- wish → wishes\n- easy → easiest\n- carry → carrying\n- play → played\n- die → dying\n- stop → stopped\n- happen → happening\n\n## French and Grammar\n\nhttps://docs.google.com/document/d/1LdFyWdLDBfq4TNdu09K8N-sawNhLbNv0bkjpPbP2vGM/edit#\n","tags":"#grammar #english #language"},{"id":"6e45b59b45884eddb2e4f4cf955d653e","title":"[Maths: variations/possible combinations] ","content":"## Factorials\n\nTo identify the various combinations of a number or letter, you need to know the number of items.\n\nSo if you're dealing with a string like \"ABC\", that's three characters.\n\nSo you would say `3!` factorial.\n\nWhich really means: `3*2*1 = 6`.\n\nAnd the reason we multiply backwards from `3` specifically is because there were three characters to begin with.\n\nSo we know there are six potential combinations:\n\n1. ABC\n2. ACB\n3. BAC\n4. BCA\n5. CAB\n6. CBA\n\nBut what if you have 10 items?\n\n```\n10*9*8*7*6*5*4*3*2*1 = 3,628,800\n```\n\nYou can see that even with a small number of items, the number of possible combinations becomes very large.\n\n## Exponents\n\nAn exponent is made up of two numbers: a \"base\" and a \"power\" (also referred to as an \"exponent\", but I prefer \"power\" as it helps to distinguish the second number from the over-arching concept of exponents).\n\nTypically the power is displayed as a superscript, but as that not always the easiest thing to type in different editors there is also a symbol to represent an exponent: `^`.\n\n```\n3^4 = 3*3*3*3\n```\n\n\u003e Note: strictly speaking the small (superscript) number is the \"exponent\", while the larger number is the \"base\". The base multiplying itself a number times (specifically by whatever number the exponent is set to) will _result_ in what's called \"raising to the power\" (the \"power\" is the resulting number). -- see https://en.wikipedia.org/wiki/Exponentiation\n","tags":"#math #factorials #exponents #power #raise"},{"id":"92ad26edc5ff8d4e52b768e85c8ef346","title":"[SDK and API] ","content":"It falls along the lines of \"All SDKs are/contain APIs but not all APIs are SDKs\".\n\n## SDK\n\nAn SDK is a complete set of APIs that allow you to perform most any action you would need to for creating applications. In addition an SDK may include other tools for developing for the platform/item that it is for.\n\n\u003e The JDK (Java Development Kit) contains the API as well as the compilers, runtimes, and other miscellaneous tools.\n\n## API\n\nAn API on the other hand is just a series of related methods that may be good for a specific purpose.\n\n\u003e The Java API is simply all the libraries that make up the core language that you can work with out of the box.\n\n## Example\n\nImagine wanting to use AWS Cognito for building a user authentication system.\n\nThe AWS Cognito API might be a preferred choice for a mobile apps team because the API provides the core functionality, but also allows the app team to implement the remainder of the functionality/behaviour themselves. On the flipside, the SDK will provide ‘out-of-the-box’ solutions that the API does not (login modals etc).\n","tags":"#sdk #api"},{"id":"5d5aa78b13576b98358d019d32bbfe2a","title":"[Process Substitution] ","content":"## Process Substitution.\n\nThe `\u003c(list)` syntax is supported by both, bash and zsh. \n\nIt provides a way to pass the output of a command (`list`) to another command when using a pipe (`|`) is not possible. \n\nFor example, when a command just does not support input from STDIN or you need the output of multiple commands:\n\n```\ndiff \u003c(ls dirA) \u003c(ls dirB)\n```\n\n`\u003c(list)` connects the output of list with a file in `/dev/fd`, if supported by the system, otherwise a named pipe (FIFO) is used (which also depends on support by the system; neither manual says what happens if both mechanisms are not supported, presumably it aborts with an error). The name of the file is then passed as argument on the command line.\n","tags":"#bash #process #substitution"},{"id":"a654cfef4d2e7713d89a5d1624f6453f","title":"[Tiny Docker Builds] ","content":"# build step\nFROM golang:alpine AS build-env\nADD . /src\nRUN cd /src \u0026\u0026 go build -o goapp\n\n# final step\nFROM alpine\nWORKDIR /app\nCOPY --from=build-env /src/goapp /app/\nENTRYPOINT ./goapp\n","tags":"#go #golang #docker #build"},{"id":"4d550544a3194ebe6bb536fe86e18fd8","title":"[Python Class Implementation of a Decorator] ","content":"\"\"\"\n[counter 1] add called 1 times\n[counter 1] add called 2 times\n[counter2] add2 called 1 times\n[counter2] add2 called 2 times\n[counter2] add2 called 3 times\n\"\"\"\n\nfrom functools import update_wrapper\n\n\nclass call_count:\n    def __init__(self, name):\n        self.__name = name\n        self.__count = 0\n\n    def __call__(self, fn, *args, **kwargs):\n        def wrapper(*args, **kwargs):\n            self.__count += 1\n            result = fn(*args, **kwargs)\n            print(f'[{self.__name}] {fn.__name__} called {self.__count} times')\n            return result\n        update_wrapper(self, wrapper)\n        return wrapper\n\n    @property\n    def call_count(self):\n        return self.__count\n\n\n@call_count('counter 1')\ndef add(a, b):\n    return a + b\n\n\nif __name__ == '__main__':\n    assert add(1, 2) == 3\n    assert add(3, 4) == 7\n\n    counter2 = call_count('counter2')\n\n    @counter2\n    def add2(a, b):\n        return a + b\n\n    add2(1, 1), add2(1, 1), add2(1, 1)\n    assert counter2.call_count == 3\n","tags":"#python #decorator #class"},{"id":"fd603239cacbb3d3d317950905b76096","title":"[Tornado AsyncHTTPClient - No Web Server] ","content":"Set-up the environment:\n\n\u003e See [this gist](https://gist.github.com/9e0c5ee9c2cc2568dd1961bf370716c9) for more information on Pipenv.\n\n- `pipenv --python 3.7`\n- `pipenv shell`\n- `pipenv install tornado==5.0.2`\n- `pipenv install --dev mypy tox flake8`\n\n```bash\n$ cat Pipfile\n\n[[source]]\nurl = \"https://pypi.org/simple\"\nverify_ssl = true\nname = \"pypi\"\n\n[dev-packages]\nmypy = \"*\"\ntox = \"*\"\n\"flake8\" = \"*\"\n\n[packages]\ntornado = \"==5.0.2\"\n\n[requires]\npython_version = \"3.7\"\n```\n\"\"\"\nsimplest implementation\n\"\"\"\n\nfrom tornado.httpclient import AsyncHTTPClient\nfrom tornado.ioloop import IOLoop\n\nAsyncHTTPClient.configure(None, defaults=dict(user_agent=\"MyUserAgent\"))\nhttp_client = AsyncHTTPClient()\n\nasync def do_thing():\n    response = await http_client.fetch(\"https://www.integralist.co.uk\")\n    print(response.code)\n    print(response.headers)\n    print(response.body)\n\nio_loop = IOLoop.current()\nio_loop.run_sync(do_thing)\n\"\"\"\ndemonstrates the 'callback' variation of AsyncHTTPClient#fetch\n\"\"\"\n\nimport json\n\nfrom tornado.httpclient import AsyncHTTPClient\nfrom tornado.ioloop import IOLoop\n\n# if None, then use tornado.simple_httpclient.SimpleAsyncHTTPClient\n# otherwise specify alternative client such as curl:\n# configure.(\"tornado.curl_httpclient.CurlAsyncHTTPClient\")\nAsyncHTTPClient.configure(None, defaults=dict(user_agent=\"MyUserAgent\"))\nhttp_client = AsyncHTTPClient()\n\n\ndef handle_response(response):\n    if response.error:\n        print(\"Error: %s\" % response.error)\n    else:\n        print('\\n' + str(response.body) + '\\n')  # .body is a byte array\n        data = json.loads(response.body)\n        print(data)\n\n\nasync def get_content():\n    await http_client.fetch(\"http://httpbin.org/json\", handle_response)\n    \n    # Note:\n    #\n    # The above callback 'style' is different to...\n    #\n    # response = await http_client.fetch(\"http://httpbin.org/json\")\n    # print(response.body)\n    #\n    # ...which forces the function to wait for the response, then print it,\n    # before returning to `main()` which attempts to print its own message.\n    #\n    # By using the callback style we end up letting `get_content` return immediately. \n    #\n    # This isn't to say that the non-callback style is synchronous, it is still asynchronous.\n    # In that other processes can be executed while it's happening, but it doesn't work quite the same.\n    # As you can see here in this example.\n    \n    post_data = {\"data\": \"test data\"}\n    body = urllib.parse.urlencode(post_data)\n    response = await http_client.fetch(\"http://httpbin.org/post\", method='POST', headers=None, body=body)\n    print('\\n' + str(response.body) + '\\n')  # .body is a byte array\n    \n    # As per the tornado documentation:\n    # http://www.tornadoweb.org/en/stable/httpclient.html#tornado.httpclient.HTTPRequest\n    #\n    # The AsyncHTTPClient can accept any keyword args that are supported by \n    # the `HTTPRequest` object, and so if you need to provide basic auth credentials...\n    #\n    # http_client.fetch(uri, auth_username=\u003c...\u003e, auth_password=\u003c...\u003e)\n\n\nasync def main():\n    await get_content()\n    print(\"I won't wait for get_content to finish. I'll show immediately.\")\n\nif __name__ == \"__main__\":\n    io_loop = IOLoop.current()\n    io_loop.run_sync(main)  # only runs the specified function, then stops\n                            # alternatively use IOLoop.current().start()\n                            # as that won't stop until explicitly called with\n                            # IOLoop.current().stop()\n\n# Other useful ioloop functions:\n#\n# tornado.ioloop.IOLoop.add_callback\n# tornado.ioloop.IOLoop.add_future\n# tornado.ioloop.IOLoop.spawn_callback\n# tornado.ioloop.PeriodicCallback(task, 1000).start()\n\n# Tornado examples:\n#\n# https://gist.github.com/lbolla/3826189\n# https://github.com/tornadoweb/tornado/blob/master/demos/webspider/webspider.py\n[pytest]\n# norecursedirs = lib\naddopts = -p no:cacheprovider\n\n[flake8]\nmax_line_length = 120\nexclude = lib,node_modules\nignore = E116\n# https://pep8.readthedocs.io/en/latest/intro.html#error-codes\n","tags":"#python #pipenv #tornado #async #concurrency #httpclient #asynchttpclient #tox #ini #basicauth #auth"},{"id":"0fd4f4b627ce3aef0278862bd16e4b71","title":"[Project Management] ","content":"\u003e [!TIP]\n\u003e See also https://gist.github.com/Integralist/bfcad74c66dfa1e8eb5e2c07b13811df\n\n## What Who How Why?\n\n- **Product Manager**: owns the story of \"what\"\n- **Engineering Manager**: owns the story of \"who\"\n- **Engineering Lead (Tech Lead)**: owns the story of \"how\"\n- **All Three**: each person shares ownership of the story of \"why\"\n\n![team leader venn diagram](https://user-images.githubusercontent.com/180050/40474139-1dd70be4-5f36-11e8-8bc4-590d4f2178ba.png)\n\n[More details...](https://medium.com/making-meetup/em-el-pm-venn-diagram-764e79b42baf)\n\n## Project Management\n\n- 🤔 Understand the requirements, and specifically why they are important. \n- 📝 Create simple/high-level Gherkin [user stories](#user-stories) to help understand the product values and standards. \n- ✅ Break down the requirements into milestones and manageable sub tasks \n  - inc. investigation time, QA (Quality Assurance) and security testing\n- 🔝 Prioritise tasks\n  - e.g. either by 'importance/impact' (High, Medium, Low) or using 'MSC' (Must Should Could)\n  - Once categorized, group related items (e.g. group together all high, medium, low items)\n  - A table matrix can help visualise the various tasks and their importance\n- 🗒 Work through the unknowns until you really feel that there is no more value to be gained in spending time on them.\n- 🗣 Figure out who and which teams need to be consulted, and communicate as often as practical.\n- 📆 Run the project and adjust the plan as you go. \n  - How far has the project has come? \n  - How far is it from completion?\n- 📈 Track changes to requirements and be clear about the cost of those changes\n  - How do they affect the completion?\n  - Should we cut some existing features in order to accommodate the new work? \n- 📊 Ensure observability and monitoring is in place. \n- ⛑ Define a rollout plan and what the roll back steps look like. \n  - What systems need to be integrated with?\n  - Notify appropriate on-call and support teams\n- ❤️ Retro \n  - What went well, what didn't, what could we do differently in future?\n- 🎉 CELEBRATE!\n\n## User Stories\n\n\u003e Gherkin is plain-text with a little extra structure and is designed to be easy to learn by non-programmers, yet structured enough to allow concise description of examples to illustrate business rules in most real-world domains. -- [https://cucumber.io/docs/reference](https://cucumber.io/docs/reference)\n\nIt's good for documentation and it can be helpful to some teams to use these user stories as a foundation for their own integration testing systems (although I personally wouldn't, I prefer just using them as a simple reference for what it is we want to achieve at a high-level).\n\n```cucumber\nFeature: User Authentication\n  \n  ...optional description about this feature here...\n\nScenario: authenticated user requesting a page\n  Given I am a BuzzFeed user (internal or external)\n  And I’m already signed in\n  When I visit www.buzzfeed.com or www.buzzfeed.com/post\n  Then I am directed to my destination page\n\nScenario: unauthenticated user requesting a page\n  Given I am a BuzzFeed user (internal or external)\n  And I’m not signed in\n  When I visit www.buzzfeed.com or www.buzzfeed.com/post\n  Then I am able to login with \u003cmethod\u003e\n\n  Examples:\n    | method            |\n    | Facebook          |\n    | Twitter           |\n    | Google            |\n    | Username/Password |\n\nScenario: unauthenticated user successful login\n  Given I am a BuzzFeed user (internal or external)\n  And I provide valid credentials\n  When I attempt to login\n  Then I am directed to my destination page\n\nScenario: unauthenticated user failed login\n  Given I am a BuzzFeed user (internal or external)\n  And I provide invalid credentials\n  When I attempt to login\n  Then I am presented with a login error\n\nScenario: unauthenticated user sign-up\n  Given I am a BuzzFeed user (internal or external)\n  And I am not already registered in the system\n  When I visit www.buzzfeed.com/cms\n  Then I am directed to a legacy sign-up flow\n```\n\n## Positive Mindset\n\nI've found that swapping the word \"problem\" for \"challenge\" a good thing to do in general, whether it be talking about an actual technical challenge or discussing a challenging interaction with another employee. The subtle switch in language helps me refocus on a more positive and motivated projectory (rather than setting myself up to be in a negative mindset for the conversation).\n\n## Recognising Trends\n\nIt can be useful, when reporting to your line manager (e.g. 1:1's where you discuss things that are on your mind), it can be difficult sometimes to voice concerns without explicit examples. \n\nDepending on the situation, explicit examples aren't always possible to recall. In those cases where you have a niggling feeling something isn't quite right but you couldn't point to an exact point in time where an incident occurred, then being able to see a _trend_ of something negative happening can help you to raise it up to leadership.\n\nBe aware of trends in people, otherwise you might find yourself in a bad situation and not sure how or why you got there in the first place. Not everything is so 'black and white' and obvious.\n","tags":"#management #process #project #pm"},{"id":"c22b1266f9df01bff6671f30ef7bf4a2","title":"[Sync Pool Golang] ","content":"// http://www.akshaydeo.com/blog/2017/12/23/How-did-I-improve-latency-by-700-percent-using-syncPool/\n\nimport (\n\t\"fmt\"\n\t\"sync\"\n\t\"time\"\n)\n\n// Pool for our struct A\nvar pool *sync.Pool\n\n// A dummy struct with a member \ntype A struct {\n\tName string\n}\n\n// Func to init pool\nfunc initPool() {\n\tpool = \u0026sync.Pool {\n\t\tNew: func()interface{} {\n\t\t\tfmt.Println(\"Returning new A\")\n\t\t\treturn new(A)\n\t\t},\n\t}\n}\n\n// Main func\nfunc main() {\n\t// Initializing pool\n\tinitPool()\n\n\t// Get hold of instance one\n\tone := pool.Get().(*A)\n\n\tone.Name = \"first\"\n\n\tfmt.Printf(\"one.Name = %s\\n\", one.Name)\n\n\t// Submit back the instance after using\n\tpool.Put(one)\n\n\t// Now the same instance becomes usable by another routine without allocating it again\n  \t//\n    // Note: depending on the data type in your pool, you might want to make sure that you\n    // zero out the data in the object before putting it back into the pool.\n    //\n    // An example of this would be a complex/expensive object creation for user authentication.\n    // But putting back a user object with a username/password would be bad as the next request\n    // would pull those values out of the pool.\n    //\n    // Meaning, if you use the pool for reducing the overhead of recreating objects, then that's\n    // fine but just be aware of making the pool dirty by putting back stateful objects.\n}\n","tags":"#pool #concurrency #go #golang"},{"id":"24df00f9d954aec96e9de27d4032a2d0","title":"[gpg agent connection refused] ","content":"Error:\n\n```\ncan't connect to `/root/.gnupg/S.gpg-agent': Connection refused\ngpg: can't connect to `/root/.gnupg/S.gpg-agent': connect failed\n```\n\nTry running:\n\n```bash\n$ gpg-connect-agent /bye\n```\n","tags":"#gpg"},{"id":"7d9b10e7f691605792cc182910eb070f","title":"Go: Server Boilerplate ","content":"package main\n\nimport (\n\t\"fmt\"\n\t\"log\"\n\t\"net/http\"\n)\n\ntype server struct {\n\trouter *http.ServeMux\n}\n\nfunc (s *server) routes() {\n\ts.router.HandleFunc(\"/health\", s.handleHealth())\n\ts.router.HandleFunc(\"/\", s.adminOnly(s.handleIndex()))\n}\n\nfunc (s *server) handleHealth() http.HandlerFunc {\n\tfmt.Println(\"handler setup only happens once\")\n\tbody := \"OK\"\n\n\treturn func(w http.ResponseWriter, r *http.Request) {\n\t\tfmt.Fprintf(w, body)\n\t}\n}\n\nfunc (s *server) handleIndex() http.HandlerFunc {\n\treturn func(w http.ResponseWriter, r *http.Request) {\n\t\tfmt.Fprintf(w, \"secret stuff\")\n\t}\n}\n\n// middleware example\n// visit /?admin=true vs /?admin=false\nfunc (s *server) adminOnly(h http.HandlerFunc) http.HandlerFunc {\n\treturn func(w http.ResponseWriter, r *http.Request) {\n\t\tqs := r.URL.Query()\n\n\t\tif qs.Get(\"admin\") != \"true\" {\n\t\t\thttp.NotFound(w, r)\n\t\t\treturn\n\t\t}\n\n\t\th(w, r)\n\t}\n}\n\nfunc main() {\n\ts := server{\n\t\trouter: http.NewServeMux(),\n\t}\n\ts.routes()\n\tlog.Fatal(http.ListenAndServe(\":9000\", s.router))\n}\n","tags":"#go #http #project"},{"id":"1f07d02d411958f024eddd387b37fc19","title":"[Python Warrant Cognito] ","content":"from warrant import Cognito, dict_to_cognito\n\nuser_pool_id = 'xxxx'\nclient_id = 'xxxx'\naws_application_access_key = 'xxxx'\naws_application_secret_key = 'xxxx'\ncognito_user_pool_app_secret_key = 'xxxx'\n\nusername = 'foo'\nemail = 'foo@foo.com'\nname = 'foo bar'\n\nu = Cognito(user_pool_id,\n            client_id,\n            access_key=aws_application_access_key,\n            secret_key=aws_application_secret_key,\n            client_secret=cognito_user_pool_app_secret_key,\n            username=username)\n\nu.add_base_attributes(email=email, name=name)\nu.add_custom_attributes(something='here if you like')\n\nattributes = u.base_attributes.copy()\nattributes.update(u.custom_attributes)\nattributes.update({'email_verified': 'true'})\n\ncognito_attributes = dict_to_cognito(attributes)\n\ntemp_password = \"foo\"\n\nresponse = u.client.admin_create_user(**{'UserPoolId': u.user_pool_id,\n                                         'UserAttributes': cognito_attributes,\n                                         'Username': username,\n                                         'TemporaryPassword': temp_password,\n                                         'MessageAction': 'SUPPRESS'})\n\nattributes.update(username=username, password=temp_password)\nu._set_attributes(response, attributes)\n\nauth_params = {'USERNAME': username, 'PASSWORD': temp_password}\nu._add_secret_hash(auth_params, 'SECRET_HASH')\n\nchallenge = u.client.admin_initiate_auth(\n    UserPoolId=u.user_pool_id,\n    ClientId=u.client_id,\n    AuthFlow='ADMIN_NO_SRP_AUTH',\n    AuthParameters=auth_params,\n)\n\ntokens = u.client.admin_respond_to_auth_challenge(\n    UserPoolId=u.user_pool_id,\n    ClientId=u.client_id,\n    ChallengeName=challenge['ChallengeName'],\n    ChallengeResponses={\n        'USERNAME': username,\n        'NEW_PASSWORD': 'foobarbaz',\n        'SECRET_HASH': auth_params['SECRET_HASH'],\n    },\n    Session=challenge['Session'],\n)\n\nu.verify_token(tokens['AuthenticationResult']['IdToken'], 'id_token','id')\nu.refresh_token = tokens['AuthenticationResult']['RefreshToken']\nu.verify_token(tokens['AuthenticationResult']['AccessToken'], 'access_token','access')\nu.token_type = tokens['AuthenticationResult']['TokenType']\nuser_pool_id = settings.get('cognito_user_pool_id')\nclient_id = settings.get('cognito_user_pool_app_client_id')\n\n#####################################\n\n# note: we need actual access keys, so I created a new IAM user\n# the client application's secret key wasn't used\n\nu = Cognito(user_pool_id, client_id,\n            access_key=settings.get('aws_application_access_key'),\n            secret_key=settings.get('aws_application_secret_key'))\n            users = u.get_users(attr_map={\"name\": \"full_name\"})\n\nif settings.get(\"debug\"):\n    for user in users:\n        logging.info(user.__dict__)\n        \n#####################################\n        \nu = Cognito(user_pool_id, client_id,\n            client_secret=settings.get('cognito_user_pool_app_secret_key'),\n            access_key=settings.get('aws_application_access_key'),\n            secret_key=settings.get('aws_application_secret_key'),\n            username='...',\n            id_token='...',\n            access_token='...',\n            refresh_token='...')\n\nresponse = u.check_token(renew=False)  # leave off `renew` if you want Warrant to attempt to refresh expired tokens\n\n","tags":"#python #cognito"},{"id":"9e0c5ee9c2cc2568dd1961bf370716c9","title":"[Python's Pipenv] ","content":"## tl;dr\n\n- `brew install pyenv`\n- `pip install pipenv`\n- `pipenv --python 3.7` (`pyenv install --list`)\n- `pipenv shell`\n- `pipenv install tornado==5.0.2`\n- `pipenv install --dev mypy tox flake8`\n- `pipenv install -r requirements.txt` (generate Pipfile from requirements.txt)\n- `pipenv lock --requirements` (generate a requirements.txt equivalent to a Pipfile)\n\n## Long explanation...\n\n[https://github.com/pypa/pipenv](https://github.com/pypa/pipenv)\n\nFirst, make sure you're using your system install of Python (likely 2.7.x) and you have no other python environments installed, otherwise that may cause you confusion if things don't work as you expect (basically, have a spring clean of your previous/old python setup).\n\nNext make sure you have `pyenv` installed (e.g. `brew install pyenv`) as Pipenv uses that for installing python versions.\n\n\u003e Note: it's unclear if Pipenv will handle installing pyenv for you, so maybe try the following steps _without_ installing pyenv and see if installing a new python version (as described below) works or not.\n\n```bash\npip install pipenv\n```\n\n\u003e Note: also, if you try to install a new Python version, I've noticed it errors saying `python-build` definitions are out of date and need to be updated to install the new version. The `python-build` is used by `pyenv` so again, it's unclear if `python-build` is installed by Pipenv or if it has to be manually installed along with `pyenv` 🤔\n\nHere's an example `Dockerfile` to try things out:\n\n```Dockerfile\nFROM python:3.6.5\n\n# Jump into directory where our Pipfile will be found\nWORKDIR /app\n\n# Install pipenv for managing dependencies instead of pip\nRUN pip install -U pipenv==10.*\n\n# This pip.conf configures pip to use our internal pypi mirror when installing\n# python packages. It's not in this service's directory, but is put in place\n# the .rig/hooks/prebuild_setup_internal_packages global prebuild hook before\n# the image is built.\nCOPY pip.conf /etc/pip.conf\n\n# Copy over both Pipfile and Pipfile.lock\nCOPY ./Pipfile* /app/\n\n# Install all dependencies to the system version (3.6.5)\nRUN pipenv install --system --deploy\n\nCOPY . /app/\n\nCMD [\"/app/service.py\"]\n```\n\nFor me this installed `pipenv-2018.5.18`.\n\nHere are the basic commands available with `pipenv`:\n\n```bash\n$ pipenv\n\nUsage: pipenv [OPTIONS] COMMAND [ARGS]...\n\nOptions:\n  --where          Output project home information.\n  --venv           Output virtualenv information.\n  --py             Output Python interpreter information.\n  --envs           Output Environment Variable options.\n  --rm             Remove the virtualenv.\n  --bare           Minimal output.\n  --completion     Output completion (to be eval'd).\n  --man            Display manpage.\n  --three / --two  Use Python 3/2 when creating virtualenv.\n  --python TEXT    Specify which version of Python virtualenv should use.\n  --site-packages  Enable site-packages for the virtualenv.\n  --version        Show the version and exit.\n  -h, --help       Show this message and exit.\n\n\nUsage Examples:\n   Create a new project using Python 3.6, specifically:\n   $ pipenv --python 3.6\n\n   Install all dependencies for a project (including dev):\n   $ pipenv install --dev\n\n   Create a lockfile containing pre-releases:\n   $ pipenv lock --pre\n\n   Show a graph of your installed dependencies:\n   $ pipenv graph\n\n   Check your installed dependencies for security vulnerabilities:\n   $ pipenv check\n\n   Install a local setup.py into your virtual environment/Pipfile:\n   $ pipenv install -e .\n\n   Use a lower-level pip command:\n   $ pipenv run pip freeze\n\nCommands:\n  check      Checks for security vulnerabilities and against PEP 508 markers\n             provided in Pipfile.\n  clean      Uninstalls all packages not specified in Pipfile.lock.\n  graph      Displays currently–installed dependency graph information.\n  install    Installs provided packages and adds them to Pipfile, or (if none\n             is given), installs all packages.\n  lock       Generates Pipfile.lock.\n  open       View a given module in your editor.\n  run        Spawns a command installed into the virtualenv.\n  shell      Spawns a shell within the virtualenv.\n  sync       Installs all packages specified in Pipfile.lock.\n  uninstall  Un-installs a provided package and removes it from Pipfile.\n  update     Runs lock, then sync.\n```\n\nLet's create a new project using Python 3.6:\n\n```bash\n$ pipenv --python 3.6\n\nCreating a virtualenv for this project…\nUsing /Users/markmcdonnell/.pyenv/versions/3.6.3/bin/python3.6m (3.6.3) to create virtualenv…\n⠋Running virtualenv with interpreter /Users/markmcdonnell/.pyenv/versions/3.6.3/bin/python3.6m\nUsing base prefix '/Users/markmcdonnell/.pyenv/versions/3.6.3'\nNew python executable in /Users/markmcdonnell/.local/share/virtualenvs/testing_pipenv-jvIwu3TP/bin/python3.6m\nAlso creating executable in /Users/markmcdonnell/.local/share/virtualenvs/testing_pipenv-jvIwu3TP/bin/python\nInstalling setuptools, pip, wheel...done.\n\nVirtualenv location: /Users/markmcdonnell/.local/share/virtualenvs/testing_pipenv-jvIwu3TP\nCreating a Pipfile for this project…\n```\n\nThis will create a `Pipfile`:\n\n```ini\n[[source]]\nurl = \"https://pypi.org/simple\"\nverify_ssl = true\nname = \"pypi\"\n\n[dev-packages]\n\n[packages]\n\n[requires]\npython_version = \"3.6\"\n```\n\nBut the current terminal/shell will be using the system Python still:\n\n```bash\n$ python --version\n\nPython 2.7.10\n```\n\nIn order to use the installed Python environment, you need to spin up a new shell:\n\n```bash\n$ pipenv shell\n\nSpawning environment shell (/usr/local/bin/bash). Use 'exit' to leave.\n. /Users/markmcdonnell/.local/share/virtualenvs/testing_pipenv-jvIwu3TP/bin/activate\n\n$ python --version\nPython 3.6.3\n```\n\n\u003e Note: when switching between git branches you might find odd things happen. I've found the best thing to do is to first check with `python --version` to see if you're using the system python or not and if you are using Pipenv still, to then `exit` so you leave the virtual environment shell that's running. Then change your git branch and move into whatever directory you need to and re-run `pipenv shell`.\n\nLet's install two dependencies (we'll see the `Pipfile` is updated and a `Pipfile.lock` is generated):\n\n```bash\n$ pipenv install boto3\n\nInstalling boto3…\nCollecting boto3\n  Downloading https://files.pythonhosted.org/packages/b8/29/f35b0a055014296bf4188043e2cc1fd4ca041a085991765598842232c2f5/boto3-1.7.26-py2.py3-none-any.whl (128kB)\nCollecting jmespath\u003c1.0.0,\u003e=0.7.1 (from boto3)\n  Using cached https://files.pythonhosted.org/packages/b7/31/05c8d001f7f87f0f07289a5fc0fc3832e9a57f2dbd4d3b0fee70e0d51365/jmespath-0.9.3-py2.py3-none-any.whl\nCollecting s3transfer\u003c0.2.0,\u003e=0.1.10 (from boto3)\n  Using cached https://files.pythonhosted.org/packages/d7/14/2a0004d487464d120c9fb85313a75cd3d71a7506955be458eebfe19a6b1d/s3transfer-0.1.13-py2.py3-none-any.whl\nCollecting botocore\u003c1.11.0,\u003e=1.10.26 (from boto3)\n  Downloading https://files.pythonhosted.org/packages/87/c5/7ed94b700d30534f346bb55408ca8501325840bcdc371628cff10d7ba68d/botocore-1.10.26-py2.py3-none-any.whl (4.2MB)\nCollecting docutils\u003e=0.10 (from botocore\u003c1.11.0,\u003e=1.10.26-\u003eboto3)\n  Downloading https://files.pythonhosted.org/packages/36/fa/08e9e6e0e3cbd1d362c3bbee8d01d0aedb2155c4ac112b19ef3cae8eed8d/docutils-0.14-py3-none-any.whl (543kB)\nCollecting python-dateutil\u003c3.0.0,\u003e=2.1; python_version \u003e= \"2.7\" (from botocore\u003c1.11.0,\u003e=1.10.26-\u003eboto3)\n  Using cached https://files.pythonhosted.org/packages/cf/f5/af2b09c957ace60dcfac112b669c45c8c97e32f94aa8b56da4c6d1682825/python_dateutil-2.7.3-py2.py3-none-any.whl\nCollecting six\u003e=1.5 (from python-dateutil\u003c3.0.0,\u003e=2.1; python_version \u003e= \"2.7\"-\u003ebotocore\u003c1.11.0,\u003e=1.10.26-\u003eboto3)\n  Downloading https://files.pythonhosted.org/packages/67/4b/141a581104b1f6397bfa78ac9d43d8ad29a7ca43ea90a2d863fe3056e86a/six-1.11.0-py2.py3-none-any.whl\nInstalling collected packages: jmespath, docutils, six, python-dateutil, botocore, s3transfer, boto3\nSuccessfully installed boto3-1.7.26 botocore-1.10.26 docutils-0.14 jmespath-0.9.3 python-dateutil-2.7.3 s3transfer-0.1.13 six-1.11.0\n\nAdding boto3 to Pipfile's [packages]…\nPipfile.lock not found, creating…\nLocking [dev-packages] dependencies…\nLocking [packages] dependencies…\nUpdated Pipfile.lock (00df60)!\nInstalling dependencies from Pipfile.lock (00df60)…\n  🐍   ▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉ 7/7 — 00:00:01\n  \n$ pipenv install ipython\n\n...same sort of stuff..\n\n$ pipenv install pyre-check --dev\n\n...same sort of stuff..\n```\n\nHere's a look at the current `Pipfile`:\n\n```ini\n[[source]]\nurl = \"https://pypi.org/simple\"\nverify_ssl = true\nname = \"pypi\"\n\n[dev-packages]\npyre-check = \"*\"\n\n[packages]\n\"boto3\" = \"*\"\nipython = \"*\"\n\n[requires]\npython_version = \"3.6\"\n```\n\nWe can now utilise these dependencies:\n\n```bash\n$ which ipython\n\n/Users/markmcdonnell/.local/share/virtualenvs/testing_pipenv-jvIwu3TP/bin/ipython\n\n$ ipython\n\nPython 3.6.3 (default, Oct 13 2017, 11:47:13)\nType 'copyright', 'credits' or 'license' for more information\nIPython 6.4.0 -- An enhanced Interactive Python. Type '?' for help.\n\nIn [1]: import boto3\n\nIn [2]: type(boto3.client('cognito-idp'))\nOut[2]: botocore.client.CognitoIdentityProvider\n```\n\nThere are other ways to install dependencies:\n\n- Explicit versions: `pipenv install flask==0.12.1`\n- Git: `pipenv install -e git+https://github.com/requests/requests.git#egg=requests`\n- AWS Lambda zip generation: `pipenv run pip install -r \u003c(pipenv lock -r) --target dist/`\n\nYou can also graph out all your dependencies:\n\n```bash\n$ pipenv graph\n\nboto3==1.7.26\n  - botocore [required: \u003e=1.10.26,\u003c1.11.0, installed: 1.10.26]\n    - docutils [required: \u003e=0.10, installed: 0.14]\n    - jmespath [required: \u003c1.0.0,\u003e=0.7.1, installed: 0.9.3]\n    - python-dateutil [required: \u003e=2.1,\u003c3.0.0, installed: 2.7.3]\n      - six [required: \u003e=1.5, installed: 1.11.0]\n  - jmespath [required: \u003c1.0.0,\u003e=0.7.1, installed: 0.9.3]\n  - s3transfer [required: \u003c0.2.0,\u003e=0.1.10, installed: 0.1.13]\n    - botocore [required: \u003e=1.3.0,\u003c2.0.0, installed: 1.10.26]\n      - docutils [required: \u003e=0.10, installed: 0.14]\n      - jmespath [required: \u003c1.0.0,\u003e=0.7.1, installed: 0.9.3]\n      - python-dateutil [required: \u003e=2.1,\u003c3.0.0, installed: 2.7.3]\n        - six [required: \u003e=1.5, installed: 1.11.0]\nipython==6.4.0\n  - appnope [required: Any, installed: 0.1.0]\n  - backcall [required: Any, installed: 0.1.0]\n  - decorator [required: Any, installed: 4.3.0]\n  - jedi [required: \u003e=0.10, installed: 0.12.0]\n    - parso [required: \u003e=0.2.0, installed: 0.2.1]\n  - pexpect [required: Any, installed: 4.5.0]\n    - ptyprocess [required: \u003e=0.5, installed: 0.5.2]\n  - pickleshare [required: Any, installed: 0.7.4]\n  - prompt-toolkit [required: \u003e=1.0.15,\u003c2.0.0, installed: 1.0.15]\n    - six [required: \u003e=1.9.0, installed: 1.11.0]\n    - wcwidth [required: Any, installed: 0.1.7]\n  - pygments [required: Any, installed: 2.2.0]\n  - setuptools [required: \u003e=18.5, installed: 39.2.0]\n  - simplegeneric [required: \u003e0.8, installed: 0.8.1]\n  - traitlets [required: \u003e=4.2, installed: 4.3.2]\n    - decorator [required: Any, installed: 4.3.0]\n    - ipython-genutils [required: Any, installed: 0.2.0]\n    - six [required: Any, installed: 1.11.0]\npyre-check==0.0.6\ntyped-ast==1.1.0\n```\n\n\u003e You can reverse the graph direction using the `--reverse` flag.\n\nYou can verify the security of your dependencies:\n\n```bash\n$ pipenv check\n\nChecking PEP 508 requirements…\nPassed!\n\nChecking installed package safety…\nAll good!\n```\n\nYou can also look at the code for any of your dependencies, and their code directory will be opened in whichever editor is assigned to the `$EDITOR` environment variable in your shell (for me this is `vim`):\n\n```bash\n$ pipenv open boto3\n\nOpening '/Users/markmcdonnell/.local/share/virtualenvs/testing_pipenv-jvIwu3TP/lib/python3.6/site-packages/boto3' in your EDITOR.\n```\n\nHere's a look at our final `Pipfile.lock`:\n\n```json\n{\n    \"_meta\": {\n        \"hash\": {\n            \"sha256\": \"e79d3c5ef5705053b19f7c653dc0adb3e99d75726138633ae95a5b3709f2e51c\"\n        },\n        \"pipfile-spec\": 6,\n        \"requires\": {\n            \"python_version\": \"3.6\"\n        },\n        \"sources\": [\n            {\n                \"name\": \"pypi\",\n                \"url\": \"https://pypi.org/simple\",\n                \"verify_ssl\": true\n            }\n        ]\n    },\n    \"default\": {\n        \"appnope\": {\n            \"hashes\": [\n                \"sha256:5b26757dc6f79a3b7dc9fab95359328d5747fcb2409d331ea66d0272b90ab2a0\",\n                \"sha256:8b995ffe925347a2138d7ac0fe77155e4311a0ea6d6da4f5128fe4b3cbe5ed71\"\n            ],\n            \"markers\": \"sys_platform == 'darwin'\",\n            \"version\": \"==0.1.0\"\n        },\n        \"backcall\": {\n            \"hashes\": [\n                \"sha256:38ecd85be2c1e78f77fd91700c76e14667dc21e2713b63876c0eb901196e01e4\",\n                \"sha256:bbbf4b1e5cd2bdb08f915895b51081c041bac22394fdfcfdfbe9f14b77c08bf2\"\n            ],\n            \"version\": \"==0.1.0\"\n        },\n        \"boto3\": {\n            \"hashes\": [\n                \"sha256:6dd9a6fe523c3e4d4fc28fe7030453ee5b4e75e778144cf22008c79dfc031bd3\",\n                \"sha256:fccad296209cfbee668292d51bd3b258eb85d4bce1bf1a5dcb2e24942a00d48a\"\n            ],\n            \"index\": \"pypi\",\n            \"version\": \"==1.7.26\"\n        },\n        \"botocore\": {\n            \"hashes\": [\n                \"sha256:c63c77e41cd514d80da06eb626f5e9f50c94c44b0206957aca23a20f889abb05\",\n                \"sha256:ca23fb013a18584a3a7043c6cc0bf02250f2665937e73290f65f1f48ee9b4f78\"\n            ],\n            \"version\": \"==1.10.26\"\n        },\n        \"decorator\": {\n            \"hashes\": [\n                \"sha256:2c51dff8ef3c447388fe5e4453d24a2bf128d3a4c32af3fabef1f01c6851ab82\",\n                \"sha256:c39efa13fbdeb4506c476c9b3babf6a718da943dab7811c206005a4a956c080c\"\n            ],\n            \"version\": \"==4.3.0\"\n        },\n        \"docutils\": {\n            \"hashes\": [\n                \"sha256:02aec4bd92ab067f6ff27a38a38a41173bf01bed8f89157768c1573f53e474a6\",\n                \"sha256:51e64ef2ebfb29cae1faa133b3710143496eca21c530f3f71424d77687764274\",\n                \"sha256:7a4bd47eaf6596e1295ecb11361139febe29b084a87bf005bf899f9a42edc3c6\"\n            ],\n            \"version\": \"==0.14\"\n        },\n        \"ipython\": {\n            \"hashes\": [\n                \"sha256:a0c96853549b246991046f32d19db7140f5b1a644cc31f0dc1edc86713b7676f\",\n                \"sha256:eca537aa61592aca2fef4adea12af8e42f5c335004dfa80c78caf80e8b525e5c\"\n            ],\n            \"index\": \"pypi\",\n            \"version\": \"==6.4.0\"\n        },\n        \"ipython-genutils\": {\n            \"hashes\": [\n                \"sha256:72dd37233799e619666c9f639a9da83c34013a73e8bbc79a7a6348d93c61fab8\",\n                \"sha256:eb2e116e75ecef9d4d228fdc66af54269afa26ab4463042e33785b887c628ba8\"\n            ],\n            \"version\": \"==0.2.0\"\n        },\n        \"jedi\": {\n            \"hashes\": [\n                \"sha256:1972f694c6bc66a2fac8718299e2ab73011d653a6d8059790c3476d2353b99ad\",\n                \"sha256:5861f6dc0c16e024cbb0044999f9cf8013b292c05f287df06d3d991a87a4eb89\"\n            ],\n            \"version\": \"==0.12.0\"\n        },\n        \"jmespath\": {\n            \"hashes\": [\n                \"sha256:6a81d4c9aa62caf061cb517b4d9ad1dd300374cd4706997aff9cd6aedd61fc64\",\n                \"sha256:f11b4461f425740a1d908e9a3f7365c3d2e569f6ca68a2ff8bc5bcd9676edd63\"\n            ],\n            \"version\": \"==0.9.3\"\n        },\n        \"parso\": {\n            \"hashes\": [\n                \"sha256:cdef26e8adc10d589f3ec4eb444bd0a29f3f1eb6d72a4292ab8afcb9d68976a6\",\n                \"sha256:f0604a40b96e062b0fd99cf134cc2d5cdf66939d0902f8267d938b0d5b26707f\"\n            ],\n            \"version\": \"==0.2.1\"\n        },\n        \"pexpect\": {\n            \"hashes\": [\n                \"sha256:9783f4644a3ef8528a6f20374eeb434431a650c797ca6d8df0d81e30fffdfa24\",\n                \"sha256:9f8eb3277716a01faafaba553d629d3d60a1a624c7cf45daa600d2148c30020c\"\n            ],\n            \"markers\": \"sys_platform != 'win32'\",\n            \"version\": \"==4.5.0\"\n        },\n        \"pickleshare\": {\n            \"hashes\": [\n                \"sha256:84a9257227dfdd6fe1b4be1319096c20eb85ff1e82c7932f36efccfe1b09737b\",\n                \"sha256:c9a2541f25aeabc070f12f452e1f2a8eae2abd51e1cd19e8430402bdf4c1d8b5\"\n            ],\n            \"version\": \"==0.7.4\"\n        },\n        \"prompt-toolkit\": {\n            \"hashes\": [\n                \"sha256:1df952620eccb399c53ebb359cc7d9a8d3a9538cb34c5a1344bdbeb29fbcc381\",\n                \"sha256:3f473ae040ddaa52b52f97f6b4a493cfa9f5920c255a12dc56a7d34397a398a4\",\n                \"sha256:858588f1983ca497f1cf4ffde01d978a3ea02b01c8a26a8bbc5cd2e66d816917\"\n            ],\n            \"version\": \"==1.0.15\"\n        },\n        \"ptyprocess\": {\n            \"hashes\": [\n                \"sha256:e64193f0047ad603b71f202332ab5527c5e52aa7c8b609704fc28c0dc20c4365\",\n                \"sha256:e8c43b5eee76b2083a9badde89fd1bbce6c8942d1045146e100b7b5e014f4f1a\"\n            ],\n            \"version\": \"==0.5.2\"\n        },\n        \"pygments\": {\n            \"hashes\": [\n                \"sha256:78f3f434bcc5d6ee09020f92ba487f95ba50f1e3ef83ae96b9d5ffa1bab25c5d\",\n                \"sha256:dbae1046def0efb574852fab9e90209b23f556367b5a320c0bcb871c77c3e8cc\"\n            ],\n            \"version\": \"==2.2.0\"\n        },\n        \"python-dateutil\": {\n            \"hashes\": [\n                \"sha256:1adb80e7a782c12e52ef9a8182bebeb73f1d7e24e374397af06fb4956c8dc5c0\",\n                \"sha256:e27001de32f627c22380a688bcc43ce83504a7bc5da472209b4c70f02829f0b8\"\n            ],\n            \"markers\": \"python_version \u003e= '2.7'\",\n            \"version\": \"==2.7.3\"\n        },\n        \"s3transfer\": {\n            \"hashes\": [\n                \"sha256:90dc18e028989c609146e241ea153250be451e05ecc0c2832565231dacdf59c1\",\n                \"sha256:c7a9ec356982d5e9ab2d4b46391a7d6a950e2b04c472419f5fdec70cc0ada72f\"\n            ],\n            \"version\": \"==0.1.13\"\n        },\n        \"simplegeneric\": {\n            \"hashes\": [\n                \"sha256:dc972e06094b9af5b855b3df4a646395e43d1c9d0d39ed345b7393560d0b9173\"\n            ],\n            \"version\": \"==0.8.1\"\n        },\n        \"six\": {\n            \"hashes\": [\n                \"sha256:70e8a77beed4562e7f14fe23a786b54f6296e34344c23bc42f07b15018ff98e9\",\n                \"sha256:832dc0e10feb1aa2c68dcc57dbb658f1c7e65b9b61af69048abc87a2db00a0eb\"\n            ],\n            \"version\": \"==1.11.0\"\n        },\n        \"traitlets\": {\n            \"hashes\": [\n                \"sha256:9c4bd2d267b7153df9152698efb1050a5d84982d3384a37b2c1f7723ba3e7835\",\n                \"sha256:c6cb5e6f57c5a9bdaa40fa71ce7b4af30298fbab9ece9815b5d995ab6217c7d9\"\n            ],\n            \"version\": \"==4.3.2\"\n        },\n        \"wcwidth\": {\n            \"hashes\": [\n                \"sha256:3df37372226d6e63e1b1e1eda15c594bca98a22d33a23832a90998faa96bc65e\",\n                \"sha256:f4ebe71925af7b40a864553f761ed559b43544f8f71746c2d756c7fe788ade7c\"\n            ],\n            \"version\": \"==0.1.7\"\n        }\n    },\n    \"develop\": {\n        \"pyre-check\": {\n            \"hashes\": [\n                \"sha256:2d631e00c15761bdeef0e3f70e3b54f8cfa2765018d42a841cbfe7373574db6d\",\n                \"sha256:a05d569441a1eadc5acbb8574710d69171898a2c02fa196e1d162faf77dc4f02\"\n            ],\n            \"index\": \"pypi\",\n            \"version\": \"==0.0.6\"\n        }\n    }\n}\n```\n","tags":"#python #pip #pipenv #virtualenv"},{"id":"911252f81830ff0ed650145c4d52f58e","title":"[Python Tornado Basic Auth Middleware] ","content":"\"\"\"\nExplanation:\n    tornado.web.RequestHandler calls an internal `_execute` method before\n    calling any other method such as `get` or `post` etc.\n\n    we wrap the internal `_execute` method so that it either returns False if\n    no basic authentication provided or it will return the result of calling\n    the actual `_execute` method.\n\nTutorial:\n    http://kevinsayscode.tumblr.com/post/7362319243/easy-basic-http-authentication-with-tornado\n\"\"\"\n\nimport base64\n\nimport tornado.ioloop\nimport tornado.web\n\n\ndef require_basic_auth(handler_class):\n    def wrap_execute(handler_execute):\n        # returns True is basic auth provided, otherwise it sends back a 401\n        # status code and requests user input their credentials.\n        #\n        # todo: write logic or pass in a function so that it can determine\n        # whether the authentication is accepted (e.g. you find the credentials\n        # within an external database).\n        def check_basic_auth(handler, kwargs):\n            def render_inputs(handler):\n                # If the browser didn't send us authorization headers,\n                # send back a response letting it know that we'd like\n                # a username and password (the \"Basic\" authentication\n                # method).  Without this, even if your visitor puts a\n                # username and password in the URL, the browser won't\n                # send it.  The \"realm\" option in the header is the\n                # name that appears in the dialog that pops up in your\n                # browser.\n                handler.set_status(401)\n                handler.set_header('WWW-Authenticate', 'Basic realm=Restricted')  # noqa\n                handler._transforms = []\n                handler.finish()\n\n            auth_header = handler.request.headers.get('Authorization')\n            if auth_header is None or not auth_header.startswith('Basic '):\n                render_inputs(handler)\n                return False\n\n            # The information that the browser sends us is\n            # base64-encoded, and in the format \"username:password\".\n            # Keep in mind that either username or password could\n            # still be unset, and that you should check to make sure\n            # they reflect valid credentials!\n            auth_decoded = base64.decodebytes(bytes(auth_header[6:], 'utf-8'))\n            username, password = auth_decoded.decode('utf-8').split(':', 2)\n            kwargs['basicauth_user'], kwargs['basicauth_pass'] = username, password  # noqa\n\n            # foo and bar should be pulled from somewhere, not hardcoded!\n            if username != \"foo\" and password != \"bar\":\n                render_inputs(handler)\n                return False\n\n            return True\n\n        # Since we're going to attach this to a RequestHandler class,\n        # the first argument will wind up being a reference to an\n        # instance of that class.\n        def _execute(self, transforms, *args, **kwargs):\n            if not check_basic_auth(self, kwargs):\n                return False\n            return handler_execute(self, transforms, *args, **kwargs)\n\n        # return our new function, which either returns False if basic auth\n        # wasn't provided, otherwise it returns the result of calling the\n        # original _execute function.\n        return _execute\n\n    # wrap tornado's internal `_execute` method, which is called first before\n    # any other method in the RequestHandler class\n    handler_class._execute = wrap_execute(handler_class._execute)\n\n    # return the modified class\n    return handler_class\n\n\n@require_basic_auth\nclass MainHandler(tornado.web.RequestHandler):\n    # use !s inside format syntax to control string conversion\n    # https://docs.python.org/3.6/library/string.html#formatstrings\n    def get(self, basicauth_user, basicauth_pass):\n        msg = 'Hi there, {0!s}!  Your password is {1}.'\n        body = msg.format(basicauth_user, basicauth_pass)\n        self.write(body)\n\n    def post(self, **kwargs):\n        basicauth_user = kwargs['basicauth_user']\n        basicauth_pass = kwargs['basicauth_pass']\n        msg = 'Hi there, {0!s}!  Your password is {1}.'\n        body = msg.format(basicauth_user, basicauth_pass)\n        self.write(body)\n\n\ndef make_app():\n    return tornado.web.Application([\n        (r\"/\", MainHandler),\n    ])\n\n\nif __name__ == \"__main__\":\n    app = make_app()\n    app.listen(9000)\n    tornado.ioloop.IOLoop.current().start()\n","tags":"#auth #authentication #basicauth #python #tornado #POST"},{"id":"5f056192ae527a7c7598cab248d73c04","title":"[Pip Python Workflow] ","content":"Some Python projects will have two dependency files:\n\n* `requirements.txt`\n* `requirements-to-freeze.txt`\n\nThe latter should contain both 'explicit' versions (i.e. versions of dependencies our service is known to support) and 'non-explicit' versions (e.g. no versions defined), where as the former (`requirements.txt`) simply acts as a lockfile.\n\nIf we execute `pip freeze` the output will include dependencies that have the explicit versions we requested and the _latest_ version for those dependencies where we defined no explicit version. We can direct that output to a new file called `requirements.txt`.\n\nFor example, your `requirements-to-freeze.txt` could look like:\n\n```\n# install these explicit versions...\npyjwt\u003e=1.5.3\n\n# install the latest of these...\nflake8\npytest\npytest-cov\nmock\n```\n\n","tags":"#pip #python #workflow"},{"id":"f9e9c4dcf621945acfe38bd13734c537","title":"[Monitor TCP traffic from NGINX] ","content":"tcpdump -vvv -s 0 -l -n port 53 -XX\n","tags":"#nginx #tcp #tcpdump"},{"id":"1debaf8bbb27fda5009888d9ff6f59a7","title":"[Jack The Ripper] ","content":"Below the skin of history are London’s veins. \n\nThese symbols, the mitre, the pentacle star, \neven to someone as ignorant and degenerate as you \ncan sense that they course with energy ...and meaning. \n\nI am that meaning. \nI am that energy. \n\nOne day, men will look back and say that I gave birth to the 20th Century.\n\n- Jack The Ripper\n","tags":"#quotes"},{"id":"fe90c05c26037a83ce47ae859b783ce9","title":"[encrypt file using a keyring] ","content":"gpg --homedir=mono/system/keyrings/default --encrypt -o SOME_FILE.gpg -r SOME_ONE@SOME_DOMAIN.com SOME_FILE.md\n","tags":"#gpg #keyring"},{"id":"44f6e2acb3a4e97c96305ed7584f6514","title":"[image quality reduction] ","content":"# sips comes with macOS (so nothing to install)\n\nsips --setProperty formatOptions 80 ~/Downloads/test.jpg\n\n# took a 6.7mb file down to 2.5mb with no apparent loss in quality!\n","tags":"#bash #image #quality"},{"id":"fb1b5dbb6271632298f44d62a2221905","title":"[Python Async Decorator] ","content":"import asyncio\n\nfrom functools import wraps\n\n\ndef dec(fn):\n    @wraps(fn)\n    async def wrapper(*args, **kwargs):\n        print(fn, args, kwargs)  # \u003cfunction foo at 0x10952d598\u003e () {}\n        await asyncio.sleep(5)\n        print(\"done with wrapper, going to call fn\")\n        return await fn()\n    return wrapper\n    \n@dec\nasync def foo():\n    return await asyncio.sleep(5, result=\"i'm done\")\n    \nloop = asyncio.get_event_loop()\nresult = loop.run_until_complete(foo())  \n\nprint(result)  # i'm done\n\nloop.close()\nimport asyncio\nimport time\n\nfrom functools import wraps\n\n\ndef dec(fn):\n    if asyncio.iscoroutinefunction(fn):\n        @wraps(fn)\n        async def wrapper(*args, **kwargs):\n            print(fn, args, kwargs)  # \u003cfunction foo at 0x10952d598\u003e () {}\n            await asyncio.sleep(5)\n            print(\"done with wrapper, going to call fn\")\n            return await fn()\n        return wrapper\n    else:\n        @wraps(fn)\n        def wrapper(*args, **kwargs):\n            print(fn, args, kwargs)  # \u003cfunction bar at 0x108fb5a60\u003e () {}\n            time.sleep(5)\n            print(\"done with wrapper, going to call fn\")\n            return fn()\n        return wrapper\n    \n@dec\nasync def foo():\n    return await asyncio.sleep(5, result=\"async function done\")\n  \n@dec\ndef bar():\n    time.sleep(5)\n    return \"sync function done\"\n    \nloop = asyncio.get_event_loop()\nresult = loop.run_until_complete(foo())  \n\nprint(result)  # async function done\nprint(bar())   # sync  function done\n\nloop.close()\nimport asyncio\n\nfrom functools import wraps\n\n\nasync def foo():\n    return await asyncio.sleep(5, result=\"i'm done\")\n    \nloop = asyncio.get_event_loop()\nresult = loop.run_until_complete(foo())\n\nprint(result)  # i'm done\n\nloop.close()\n","tags":"#python #asyncio #decorator"},{"id":"2af63c57242e1183c37cc0ce1cdc9e1a","title":"[Replace macOS Terminal Emulator with GPU accelerated Alacritty] ","content":"\u003e https://arslan.io/2018/02/05/gpu-accelerated-terminal-alacritty/\n\n- Install rust: `curl https://sh.rustup.rs -sSf | sh`\n- Make rust available: `echo 'source \"$HOME/.cargo/env\"' \u003e\u003e ~/.bashrc`\n- Set rust compiler: `rustup override set stable`\n- Update rust: `rustup update stable`\n- Get Alacritty: `git clone https://github.com/jwilm/alacritty.git`\n- Build Alacritty: `cd alacritty \u0026\u0026 make app`\n- Add Alacritty to your Applications directory: `cp -r target/release/osx/Alacritty.app /Applications/`\n- Create Alacritty config: `mkdir -p ~/.config/alacritty \u0026\u0026 cp alacritty_macos.yml ~/.config/alacritty/alacritty.yml`\n\n\u003e https://github.com/jwilm/alacritty/issues/99 for tmux binding to be reinstated\n","tags":"#macOS #terminal #shell #alacritty"},{"id":"db14b7d8a336176022b49a9e550780e5","title":"[Vim Automatic Bootstrap] ","content":"\"*****************************************************************************\n\"\" Vim-Plug core\n\"*****************************************************************************\n\nif has('vim_starting')\n  set nocompatible\nendif\n\nlet vimplug_exists=expand('~/.vim/autoload/plug.vim')\n\nlet g:vim_bootstrap_langs = \"go,javascript,python\"\nlet g:vim_bootstrap_editor = \"vim\"\t\t\t\t\" nvim or vim\n\nif !filereadable(vimplug_exists)\n  if !executable(\"curl\")\n    echoerr \"You have to install curl or first install vim-plug yourself!\"\n    execute \"q!\"\n  endif\n  echo \"Installing Vim-Plug...\"\n  echo \"\"\n  silent !\\curl -fLo ~/.vim/autoload/plug.vim --create-dirs https://raw.githubusercontent.com/junegunn/vim-plug/master/plug.vim\n  let g:not_finish_vimplug = \"yes\"\n\n  autocmd VimEnter * PlugInstall\nendif\n\n\" Required:\ncall plug#begin(expand('~/.vim/plugged'))\n\n\"*****************************************************************************\n\"\" Plug install packages\n\"*****************************************************************************\n\nPlug 'foo/bar'\n\nif isdirectory('/usr/local/opt/fzf')\n  Plug '/usr/local/opt/fzf' | Plug 'junegunn/fzf.vim'\nelse\n  Plug 'junegunn/fzf', { 'dir': '~/.fzf', 'do': './install --bin' }\n  Plug 'junegunn/fzf.vim'\nendif\n    \nlet g:make = 'gmake'\nif exists('make')\n        let g:make = 'make'\nendif\n\n\"*****************************************************************************\n\"\" Custom bundles\n\"*****************************************************************************\n\n\" go\nPlug 'fatih/vim-go', {'do': ':GoInstallBinaries'}\n\n\" javascript\nPlug 'jelera/vim-javascript-syntax'\n\n\" python\nPlug 'raimon49/requirements.txt.vim', {'for': 'requirements'}\n\n\"*****************************************************************************\n\"*****************************************************************************\n\n\"\" Include user's extra bundle\nif filereadable(expand(\"~/.vimrc.local.bundles\"))\n  source ~/.vimrc.local.bundles\nendif\n\ncall plug#end()\n\n\" Required:\nfiletype plugin indent on\n\n\"*****************************************************************************\n\"\" Basic Setup\n\"*****************************************************************************\"\n\n\"\" Encoding\nset encoding=utf-8\nset fileencoding=utf-8\nset fileencodings=utf-8\nset bomb\nset binary\nset ttyfast\n\n\"\" Fix backspace indent\nset backspace=indent,eol,start\n\n\"\" Tabs. May be overridden by autocmd rules\nset tabstop=4\nset softtabstop=0\nset shiftwidth=4\nset expandtab\n\n\"\" Map leader to ,\nlet mapleader=','\n\n\"\" Enable hidden buffers\nset hidden\n\n\"\" Searching\nset hlsearch\nset incsearch\nset ignorecase\nset smartcase\n\n\"\" Directories for swp files\nset nobackup\nset noswapfile\n\nset fileformats=unix,dos,mac\n\nif exists('$SHELL')\n    set shell=$SHELL\nelse\n    set shell=/bin/sh\nendif\n\n\" session management\nlet g:session_directory = \"~/.vim/session\"\nlet g:session_autoload = \"no\"\nlet g:session_autosave = \"no\"\nlet g:session_command_aliases = 1\n\n\"*****************************************************************************\n\"\" Visual Settings\n\"*****************************************************************************\n\nsyntax on\nset ruler\nset number\n\nlet no_buffers_menu=1\nif !exists('g:not_finish_vimplug')\n  colorscheme molokai\nendif\n\nset mousemodel=popup\nset t_Co=256\nset guioptions=egmrti\nset gfn=Monospace\\ 10\n\nif has(\"gui_running\")\n  if has(\"gui_mac\") || has(\"gui_macvim\")\n    set guifont=Menlo:h12\n    set transparency=7\n  endif\nelse\n  let g:CSApprox_loaded = 1\n\n  \" IndentLine\n  let g:indentLine_enabled = 1\n  let g:indentLine_concealcursor = 0\n  let g:indentLine_char = '┆'\n  let g:indentLine_faster = 1\n\n  \n  if $COLORTERM == 'gnome-terminal'\n    set term=gnome-256color\n  else\n    if $TERM == 'xterm'\n      set term=xterm-256color\n    endif\n  endif\n  \nendif\n\nif \u0026term =~ '256color'\n  set t_ut=\nendif\n\n\"\" Disable the blinking cursor.\nset gcr=a:blinkon0\nset scrolloff=3\n\n\"\" Status bar\nset laststatus=2\n\n\"\" Use modeline overrides\nset modeline\nset modelines=10\n\nset title\nset titleold=\"Terminal\"\nset titlestring=%F\n\nset statusline=%F%m%r%h%w%=(%{\u0026ff}/%Y)\\ (line\\ %l\\/%L,\\ col\\ %c)\\\n\n\" Search mappings: These will make it so that going to the next one in a\n\" search will center on the line it's found in.\nnnoremap n nzzzv\nnnoremap N Nzzzv\n\n\"*****************************************************************************\n\"\" Abbreviations\n\"*****************************************************************************\n\n\"\" no one is really happy until they have these shortcuts\ncnoreabbrev W! w!\ncnoreabbrev Q! q!\ncnoreabbrev Qall! qall!\ncnoreabbrev Wq wq\ncnoreabbrev Wa wa\ncnoreabbrev wQ wq\ncnoreabbrev WQ wq\ncnoreabbrev W w\ncnoreabbrev Q q\ncnoreabbrev Qall qall\n\n\" grep.vim\nnnoremap \u003csilent\u003e \u003cleader\u003ef :Rgrep\u003cCR\u003e\nlet Grep_Default_Options = '-IR'\nlet Grep_Skip_Files = '*.log *.db'\nlet Grep_Skip_Dirs = '.git node_modules'\n\n\" vimshell.vim\nlet g:vimshell_user_prompt = 'fnamemodify(getcwd(), \":~\")'\nlet g:vimshell_prompt =  '$ '\n\n\"*****************************************************************************\n\"\" Autocmd Rules\n\"*****************************************************************************\n\n\"\" The PC is fast enough, do syntax highlight syncing from start unless 200 lines\naugroup vimrc-sync-fromstart\n  autocmd!\n  autocmd BufEnter * :syntax sync maxlines=200\naugroup END\n\n\"\" Remember cursor position\naugroup vimrc-remember-cursor-position\n  autocmd!\n  autocmd BufReadPost * if line(\"'\\\"\") \u003e 1 \u0026\u0026 line(\"'\\\"\") \u003c= line(\"$\") | exe \"normal! g`\\\"\" | endif\naugroup END\n\nset autoread\n\n\"*****************************************************************************\n\"\" Mappings\n\"*****************************************************************************\n\n\"\" Tabs\nnnoremap \u003cTab\u003e gt\nnnoremap \u003cS-Tab\u003e gT\nnnoremap \u003csilent\u003e \u003cS-t\u003e :tabnew\u003cCR\u003e\n\n\"\" Set working directory\nnnoremap \u003cleader\u003e. :lcd %:p:h\u003cCR\u003e\n\n\"\" fzf.vim\nset wildmode=list:longest,list:full\nset wildignore+=*.o,*.obj,.git,*.rbc,*.pyc,__pycache__\n    \n\" The Silver Searcher\nif executable('ag')\n  let $FZF_DEFAULT_COMMAND = 'ag --hidden --ignore .git -g \"\"'\n  set grepprg=ag\\ --nogroup\\ --nocolor\nendif\n\n\" ripgrep\nif executable('rg')\n  let $FZF_DEFAULT_COMMAND = 'rg --files --hidden --follow --glob \"!.git/*\"'\n  set grepprg=rg\\ --vimgrep\n  command! -bang -nargs=* Find call fzf#vim#grep('rg --column --line-number --no-heading --fixed-strings --ignore-case --hidden --follow --glob \"!.git/*\" --color \"always\" '.shellescape(\u003cq-args\u003e).'| tr -d \"\\017\"', 1, \u003cbang\u003e0)\nendif\n\n\" Disable visualbell\nset noerrorbells visualbell t_vb=\nif has('autocmd')\n  autocmd GUIEnter * set visualbell t_vb=\nendif\n\n\"\" Copy/Paste/Cut\nif has('unnamedplus')\n  set clipboard=unnamed,unnamedplus\nendif\n\nif has('macunix')\n  \" pbcopy for OSX copy/paste\n  vmap \u003cC-x\u003e :!pbcopy\u003cCR\u003e\n  vmap \u003cC-c\u003e :w !pbcopy\u003cCR\u003e\u003cCR\u003e\nendif\n\n\"\" Move visual block\nvnoremap J :m '\u003e+1\u003cCR\u003egv=gv\nvnoremap K :m '\u003c-2\u003cCR\u003egv=gv\n\n\"*****************************************************************************\n\"\" Custom configs\n\"*****************************************************************************\n\n\" go\n\" vim-go\n\" run :GoBuild or :GoTestCompile based on the go file\nfunction! s:build_go_files()\n  let l:file = expand('%')\n  if l:file =~# '^\\f\\+_test\\.go$'\n    call go#test#Test(0, 1)\n  elseif l:file =~# '^\\f\\+\\.go$'\n    call go#cmd#Build(0)\n  endif\nendfunction\n\nlet g:go_list_type = \"quickfix\"\nlet g:go_fmt_command = \"goimports\"\nlet g:go_fmt_fail_silently = 1\nlet g:syntastic_go_checkers = ['golint', 'govet']\nlet g:syntastic_mode_map = { 'mode': 'active', 'passive_filetypes': ['go'] }\n\nlet g:go_highlight_types = 1\nlet g:go_highlight_fields = 1\nlet g:go_highlight_functions = 1\nlet g:go_highlight_methods = 1\nlet g:go_highlight_operators = 1\nlet g:go_highlight_build_constraints = 1\nlet g:go_highlight_structs = 1\nlet g:go_highlight_generate_tags = 1\nlet g:go_highlight_space_tab_error = 0\nlet g:go_highlight_array_whitespace_error = 0\nlet g:go_highlight_trailing_whitespace_error = 0\nlet g:go_highlight_extra_types = 1\n\nautocmd BufNewFile,BufRead *.go setlocal noexpandtab tabstop=4 shiftwidth=4 softtabstop=4\n\naugroup completion_preview_close\n  autocmd!\n  if v:version \u003e 703 || v:version == 703 \u0026\u0026 has('patch598')\n    autocmd CompleteDone * if !\u0026previewwindow \u0026\u0026 \u0026completeopt =~ 'preview' | silent! pclose | endif\n  endif\naugroup END\n\naugroup go\n\n  au!\n  au Filetype go command! -bang A call go#alternate#Switch(\u003cbang\u003e0, 'edit')\n  au Filetype go command! -bang AV call go#alternate#Switch(\u003cbang\u003e0, 'vsplit')\n  au Filetype go command! -bang AS call go#alternate#Switch(\u003cbang\u003e0, 'split')\n  au Filetype go command! -bang AT call go#alternate#Switch(\u003cbang\u003e0, 'tabe')\n\n  au FileType go nmap \u003cLeader\u003edd \u003cPlug\u003e(go-def-vertical)\n  au FileType go nmap \u003cLeader\u003edv \u003cPlug\u003e(go-doc-vertical)\n  au FileType go nmap \u003cLeader\u003edb \u003cPlug\u003e(go-doc-browser)\n\n  au FileType go nmap \u003cleader\u003er  \u003cPlug\u003e(go-run)\n  au FileType go nmap \u003cleader\u003et  \u003cPlug\u003e(go-test)\n  au FileType go nmap \u003cLeader\u003egt \u003cPlug\u003e(go-coverage-toggle)\n  au FileType go nmap \u003cLeader\u003ei \u003cPlug\u003e(go-info)\n  au FileType go nmap \u003csilent\u003e \u003cLeader\u003el \u003cPlug\u003e(go-metalinter)\n  au FileType go nmap \u003cC-g\u003e :GoDecls\u003ccr\u003e\n  au FileType go nmap \u003cleader\u003edr :GoDeclsDir\u003ccr\u003e\n  au FileType go imap \u003cC-g\u003e \u003cesc\u003e:\u003cC-u\u003eGoDecls\u003ccr\u003e\n  au FileType go imap \u003cleader\u003edr \u003cesc\u003e:\u003cC-u\u003eGoDeclsDir\u003ccr\u003e\n  au FileType go nmap \u003cleader\u003erb :\u003cC-u\u003ecall \u003cSID\u003ebuild_go_files()\u003cCR\u003e\n\naugroup END\n\n\n\" javascript\nlet g:javascript_enable_domhtmlcss = 1\n\n\" vim-javascript\naugroup vimrc-javascript\n  autocmd!\n  autocmd FileType javascript set tabstop=4|set shiftwidth=4|set expandtab softtabstop=4\naugroup END\n\n\n\" python\n\" vim-python\naugroup vimrc-python\n  autocmd!\n  autocmd FileType python setlocal expandtab shiftwidth=4 tabstop=8 colorcolumn=79\n      \\ formatoptions+=croq softtabstop=4\n      \\ cinwords=if,elif,else,for,while,try,except,finally,def,class,with\naugroup END\n\n\" jedi-vim\nlet g:jedi#popup_on_dot = 0\nlet g:jedi#goto_assignments_command = \"\u003cleader\u003eg\"\nlet g:jedi#goto_definitions_command = \"\u003cleader\u003ed\"\nlet g:jedi#documentation_command = \"K\"\nlet g:jedi#usages_command = \"\u003cleader\u003en\"\nlet g:jedi#rename_command = \"\u003cleader\u003er\"\nlet g:jedi#show_call_signatures = \"0\"\nlet g:jedi#completions_command = \"\u003cC-Space\u003e\"\nlet g:jedi#smart_auto_mappings = 0\n\n\" Syntax highlight\n\" Default highlight is better than polyglot\nlet g:polyglot_disabled = ['python']\nlet python_highlight_all = 1\n\n\n\"*****************************************************************************\n\"*****************************************************************************\n\n\"\" Include user's local vim config\nif filereadable(expand(\"~/.vimrc.local\"))\n  source ~/.vimrc.local\nendif\n\n","tags":"#vim #bootstrap #install"},{"id":"b919f3a4f499501b0f0545204b48f953","title":"[Sorting a Dictionary by Key] ","content":"import json\nimport operator\nimport yaml\n\ndir = \"/Users/integralist/code/foo\"\npath = f\"{dir}/url_redirects.yml\"\n\n\"\"\"\nYAML format\n\n- original: '/foo'\n  redirect: '/bar'\n\"\"\"\n\nwith open(path) as f:\n    redirects = yaml.load(f.read())\n    redirects_sorted = sorted(redirects, key=operator.itemgetter(\"original\"))\n    print(json.dumps(redirects_sorted, indent=4))\n\n\n","tags":"#python #sort"},{"id":"a0b1d9e31c9b2cdd25e9795b82dbcd37","title":"[Handling CSV files in Python] ","content":"import csv\nimport re\n\nTEMPLATE = \"\"\"\n- original: '{}'\n  redirect: '{}'\"\"\"\n\nwith open(\"/Users/integralist/Downloads/example.csv\") as csvfile:\n    reader = csv.DictReader(csvfile)\n\n    for row in reader:\n        for k, v in row.items():\n            if k == \"tasty.co link\" and len(v) \u003e 10:\n                match = re.search(\"^(https?://)?tasty.co(?P\u003cpath\u003e.+)\", v)\n                if match:\n                    print(TEMPLATE.format(row[\"slug\"], match.group(\"path\")))\nimport csv\nimport operator\nimport re\n\nTEMPLATE = \"\"\"\n- original: '{}'\n  redirect: '{}'\"\"\"\n\nwith open(\"/Users/integralist/Downloads/example.csv\") as csvfile:\n    reader = csv.reader(csvfile)\n    sortedlist = sorted(reader, key=operator.itemgetter(1))  # sort by column index 1 (i.e. \"slug\")\n\n    for row in sortedlist:\n        if not row[1].startswith(\"/\"):  # skip the header row (i.e. \"slug\")\n            continue\n\n        if len(row[4]) \u003e 10:  # there is an appropriate redirect path\n            match = re.search(\"^(https?://)?tasty.co(?P\u003cpath\u003e.+)\", row[4])\n            if match:\n                print(TEMPLATE.format(row[1], match.group(\"path\")))\n","tags":"#csv #python"},{"id":"70409dd264eebf5ec6a93f733d66038a","title":"[Python Semaphore] ","content":"import asyncio\n\nasync def do_work(semaphore):\n    # new: only enter if semaphore can be acquired\n    async with semaphore:\n        print(\"start work\")\n        await asyncio.sleep(1) # optionally do a lot of work that will consume memory\n        print(\"end work\")\n\nasync def main():\n    tasks = []\n    \n    # new: instantiate a semaphore before calling our coroutines\n    semaphore = asyncio.BoundedSemaphore(10)\n    \n    for i in range(100):\n        # new: pass the semaphore to the coroutine that will limit itself\n        tasks.append(asyncio.ensure_future(do_work(semaphore)))\n        \n    await asyncio.gather(*tasks)\n\nif __name__ == \"__main__\":\n    loop = asyncio.get_event_loop()\n    loop.set_debug(True)\n    loop.run_until_complete(main())\n","tags":"#python #concurrency #semaphore"},{"id":"18106b28d4d4d66708da09d652f83cc5","title":"[Bracket Terminology] ","content":"```\nparentheses:     ( ) \nbraces:          { } \nbrackets:        \u003c \u003e \nsquare-brackets: [ ]\n```\n","tags":"#bracket #terminology #parentheses #braces"},{"id":"aa4c0d3c98f6bbef40de03d072ff2419","title":"[DNS Change Best Practice] ","content":"Best practice for making a change: \n\n1. If your TTL is X, then X units of time before you need to make a change, update TTL to 5 minutes. \n\n2. Now you can deploy your system change, then 5 minutes later it'll be available to your customers.\n\n3. Finally, you can reset the TTL back to its original value. \n","tags":"#dns #ttl"},{"id":"5681fd7e4259edb972771a830d074b4a","title":"[Multi Torrent Site Search] ","content":"\u003e Note: for _searching_ torrents you can use [torrench](https://github.com/kryptxy/torrench)\n\n- `pip install pyopenssl`\n- `pip install --upgrade torrench`\n- `torrench -h`\n\nTo use illegal torrent sites (at your own risk!)\n\n```\n# generate config directory\nmkdir ~/.config/torrench`\n\n# download config file\ncurl -so ~/.config/torrench/config.ini https://pastebin.com/raw/reymRHSL`\n\n# enable TBP searching\nsed -i '' 's/\\(enable = \\)0/\\11/' ~/.config/torrench/config.ini`\n\n# search TBP\ntorrench -t 'ufc 219'`\n```\n\n\u003e Note: for _downloading_ you can use [tget](https://github.com/jeffjose/tget)\n","tags":"#torrents #cli #shell #bash #python"},{"id":"08266927214e0b5f12636a6b46900fb0","title":"[Calculate Percentages] ","content":"A class has 28 children. \n\nSeven of them play the piano - what percentage of the class is this?\n\n```\n7 / 28 x 100 = 25%\n```\n\nThere are 378 README files.\n\nOnly 20 of them are valid - what percentage of the READMEs is this?\n\n```\n20 / 378 x 100 = 5%\n```\n\nGiven Data:\n\nNormal Logs (N): 827  \nError Logs (E): 212  \nTotal Logs (T): N + E = 827 + 212 = 1039\n\nPercentage of Error Logs:\nCalculation: `(E / T) * 100` = `(212 / 1039) * 100 ≈ 20.4%`\n\nPercentage of Normal Logs:\nCalculation: `(N / T) * 100` = `(827 / 1039) * 100 ≈ 79.6%`\n\n---\n\nTo calculate a specific percentage you first have to calculate `1%`.  \nThen you can multiple that result by the percentage you're after. \n\nFor example, imagine we have 80 balls, and we want to see what 50% of that number is...\n\n```\ntotal = 80\n1% = total/100\n50% = (total/100)*50 = 40\n```\n\nSome alternative ways to do it...\n\n```\n£350,000 × 1% ×.01\n\n3,500\n\n£350,000 × 0.9% ×.01\n\n3,150\n```\n","tags":"#math #percentage"},{"id":"a9171ca1cce786d7dbf7a61df2685e8a","title":"[Rollout Strategies with A/B logic via Varnish and VCL] ","content":"## Rollout Strategies via Varnish\n\nWe can utilise A/B testing as a rollout strategy in VCL with Fastly CDN using either:\n\n- [Percentage based rollouts](#percentage-based-rollouts) (N % of users get access)\n- [Regional rollouts](#regional-rollouts) (access by locality)\n- [Alternative bucketing logic](#alternative-bucketing-logic)\n\n### Percentage based rollouts\n\n\u003e Note: see also https://www.fastly.com/blog/ab-testing-edge/\n\nThese can be a bit more complicated than the 'regional rollout' approach, so let's look at them first.\n\nEffectively you utilise cookies to help persist the various buckets you place users into, and then you need your application (or proxy) to process/inspect the HTTP request header that is then set and react accordingly (e.g. if the header exists and it has a value of `\"true\"`, then your proxy can pass the request onto a different origin or if there's only one origin you can have the application itself change the type of page that's rendered).\n\n```vcl\nvcl_recv {\n  # if there is no cookie found then this is the first time this user has made a request\n  # so we'll determine if they can have access to the new feature or not\n  if (!req.http.Cookie:NewFeature) {\n    # 10% of users will get access to the new feature\n    if (randombool(10,100)) {\n      set req.http.X-NewFeature = \"true\";\n    } else {\n      set req.http.X-NewFeature = \"false\";\n    }\n  } \n  # otherwise if there is a cookie, then we've already made the 'access' decision\n  # so we'll use whatever value we determined previously for them by taking the value from the cookie\n  else {\n    # set the value of the header to whatever decision was previously made\n    set req.http.X-NewFeature = req.http.Cookie:NewFeature; \n  }\n}\n\nvcl_fetch {\n  # the following Vary header logic can be added by your application if necessary\n  # we need to use Vary in order to ensure we serve the same content version as before for returning users\n  if (beresp.http.Vary) {\n      set beresp.http.Vary = beresp.http.Vary \", X-NewFeature\";\n  } else {\n      set beresp.http.Vary = \"X-NewFeature\";\n  }\n}\n\nvcl_deliver {\n  # if the cookie doesn't already exist, set it.\n  if (!req.http.Cookie:NewFeature){\n    add resp.http.Set-Cookie = \"NewFeature=\" req.http.X-NewFeature \";\";\n  }\n}\n```\n\n\u003e Note: be careful with setting the Vary header via the CDN/VCL as you might not necessarily want _every_ origin response to be cached with a Vary header. If you do this then make sure you _always_ set `X-NewFeature` (doesn't matter the value, but it must at least be set) because otherwise your cache HIT ratio could end up being zero! as no matches might be found unless the header was provided (with at least _some value_)\n\n### Regional rollouts\n\nThese rollouts are simpler as they don't rely on the `Vary` header.\n\nThe reason you can get away with not using a `Vary` header to change the content looked up in the cache is because users will obviously only be in one specific region at any given time (let's say a user is based in Australia, in one session their requests are unlikely to suddenly be coming from America) and so they will always go to the same set of POPs (as that's how a CDN's locality based routing works - users are routed to specific POPs that are _nearest_ to them).\n\n\u003e Note: the downside of this approach is that it's difficult to test because of needing tools such as a proxy to mimic you being in a different locality (which might not be as straight forward as you think, when for example, your source device isn't a desktop browser but a native mobile application)\n\n```vcl\nvcl_recv {\n  # by default no one gets the new feature\n  set req.http.X-NewFeature = \"false\";\n  \n  # everywhere except the US will get the new feature\n  if (!client.geo.country_code == \"US\") {\n    set req.http.X-NewFeature = \"true\";\n  }\n}\n```\n\n### Alternative bucketing logic\n\nThere's two alternative approaches. \n\nThe first...\n\n```vcl\nset req.http.X-Unique-Id = regsuball(\"39059176dab142e19321c3255e01e56e\", \"\\-\", \"\");\nset req.http.X-Val = std.strtol(req.http.X-Unique-Id, 16);\nset req.http.X-Bucket = randomint_seeded(0, 99, std.strtol(req.http.X-Unique-Id, 16)); \n```\n\nThe second uses multiple 'less than' comparisons to identify specific percentages...\n\n```\nsub abtest_us_lift_feedranker_recv {\n    if (req.url.path == \"/\" \u0026\u0026 req.http.X-User-Edition == \"en-us\") {\n        if (req.http.Cookie:ab_cookie) {\n            set req.http.X-AB-Test = req.http.Cookie:ab_cookie;\n        } else {\n            declare local var.bucketing_index INTEGER;\n            \n            set var.bucketing_index = randomint(0,99);\n            \n            if (var.bucketing_index \u003c 5) {\n                # var.bucketing_index between [0-4] - 5% exposure \n                set req.http.X-AB-Test = \"control\";\n            } elseif (var.bucketing_index \u003c 6) {\n                # var.bucketing_index 5 - 1% exposure\n                set req.http.X-AB-Test = \"foo\";\n            } elseif (var.bucketing_index \u003c 11) {\n                # var.bucketing_index between [6-11] 5% exposure\n                set req.http.X-AB-Test = \"bar\";\n            } elseif (var.bucketing_index \u003c 16) {\n                # var.bucketing_index between [11-16] 5% exposure\n                set req.http.X-AB-Test = \"baz\";\n            } else {\n                # not exposed to the experiment\n                set req.http.X-AB-Test = \"not-exposed\";\n            }\n        }\n    }\n}\n\nsub abtest_us_lift_feedranker_deliver {\n    if (!req.http.Cookie:ab_cookie \u0026\u0026 req.url.path == \"/\" \u0026\u0026 req.http.X-User-Edition == \"en-us\") {\n        add resp.http.Set-Cookie = \"ab_cookie=\" req.http.X-AB-Test \";expires=\" time.add(now,14d) \";\";\n    }\n}\n```\n\nFor example, if a user randomly gets a number `\u003c 5` (let's say 3) then because we've picked a number out of a 100 (to represent 100%) that means 3 is equal to 3%. Where as if the random number they got was 5, then that's not going to match `\u003c 5` so we move to the next comparison which is `\u003c 6`, so _that_ matches the number 5 and it means the percentage for those users will be 1% because there is 1 number difference between `\u003c 5` and `\u003c 6`. \n","tags":"#rollout #vcl #cdn #varnish #fastly #ab"},{"id":"24c8a9ce570d78d37ed0cf9967594e0e","title":"[SBI Framework] ","content":"# Situation, Behaviour, Impact\n\n## Situation\n\n**Goal**: provide context.\n\n- **Who** was there?\n- **Where** was it?\n- **When** was it?\n\n## Behaviour\n\n**Goal**: recognise\twhat they _did_ or _didn't_ do.\n\n- **What** did they do that should be continued or changed?\n- **What** was the behaviour that occurred?\n\n## Impact\n\n**Goal**: understand the importance of feedback.\n\n- **How** did it effect them, you, the team or the company?\n\n# Key Take-Aways to keep in mind\n\n- **Avoid common biases**: Let's check our biases (Negative, Halo, and Similarity) at the door. Reviews should be fair and impartial.\n- **Keep feedback objective and focused on the big picture**: Relate feedback to the overall expectations of the position by using SBI; situation, behavior, impact.\n- **Partner with your HRBP or manager**: Don't go at it alone! Schedule time with me or your manager if you need help with talking points, addressing feedback, or you just need to bounce your thoughts off someone.\n","tags":"#framework #reviews"},{"id":"e2e2599fff9eb5ee54d939ae51334de2","title":"[Using Vim to format nginx file] ","content":"# note: have to double escape the \\ for the regex operator +\n# + means \"one or more occurrences\", but in vim you need to escape it \\+\n# but in execute mode you need to escape the escape as \\ is a special character in execute mode\n\n# this didn't work...\n#\n# :execute \"normal gg/upstream .\\\\+ {\\\u003ccr\u003emq\"\n# :execute \"normal 'qI\\\u003ccr\u003e\\\u003cesc\u003e\"\n# \n# nor...\n#\n# :execute \"normal gg/upstream .\\\\+ {\\\u003ccr\u003eO\"\n\nvim -E -s site_router/nginx_rendered_dev.conf \u003c\u003c-EOF\n:execute \"normal gg=G\"\n:g/^$/normal dd\n:update\n:quit\nEOF\n\n# the following is a long form version of the above succinct version...\n\n# format nginx file\n=G\n:g/^$/normal dd\n:setf nginx\n\n# create line break before first upstream\ngg\n/upstream .\\+ {\nO\nEsc\n\n# create line break before first log_format\ngg\n/log_format\nO\nEsc\n\n# create line break after last log_format (limit_req_zone is known to follow log_format)\ngg\n/limit_req_zone\nO\nEsc\n\n# create line break before each # code comment\ngg\n/#\nO\nEsc\nnn # to find next match\n\n# create line break before each server block\ngg\n/server {\nO\nEsc\nnn # to find next match\n\n# create line break before each location block\ngg\n/location \\~\nO\nEsc\nnn # to find next match\n\n# create line break before each location 'fallback' block\ngg\n/location @\nO\nEsc\nnn # to find next match\n\n# create line break before each location 'health check' block\ngg\n/location =\nO\nEsc\nnn # to find next match\n","tags":"#vim #nginx"},{"id":"94a73bb9f3b15ccb824881d3ddb7ec6f","title":"Extend expired GPG key ","content":"# list the public keys and their IDs\ngpg --list-keys\n\n# select public key ID for expired key you wish to extend\ngpg --edit-key \u003c...\u003e\n\n# you're dropped into gpg interactive shell, here you'll execute commands (e.g. type \"help\")\ngpg\u003e list\n\n# set new expiry for the primary key (which is the default and is equivalent to \"key 0\")\ngpg\u003e expire\n\n# you can also select the subkey (once you type this you'll see an asterisk next to the subkey)\ngpg\u003e key 1\n\n# set new expiry for the subkey\ngpg\u003e expire\n\n# this will save your changes and quit\ngpg\u003e save\n\n# you can also quit without saving if you need to\ngpg\u003e quit\n","tags":"#gpg #keys #encryption"},{"id":"57ae3bb90883e603f3851bab496682b9","title":"[website day/night theme switcher with cookies] ","content":"/* \nthe normal css (not shown) is standard 'day' mode stylings.\nwe simply add a .night class to override the styles to 'night' mode.\n*/\n\n.night {\n  background: #263238;\n}\n\n.night .title, .night h1, .night h2, .night h3, .night h4, .night h5, .night h6,\n.night a, .night a:visited {\n  color: #fff;\n}\n\nbody.night, .night button, .night input, .night select, .night textarea,\n.night .main-menu a:hover, .night .social-menu a:hover,\n.night a:active, .night a:focus, .night a:hover{\n  color: #ccc;\n}\n\n.night blockquote strong,\n.night td \u003e code,\n.night h1 \u003e code,\n.night h2 \u003e code,\n.night h3 \u003e code,\n.night h4 \u003e code,\n.night h5 \u003e code,\n.night h6 \u003e code,\n.night li \u003e code,\n.night a \u003e code,\n.night p \u003e code,\n.night li strong {\n  color: #ff6ed0;\n}\nvar menu = document.getElementsByClassName(\"main-menu\")[0];\nvar anchors = menu.getElementsByTagName(\"a\");\nvar trigger;\n\n// search menu for button that has #theme id attribute\n// this is a button we've explicitly added to the HTML for theme switching\n// ideally you'd generate this button in JS instead\n// for some reason I didn't do that, no reason, I was just lazy ¯\\_(ツ)_/¯\nfor (var i = 0; i \u003c anchors.length; i++) {\n  a = anchors[i];\n  if (a.href.indexOf(\"#theme\") \u003e= 0) {\n    trigger = a;\n  }\n}\n\n// check if we already have a 'theme' cookie set\ntheme = document.cookie.match(\"theme=([^;]+)\");\n\n// if we do have a cookie, then trigger the right theme based on its current value\n// this code block is executed as the page loads\n// note: switching between theme modes is otherwise manually handled by the user clicking theme button\nif (theme) {\n  mode = theme[1];\n  \n  // check if we're in 'night' mode and switch to 'day' mode\n  if (mode == \"night\") {\n    document.body.classList.add(\"night\");\n    document.body.classList.remove(\"day\");\n    trigger.innerText = \"Day Mode\";\n  }\n\n  // check if we're in 'day' mode and switch to 'night' mode\n  if (mode == \"day\") {\n    document.body.classList.add(\"day\");\n    document.body.classList.remove(\"night\");\n    trigger.innerText = \"Night Mode\";\n  }\n}\n\n// this function sets 'theme' cookie and switches theme\nfunction themeSwitch(e) {\n  if (e.target.href.indexOf(\"#theme\") \u003e= 0) {\n    document.body.classList.toggle(\"night\");\n\n    if (document.body.classList.contains(\"night\")) {\n      e.target.innerText = \"Day Mode\";\n      document.cookie = \"theme=night;domain=.integralist.co.uk;path=/\";\n    } else {\n      e.target.innerText = \"Night Mode\";\n      document.cookie = \"theme=day;domain=.integralist.co.uk;path=/\";\n    }\n  }\n}\n\nvar menu = document.getElementById(\"navmenu\");\n\n// allow the user to click the 'theme switcher' button to change the theme\nmenu.addEventListener(\"click\", themeSwitch);\n","tags":"#js #javascript #cookies"},{"id":"92a6e96aa4757365e1f4b7460ffd1bd8","title":"[Dynamically import modules from a package in Python] ","content":"import pkgutil\n\n\ndef get_test_routes():\n\t\"\"\"\n    imagine 'routes' contains foo.py bar.py and baz.py\n    and in each of those files is a 'tests' variable\n    we want to import each 'tests' variable into this file's scope\n    \"\"\"\n    from tests import routes\n    test_modules = []\n    for importer in pkgutil.iter_modules(routes.__path__):\n        if importer.ispkg is False:\n            print(f\"Loading test routes for {importer.name}\")\n            test_modules.append(importer.module_finder.find_module(importer.name).load_module(importer.name))\n    return test_modules\n\n\ntest_modules = get_test_routes()\nfor mod in test_modules:\n    print(len(mod.tests))\n    \n# construct a single list made up of the contents of the multiple 'tests' lists\nhost_endpoint_tests = [test for mod in get_test_routes() for test in mod.tests]\n","tags":"#python"},{"id":"dcee6630903658a6b84b5bcb11ac4d5b","title":"[nginx redirect request to separate server block with different server_name] ","content":"# let's imagine that we have two virtual servers\n#\n# 1. *.example.com\n# 2. *.foo.com\n#\n# let's also imagine that nearly all our requests are from host www.example.com\n# so the first server block would handle those requests\n#\n# but if we get a request for a location that doesn't match in the *.example.com\n# how do we get it to failover to the other server block to see if that has the path?\n#\n# we can use a rewrite rule (http://nginx.org/en/docs/http/ngx_http_rewrite_module.html#rewrite)...\n\nset $is_foo 0;\n\nif ($host = 'foo.com') {\n  set $is_foo 1;\n}\n\nif ($is_foo = 1) {\n  rewrite ^/(.*)$ http://www.foo.com/$1 permanent; # see link above for the various flag options\n}  \n","tags":"#nginx #rewrite #server"},{"id":"f7e17034800b65b51eb7e9807720025a","title":"[GPG Security Best Practice] ","content":"## Concept\n\nhttps://alexcabal.com/creating-the-perfect-gpg-keypair/\n\n1. Create a regular GPG keypair. By default GPG creates one signing subkey (your identity) and one encryption subkey (how you receive messages intended for you).\n\n2. Use GPG to add an additional signing subkey to your keypair. This new subkey is linked to the first signing key. Now we have three subkeys.\n\n3. This keypair is your master keypair. Store it in a protected place like your house or a safe-deposit box. Your master keypair is the one whose loss would be truly catastrophic.\n\n4. Copy your master keypair to your laptop. Then use GPG to remove the original signing subkey, leaving only the new signing subkey and the encryption subkey. This transforms your master keypair into your laptop keypair.\n\nYour laptop keypair is what you’ll use for day-to-day GPG usage.\n\nWhat’s the benefit to this setup? Since your master keypair isn’t stored on your traveling laptop, that means you can revoke the subkeys on your laptop should your laptop be stolen. Since you’re not revoking the original subkey you created in the master keypair—remember, we removed it from our laptop’s keypair—that means you don’t have to create a new keypair and go through the hassle of getting people to sign it again. You’d still have to revoke the stolen subkey, and the thief could still use the encryption subkey to decrypt any messages you’ve already received, but at least the damage done won’t be as catastrophic.\n\n## Step by Step\n\n### Generate Key\n\n- `gpg ‐‐gen-key`\n- Set expiry to zero (never expires)\n\n\u003e Note: you could even add a photo to your GPG public key using `gpg ‐‐edit-key \u003cemail or id\u003e` and at the interactive prompt use the command `gpg\u003e addphoto` then specify full path `/home/integralist/profile.jpg`.\n\n### Extra secure hashes (optional)\n\n- `gpg ‐‐edit-key \u003cemail or id\u003e`\n- `gpg\u003e setpref SHA512 SHA384 SHA256 SHA224 AES256 AES192 AES CAST5 ZLIB BZIP2 ZIP Uncompressed`\n\n### Create 'signing' subkey\n\n- `gpg ‐‐edit-key \u003cemail or id\u003e`\n- `gpg\u003e addkey`\n- Select \"RSA (sign only)\" and 4096 for the keysize\n- Key does not expire\n- `gpg\u003e save`\n\n### Create 'revocation' certificate\n\n- `gpg --gen-revoke my.email@domain.com` (store somewhere)\n- `gpg --import revocation.cert` (only do when you want to revoke)\n\n### Export for Backups\n\n- `gpg --export-secret-keys --armor email@domain.com \u003e secret.gpg-key`\n- `gpg --export --armor email@domain.com \u003e public.gpg-key`\n\n### Now remove master key pair\n\nWe have to remove the original signing subkey from the master keypair in our keyring.\n\n1. Export all of the subkeys from our new keypair to a file. We first create a RAM-based ramfs temporary folder to prevent our keys from being written to permanent storage. We use ramfs instead of tmpfs/ or /dev/shm/ because ramfs doesn’t write to swap.\n\n```\nmkdir /tmp/gpg\nsudo mount -t ramfs -o size=1M ramfs /tmp/gpg\nsudo chown $(logname):$(logname) /tmp/gpg\ngpg --export-secret-subkeys email@domain.com \u003e /tmp/gpg/subkeys\n```\n\n2. Delete the original signing subkey from the keypair in our keyring:\n\n```\ngpg --delete-secret-key email@domain.com\n```\n\n3. Re-import the keys we exported and clean up our temporary file:\n\n```\ngpg --import /tmp/gpg/subkeys\nsudo umount /tmp/gpg\nrmdir /tmp/gpg\n```\n\n4. `gpg --list-secret-keys`: see how the third line begins with `sec#`, not `sec`? The pound sign means the signing subkey is not in the keypair located in the keyring.\n","tags":"#gpg #security #encryption"},{"id":"00ee13f2c2ede5e2200e6ea129d3c43d","title":"[Limit Concurrency] ","content":"If you find that you're running out of system resources whilst trying to open lots of files, then you should consider limiting your concurrency.\n\nOne way would be to define a pool that controls the concurrency so that you don't try to open too many files at once and exhaust your system resources.\n\nThere are two approaches you can take to implement that:\n\n1. Channels\n2. Semaphore (via channels)\n3. Semaphore (via golang.org/x/sync/semaphore)\npackage main\n\nimport (\n\t\"fmt\"\n\t\"log\"\n\t\"sync\"\n\t\"time\"\n)\n\nconst iterations = 5\n\nfunc main() {\n\tvar wg sync.WaitGroup\n\n\tstartTime := time.Now()\n  \n    // we use channels to coordinate the tasks\n\ttasks := make(chan time.Duration, 10)\n\n\t// we avoid creating 'unbounded' number of goroutines (10 in this case)\n    // we need to decide on the size of this 'worker pool' and so we'll pick 10 to match up with the channel\n    // but depending on how many tasks there are you'll need to be more selective on pool size\n\tfor i := 0; i \u003c 10; i++ {\n\t\twg.Add(1)\n\n\t\tgo func(i int) {\n\t\t\tdefer wg.Done()\n\n\t\t\t// we can do 10 things at a time due to the buffered task channel\n\t\t\tfor d := range tasks {\n\t\t\t\tfmt.Printf(\"goroutine %d: will pause for %d milliseconds\\n\", i, d)\n\t\t\t\ttime.Sleep(d * time.Millisecond)\n\t\t\t\tfmt.Printf(\"goroutine %d: finished task (%d)\\n\", i, d)\n\t\t\t}\n\t\t}(i)\n\t}\n\n\t// we use channels to coordinate and generate tasks\n\tfor i := 0; i \u003c iterations; i++ {\n\t\ttasks \u003c- 100\n\t\ttasks \u003c- 5000\n\t\ttasks \u003c- 2000\n\t}\n\n\tclose(tasks)\n\twg.Wait()\n\tlog.Println(\"time spent:\", time.Since(startTime))\n}\n\n/*\nOUTPUT: notice although we pause for long periods of time,\n        the overall time is just over 5 seconds because we\n        are parallelising the processing via goroutines.\n\ngoroutine 7: will pause for 5000 milliseconds\ngoroutine 3: will pause for 5000 milliseconds\ngoroutine 5: will pause for 100 milliseconds\ngoroutine 0: will pause for 100 milliseconds\ngoroutine 8: will pause for 2000 milliseconds\ngoroutine 2: will pause for 100 milliseconds\ngoroutine 9: will pause for 100 milliseconds\ngoroutine 6: will pause for 2000 milliseconds\ngoroutine 1: will pause for 5000 milliseconds\ngoroutine 4: will pause for 2000 milliseconds \u003c\u003c first 10 tasks have filled up the channel!\ngoroutine 5: finished task (100)\ngoroutine 5: will pause for 5000 milliseconds \u003c\u003c once a task has finished, the channel frees up one space.\ngoroutine 0: finished task (100)\ngoroutine 2: finished task (100)\ngoroutine 2: will pause for 100 milliseconds\ngoroutine 9: finished task (100)\ngoroutine 9: will pause for 5000 milliseconds\ngoroutine 0: will pause for 2000 milliseconds\ngoroutine 2: finished task (100)\ngoroutine 2: will pause for 2000 milliseconds\ngoroutine 8: finished task (2000)\ngoroutine 6: finished task (2000)\ngoroutine 4: finished task (2000)\ngoroutine 0: finished task (2000)\ngoroutine 2: finished task (2000)\ngoroutine 7: finished task (5000)\ngoroutine 3: finished task (5000)\ngoroutine 1: finished task (5000)\ngoroutine 9: finished task (5000)\ngoroutine 5: finished task (5000)\n2019/02/08 14:31:30 time spent: 5.107444551s\n*/\nsem := make(chan struct{}, 12) // 12 is the maximum number of concurrent processes that may run at any time\n\nfunc main() {\n    var wg sync.WaitGroup\n    wg.Add(1024 * 1024)\n\n    for i := 0; i \u003c (1024 * 1024); i++ {\n        go func(index int) {\n            // if there are already 12 goroutines running,\n            // the buffered channel will block\n            // and a new file wont be opened\n            sem \u003c- struct{}{}\n\n            // once this goroutine finishes, empty the buffer by one\n            // so the next process may start \n            //\n            // i.e. another goroutine blocked on the above channel 'send' \n            // will now be able to execute the statement and continue\n            defer func() { \u003c-sem }()\n\n            // wg.Done must be called _before_ the read from the sem channel\n            // remember that defers are executed like a stack (LIFO)\n            // hence we defer wg.Done _after_ deferring the sem read\n            defer wg.Done()\n\n            if f, e := os.Open(strconv.Itoa(index)); e != nil {\n                // handle file open failure\n                return\n            }\n            defer f.Close()\n            \n            // handle open file\n        }(i)\n    }\n\n    wg.Wait()\n    close(sem)\n}\n// Package middleware provides wrapper functions around the http.Handler\n// interface, allowing for an incoming HTTP request to be modified or analysed.\npackage middleware\n\nimport (\n\t\"net/http\"\n\n\t\"github.com/example/internal/pkg/settings\"\n\t\"golang.org/x/sync/semaphore\"\n)\n\n// LimitConcurrency will reject any new connections that exceed the service's\n// ability to continue functioning.\nfunc LimitConcurrency(handler http.Handler, config *settings.Config) http.Handler {\n  \ts := semaphore.NewWeighted(int64(config.ConcurrencyLimit))\n\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif !s.TryAcquire(1) {\n\t\t\thttp.Error(w, \"TOO_MANY_CONCURRENT_CONNECTIONS\", http.StatusServiceUnavailable)\n\t\t\treturn\n\t\t}\n\t\tdefer func() {\n\t\t\ts.Release(1)\n\t\t}()\n\n\t\thandler.ServeHTTP(w, r)\n\t})\n}\n","tags":"#go #golang #concurrency #semaphore"},{"id":"730b6f33dc5b0763b152caaff81d397f","title":"[Upstream vs Downstream] ","content":"## Upstream\n\nUpstream components are other parts of the system that your component depends on to do its job. \n\nIf the design of an upstream component changes, the ability of your component to function may be affected. \n\nIf an upstream component has a bug, this bug may be manifested in your component.\n\n## Downstream\n\nDownstream components are parts of the system that your component can affect. \n\nChanges in your component can ripple to components that are downstream from your component.\n\n## Example\n\nConsider an application that consists of a database tier and an application tier. \n\nThe database tier would be considered to be upstream of the application tier.\n\n## Rationale\n\nThe reason behind why I use the flow 'direction' I do (e.g. downstream services are those my service can affect, and upstream services are those services I rely upon and who can affect me) is related to the flow of water.\n\nIf you look at a mountain stream, the water flows from the top of the mountain ...'downstream'. If a large rock falls upon the path halfway up the mountain, then that will of course prevent the water from flowing further (the water flow has been restricted). Any people at the bottom (i.e. downstream) of the mountain will be affected by this rock falling on the stream from above (i.e. upstream) their own position.\n","tags":"#upstream #downstream"},{"id":"3fef386bd3beefac93f71e2a074803fb","title":"[Set Operations] ","content":"## Union\n\nThe union of two sets is a set containing all elements that are in A or in B (possibly both). For example, `{1,2}∪{2,3}`=`{1,2,3}`.\n\n## Intersection\n\nThe intersection of two sets A and B, denoted by `A∩B`, consists of all elements that are both in A and B. For example, `{1,2}∩{2,3}`=`{2}`.\n\n## Difference\n\nThe difference (subtraction) is defined as follows. The set `A−B` consists of elements that are in A but not in B. For example if A=`{1,2,3}` and B=`{3,5}`, then `A−B`=`{1,2}`.\n\n## Complement\n\nThe complement of a set A, denoted by `Ac`, is the set of all elements that are in the universal set S but are not in A.\n\n![Set Operations](https://www.onlinemathlearning.com/image-files/set-operations-venn-diagrams.png)\n\n## Golang\n\nIt is easy to create a set from map:\n\n```go\ns := map[int]bool{5: true, 2: true}\n\n_, ok := s[6] // check for existence\ns[8] = true   // add element \ndelete(s, 2)  // remove element\n```\n\n## Union\n\n```go\ns_union := map[int]bool{}\nfor k, _ := range s1{\n    s_union[k] = true\n}\nfor k, _ := range s2{\n    s_union[k] = true\n}\n```\n\n## Intersection\n\n```go\ns_intersection := map[int]bool{}\nfor k,_ := range s1 { \n  if s2[k] {\n    s_intersection[k] = true\n  }\n}\n```\n","tags":"#set #theory #operations #go #golang"},{"id":"a1b252f8da926043d67ab90ee47818b2","title":"[UTC, GMT, BST, DST] ","content":"There is a world-wide 24-hour clock called **Zulu time (Z)**, more commonly called [**Coordinated Universal Time (UTC)**](https://en.wikipedia.org/wiki/Coordinated_Universal_Time). \n\nYou will notice all weather maps, radar, and satellite images all have their time expressed in \"Z\". \n\nThe Zulu term stems from military usage while UTC is the civilian term for this 24-hour clock.\n\nAn example of Zulu time/UTC would be:\n\n```\n2020-05-30T09:14:59Z (May 30, 2020 at 9:14:59 UTC)\n```\n\nUTC supports an 'offset', which is the difference in hours and minutes between a 'time zone' and the UTC. It is used to indicate the local time in a particular time zone.\n\nAn example of Zulu time/UTC with a 1 hour offset would be:\n\n```\n2020-05-30T10:14:59+01:00 (May 30, 2020 at 10:14:59 UTC+1)\n```\n\n[**GMT (Greenwich Mean Time)**](https://en.wikipedia.org/wiki/Greenwich_Mean_Time) is a 'time zone'. UTC is a 'way of keeping time' around the world. \n\nGMT is the same as UTC, but GMT is a time zone 'name' while UTC is the way time is measured worldwide.\n\n[**Daylight Saving Time (DST)**](https://en.wikipedia.org/wiki/Daylight_saving_time) is a way to make better use of daylight. By moving the clock forward one hour during the summer months, we can enjoy an extra hour of sunlight in the evening when people are more likely to be outside and enjoying activities. \n\nNeither UTC nor GMT ever change for DST. \n\nHowever, some of the countries that use GMT switch to different time zones during their DST period. \n\nFor example, the United Kingdom is not on GMT all year, it uses British Summer Time (BST), which is one hour ahead of GMT, during the summer months.\n\n\u003e Summer months being March to October.  \n\u003e So first two and last two months of the year the UK uses GMT/UTC timezone.  \n\u003e Meaning in March the clocks \"go forward 1hr\", while in November the clocks \"go back 1hr\".\n","tags":"#time #timezones"},{"id":"1f8efb4fdedd69d4a4387ce95e743f0d","title":"[Python Boolean Argument Flag] ","content":"import argparse\n\nparser = argparse.ArgumentParser(description=\"Validate READMEs\")\nparser.add_argument(\"-d\", \"--debug\", help=\"Show failure details\", action=\"store_true\")\nparser.set_defaults(debug=False)\nargs = parser.parse_args()\n\nif args.debug:\n  print(\"show debug info\")\n  \nprint(\"show normal stuff\")\n\n# You could also use a custom type... \n\ndef str2bool(v):\n    if v.lower() in ('yes', 'true', 't', 'y', '1'):\n        return True\n    elif v.lower() in ('no', 'false', 'f', 'n', '0'):\n        return False\n    else:\n        raise argparse.ArgumentTypeError('Boolean value expected.')\n        \nparser.add_argument(\"-d\", \"--debug\", help=\"Show failure details\", type=str2bool)\n","tags":"#python #cli #flags"},{"id":"56cf991ae97551583d5a2f0d69f37788","title":"[Fastly's Custom VCL] ","content":"See https://docs.fastly.com/guides/vcl/mixing-and-matching-fastly-vcl-with-custom-vcl for details.\n\n- [`vcl_deliver`](#file-fastly_vcl_deliver-vcl)\n- [`vcl_error`](#file-fastly_vcl_error-vcl)\n- [`vcl_fetch`](#file-fastly_vcl_fetch-vcl)\n- [`vcl_hash`](#file-fastly_vcl_hash-vcl)\n- [`vcl_hit`](#file-fastly_vcl_hit-vcl)\n- [`vcl_miss`](#file-fastly_vcl_miss-vcl)\n- [`vcl_pass`](#file-fastly_vcl_pass-vcl)\n- [`vcl_pipe`](#file-fastly_vcl_pipe-vcl)\n- [`vcl_recv`](#file-fastly_vcl_recv-vcl)\n#--FASTLY DELIVER BEGIN\n# record the journey of the object, expose it only if req.http.Fastly-Debug.\n  if (req.http.Fastly-Debug || req.http.Fastly-FF) {\n    set resp.http.Fastly-Debug-Path = \"(D \" server.identity \" \" now.sec \") \"\n       if(resp.http.Fastly-Debug-Path, resp.http.Fastly-Debug-Path, \"\");\n    set resp.http.Fastly-Debug-TTL = if(obj.hits \u003e 0, \"(H \", \"(M \")\n       server.identity\n       if(req.http.Fastly-Tmp-Obj-TTL \u0026\u0026 req.http.Fastly-Tmp-Obj-Grace, \" \" req.http.Fastly-Tmp-Obj-TTL \" \" req.http.Fastly-Tmp-Obj-Grace \" \", \" - - \")\n       if(resp.http.Age, resp.http.Age, \"-\")\n       \") \"\n       if(resp.http.Fastly-Debug-TTL, resp.http.Fastly-Debug-TTL, \"\");\n    set resp.http.Fastly-Debug-Digest = digest.hash_sha256(req.digest);\n  } else {\n    unset resp.http.Fastly-Debug-Path;\n    unset resp.http.Fastly-Debug-TTL;\n  }\n  # add or append X-Served-By/X-Cache(-Hits)\n  {\n    if(!resp.http.X-Served-By) {\n      set resp.http.X-Served-By  = server.identity;\n    } else {\n      set resp.http.X-Served-By = resp.http.X-Served-By \", \" server.identity;\n    }\n    set resp.http.X-Cache = if(resp.http.X-Cache, resp.http.X-Cache \", \",\"\") if(fastly_info.state ~ \"HIT($|-)\", \"HIT\", \"MISS\");\n    if(!resp.http.X-Cache-Hits) {\n      set resp.http.X-Cache-Hits = obj.hits;\n    } else {\n      set resp.http.X-Cache-Hits = resp.http.X-Cache-Hits \", \" obj.hits;\n    }\n  }\n  if (req.http.X-Timer) {\n    set resp.http.X-Timer = req.http.X-Timer \",VE\" time.elapsed.msec;\n  }\n  # VARY FIXUP\n  {\n    # remove before sending to client\n    set resp.http.Vary = regsub(resp.http.Vary, \"Fastly-Vary-String, \", \"\");\n    if (resp.http.Vary ~ \"^\\s*$\") {\n      unset resp.http.Vary;\n    }\n  }\n  unset resp.http.X-Varnish;\n  # Pop the surrogate headers into the request object so we can reference them later\n  set req.http.Surrogate-Key = resp.http.Surrogate-Key;\n  set req.http.Surrogate-Control = resp.http.Surrogate-Control;\n  # If we are not forwarding or debugging unset the surrogate headers so they are not present in the response\n  if (!req.http.Fastly-FF \u0026\u0026 !req.http.Fastly-Debug) {\n    unset resp.http.Surrogate-Key;\n    unset resp.http.Surrogate-Control;\n  }\n  if(resp.status == 550) {\n    return(deliver);\n  }\n  #default response conditions\n#--FASTLY DELIVER END\n#--FASTLY FETCH BEGIN\n# record which cache ran vcl_fetch for this object and when\n  set beresp.http.Fastly-Debug-Path = \"(F \" server.identity \" \" now.sec \") \" if(beresp.http.Fastly-Debug-Path, beresp.http.Fastly-Debug-Path, \"\");\n# generic mechanism to vary on something\n  if (req.http.Fastly-Vary-String) {\n    if (beresp.http.Vary) {\n      set beresp.http.Vary = \"Fastly-Vary-String, \"  beresp.http.Vary;\n    } else {\n      set beresp.http.Vary = \"Fastly-Vary-String, \";\n    }\n  }\n # priority: 0\n  # Gzip basic GZIP rules\n  if ((beresp.status == 200 || beresp.status == 404) \u0026\u0026 (beresp.http.content-type ~ \"^(text\\/html|application\\/x\\-javascript|text\\/css|application\\/javascript|text\\/javascript|application\\/json|application\\/vnd\\.ms\\-fontobject|application\\/x\\-font\\-opentype|application\\/x\\-font\\-truetype|application\\/x\\-font\\-ttf|application\\/xml|font\\/eot|font\\/opentype|font\\/otf|image\\/svg\\+xml|image\\/vnd\\.microsoft\\.icon|text\\/plain|text\\/xml)\\s*($|;)\" || req.url ~ \"\\.(css|js|html|eot|ico|otf|ttf|json)($|\\?)\" ) ) {\n    # always set vary to make sure uncompressed versions dont always win\n    if (!beresp.http.Vary ~ \"Accept-Encoding\") {\n      if (beresp.http.Vary) {\n        set beresp.http.Vary = beresp.http.Vary \", Accept-Encoding\";\n      } else {\n         set beresp.http.Vary = \"Accept-Encoding\";\n      }\n    }\n    if (req.http.Accept-Encoding == \"gzip\") {\n      set beresp.gzip = true;\n    }\n  }\n#--FASTLY FETCH END\n#--FASTLY HASH BEGIN\n# support purge all\n  set req.hash += \"#####GENERATION#####\";\n#--FASTLY HASH END\n#--FASTLY ERROR BEGIN\n  if (obj.status == 801) {\n     set obj.status = 301;\n     set obj.response = \"Moved Permanently\";\n     set obj.http.Location = \"https://\" req.http.host req.url;\n     synthetic {\"\"};\n     return (deliver);\n  }\n  if (req.http.Fastly-Restart-On-Error) {\n    if (obj.status == 503 \u0026\u0026 req.restarts == 0) {\n      restart;\n    }\n  }\n  {\n    if (obj.status == 550) {\n      return(deliver);\n    }\n  }\n#--FASTLY ERROR END\n#--FASTLY HIT BEGIN\n# we cannot reach obj.ttl and obj.grace in deliver, save them when we can in vcl_hit\n  set req.http.Fastly-Tmp-Obj-TTL = obj.ttl;\n  set req.http.Fastly-Tmp-Obj-Grace = obj.grace;\n  {\n    set req.http.Fastly-Cachetype = \"HIT\";\n  }\n#--FASTLY HIT END\n#--FASTLY MISS BEGIN\n# this is not a hit after all, clean up these set in vcl_hit\n  unset req.http.Fastly-Tmp-Obj-TTL;\n  unset req.http.Fastly-Tmp-Obj-Grace;\n  {\n    if (req.http.Fastly-Check-SHA1) {\n       error 550 \"Doesnt exist\";\n    }\n#--FASTLY BEREQ BEGIN\n    {\n      if (req.http.Fastly-Original-Cookie) {\n        set bereq.http.Cookie = req.http.Fastly-Original-Cookie;\n      }\n      if (req.http.Fastly-Original-URL) {\n        set bereq.url = req.http.Fastly-Original-URL;\n      }\n      {\n        if (req.http.Fastly-FF) {\n          set bereq.http.Fastly-Client = \"1\";\n        }\n      }\n      {\n        # do not send this to the backend\n        unset bereq.http.Fastly-Original-Cookie;\n        unset bereq.http.Fastly-Original-URL;\n        unset bereq.http.Fastly-Vary-String;\n        unset bereq.http.X-Varnish-Client;\n      }\n      if (req.http.Fastly-Temp-XFF) {\n         if (req.http.Fastly-Temp-XFF == \"\") {\n           unset bereq.http.X-Forwarded-For;\n         } else {\n           set bereq.http.X-Forwarded-For = req.http.Fastly-Temp-XFF;\n         }\n         # unset bereq.http.Fastly-Temp-XFF;\n      }\n    }\n#--FASTLY BEREQ END\n #;\n    set req.http.Fastly-Cachetype = \"MISS\";\n  }\n#--FASTLY MISS END\n#--FASTLY PASS BEGIN\n  {\n#--FASTLY BEREQ BEGIN\n    {\n      if (req.http.Fastly-Original-Cookie) {\n        set bereq.http.Cookie = req.http.Fastly-Original-Cookie;\n      }\n      if (req.http.Fastly-Original-URL) {\n        set bereq.url = req.http.Fastly-Original-URL;\n      }\n      {\n        if (req.http.Fastly-FF) {\n          set bereq.http.Fastly-Client = \"1\";\n        }\n      }\n      {\n        # do not send this to the backend\n        unset bereq.http.Fastly-Original-Cookie;\n        unset bereq.http.Fastly-Original-URL;\n        unset bereq.http.Fastly-Vary-String;\n        unset bereq.http.X-Varnish-Client;\n      }\n      if (req.http.Fastly-Temp-XFF) {\n         if (req.http.Fastly-Temp-XFF == \"\") {\n           unset bereq.http.X-Forwarded-For;\n         } else {\n           set bereq.http.X-Forwarded-For = req.http.Fastly-Temp-XFF;\n         }\n         # unset bereq.http.Fastly-Temp-XFF;\n      }\n    }\n#--FASTLY BEREQ END\n #;\n    set req.http.Fastly-Cachetype = \"PASS\";\n  }\n#--FASTLY PASS END\n#--FASTLY PIPE BEGIN\n  {\n#--FASTLY BEREQ BEGIN\n    {\n      if (req.http.Fastly-Original-Cookie) {\n        set bereq.http.Cookie = req.http.Fastly-Original-Cookie;\n      }\n      if (req.http.Fastly-Original-URL) {\n        set bereq.url = req.http.Fastly-Original-URL;\n      }\n      {\n        if (req.http.Fastly-FF) {\n          set bereq.http.Fastly-Client = \"1\";\n        }\n      }\n      {\n        # do not send this to the backend\n        unset bereq.http.Fastly-Original-Cookie;\n        unset bereq.http.Fastly-Original-URL;\n        unset bereq.http.Fastly-Vary-String;\n        unset bereq.http.X-Varnish-Client;\n      }\n      if (req.http.Fastly-Temp-XFF) {\n         if (req.http.Fastly-Temp-XFF == \"\") {\n           unset bereq.http.X-Forwarded-For;\n         } else {\n           set bereq.http.X-Forwarded-For = req.http.Fastly-Temp-XFF;\n         }\n         # unset bereq.http.Fastly-Temp-XFF;\n      }\n    }\n#--FASTLY BEREQ END\n    #;\n    set req.http.Fastly-Cachetype = \"PIPE\";\n    set bereq.http.connection = \"close\";\n  }\n#--FASTLY PIPE END\n#--FASTLY RECV BEGIN\n  if (req.restarts == 0) {\n    if (!req.http.X-Timer) {\n      set req.http.X-Timer = \"S\" time.start.sec \".\" time.start.usec_frac;\n    }\n    set req.http.X-Timer = req.http.X-Timer \",VS0\";\n  }\n            set req.backend = autodirector_;\n  # default conditions\n  set req.backend = autodirector_;\n    # end default conditions\n#--FASTLY RECV END\n","tags":"#fastly #cdn #varnish #vcl"},{"id":"76829e05ec57cc908d30fc6a7731688d","title":"Python: Analyse Logs and report top N common matches ","content":"\"\"\"\nExample:\n    python logs.py -i \"10 seconds ago\"\n    python logs.py -i \"10 seconds ago\" -x \"now\"\n    python logs.py -i \"10 seconds ago\" -x \"now\" -u \"obiwan\"\n    python logs.py --min \"today at 9.20\" --max \"today at 10.20\" --upstream \"obiwan\"\n\"\"\" # noqa\n\nimport argparse\nimport re\nimport subprocess\n\nfrom collections import Counter\nfrom datetime import datetime\n\nparser = argparse.ArgumentParser(description=\"Process Site Router - nginx - Logs\")\nparser.add_argument(\"-i\", \"--min\", type=str, required=True, help=\"When to start getting logs\") # noqa\nparser.add_argument(\"-x\", \"--max\", type=str, default=\"now\", help=\"When to stop getting logs\") # noqa\nparser.add_argument(\"-u\", \"--upstream\", type=str, default=\"bpager\", help=\"Filter logs by this upstream\") # noqa\nargs = parser.parse_args()\n\n\ndef upstreams(logs):\n    result = set()\n\n    for line in logs:\n        match = re.search(\"upstream \\(([^:]+)\", line)\n        if match:\n            result.add(match.groups(0)[0])\n\n    return sorted(result)\n\n\ndef filter_logs_by_upstream(logs, upstream):\n    log_lines_keep = []\n\n    for line in logs:\n        result = re.search(\"upstream \\(([^:]+)\", line)\n        if result and result.groups(0)[0] == upstream:\n            log_lines_keep.append(line)\n\n    return log_lines_keep\n\n\ndef filter_logs_by_gets_that_were_errors(logs):\n    log_lines_gets = []\n\n    for line in logs:\n        result = re.search(\"GET /.+ HTTP/1.1 [4-5][0-9]{2}\", line)\n        if result:\n            log_lines_gets.append(line)\n\n    return log_lines_gets\n\n\ndef parse_log_urls(logs):\n    if len(logs) \u003c 1:\n        return \"no 4xx/5xx errors in the provided log data time period\"\n\n    log_processed = []\n\n    for line in logs:\n        result = re.search(\"(GET /.+ HTTP/1.1 [4-5][0-9]{2})\", line)\n        if result:\n            log_processed.append(result.groups(0)[0])\n\n    return sorted(log_processed)\n\n\ndef timeit(fn):\n    def helper():\n        start = datetime.now()\n        print(\"log retrieval started:\", start)\n\n        logs = fn()\n\n        finish = datetime.now()\n        print(f\"log retrieval finished: {finish}\\n\")\n\n        difference = finish - start\n        time_taken = f\"{round(difference.seconds / 60)}mins\" if difference.seconds \u003e= 60 else f\"{difference.seconds}s\" # noqa\n\n        print(f\"time taken to retrieve the logs: {time_taken}\\n\")\n        print(f\"number of log lines: {len(logs)}\")\n\n        print(\"upstreams found within the logs:\\n\")\n        for upstream in upstreams(logs):\n            print(f\"\\t{upstream}\")\n        print(\"\\n\")\n\n        return logs\n\n    return helper\n\n\n@timeit\ndef process():\n    command = [\n        \"papertrail\",\n        \"-g\",\n        \"rig-web-public\",\n        f'--min-time=\"{args.min}\"',\n        f'--max-time=\"{args.max}\"',\n        \"program:web-public/site_router/\"\n    ]\n\n    output = subprocess.run(command, stdout=subprocess.PIPE)\n    logs = output.stdout.decode(\"utf-8\").splitlines()\n\n    return logs\n\n\n# Acquire a set of logs for the specified time period\nlogs = process()\n\n# Filter logs so we only keep those for a specific upstream\nlogs_keep = filter_logs_by_upstream(logs, args.upstream)\nprint(f\"logs we're keeping (upstream: {args.upstream}): {len(logs_keep)}\")\n\n# Filter logs so we only keep 4xx/5xx GET requests\nlogs_gets = filter_logs_by_gets_that_were_errors(logs_keep)\nprint(f\"logs after filtering for 4xx/5xx GET requests: {len(logs_gets)}\\n\")\n\n# Track the top 10 4xx/5xx URLs\nresult_for_parse_log_urls = parse_log_urls(logs_gets)\ncount = Counter(result_for_parse_log_urls)\nfor item in count.most_common(10):\n    print(f\"{item[0]}\\ncount: {item[1]}\\n\")\n","tags":"#python #logs"},{"id":"9b496994a22d2c7d8aa24bf495ac355f","title":"[vim-plug load specific plugin] ","content":"\" we load our 'simple autocomplete' plugin for every filetype _except_ .go files\n\nfun! LoadSimpleAutoCompletePlugin()\n  \" Load vim-simple-complete for everything except .go files\n  if \u0026ft == \"go\"\n    return\n  endif\n  call plug#load('vim-simple-complete')\nendfun\n\naugroup LoadSACP\n  \" remove any previously loaded autocmd! for the InsertEnter event\n  autocmd!\n  autocmd InsertEnter * call LoadSimpleAutoCompletePlugin() | autocmd! LoadSACP\naugroup END\n\n","tags":"#vim #plugin"},{"id":"8a03b201d5de15fac8845414859b4f04","title":"[varnish hit-for-pass explanation] ","content":"## Hit For Pass\n\nYou may notice in `vcl_fetch` some logic like:\n\n```vcl\nif (beresp.http.Cache-Control ~ \"private\") {\n  return(pass);\n}\n```\n\nThe reason we `return(pass)` is because we don't want to cache this content (because we can see the response headers tell us it should be \"private\").\n\nBut in doing so varnish does _still_ create an object and caches it?\n\nThe object it creates is called \"hit-for-pass\" and it has a ttl of 120s.\n\n\u003e Note: the ttl can be changed using vcl but it should be kept small\n\nThe reason varnish does this is because if it _didn't_, then when the content is not cached and another request is made for that content, we would find that \"request collapsing\" starts causing an issue.\n\nRequest collapsing is where varnish blocks requests for the same uncached content in order to prevent overloading your origin. But in the case of uncachable content, users are blocked waiting for another request to complete only to find that the request wasn't cached and so the request is made again for the current user.\n\nAs you can imagine, this is very bad because the requests for this uncachable content has resulted in sequential processing. \n\nSo when we \"pass\" inside of `vcl_fetch` varnish prevents this bad sequential processing. It does this creating a \"hit-for-pass\" object which has a short ttl of 120s, and so for the next 120s any requests for this same resource will _not_ result in request collapsing (i.e. user requests to origin will not be blocked waiting for an already \"in-flight\" origin request to complete). Meaning, _all_ requests will be sent straight through to the origin.\n\n\u003e Note: you'll see in `vcl_hit` it looks out for `obj.cacheable` being false and subsequently executes `return(pass)` to allow the request to flow through to origin. When Varnish executes `return(pass)` inside of `vcl_fetch` it caches the \"hit-for-pass\" object with the `cacheable` attribute set to `false`.\n\nThe reason the ttl is supposed to be short is because for that ttl time period your origin is susceptible to multiple requests.\n\nSee the following link for a more detailed explanation:  \nhttps://info.varnish-software.com/blog/hit-for-pass-varnish-cache\n","tags":"#varnish #vcl"},{"id":"a7b496f4af3b83eead289af7ba8b0261","title":"[Python CLI Flags for CDN purge] ","content":"#!/usr/bin/env python3\n\nimport argparse\nimport time\nimport json\nfrom urllib.request import Request, urlopen\n\n\ndef purge_cdn(service_id: str, key: str, fastly_key: str) -\u003e None:\n    print('[cdn-purger] Purging {}'.format(key))\n    prurge_url = 'https://api.fastly.com/service/{}/purge/{}'.format(service_id, key)\n    headers = {\n        'X-Fastly-Key': fastly_key,\n        'Fastly-Soft-Purge': '1'\n    }\n    with urlopen(Request(prurge_url, method='POST', headers=headers), timeout=5) as response:\n        resp = json.loads(response.read().decode())\n    print('[cdn-purger] Purge status: {}, id: {}'.format(resp['status'], resp['id']))\n\n\ndef main():\n    parser = argparse.ArgumentParser(description='Purge CDN')\n    parser.add_argument('-d', '--delay', help='delay befor purge request (seconds)', type=int, default=30)\n    parser.add_argument('-r', '--retry', help='number of retries before giving up', type=int, default=3)\n    args = parser.parse_args()\n    time.sleep(args.delay)\n    service_id = \"123\"\n    key = '{}-{}'.format(\"foo\", \"stage\")\n    fastly_key = \"456\"\n    for i, _ in enumerate(range(args.retry), 1):\n        try:\n            purge_cdn(service_id, key, fastly_key)\n        except Exception as e:\n            print('[cdn-purger] Purge failed: {}, try: {}/{}'.format(e, i, args.retry))\n        else:\n            break\n\n\nif __name__ == '__main__':\n    main()\n","tags":"#python #cli #flags #cdn #purge"},{"id":"70856b480ecb343b85b796d4dd2f9f32","title":"[Python mutate list content and return new list as they're immutable] ","content":"def append_params(urls: list, params: str) -\u003e list:\n    \"\"\"Returns copy of list with modified values.\n\n    Example:\n        append_params([\"/foo\", \"/bar\", \"/baz\"], \"?id=123\")\n\n\t\t-\u003e [\"/foo?id=123\", \"/bar?id=123\", \"/baz?id=123\"]\n    \"\"\"\n    return list(map(lambda v: f\"{v}{params}\", urls))\n","tags":"#python"},{"id":"d387c16f9f7b06400e4d22581ccbc338","title":"[Fastly to S3 with Query Params] ","content":"sub filter_qs_by_whitelist {\n  # Clean up the query string:\n  #\n  #  - Sort query params by name\n  #  - Remove unnecessary query params (i.e. keep only those that match regex pattern)\n  #\n  # See helper functions documentation:\n  # https://docs.fastly.com/guides/vcl/query-string-manipulation-vcl-features\n  #\n  # tested:\n  # https://fiddle.fastlydemo.net/fiddle/d19f1e72\n  set req.url = querystring.sort(req.url);\n  set req.url = querystring.regfilter_except(req.url, \"^(adops_giraffe|bids|country|cs|ct|ids|language|network|or|p|page|page_quantity|page_size|s|sub|u|uo|user_id|wid)$\");\n}\n\nsub plan_z_recv {\n    ...\n    \n    # S3 doesn't understand Query Params\n    # So we need to encode any params into the url itself\n    #\n    # e.g. /news?id=foo -\u003e /news%3Fid%3Dfoo\n    #\n    if (req.url.qs != \"\") {\n      call filter_qs_by_whitelist;\n      set req.http.X-URL-Original = req.url;\n      set req.url = req.url.path + urlencode(\"?\" + req.url.qs);\n      set req.http.X-URL-Modified = req.url;\n    }\n    \n    ...\n}\n","tags":"#fastly #vcl #varnish"},{"id":"9cf6f2376aa25520a80e191e8925263f","title":"[Golang AWS S3 Examples] ","content":"\tsessionToken := \"\" // not required\n\taccessKey := \"AWS_ACCESS_KEY_ID\"\n\tsecretKey := \"AWS_SECRET_ACCESS_KEY\"\n\n\tsess, err := session.NewSession(\u0026aws.Config{\n\t\tRegion:      aws.String(\"us-east-1\"),\n\t\tCredentials: credentials.NewStaticCredentials(accessKey, secretKey, sessionToken),\n\t})\n\tif err != nil {\n\t\tlog.Fatal(\"unable to create aws session\")\n\t}\n\n\tsvc := s3.New(sess)\n\n\tinput := \u0026s3.ListObjectsInput{\n\t\tBucket:  aws.String(\"some_bucket_name\"),\n\t\tMaxKeys: aws.Int64(2), // only return two results!\n\t}\n\n\tresult, err := svc.ListObjects(input)\n\tif err != nil {\n\t\tif aerr, ok := err.(awserr.Error); ok {\n\t\t\tswitch aerr.Code() {\n\t\t\tcase s3.ErrCodeNoSuchBucket:\n\t\t\t\tfmt.Println(s3.ErrCodeNoSuchBucket, aerr.Error())\n\t\t\tdefault:\n\t\t\t\tfmt.Println(aerr.Error())\n\t\t\t}\n\t\t} else {\n\t\t\t// Print the error, cast err to awserr.Error to get the Code and\n\t\t\t// Message from an error.\n\t\t\tfmt.Println(err.Error())\n\t\t}\n\t\treturn\n\t}\n\n\tfmt.Println(result)\n/*\nOriginal written by Mark Gannaway...\nhttps://gist.github.com/Ganners/86f23c2d121332a8b3968bf05d2f720a\n\nDry Runs:\n\n# stage\ngo run main.go --bucket=\u003cyour_bucket_name\u003e --profile=planz-stage\n\n# prod\ngo run main.go --bucket=\u003cyour_bucket_name\u003e --profile=planz-prod\n\nReal Deletes:\n\n# stage\ngo run main.go --bucket=\u003cyour_bucket_name\u003e --profile=planz-stage --dryrun=false\n\n# prod\ngo run main.go --bucket=\u003cyour_bucket_name\u003e --profile=planz-prod --dryrun=false\n*/\n\npackage main\n\nimport (\n\t\"errors\"\n\t\"flag\"\n\t\"fmt\"\n\t\"log\"\n\t\"math/rand\"\n\t\"net/url\"\n\t\"strings\"\n\t\"sync\"\n\t\"time\"\n\n\t\"github.com/aws/aws-sdk-go/aws\"\n\t\"github.com/aws/aws-sdk-go/aws/credentials/stscreds\"\n\t\"github.com/aws/aws-sdk-go/aws/session\"\n\t\"github.com/aws/aws-sdk-go/service/s3\"\n)\n\nvar (\n\twhitelist = map[string]struct{}{\n\t\t// Used for /wd/UserWidget (which is used for ads)\n\t\t\"bids\":    struct{}{},\n\t\t\"cs\":      struct{}{},\n\t\t\"ct\":      struct{}{},\n\t\t\"network\": struct{}{},\n\t\t\"or\":      struct{}{},\n\t\t\"u\":       struct{}{},\n\t\t\"uo\":      struct{}{},\n\t\t\"wid\":     struct{}{},\n\n\t\t// Keep\n\t\t\"country\":         struct{}{}, // Used for varying the country, usually used when fetching feeds\n\t\t\"p\":               struct{}{}, // Used for selecting page\n\t\t\"page\":            struct{}{}, // Used for selecting page\n\t\t\"page_quantity\":   struct{}{}, // Used for specifying page size\n\t\t\"page_size\":       struct{}{}, // Used for specifying page size\n\t\t\"render_template\": struct{}{}, // Used for next pages in, etc. /nifty?render_template=0\u0026page=2\n\t}\n\n\tinvalidSuffix = []string{\n\t\t\".mobile.js\",\n\t\t\".mobile3.js\",\n\t}\n\n\tinvalidPrefix = []string{\n\t\t\"/\",\n\t\t\"api/comments\",\n\t}\n)\n\nconst (\n\tdeleteWorkers   = 100\n\tdeleteBatchSize = 10\n\tlistWorkers     = 1000\n)\n\nfunc main() {\n\tdryrun := true\n\tbucket := \"\"\n\tprofile := \"\"\n\t{\n\t\tflag.BoolVar(\u0026dryrun, \"dryrun\", true, \"is this a dry run? false will execute deletes\")\n\t\tflag.StringVar(\u0026bucket, \"bucket\", \"plan-z-stage-us-east-1\", \"what bucket to use\")\n\t\tflag.StringVar(\u0026profile, \"profile\", \"planz\", \"what bucket to use\")\n\t\tflag.Parse()\n\t}\n\n\tsvc := s3.New(session.Must(session.NewSessionWithOptions(session.Options{\n\t\tAssumeRoleTokenProvider: stscreds.StdinTokenProvider,\n\t\tConfig:                  aws.Config{Region: aws.String(\"us-east-1\")},\n\t\tProfile:                 profile,\n\t})))\n\n\tprefixes := []string{\"api/comments/stats\", \"/api/comments/stats\", \"?\"}\n\n\t// build the prefix list, this is geared specifically towards speeding up\n\t// the plan z deletions\n\tfor c1 := '0'; c1 \u003c= '9'; c1++ {\n\t\tfor c2 := '0'; c2 \u003c= '9'; c2++ {\n\t\t\tfor c3 := '0'; c3 \u003c= '9'; c3++ {\n\t\t\t\t// it appears we can have those starting with a slash and not\n\t\t\t\tprefixes = append(prefixes, \"api/comments/\"+string(c1)+string(c2)+string(c3))\n\t\t\t\tprefixes = append(prefixes, \"/api/comments/\"+string(c1)+string(c2)+string(c3))\n\t\t\t}\n\t\t}\n\t}\n\tfor c1 := '!'; c1 \u003c= '~'; c1++ {\n\t\tfor c2 := '!'; c2 \u003c= '~'; c2++ {\n\t\t\tfor c3 := '!'; c3 \u003c= '~'; c3++ {\n\t\t\t\tprefix := string(c1) + string(c2) + string(c3)\n\t\t\t\tif prefix == \"api\" {\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t\t// it appears we can have those starting with a slash and not\n\t\t\t\tprefixes = append(prefixes, prefix)\n\t\t\t}\n\t\t}\n\t}\n\n\t// shuffle keys\n\tfor i := range prefixes {\n\t\tj := rand.Intn(i + 1)\n\t\tprefixes[i], prefixes[j] = prefixes[j], prefixes[i]\n\t}\n\n\t// file list workers\n\toutputChan := NewListFilesWorkers(svc, bucket, prefixes, listWorkers)\n\n\tif dryrun {\n\t\tfor output := range outputChan {\n\t\t\t// dryrun just prints\n\t\t\tfmt.Println(output)\n\t\t}\n\t} else {\n\t\t// file delete workers\n\t\t\u003c-NewDeleteFilesWorkers(svc, bucket, outputChan, deleteWorkers)\n\t}\n}\n\n// DeleteFilesWorkers handles multiple workers to delete files\ntype DeleteFilesWorkers struct {\n\tsvc      *s3.S3\n\tbucket   string\n\tkeysChan chan string\n}\n\n// NewDeleteFilesWorkers will spawn and start a number of workers to handle\n// deletion, will output to the returned channel when complete\nfunc NewDeleteFilesWorkers(svc *s3.S3, bucket string, keysChan chan string, numWorkers int) chan struct{} {\n\tdfw := \u0026DeleteFilesWorkers{\n\t\tsvc:      svc,\n\t\tbucket:   bucket,\n\t\tkeysChan: keysChan,\n\t}\n\treturn dfw.Start(numWorkers)\n}\n\n// del will handle the actual deletion request to S3, retries up to 5 times\n// with jittered exponential backoff\nfunc (dfw *DeleteFilesWorkers) del(objects []*s3.ObjectIdentifier) error {\n\tif len(objects) == 0 {\n\t\treturn nil\n\t}\n\tfor attempt := 0; attempt \u003c 5; attempt++ {\n\t\tif attempt \u003e 0 {\n\t\t\tsleepJitter := time.Duration(rand.Intn(30))\n\t\t\tsleepSeconds := sleepJitter + time.Duration(attempt*attempt)\n\t\t\ttime.Sleep(sleepSeconds * time.Second)\n\t\t}\n\n\t\t_, err := dfw.svc.DeleteObjects(\u0026s3.DeleteObjectsInput{\n\t\t\tBucket: aws.String(dfw.bucket),\n\t\t\tDelete: \u0026s3.Delete{\n\t\t\t\tObjects: objects,\n\t\t\t},\n\t\t})\n\n\t\tif err == nil {\n\t\t\treturn nil\n\t\t}\n\t\tlog.Println(\"delete error\", err)\n\t}\n\treturn errors.New(\"unable to delete\")\n}\n\n// Start will start a number of workers to handle file batch deletion\nfunc (dfw *DeleteFilesWorkers) Start(workers int) chan struct{} {\n\tdoneCh := make(chan struct{})\n\tgo func() {\n\t\twg := sync.WaitGroup{}\n\t\tfor i := 0; i \u003c workers; i++ {\n\t\t\twg.Add(1)\n\t\t\tgo func() {\n\t\t\t\tdefer wg.Done()\n\t\t\t\tobjects := make([]*s3.ObjectIdentifier, 0, deleteBatchSize)\n\t\t\t\tfor key := range dfw.keysChan {\n\t\t\t\t\tobjects = append(objects, \u0026s3.ObjectIdentifier{\n\t\t\t\t\t\tKey: aws.String(key),\n\t\t\t\t\t})\n\n\t\t\t\t\tif len(objects) \u003c deleteBatchSize {\n\t\t\t\t\t\tcontinue\n\t\t\t\t\t}\n\n\t\t\t\t\terr := dfw.del(objects)\n\t\t\t\t\tif err == nil {\n\t\t\t\t\t\tlog.Println(\"successfully deleted\", len(objects), \"items\")\n\t\t\t\t\t\tobjects = make([]*s3.ObjectIdentifier, 0, deleteBatchSize)\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\t// if chan has been closed, trigger final delete\n\t\t\t\tdfw.del(objects)\n\t\t\t}()\n\t\t}\n\t\twg.Wait()\n\t\tdoneCh \u003c- struct{}{}\n\t}()\n\treturn doneCh\n}\n\n// ListFilesWorkers will start a number of workers to list files matching the\n// pattern and then sending them to the outputChan\ntype ListFilesWorkers struct {\n\tsvc        *s3.S3\n\tbucket     string\n\tprefixes   []string\n\toutputChan chan string\n}\n\n// NewListFilesWorkers will spawn a number of workers to iterate over the\n// prefixes to divide up the work\nfunc NewListFilesWorkers(svc *s3.S3, bucket string, prefixes []string, numWorkers int) chan string {\n\tlfw := \u0026ListFilesWorkers{\n\t\tsvc:        svc,\n\t\tbucket:     bucket,\n\t\tprefixes:   prefixes,\n\t\toutputChan: make(chan string),\n\t}\n\n\tgo lfw.Start(numWorkers)\n\n\treturn lfw.outputChan\n}\n\n// listObjects will handle looping and checking the contents of each key\nfunc (lfw *ListFilesWorkers) listObjects(p *s3.ListObjectsOutput, last bool) bool {\n\tfor _, obj := range p.Contents {\n\t\tif obj == nil {\n\t\t\tcontinue\n\t\t}\n\n\t\t// check if it is valid\n\t\turl, err := url.Parse(strings.Replace(*obj.Key, \"%3F\", \"?\", -1))\n\t\tif err != nil {\n\t\t\t// if there was an error, assume it's fine\n\t\t\tcontinue\n\t\t}\n\n\t\tinvalidParams := []string{}\n\t\tquery := url.Query()\n\n\t\tfor _, suffix := range invalidSuffix {\n\t\t\tif strings.HasSuffix(*obj.Key, suffix) {\n\t\t\t\tgoto delete\n\t\t\t}\n\t\t}\n\t\tfor _, prefix := range invalidPrefix {\n\t\t\tif strings.HasPrefix(*obj.Key, prefix) {\n\t\t\t\tgoto delete\n\t\t\t}\n\t\t}\n\n\t\tfor key := range query {\n\t\t\tif _, ok := whitelist[key]; !ok {\n\t\t\t\tinvalidParams = append(invalidParams, key)\n\t\t\t}\n\t\t}\n\n\t\tif len(invalidParams) == 0 {\n\t\t\tcontinue\n\t\t}\n\n\tdelete:\n\t\tlfw.outputChan \u003c- *obj.Key\n\t}\n\n\treturn true\n}\n\n// Start will commence a the workers, should be called in a goroutine. Will\n// close up the outputChan when it is finished\nfunc (lfw *ListFilesWorkers) Start(workers int) {\n\tnumPrefixes := len(lfw.prefixes)\n\tif numPrefixes \u003c workers {\n\t\tworkers = numPrefixes\n\t}\n\n\tsplitPrefixes := [][]string{}\n\tfor i, j := 0, 0; i \u003c= numPrefixes; j, i = i, (i + numPrefixes/workers) {\n\t\tif i == 0 {\n\t\t\tcontinue\n\t\t}\n\t\tsplitPrefixes = append(splitPrefixes, lfw.prefixes[j:i])\n\t}\n\n\twg := \u0026sync.WaitGroup{}\n\twg.Add(len(splitPrefixes))\n\tfor _, chunk := range splitPrefixes {\n\t\tgo func(chunk []string) {\n\t\t\tdefer wg.Done()\n\t\t\tfor _, prefix := range chunk {\n\t\t\t\terr := lfw.svc.ListObjectsPages(\n\t\t\t\t\t\u0026s3.ListObjectsInput{\n\t\t\t\t\t\tBucket:  aws.String(lfw.bucket),\n\t\t\t\t\t\tPrefix:  aws.String(prefix),\n\t\t\t\t\t\tMaxKeys: aws.Int64(1000),\n\t\t\t\t\t},\n\t\t\t\t\tlfw.listObjects,\n\t\t\t\t)\n\t\t\t\tif err != nil {\n\t\t\t\t\tfmt.Println(\"failed to list objects\", err)\n\t\t\t\t}\n\t\t\t}\n\t\t}(chunk)\n\t}\n\twg.Wait()\n\tclose(lfw.outputChan)\n}\n","tags":"#go #golang #aws #s3"},{"id":"a02ff1e208218442e04f2160dae6d2c6","title":"[Golang Generator (Yield) like Python] ","content":"package main\n\nimport \"fmt\"\n\nconst max = 10000000\n\nvar r int\n\nfunc process(x int) bool {\n\tr = x ^ x ^ x\n\n\treturn x == max\n}\n\nfunc getNumber(process func(x int) bool) {\n\tfor i := 0; i \u003c max; i++ {\n\t\tif process(i) {\n\t\t\tbreak\n\t\t}\n\t}\n}\n\nfunc main() {\n\tgetNumber(process)\n\tfmt.Println(r) // 9999999\n}\n","tags":"#go #golang #generator #yield"},{"id":"def6f72d6651c4bd86c610da1d04dc48","title":"[GitHub DNS Reverse Lookup] ","content":"$ dig +short -x $(echo $(dig +short github.com) | cut -d ' ' -f 1)\n\nlb-192-30-253-113-iad.github.com.\n","tags":"#dns #domain #ip #lookup"},{"id":"03279be86a356119b1f820da6ebb8740","title":"[Validate README format with Python] ","content":"# no improvement in performance as the os.walk is the bottleneck and can't be sped up\n\nimport fnmatch\nimport itertools\nimport multiprocessing\nimport os\nimport re\nimport unicodedata\n\nvalid_headers = set([\n    \"## Point of Contact and Slack channel\",\n    \"## Running the service\",\n    \"## System\",\n    \"## Runbook\",\n    \"## Monitoring\",\n    \"## Documentation\",\n])\n\ntitle = re.compile(\"^\\s*(#.+$)\", re.MULTILINE)\ninvalid = re.compile(\"node_modules\")\n\ndef worker(filename):\n    with open(filename, \"r\") as f:\n        if not invalid.search(filename):\n            print(filename, \"\\n\\n\")\n\n            contents = f.read()\n            contents = unicodedata.normalize(\"NFKD\", contents)\n            matches = title.findall(contents)\n            missing_headers = valid_headers - set(matches)\n            is_valid = valid_headers.issubset(set(matches))\n\n            if matches:\n                print(\"Is README valid?\\n\", is_valid)\n            else:\n                print(\"no matching headers found? so will presume this README is invalid\")\n\n            print(\"\\n\\n---\\n\\n\")\n\nwith multiprocessing.Pool(48) as Pool: # pool of 48 processes\n    walk = os.walk(\"./\") # generator\n\n    # this is the bottleneck (the walking of all files \u0026 directories)\n    fn_gen = itertools.chain.from_iterable((os.path.join(root, file)\n                                            for file in fnmatch.filter(files, 'README.md'))\n                                           for root, dirs, files in walk)\n\n    results_of_work = Pool.map(worker, fn_gen) # this does the parallel processing\n\"\"\"\nUsage:\n\n    python ./scripts/validate_readmes.py\n        validate every README (~1min)\n\n    python ./scripts/validate_readmes.py --debug\n        validate every README with details on what headers are missing (~1min)\n\n    python ./scripts/validate_readmes.py --debug --service bpager\n        validate specific service README (time varies by service directory structure)\n\"\"\"\n\nimport argparse\nimport glob\nimport re\nimport unicodedata\n\nparser = argparse.ArgumentParser(description=\"Validate READMEs\")\nparser.add_argument(\"-d\", \"--debug\",\n                    help=\"Show failure details\", action=\"store_true\")\nparser.add_argument(\"-s\", \"--service\", help=\"Validate specific service\",\n                    default=\"**\")\nparser.set_defaults(debug=False)\nargs = parser.parse_args()\n\nvalid_headers = set([\n    \"## Point of Contact and Slack channel\",\n    \"## Running the service\",\n    \"## System\",\n    \"## Runbook\",\n    \"## Monitoring\",\n    \"## Documentation\",\n])\n\ntitle = re.compile(\"^\\s*(#.+$)\", re.MULTILINE)\ninvalid = re.compile(\"node_modules\")\nservice = args.service\npath = f\"../buzzfeed/mono/{service}/README.md\"\n\n\nfor filename in glob.iglob(path, recursive=True):\n    with open(filename, \"r\") as f:\n        if not (invalid.search(filename)):\n            print(filename, \"\\n\\n\")\n\n            contents = f.read()\n            contents = unicodedata.normalize(\"NFKD\", contents)\n            matches = title.findall(contents)\n            missing_headers = valid_headers - set(matches)\n            is_valid = valid_headers.issubset(set(matches))\n\n            if matches:\n                if args.debug:\n                    print(\"Found headers:\\n\", matches, \"\\n\\n\")\n                    print(\"Expected headers:\\n\", valid_headers, \"\\n\\n\")\n                    print(\"Missing headers:\\n\", missing_headers, \"\\n\\n\")\n                print(\"Is README valid?\\n\", is_valid)\n            else:\n                print(\"no matching headers found? so will presume this README is invalid\")\n\n            print(\"\\n\\n---\\n\\n\")\n# Python 3.4 has no iglob recursive option so we have to walk the entire tree (very slow)\n\n#!/usr/bin/env python3\n\n\"\"\"\nUsage:\n\n    ./scripts/validate_readmes\n        validate every README (~40s)\n\n    ./scripts/validate_readmes --missing\n        report how many READMEs are missing from top level service directories\n\n    ./scripts/validate_readmes --debug\n        validate every README with details on what headers are missing (~40s+)\n\n    ./scripts/validate_readmes --debug --service bpager\n        validate specific service README (time varies by service directory structure)\n\n    ./scripts/validate_readmes --result\n        validate every README and show the number of valid vs invalid READMEs (~40s+)\n\n    ./scripts/validate_readmes --service bpager --result\n        validate specific service README and show the number of valid vs invalid READMEs\n\n    ./scripts/validate_readmes --csv \u003e readmes.csv\n        generate CSV data highlighting valid vs invalid READMEs (~40s+)\n\n    ./scripts/validate_readmes --service bpager --csv \u003e bpager.csv\n        generate CSV data highlighting valid vs invalid READMEs for a specific service\n\"\"\"\n\nimport argparse\nimport fnmatch\nimport json\nimport re\nimport os\nimport unicodedata\n\nparser = argparse.ArgumentParser(description=\"Validate READMEs\")\nparser.add_argument(\"-d\", \"--debug\",\n                    help=\"Show failure details\", action=\"store_true\")\nparser.add_argument(\"-s\", \"--service\", help=\"Validate specific service\",\n                    default=\"\")\nparser.add_argument(\"-r\", \"--result\", help=\"Show only the results of the validation checker\",\n                    action=\"store_true\")\nparser.add_argument(\"-c\", \"--csv\", help=\"Generate CSV of results\",\n                    action=\"store_true\")\nparser.add_argument(\"-m\", \"--missing\", help=\"Show services that have no README file\", action=\"store_true\")\nparser.set_defaults(debug=False, result=False, csv=False, missing=False)\nargs = parser.parse_args()\n\nvalid_headers = set([\n    \"## Point of Contact and Slack channel\",\n    \"## Running the service\",\n    \"## System\",\n    \"## Runbook\",\n    \"## Monitoring\",\n    \"## Documentation\",\n])\n\ntitle = re.compile(\"^\\s*(#.+$)\", re.MULTILINE)\ninvalid = re.compile(\"node_modules\")\nservice = args.service\nvalid = 0\ncsv = \"file,valid\\n\"\ntop_level_dirs = {}\n\nif args.missing:\n    for item in sorted(os.listdir(\"./\")):\n        path = os.path.join(\"./\", item)\n        is_dir = os.path.isdir(path)\n        if is_dir and not path.startswith(\"./.\"):\n            top_level_dirs[path] = False\n            for file in os.listdir(path):\n                if file == \"README.md\":\n                    top_level_dirs[path] = True\n\n    if args.debug:\n        print(json.dumps(top_level_dirs, indent=2, sort_keys=True))\n\n    total = len(top_level_dirs)\n    missing = total - sum(top_level_dirs.values())\n    percent = round(missing / total * 100)\n    print(\"\\n{}% of top level directories are missing a README ({} out of {})\\n\".format(percent, missing, total))\n    exit()\n\nif service == \"\" and not args.csv:\n    print(\"hold tight, this can take up to 40 seconds to process every README in mono...\")\n\nfile_matches = []\nfor root, dirnames, filenames in os.walk(\"./\" + args.service):\n    for filename in fnmatch.filter(filenames, \"README.md\"):\n        fn = os.path.join(root, filename)\n        if not invalid.search(fn):\n            file_matches.append(fn)\n\nfor filename in file_matches:\n    with open(filename, \"r\") as f:\n        contents = f.read()\n        contents = unicodedata.normalize(\"NFKD\", contents)\n        matches = title.findall(contents)\n        missing_headers = valid_headers - set(matches)\n        is_valid = valid_headers.issubset(set(matches))\n\n        if args.csv:\n            csv += \"{},{}\\n\".format(filename, is_valid)\n\n        if is_valid:\n            valid += 1\n\n        if not args.result and not args.csv:\n            print(filename, \"\\n\\n\")\n\n            if matches:\n                if args.debug:\n                    print(\"Found headers:\\n\", matches, \"\\n\\n\")\n                    print(\"Expected headers:\\n\", valid_headers, \"\\n\\n\")\n                    print(\"Missing headers:\\n\", missing_headers, \"\\n\\n\")\n                print(\"Is README valid?\\n\", is_valid)\n            else:\n                print(\"no matching headers found? so will presume this README is invalid\")\n\n            print(\"\\n\\n---\\n\\n\")\n\nif args.result and not args.csv:\n    percent = round(valid / len(file_matches) * 100)\n    print(\"\\n{}% of the READMEs found are valid ({} out of {})\\n\".format(percent, valid, len(file_matches)))\n\nif args.csv:\n    print(csv)\n    \n\"\"\"\nInconsistent Numbers?\n\nWhen using the `--missing` flag, the script doesn't walk every _nested_ directory (like it does when validating READMEs using the `--result` flag). This is because not all nested directories would logically have a README.\n\ne.g. `/foo-service/random-dir/` can't necessarily be classed as _missing_ a README as there may well be no need for one there. Where as the top level directories in mono are all expected to have a README at the very least.\n\nBut some top level directories will indeed have a nested directory that _does_ have a README and if so we should at least validate those the best we can against the standard format.\n\ne.g. `./scripts/validate_readmes -s bpager` reports there are two READMEs `./bpager/README.md` (valid) and `./bpager/tests/e2e/README.md` (invalid).\n\nSubsequently, because `--missing` only checks the top level directories, we'll likely find that number (i.e. the number of directories \"missing\" a README) will be a much lower number than the number of \"invalid vs valid\" READMEs reported by the `--result` flag.\n\nIf you look at the examples given above, that's why the number of \"found\" READMEs is 378 (because it recursively searched all nested directories) where as the total number of top level directories is reported as 469. If you were to do `469-378` you won't see the same result as what is being reported as directories with \"missing\" READMEs (205) because that's not a comparison that can be made.\n\nThe reason the script validates all found READMEs, rather than just validating the READMEs in the top level directories, is because there's lots of Python package related READMEs (e.g. `./packages/foo-package/README.md`) that need to be validated and those would otherwise be missed. We could potentially add a whitelist or blacklist to account for \"known\" directories that we should recurse into but then we could in future end up skipping over directories that we might want to validate READMEs.\n\"\"\"\n$ python validate.py --debug\n\n# note: this would print out 'all' READMEs...\n\n---\n\n\n../buzzfeed/mono/video_player/README.md\n\n\nFound headers:\n ['# Video Player Service (VPS)', '## Usage', '## Data Response', '## Running the service', '## System', '## Runbook', '## Monitoring', '### Logs', '### Dashboards', '### Alarms', '## Documentation']\n\n\nExpected headers:\n {'## System', '## Documentation', '## Running the service', '## Monitoring', '## Point of Contact and Slack channel', '## Runbook', '## Usage'}\n\n\nMissing headers:\n {'## Point of Contact and Slack channel'}\n\n\nIs README valid?\n False\n\n\n---\n\n$ python validate.py\n\n# note: this would print out 'all' READMEs...\n\n---\n\n\n../buzzfeed/mono/video_player/README.md\n\n\nIs README valid?\n False\n\n\n---\n\n$ python validate.py --debug --service bpager\n\n# note: this would print out 'only' the bpager README...\n\n---\n\n../buzzfeed/mono/bpager/README.md \n\nFound headers:\n ['# BPager', '## Running the service', '## Point of Contact and Slack channel', '## Runbook', '## System', '## Monitoring', '### Logs', '### Dashboards', '## Documentation'] \n\n\nExpected headers:\n {'## System', '## Monitoring', '## Running the service', '## Runbook', '## Point of Contact and Slack channel', '## Documentation'} \n\n\nMissing headers:\n set() \n\n\nIs README valid?\n True\n\n---\n\n$ python validate.py --service bpager\n\n# note: this would print out 'only' the bpager README...\n\n---\n\n../buzzfeed/mono/bpager/README.md \n\nIs README valid?\n True\n\n---\n\n./scripts/validate_readmes --service bpager --result                                                                                                                                     \n\n1 of 2 are valid\n\n./scripts/validate_readmes --result                                                                                                                                                      \n\nhold tight, this can take up to 40 seconds to process every README in mono...\n\n19 of 1156 are valid\n","tags":"#python"},{"id":"4dcf314dffecb366dee081e0e1081d50","title":"[Python Flame Graph with pyflame] ","content":"FROM python:3.6.3\n\nWORKDIR /pyflame\n\nRUN apt-get update -y\nRUN apt-get install -y git autoconf automake autotools-dev g++ pkg-config python-dev python3-dev libtool make\n\nRUN git clone https://github.com/uber/pyflame.git \u0026\u0026 \\\n    cd pyflame \u0026\u0026 ./autogen.sh \u0026\u0026 ./configure \u0026\u0026 make\n\nWORKDIR /flamegraph\n\nRUN git clone https://github.com/brendangregg/FlameGraph\n\nCOPY app.py /app/app.py\n\nWORKDIR /app\n\nCMD /pyflame/pyflame/src/pyflame -o prof.txt -t python app.py \u0026\u0026\\\n    /flamegraph/FlameGraph/flamegraph.pl ./prof.txt\n\n# docker build -t pyflame .\n# docker run --privileged pyflame \u003e output.svg \u0026\u0026 tail -n+2 output.svg \u003e output_stripped.svg\ndef foo():\n    return 1 + 1\n\n\ndef get_number():\n    foo()\n    for i in range(10000000):\n        yield i\n\n\ndef expensive_function():\n    for n in get_number():\n        r = n ^ n ^ n\n    return f\"some result! {r}\"\n\n\nresult = expensive_function()\nprint(result)\n","tags":"#pyflame #flame #graph #python"},{"id":"8f6a3aeb721ec00affbc5c42590343b0","title":"[Go Loop Alphabet via Code Points] ","content":"package main\n\nimport (\n\t\"fmt\"\n)\n\nfunc main() {\n\tfor c := 'a'; c \u003c= 'z'; c++ {\n\t\tfmt.Printf(\"%s (code point: %v)\\n\", string(c), c)\n\t}\n}\n","tags":"#go #golang"},{"id":"73753be0eb5c35bd3ae1e234f3f77dde","title":"[awk search and sum columns] ","content":"ls -l | awk '{sum += $5}; END {print sum}'\n\n# you can also ignore a line before summing...\nls -l | awk '/^total/{next} {sum += $5}; END {print sum}'\n","tags":"#awk #search #sum"},{"id":"e2f3ff5522d20605874e1ce18258bc02","title":"[Dockerize Node] ","content":"FROM node:9.11.1\n\nENV NPM_CONFIG_LOGLEVEL warn\nENV NODE_PATH=/node_modules\n\n# Seems react drops path-expected binaries, so we just add node’s bin folder to the PATH\nENV PATH=$PATH:/node_modules/.bin\n\nCOPY app/package.json /\nRUN cd /\nRUN npm install\n\nCOPY app /application\nWORKDIR /application\n\nCMD [\"npm\", \"run\", \"start\"]\n# CMD [\"bash\", \"/app/scripts/run\"]\n","tags":"#docker #node"},{"id":"f04b2ac395bd6ded45efcfb4fceec5a4","title":"[AWS Amplify Tips] ","content":"## Enable debug log\n\n```js\nwindow.LOG_LEVEL = 'DEBUG';\n```\n\n## Disable analytics \n\nThe noise in the debug logs is insane:\n\n```js\nimport { Analytics } from 'aws-amplify';\n\nAnalytics.disable();\n```\n\n## Manual Configuration\n\n```js\nimport Amplify,{Auth} from 'aws-amplify';\n\nAmplify.configure({\n  Auth: {\n    identityPoolId: '...',\n    region: '...',\n    userPoolId: '...',\n    userPoolWebClientId: '...',\n  }\n});\n```\n\n## Sign Up\n\n```js\nconst phone = this.state.phone.trim();\n\nvar attributes = {\n    email: email,\n    name: fullname\n}\n\nif (phone) {\n    attributes['phone_number'] = phone;\n}\n\nAuth.signUp({\n    username: username,\n    password: password,\n    attributes: attributes\n})\n.then(\n    this.setState(() =\u003e {\n        return {\n            enterAuth: true\n        }\n    })\n)\n.catch( err =\u003e {\n    console.log(username, password, email, phone, fullname);\n    console.log(err);\n})\n```\n","tags":"#aws #amplify #cognito #js #javascript"},{"id":"a29f00053771789914baa652c104cac8","title":"[ElasticSearch] ","content":"```bash\ncurl -XPUT 'localhost:9200/foo/bar/1?pretty' -d '{\"name\": \"Elasticsearch Denver\", \"organizer\": \"Lee\"}'\n```\n\nResponse...\n\n```json\n{\n  \"_index\" : \"foo\",\n  \"_type\" : \"bar\",\n  \"_id\" : \"1\",\n  \"_version\" : 1,\n  \"created\" : true\n}\n```\n\n\u003e Creating the index itself takes more time than creating a document, so you might want to have the index ready beforehand.\n\n```bash\ncurl -XPUT 'localhost:9200/new-index'\n\n{\"acknowledged\":true}\n```\n\nExample population script from the book \"ElasticSearch in Action\"...\n\nhttps://github.com/dakrone/elasticsearch-in-action/blob/master/populate.sh\n\n```bash\n#!/usr/bin/env bash\n\nADDRESS=$1\n\nif [ -z $ADDRESS ]; then\n  ADDRESS=\"localhost:9200\"\nfi\n\n# Check that Elasticsearch is running\ncurl -s \"http://$ADDRESS\" 2\u003e\u00261 \u003e /dev/null\nif [ $? != 0 ]; then\n    echo \"Unable to contact Elasticsearch at $ADDRESS\"\n    echo \"Please ensure Elasticsearch is running and can be reached at http://$ADDRESS/\"\n    exit -1\nfi\n\necho \"WARNING, this script will delete the 'get-together' and the 'myindex' indices and re-index all data!\"\necho \"Press Control-C to cancel this operation.\"\necho\necho \"Press [Enter] to continue.\"\nread\n\n# Delete the old index, swallow failures if it doesn't exist\ncurl -s -XDELETE \"$ADDRESS/get-together\" \u003e /dev/null\n\n# Create the next index using mapping.json\necho \"Creating 'get-together' index...\"\ncurl -s -XPOST \"$ADDRESS/get-together\" -d@$(dirname $0)/mapping.json\n\n# Wait for index to become yellow\ncurl -s \"$ADDRESS/get-together/_health?wait_for_status=yellow\u0026timeout=10s\" \u003e /dev/null\necho\necho \"Done creating 'get-together' index.\"\n\necho\necho \"Indexing data...\"\n\necho \"Indexing groups...\"\ncurl -s -XPOST \"$ADDRESS/get-together/group/1\" -d'{\n  \"name\": \"Denver Clojure\",\n  \"organizer\": [\"Daniel\", \"Lee\"],\n  \"description\": \"Group of Clojure enthusiasts from Denver who want to hack on code together and learn more about Clojure\",\n  \"created_on\": \"2012-06-15\",\n  \"tags\": [\"clojure\", \"denver\", \"functional programming\", \"jvm\", \"java\"],\n  \"members\": [\"Lee\", \"Daniel\", \"Mike\"],\n  \"location_group\": \"Denver, Colorado, USA\"\n}'\n\necho\ncurl -s -XPOST \"$ADDRESS/get-together/group/2\" -d'{\n  \"name\": \"Elasticsearch Denver\",\n  \"organizer\": \"Lee\",\n  \"description\": \"Get together to learn more about using Elasticsearch, the applications and neat things you can do with ES!\",\n  \"created_on\": \"2013-03-15\",\n  \"tags\": [\"denver\", \"elasticsearch\", \"big data\", \"lucene\", \"solr\"],\n  \"members\": [\"Lee\", \"Mike\"],\n  \"location_group\": \"Denver, Colorado, USA\"\n}'\n\necho\ncurl -s -XPOST \"$ADDRESS/get-together/group/3\" -d'{\n  \"name\": \"Elasticsearch San Francisco\",\n  \"organizer\": \"Mik\",\n  \"description\": \"Elasticsearch group for ES users of all knowledge levels\",\n  \"created_on\": \"2012-08-07\",\n  \"tags\": [\"elasticsearch\", \"big data\", \"lucene\", \"open source\"],\n  \"members\": [\"Lee\", \"Igor\"],\n  \"location_group\": \"San Francisco, California, USA\"\n}'\n\necho\ncurl -s -XPOST \"$ADDRESS/get-together/group/4\" -d'{\n  \"name\": \"Boulder/Denver big data get-together\",\n  \"organizer\": \"Andy\",\n  \"description\": \"Come learn and share your experience with nosql \u0026 big data technologies, no experience required\",\n  \"created_on\": \"2010-04-02\",\n  \"tags\": [\"big data\", \"data visualization\", \"open source\", \"cloud computing\", \"hadoop\"],\n  \"members\": [\"Greg\", \"Bill\"],\n  \"location_group\": \"Boulder, Colorado, USA\"\n}'\n\necho\ncurl -s -XPOST \"$ADDRESS/get-together/group/5\" -d'{\n  \"name\": \"Enterprise search London get-together\",\n  \"organizer\": \"Tyler\",\n  \"description\": \"Enterprise search get-togethers are an opportunity to get together with other people doing search.\",\n  \"created_on\": \"2009-11-25\",\n  \"tags\": [\"enterprise search\", \"apache lucene\", \"solr\", \"open source\", \"text analytics\"],\n  \"members\": [\"Clint\", \"James\"],\n  \"location_group\": \"London, England, UK\"\n}'\n\necho\necho \"Done indexing groups.\"\n\necho \"Indexing events...\"\n\ncurl -s -XPOST \"$ADDRESS/get-together/event/100?parent=1\" -d'{\n  \"host\": [\"Lee\", \"Troy\"],\n  \"title\": \"Liberator and Immutant\",\n  \"description\": \"We will discuss two different frameworks in Clojure for doing different things. Liberator is a ring-compatible web framework based on Erlang Webmachine. Immutant is an all-in-one enterprise application based on JBoss.\",\n  \"attendees\": [\"Lee\", \"Troy\", \"Daniel\", \"Tom\"],\n  \"date\": \"2013-09-05T18:00\",\n  \"location_event\": {\n    \"name\": \"Stoneys Full Steam Tavern\",\n    \"geolocation\": \"39.752337,-105.00083\"\n  },\n  \"reviews\": 4\n}'\necho\ncurl -s -XPOST \"$ADDRESS/get-together/event/101?parent=1\" -d'{\n  \"host\": \"Sean\",\n  \"title\": \"Sunday, Surly Sunday\",\n  \"description\": \"Sort out any setup issues and work on Surlybird issues. We can use the EC2 node as a bounce point for pairing.\",\n  \"attendees\": [\"Daniel\", \"Michael\", \"Sean\"],\n  \"date\": \"2013-07-21T18:30\",\n  \"location_event\": {\n    \"name\": \"IRC, #denofclojure\"\n  },\n  \"reviews\": 2\n}'\n\necho\ncurl -s -XPOST \"$ADDRESS/get-together/event/102?parent=1\" -d'{\n  \"host\": \"Daniel\",\n  \"title\": \"10 Clojure coding techniques you should know, and project openbike\",\n  \"description\": \"What are ten Clojure coding techniques that you wish everyone knew? We will also check on the status of Project Openbike.\",\n  \"attendees\": [\"Lee\", \"Tyler\", \"Daniel\", \"Stuart\", \"Lance\"],\n  \"date\": \"2013-07-11T18:00\",\n  \"location_event\": {\n    \"name\": \"Stoneys Full Steam Tavern\",\n    \"geolocation\": \"39.752337,-105.00083\"\n  },\n  \"reviews\": 3\n}'\n\necho\ncurl -s -XPOST \"$ADDRESS/get-together/event/103?parent=2\" -d'{\n  \"host\": \"Lee\",\n  \"title\": \"Introduction to Elasticsearch\",\n  \"description\": \"An introduction to ES and each other. We can meet and greet and I will present on some Elasticsearch basics and how we use it.\",\n  \"attendees\": [\"Lee\", \"Martin\", \"Greg\", \"Mike\"],\n  \"date\": \"2013-04-17T19:00\",\n  \"location_event\": {\n    \"name\": \"Stoneys Full Steam Tavern\",\n    \"geolocation\": \"39.752337,-105.00083\"\n  },\n  \"reviews\": 5\n}'\n\necho\ncurl -s -XPOST \"$ADDRESS/get-together/event/104?parent=2\" -d'{\n  \"host\": \"Lee\",\n  \"title\": \"Queries and Filters\",\n  \"description\": \"A get together to talk about different ways to query Elasticsearch, what works best for different kinds of applications.\",\n  \"attendees\": [\"Lee\", \"Greg\", \"Richard\"],\n  \"date\": \"2013-06-17T18:00\",\n  \"location_event\": {\n    \"name\": \"Stoneys Full Steam Tavern\",\n    \"geolocation\": \"39.752337,-105.00083\"\n  },\n  \"reviews\": 1\n}'\n\necho\ncurl -s -XPOST \"$ADDRESS/get-together/event/105?parent=2\" -d'{\n  \"host\": \"Lee\",\n  \"title\": \"Elasticsearch and Logstash\",\n  \"description\": \"We can get together and talk about Logstash - http://logstash.net with a sneak peek at Kibana\",\n  \"attendees\": [\"Lee\", \"Greg\", \"Mike\", \"Delilah\"],\n  \"date\": \"2013-07-17T18:30\",\n  \"location_event\": {\n    \"name\": \"Stoneys Full Steam Tavern\",\n    \"geolocation\": \"39.752337,-105.00083\"\n  },\n  \"reviews\": null\n}'\n\necho\ncurl -s -XPOST \"$ADDRESS/get-together/event/106?parent=3\" -d'{\n  \"host\": \"Mik\",\n  \"title\": \"Social management and monitoring tools\",\n  \"description\": \"Shay Banon will be there to answer questions and we can talk about management tools.\",\n  \"attendees\": [\"Shay\", \"Mik\", \"John\", \"Chris\"],\n  \"date\": \"2013-03-06T18:00\",\n  \"location_event\": {\n    \"name\": \"Quid Inc\",\n    \"geolocation\": \"37.798442,-122.399801\"\n  },\n  \"reviews\": 5\n}'\n\necho\ncurl -s -XPOST \"$ADDRESS/get-together/event/107?parent=3\" -d'{\n  \"host\": \"Mik\",\n  \"title\": \"Logging and Elasticsearch\",\n  \"description\": \"Get a deep dive for what Elasticsearch is and how it can be used for logging with Logstash as well as Kibana!\",\n  \"attendees\": [\"Shay\", \"Rashid\", \"Erik\", \"Grant\", \"Mik\"],\n  \"date\": \"2013-04-08T18:00\",\n  \"location_event\": {\n    \"name\": \"Salesforce headquarters\",\n    \"geolocation\": \"37.793592,-122.397033\"\n  },\n  \"reviews\": 3\n}'\n\necho\ncurl -s -XPOST \"$ADDRESS/get-together/event/108?parent=3\" -d'{\n  \"host\": \"Elyse\",\n  \"title\": \"Piggyback on Elasticsearch training in San Francisco\",\n  \"description\": \"We can piggyback on training by Elasticsearch to have some Q\u0026A time with the ES devs\",\n  \"attendees\": [\"Shay\", \"Igor\", \"Uri\", \"Elyse\"],\n  \"date\": \"2013-05-23T19:00\",\n  \"location_event\": {\n    \"name\": \"NoSQL Roadshow\",\n    \"geolocation\": \"37.787742,-122.398964\"\n  },\n  \"reviews\": 5\n}'\n\necho\ncurl -s -XPOST \"$ADDRESS/get-together/event/109?parent=4\" -d'{\n  \"host\": \"Andy\",\n  \"title\": \"Hortonworks, the future of Hadoop and big data\",\n  \"description\": \"Presentation on the work that hortonworks is doing on Hadoop\",\n  \"attendees\": [\"Andy\", \"Simon\", \"David\", \"Sam\"],\n  \"date\": \"2013-06-19T18:00\",\n  \"location_event\": {\n    \"name\": \"SendGrid Denver office\",\n    \"geolocation\": \"39.748477,-104.998852\"\n  },\n  \"reviews\": 2\n}'\n\necho\ncurl -s -XPOST \"$ADDRESS/get-together/event/110?parent=4\" -d'{\n  \"host\": \"Andy\",\n  \"title\": \"Big Data and the cloud at Microsoft\",\n  \"description\": \"Discussion about the Microsoft Azure cloud and HDInsight.\",\n  \"attendees\": [\"Andy\", \"Michael\", \"Ben\", \"David\"],\n  \"date\": \"2013-07-31T18:00\",\n  \"location_event\": {\n    \"name\": \"Bing Boulder office\",\n    \"geolocation\": \"40.018528,-105.275806\"\n  },\n  \"reviews\": 1\n}'\n\necho\ncurl -s -XPOST \"$ADDRESS/get-together/event/111?parent=4\" -d'{\n  \"host\": \"Andy\",\n  \"title\": \"Moving Hadoop to the mainstream\",\n  \"description\": \"Come hear about how Hadoop is moving to the main stream\",\n  \"attendees\": [\"Andy\", \"Matt\", \"Bill\"],\n  \"date\": \"2013-07-21T18:00\",\n  \"location_event\": {\n    \"name\": \"Courtyard Boulder Louisville\",\n    \"geolocation\": \"39.959409,-105.163497\"\n  },\n  \"reviews\": 4\n}'\n\necho\ncurl -s -XPOST \"$ADDRESS/get-together/event/112?parent=5\" -d'{\n  \"host\": \"Dave Nolan\",\n  \"title\": \"real-time Elasticsearch\",\n  \"description\": \"We will discuss using Elasticsearch to index data in real time\",\n  \"attendees\": [\"Dave\", \"Shay\", \"John\", \"Harry\"],\n  \"date\": \"2013-02-18T18:30\",\n  \"location_event\": {\n    \"name\": \"SkillsMatter Exchange\",\n    \"geolocation\": \"51.524806,-0.099095\"\n  },\n  \"reviews\": 3\n}'\n\necho\ncurl -s -XPOST \"$ADDRESS/get-together/event/113?parent=5\" -d'{\n  \"host\": \"Dave\",\n  \"title\": \"Elasticsearch at Rangespan and Exonar\",\n  \"description\": \"Representatives from Rangespan and Exonar will come and discuss how they use Elasticsearch\",\n  \"attendees\": [\"Dave\", \"Andrew\", \"David\", \"Clint\"],\n  \"date\": \"2013-06-24T18:30\",\n  \"location_event\": {\n    \"name\": \"Alumni Theatre\",\n    \"geolocation\": \"51.51558,-0.117699\"\n  },\n  \"reviews\": 3\n}'\n\necho\ncurl -s -XPOST \"$ADDRESS/get-together/event/114?parent=5\" -d'{\n  \"host\": \"Yann\",\n  \"title\": \"Using Hadoop with Elasticsearch\",\n  \"description\": \"We will walk through using Hadoop with Elasticsearch for big data crunching!\",\n  \"attendees\": [\"Yann\", \"Bill\", \"James\"],\n  \"date\": \"2013-09-09T18:30\",\n  \"location_event\": {\n    \"name\": \"SkillsMatter Exchange\",\n    \"geolocation\": \"51.524806,-0.099095\"\n  },\n  \"reviews\": 2\n}'\n\necho\necho \"Done indexing events.\"\n\n# Refresh so data is available\ncurl -s -XPOST \"$ADDRESS/get-together/_refresh\"\n\necho\necho \"Done indexing data.\"\necho\n\necho\necho \"Creating Templates.\"\ncurl -s -XPUT \"http://$ADDRESS/_template/logging_index_all\" -d'{\n    \"template\" : \"logstash-09-*\",\n    \"order\" : 1,\n    \"settings\" : {\n        \"number_of_shards\" : 2,\n        \"number_of_replicas\" : 1\n   },\n    \"mappings\" : {\n        \"date\" : { \"store\": false }\n    },\n    \"alias\" : { \"november\" : {} }\n}'\n\necho\ncurl -s -XPUT \"http://$ADDRESS/_template/logging_index\" -d '{\n    \"template\" : \"logstash-*\",\n    \"order\" : 0,\n    \"settings\" : {\n        \"number_of_shards\" : 2,\n        “number_of_replicas” : 1\n   },\n    \"mappings\" : {\n     \"date\" : { \"store\": true }\n    }\n}'\necho\necho \"Done Creating Templates.\"\n\n\necho\necho \"Adding Dynamic Mapping\"\ncurl -s -XDELETE \"http://$ADDRESS/myindex\" \u003e /dev/null\ncurl -s -XPUT \"http://$ADDRESS/myindex\" -d'\n{\n    \"mappings\" : {\n        \"my_type\" : {\n            \"dynamic_templates\" : [{\n                \"UUID\" : {\n                    \"match\" : \"*_guid\",\n                    \"match_mapping_type\" : \"string\",\n                    \"mapping\" : {\n                        \"type\" : \"string\",\n                        \"index\" : \"not_analyzed\"\n                    }\n                }\n            }]\n        }\n    }\n}'\necho\necho \"Done Adding Dynamic Mapping\"\n\necho\necho \"Adding Aliases\"\ncurl -s -XDELETE \"http://$ADDRESS/november_2014_invoices\" \u003e /dev/null\ncurl -s -XDELETE \"http://$ADDRESS/december_2014_invoices\" \u003e /dev/null\ncurl -s -XPOST \"http://$ADDRESS/november_2014_invoices\" -d'{}'\necho\ncurl -s -XPOST \"http://$ADDRESS/december_2014_invoices\" -d'\n{\n    \"mappings\" :\n    {\n        \"invoice\" :\n        {\n            \"properties\" :\n            {\n                \"revenue\" : { \"type\" : \"integer\" }\n            }\n        }\n    }\n}'\n\necho\n\ncurl -s -XPOST \"http://$ADDRESS/_aliases\" -d'\n{\n    \"actions\" : [\n\t{\n\t\t\"add\" :\n\t\t{\n\t\t\t\"index\" : \"november_2014_invoices\",\n\t\t\t\"alias\" : \"2014_invoices\"\n\t\t},\n\t\t\"add\" :\n\t\t{\n\t\t\t\"index\" : \"december_2014_invoices\",\n\t\t\t\"alias\" : \"2014_invoices\"\n\t\t},\n\t\t\"remove\" :\n\t\t{\n\t\t  \"index\" : \"myindex\",\n\t\t  \"alias\" : \"december_2014_invoices\"\n\t\t}\n\t}\n    ]\n}'\necho\necho \"Done Adding Aliases\"\n\necho \"Adding Filter Alias\"\ncurl -s -XPOST \"http://$ADDRESS/_aliases\" -d '\n{\n    \"actions\" : [\n        {\n            \"add\" : {\n                 \"index\" : \"december_2014_invoices\",\n                 \"alias\" : \"bigmoney\",\n                 \"filter\" :\n                 {\n                    \"range\" :\n                    {\n                      \"revenue\" :\n                      {\n                        \"gt\" : 1000\n                      }\n                    }\n                 }\n            }\n        }\n    ]\n}'\necho\necho \"Done Adding Filter Alias\"\n\necho\necho \"Adding Routing Alias\"\ncurl -s -XPOST \"http://$ADDRESS/_aliases\" -d '\n{\n    \"actions\" : [\n        {\n            \"add\" : {\n                 \"index\" : \"december_2014_invoices\",\n                 \"alias\" : \"2014_invoices\",\n                 \"search_routing\" : \"en,es\",\n                 \"index_routing\" : \"en\"\n            }\n        }\n    ]\n}'\necho\necho \"Done Adding Routing Alias\"\n\necho\n```\n","tags":"#elasticsearch"},{"id":"d82ed806ce634c30329fae88427f18f8","title":"Homebrew: Formula Example ","content":"class Kpop \u003c Formula\n  desc \"Mac CLI utility to quickly kill a process that is hogging a port\"\n  version \"0.2\"\n  homepage \"\"\n  url \"https://github.com/tmaslen/kpop/archive/0.2.zip\"\n  sha256 \"1ed1f832baa759f9dfb53dc362fd6b1f2ee21a7e88cd8c75a1d77a204be5cc92\"\n\n  def install\n    system \"./configure\", \"--disable-debug\",\n                          \"--disable-dependency-tracking\",\n                          \"--disable-silent-rules\",\n                          \"--prefix=#{prefix}\"\n    system \"make\", \"install\"\n  end\nend\n","tags":"#homebrew #package"},{"id":"ddaab0ae0ee43b8c7c3e88b8cf6b88cd","title":"[React JS] ","content":"- [Beginners Guide](https://www.sitepoint.com/getting-started-react-beginners-guide/)\n- [JSX](https://www.sitepoint.com/an-introduction-to-jsx/)\n- [Data via Properties and State](https://www.sitepoint.com/working-with-data-in-react-properties-state/)\n- [Manipulating State](https://www.sitepoint.com/work-with-and-manipulate-state-in-react/)\n- [Re-Rendering Performance Concerns](https://www.sitepoint.com/optimizing-react-performance-stateless-components/)\n- [Routing](https://reacttraining.com/react-router/core/guides/philosophy)\n- [Docs: setState](https://reactjs.org/docs/react-component.html#setstate)\n- [Docs: render](https://reactjs.org/docs/react-dom.html#render)\n\n![](https://docs.google.com/drawings/d/e/2PACX-1vSSEEl5c8pkwYNRM8R4K7TVupaGC1bOShhe35Klf25XBXwA-FiydGylSljIUJpEOrhk5UxrMsgBTfS7/pub?w=884\u0026amp;h=778)\n","tags":"#js #javascript #react"},{"id":"979098ebd90a0820456c246c4224f770","title":"[Fastly VCL Boilerplate for handling mutliple subdomains] ","content":"######################################################################################\n#\n# detailed blog post on fastly's implementation details:\n# http://www.integralist.co.uk/posts/fastly-varnish/\n#\n# fastly custom vcl boilerplate:\n# https://docs.fastly.com/vcl/custom-vcl/creating-custom-vcl/#fastlys-vcl-boilerplate\n#\n# vcl_recv\n# vcl_error\n# vcl_hash\n# vcl_pass\n# vcl_miss\n# vcl_hit\n# vcl_fetch\n# vcl_deliver\n#\n######################################################################################\n\ntable deny_list {\n  \"/bad-thing-1\": \"true\",\n  \"/bad-thing-2\": \"true\",\n}\n\nsub set_backend {\n  set req.backend = F_httpbin;\n\n  if (req.http.Host == \"example-stage.acme.com/\") {\n   set req.backend = F_httpbin_stage;\n  }\n}\n\nsub vcl_recv {\n  #FASTLY recv\n\n  call set_backend;\n\n  # configure purges to require api authentication:\n  # https://docs.fastly.com/en/guides/authenticating-api-purge-requests\n  #\n  if (req.method == \"FASTLYPURGE\") {\n      set req.http.Fastly-Purge-Requires-Auth = \"1\";\n  }\n\n  # force HTTP to HTTPS\n  #\n  # related: req.http.Fastly-SSL\n  # https://docs.fastly.com/en/guides/tls-termination\n  #\n  if (req.protocol != \"https\") {\n    error 601 \"Force SSL\";\n  }\n\n  # fastly 'tables' are different to 'edge dictionaries':\n  # https://docs.fastly.com/en/guides/about-edge-dictionaries\n  #\n  if (table.lookup(deny_list, req.url.path)) {\n    error 600 \"Not found\";\n  }\n\n  # don't bother doing a cache lookup for a request type that isn't cacheable\n  if (req.method !~ \"(GET|HEAD|FASTLYPURGE)\") {\n    return(pass);\n  }\n\n  if (req.restarts == 0) {\n    # nagios/monitoring cache bypass\n    #\n    if (req.url ~ \"123\") {\n      set req.http.X-Monitoring = \"true\";\n      return(pass);\n    }\n  }\n\n  return(lookup);\n}\n\nsub vcl_error {\n  #FASTLY error\n\n  # fastly synthetic error responses:\n  # https://docs.fastly.com/en/guides/creating-error-pages-with-custom-responses\n  #\n  if (obj.status == 600) {\n    set obj.status = 404;\n\n    synthetic {\"\n      \u003c!doctype html\u003e\n      \u003chtml\u003e\n        \u003chead\u003e\n          \u003cmeta charset=\"utf-8\"\u003e\n          \u003ctitle\u003eError\u003c/title\u003e\n        \u003c/head\u003e\n        \u003cbody\u003e\n          \u003ch1\u003e404 Not Found (varnish)\u003c/h1\u003e\n        \u003c/body\u003e\n      \u003c/html\u003e\n      \"};\n\n    return(deliver);\n  }\n\n  # fastly HTTP to HTTPS 301 redirect:\n  # https://docs.fastly.com/en/guides/generating-http-redirects-at-the-edge\n  #\n  # example:\n  # curl -sD - http://example.acme.com/\n  # curl -H Fastly-Debug:1 -sLD - -o /dev/null http://example.acme.com/?cachebust=$(uuidgen)\n  #\n  if (obj.status == 601 \u0026\u0026 obj.response == \"Force SSL\") {\n    set obj.status = 301;\n    set obj.response = \"Moved Permanently\";\n    set obj.http.Location = \"https://\" req.http.host req.url;\n    synthetic {\"\"};\n    return (deliver);\n  }\n}\n\nsub vcl_hash {\n  #FASTLY hash\n\n  set req.hash += req.url;\n  set req.hash += req.http.host;\n\n  # call debug_info_hash;\n\n  return(hash);\n}\n\nsub vcl_pass {\n  #FASTLY pass\n}\n\nsub vcl_miss {\n  #FASTLY miss\n\n  return(fetch);\n}\n\nsub vcl_hit {\n  #FASTLY hit\n}\n\nsub vcl_fetch {\n  #FASTLY fetch\n\n  # fastly caching directive:\n  # https://docs.fastly.com/en/guides/cache-control-tutorial\n  #\n  # example:\n  # define stale behaviour if none provided by origin\n  #\n  if (beresp.http.Surrogate-Control !~ \"(stale-while-revalidate|stale-if-error)\") {\n    set beresp.stale_if_error = 31536000s; // 1 year\n    set beresp.stale_while_revalidate = 60s; // 1 minute\n  }\n\n  # fastly stale-if-error:\n  # https://docs.fastly.com/en/guides/serving-stale-content\n  #\n  if (beresp.status \u003e= 500 \u0026\u0026 beresp.status \u003c 600) {\n    if (stale.exists) {\n      return(deliver_stale);\n    }\n  }\n\n  # hit-for-pass:\n  # https://www.integralist.co.uk/posts/fastly-varnish/#hit-for-pass\n  #\n  if (beresp.http.Cache-Control ~ \"private\") {\n    return(pass);\n  }\n  \n  # ensure we set our own default cache TTL if no caching directives found\n  if (beresp.cacheable \u0026\u0026 !beresp.http.Surrogate-Control:max-age \u0026\u0026 !beresp.http.Cache-Control:max-age) {\n    set beresp.ttl = 1h; # 1 hour\n  }\n\n  return(deliver);\n}\n\nsub vcl_deliver {\n  #FASTLY deliver\n\n  # fastly internal state information:\n  # https://docs.fastly.com/en/guides/useful-variables-to-log\n  #\n  set resp.http.Fastly-State = fastly_info.state;\n\n  if (req.http.X-Monitoring == \"true\") {\n    set resp.http.X-Monitoring = req.http.X-Monitoring;\n  }\n\n  return(deliver);\n}\n","tags":"#fastly #vcl #boilerplate"},{"id":"15e50d705424e41e1f4f035dc43fa7fc","title":"[Python Boto Exception Handling] ","content":"\"\"\"\npipenv --python 3.7\npipenv shell\npip install boto3 structlog ipython\n\"\"\"\n\nimport boto3\nfrom botocore.exceptions import ClientError\nsdk_client = boto3.client('cognito-idp', **{'region_name': 'eu-west-1'})\n\nimport logging\nimport structlog\nstructlogger = structlog.getLogger(__name__)\nstructlog.configure(cache_logger_on_first_use=True,\n                    context_class=dict,\n                    logger_factory=structlog.stdlib.LoggerFactory(),\n                    processors=[structlog.stdlib.add_logger_name,\n                                structlog.stdlib.add_log_level,\n                                structlog.processors.TimeStamper(fmt=\"%Y-%m-%d %H:%M.%S\"),\n                                structlog.processors.JSONRenderer(sort_keys=True)])\n\ntry:\n\tsdk_client.global_sign_out(AccessToken=\"123\")\nexcept TypeError as err:  \n\tstructlogger.error('TypeError Caught', \n                       exc_type=err.__class__.__name__, \n                       exc_msg=str(err), \n                       orig_err=err)\n    logging.error(\"Stdlib Logger: TypeError Caught: %s\", err, exc_info=True)\nexcept ClientError as err:\n\tstructlogger.error('ClientError Caught', \n                       exc_type=err.__class__.__name__, \n                       exc_msg=str(err), \n                       orig_err=err)\n    logging.error(\"Stdlib Logger: ClientError Caught: %s\", err, exc_info=True)\nexcept Exception as err:\n\tstructlogger.error('Exception Caught', \n                       exc_type=err.__class__.__name__, \n                       exc_msg=str(err), \n                       orig_err=err)\n    logging.error(\"Stdlib Logger: Exception Caught: %s\", err, exc_info=False)  # hide stack trace\n\n###################################################################################################\n\naws_access_key = '111'\naws_secret_key = '222'\nregion = 'us-east-1'\n\ntry:\n    iam = boto3.client('iam', **{'aws_access_key_id': aws_access_key,\n                                 'aws_secret_access_key': aws_secret_key,\n                                 'region_name': region})\n    user = iam.create_user(UserName='foobar')\n    print(f\"created user! {user}\")\nexcept TypeError as err:\n    structlogger.error('TypeError Caught',\n                       exc_class=type(err),\n                       exc_type=err.__class__.__name__,\n                       exc_msg=str(err),\n                       err_code=err.response['ResponseMetadata']['HTTPStatusCode'] if hasattr(err, 'response') else 500)\n    logging.error(\"Stdlib Logger: TypeError Caught: %s\", err, exc_info=True)\nexcept ClientError as err:\n    structlogger.error('ClientError Caught',\n                       exc_class=type(err),\n                       exc_type=err.__class__.__name__,\n                       exc_msg=str(err),\n                       err_code=err.response['ResponseMetadata']['HTTPStatusCode'] if hasattr(err, 'response') else 500)\n    logging.error(\"Stdlib Logger: ClientError Caught: %s\", err, exc_info=True)\nexcept Exception as err:\n    structlogger.error('Exception Caught',\n                       exc_class=type(err),\n                       exc_type=err.__class__.__name__,\n                       exc_msg=str(err),\n                       err_code=err.response['ResponseMetadata']['HTTPStatusCode'] if hasattr(err, 'response') else 500)\n    logging.error(\"Stdlib Logger: Exception Caught: %s\", err, exc_info=False)  # hide stack trace\n   \n\"\"\"\nlog output...\n\n{\n\t\"err_code\": 403, \n    \"event\": \"Exception Caught\", \n    \"exc_msg\": \"An error occurred (AccessDenied) when calling the CreateUser operation: User: arn:aws:iam::123:user/beep is not authorized to perform: iam:CreateUser on resource: arn:aws:iam::123:user/foobar\", \n    \"exc_class\": \"\u003cclass 'botocore.exceptions.ClientError'\u003e\", \n    \"exc_type\": \"ClientError\", \n    \"level\": \"error\", \n    \"logger\": \"__main__\", \n    \"timestamp\": \"2018-08-31 11:46.23\"\n}\n\nerr.response...\n\n{  \n   \"err_code\":{  \n      \"Error\":{  \n         \"Code\":\"AccessDenied\",\n         \"Message\":\"User: arn:aws:iam::123:user/beep is not authorized to perform: iam:CreateUser on resource: arn:aws:iam::123:user/foobar\",\n         \"Type\":\"Sender\"\n      },\n      \"ResponseMetadata\":{  \n         \"HTTPHeaders\":{  \n            \"content-length\":\"405\",\n            \"content-type\":\"text/xml\",\n            \"date\":\"Fri, 31 Aug 2018 11:30:15 GMT\",\n            \"x-amzn-requestid\":\"456\"\n         },\n         \"HTTPStatusCode\":403,\n         \"RequestId\":\"456\",\n         \"RetryAttempts\":0\n      }\n   },\n   \"err_type\":\"\u003cclass 'botocore.exceptions.ClientError'\u003e\",\n   \"event\":\"ClientError Caught\",\n   \"exc_msg\":\"An error occurred (AccessDenied) when calling the CreateUser operation: User: arn:aws:iam::123:user/beep is not authorized to perform: iam:CreateUser on resource: arn:aws:iam::123:user/foobar\",\n   \"exc_type\":\"ClientError\",\n   \"level\":\"error\",\n   \"logger\":\"__main__\",\n   \"orig_err\":\"ClientError('An error occurred (AccessDenied) when calling the CreateUser operation: User: arn:aws:iam::123:user/beep is not authorized to perform: iam:CreateUser on resource: arn:aws:iam::123:user/foobar')\",\n   \"timestamp\":\"2018-08-31 11:30.16\"\n}\n\nSee also...\n\ntry:\n    # some aws api call\nexcept ClientError as exc:\n    error = exc.response.get('Error', {})\n    error_code = error.get('Code')\n    error_msg = error.get('Message')\n    invalid_refresh_token = re.compile('Invalid Refresh Token')\n\n    if error_code == 'NotAuthorizedException' and invalid_refresh_token.match(error_msg):\n        instr_exc(exc, msg, state='expired', **exc_tags)\n        raise exceptions.CognitoException(msg, code=extract_status_code(exc))\n\n    instr_exc(exc, msg, state='failed', **exc_tags)\n    raise exceptions.CognitoException(msg, code=extract_status_code(exc))\n    \n    \n...and...\n\ndef extract_status_code(exc):\n    \"\"\"If dealing with an AWS SDK response, attempt to extract the status code.\"\"\"\n\n    return exc.response['ResponseMetadata']['HTTPStatusCode'] if hasattr(exc, 'response') else 500\n\"\"\"\n","tags":"#boto #boto3 #python #cognito #aws"},{"id":"a7dda88c5959e3684fc9cd467464813d","title":"[Memorize Days in the Month] ","content":"Use the knuckles on your hand.\n\nEach knuckle = 31\n\nThe space inbetween the knuckles = 30 (except for February, which is 28)\n\n\u003e Don't include the gap between your index and thumb, or the thumb's knuckle\n\n![memorise months](https://user-images.githubusercontent.com/180050/41415593-d785926c-6fe0-11e8-8299-1e54e84a1522.png)\n","tags":"#month #day #calendar"},{"id":"252aa731f5aee6933f4bbc96bdceb921","title":"[Basic `tree` command written in Go] ","content":"package main\n\nimport (\n\t\"fmt\"\n\t\"io/ioutil\"\n\t\"log\"\n\t\"os\"\n\t\"path/filepath\"\n)\n\nfunc main() {\n\targs := []string{\".\"}\n\tif len(os.Args) \u003e 1 {\n\t\targs = os.Args[1:]\n\t}\n\n\tfor _, arg := range args {\n\t\terr := tree(arg, \"\")\n\t\tif err != nil {\n\t\t\tlog.Printf(\"tree %s: %v\\n\", arg, err)\n\t\t}\n\t}\n}\n\nfunc tree(root, indent string) error {\n\tfi, err := os.Stat(root)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"could not stat %s: %v\", root, err)\n\t}\n\n\tfmt.Println(fi.Name())\n\tif !fi.IsDir() {\n\t\treturn nil\n\t}\n\n\tfis, err := ioutil.ReadDir(root)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"could not read dir %s: %v\", root, err)\n\t}\n\n\tvar names []string\n\tfor _, fi := range fis {\n\t\tif fi.Name()[0] != '.' {\n\t\t\tnames = append(names, fi.Name())\n\t\t}\n\t}\n\n\tfor i, name := range names {\n\t\tadd := \"│  \"\n\t\tif i == len(names)-1 {\n\t\t\tfmt.Printf(indent + \"└──\")\n\t\t\tadd = \"   \"\n\t\t} else {\n\t\t\tfmt.Printf(indent + \"├──\")\n\t\t}\n\n\t\tif err := tree(filepath.Join(root, name), indent+add); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\treturn nil\n}\n","tags":"#go #golang #tree"},{"id":"11bf6bfb16a9b5fccef2764f8b4d2b67","title":"[URI Regex] ","content":"Pattern...\n\n```\nhttps?:\\/\\/(?:www\\.)?[\\w\\.]{2,256}\\/?(?:[\\w/]+)?(?:\\?[^#]+)?(?:#.+)?$\n```\n\n\u003e Note: do not use, it's not going to cover all use cases (as matching a uri properly is a complex thing to do).\n\nMatches...\n\n```\nGOOD...\n\nhttp://example.com\nhttps://example.com\n\nhttp://example.com/\nhttps://example.com/\n\n# This might be an issue (as it matches any subdomain currently)...\nhttp://whatever.example.com\nhttps://whatever.example.com\n\nhttp://www.example.com\nhttps://www.example.com\n\nhttp://www.example.com/\nhttps://www.example.com/\n\nhttp://example.com/foo/bar\nhttps://example.com/foo/bar\nhttps://example.com/foo/bar/\n\nhttp://www.example.com/foo/bar\nhttps://www.example.com/foo/bar\nhttps://www.example.com/foo/bar/\n\nhttp://example.com?foo=bar#beepboop\nhttps://example.com?foo=bar#beepboop\n\nhttp://example.com/?foo=bar#beepboop\nhttps://example.com/?foo=bar#beepboop\n\nhttp://www.example.com?foo=bar#beepboop\nhttps://www.example.com?foo=bar#beepboop\n\nhttp://www.example.com/?foo=bar#beepboop\nhttps://www.example.com/?foo=bar#beepboop\n\nhttp://example.com/foo/bar?foo=bar#beepboop\nhttps://example.com/foo/bar?foo=bar#beepboop\nhttps://example.com/foo/bar/?foo=bar#beepboop\n\nhttp://www.example.com/foo/bar?foo=bar#beepboop\nhttps://www.example.com/foo/bar?foo=bar#beepboop\nhttps://www.example.com/foo/bar/?foo=bar#beepboop\n\nhttp://example.com#beepboop\nhttps://example.com#beepboop\n\nhttp://example.com/#beepboop\nhttps://example.com/#beepboop\n\nhttp://www.example.com#beepboop\nhttps://www.example.com#beepboop\n\nhttp://www.example.com/#beepboop\nhttps://www.example.com/#beepboop\n\nhttp://example.com/foo/bar#beepboop\nhttps://example.com/foo/bar#beepboop\nhttps://example.com/foo/bar/#beepboop\n\nhttp://www.example.com/foo/bar#beepboop\nhttps://www.example.com/foo/bar#beepboop\nhttps://www.example.com/foo/bar/#beepboop\n\nBAD...\n\nhttps://example.com:8080\nhttps://example.com:8080/\n\nAnything other than ^^\n```\n","tags":"#regex"},{"id":"faffc17e27185cd8271e942f69a811b2","title":"[Golang Prevent Directory Listing with Static FileServer] ","content":"func noDirListing(h http.Handler) http.HandlerFunc {\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif strings.HasSuffix(r.URL.Path, \"/\") {\n\t\t\thttp.NotFound(w, r)\n\t\t\treturn\n\t\t}\n\t\th.ServeHTTP(w, r)\n\t})\n}\n\nfunc main() {\n\thttp.Handle(\"/\", noDirListing(http.FileServer(http.Dir(\"./static/\"))))\n\tlog.Println(http.ListenAndServe(\":8080\", nil))\n}\n","tags":"#static #fileserver #go #golang"},{"id":"32d2d7a30c1efe14316d28d74a821600","title":"[Simple Math and Notation] ","content":"1.2k = 1.2 * 1000 = 1,200  \n0.15k = 0.15 * 1000 = 150\n\n---\n\nScientific Notation Calculator and Decimal Conversion:\nhttps://www.inchcalculator.com/scientific-notation-calculator/\n\n^^ can help understand a value such as 'E notation' `2.9e-4` (which equates to `0.00029`, i.e. `2.9 * (10/10/10/10)` and the `10/10/10/10` is another way of saying 10 to the _negative_ power of 4 which is called 'logarithm' `10-4`).\n  \n---\n\nNumber Notation (inc. metric prefixes, such as `G` for giga and `M` for mega):  \nhttp://math2.org/math/general/numnotation.htm\n\n- `4G` == `4,000,000,000`\n- `4M` == `4,000,000`\n\nCommas `,` are used to make reading the numbers easier. They _are not_ supposed to represent 'decimal' places. \n\nIf decimals were included then a number such as `4G` would look more like `4,000,000,000.00`.\n\nIf you saw the number `42.68G` then this really means: `42,000,000,000.68` (_NOT_: `42.68000000000`).\n\nIf you saw the number `1.03K`(K stands for kilo, meaning thousand) then this really means: `1,030` (e.g. `1.03*1000`).\n\nBelow is a dashboard that demonstrates this. See the blue line is higher up the y axis which indicates the number is larger, while the red line is a lot lower...\n\n![Example Dashboard Graph](https://user-images.githubusercontent.com/180050/76610382-ba6fe980-6510-11ea-9e3c-522681e4ea1d.png)\n\nIn that image we can also see the 'average' value for the red line is `302.99M` which means `302,000,000.99`. That number is a lot smaller than the average reported for the blue line, which is `42.68G` (as that's `42,000,000,000.68`).\n\n---\n\nPlace Value and Rounding:  \n![](https://sites.google.com/site/amparosmithclassroom/_/rsrc/1447343920075/math-quizes/assigments-2/placevalue.gif)\n","tags":"#math #number #notation #decimal #point #metric #prefix"},{"id":"430fec07b713e2480f718d78550cc32a","title":"[Python timestamp to epoch and back, inc. UTC timezone] ","content":"from datetime import datetime, timedelta, timezone\n\ndatetime(2018,3,30,23,30).timestamp()\n# 1522449000.0\n\ndatetime.fromtimestamp(1522449000).strftime('%c')\n# 'Fri Mar 30 23:30:00 2018'\n\nn = datetime.now()\nt = n - timedelta(minutes=15)\n# datetime.datetime(2019, 10, 15, 11, 11, 6, 149052)\nt.timestamp()\n# 1571134266.149052\n\nutc_timestamp = datetime(2020,6,6,13,00, tzinfo=timezone.utc).timestamp()\n# 1591448400.0\ndatetime.fromtimestamp(utc_timestamp, tz=timezone.utc)\n# datetime.datetime(2020, 6, 6, 13, 0, tzinfo=datetime.timezone.utc)\n","tags":"#python #timezone #timestamp #epoch #utc"},{"id":"7c4cbd811acb2d9719b5288198a1882b","title":"[Tornado AsyncHTTPClient POST form params example] ","content":"# synchronous api\n# response = sg.client.mail.send.post(request_body=data)\n# except urllib.error.HTTPError as exc:\n\n# async implementation\napi_endpoint = 'https://api.sendgrid.com/v3/mail/send'\n\nheaders = {'Authorization': f'Bearer {sendgrid_api_key}',\n           'Content-Type': 'application/json'}\n\njson_data = json.dumps(data)\n\nresponse = await http_client.fetch(api_endpoint,\n                                   raise_error=False,\n                                   method='POST',\n                                   body=json_data,\n                                   headers=headers)\nimport urllib\n\ndef handle_request(http_response):\n  # do something with HTTPResponse object\n\npost_data = { 'data': 'test data' }\nbody = urllib.parse.urlencode(post_data)\n\nhttp_client.fetch(\"http://0.0.0.0:8888\", handle_request, method='POST', headers=None, body=body)\n\n# handle_request callback can be omitted (and in fact is deprecated since Tornado version 5.1)\n\nresponse = await http_client.fetch(\"http://0.0.0.0:8888\", method='POST', headers=None, body=body)\n","tags":"#python #tornado #post #httpclient #asynchttpclient"},{"id":"916c150d64ccafb4bf7ad74650b4a6a9","title":"[Python Type Hinting MyPy] ","content":"You need to generate stubs that are missing, since dependencies such as `boto3` doesn’t provide type hints (as do most packages unfortunately). Mostly we don’t really care about external packages, and type hinting is mostly useful as a documentation tool and can help with autocompletion tools.\n\nSo typically you'll run MyPy with: `--ignore-missing-imports`.\n\n\u003e Note: alternatively specify which modules you want to ignore [like this](https://github.com/python/mypy/issues/3905#issuecomment-421065323).\n\nConsider the following code:\n\n```py\nimport boto3\n\nfrom botocore.client import BaseClient\n\nclient = boto3.client('cognito-idp')\n\ndef foo(client: BaseClient):\n    print('hey')\n\nfoo('ccccc')\n```\n\nMyPy will not see any problems here because we'll either have generated a stub for boto3 or we would be skipping the import altogether.\n\nTo generate the missing stub for boto3:\n\n1. generate stubs: `stubgen --recursive botocore`\n2. `MYPYPATH='./out' mypy your_file.py`\n\n\u003e `./out` is the default directory `stubgen` where `stubgen` puts the stubs\n\nThen executing MyPy will pick up the error:\n\n```\ntest.py:12: error: Argument 1 to \"foo\" has incompatible type \"str\"; expected \"BaseClient\"\n```\nfrom typing import Union\n\nNumber = Union[int, float]\n\ndef add(x: Number = 10, y: Number = 5) -\u003e Number:\n  print(x, y)\n","tags":"#mypy #python #types #hinting"},{"id":"0f46fe9c24015fb0e9a1e51e69e2cb4e","title":"[Refresh OAuth Token] For non-UI apps ","content":"// Manually setup oauth with a separate UI based app\n// Then if you need to refresh your token, read:\n// https://developers.google.com/identity/protocols/OAuth2WebServer#offline\n//\n// The refresh_token is something you get only once you've authenticated\n// Having this means you're already authenticated and so it's ok for a new token to be issued to you\n// Unless the service owner has revoked your token already, then this wouldn't work\n\nform := url.Values{}\nform.Add(\"refresh_token\", settings.GoogleRefreshToken)\nform.Add(\"client_id\", settings.GoogleClientID)\nform.Add(\"client_secret\", settings.GoogleClientSecret)\nform.Add(\"grant_type\", \"refresh_token\")\nparams := strings.NewReader(form.Encode())\n\nreq, err := http.NewRequest(\"POST\", \"https://www.googleapis.com/oauth2/v4/token\", params)\nif err != nil {\n\thttp.Error(w, err.Error(), http.StatusBadRequest)\n}\nreq.Header.Add(\"Content-Type\", \"application/x-www-form-urlencoded\")\n\nclient := \u0026http.Client{}\nresponse, err := client.Do(req)\nif err != nil {\n\thttp.Error(w, err.Error(), http.StatusBadRequest)\n}\n\nresponseBody, err := ioutil.ReadAll(response.Body)\nif err != nil {\n\thttp.Error(w, err.Error(), http.StatusBadRequest)\n}\n\nfmt.Printf(\"responseBody: %+v\\n\", string(responseBody)) // JSON reponse with your new token\n","tags":"#golang #oauth"},{"id":"993863467f978c9a42ef787a56bafcee","title":"[Perl Regex Bash Example] ","content":"\u003e\u003e cat /etc/hosts | perl -ne 'print $_ if m/(dev\\..*)/;'\n\n10.51.50.10 spicerack-api.dev.rig.dev\n10.51.50.10 bpager.dev.rig.dev\n10.51.50.10 feedpager.dev.rig.dev\n10.51.50.10 site_admin.dev.rig.dev\n10.51.50.13 hogwarts-dev.buzzfeed.com\n10.51.50.12 socialmc-dev.buzzfeed.com\n10.16.39.6 honeybear-dev.buzzfeed.com hive-api-dev.buzzfeed.com hive-docs-dev.buzzfeed.com hive-flower-dev.buzzfeed.com\n127.0.0.1 dev.buzzfed.com dev.buzzfeed.com dev.terminal.buzzfeed.com dev.www.buzzfed.com dev.www.buzzfeed.com\n\n# or if you want to print only matched part use `$1`,`$2`, etc instead of `$_`\n# see also: http://www.rexegg.com/regex-perl-one-liners.html\n","tags":"#perl #regex #pcre"},{"id":"2f03b8b13d8c0b5515bfd32ba15a2864","title":"VirtualBox: Kali Linux Linux Headers","content":"sudo apt-get update\nsudo apt-get install linux-headers-$(uname -r)\n\n# if any errors then open /etc/apt/sources.list and add the following\n\ndeb http://http.kali.org/ /kali main contrib non-free\ndeb http://http.kali.org/ /wheezy main contrib non-free\ndeb http://http.kali.org/kali kali-dev main contrib non-free\ndeb http://http.kali.org/kali kali-dev main/debian-installer\ndeb-src http://http.kali.org/kali kali-dev main contrib non-free\ndeb http://http.kali.org/kali kali main contrib non-free\ndeb http://http.kali.org/kali kali main/debian-installer\ndeb-src http://http.kali.org/kali kali main contrib non-free\ndeb http://security.kali.org/kali-security kali/updates main contrib non-free\ndeb-src http://security.kali.org/kali-security kali/updates main contrib non-free\ndeb http://repo.kali.org/kali kali-bleeding-edge main\n\n# then run the first two commands again\n","tags":""},{"id":"e4b4e53dd09745b645e10e89fc133f63","title":"[Vegeta + pdsh wrapper for distributed load testing] ","content":"#!/usr/bin/env python\n\n\"\"\"Usage example:\n./distributed-load-test.py 'GET https://foo.stage.example.com/beep/boop' -r 70 -d 30s -H newsiege01 newsiege02\n\"\"\"\n\nimport argparse\nimport sys\n\nfrom typing import List\nfrom subprocess import run, Popen, PIPE\n\n\ndef parse_args():\n    p = argparse.ArgumentParser(description='Distributed testing with vegeta and pdash')\n    p.add_argument('target', help='vegeta targer, e.g. \"GET https://httpbin.org/get\"')\n    p.add_argument('-H', '--hosts', action='store', type=str, nargs='*',\n                   default=['newsiege01', 'newsiege02', 'newsiege03'], help='host list')\n    p.add_argument('-r', '--rate', type=int, required=True,\n                   help='Request rate, going to be devided evenly across hosts')\n    p.add_argument('-d', '--duration', type=str, required=True,\n                   help='Load test duration')\n    p.add_argument('-e', '--executable', type=str, default='/usr/local/bin/vegeta',\n                   help='Vegeta executable')\n    p.add_argument('-o', '--output', default='stdout', type=str,\n                   help='Output file')\n    p.add_argument('-R', '--reporter', default='text', type=str,\n                   help='Reporter [text, json, plot, hist[buckets]]')\n    return p.parse_args()\n\n\ndef main(target: str, hosts: List[str], rate: int, duration: str, vegeta: str,\n         output: str, reporter: str):\n    cmd = f\"pdsh -b -w '{','.join(hosts)}' 'echo \\\"{target}\\\" | vegeta attack -rate={int(rate/len(hosts))} -duration={duration} \u003e result.bin'\"\n    pdsh = run(cmd, shell=True, stdout=PIPE, stderr=PIPE)\n    if pdsh.returncode \u003e 0:\n        sys.stderr.write('pdsh failed:')\n        sys.stderr.write(pdsh.stderr)\n        sys.exit(pdsh.returncode)\n    scps = []\n    for host in hosts:\n        scps.append(Popen(['scp', f'{host}:~/result.bin', f'{host}.bin'], stdout=PIPE, stderr=PIPE))\n    [scp.communicate() for scp in scps]\n    inputs = ','.join((f'{host}.bin' for host in hosts))\n    run(f'{vegeta} report -inputs=\"{inputs}\" -output={output} -reporter={reporter}', shell=True)\n\n\nif __name__ == '__main__':\n    args = parse_args()\n    main(args.target, args.hosts, args.rate, args.duration, args.executable, args.output, args.reporter)\n","tags":"#distributed #loadtest #performance #vegeta #golang #python"},{"id":"dbbc25b6f851670f5f03585a75d784ce","title":"[Base64 JS Object] Allow for passing complex object to an iframe via Query String ","content":"var s = window.btoa(JSON.stringify({'id': 1234}));\n// \"eyJpZCI6MTIzNH0=\"\n\nvar o = JSON.parse(window.atob(s));\n// {id: 1234}\n\no.id\n// 1234\n","tags":"#js #pickle #base64"},{"id":"958e5ae15640100fa1752f6112184601","title":"[Go defer cleanup exit pattern] ","content":"\u003e Taken from Go Programming Blueprints (second edition)\n\n```go\npackage main \n\nimport ( \n  \"flag\" \n  \"fmt\" \n  \"os\" \n) \nvar fatalErr error \nfunc fatal(e error) { \n  fmt.Println(e) \n  flag.PrintDefaults() \n  fatalErr = e \n} \nfunc main() { \n  defer func() { \n    if fatalErr != nil { \n      os.Exit(1) \n    } \n  }() \n} \n```\n\nNormally when we encounter an error in our code, we use a call such as log.Fatal or os.Exit, which immediately terminates the program. Exiting the program with a nonzero exit code is important because it is our way of telling the operating system that something went wrong, and we didn't complete our task successfully. The problem with the normal approach is that any deferred functions we have scheduled (and therefore any teardown code we need to run) won't get a chance to execute.\n\nThe pattern employed in the preceding code snippet lets us call the fatal function to record that an error has occurred. Note that only when our main function exits will the deferred function run, which in turn calls os.Exit(1) to exit the program with an exit code of 1. Because the deferred statements are run in LIFO (last in, first out) order, the first function we defer will be the last function to be executed, which is why the first thing we do in the main function is defer the exiting code. This allows us to be sure that other functions we defer will be called before the program exits. We'll use this feature to ensure that our database connection gets closed regardless of any errors.\n","tags":"#tags: go, golang, pattern, cleanup"},{"id":"05247b9a12bad8a93c84c74e4784b8a7","title":"[Python regex replace with capture group] ","content":"html = '\u003ciframe src=\"http://www.foo.com/?video_id=1234\" allowfullscreen\u003e'\n\nre.sub('src=\"([^\"]+)', lambda o: 'src=\"{}\u0026platform=mobile_app'.format(o.groups(0)[0]), html)\n# '\u003ciframe src=\"http://www.foo.com/?video_id=1234\u0026platform=mobile_app\" allowfullscreen\u003e'\n\n# Alternative that uses f string formatting\nre.sub('src=\"([^\"]+)', lambda o: f'src=\"{o.groups(0)[0]}\u0026platform=mobile_app', html)\n","tags":"#python #regex #replace #substring"},{"id":"772c7a32b313930dbb4493253d80e893","title":"[Large Number of JavaScript Cookies] ","content":"function setCookie(cname, cvalue, exdays) {\n    var d = new Date();\n    d.setTime(d.getTime() + (exdays*24*60*60*1000));\n    var expires = \"expires=\"+ d.toUTCString();\n    document.cookie = cname + \"=\" + cvalue + \";\" + expires + \";path=/\";\n}\n\n// Generate large number of cookies\nfor (var i = 0; i \u003c= 100; i++) {\n    // Each with large amount of data\n    setCookie(`test_cookie_${i}`, \"THIS IS SOME TEST DATA \".repeat(50), 1);\n}\n","tags":"#cookie #js"},{"id":"0c3f6434d4b953a603d3d54b613f5572","title":"[Python method signature syntax] Along with functools.partial interaction ","content":"from functools import partial\n\ndef foo(bar, *args, beep=False, **kwargs):\n    print(bar)\n    print(args)\n    print(beep)\n    print(kwargs)\n\np = partial(foo, 'bar equals this')\np()\n# bar equals this\n# ()\n# False\n# {}\n\np = partial(foo, 'bar equals this', boop=123)\np()\n# bar equals this\n# ()\n# False\n# {'boop': 123}\n\np = partial(foo, 'bar equals this', 'some', 'stuff', boop=123)\np()\n# bar equals this\n# ('some', 'stuff')\n# False\n# {'boop': 123}\ndef foo(bar, *args, beep=False, **kwargs):\n    print(bar)\n    print(args)\n    print(beep)\n    print(kwargs)\n    \nfoo('b')\n# b\n# ()\n# False\n# {}\n\nfoo('b', 'c')\n# b\n# ('c',)\n# False\n# {}\n\nfoo('b', 'c', beep=True)\n# b\n# ('c',)\n# True\n# {}\n\nfoo('b', 'c', beep=True, boop=123)\n# b\n# ('c',)\n# True\n# {'boop': 123}\n","tags":"#tags: python, args, kwargs, partial"},{"id":"f94955d51daabd4fe874c8d6491924ec","title":"[Git Search logs via Grep] ","content":"git log --grep=\u003cpattern\u003e --grep=\u003cpattern\u003e -i --all-match\n\n# man git-log\n# -i means use a case insensitive search\n# --all-match means log message needs all provided patterns to match\n","tags":"#git #grep #search"},{"id":"fb8782908abe5fcd47f4ef8e39d2f56d","title":"[Bash Show All Builtin Commands.sh] ","content":"# see also http://tldp.org/LDP/abs/html/internal.html\n# for information on builtins vs external commands\n# such as bash's echo command vs /bin/echo †\n#\n# † functionally equivalent but not the same (bash reimplements that external command)\n\nenable -a  # show all shell builtin commands\n\nenable .\nenable :\nenable [\nenable alias\nenable bg\nenable bind\nenable break\nenable builtin\nenable caller\nenable cd\nenable command\nenable compgen\nenable complete\nenable compopt\nenable continue\nenable declare\nenable dirs\nenable disown\nenable echo\nenable enable\nenable eval\nenable exec\nenable exit\nenable export\nenable false\nenable fc\nenable fg\nenable getopts\nenable hash\nenable help\nenable history\nenable jobs\nenable kill\nenable let\nenable local\nenable logout\nenable mapfile\nenable popd\nenable printf\nenable pushd\nenable pwd\nenable read\nenable readarray\nenable readonly\nenable return\nenable set\nenable shift\nenable shopt\nenable source\nenable suspend\nenable test\nenable times\nenable trap\nenable true\nenable type\nenable typeset\nenable ulimit\nenable umask\nenable unalias\nenable unset\nenable wait\n","tags":"#bash #shell"},{"id":"f03ade30c36887b9de68dd4635ae981c","title":"[Bash basic syntax checker] ","content":"bash -n ./foo.sh  # read commands but do not execute them\n\nhelp set | less  # check docs for this feature\n","tags":"#bash #shell"},{"id":"4ca9ff94ea82b0e407f540540f1d8c6c","title":"[Calculate Aspect Ratio] ","content":"def calculate_aspect(width: int, height: int) -\u003e str:\n    def gcd(a, b):\n        \"\"\"The GCD (greatest common divisor) is the highest number that evenly divides both width and height.\"\"\"\n        return a if b == 0 else gcd(b, a % b)\n\n    r = gcd(width, height)\n    x = int(width / r)\n    y = int(height / r)\n\n    return f\"{x}:{y}\"\n    \ncalculate_aspect(1920, 1080) # '16:9'\n","tags":"#aspect #ratio #python"},{"id":"3c64fc7b72039be9770db8a6eed346b4","title":"[Python Garbage Collection Circular References] ","content":"import gc\n\ngc.set_debug(gc.DEBUG_SAVEALL)  # gc.collect saves to gc.garbage instead of deleting.\n\nclass A(object):\n    ref = None\n\na = A()\na.ref = a  # circular reference created\ndel a  # only __main__ reference is deleted\n\ngc.collect()\n# \u003e\u003e\u003e 2 - 2 references were collected\n\ngc.garbage\n# \u003e\u003e\u003e [\u003c__main__.A object at 0x29ce750\u003e, {'ref': \u003c__main__.A object at 0x29ce750\u003e}]\n","tags":"#python #gc #memory"},{"id":"22ced4b4700df1e6cbec88c1074c8b2d","title":"[Golang Memory Allocation] ","content":"## Links\n\n- https://segment.com/blog/allocation-efficiency-in-high-performance-go-services/\n- https://medium.com/a-journey-with-go/go-memory-management-and-allocation-a7396d430f44\n- https://fosdem.org/2025/schedule/event/fosdem-2025-5343-go-ing-easy-on-memory-writing-gc-friendly-code/\n- https://tip.golang.org/doc/gc-guide (has some nice ui tools for visualising GC)\n\n## Summary\n\n\u003e [!TIP]\n\u003e - Returning a pointer (or a value containing a pointer, e.g. slice) will escape to the heap.\n\u003e - `any`/`interface{}` and generics all escape to heap.\n\u003e - Some types contain a pointer and you might not realise (e.g. `Time` struct).\n\u003e - Storing non-pointer values in `sync.Pool.Put(t any)` allocates (so send `*T`, e.g. `*[]string`).\n\u003e - \"_Copying is expensive_\" usually is a myth (pointers should represent ownership and mutability).\n\u003e - Pre-allocate maps/slices to avoid unnecessary allocations when a resize occurs.\n\u003e - Use interface types sparingly in hot paths (e.g. method calls will cause the receiver + certain args to escape).\n\u003e - Prefer non-reference types for map keys/values.\n\u003e - Try keeping map keys/values \u003c= 128 bytes.\n\n\u003e [!NOTE]\n\u003e When a function accepts `any`, Go needs to create an interface _value_, and the storage of the underlying value might involve a heap allocation.\n\n## Full Details\n\nHere’s a list of some patterns we’ve found which typically cause variables to escape to the heap:\n\n- **Sending pointers or values containing pointers to channels.** At compile time there’s no way to know which goroutine will receive the data on a channel. Therefore the compiler cannot determine when this data will no longer be referenced.\n- **Storing pointers or values containing pointers in a slice.** An example of this is a type like `[]*string`. This always causes the contents of the slice to escape. Even though the backing array of the slice may still be on the stack, the referenced data escapes to the heap.\n- **Backing arrays of slices that get reallocated because an append would exceed their capacity.** In cases where the initial size of a slice is known at compile time, it will begin its allocation on the stack. If this slice’s underlying storage must be expanded based on data only known at runtime, it will be allocated on the heap.\n- **Calling methods on an interface type.** Method calls on interface types are a dynamic dispatch — the actual concrete implementation to use is only determinable at runtime. Consider a variable r with an interface type of `io.Reader`. A call to `r.Read(b)` will cause both the value of `r` and the backing array of the byte slice `b` to escape and therefore be allocated on the heap. So use interface types _sparingly_ in hot paths.\n\nThe rule of thumb is: **pointers point to data allocated on the heap.**  \nErgo, reducing the number of pointers in a program reduces the number of heap allocations.  \n**Pointers should primarily be used to reflect ownership semantics and mutability.**\n\n\u003e Note: an extra bonus of 'passing by value' is the increased safety of eliminating `nil`.\n\nCopying a value is much less expensive than the overhead of using a pointer:\n\n- **The compiler generates checks when dereferencing a pointer.** The purpose is to avoid memory corruption by running panic() if the pointer is nil. This is extra code that must be executed at runtime. When data is passed by value, it cannot be nil.\n- **Pointers often have poor locality of reference.** All of the values used within a function are collocated in memory on the stack. [Locality of reference](https://en.wikipedia.org/wiki/Locality_of_reference) is an important aspect of efficient code. It dramatically increases the chance that a value is warm in CPU caches and reduces the risk of a miss penalty during [prefetching](https://en.wikipedia.org/wiki/Cache_prefetching).\n- **Copying objects within a cache line is roughly equivalent to copying a single pointer.** CPUs move memory between caching layers and main memory on cache lines of constant size. On x86 this is 64 bytes. Further, Go uses a technique called [Duff’s device](https://luciotato.svbtle.com/golangs-duffs-devices) to make common memory operations like copies very efficient.\n\nReducing the number of pointers in a program can yield another helpful result: **the garbage collector will skip regions of memory that it can prove will contain no pointers.** For example, regions of the heap which back slices of type `[]byte` aren’t scanned at all. This also holds true for arrays of struct types that don’t contain any fields with pointer types.\n\nNot only does reducing pointers result in less work for the garbage collector, it produces more cache-friendly code. Reading memory moves data from main memory into the CPU caches. Caches are finite, so some other piece of data must be evicted to make room. Evicted data may still be relevant to other portions of the program. \n\n## Golang Memory Analysis\n\nTo see optimisations the go compiler has applied to your code when running it, you can use the `-gcflags` flag:\n\n```bash\ngo run -gcflags=\"-m\" ./main.go\n```\n\nTo find out more about this flag we have to understand where it actually lives (because if you try to look for the flag and the possible values it can accept, then you'll be surprised to discover no information about it when running `go help run`).\n\nTo start, let's consider the `go run` subcommand. This will trigger a build, and that's where the `-gcflags` is exposed.\n\n```bash\ngo help build\n\n  -gcflags '[pattern=]arg list'                \n    arguments to pass on each go tool compile invocation.\n```\n\nIt tells us that the `go tool compile` subcommand is what the flag values are passed on to, so we should look there for the relevant values, of which we'll find (amongst many other flags) `-m` which is used for printing out any optimisations the go compiler has applied to the code (such as, when data escapes to the heap):\n\n```bash\ngo tool compile -help\n\n  -m    print optimization decisions \n```\n\n## Optimising Struct Fields\n\nModern CPU hardware performs reads and writes to memory most efficiently when the data is [naturally aligned](https://en.wikipedia.org/wiki/Data_structure_alignment). CPU reads data in word-size instead of byte-size. A word in a 64-bit system is 8 bytes, while a word in a 32-bit system is 4 bytes. In short, CPU reads address in the multiple of its word size.\n\nThe side-effect of this is that the compiler will sometimes add 'padding' to the memory reservation to help keep things nice and even. Padding is the key to achieving data alignment, but that means a certain order of struct fields can yield extra/unncessary memory reservation, as demonstrated in the following example program (for visual aids see: https://wagslane.dev/posts/go-struct-ordering/ and https://betterprogramming.pub/how-to-speed-up-your-struct-in-golang-76b846209587):\n\n```go\npackage main\n\nimport (\n\t\"unsafe\"\n)\n\ntype T1 struct {\n\ta int8\n\tb int64\n\tc int16\n}\n\ntype T2 struct {\n\ta int8\n\tc int16\n\tb int64\n}\n\nfunc main() {\n    println(unsafe.Sizeof(T1{})) // 24 (more memory reserved)\n\tprintln(unsafe.Sizeof(T2{})) // 16\n}\n```\n\nImagine using a 64-bit system and fetching the `b` variable. The CPU would take _two_ cycles to access the data instead of one. The first cycle will fetch memory 0 to 7 and the subsequent cycle will fetch the rest. Think of it as a notebook: each page can only store word-size data, in this case, 8 bytes. If the `b` data is scattered across two pages, it takes two page flips to retrieve the complete data.\n\nAnother way to verify this is to first know the amount of bytes each type _should_ consume and then check the offsets.\n\nHere's an example program to validate this approach:\n\n```go\npackage main\n\nimport (\n\t\"fmt\"\n\t\"reflect\"\n\t\"runtime\"\n)\n\n// Should be 4 bytes total but is actually 6!\n//\n// Notice the offsets aren't correct!\n// Foo only takes up 1 byte (8 bits) and so Bar, which takes\n// up 2 bytes (16 bits), should actually be at offset 1. \n// The fact it's offset 2 means a whole byte was reserved for\n// Foo when it only needed 1 byte.\ntype stats struct {\n\tFoo uint8  // should take up 1 byte (offset: 0)\n\tBar uint16 // should take up 2 byte (offset: 2)\n\tBaz uint8  // should take up 1 byte (offset: 4)\n}\n\nfunc main() {\n\ttyp := reflect.TypeOf(stats{})\n\tfmt.Printf(\"Struct is %d bytes long\\n\", typ.Size())\n\tn := typ.NumField()\n\tfor i := 0; i \u003c n; i++ {\n\t\tfield := typ.Field(i)\n\t\tfmt.Printf(\"%s at offset %v, size=%d, align=%d\\n\",\n\t\t\tfield.Name, field.Offset, field.Type.Size(),\n\t\t\tfield.Type.Align())\n\t}\n\n\tallStats := []stats{}\n\tfor i := 0; i \u003c 100000000; i++ {\n\t\tallStats = append(allStats, stats{})\n\t}\n\n\tprintMemUsage()\n}\n\nfunc printMemUsage() {\n\tvar m runtime.MemStats\n\truntime.ReadMemStats(\u0026m)\n\tfmt.Printf(\"Alloc = %v MiB\", bToMb(m.Alloc))\n\tfmt.Printf(\"\\tTotalAlloc = %v MiB\", bToMb(m.TotalAlloc))\n\tfmt.Printf(\"\\tSys = %v MiB\", bToMb(m.Sys))\n\tfmt.Printf(\"\\tNumGC = %v\\n\", m.NumGC)\n}\n\nfunc bToMb(b uint64) uint64 {\n\treturn b / 1024 / 1024\n}\n```\n\nThe output of this program is:\n\n```\nStruct is 6 bytes long\nFoo at offset 0, size=1, align=1\nBar at offset 2, size=2, align=2\nBaz at offset 4, size=1, align=1\n```\n\nWe can see although the struct should really only take up four bytes, it actually takes up six because the `uint8` types are getting double the amount of bytes reserved (two instead of one).\n\nIf we change the struct such that the `uint16` isn’t defined between the `uint8`s and check the offsets again, then we'll get the following output:\n\n```\nStruct is 4 bytes long\nBar at offset 0, size=2, align=2\nFoo at offset 2, size=1, align=1\nBaz at offset 3, size=1, align=1\n```\n\nNotice that the offsets are what we would expect, offset zero for Bar, then Foo is offset straight after it at 2 and only 1 byte is reserved so Baz is offset straight after it at 3.\n\nAlso notice that because of this the total struct size is now smaller.\npackage main\n\nimport \"fmt\"\n\nfunc main() {\n        x := 42\n        fmt.Println(x)\n}\n$ go build -gcflags '-m' ./main.go\n\n./main.go:7: x escapes to heap\n./main.go:7: main ... argument does not escape\n\n$ go build -gcflags '-m -m' ./main.go # extra -m's to increase verbosity (alternatively use \"-m=N\")\n\n./main.go:5: cannot inline main: non-leaf function\n./main.go:7: x escapes to heap\n./main.go:7:         from ... argument (arg to ...) at ./main.go:7\n./main.go:7:         from *(... argument) (indirection) at ./main.go:7\n./main.go:7:         from ... argument (passed to call[argument content escapes]) at ./main.go:7\n./main.go:7: main ... argument does not escape\n\n# This ^^ shows that x escapes because it is passed to a function argument which escapes itself (I take this to mean it's because it accepts the argument type as interface{} and so at runtime the type has to be determined).\n","tags":"#go #golang #memory #allocation"},{"id":"82539776c218e590d64126d58edc5e38","title":"[Bash Date Formatting] ","content":"# when using UTC timezone, always add 1 hour to the intended hour\n# so if you want 1hr in the future UTC, then use +2H\n# you'll notice this when you switch between BST (no -u flag) and UTC\n\n# macOS (standard: posix install)\n#\n# -u:  utc timezone\n# -v:  adjust current datetime\n# +%s: convert output to seconds since epoch\ndate -u -v +1H +%s\n\n# macOS (gnu coreutils installed)\n#\n# -u:  utc timezone\n# -d:  adjust specified datetime\n# +%s: convert output to seconds since epoch\ngdate -u -d \"today 1 hour\" +%s\n\n# linux (standard: gnu coreutils)\n# \n# automatically defaults to utc timezone\n#\n# -d:  adjust specified datetime\n# +%s: convert output to seconds since epoch\ndate -d \"today 1 hour\" +%s\n\n# You can go the reverse direction (timestamp -\u003e date)\ndate -d @1267619929 # Wed Mar  3 12:38:49 UTC 2010\ngdate -d @1267619929 -u # UTC flag required for macOS gnu coreutils version\ndate -r 1267619929 -u # macOS standard posix install\n","tags":"#bash #date #gnu #posix"},{"id":"70e455bb56bd5d780c7b01704fc368ed","title":"[AWS CloudFront Signed-Cookie Access] ","content":"{\n   \"Statement\":[\n      {\n         \"Resource\":\"https://your.domain.com/*\",\n         \"Condition\":{\n            \"DateLessThan\":{\n               \"AWS:EpochTime\": 1504357200 // some future timestamp\n            }\n         }\n      }\n   ]\n}\nrequire \"base64\"\nrequire \"json\"\nrequire \"openssl\"\n\ndef cookie_data(resource, expiry)\n  raw_policy = policy(resource, expiry)\n\n  {\n    \"CloudFront-Policy\" =\u003e safe_base64(raw_policy),\n    \"CloudFront-Signature\" =\u003e sign(raw_policy),\n    \"CloudFront-Key-Pair-Id\" =\u003e ENV[\"CLOUDFRONT_KEY_PAIR_ID\"]\n  }\nend\n\ndef policy(url, expiry)\n  {\n     \"Statement\"=\u003e [\n        {\n           \"Resource\" =\u003e url,\n           \"Condition\"=\u003e{\n              \"DateLessThan\" =\u003e{\"AWS:EpochTime\"=\u003e expiry.utc.to_i}\n           }\n        }\n     ]\n  }.to_json.gsub(/\\s+/,'')\nend\n\ndef safe_base64(data)\n  # equivalent to:\n  # cat policy.json | tr -d \" \\t\\n\\r\" | base64 | tr '+=/' '-_~'\n  # remove all linebreaks/whitespace, base64 encode, strip invalid characters\n\n  Base64.strict_encode64(data).tr(\"+=/\", \"-_~\")\nend\n\ndef sign(data)\n  # equivalent to:\n  # cat policy.json | openssl sha1 -sign ./pk-APKAIT3GGGOSP434T2JQ.pem | base64 | tr '+=/' '-_~'\n\n  digest = OpenSSL::Digest::SHA1.new\n  key    = OpenSSL::PKey::RSA.new File.read(ENV[\"CLOUDFRONT_PRIVATE_KEY\"])\n  result = key.sign digest, data\n  safe_base64(result)\nend\n\nprintf \"curl -v -o /dev/null \"\ncookie_data(\"https://your.domain.com/*\", Time.now + (60*60)).each do |k,v|\n  # printf \"Set-Cookie: Domain=domain.com; Path=/; Secure; HttpOnly; %s=%s\\n\\n\", k, v\n  printf \"-H 'Cookie: %s=%s' \", k, v\nend\n\n# execute with:\n# eval $(ruby signed-cookies.rb) https://your.domain.com/robots.txt\n#!/usr/bin/env bash\n#\n# chmod +x ./planz.sh\n#\n# For usage try:\n# \t./planz.sh -h\n# \t./planz.sh help\n\nfile=/tmp/planz_credentials\n\nfunction generate_policy_template {\n  # \u003c\u003c- is different from \u003c\u003c in that you can indent the contents\n  # but you can only indent using tabs (not spaces)\n\tcat \u003e policy.json \u003c\u003c-EOF\n\t{\n\t\t\"Statement\":[\n\t\t\t{\n\t\t\t\t\"Resource\":\"https://plan-z.buzzfeed.com/*\",\n\t\t\t\t\"Condition\":{\n\t\t\t\t\t\"DateLessThan\":{\n\t\t\t\t\t\t\"AWS:EpochTime\": {{date}}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t]\n\t}\n\tEOF\n}\n\nfunction init {\n  local cookie_ttl_hours=\"+${1:-2}H\" # default to two hours cookie ttl\n\n  local CLOUDFRONT_PRIVATE_KEY_CONTAINER=./cloudfront-keypair.tgz.asc\n  local CLOUDFRONT_PRIVATE_KEY_ID=APKAIT3GGGOSP434T2JQ\n  local CLOUDFRONT_PRIVATE_KEY=\"pk-$CLOUDFRONT_PRIVATE_KEY_ID.pem\"\n\n  if [ ! -f \"$CLOUDFRONT_PRIVATE_KEY_CONTAINER\" ]; then\n    echo \"You need the AWS CloudFront keypair file: $CLOUDFRONT_PRIVATE_KEY_CONTAINER\"\n    exit 1\n  fi\n\n  rm \"$file\" 2\u003e/dev/null\n  rm policy.json 2\u003e/dev/null\n  rm policy.json.backup 2\u003e/dev/null\n\n  generate_policy_template\n\n  sed -i \".backup\" \"s/{{date}}/$(date -u -v \"$cookie_ttl_hours\" +%s)/\" policy.json\n  \n  # Linux version\n  # sed -i \".backup\" \"s/{{date}}/$(date -d \"today 1 hour\" +%s)/\" policy.json\n\n  if [ ! -f \"./$CLOUDFRONT_PRIVATE_KEY\" ]; then\n    gpg -d \"$CLOUDFRONT_PRIVATE_KEY_CONTAINER\" | tar -zxv -C ./ --strip-components=3\n  fi\n\n  # shellcheck disable=SC2155,SC2002\n  export POLICY=$(cat policy.json | tr -d \" \\t\\n\\r\" | base64 | tr '+=/' '-_~')\n\n  # shellcheck disable=SC2155,SC2002\n  export SIGNATURE=$(cat policy.json | tr -d \" \\t\\n\\r\" | openssl sha1 -sign $CLOUDFRONT_PRIVATE_KEY | base64 | tr '+=/' '-_~')\n\n  {\n    echo \"CLOUDFRONT_PRIVATE_KEY=$CLOUDFRONT_PRIVATE_KEY\"\n    echo \"ID=$CLOUDFRONT_PRIVATE_KEY_ID\"\n    echo \"POLICY=$POLICY\"\n    echo \"SIGNATURE=$SIGNATURE\"\n  } \u003e\u003e \"$file\"\n\n  cat \"$file\"\n}\n\nfunction web {\n  cat \"$file\"\n}\n\nfunction req {\n  local path=$1\n\n  # shellcheck disable=SC2155\n  local id=$(web | awk 'NR == 2 { print $0 }' | cut -d \"=\" -f 2)\n\n  # shellcheck disable=SC2155\n  local policy=$(web | awk 'NR == 3 { print $0 }' | cut -d \"=\" -f 2)\n\n  # shellcheck disable=SC2155\n  local signature=$(web | awk 'NR == 4 { print $0 }' | cut -d \"=\" -f 2)\n\n  curl -v \\\n    -H \"Cookie: CloudFront-Policy=$policy\" \\\n    -H \"Cookie: CloudFront-Signature=$signature\" \\\n    -H \"Cookie: CloudFront-Key-Pair-Id=$id\" \\\n    \"https://plan-z.buzzfeed.com$path\"\n}\n\nif [ \"$1\" == \"clear\" ]; then\n  rm \"$file\"\nfi\n\nif [ \"$1\" == \"init\" ]; then\n  init \"$2\"\nfi\n\nif [ \"$1\" == \"web\" ]; then\n  web\nfi\n\nif [ \"$1\" == \"req\" ]; then\n  req \"$2\"\nfi\n\nif [[ \"$1\" =~ help|-h ]]; then\n  printf \"Usage:\\n\\t./planz.sh clear\\n\\t./planz.sh init [cookie_ttl_hours: 2]\\n\\t./planz.sh web\\n\\t./planz.sh req /robots.txt\\n\\t./planz.sh req /robots.txt 1\u003e/dev/null\\n\"\nfi\nexport CLOUDFRONT_KEY_PAIR_ID=\"APKAIT3GGGOSP434T2JQ\"\nexport CLOUDFRONT_PRIVATE_KEY=\"pk-APKAIT3GGGOSP434T2JQ.pem\"\nexport POLICY=$(cat policy.json | tr -d \" \\t\\n\\r\" | base64 | tr '+=/' '-_~')\nexport SIGNATURE=$(cat policy.json | tr -d \" \\t\\n\\r\" | openssl sha1 -sign $CLOUDFRONT_PRIVATE_KEY | base64 | tr '+=/' '-_~')\n\ncurl -v -o /dev/null \\\n  -H \"Cookie: CloudFront-Policy=$POLICY\" \\\n  -H \"Cookie: CloudFront-Signature=$SIGNATURE\" \\\n  -H \"Cookie: CloudFront-Key-Pair-Id=$CLOUDFRONT_KEY_PAIR_ID\" \\\n  https://plan-z.buzzfeed.com/robots.txt\n","tags":"#aws #cloudfront #cookie #planz"},{"id":"2718a4eb51b00a7a4138fd182566c53b","title":"[Check TLS version using by Python] ","content":"# Python 3.5.2-slim\n\nimport json\nfrom tornado.httpclient import HTTPClient\n\nresponse = HTTPClient().fetch(\"https://www.howsmyssl.com/a/check\").body.decode()\ndata = json.loads(response)\ntls_version = data[\"tls_version\"]\n\nprint(tls_version)\"  # TLS 1.2\n","tags":"#python #tls #ssl"},{"id":"7a13c09791ceba62b9bd70f954552f3f","title":"[Sed Date Insertion] ","content":"# for date command read...\n# https://gist.github.com/Integralist/82539776c218e590d64126d58edc5e38\n\n# linux example (no backup file created)\necho '\"foo\": \"{{date}}\"' \u003e foo.txt\ncat foo.txt | sed \"s/{{date}}/$(date -d \"today 1 hour\" +%s)/\"\nsed -i \"s/{{date}}/$(date -d \"today 1 hour\" +%s)/\" foo.txt\n\n# macOS example (backup file mandatory: requires manual removal)\necho '\"foo\": \"{{date}}\"' \u003e foo.txt\ncat foo.txt | sed \"s/{{date}}/$(date -u -v +1H +%s)/\"\nsed -i \".backup\" \"s/{{date}}/$(date -u -v +1H +%s)/\" foo.txt\n","tags":"#sed #bash #date"},{"id":"8b58308965b9b1839f3c76eb610d43ab","title":"Shell: list, download and extract S3 log files ","content":"#!/usr/bin/env bash\n\n# WARNING: this can exhaust process resources\n# there is no process pool implementation\n\nfunction get_logs {\n  aws s3 ls \"bf-logs-archive/Fastly/$1/\" \u003e ls_results.txt\n}\n\nfunction copy_log {\n  aws s3 cp \"s3://bf-logs-archive/Fastly/$1/$2\" ./logs/ \u0026\n}\n\nfunction process {\n  local dir=$1\n  local logs=$2\n  local file\n\n  while read -r line; do\n    file=$(echo \"$line\" | cut -d ' ' -f 10)\n\n    if [[ $file != \"\" ]]; then\n      copy_log \"$dir\" \"$file\"\n    fi\n  done \u003c \"$logs\"\n\n  wait\n}\n\nfunction decode_gzipped_files {\n  # note: this will replace .gz with the extract log file\n  find ./logs -name '*.gz' -exec gzip -d {} \\;\n}\n\ntime get_logs \"video-player.buzzfeed.com\"\ntime process \"video-player.buzzfeed.com\" \"ls_results.txt\"\ntime decode_gzipped_files\n","tags":"#aws #logs #shell"},{"id":"548e1d149e15003b5c799da2520ed46c","title":"[Hugo build script for User page] ","content":"#!/usr/bin/env bash\n\nfunction contains {\n  local e match=\"$1\"\n  shift\n  for e; do [[ \"$e\" == \"$match\" ]] \u0026\u0026 return 0; done\n  return 1\n}\n\nfunction remove_toplevel {\n  local blacklist=(build.sh CNAME keybase.txt src)\n  local trigger=0\n\n  for i in *; do\n    if contains \"$i\" \"${blacklist[@]}\"; then\n      trigger=1\n      echo \"this is a blacklist file: $i\"\n    else\n      rm -rf \"$i\"\n    fi\n  done\n\n  if [[ $trigger -eq 1 ]]; then\n    printf \"\\n...we won't delete these files.\\n\\n\"\n  fi\n}\n\nfunction build_site {\n  pushd \"./src\" 1\u003e/dev/null\n  hugo\n  cp -r ./public/ ../\n  popd 1\u003e/dev/null\n}\n\nremove_toplevel\nbuild_site\n","tags":"#github #hugo #build"},{"id":"4ad4574f66339ccefa74260bfa39e5f2","title":"[Python Decorator with optional arguments] ","content":"import asyncio\nimport time\n\nfrom functools import wraps\n\ndef dec(ttl=10):\n    print('ttl', ttl)\n\n    def real_dec(fn):\n        if asyncio.iscoroutinefunction(fn):\n            @wraps(fn)\n            async def wrapper(*args, **kwargs):\n                print('fn args kwargs', fn, args, kwargs)\n                await asyncio.sleep(5)\n                print(\"done with wrapper, going to call fn\")\n                return await fn()\n            return wrapper\n        else:\n            @wraps(fn)\n            def wrapper(*args, **kwargs):\n                print('fn args kwargs:', fn, args, kwargs)\n                time.sleep(5)\n                print(\"done with wrapper, going to call fn\")\n                return fn()\n            return wrapper\n\n    return real_dec\n\n@dec(ttl=123)\nasync def foo():\n    return await asyncio.sleep(5, result=\"async function done\")\n\n@dec(ttl=456)\ndef bar():\n    time.sleep(5)\n    return \"sync function done\"\n\nloop = asyncio.get_event_loop()\nresult = loop.run_until_complete(foo('FOO!'))\n\nprint(result)\nprint(bar('BAR!'))\n\n\"\"\"\noutput...\n\nttl 123\nttl 456\n\nfn args kwargs \u003cfunction foo at 0x10cfa4620\u003e ('FOO!',) {}\ndone with wrapper, going to call fn\nasync function done\n\nfn args kwargs: \u003cfunction bar at 0x10cc7b8c8\u003e ('BAR!',) {}\ndone with wrapper, going to call fn\nsync function done\n\"\"\"\n","tags":"#tags: python, decorator"},{"id":"e35cf61b857829bbf340260ac4f46210","title":":w ~/.vim/colors/vim-integralist.vim - doesn't work though with macOS terminal :-( although it could be modified to use terminal equivalent like 'ctermbg=233' but refer to this palette... https://upload.wikimedia.org/wikipedia/en/1/15/Xterm_256color_chart.svg","content":"hi clear\nsyntax reset\nlet g:colors_name = \"vim-integralist\"\nif \u0026background == \"light\"\n    hi Boolean gui=NONE guifg=#707070 guibg=NONE\n    hi ColorColumn gui=NONE guifg=NONE guibg=#f5f5f5\n    hi Comment gui=NONE guifg=#969696 guibg=NONE\n    hi Conceal gui=NONE guifg=#707070 guibg=NONE\n    hi Conditional gui=NONE guifg=#4a4a4a guibg=NONE\n    hi Constant gui=NONE guifg=#707070 guibg=NONE\n    hi Cursor gui=reverse guifg=NONE guibg=NONE\n    hi CursorColumn gui=NONE guifg=NONE guibg=#f5f5f5\n    hi CursorLine gui=NONE guifg=NONE guibg=#f5f5f5\n    hi CursorLineNr gui=NONE guifg=#969696 guibg=NONE\n    hi DiffAdd gui=NONE guifg=NONE guibg=#f0fff0\n    hi DiffChange gui=NONE guifg=NONE guibg=#f5f5f5\n    hi DiffDelete gui=NONE guifg=NONE guibg=#fff0f0\n    hi DiffText gui=NONE guifg=NONE guibg=#e3e3e3\n    hi Directory gui=NONE guifg=#4a4a4a guibg=NONE\n    hi Error gui=NONE guifg=NONE guibg=#fff0f0\n    hi ErrorMsg gui=NONE guifg=NONE guibg=#fff0f0\n    hi FoldColumn gui=NONE guifg=#c2c2c2 guibg=NONE\n    hi Folded gui=NONE guifg=#969696 guibg=NONE\n    hi Ignore gui=NONE guifg=NONE guibg=NONE\n    hi IncSearch gui=NONE guifg=NONE guibg=#e3e3e3\n    hi LineNr gui=NONE guifg=#c2c2c2 guibg=NONE\n    hi MatchParen gui=NONE guifg=NONE guibg=#e3e3e3\n    hi ModeMsg gui=NONE guifg=NONE guibg=NONE\n    hi MoreMsg gui=NONE guifg=NONE guibg=NONE\n    hi NonText gui=NONE guifg=#c2c2c2 guibg=NONE\n    hi Normal gui=NONE guifg=#000000 guibg=#ffffff\n    hi Number gui=NONE guifg=#707070 guibg=NONE\n    hi Pmenu gui=NONE guifg=NONE guibg=#f5f5f5\n    hi PmenuSbar gui=NONE guifg=NONE guibg=#ededed\n    hi PmenuSel gui=NONE guifg=NONE guibg=#e3e3e3\n    hi PmenuThumb gui=NONE guifg=NONE guibg=#dbdbdb\n    hi Question gui=NONE guifg=NONE guibg=NONE\n    hi Search gui=NONE guifg=NONE guibg=#ededed\n    hi SignColumn gui=NONE guifg=#c2c2c2 guibg=NONE\n    hi Special gui=NONE guifg=#707070 guibg=NONE\n    hi SpecialKey gui=NONE guifg=#c2c2c2 guibg=NONE\n    hi SpellBad gui=undercurl guisp=NONE guifg=NONE guibg=#fff0f0\n    hi SpellCap gui=undercurl guisp=NONE guifg=NONE guibg=NONE\n    hi SpellLocal gui=undercurl guisp=NONE guifg=NONE guibg=#f0fff0\n    hi SpellRare gui=undercurl guisp=NONE guifg=NONE guibg=#ededed\n    hi Statement gui=NONE guifg=#4a4a4a guibg=NONE\n    hi StatusLine gui=NONE guifg=#262626 guibg=#ededed\n    hi StatusLineNC gui=NONE guifg=#969696 guibg=#ededed\n    hi StorageClass gui=NONE guifg=#4a4a4a guibg=NONE\n    hi String gui=NONE guifg=#707070 guibg=NONE\n    hi TabLine gui=NONE guifg=#969696 guibg=#ededed\n    hi TabLineFill gui=NONE guifg=NONE guibg=#ededed\n    hi TabLineSel gui=NONE guifg=#262626 guibg=#ededed\n    hi Title gui=NONE guifg=#707070 guibg=NONE\n    hi Todo gui=standout guifg=NONE guibg=NONE\n    hi Type gui=NONE guifg=#4a4a4a guibg=NONE\n    hi Underlined gui=NONE guifg=NONE guibg=NONE\n    hi VertSplit gui=NONE guifg=#e3e3e3 guibg=NONE\n    hi Visual gui=NONE guifg=NONE guibg=#e3e3e3\n    hi VisualNOS gui=NONE guifg=NONE guibg=NONE\n    hi WarningMsg gui=NONE guifg=NONE guibg=#fff0f0\n    hi WildMenu gui=NONE guifg=NONE guibg=#d1d1d1\n    hi lCursor gui=NONE guifg=NONE guibg=NONE\n    hi Identifier gui=NONE guifg=NONE guibg=NONE\n    hi PreProc gui=NONE guifg=NONE guibg=NONE\nelseif \u0026background == \"dark\"\n    hi Boolean gui=NONE guifg=#808080 guibg=NONE\n    hi ColorColumn gui=NONE guifg=NONE guibg=#1a1a1a\n    hi Comment gui=NONE guifg=#707070 guibg=NONE\n    hi Conceal gui=NONE guifg=#808080 guibg=NONE\n    hi Conditional gui=NONE guifg=#999900 guibg=NONE\n    hi Constant gui=NONE guifg=#808080 guibg=NONE\n    hi Cursor gui=reverse guifg=NONE guibg=NONE\n    hi CursorColumn gui=NONE guifg=NONE guibg=#1a1a1a\n    hi CursorLine gui=NONE guifg=NONE guibg=#1a1a1a\n    hi CursorLineNr gui=NONE guifg=#707070 guibg=NONE\n    hi DiffAdd gui=NONE guifg=#ffffff guibg=#006633\n    hi DiffChange gui=NONE guifg=NONE guibg=#1a1a1a\n    hi DiffDelete gui=NONE guifg=#ffffff guibg=#990000\n    hi DiffText gui=reverse guifg=#ffcc00 guibg=#333333\n    hi Directory gui=NONE guifg=#8f8f8f guibg=NONE\n    hi Error gui=NONE guifg=NONE guibg=#260808\n    hi ErrorMsg gui=NONE guifg=#ffffff guibg=#990000\n    hi FoldColumn gui=NONE guifg=#616161 guibg=NONE\n    hi Folded gui=NONE guifg=#707070 guibg=NONE\n    hi Ignore gui=NONE guifg=NONE guibg=NONE\n    hi IncSearch gui=NONE guifg=NONE guibg=#333333\n    hi LineNr gui=NONE guifg=#666666 guibg=NONE\n    hi MatchParen gui=NONE guifg=NONE guibg=#333333\n    hi ModeMsg gui=NONE guifg=#ff0000 guibg=#ffffff\n    hi MoreMsg gui=NONE guifg=NONE guibg=#141414\n    hi NonText gui=NONE guifg=#666666 guibg=NONE\n    hi Normal gui=NONE guifg=#cccccc guibg=#1a1a1a\n    hi Number gui=NONE guifg=#808080 guibg=NONE\n    hi Pmenu gui=NONE guifg=NONE guibg=#1a1a1a\n    hi PmenuSbar gui=NONE guifg=NONE guibg=#262626\n    hi PmenuSel gui=NONE guifg=NONE guibg=#333333\n    hi PmenuThumb gui=NONE guifg=NONE guibg=#424242\n    hi Question gui=NONE guifg=NONE guibg=NONE\n    hi Search gui=NONE guifg=NONE guibg=#262626\n    hi SignColumn gui=NONE guifg=#616161 guibg=NONE\n    hi Special gui=NONE guifg=#af8764 guibg=NONE\n    hi SpecialKey gui=NONE guifg=#616161 guibg=NONE\n    hi SpellBad gui=undercurl guisp=NONE guifg=NONE guibg=#260808\n    hi SpellCap gui=undercurl guisp=NONE guifg=NONE guibg=NONE\n    hi SpellLocal gui=undercurl guisp=NONE guifg=NONE guibg=#082608\n    hi SpellRare gui=undercurl guisp=NONE guifg=NONE guibg=#262626\n    hi Statement gui=NONE guifg=#ffcc00 guibg=NONE\n    hi StatusLine gui=NONE guifg=#ffffff guibg=#262626\n    hi StatusLineNC gui=NONE guifg=#707070 guibg=#262626\n    hi StorageClass gui=NONE guifg=#c27005 guibg=NONE\n    hi String gui=NONE guifg=#e5e7a2 guibg=NONE\n    hi TabLine gui=NONE guifg=#707070 guibg=#333333\n    hi TabLineFill gui=NONE guifg=NONE guibg=#333333\n    hi TabLineSel gui=NONE guifg=#333333 guibg=#ffffcc\n    hi Title gui=NONE guifg=#cccccc guibg=NONE\n    hi Todo gui=standout guifg=NONE guibg=NONE\n    hi Type gui=underline guifg=#8f8f8f guibg=NONE\n    hi Underlined gui=NONE guifg=NONE guibg=NONE\n    hi VertSplit gui=NONE guifg=#333333 guibg=NONE\n    hi Visual gui=NONE guifg=NONE guibg=#333333\n    hi VisualNOS gui=NONE guifg=NONE guibg=NONE\n    hi WarningMsg gui=NONE guifg=#333333 guibg=#cc9900\n    hi WildMenu gui=NONE guifg=#333333 guibg=#ffffbd\n    hi lCursor gui=NONE guifg=NONE guibg=NONE\n    hi Identifier gui=NONE guifg=NONE guibg=NONE\n    hi PreProc gui=NONE guifg=NONE guibg=NONE\nendif\n","tags":""},{"id":"edcfb88c925658a13fc3e51f581fe4bc","title":"[Python URL Validation] ","content":"import re\n\nip_middle_octet = u\"(?:\\.(?:1?\\d{1,2}|2[0-4]\\d|25[0-5]))\"\nip_last_octet = u\"(?:\\.(?:[1-9]\\d?|1\\d\\d|2[0-4]\\d|25[0-4]))\"\n\nregex = re.compile(\n    u\"^\"\n    # protocol identifier\n    u\"(?:(?:https?|ftp)://)\"\n    # user:pass authentication\n    u\"(?:\\S+(?::\\S*)?@)?\"\n    u\"(?:\"\n    u\"(?P\u003cprivate_ip\u003e\"\n    # IP address exclusion\n    # private \u0026 local networks\n    u\"(?:(?:10|127)\" + ip_middle_octet + u\"{2}\" + ip_last_octet + u\")|\"\n    u\"(?:(?:169\\.254|192\\.168)\" + ip_middle_octet + ip_last_octet + u\")|\"\n    u\"(?:172\\.(?:1[6-9]|2\\d|3[0-1])\" + ip_middle_octet + ip_last_octet + u\"))\"\n    u\"|\"\n    # IP address dotted notation octets\n    # excludes loopback network 0.0.0.0\n    # excludes reserved space \u003e= 224.0.0.0\n    # excludes network \u0026 broadcast addresses\n    # (first \u0026 last IP address of each class)\n    u\"(?P\u003cpublic_ip\u003e\"\n    u\"(?:[1-9]\\d?|1\\d\\d|2[01]\\d|22[0-3])\"\n    u\"\" + ip_middle_octet + u\"{2}\"\n    u\"\" + ip_last_octet + u\")\"\n    u\"|\"\n    # host name\n    u\"(?:(?:[a-z\\u00a1-\\uffff0-9]-?)*[a-z\\u00a1-\\uffff0-9]+)\"\n    # domain name\n    u\"(?:\\.(?:[a-z\\u00a1-\\uffff0-9]-?)*[a-z\\u00a1-\\uffff0-9]+)*\"\n    # TLD identifier\n    u\"(?:\\.(?:[a-z\\u00a1-\\uffff]{2,}))\"\n    u\")\"\n    # port number\n    u\"(?::\\d{2,5})?\"\n    # resource path\n    u\"(?:/\\S*)?\"\n    # query string\n    u\"(?:\\?\\S*)?\"\n    u\"$\",\n    re.UNICODE | re.IGNORECASE\n)\n\npattern = re.compile(regex)\n\n\ndef url(value, public=False):\n    \"\"\"\n    Return whether or not given value is a valid URL.\n\n    This validator is based on the wonderful `URL validator of dperini`_.\n\n    .. _URL validator of dperini:\n        https://gist.github.com/dperini/729294\n\n    Examples::\n\n        \u003e\u003e\u003e url('http://foobar.dk')\n        True\n\n        \u003e\u003e\u003e url('http://10.0.0.1')\n        True\n\n        \u003e\u003e\u003e url('http://foobar.d')\n        ValidationFailure(func=url, ...)\n\n        \u003e\u003e\u003e url('http://10.0.0.1', public=True)\n        ValidationFailure(func=url, ...)\n\n    :param value: URL address string to validate\n    :param public: (default=False) Set True to only allow a public IP address\n    \"\"\"\n    result = pattern.match(value)\n    if not public:\n        return result\n\n    return result and not result.groupdict()[\"private_ip\"]\n# ipython repl...\n\n$ url(\"http://10.0.0.1\", public=True)\nFalse\n\n$ url(\"http://beep.com\", public=True)\nTrue  # it's considered a public ip\n\n$ url(\"http://beep.com\")\n\u003c_sre.SRE_Match object; span=(0, 15), match='http://beep.com'\u003e\n\n$ url(\"http://www.google.com?{xxx}\")\n\u003c_sre.SRE_Match object; span=(0, 27), match='http://www.google.com?{xxx}'\u003e\n","tags":"#python #urls #validation"},{"id":"d29b157e104fda2e6589063d2c5c6803","title":"[Requests per hour, per docker container] ","content":"10ToThePowerOf6 = 10^6 # 10*10*10*10*10*10\nrequests_per_hour = 1.5*(10ToThePowerOf6) # 1,500,000 (1.5 million)\nminutes = 60\nseconds = 60\nnum_of_containers = 20\n\n((requests_per_hour) / minutes / seconds) / num_of_containers = 20.8333333333 # ~20 rps per container\n","tags":"#docker #rps #performance"},{"id":"ebc452a46e411cf432b01c7812ddb07f","title":"[Python and Go Structured Logging] ","content":"package main\n\nimport (\n  \"os\"\n\n  log \"github.com/Sirupsen/logrus\"\n)\n\nfunc main() {\n  // Standard stdout ASCII logging\n  log.WithFields(log.Fields{\n    \"animal\": \"walrus\",\n  }).Info(\"A walrus appears\")\n\n  // JSON style structured logging\n  log.SetFormatter(\u0026log.JSONFormatter{})\n  f, e := os.Create(\"logs\")\n  if e != nil {\n    log.Fatal(\"Failed to create log file\")\n  }\n  log.SetOutput(f)\n  log.WithFields(log.Fields{\n    \"animal\": \"walrus\",\n    \"size\":   10,\n  }).Info(\"A group of walrus emerges from the ocean\")\n\n  /*\n  Output...\n\n      {\n        \"animal\": \"walrus\",\n        \"level\": \"info\",\n        \"msg\": \"A group of walrus emerges from the ocean\",\n        \"size\": 10,\n        \"time\": \"2015-12-22T13:58:46Z\"\n      }\n  */\n}\nimport structlog\n\n\ndef rename_event_key(_, __, ed):\n    \"\"\"Datadog prefers the message field to be called 'message' not 'event'.\n    \n    DOCS:\n    \thttps://www.structlog.org/en/stable/processors.html\n    \"\"\"\n\n    ed[\"message\"] = ed.pop(\"event\")\n    return ed\n\n  \nstructlog.configure(\n  processors=[\n    rename_event_key,\n    structlog.processors.JSONRenderer(sort_keys=True),\n  ]\n)\n\nlog = structlog.get_logger()\nlog.info(\"foo\", bar=123, baz={\"a\": 555})\n\n# {\"bar\": 123, \"baz\": {\"a\": 555}, \"message\": \"foo\"}\n# logger.py\n#\n# EXAMPLE USAGE:\n#\n# import logger\n# log = logger.log\n# log.info(...)\n\nimport logging\n\nimport structlog\nfrom bf_rig import settings\n\n\ndef rename_event_key(_, __, ed):\n    \"\"\"Datadog prefers the message field to be called 'message' not 'event'.\"\"\"\n\n    ed[\"message\"] = ed.pop(\"event\")\n    return ed\n\n\ndef new_logger():\n    log_format = \"\"\n    datefmt = \"\"\n\n    if settings.get(\"debug\"):\n        log_format = \"[%(levelname)s %(asctime)s path:%(pathname)s lineno:%(lineno)s] %(message)s\"\n        datefmt = \"%Y/%m/%d %I:%M:%S\"\n\n        if settings.get(\"cluster\") == \"prod\":\n            logging.getLogger(\"nsq\").setLevel(logging.WARNING)\n    else:\n        # keep logs quiet outside of local development\n        logging.getLogger(\"botocore\").setLevel(logging.CRITICAL)\n        logging.getLogger(\"boto3\").setLevel(logging.CRITICAL)\n        logging.getLogger(\"nsq\").setLevel(logging.CRITICAL)\n\n    level = getattr(logging, settings.get(\"log_level\").upper())\n    logging.basicConfig(level=level, format=log_format, datefmt=datefmt)\n\n    structlog.configure(\n        processors=[\n            rename_event_key,\n            structlog.stdlib.add_log_level,\n            structlog.processors.TimeStamper(fmt=\"%Y-%m-%d %H:%M.%S\"),\n            structlog.processors.JSONRenderer(sort_keys=True),\n        ],\n        context_class=dict,\n        cache_logger_on_first_use=True,\n    )\n\n    log = structlog.get_logger()\n\n    return log.bind(\n        rig={\n            \"cluster\": settings.get('cluster'),\n            \"service\": settings.get('service'),\n            \"version\": settings.get('rig_image_version'),\n        },\n        meta={\n            \"deployment_name\": settings.get(\"rig_deployment_name\"),\n            \"deployment_type\": settings.get(\"rig_deployment_type\"),\n        },\n    )\n\n\nlog = new_logger()\n","tags":"#go #golang #python #logging #structured #logrus #structlog"},{"id":"8683880c5a5d0f36802c4a02522710fa","title":"[Bash search find and filter, then execute] ","content":"# the `-type f` is not needed as I'm using the `-name` flag to anchor to Python files\n# but I kept it in for the sake of me needing to remember the flag and how to use it.\n#\n# some files use \"double\" quotes while others use 'single' quotes\n# to catch both variations we have to make sure the pattern is wrapped in double quotes\n# as this allows us to escape the double quotes used in the pattern itself\n# if your pattern was wrapped in single quotes, then the shell will ignore any \\ escaping of a single quote within your pattern\ntime find . -type f -name '*.py' -exec egrep -o \"\\(r?f?['\\\"](\\/[^'\\\"]+)\" {} \\; | sort | uniq -c | sort\n# find all yaml files inside of a 'src' directory but ignore 'settings.yaml'\n# TODO: double check we didn't mean -name instead of -path\n$ find -E ~/Code/fastly/api-documentation -iregex '.+/src/.+\\.yaml$' ! -path '*settings.yaml' -print\n\n# now find all API endpoints defined in those files\n# e.g. I want to find things like '/customer/{customer_id}/users:'\n$ find -E ~/Code/fastly/api-documentation -iregex '.+/src/.+\\.yaml$' -print -exec grep -E '\\s/.+:$' {} \\;\n\n# now normalise the api by replacing the interpolation syntax {} with ...\n# we do this by using gsed's extended regex -E and then starting by finding { and keep going until something that's not an } and then ending match with }\n$ find -E ~/Code/fastly/api-documentation -iregex '.+/src/.+\\.yaml$' -exec grep -E '\\s/.+:$' {} \\; | gsed -E 's/\\{[^}]+\\}/.../g'\n\n# find all files named pipfile or requirement\n$ find -E . -iregex '.+(pipfile|requirements).+'\n\n# print all matching files that include bf_tornado (or bf-tornado) + print the bf_tornado value itself\n# we do the latter by searching lines that match the bf_tornado pattern and then use -B (\"before\") to specify that the output should include one line before\n$ find -E . -iregex '.+(pipfile|requirements).+' -print -exec egrep 'bf[_-]tornado' {} \\; | egrep -B 1 '^bf\\-'\n# find any files that contain the given string (\"nginx\").\n# then we use the grep command's -l, --files-with-matches flag to ensure only file names are printed.\n# we use the ! operator (same as -not flag) to exclude matches.\n# we also have to be careful with files that have spaces in their name, so we use '* *' to try and capture those.\n# we also want to avoid dotfiles such as .git\n# the output will be paths like './webapp_waf/nginx.conf.j2' so we use the cut command to extract the service name (e.g. webapp_waf)\n$ time find . -type f ! -path '*.git/*' ! -path '*.venv*' ! -path '* *' ! -name '*.md' ! -name '*.json' ! -name '*.yml' | xargs grep -l -i nginx | sort | uniq | sort | cut -d / -f 2 | uniq | sort\n#!/usr/local/bin/bash\n\nDIR=\"$HOME/code/project-foo/\"\n\npushd \"$DIR\"\n\n# the \\; is necessary when using -exec flag\nfind . -name 'README*' ! -path '*node_modules*' -exec wc -l {} \\;\n\npopd\n","tags":"#bash #find #filter #execute #grep #uniq #sort #search"},{"id":"c0f1e3fe02d8d03fc3a49e806d102f4b","title":"[Go Interface Design] ","content":"The rule of thumb when writing Go code is:\n\n\u003e accept interfaces, return structs\n\nAccepting interfaces gives your API the greatest flexibility  \nand returning structs allows the people reading your code to quickly navigate to the correct function.\n\nAvoid concrete types in favour of interface types.\n\nWhen you know the required functionality of a package, codify it into a interface.  \nThen check there isn't already an interface in the stdlib that defines those behaviours.\n\nA good blog post to refer to is: \nhttps://www.goinggo.net/2016/10/avoid-interface-pollution.html\n\nIn that it shows an example where an interface was unnecessary, in that it:\n\n1. it described the complete concrete implementation\n2. wasn't decoupling the code from change\n3. could be removed and nothing changed for the user\n\nThe author suggests using an interface in these circumstances:\n\n* When users of the API need to provide an implementation detail.\n* When API’s have multiple implementations they need to maintain internally.\n* When parts of the API that can change have been identified and require decoupling.\n","tags":"#tags: go, interface"},{"id":"abe4a3e377b4114d08564164e9e8b192","title":"[Python Tornado Example Application] ","content":"There are two examples...\n\n1. Simple\n2. Advanced\nimport os\n\nimport tornado.autoreload\nimport tornado.httpclient\nimport tornado.httpserver\nimport tornado.ioloop\nimport tornado.options\nimport tornado.web\nimport uvloop\n\napp_settings = {\n    \"env\": os.environ.get(\"ENV\", \"dev\"),\n    \"port\": os.environ.get(\"APP_PORT\", \"9000\"),\n}\n\nhttp_client = tornado.httpclient.AsyncHTTPClient()\n\n\nclass FooHandler(tornado.web.RequestHandler):\n    async def get(self, *args, **kwargs):\n        resp = await http_client.fetch(\"https://httpbin.org/get\")\n        self.finish(resp.body)\n\n\nclass App(tornado.web.Application):\n    def __init__(self):\n        super().__init__([\n            (r\"/\", FooHandler),\n        ], **app_settings)\n\n\nif __name__ == \"__main__\":\n    uvloop.install()\n\n    tornado.options.options.logging = None  # configure tornado to leave logging alone\n\n    if app_settings[\"env\"] == \"dev\":\n        tornado.autoreload.start()\n        App().listen(app_settings[\"port\"])\n    else:\n        server = tornado.httpserver.HTTPServer(App())\n        server.bind(app_settings[\"port\"])\n        server.start(0)  # multi process mode (one process per cpu)\n\n    tornado.ioloop.IOLoop.current().start()\n#!/usr/bin/env python\n\n\"\"\"This is our complete Tornado application.\n\nExample endpoints...\n\ncurl localhost:9000/headers\ncurl localhost:9000/static/foo.js\ncurl localhost:9000/\n\"\"\"\n\nimport logging\nimport os\nimport structlog\n\n# from tornado import gen\nfrom tornado.httpclient import AsyncHTTPClient\nfrom tornado.httpserver import HTTPServer\nfrom tornado.ioloop import IOLoop\nfrom tornado.options import options\nfrom tornado.process import cpu_count\nfrom tornado.web import Application, RequestHandler, StaticFileHandler\nfrom tornado.web import ErrorHandler as BaseErrorHandler\n\napp_settings = {\n    \"compress_response\": True,\n    \"default_handler_args\": dict(status_code=404),\n    \"default_handler_class\": ErrorHandler,\n    \"env\": os.environ.get(\"ENV\", \"dev\"),\n    \"log_level\": os.environ.get(\"LOG_LEVEL\", \"INFO\"),\n    \"port\": os.environ.get(\"APP_PORT\", \"9000\"),\n    \"static_path\": os.path.join(os.path.dirname(__file__), \"static\"),\n    \"static_handler_class\": RobotsHandler,  # probably should be more generically named\n    \"template_path\": os.path.join(os.path.dirname(__file__), \"templates\"),\n    # debug=True (can also use explicit: tornado.autoreload.start())\n  \t#\n  \t# Example:\n  \t#\n  \t# if settings.get(\"cluster\") == \"dev\":\n    #     tornado.autoreload.start()\n}\n\nlogging.basicConfig(\n    level=getattr(logging, app_settings[\"log_level\"]),\n    format=\"[%(levelname)s %(asctime)s path:%(pathname)s lineno:%(lineno)s] %(message)s\",  # noqa\n    datefmt=\"%Y/%m/%d %I:%M:%S\"\n)\n\nstructlog.configure(logger_factory=structlog.stdlib.LoggerFactory())\nlog = structlog.get_logger()\n\n\nclass HeadersHandler(RequestHandler):\n    \"\"\"Serves application header information.\"\"\"\n\n    # Following method is here to demonstrate older Tornado syntax\n    # Pre-async/await support version, where you needed Tornado's gen module\n    #\n    # @gen.coroutine\n    # def get(self, *args, **kwargs):\n    #     \"\"\"A function that will return the content for the health endpoint.\"\"\" # noqa\n    #     log.info(\"Endpoint hit\", handler=\"health\")\n    #     http_client = AsyncHTTPClient()\n    #     response = yield http_client.fetch(\"https://httpbin.org/headers\")\n    #     self.finish(response.body)\n\n    def initialize(self, some_data_object):\n        self.some_data_object = some_data_object\n    \n    async def get(self, *args, **kwargs):\n        \"\"\"A function that will return the content for the header endpoint.\"\"\"\n        log.info(\"Endpoint hit\", handler=\"health\")\n        http_client = AsyncHTTPClient()\n        response = await http_client.fetch(\"https://httpbin.org/headers\")\n        self.finish(response.body)\n\n    def data_received(self, chunk):\n        \"\"\"Defined to avoid abstract-method lint issue.\"\"\"\n        pass\n\n\nclass HomeHandler(RequestHandler):\n    \"\"\"Serves application home information.\"\"\"\n\n    async def get(self, *args, **kwargs):\n        \"\"\"A function that will return the content for the home endpoint.\"\"\"\n        log.info(\"Endpoint hit\", handler=\"home\")\n        self.render(\n            \"index.html\",\n            header_text=\"Header goes here\",\n            footer_text=\"Footer goes here\"\n        )\n\n    def data_received(self, chunk):\n        \"\"\"Defined to avoid abstract-method lint issue.\"\"\"\n        pass\n\n\nclass RobotsHandler(StaticFileHandler):\n    async def get(self, path=\"robots.txt\", include_body=True):\n        return await super().get(path, include_body)\n\n    def set_default_headers(self):\n        self.clear_header(\"Server\")\n\n    def set_extra_headers(self, path):\n        self.set_header(\"foo\", \"bar\")\n        \n        \nclass ErrorHandler(BaseErrorHandler):\n    def write_error(self, status_code, **kwargs):\n        log = logger.bind(status=status_code)\n        log.error(\"incoming request\")\n        \n        # notice these methods... \n        self.set_default_headers()\n        self.set_extra_headers()\n        # ...are no longer automatically called\n        #\n        # so I manually call them\n        #\n        # i believe this is because tornado.web.ErrorHandler doesn't call the parent RequestHandler __init__ \n        \n        self.write(\"Error %s\" % status_code)\n\n    def set_default_headers(self):\n        self.clear_header(\"Server\")\n\n    def set_extra_headers(self, path=None):\n        for header, value in get_headers(self.get_status(), key=path):\n            self.set_header(header, value)\n      \n \ndef robots_path() -\u003e str:\n    return os.path.join(os.path.dirname(__file__), \"static\", \"robots.txt\")\n\n\nclass App(Application):\n    \"\"\"Base Application class to define the app's routes and settings.\"\"\"\n\n    def __init__(self):\n        \"\"\"Setup the routes and import the application settings.\"\"\"\n        app_handlers = [\n            (r\"/\", HomeHandler),\n            (r\"/headers\", HeadersHandler, {\"some_data_object\": [\"i\", \"could\", \"be\", \"a\", \"class\"]}),\n            (r\"/robots.txt\", RobotsHandler, {\"path\": robots_path()}),  # MUST set `static_handler_class` in app_settings\n        ]\n\n        super().__init__(app_handlers, **app_settings)\n\n\nif __name__ == \"__main__\":\n    options.logging = None  # configure tornado to leave logging alone\n    log = log.bind(port=app_settings[\"port\"])\n\n    if app_settings[\"env\"] == \"dev\":\n        log.info(\"Starting applications\", mode=\"single\")\n        App().listen(app_settings[\"port\"])\n    else:\n        log.info(\"Starting applications\", mode=\"forked\", cpu_count=cpu_count())\n        server = HTTPServer(App())\n        server.bind(app_settings[\"port\"])\n        server.start(0)  # multi process mode (one process per cpu)\n\n    IOLoop.current().start()\nalert('hello');\n{{ static_url(\"foo.js\") }}\n\u003c!--\ncreates a hash based on the content of the file and appends it to the end of the URL\n/static/foo.js?v=da9209eb23a61fd3633a1fd140069bae\n--\u003e\n\n{% extends layout.html %}\n\u003c!--\nalternatively we could 'include' another file (path is relevative to the current 'templates' directory):\n\n{% include partials/_head.html %}\n\n...so the file would be located: templates/partials/_head.html\n--\u003e\n\n{% block header %}\n    \u003ch1\u003e{{ header_text }}\u003c/h1\u003e\n{% end %}\n\n{% block body %}\n    \u003cp\u003eHello from the child template!\u003c/p\u003e\n{% end %}\n\n{% block footer %}\n    \u003cp\u003e{{ footer_text }}\u003c/p\u003e\n    {% set mailLink = \"\u003ca href=\\\"mailto:foo@bar.com\\\"\u003eContact Us\u003c/a\u003e\" %}\n    \u003cp\u003e{{ mailLink }}\u003c/p\u003e\n    \u003cp\u003e{% raw mailLink %}\u003c/p\u003e\n{% end %}\n\u003chtml\u003e\n\u003cbody\u003e\n    \u003cheader\u003e\n        {% block header %}{% end %}\n    \u003c/header\u003e\n    \u003ccontent\u003e\n        {% block body %}{% end %}\n    \u003c/content\u003e\n    \u003cfooter\u003e\n        {% block footer %}{% end %}\n    \u003c/footer\u003e\n\u003c/body\u003e\n\u003c/html\u003e\n","tags":"#python #python3 #tornado #example #basic #simple"},{"id":"56f304c94c42fb60c04cc7b60aa48732","title":"[vim debugging] ","content":"vim -D                  # starts vim in a step-debugger mode\n:h map-listing          # show information about key bindings that have been mapped by either your .vimrc or other scripts\n:scriptnames            # shows list of sourced script names, in the order they were sourced\n:set runtimepath?       # shows list of directories which will be searched for runtime files\n:verbose set \u003coption\u003e?  # shows where \u003coption\u003e was last set (e.g. :verbose set history?)\n:set rtp+=\u003cpath\u003e        # allows appending \u003cpath\u003e to the runtimepath variable\n\n# example mappings I use, and last item demonstrates a bug...\n\n:map \\\\\\                # mapped to a Commentary plugin command\n:map \u003cLeader\u003ef          # mapped to :FZF\u003cCR\u003e\n:map \u003cC-i\u003e              # incorrectly mapped to `gt` which is mapped to \u003cTab\u003e!\n:verbose map \u003cC-i\u003e      # this helps to identify where it was last set! `Last set from ~/.vimrc line 306`\n\n# Although \u003cC-i\u003e indicates the mapping, the help file is CTRL-I (`:h CTRL-I`)\n","tags":"#vim #debugging"},{"id":"12caf8067bbafbfb9113d752e299f2cd","title":"[Increment parsed number within a pipeline sub shell] When you need the next available port number ","content":"egrep -roh 'port: \\d{5}' **/service.yml | sort | tail -n 1 | egrep -o '\\d{5}' | xargs -I {} bash -c 'echo $((\"$@\" + 1))' _ {}\n","tags":"#buzzfeed #bash"},{"id":"17f9ffb8178ec9b543025ab3116ef2ed","title":"[Python Auto Documentation Generation] Use pycco for generating documentation using docstrings from code files ","content":"REPO := $(shell git rev-parse --show-toplevel)\nGIT := \".git/hooks\"\nHOOK := \".custom-hooks\"\n\ndefine copy_base_hooks\n\t@cp \"$(REPO)/$(HOOK)/pre-commit\" \"$(REPO)/$(GIT)/pre-commit\"\nendef\n\ndefine copy_template_hooks\n\t@cp \"$(REPO)/$(HOOK)/pre-commit-pydoc\" \"$(REPO)/$(GIT)/pre-commit-pydoc\"\nendef\n\ncheck_hook_requirements:\n\t@pycco -h 1\u003e/dev/null 2\u003e\u00261 || (echo \"Looks like you don't have the pycco executable, we need that to auto generate documentation\" \u0026\u0026 exit 1)\n\nclean_hooks:\n\t-@rm $(REPO)/$(GIT)/pre-commit.sample \u0026\u003e /dev/null || true\n\t-@rm $(REPO)/$(GIT)/pre-commit \u0026\u003e /dev/null || true\n\t-@rm $(REPO)/$(GIT)/pre-commit-* \u0026\u003e /dev/null || true\n\nhooks: check_hook_requirements clean_hooks\n\t$(call copy_base_hooks)\n\t$(call copy_template_hooks)\n\n# Explanation of clean_precommits syntax:\n#\n# -       ...allows errors to be ignored (i.e. don't stop further execution steps)\n# @       ...stops makefile from printing command that was executed\n# \u0026\u003e      ...redirects stdout/stderr to /dev/null (as command can sometimes error)\n# || true ...prevents Make from printing 'error ignored'\nHelp menu...\n\n```bash\n$ pycco -h\nUsage: pycco [options]\n\nOptions:\n  -h, --help            show this help message and exit\n  -p, --paths           Preserve path structure of original files\n  -d OUTDIR, --directory=OUTDIR\n                        The output directory that the rendered files should go\n                        to.\n  -w, --watch           Watch original files and re-generate documentation on\n                        changes\n  -l LANGUAGE, --force-language=LANGUAGE\n                        Force the language for the given files\n  -i, --generate_index  Generate an index.html document with sitemap content\n  -s, --skip-bad-files  Continue processing after hitting a bad file\n```\n\nGenerate documentation...\n\n```\n$ pycco **/*.py -d ./docs/api -p -i\n```\n#!/bin/bash\n\n# grab list of file names that have been staged ready for commit\nPY_FILES=($(git diff --staged --name-only | grep \"\\.py$\" || true))\n\n# construct list of directories that have changes (there will be duplicates)\nPY_DIRS=()\nfor i in \"${PY_FILES[@]}\"; do\n  PY_DIRS+=(\"$(echo $i | cut -d '/' -f 1)\")\ndone\n\n# remove duplicates\nPY_DIRS=($(echo \"${PY_DIRS[*]}\" | tr ' ' '\\n' | sort | uniq))\n\n# run pydoc for each directory with changes\nif [ ${#PY_DIRS[@]} -gt 0 ]; then\n  printf '\\n********** Documentation Generation **********\\n\\n'\n  for i in \"${PY_DIRS[@]}\"; do\n    pushd \"./$i\"\n    pycco -p -i -d ./docs/api -- ./**/*.py 2\u003e/dev/null || \\\n      echo \"uh-oh, something went wrong with $i\"\n    popd\n  done\nelse\n  printf \"\\nThere are no python changes that would cause us to run pydoc\\n\\n\"\nfi\n\n# pycco -h\n#\n# -p, --paths           Preserve path structure of original files\n# -d, --directory       The output directory that the rendered files should go\n# -i, --generate_index  Generate an index.html document with sitemap content\n#\n# https://realpython.com/blog/python/generating-code-documentation-with-pycco/\n#!/bin/bash\n\nset -e\n\nerr_report() {\n    echo \"There was an issue with one of the pre-commit hooks\"\n    echo \".git/hooks/pre-commit-*\"\n    echo \"Error on line $1\"\n}\ntrap 'err_report $LINENO' ERR\n\nfor commit_hook in .git/hooks/pre-commit-*; do\n  source \"$commit_hook\"\ndone\n","tags":"#python #docs"},{"id":"06afe9a193413593f630b357a898d1c5","title":"Python Format Date String","content":"# https://docs.python.org/3.5/library/datetime.html#strftime-strptime-behavior\n\nimport time\nfrom_date = 'Wed Mar 09 16:03:13 +0000 2016'\nconv=time.strptime(from_date,\"%a %b %d %H:%M:%S %z %Y\")\ntime.strftime(\"%d/%m/%Y\",conv)\n\n# REAL EXAMPLE\n\nimport time\ndate = '1995-07-01T00:00:00Z'\nparsed = time.strptime(date, '%Y-%m-%dT%H:%M:%SZ')\ntime.strftime(\"%Y.%m.%d\", parsed)  # '1995.07.01'\n","tags":""},{"id":"e1743503f18904e3af99dac27134de91","title":"[Python Auto Generate API Documentation] Python Auto Generate API Documentation ","content":"#!/bin/bash\n\nset -e\n\nerr_report() {\n    echo \"There was an issue with one of the pre-commit hooks\"\n    echo \".git/hooks/pre-commit-*\"\n    echo \"Error on line $1\"\n}\ntrap 'err_report $LINENO' ERR\n\nfor commit_hook in .git/hooks/pre-commit-*; do\n  source \"$commit_hook\"\ndone\n#!/bin/bash\n\n# grab list of file names that have been staged ready for commit\nPY_FILES=($(git diff --staged --name-only | grep \"\\.py$\" || true))\n\n# construct list of directories that have changes (there will be duplicates)\nPY_DIRS=()\nfor i in \"${PY_FILES[@]}\"; do\n  PY_DIRS+=(\"$(echo $i | cut -d '/' -f 1)\")\ndone\n\n# remove duplicates\nPY_DIRS=($(echo \"${PY_DIRS[*]}\" | tr ' ' '\\n' | sort | uniq))\n\n# run pydoc for each directory with changes\nif [ ${#PY_DIRS[@]} -gt 0 ]; then\n  printf '\\n********** Documentation Generation **********\\n\\n'\n  for i in \"${PY_DIRS[@]}\"; do\n    pushd \"./$i\"\n    pycco -p -i -d ./docs/api -- ./**/*.py 2\u003e/dev/null || \\\n      echo \"uh-oh, something went wrong with $i\"\n    popd\n  done\nelse\n  printf \"\\nThere are no python changes that would cause us to run pydoc\\n\\n\"\nfi\n\n# pycco -h\n#\n# -p, --paths           Preserve path structure of original files\n# -d, --directory       The output directory that the rendered files should go\n# -i, --generate_index  Generate an index.html document with sitemap content\n#\n# https://realpython.com/blog/python/generating-code-documentation-with-pycco/\nREPO := $(shell git rev-parse --show-toplevel)\nGIT := \".git/hooks\"\nHOOK := \".custom-hooks\"\n\ndefine copy_base_hooks\n\t@cp \"$(REPO)/$(HOOK)/pre-commit\" \"$(REPO)/$(GIT)/pre-commit\"\nendef\n\ndefine copy_template_hooks\n\t@cp \"$(REPO)/$(HOOK)/pre-commit-pydoc\" \"$(REPO)/$(GIT)/pre-commit-pydoc\"\nendef\n\ncheck_hook_requirements:\n\t@pycco -h 1\u003e/dev/null 2\u003e\u00261 || (echo \"Looks like you don't have the pycco executable, we need that to auto generate documentation\" \u0026\u0026 exit 1)\n\nclean_hooks:\n\t-@rm $(REPO)/$(GIT)/pre-commit.sample \u0026\u003e /dev/null || true\n\t-@rm $(REPO)/$(GIT)/pre-commit \u0026\u003e /dev/null || true\n\t-@rm $(REPO)/$(GIT)/pre-commit-* \u0026\u003e /dev/null || true\n\nhooks: check_hook_requirements clean_hooks\n\t$(call copy_base_hooks)\n\t$(call copy_template_hooks)\n\n# Explanation of clean_precommits syntax:\n#\n# -       ...allows errors to be ignored (i.e. don't stop further execution steps)\n# @       ...stops makefile from printing command that was executed\n# \u0026\u003e      ...redirects stdout/stderr to /dev/null (as command can sometimes error)\n# || true ...prevents Make from printing 'error ignored'\n","tags":"#tags: python, git, bash, make"},{"id":"23e8b8e732fa6c033e090dde3547ec82","title":"[Python State Machine] simple state machine for replacing quotations in a string ","content":"def replace_quotes():\n    state = 0\n    def state_machine(match):\n        nonlocal state\n        state = 1 if not state else 0\n        return \"\u0026ldquo;\" if state else \"\u0026rdquo;\"\n    return state_machine\n    \ntxt = 'I said \"hello mark\" but he did not reply so I said \"fine then?\" and he walked off'\n\nre.sub(r'\"', replace_quotes(), txt)\n\n# 'I said \u0026ldquo;hello mark\u0026rdquo; but he did not reply so I said \u0026ldquo;fine then?\u0026rdquo; and he walked off'\n","tags":"#tags: python3, state-machine"},{"id":"1670fa65ad8f685d35a5235b3fba7af0","title":"Python aiohttp example using mustache (also consider https://github.com/saghul/aiodns)","content":"#!/usr/bin/env python\nimport asyncio\n\nimport uvloop\nasyncio.set_event_loop_policy(uvloop.EventLoopPolicy())\n\nfrom aiohttp import web, get\nimport ujson\nimport pystache\n\nTEMPLATE = open('./template.mustache').read()\n\nasync def fetch_json(url):\n    respone = await get(url)\n    data = await respone.json(loads=ujson.loads)\n    await respone.release()\n    return data\n\n\nasync def handler(request):\n    requests = [fetch_json('https://www.example.com/some/api') for _ in range(3)]\n    results = await asyncio.gather(*requests)\n    badge = next(iter(results))\n    body = pystache.render(TEMPLATE, badge)\n    return web.Response(text=body, content_type='text/html')\n\nasync def health(r):\n    return web.Response(text='OK')\n\n\ndef get_app():\n    app = web.Application(debug=True)\n    app.router.add_get(r'/', handler)\n    app.router.add_get(r'/health', health)\n    return app\n\n\nif __name__ == '__main__':\n    app = get_app()\n    web.run_app(app, port=8080)\naiohttp==1.1.6\nasync-timeout==1.1.0\ncchardet==1.1.1\nchardet==2.3.0\nmultidict==2.1.4\npystache==0.5.4\ntornado==4.4.2\nujson==1.35\nuvloop==0.6.7\nyarl==0.8.1\n\u003c!DOCTYPE html\u003e\n\u003chtml\u003e\n  \u003chead\u003e\n    \u003cmeta charset=\"utf-8\"\u003e\n    \u003ctitle\u003ePerf testing\u003c/title\u003e\n  \u003c/head\u003e\n  \u003cbody\u003e\n    \u003cp\u003e{{success}}\u003c/p\u003e\n    {{#data}}\n      \u003cp\u003e{{name}}\u003c/p\u003e\n      \u003cp\u003e{{path}}\u003c/p\u003e\n      \u003cp\u003e{{category}}\u003c/p\u003e\n    {{/data}}\n  \u003c/body\u003e\n\u003c/html\u003e\n","tags":""},{"id":"d615647810c9f3961b29b9e84e252c8b","title":"Go test with interface","content":"package main\n\nimport (\n  \"testing\"\n\n  \"github.com/stretchr/testify/assert\"\n)\n\ntype FakeFoo struct{}\n\nfunc (s *FakeFoo) Read() string {\n  return \"We 'pretend' to READ something from disk\"\n}\n\nfunc TestSomething(t *testing.T) {\n  assert := assert.New(t)\n\n  foo := \u0026FakeFoo{}\n  contents := Stuff(foo)\n\n  assert.Equal(contents, \"We 'pretend' to READ something from disk\")\n}\nThe purpose of this gist is to show you how to use an interface for swapping out behaviour within a testing context. This allows you to fake (i.e. mock) specific functionality so you don't have to rely on actual network conditions for your unit tests.\n\nI've used a custom interface here (e.g. `FooIO`), but in reality/practice you'd likely use a built-in interface.\n\nFor example, the [Reader](https://golang.org/pkg/io/#Reader) interface. \n\nOr maybe a [ReadWriter](https://golang.org/pkg/io/#ReadWriter) interface, which combines the [Reader](https://golang.org/pkg/io/#Reader) and [Writer](https://golang.org/pkg/io/#Writer) interfaces.\npackage main\n\nimport \"fmt\"\n\ntype FooIO interface {\n  Read() string\n}\n\ntype Foo struct{}\n\nfunc (f *Foo) Read() string {\n  return \"We READ something from disk\"\n}\n\nfunc Stuff(f FooIO) string {\n  return f.Read()\n}\n\nfunc main() {\n  foo := \u0026Foo{}\n  contents := Stuff(foo)\n  fmt.Println(contents)\n}\n","tags":""},{"id":"0f088983d522de5c0c81ea148823eef1","title":"[Python3 Logging] Simple Python3 Logging Configuration ","content":"import io\nimport logging\n\nlogger = logging.getLogger(\"your_logger\")\nlogger.setLevel(logging.INFO)\n\nlogger_output = io.StringIO()\nlogger.addHandler(logging.StreamHandler(logger_output))\n\n# do stuff that triggers some logs\n\nlogger_contents = logger_output.getvalue()\nlogger_output.close()\n\nprint(logger_contents)\n# https://docs.python.org/3/library/logging.html#logrecord-attributes\n\nimport logging\nlog = logging.getLogger()  # \u003clogging.RootLogger at 0x107f72f98\u003e\nlog.setLevel(logging.DEBUG)\nlog.debug('123')  # DEBUG:root:123\nlog.info('456')  # INFO:root:456\n\n# Alternatively, you can default to the 'root' logger implicitly,\n# but you can't use setLevel as that's only available on the logger instance,\n# and a logger instance is what you're getting with getLogger.\n# so instead you use basicConfig...\nimport logging\nlogging.basicConfig(level=logging.DEBUG, format='%(relativeCreated)6d %(threadName)s %(message)s')\n\n# A format I like...\nimport logging\nlogging.basicConfig(\n    level=logging.INFO,\n    format='[%(levelname)s %(asctime)s path:%(pathname)s lineno:%(lineno)s] %(message)s',\n    datefmt='%Y/%m/%d %I:%M:%S'\n)\n# Keep logs quiet (so only critical messages are shown, not INFO messages)\nlogging.getLogger(\"boto\").setLevel(logging.CRITICAL)\nlogging.getLogger(\"nsq\").setLevel(logging.CRITICAL)\nimport logging\nimport structlog\n\n# create logger\nlogger = logging.getLogger('simple_example')\nlogger.setLevel(logging.DEBUG)\n\n# We need factory, to return application-wide logger\ndef logger_factory():\n    return logger\n\nstructlog.configure(\n    processors=[\n            structlog.processors.JSONRenderer(indent=2, sort_keys=True)      \n        ],\n        logger_factory=logger_factory\n    )\n\nlog = structlog.getLogger()\nlog.debug(\"Now you see me\")\nlogger.setLevel(logging.ERROR)\nlog.debug(\"Now you don't\")\n","tags":"#logs #python"},{"id":"f790b21acc5fa178830f060f649a04c4","title":"Python subclass dictionary","content":"class MyDict(OrderedDict):\n    def __init__(self):\n        super().__init__()\n\n    def __setitem__(self, key, value):\n        # set device_type to mobile by default, and allow override to be provided\n        value = {'device_type': 'mobile', **value} if not value.get('device_type') else {**value}\n        print('value set is {}'.format(value))\n        super().__setitem__(key, value)\n\nd = MyDict()\ndict(d)  # {}\n\nd['foo'] = {'beep': 'boop'}\n# value set is {'device_type': 'mobile', 'beep': 'boop'}\n\nd['bar'] = {'device_type': 'something', 'beep': 'boop'}\n# value set is {'device_type': 'something', 'beep': 'boop'}\n\ndict(d)  \n# {'bar': {'beep': 'boop', 'device_type': 'something'}, 'foo': {'beep': 'boop', 'device_type': 'mobile'}}\n","tags":""},{"id":"124f65630d23bc9834081b8551e4421d","title":"[Python timestamp handling] ","content":"# seconds...\n\nthen = datetime.now()\nnow = datetime.now()\n\ndiff_now_then = now - then\ndiff_now_then.seconds\n\n# days...\n\nthen = datetime(2018, 11, 1, 00, 00, 00, 00)\nnow = datetime(2018, 11, 25, 00, 00, 00, 00)\ndelta = now - then\ndelta.days  # 24\ndelta.days \u003e= 30  # False\n# https://docs.python.org/3.6/library/time.html#time.strftime\n  \nfrom datetime import datetime\n\nreleased_at = \"2017-05-30T20:54:37.228197Z\"\n\nthen = datetime.strptime(released_at, \"%Y-%m-%dT%H:%M:%S.%fZ\")\n# datetime.datetime(2017, 5, 30, 20, 54, 37, 228197)\n\nnow = datetime.now()\n# datetime.datetime(2017, 5, 31, 16, 31, 36, 507198)\n\ndifference = then - now\n# datetime.timedelta(-1, 15780, 720999)\n\ndifference.days\n# -1\n\nlatest = max((then, now))\n# now was the latest of the two...\n# datetime.datetime(2017, 5, 31, 16, 31, 36, 507198)\nfrom datetime import datetime, timedelta\n\ndatetime.now() - timedelta(hours=1)\n\n# datetime.datetime(2018, 3, 14, 10, 29, 18, 595972)\n","tags":"#python #date #time"},{"id":"1a256fc6e9112a084cddd94a49bb5fba","title":"Python if/else list comprehension (generator expression)","content":"[i if i is True else 'nope' for i in [True, False, True]]\n\n# [True, 'nope', True]\n\n# Notice this is a conditional expression and different from list comprehension\n# Which typically is `for ... if ...`\n# Now it's reversed and no expression for truthy condition `if x \u003ccondition\u003e else \u003cexpression\u003e`\n","tags":""},{"id":"06866d9c6faba66517d05b9278766376","title":"Compile Mozilla's Servo web browser (built with their new Rust language)","content":"## Requirements\n\n- `brew install rust pyenv automake pkg-config cmake yasm`\n- `pyenv local 2.x`\n- `pip install pyobjc virtualenv`\n- `git clone git@github.com:servo/servo.git`\n\n\u003e Note: `pyobjc` takes _forever_ to install\n\n## Installation\n\n- `./mach build -r`\n\n## Running\n\n- ``\n","tags":""},{"id":"99a20bc40fee08e8ec8d63d06c7788f0","title":"[HTTP Headers Shell Script Abstraction] ","content":"curl -sv --head \"https://www.buzzfeed.com/news\" 2\u003e\u00261 | sort | egrep -i '^(x-(siterouter|cache|vcl)|vary)'\nfunction headers {\n  if [[ \"$1\" =~ -(h|help) ]]; then\n    printf \"\\n\\t1st param: URL\\n\\t2nd param: regex\\n\\t3rd param: http request header\"\n    printf \"\\n\\n\\tif you have no need for a regex\\n\\tbut need a http header\\n\\tthen just use an empty string ''\\n\"\n    return\n  fi\n\n  if [ -z \"$1\" ]; then\n    printf \"\\n\\tExamples:\\n\\t\\theaders https://www.buzzfeed.com/?country=us 'x-cache|x-timer|device' '-H User-Agent:iphone'\\n\"\n    printf \"\\t\\theaders https://www.buzzfeed.com/?country=us '' '-H User-Agent:iphone -H X-Foo:bar'\\n\"\n    printf \"\\n\\tHelp:\\theaders -h\\n\\t\\theaders -help\\n\"\n    return\n  fi\n\n  local url=$1\n  local pattern=${2:-''}\n  local header=${3:-}\n  local response=$(curl -H Fastly-Debug:1 $header -D - -o /dev/null -s \"$url\") # -D - will dump to stdout\n  local status=$(echo \"$response\" | head -n 1)\n\n  printf \"\\n%s\\n\\n\" \"$status\"\n  echo \"$response\" | sort | tail -n +3 | egrep -i \"$pattern\"\n}\n\n# EXAMPLE OUTPUT...\n\n$ headers\n\n        Examples:\n                headers https://www.buzzfeed.com/?country=us 'x-cache|x-timer|device' '-H User-Agent:iphone'\n                headers https://www.buzzfeed.com/?country=us '' '-H User-Agent:iphone -H X-Foo:bar'\n\n        Help:   headers -h\n                headers -help\n                \n$ headers -h\n\n        1st param: URL\n        2nd param: regex\n        3rd param: http request header\n\n        if you have no need for a regex\n        but need a http header\n        then just use an empty string ''\n        \n$ headers https://www.buzzfeed.com/?country=us 'x-cache|x-timer|device' '-H User-Agent:iphone'\n\nHTTP/1.1 200 OK\n\nX-BF-Device-Type: mobile\nX-Cache-Hits: 0\nX-Cache: MISS\nX-Timer: S1488622282.330156,VS0,VE429\n","tags":"#tags: bash, http-headers"},{"id":"7fd120f523e82e352163302544c9f6b6","title":"[Python VCR] ","content":"# http://vcrpy.readthedocs.io/en/latest/usage.html#record-modes\n#\n# to generate a new cassette you need to ensure your container is in a read/write mode\n# e.g. for BuzzFeed tooling this equates to: `rig run \u003cservice\u003e --rw bash`, then `py.test tests/integration/test_\u003cservice\u003e.py`\n#\n# that will generate a `test_news_feed.json` cassette for you\n#\n# the cassette structure is [{\"request\":\"...\", \"response\":\"...\"}, {...}]\n# it records the dicts in the specific order of the requests made\n#\n# once the cassettes are recorded you might decided to set `record_mode` to `never`?\n# but to be honest `once` should be a good default\n\nimport vcr as vcr_\n\nvcr = vcr_.VCR(\n    serializer='json',\n    cassette_library_dir='tests/fixtures/cassettes',\n    match_on=['method', 'scheme', 'host', 'port', 'path'],\n    record_mode='once',\n    ignore_localhost=True,\n    filter_headers=['X-Auth-Token']\n)\n\nclass NewsHandlerTest(testing.AsyncHTTPTestCase):\n    def get_app(self):\n        return App()\n\n    @vcr.use_cassette('test_news_feed.json')\n    def test_news_response_headers(self):\n        self.fetch('/news')\n        assert True is True\n\n","tags":"#tags: python, vcr, testing"},{"id":"2700697b316637e2a1f57b9cd802914c","title":"[Search for package versions] ","content":"docker run -it ubuntu\n\nroot@8fea4e1634e1:/$ apt-get update\nroot@8fea4e1634e1:/$ apt-cache policy nginx\n\nnginx:\n  Installed: (none)\n  Candidate: 1.10.0-0ubuntu0.16.04.4\n  Version table:\n     1.10.0-0ubuntu0.16.04.4 500\n        500 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 Packages\n        500 http://archive.ubuntu.com/ubuntu xenial-security/main amd64 Packages\n     1.9.15-0ubuntu1 500\n        500 http://archive.ubuntu.com/ubuntu xenial/main amd64 Packages\n\nroot@cd0aa2494917:/$ apt-cache policy nginx-plus\n\nnginx-plus:\n  Installed: 1.11.10-4~jessie\n  Candidate: 1.13.4-1~jessie\n  Version table:\n     1.13.4-1~jessie 0\n        500 https://plus-pkgs.nginx.com/debian/ jessie/nginx-plus amd64 Packages\n *** 1.11.10-4~jessie 0\n        500 https://plus-pkgs.nginx.com/debian/ jessie/nginx-plus amd64 Packages\n        100 /var/lib/dpkg/status\n     1.11.10-3~jessie 0\n        500 https://plus-pkgs.nginx.com/debian/ jessie/nginx-plus amd64 Packages\n     1.11.10-2~jessie 0\n        500 https://plus-pkgs.nginx.com/debian/ jessie/nginx-plus amd64 Packages\n     1.11.10-1~jessie 0\n        500 https://plus-pkgs.nginx.com/debian/ jessie/nginx-plus amd64 Packages\n     1.11.5-1~jessie 0\n        500 https://plus-pkgs.nginx.com/debian/ jessie/nginx-plus amd64 Packages\n     1.11.3-1~jessie 0\n        500 https://plus-pkgs.nginx.com/debian/ jessie/nginx-plus amd64 Packages\n     1.9.13-2~jessie 0\n        500 https://plus-pkgs.nginx.com/debian/ jessie/nginx-plus amd64 Packages\n     1.9.13-1~jessie 0\n        500 https://plus-pkgs.nginx.com/debian/ jessie/nginx-plus amd64 Packages\n     1.9.9-4~jessie 0\n        500 https://plus-pkgs.nginx.com/debian/ jessie/nginx-plus amd64 Packages\n     1.9.9-3~jessie 0\n        500 https://plus-pkgs.nginx.com/debian/ jessie/nginx-plus amd64 Packages\n     1.9.9-2~jessie 0\n        500 https://plus-pkgs.nginx.com/debian/ jessie/nginx-plus amd64 Packages\n     1.9.9-1~jessie 0\n        500 https://plus-pkgs.nginx.com/debian/ jessie/nginx-plus amd64 Packages\n     1.9.4-3~jessie 0\n        500 https://plus-pkgs.nginx.com/debian/ jessie/nginx-plus amd64 Packages\n     1.9.4-2~jessie 0\n        500 https://plus-pkgs.nginx.com/debian/ jessie/nginx-plus amd64 Packages\n     1.9.4-1~jessie 0\n        500 https://plus-pkgs.nginx.com/debian/ jessie/nginx-plus amd64 Packages\n     1.7.11-2~jessie 0\n        500 https://plus-pkgs.nginx.com/debian/ jessie/nginx-plus amd64 Packages\n\n# an alternative would be: apt-cache madison \u003cpackage_name\u003e\n# which also displays different versions but in a more compact way...\n\nroot@cd0aa2494917:/$ apt-cache madison nginx-plus\n\nnginx-plus | 1.13.4-1~jessie | https://plus-pkgs.nginx.com/debian/ jessie/nginx-plus amd64 Packages\nnginx-plus | 1.11.10-4~jessie | https://plus-pkgs.nginx.com/debian/ jessie/nginx-plus amd64 Packages\nnginx-plus | 1.11.10-3~jessie | https://plus-pkgs.nginx.com/debian/ jessie/nginx-plus amd64 Packages\nnginx-plus | 1.11.10-2~jessie | https://plus-pkgs.nginx.com/debian/ jessie/nginx-plus amd64 Packages\nnginx-plus | 1.11.10-1~jessie | https://plus-pkgs.nginx.com/debian/ jessie/nginx-plus amd64 Packages\nnginx-plus | 1.11.5-1~jessie | https://plus-pkgs.nginx.com/debian/ jessie/nginx-plus amd64 Packages\nnginx-plus | 1.11.3-1~jessie | https://plus-pkgs.nginx.com/debian/ jessie/nginx-plus amd64 Packages\nnginx-plus | 1.9.13-2~jessie | https://plus-pkgs.nginx.com/debian/ jessie/nginx-plus amd64 Packages\nnginx-plus | 1.9.13-1~jessie | https://plus-pkgs.nginx.com/debian/ jessie/nginx-plus amd64 Packages\nnginx-plus | 1.9.9-4~jessie | https://plus-pkgs.nginx.com/debian/ jessie/nginx-plus amd64 Packages\nnginx-plus | 1.9.9-3~jessie | https://plus-pkgs.nginx.com/debian/ jessie/nginx-plus amd64 Packages\nnginx-plus | 1.9.9-2~jessie | https://plus-pkgs.nginx.com/debian/ jessie/nginx-plus amd64 Packages\nnginx-plus | 1.9.9-1~jessie | https://plus-pkgs.nginx.com/debian/ jessie/nginx-plus amd64 Packages\nnginx-plus | 1.9.4-3~jessie | https://plus-pkgs.nginx.com/debian/ jessie/nginx-plus amd64 Packages\nnginx-plus | 1.9.4-2~jessie | https://plus-pkgs.nginx.com/debian/ jessie/nginx-plus amd64 Packages\nnginx-plus | 1.9.4-1~jessie | https://plus-pkgs.nginx.com/debian/ jessie/nginx-plus amd64 Packages\nnginx-plus | 1.7.11-2~jessie | https://plus-pkgs.nginx.com/debian/ jessie/nginx-plus amd64 Packages\n","tags":"#tags: bash, apt, versions"},{"id":"ecb0890a7ea36d0010bf1cc47306d13f","title":"[VCL Logging Abstraction] vcl abstraction around logging to make calls cleaner ","content":"# log_it.vcl\nsub log_it {\n  log {\"syslog \u003cservice_id\u003e \u003cservice_name\u003e :: \"} req.http.X-MutableThing;\n}\n\n# vcl_recv\nimport \"log_it\"\nset req.http.X-MutableThing = \"foo\"\ncall log_it;\nset req.http.X-MutableThing = \"bar\"\ncall log_it;\ndeclare local var.stage_id STRING;\ndeclare local var.prod_id STRING;\ndeclare local var.common STRING;\ndeclare local var.debug_logs_active BOOL;\ndeclare local var.defaults STRING;\ndeclare local var.debug STRING;\n\n# DO NOT add a space in front of \"syslog\"\n# \" syslog ...\" will break the logging\n\nset var.stage_id = \"123\";\nset var.prod_id = \"456\";\nset var.common = \" :: \" req.http.Fastly-Client-IP \" '-' '-' \" now \" \" req.request \" \" req.url \" \";\nset var.debug_logs_active = false;\n\nif (req.service_id == var.stage_id) {\n  set var.defaults = \"syslog \" var.stage_id \" www-stage-fastly\" var.common;\n}\nelsif (req.service_id == var.prod_id) {\n  set var.defaults = \"syslog \" var.prod_id \" fastly-www\" var.common;\n}\nelse {\n  set var.defaults = \"\"; # no-op if an unidentified service\n}\nset var.debug = if (var.debug_logs_active, var.defaults, \"\");\ndeclare local var.logs_active BOOL;\ndeclare local var.defaults STRING;\n\n# Note: DO NOT add a space in front of \"syslog\"\n#       e.g. \" syslog ...\" will break the logging\n\nset var.logs_active = false;\nset var.defaults = if (var.logs_active, \"syslog \u003cservice_id\u003e \u003cendpoint\u003e :: \" req.http.Fastly-Client-IP \" '-' '-' \" now \" \" req.request \" \" req.url \" \", \"\");\n\n# some of the request variables used are specific to Fastly\n# also the reference to \u003cservice_id\u003e \u003cendpoint\u003e are specific to Fastly and Papertrail\n# so your mileage may vary\nsub vcl_recv {\n#FASTLY recv\n  include \"logging\"\n  log var.defaults req.restarts \" [main.vcl] X-FOO HEADER VALUE: \" req.http.X-Foo;\n}\n","tags":"#tags: vcl, varnish, logging"},{"id":"06bb03a150c7fb54a783c13dddf6b720","title":"netcat web server","content":"sudo /usr/bin/nc -l 80 \u003c response.txt\n\n# Note: using GNU netcat doesn't work, not sure why (so we use macOS' netcat)\ncurl -v 127.0.0.1:80\n\n* Rebuilt URL to: 127.0.0.1:80/\n*   Trying 127.0.0.1...\n* TCP_NODELAY set\n* Connected to 127.0.0.1 (127.0.0.1) port 80 (#0)\n\u003e GET / HTTP/1.1\n\u003e Host: 127.0.0.1\n\u003e User-Agent: curl/7.50.3\n\u003e Accept: */*\n\u003e \n\u003c HTTP/1.1 200 OK\n\u003c Date: Mon, 27 Jul 2009 12:28:53 GMT\n\u003c Server: Apache/2.2.14 (Win32)\n\u003c Last-Modified: Wed, 22 Jul 2009 19:15:56 GMT\n\u003c Content-Length: 88\n\u003c Content-Type: text/html\n\u003c Connection: Closed\n\u003c \n\u003cp\u003eStuff\u003c/p\u003e\n* transfer closed with 75 bytes remaining to read\n* Curl_http_done: called premature == 1\n* stopped the pause stream!\n* Closing connection 0\ncurl: (18) transfer closed with 75 bytes remaining to read\nHTTP/1.1 200 OK\nContent-Type: text/html\nConnection: keep-alive\n\n\u003cp\u003eStuff\u003c/p\u003e\n#!/bin/bash\n\nRESPONSE=\"HTTP/1.1 200 OK\\r\\nConnection: keep-alive\\r\\n\\r\\n${2:-\"OK\"}\\r\\n\"\n\nwhile { echo -en \"$RESPONSE\"; } | /usr/bin/nc -l \"${1:-8080}\"; do\n  echo \"================================================\"\ndone\n\n# Note: using GNU netcat doesn't work, not sure why (so we use macOS' netcat)\n","tags":""},{"id":"025dd8456b459ae823f3795969cf1e28","title":"Pylint Detect Similarities","content":"pylint --disable=all --enable=similarities **/*.py\n","tags":""},{"id":"835e6ce181584bec9ba6391d29ebaf12","title":"[Varnish VCL] use vcl to store provided query string and path into HTTP response headers ","content":"vcl 4.0;\n\nbackend default { \n  .host = \"www.vclfiddle.net\"; \n  .port = \"80\"; \n}\n\nsub vcl_recv {\n  if (req.url ~ \"(foo/bar)\") {\n    set req.http.X-QS = regsub(req.url, \"^[^?]+\\?\", \"\"); // good=hey\u0026bad1=true\u0026bad2=boop\n    set req.http.X-Path = regsub(req.url, \"\\?.+$\", \"\");  // /foo/bar\n  }\n}\n\n/*\ncurl http://www.vclfiddle.net/foo/bar?good=hey\u0026bad1=true\u0026bad2=boop --header 'User-Agent: vclFiddle'\nhttp://vclfiddle.net/161102-3c995c5/44\n*/\n","tags":"#tags: vcl, varnish"},{"id":"240275c63598f69a83d1678644824063","title":"Example NGINX global \"rollout\" strategy","content":"\u003e Note: `X-User-Country-Code` \u0026 `X-Device-Type` provided by our CDN (YMMV)  \n\u003e `set req.http.X-User-Country-Code = geoip.country_code;`  \n\u003e `set req.http.X-User-Continent-Code = geoip.continent_code;`\n\nSend Australia/New Zealand homepage mobile traffic\n\n```bash\n30_home_mobile:\n  variable: '$http_x_user_country_code:$http_x_device_type'\n  match: '~*(?:NZ|AU):mobile'\n```\n\nSend UK homepage mobile traffic\n\n```bash\n30_home_mobile:\n  variable: '$http_x_user_country_code:$http_x_device_type'\n  match: '~*(?:NZ|AU|GB):mobile'\n```\n\nSend Europe/Oceania homepage mobile traffic\n\n```bash\n30_home_mobile:\n  variable: '$http_x_user_continent_code:$http_x_device_type'\n  match: '~*(?:OC|EU):mobile'\n```\n\n\u003e Note: we're using `X-User-Continent-Code` this time, not `X-User-Country-Code`\n\nSend all (except North America) homepage mobile traffic\n\n```bash\n30_home_mobile:\n  variable: '$http_x_user_continent_code:$http_x_device_type'\n  match: '~*(?:AF|AS|EU|OC|SA):mobile'\n```\n\n\u003e Note: we're using `X-User-Continent-Code` this time, not `X-User-Country-Code`\n\nSend ALL homepage mobile traffic pointing\n\n```bash\n30_home_mobile:\n  variable: '$http_x_device_type'\n  match: 'mobile'\n```\n","tags":""},{"id":"d9b00fc9deafc80f845193deb43f1edf","title":"Python Class Decorator (AOP)","content":"def aop(cls):\n    class Wrapper:\n        def __init__(self, *args):\n            self.wrapped = cls(*args) # create instance of decorated class\n        def __getattr__(self, name):\n            print('Getting the {} of {}'.format(name, self.wrapped))\n            return getattr(self.wrapped, name)\n    return Wrapper\n\n@aop\nclass Foo:\n    def test_foo(self):\n        print(\"foo called\")\n    def test_bar(self):\n        print(\"bar called\")\n\nf = Foo()\nf.test_foo()\n\n# Getting the test_foo of \u003c__main__.Foo object at 0x1099c36a0\u003e\n# foo called\n","tags":""},{"id":"88cb5699ccd9324efb91fee600c79a39","title":"Stylish Chrome Extension: doc.rust-lang.org - stylised to be black as the white is a bit intense on my eyes","content":"#sbo-rt-content .feature {\n\tbackground-color: #333;\n}\n\n.detail-book.pod .description * {\n    font-size: 1.1em;\n}\n\n.detail-book.pod .description {\n    padding-left: 8em;\n    padding-right: 6em;\n}\n\n.pod, section[role=document] {\n\tbackground-color: #404040;\n}\n\n.Table,\n.even,\n.note,\n.sidebar {\n\tcolor: #404040;\n}\n\n#lesson-fragment tbody tr:nth-child(even), #sbo-rt-content tbody tr:nth-child(even) td {\n\tcolor: #404040;\n}\n\n.pod, [class*=detail-].pod, \nsection[role=document], \n#sbo-rt-content, \n#sbo-rt-content h1, \n#sbo-rt-content h2, \n#sbo-rt-content h3 {\n\tcolor: white;\n}\n\n#sbo-rt-content a,\n#sbo-rt-content a:link {\n\tcolor: pink;\n    font-weight: bold;\n}\n\n#sbo-rt-content a:visited {\n\tcolor: #CCCCCC;\n}\n\n#sbo-rt-content section[data-type=\"chapter\"]\u003ediv\u003eh1,\n#sbo-rt-content section[data-type=\"sect1\"] h1 {\n\tcolor: #f1c40f;\n}\n","tags":""},{"id":"f5c713a63db3679ee60d1c739b0aa226","title":"Storing Passwords (salt + pepper)","content":"To Store a Password\n\n* Generate a long random salt using a CSPRNG.\n* Prepend the salt to the password and hash it with a standard password hashing function like Argon2, bcrypt, scrypt, or PBKDF2.\n* Save both the salt and the hash in the user's database record.\n\nTo Validate a Password\n\n* Retrieve the user's salt and hash from the database.\n* Prepend the salt to the given password and hash it using the same hash function.\n* Compare the hash of the given password with the hash from the database. \n* If they match, the password is correct. Otherwise, the password is incorrect.\n\nExample CSPRNG\n\n* https://docs.python.org/3/library/os.html#os.urandom\n* http://www.rubydoc.info/stdlib/securerandom/1.9.3/SecureRandom\n* https://en.m.wikipedia.org/wiki//dev/random\n","tags":""},{"id":"402d7ebc44fefdac9779dd4be2791b0e","title":"[Python Tornado Request Performance] ","content":"Imagine a tornado server that makes three asynchronous HTTP requests using `AsyncHTTPClient`.\n\nThe `AsyncHTTPClient` is configured using `max_client=10`...\n\n```py\nAsyncHTTPClient.configure(None, max_clients=10)\n```\n\nMeaning tornado will be able to handle a maximum of 10 simultaneous `fetch()` operations in parallel on each IOLoop.\n\n\u003e See [tornado docs for full details](https://www.tornadoweb.org/en/stable/httpclient.html#tornado.httpclient.AsyncHTTPClient.configure)\n\nThe maths is then...\n\n- 10 client request spaces available / 3 api requests = 3.xxxx user requests  \n- meaning only 3 user requests are handled\n- before the tornado queue has only 1 space left\n- so further api requests are queued\n\nThis means a single tornado process should only be able to handle ~3 incoming requests before subsequent ones would queue in Tornado's AsyncHTTPClient.\n\nAccording to our metrics it looks like the internal API request takes ~250ms, so it would only take a backlog of 4 to reach the tornado application's configured 1s timeout.\n\nWhere we've tested using aiohttp and found better performance 'out-of-the-box', what's most likely happening is that aiohttp provides no mechanism to _control concurrency_, which appears useful in this specific case, but is ultimately not what we want, because we don't want the application to be able to DoS downstream dependencies. Granted, aiohttp might be actually be more performant. But it doesn't appear as though we're resource starved and so further configuration tweaking should be investigated before switching.\n","tags":"#tornado #performance #async #requests"},{"id":"8fdd949bc049c5169f2311ed2e5263f5","title":"Stylish Chrome Extension: github.com - stylised to be black as the white is a bit intense on my eyes","content":"body,\n.discussion-timeline-actions {\n  background: #222;\n}\n\n.repohead.experiment-repo-nav {\n\tbackground-color: #444;\n}\n\n.pagehead {\n\tborder-color: #444;\n}\n\n.numbers-summary, \n.file, .timeline-comment {\n  background-color: #EEE;\n}\n\n.repository-meta,\n.gist-snippet-meta .description, \n.octofication .message p, \n.news .alert .simple .title, \n.gist-snippet-meta .creator, \nh1, h2, h3,\n.protip,\n.breadcrumb strong.final-path {\n\tcolor: #CCC;\n}\n\n.readme h1, h2, h3 {\n\tcolor: inherit;\n}\n\n.text-gray-dark, \n.text-gray,\n.muted-link {\n\tcolor: #CCC !important;\n}\n\n.link-gray-dark {\n\tcolor: #DDD !important;\n}\n\n.Box-row--focus-gray.navigation-focus .link-gray-dark {\n\tcolor: #4078c0 !important;\n}\n\n.timeline-comment-wrapper,\n.discussion-timeline-actions {\n\tborder-color: #222;\n}\n\na, .reponav-item,\n.gist-snippet-meta .gist-count-links\u003eli\u003ea,\n.user-mention, .team-mention, \n.underline-nav-item:hover, .underline-nav-item:focus,\na.subnav-item,\n.timeline-commits .commit-message\u003ecode a,\na.text-emphasized,\n.gh-header-meta .author,\n.commit .commit-title, .commit .commit-title a {\n\tcolor: #CCAD00;\n}\n\n.subnav-item.selected, .subnav-item.selected:hover, .subnav-item.selected:focus {\n\tbackground-color: #CCAD00;\n    border-color: #CCAD00;\n}\n\n.gist-snippet-meta .gist-count-links\u003eli\u003ea:hover {\n\tcolor: white;\n    background: none;\n}\n\n.reponav-item:hover,\n.repohead h1, \nsvg:not(:root), \n.news .alert .dashboard-event-icon, \n.underline-nav-item.selected {\n\tcolor: white;\n}\n\n.commit-group svg:not(:root),\n.tabnav-tab.selected svg:not(:root),\n.thread-subscribe-form svg:not(:root),\n.timeline-commits svg:not(:root),\n.pagehead-actions svg:not(:root),\n.readme svg:not(:root),\n.timeline-comment-header svg:not(:root),\n.gisthead svg:not(:root),\n.comment-form-head svg:not(:root),\n.file-info svg:not(:root),\n.file-header svg:not(:root),\n.subnav-search svg:not(:root),\n.table-list-header-toggle svg:not(:root),\n.Box-row--focus-gray.navigation-focus svg:not(:root),\n.file-header a {\n\tcolor: #222 !important;\n}\n\n.reponav svg:not(:root) {\n\tcolor: #777 !important;\n}\n\n.gist-header .header-logo-wordmark .octicon, \n.header-logo-invertocat .octicon-mark-github,\n.user-nav .octicon-plus, \n.reponav-item.selected:hover,\na.subnav-item:hover {\n\tcolor: #222;\n}\n\n.tooltipped {\n\tcolor: #666;\n}\n\n.file-navigation-option .input-group .form-control {\n\theight: 27px;\n}\n\n.user-profile-nav {\n\tbackground: none;\n    border-bottom-color: inherit;\n}\n\n.pr-toolbar, .diffbar {\n\tbackground: none;\n}\n\n.reponav-item:hover, .repohead h1, svg:not(:root), .news .alert .dashboard-event-icon, .underline-nav-item.selected {\n\tcolor: inherit;\n}\n","tags":""},{"id":"1017c8df0c3be2e0fd979fffa3fb80ff","title":"Configure Wrk https://github.com/wg/wrk (brew install wrk) with Lua to execute against multiple URLs","content":"$ docker run --rm -v \"$(pwd)/multi-request-json.lua\":/multi-request-json.lua -v \"$(pwd)/requests.json\":/requests.json czerasz/wrk-json wrk -c1 -t1 -d5s -s /multi-request-json.lua https://www.example.com\n\nmultiplerequests: Found 2 requests\nmultiplerequests: Found 2 requests\n\nRunning 5s test @ https://www.example.com\n\n  1 threads and 1 connections\n  Thread Stats   Avg      Stdev     Max   +/- Stdev\n    Latency   887.09ms  415.48ms   1.36s    60.00%\n    Req/Sec     0.60      0.55     1.00     60.00%\n  5 requests in 5.10s, 1.54MB read\n\nRequests/sec:      0.98\nTransfer/sec:    309.12KB\nFROM debian:jessie\nMAINTAINER Michał Czeraszkiewicz \u003cczerasz.hosting@gmail.com\u003e\n\n# Set the reset cache variable\nENV REFRESHED_AT 2015-06-15\n\nENV DEBIAN_FRONTEND noninteractive\n\n# Update packages list\nRUN apt-get update -y\n\n# Install useful packages\n# RUN apt-get install -y strace procps tree vim git curl wget gnuplot\n\n# Install required software\nRUN apt-get install -y git make build-essential libssl-dev\n\n# Install wrk - benchmarking software\n# Resource: https://github.com/wg/wrk/wiki/Installing-Wrk-on-Linux\nWORKDIR /tmp\n\nRUN git clone https://github.com/wg/wrk.git \u0026\u0026\\\n    cd wrk \u0026\u0026\\\n    make \u0026\u0026\\\n    mv wrk /usr/local/bin\n\n# Install Luarocks dependencies\nRUN apt-get install -y curl \\\n                       make \\\n                       unzip \\\n                       lua5.1 \\\n                       liblua5.1-dev\n\n# Install Luarocks - a lua package manager\nRUN curl http://keplerproject.github.io/luarocks/releases/luarocks-2.2.2.tar.gz -O \u0026\u0026\\\n    tar -xzvf luarocks-2.2.2.tar.gz \u0026\u0026\\\n    cd luarocks-2.2.2 \u0026\u0026\\\n    ./configure \u0026\u0026\\\n    make build \u0026\u0026\\\n    make install\n\n# Install the cjson package\nRUN luarocks install lua-cjson\n\nWORKDIR /\n\n# Cleanup\nRUN apt-get clean\nRUN rm -rf /var/lib/apt/lists/* /tmp/* /var/tmp/*\n\n# Raise the limits to successfully run benchmarks\nRUN ulimit -c -m -s -t unlimited\n\nENV DEBIAN_FRONTEND=newt\n-- http://czerasz.com/2015/07/19/wrk-http-benchmarking-tool-example/\n-- https://github.com/czerasz/docker-wrk-json\n-- docker run --rm -v \"$(pwd)/multi-request-json.lua\":/multi-request-json.lua -v \"$(pwd)/requests.json\":/requests.json czerasz/wrk-json wrk -c1 -t1 -d5s -s /multi-request-json.lua https://www.example.com\n\n-- TRIED LOCAL SETUP ON MAC BUT MODULE STILL COULDN'T BE FOUND...\n-- sudo luarocks install lua-cjson\n-- package.path = package.path .. ';/usr/local/lib/luarocks/rocks-5.2/?/?.lua'\n-- wrk -c1 -t1 -d5s -s multi-request-json.lua https://www.example.com\n\n-- Module instantiation\nlocal cjson = require \"cjson\"\nlocal cjson2 = cjson.new()\nlocal cjson_safe = require \"cjson.safe\"\n\n-- Initialize the pseudo random number generator\n-- Resource: http://lua-users.org/wiki/MathLibraryTutorial\nmath.randomseed(os.time())\nmath.random(); math.random(); math.random()\n\n-- Shuffle array\n-- Returns a randomly shuffled array\nfunction shuffle(paths)\n  local j, k\n  local n = #paths\n\n  for i = 1, n do\n    j, k = math.random(n), math.random(n)\n    paths[j], paths[k] = paths[k], paths[j]\n  end\n\n  return paths\nend\n\n-- Load URL paths from the file\nfunction load_request_objects_from_file(file)\n  local data = {}\n  local content\n\n  -- Check if the file exists\n  -- Resource: http://stackoverflow.com/a/4991602/325852\n  local f=io.open(file,\"r\")\n  if f~=nil then\n    content = f:read(\"*all\")\n\n    io.close(f)\n  else\n    -- Return the empty array\n    return lines\n  end\n\n  -- Translate Lua value to/from JSON\n  data = cjson.decode(content)\n\n  return shuffle(data)\nend\n\n-- Load URL requests from file\nrequests = load_request_objects_from_file(\"/requests.json\")\n\n-- Check if at least one path was found in the file\nif #requests \u003c= 0 then\n  print(\"multiplerequests: No requests found.\")\n  os.exit()\nend\n\nprint(\"multiplerequests: Found \" .. #requests .. \" requests\")\n\n-- Initialize the requests array iterator\ncounter = 1\n\nrequest = function()\n  -- Get the next requests array element\n  local request_object = requests[counter]\n\n  -- Increment the counter\n  counter = counter + 1\n\n  -- If the counter is longer than the requests array length then reset it\n  if counter \u003e #requests then\n    counter = 1\n  end\n\n  -- Return the request object with the current URL path\n  return wrk.format(request_object.method, request_object.path, request_object.headers, request_object.body)\nend\n[\n  {\n    \"path\": \"/bar\",\n    \"body\": \"some content\",\n    \"method\": \"GET\",\n    \"headers\": {\n      \"X-Custom-Header-1\": \"test 1\",\n      \"X-Custom-Header-2\": \"test 2\"\n    }\n  },\n  {\n    \"path\": \"/baz\",\n    \"body\": \"some content\",\n    \"method\": \"GET\",\n    \"headers\": {\n      \"X-Custom-Header-1\": \"test 3\",\n      \"X-Custom-Header-2\": \"test 4\"\n    }\n  }\n]\n","tags":""},{"id":"11e10dd3acf972dd97f5c122db531162","title":"Install more recent version of Siege (https://github.com/JoeDog/siege) inside of a Docker container","content":"docker build -t integralist/siege .\n\n# docker run -v \"$HOME/Downloads/siege-urls.txt\":/urls.txt integralist/siege -b -H \"Host: foo.example.com\" -v -c 150 -t 30s -f /urls.txt\n\ndocker run integralist/siege\n\nNew configuration template added to /root/.siege\nRun siege -C to view the current settings in that file\nUsage: siege [options]\n       siege [options] URL\n       siege -g URL\nOptions:\n  -V, --version             VERSION, prints the version number.\n  -h, --help                HELP, prints this section.\n  -C, --config              CONFIGURATION, show the current config.\n  -v, --verbose             VERBOSE, prints notification to screen.\n  -q, --quiet               QUIET turns verbose off and suppresses output.\n  -g, --get                 GET, pull down HTTP headers and display the\n                            transaction. Great for application debugging.\n  -c, --concurrent=NUM      CONCURRENT users, default is 10\n  -r, --reps=NUM            REPS, number of times to run the test.\n  -t, --time=NUMm           TIMED testing where \"m\" is modifier S, M, or H\n                            ex: --time=1H, one hour test.\n  -d, --delay=NUM           Time DELAY, random delay before each requst\n  -b, --benchmark           BENCHMARK: no delays between requests.\n  -i, --internet            INTERNET user simulation, hits URLs randomly.\n  -f, --file=FILE           FILE, select a specific URLS FILE.\n  -R, --rc=FILE             RC, specify an siegerc file\n  -l, --log[=FILE]          LOG to FILE. If FILE is not specified, the\n                            default is used: PREFIX/var/siege.log\n  -m, --mark=\"text\"         MARK, mark the log file with a string.\n                            between .001 and NUM. (NOT COUNTED IN STATS)\n  -H, --header=\"text\"       Add a header to request (can be many)\n  -A, --user-agent=\"text\"   Sets User-Agent in request\n  -T, --content-type=\"text\" Sets Content-Type in request\n\nCopyright (C) 2016 by Jeffrey Fulmer, et al.\nThis is free software; see the source for copying conditions.\nThere is NO warranty; not even for MERCHANTABILITY or FITNESS\nFOR A PARTICULAR PURPOSE.\n\n[alert] Zip encoding disabled; siege requires zlib support to enable it: No such file or directory\nSIEGE 4.0.2\nFROM ubuntu:latest\nMAINTAINER Integralist \"mark.mcdx@gmail.com\"\n\nENV VERSION=4.0.2\nENV DEBIAN_FRONTEND noninteractive\n\nRUN apt-get update \\\n      \u0026\u0026 apt-get install -y curl g++ make libssl-dev \\\n      \u0026\u0026 curl http://download.joedog.org/siege/siege-$VERSION.tar.gz \u003e siege-$VERSION.tar.gz \\\n      \u0026\u0026 tar -xf siege-${VERSION}.tar.gz \\\n      \u0026\u0026 cd siege-${VERSION} \\\n      \u0026\u0026 ./configure \\\n      \u0026\u0026 make install \\\n      \u0026\u0026 apt-get clean \\\n      \u0026\u0026 rm -rf /var/lib/apt/lists\n\n# Raise the limits to successfully run benchmarks\nRUN ulimit -c -m -s -t unlimited\n\nENTRYPOINT [\"siege\"]\nCMD [\"--help\"]\n","tags":""},{"id":"16c24949a076ea5554a45a7c2001e9a4","title":"[Simple Bash File Watcher] ","content":"if [ \"$#\" -ne 1 ]; then\n  echo \"ERROR: directory is required.\"\n  exit 1\nfi\n\nDIRECTORY=$1\n\ncheckSum1=\"\"\n\nwhile [[ true ]]\ndo\n  checkSum2=`find $DIRECTORY -type f \\( -iname \"*.go\" \\) -exec md5 {} \\;`\n  \n  if [[ $checkSum1 != $checkSum2 ]] ; then\n\t# do something like run a test suite\n    \n    # update last seen checksum\n    checkSum1=$checkSum2\n  fi\n  \n  # don't overload the system\n  sleep 2\ndone\n","tags":"#tags: bash, watcher, polling"},{"id":"90499f2bb24073ec5eb487020078a582","title":"[Golang CLI Flags and Subcommands] ","content":"// this is the consumer of the code\n\npackage main\n\nimport (\n\t\"fmt\"\n\t\"os\"\n\n\tflag \"github.com/integralist/go-flags/flags\"\n)\n\nfunc main() {\n\t// standalone flags (i.e. no command necessary)\n\t//\n\t// examples: app -debug\n\t//           app -d\n\t//\n\tflags := flag.Flags{\n\t\t{\"debug\", \"d\", \"bool\", \"description\"},\n\t}\n\n\t// flags for the foo command\n\t//\n\tfooFlags := flag.Flags{\n\t\t{\"AAA\", \"a\", \"string\", \"description\"},\n\t\t{\"BBB\", \"b\", \"int\", \"description\"},\n\t}\n\n\t// flags for the bar command\n\t//\n\tbarFlags := flag.Flags{\n\t\t{\"CCC\", \"c\", \"bool\", \"description\"},\n\t}\n\n\t// commands\n\t//\n\t// examples: app foo\n\t//           app foo -a test -b 123\n\t//           app bar -c\n\t//           app baz\n\t//\n\tcommands := flag.Commands{\n\t\t{\"foo\", fooFlags},\n\t\t{\"bar\", barFlags},\n\t\t{\"baz\", nil},\n\t}\n\n\tschema := \u0026flag.Schema{\n\t\tFlags:    flags,\n\t\tCommands: commands,\n\t}\n\n\t// produces the following data structure...\n\t//\n\t// \u0026{\n\t// \tCommands:[\n\t// \t\t{\n\t// \t\t\tName:foo\n\t// \t\t\tFlags:[\n\t// \t\t\t\t{Verbose:AAA Short:a Type:string Usage:description}\n\t// \t\t\t\t{Verbose:BBB Short:b Type:int Usage:description}\n\t// \t\t\t]\n\t// \t\t}\n\t// \t\t{\n\t// \t\t\tName:bar\n\t// \t\t\tFlags:[\n\t// \t\t\t\t{Verbose:CCC Short:c Type:bool Usage:description}\n\t// \t\t\t]\n\t// \t\t}\n\t// \t\t{\n\t// \t\t\tName:baz\n\t// \t\t\tFlags:[]\n\t// \t\t}\n\t// \t]\n\t// \tFlags:[\n\t// \t\t{Verbose:debug Short:d Type:bool Usage:description}\n\t// \t]\n\t// }\n\n\t// TODO: should 'no args' really be an error?\n\t//\n\tfd, err := schema.Parse()\n\tif err != nil \u0026\u0026 err != flag.ErrNoArgs {\n\t\tfmt.Printf(\"something unexpected happened: %w\", err)\n\t\tos.Exit(1)\n\t}\n\n\tif fd.Cmd == \"\" {\n\t\tfmt.Println(\"no recognized flag or command was provided\")\n\t} else {\n\t\tfmt.Println(\"command executed:\", fd.Cmd)\n\t}\n\n  \t// TODO: figure out how to get at the other fields?\n  \t//\n\t// fmt.Println(fd.Debug, fd.D, fd.AAA, fd.A, fd.BBB, fd.B, fd.CCC, fd.C)\n  \t//\n  \t// ...because we can't type assert the returned data structure.\n}\n// builder.go uses reflection to dynamically generate a struct.\n// the struct will contain the parsed flag values.\n//\n// the struct generation code was extracted from the great work done by:\n// https://github.com/Ompluscator/dynamic-struct\n// so all credit for that code goes to him.\n//\npackage flags\n\nimport (\n\t\"reflect\"\n)\n\n// DynamicStruct contains defined dynamic struct.\n// This definition can't be changed anymore, once is built.\n// It provides a method for creating new instances of same defintion.\ntype DynamicStruct interface {\n\t// New provides new instance of defined dynamic struct.\n\t//\n\t// value := dStruct.New()\n\t//\n\tNew() interface{}\n}\n\n// Builder holds all fields' definitions for desired structs.\ntype Builder interface {\n\t// AddField creates new struct's field.\n\t// It expects field's name, type and string.\n\t// Type is provided as an instance of some golang type.\n\t// Tag is provided as classical golang field tag.\n\t//\n\t// builder.AddField(\"SomeFloatField\", 0.0, `json:\"boolean\" validate:\"gte=10\"`)\n\t//\n\tAddField(name string, typ interface{}, tag string) Builder\n\n\t// Build returns definition for dynamic struct.\n\t// Definition can be used to create new instances.\n\t//\n\t// dStruct := builder.Build()\n\t//\n\tBuild() DynamicStruct\n}\n\ntype dynamicStructImpl struct {\n\tdefinition reflect.Type\n}\n\ntype fieldConfigImpl struct {\n\ttyp interface{}\n\ttag string\n}\n\ntype builderImpl struct {\n\tfields map[string]*fieldConfigImpl\n}\n\nfunc (b *builderImpl) AddField(name string, typ interface{}, tag string) Builder {\n\tb.fields[name] = \u0026fieldConfigImpl{\n\t\ttyp: typ,\n\t\ttag: tag,\n\t}\n\n\treturn b\n}\n\nfunc (b *builderImpl) Build() DynamicStruct {\n\tvar structFields []reflect.StructField\n\n\tfor name, field := range b.fields {\n\t\tstructFields = append(structFields, reflect.StructField{\n\t\t\tName: name,\n\t\t\tType: reflect.TypeOf(field.typ),\n\t\t\tTag:  reflect.StructTag(field.tag),\n\t\t})\n\t}\n\n\treturn \u0026dynamicStructImpl{\n\t\tdefinition: reflect.StructOf(structFields),\n\t}\n}\n\nfunc (ds *dynamicStructImpl) New() interface{} {\n\treturn reflect.New(ds.definition).Interface()\n}\n\n// NewStruct returns new clean instance of Builder interface\n// for defining fresh dynamic struct.\n//\n// builder := NewStruct()\n//\nfunc NewStruct() Builder {\n\treturn \u0026builderImpl{\n\t\tfields: map[string]*fieldConfigImpl{},\n\t}\n}\npackage flags\n\nimport (\n\t\"encoding/json\"\n\t\"errors\"\n\t\"flag\"\n\t\"fmt\"\n\t\"os\"\n\t\"strings\"\n)\n\nvar (\n\tErrNoArgs               = errors.New(\"no flags or commands provided\")\n\tErrCmdFlagParse         = errors.New(\"failed to parse the command flags\")\n\tErrInterpolationMarshal = errors.New(\"unable to parse interpolation map into json\")\n\tErrStructBuild          = errors.New(\"failed to dynamically generate struct\")\n)\n\ntype Data struct {\n\tCmd string\n}\n\ntype Flag struct {\n\tVerbose string\n\tShort   string\n\tType    string\n\tUsage   string\n}\n\ntype Flags []Flag\n\ntype Command struct {\n\tName  string\n\tFlags Flags\n}\n\ntype CommandParsed struct {\n\tCommand\n\tFlagSet *flag.FlagSet\n}\n\ntype Commands []Command\n\ntype Schema struct {\n\tCommands Commands\n\tFlags    Flags\n}\n\nfunc (s *Schema) Parse() (*Data, error) {\n\targs := os.Args[1:]\n\n\tif len(args) == 0 {\n\t\treturn \u0026Data{}, ErrNoArgs\n\t}\n\n\tfor _, f := range s.Flags {\n\t\tswitch f.Type {\n\t\tcase \"bool\":\n\t\t\tvar boolType bool\n\t\t\tflagValue := false\n\t\t\tflagUsage := f.Usage\n\n\t\t\tflag.BoolVar(\u0026boolType, f.Verbose, flagValue, flagUsage)\n\t\t\tflag.BoolVar(\u0026boolType, f.Short, flagValue, flagUsage+\" (shorthand)\")\n\t\tcase \"string\":\n\t\t\tvar stringType string\n\t\t\tflagValue := \"\"\n\t\t\tflagUsage := f.Usage\n\n\t\t\tflag.StringVar(\u0026stringType, f.Verbose, flagValue, flagUsage)\n\t\t\tflag.StringVar(\u0026stringType, f.Short, flagValue, flagUsage+\" (shorthand)\")\n\t\tcase \"int\":\n\t\t\tvar intType int\n\t\t\tflagValue := 0\n\t\t\tflagUsage := f.Usage\n\n\t\t\tflag.IntVar(\u0026intType, f.Verbose, flagValue, flagUsage)\n\t\t\tflag.IntVar(\u0026intType, f.Short, flagValue, flagUsage+\" (shorthand)\")\n\t\tcase \"float\":\n\t\t\tvar floatType float64\n\t\t\tflagValue := 0.0\n\t\t\tflagUsage := f.Usage\n\n\t\t\tflag.Float64Var(\u0026floatType, f.Verbose, flagValue, flagUsage)\n\t\t\tflag.Float64Var(\u0026floatType, f.Short, flagValue, flagUsage+\" (shorthand)\")\n\t\t}\n\t}\n\n\tflag.Parse()\n\n\tcmd := s.identifyCommand(args)\n\tcmdFlags := s.commandFlags(cmd, flag.Args())\n\n\tinstance := NewStruct()\n\n\tdata := make(map[string]interface{})\n\tdata[\"cmd\"] = cmd\n\n\tflag.VisitAll(func(f *flag.Flag) {\n\t\t// create zero value struct dynamically\n\t\t// later on we'll be able to populate it dynamically too\n\t\t//\n\t\tfor _, sf := range s.Flags {\n\t\t\tif sf.Verbose == f.Name || sf.Short == f.Name {\n\t\t\t\ttitle := strings.Title(f.Name)\n\t\t\t\ttag := fmt.Sprintf(`json:\"%s\"`, f.Name) // f.Name must be present in data bytes\n\t\t\t\tdata[f.Name] = f.Value\n\n\t\t\t\tswitch sf.Type {\n\t\t\t\tcase \"bool\":\n\t\t\t\t\tinstance.AddField(title, false, \"\")\n\t\t\t\tcase \"string\":\n\t\t\t\t\tinstance.AddField(title, \"\", tag)\n\t\t\t\tcase \"int\":\n\t\t\t\t\tinstance.AddField(title, 0, tag)\n\t\t\t\tcase \"float\":\n\t\t\t\t\tinstance.AddField(title, 0.0, tag)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t})\n\n\tcfs := s.commandFlagSet(cmd, cmdFlags)\n\n\terr := cfs.Parse(cmdFlags)\n\tif err != nil {\n\t\treturn \u0026Data{}, fmt.Errorf(\"%s %w\", ErrCmdFlagParse, err)\n\t}\n\n\tcfs.VisitAll(func(f *flag.Flag) {\n\t\t// create zero value struct dynamically\n\t\t// later on we'll be able to populate it dynamically too\n\t\t//\n\t\tfor _, c := range s.Commands {\n\t\t\tif c.Name == cmd {\n\t\t\t\tfor _, cf := range c.Flags {\n\t\t\t\t\tif cf.Verbose == f.Name || cf.Short == f.Name {\n\t\t\t\t\t\ttitle := strings.Title(f.Name)\n\t\t\t\t\t\ttag := fmt.Sprintf(`json:\"%s\"`, f.Name) // f.Name must be present in data bytes\n\n\t\t\t\t\t\t// TODO:\n\t\t\t\t\t\t//\n\t\t\t\t\t\t// figure out how to protect against a top-level flag and a command\n\t\t\t\t\t\t// flag both having the same field name.\n\t\t\t\t\t\t//\n\t\t\t\t\t\t// e.g. this should be a valid command:\n\t\t\t\t\t\t// app -debug foocmd -debug\n\t\t\t\t\t\t//\n\t\t\t\t\t\t// our current implementation would mean the command's -debug flag\n\t\t\t\t\t\t// would override the value in the top-level -debug. ok it's a\n\t\t\t\t\t\t// contrived example so it's unlikely to happen but it's not\n\t\t\t\t\t\t// impossible to want the same flag at both the top-level and at a\n\t\t\t\t\t\t// command specific level.\n\t\t\t\t\t\t//\n\t\t\t\t\t\tdata[f.Name] = f.Value\n\n\t\t\t\t\t\tswitch cf.Type {\n\t\t\t\t\t\tcase \"bool\":\n\t\t\t\t\t\t\tinstance.AddField(title, false, \"\")\n\t\t\t\t\t\tcase \"string\":\n\t\t\t\t\t\t\tinstance.AddField(title, \"\", tag)\n\t\t\t\t\t\tcase \"int\":\n\t\t\t\t\t\t\tinstance.AddField(title, 0, tag)\n\t\t\t\t\t\tcase \"float\":\n\t\t\t\t\t\t\tinstance.AddField(title, 0.0, tag)\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t})\n\n\tinstance.AddField(\"Cmd\", \"\", `json:\"cmd\"`)\n\tds := instance.Build().New()\n\n\tj, err := json.Marshal(data)\n\tif err != nil {\n\t\treturn \u0026Data{}, fmt.Errorf(\"%s %w\", ErrInterpolationMarshal, err)\n\t}\n\n\tfmt.Println(\"interpolated data:\", string(j))\n\n\terr = json.Unmarshal(j, \u0026ds)\n\tif err != nil {\n\t\treturn \u0026Data{}, fmt.Errorf(\"%s %w\", ErrStructBuild, err)\n\t}\n\n\t// TODO:\n\t//\n\t// figure out how to type assert interface{} to concrete type?\n\t// otherwise dynamically generating a struct is pointless :grimace:\n\n\tfmt.Printf(\"\\ndynamic struct data:\\n%+v\\n\\ntype:\\n%T\\n\\n\", ds, ds)\n\n\t// v := reflect.ValueOf(ds).Type()\n\n\t// var ei interface{} = ds\n\n\t// d, ok := ei.(*struct {\n\t// \tAAA   string \"json:\\\"AAA\\\"\"\n\t// \tBBB   int    \"json:\\\"BBB\\\"\"\n\t// \tA     string \"json:\\\"a\\\"\"\n\t// \tB     int    \"json:\\\"b\\\"\"\n\t// \tCmd   string \"json:\\\"cmd\\\"\"\n\t// \tD     bool\n\t// \tDebug bool\n\t// })\n\t// if !ok {\n\t// \tfmt.Println(\"uh-oh:\", d, ok)\n\t// }\n\t// fmt.Println(d.Cmd, d.Debug)\n\n\treturn \u0026Data{\n\t\tCmd: cmd,\n\t}, nil\n}\n\nfunc (s *Schema) commandFlagSet(cmd string, cmdFlags []string) *flag.FlagSet {\n\tfor _, c := range s.Commands {\n\t\tif c.Name == cmd {\n\t\t\tcfs := flag.NewFlagSet(c.Name, flag.ExitOnError)\n\n\t\t\tfor _, f := range c.Flags {\n\t\t\t\tswitch f.Type {\n\t\t\t\tcase \"bool\":\n\t\t\t\t\tvar boolType bool\n\t\t\t\t\tflagValue := false\n\t\t\t\t\tflagUsage := f.Usage\n\n\t\t\t\t\tcfs.BoolVar(\u0026boolType, f.Verbose, flagValue, flagUsage)\n\t\t\t\t\tcfs.BoolVar(\u0026boolType, f.Short, flagValue, flagUsage+\" (shorthand)\")\n\t\t\t\tcase \"string\":\n\t\t\t\t\tvar stringType string\n\t\t\t\t\tflagValue := \"\"\n\t\t\t\t\tflagUsage := f.Usage\n\n\t\t\t\t\tcfs.StringVar(\u0026stringType, f.Verbose, flagValue, flagUsage)\n\t\t\t\t\tcfs.StringVar(\u0026stringType, f.Short, flagValue, flagUsage+\" (shorthand)\")\n\t\t\t\tcase \"int\":\n\t\t\t\t\tvar intType int\n\t\t\t\t\tflagValue := 0\n\t\t\t\t\tflagUsage := f.Usage\n\n\t\t\t\t\tcfs.IntVar(\u0026intType, f.Verbose, flagValue, flagUsage)\n\t\t\t\t\tcfs.IntVar(\u0026intType, f.Short, flagValue, flagUsage+\" (shorthand)\")\n\t\t\t\tcase \"float\":\n\t\t\t\t\tvar floatType float64\n\t\t\t\t\tflagValue := 0.0\n\t\t\t\t\tflagUsage := f.Usage\n\n\t\t\t\t\tcfs.Float64Var(\u0026floatType, f.Verbose, flagValue, flagUsage)\n\t\t\t\t\tcfs.Float64Var(\u0026floatType, f.Short, flagValue, flagUsage+\" (shorthand)\")\n\t\t\t\t}\n\t\t\t}\n\n\t\t\treturn cfs\n\t\t}\n\t}\n\n\treturn \u0026flag.FlagSet{}\n}\n\nfunc (s *Schema) commandFlags(cmd string, args []string) []string {\n\tfor i, v := range args {\n\t\tif v == cmd {\n\t\t\treturn args[i+1:]\n\t\t}\n\t}\n\n\treturn []string{}\n}\n\nfunc (s *Schema) identifyCommand(args []string) string {\n\tcommandIndex := 0\n\tcommandSeen := false\n\n\tfor _, arg := range args {\n\t\tif commandSeen {\n\t\t\tbreak\n\t\t}\n\n\t\tif strings.HasPrefix(arg, \"-\") == true {\n\t\t\tcommandIndex++\n\t\t\tcontinue\n\t\t}\n\n\t\tfor _, cmd := range s.Commands {\n\t\t\tif arg == cmd.Name {\n\t\t\t\tcommandSeen = true\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\n\t\tif !commandSeen {\n\t\t\tcommandIndex++\n\t\t}\n\t}\n\n\tif !commandSeen {\n\t\treturn \"\"\n\t}\n\n\treturn args[commandIndex]\n}\npackage main\n\nimport (\n\t\"errors\"\n\t\"flag\"\n\t\"fmt\"\n\t\"os\"\n\t\"reflect\"\n\t\"strings\"\n)\n\nvar (\n\tErrNoArgs = errors.New(\"no flags or commands provided\")\n)\n\ntype Schema struct {\n\tDebug   bool   `short:\"d\" usage:\"enable debug level logs\"`\n\tNumber  int    `short:\"n\" usage:\"a number field\"`\n\tMessage string `short:\"m\" usage:\"a message field\"`\n\tFoo     struct {\n\t\tAAA string `short:\"a\" usage:\"does A\"`\n\t\tBBB string `short:\"b\" usage:\"does B\"`\n\t}\n\tBar struct {\n\t\tCCC bool `short:\"c\" usage:\"does C\"`\n\t}\n}\n\nfunc Parse(s interface{}) error {\n\targs := os.Args[1:]\n\tif len(args) == 0 {\n\t\treturn ErrNoArgs\n\t}\n\n\tst := reflect.TypeOf(s).Elem()\n\tv := reflect.ValueOf(s)\n\tv = reflect.Indirect(v)\n\n\tIterFields(st, v, func(field reflect.Value, sf reflect.StructField) {\n\t\tswitch field.Kind() {\n\t\tcase reflect.Bool:\n\t\t\tvar v bool\n\t\t\tflag.BoolVar(\u0026v, strings.ToLower(sf.Name), false, sf.Tag.Get(\"usage\"))\n\t\t\tflag.BoolVar(\u0026v, sf.Tag.Get(\"short\"), false, sf.Tag.Get(\"usage\")+\" (shorthand)\")\n\t\tcase reflect.Int:\n\t\t\tvar v int\n\t\t\tflag.IntVar(\u0026v, strings.ToLower(sf.Name), 0, sf.Tag.Get(\"usage\"))\n\t\t\tflag.IntVar(\u0026v, sf.Tag.Get(\"short\"), 0, sf.Tag.Get(\"usage\")+\" (shorthand)\")\n\t\tcase reflect.String:\n\t\t\tvar v string\n\t\t\tflag.StringVar(\u0026v, strings.ToLower(sf.Name), \"\", sf.Tag.Get(\"usage\"))\n\t\t\tflag.StringVar(\u0026v, sf.Tag.Get(\"short\"), \"\", sf.Tag.Get(\"usage\")+\" (shorthand)\")\n\t\t}\n\t})\n\n\tflag.Parse()\n\n\tIterFields(st, v, func(field reflect.Value, sf reflect.StructField) {\n\t\tflag.Visit(func(f *flag.Flag) {\n\t\t\tgetter, ok := f.Value.(flag.Getter)\n\t\t\tif ok {\n\t\t\t\tif f.Name == strings.ToLower(sf.Name) || f.Name == sf.Tag.Get(\"short\") {\n\t\t\t\t\tswitch field.Kind() {\n\t\t\t\t\tcase reflect.Bool:\n\t\t\t\t\t\tif b, ok := getter.Get().(bool); ok {\n\t\t\t\t\t\t\tfield.Set(reflect.ValueOf(b))\n\t\t\t\t\t\t}\n\t\t\t\t\tcase reflect.Int:\n\t\t\t\t\t\tif i, ok := getter.Get().(int); ok {\n\t\t\t\t\t\t\tfield.Set(reflect.ValueOf(i))\n\t\t\t\t\t\t}\n\t\t\t\t\tcase reflect.String:\n\t\t\t\t\t\tif s, ok := getter.Get().(string); ok {\n\t\t\t\t\t\t\tfield.Set(reflect.ValueOf(s))\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t})\n\t})\n\n\tcmds := []string{\"foo\", \"bar\", \"baz\"}\n\tcmd := IdentifyCommand(cmds, args)\n\tcmdFlags := CommandFlags(cmd, flag.Args())\n\n\tcfs := CommandFlagSet(cmd, cmdFlags, st, v)\n\terr := cfs.Parse(cmdFlags)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tIterFields(st, v, func(field reflect.Value, sf reflect.StructField) {\n\t\tcfs.Visit(func(f *flag.Flag) {\n\t\t\tgetter, ok := f.Value.(flag.Getter)\n\t\t\tif ok {\n\t\t\t\tif f.Name == strings.ToLower(sf.Name) || f.Name == sf.Tag.Get(\"short\") {\n\t\t\t\t\tswitch field.Kind() {\n\t\t\t\t\tcase reflect.Bool:\n\t\t\t\t\t\tif b, ok := getter.Get().(bool); ok {\n\t\t\t\t\t\t\tfield.Set(reflect.ValueOf(b))\n\t\t\t\t\t\t}\n\t\t\t\t\tcase reflect.Int:\n\t\t\t\t\t\tif i, ok := getter.Get().(int); ok {\n\t\t\t\t\t\t\tfield.Set(reflect.ValueOf(i))\n\t\t\t\t\t\t}\n\t\t\t\t\tcase reflect.String:\n\t\t\t\t\t\tif s, ok := getter.Get().(string); ok {\n\t\t\t\t\t\t\tfield.Set(reflect.ValueOf(s))\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t})\n\t})\n\n\treturn nil\n}\n\n// IterFields iterates over all fields of a struct, including nested structs,\n// and processes their individual fields by passing them into a callback.\n//\nfunc IterFields(st reflect.Type, v reflect.Value, fn func(f reflect.Value, sf reflect.StructField)) {\n\tfor i := 0; i \u003c v.NumField(); i++ {\n\t\tfield := v.Field(i)\n\t\tsf := st.Field(i)\n\n\t\tif field.Kind() == reflect.Struct {\n\t\t\tst := reflect.TypeOf(field.Interface())\n\n\t\t\tfor i := 0; i \u003c st.NumField(); i++ {\n\t\t\t\tfield := field.Field(i)\n\t\t\t\tst := st.Field(i)\n\n\t\t\t\tif field.CanSet() {\n\t\t\t\t\tfn(field, st)\n\t\t\t\t}\n\t\t\t}\n\t\t} else if field.CanSet() {\n\t\t\tfn(field, sf)\n\t\t}\n\t}\n}\n\n// IdentifyCommand parses the arguments provided looking for a 'command'.\n//\n// this implementation presumes that the format of the arguments will be...\n//\n// \u003cprogram\u003e \u003cflag(s)\u003e \u003ccommand\u003e \u003cflag(s) for command\u003e\n//\nfunc IdentifyCommand(cmds, args []string) string {\n\tcommandIndex := 0\n\tcommandSeen := false\n\n\tfor _, arg := range args {\n\t\tif commandSeen {\n\t\t\tbreak\n\t\t}\n\n\t\tif strings.HasPrefix(arg, \"-\") == true {\n\t\t\tcommandIndex++\n\t\t\tcontinue\n\t\t}\n\n\t\tfor _, cmd := range cmds {\n\t\t\tif arg == cmd {\n\t\t\t\tcommandSeen = true\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\n\t\tif !commandSeen {\n\t\t\tcommandIndex++\n\t\t}\n\t}\n\n\tif !commandSeen {\n\t\treturn \"\"\n\t}\n\n\treturn args[commandIndex]\n}\n\n// CommandFlags parses the flags that are provided after the 'command'.\n//\nfunc CommandFlags(cmd string, args []string) []string {\n\tfor i, v := range args {\n\t\tif v == cmd {\n\t\t\treturn args[i+1:]\n\t\t}\n\t}\n\n\treturn []string{}\n}\n\n// CommandFlagSet defines flags for the command as a FlagSet.\n//\nfunc CommandFlagSet(cmd string, cmdFlags []string, st reflect.Type, v reflect.Value) *flag.FlagSet {\n\tcfs := flag.NewFlagSet(cmd, flag.ExitOnError)\n\n\tIterFields(st, v, func(field reflect.Value, sf reflect.StructField) {\n\t\tswitch field.Kind() {\n\t\tcase reflect.Bool:\n\t\t\tvar v bool\n\t\t\tcfs.BoolVar(\u0026v, strings.ToLower(sf.Name), false, sf.Tag.Get(\"usage\"))\n\t\t\tcfs.BoolVar(\u0026v, sf.Tag.Get(\"short\"), false, sf.Tag.Get(\"usage\")+\" (shorthand)\")\n\t\tcase reflect.Int:\n\t\t\tvar v int\n\t\t\tcfs.IntVar(\u0026v, strings.ToLower(sf.Name), 0, sf.Tag.Get(\"usage\"))\n\t\t\tcfs.IntVar(\u0026v, sf.Tag.Get(\"short\"), 0, sf.Tag.Get(\"usage\")+\" (shorthand)\")\n\t\tcase reflect.String:\n\t\t\tvar v string\n\t\t\tcfs.StringVar(\u0026v, strings.ToLower(sf.Name), \"\", sf.Tag.Get(\"usage\"))\n\t\t\tcfs.StringVar(\u0026v, sf.Tag.Get(\"short\"), \"\", sf.Tag.Get(\"usage\")+\" (shorthand)\")\n\t\t}\n\t})\n\n\treturn cfs\n}\n\n// EXAMPLE:\n//\n// go run test_flags.go -debug -n 123 -m \"something here\" foo -a foobar -b 666\n//\nfunc main() {\n\tvar s Schema\n\n\terr := Parse(\u0026s)\n\tif err != nil {\n\t\tfmt.Printf(\"error parsing schema: %v\\n\", err)\n\t\tos.Exit(1)\n\t}\n\n\tfmt.Printf(\"\\nfinal struct: %+v\\n\", s)\n\t/*\n\t\tOutput:\n\n\t\t{\n\t\t\tDebug:true\n\t\t\tNumber:123\n\t\t\tMessage:something here\n\t\t\tFoo:{\n\t\t\t\tAAA:foobar\n\t\t\t\tBBB:666\n\t\t\t}\n\t\t\tBar:{\n\t\t\t\tCCC:false\n\t\t\t}\n\t\t}\n\t*/\n\n\tfmt.Printf(\"\\nDebug: %+v\\n\", s.Debug)   // true\n\tfmt.Printf(\"Number: %+v\\n\", s.Number)   // 123\n\tfmt.Printf(\"Message: %+v\\n\", s.Message) // something here\n\tfmt.Printf(\"AAA: %+v\\n\", s.Foo.AAA)     // foobar\n\tfmt.Printf(\"BBB: %+v\\n\", s.Foo.BBB)     // 666\n\tfmt.Printf(\"CCC: %+v\\n\", s.Bar.CCC)     // false\n}\nThree approaches...\n\n1. Flags are known up front. 👌🏻\n2. Flags are defined by user (ugly data structure). ❌\n3. Flags are defined by user (dynamic struct creation BUT doesn't work fully) ❌\n4. Flags are defined by user (dynamic population of a struct provided by the user) ✅\n\n## `flag.FlagSet` ?\n\n**Note**: the trick to understanding `flag.NewFlagSet` is that you have to pass it a string of command line args that you need it to parse. `flag.Parse` is able to do this automatically for you, but a flag set is expected to work with a _subset_ of the arguments provided to the program when it's being run. The way I typically do this is as follows...\n\nA simple FlagSet example:\n\n```go\npackage main\n\nimport (\n\t\"fmt\"\n\t\"os\"\n\n\t\"github.com/integralist/go-gitbranch/internal/pkg/create\"\n)\n\nfunc main() {\n\targs := os.Args[1:]\n\n\tif len(args) == 0 {\n\t\tfmt.Println(\"no subcommand provided\")\n\t\tos.Exit(1)\n\t}\n\n\tswitch args[0] {\n\tcase \"create\":\n\t\tflags := create.ParseFlags(args[1:])\n\t\tfmt.Println(\"name:\", flags.Name)\n\tcase \"rename\":\n\t\t//\n\tcase \"checkout\":\n\t\t//\n\tcase \"delete\":\n\t\t//\n\t}\n}\n\n////////////////////////////////////////////////////////////////////////\n\npackage create\n\nimport (\n\t\"flag\"\n)\n\ntype Flags struct {\n\tName string\n}\n\n// ParseFlags defines and parses flags for the create subcommand.\nfunc ParseFlags(args []string) Flags {\n\tfs := flag.NewFlagSet(\"create\", flag.ExitOnError)\n\tname := fs.String(\"name\", \"\", \"name of the branch to create\")\n\tfs.Parse(args)\n\n\treturn Flags{\n\t\tName: *name,\n\t}\n}\n```\n\nMore context for identifying subcommands dynamically...\n\n```go\n// Example: app -debug foo -x 1 -y 2\n\n// define flag(s), in this case a -debug flag, then parse it...\nflag.Parse()\n\n// slice args from after the program name \"app\" (so `args` = `-debug foo -x 1 -y 2`)\nargs := os.Args[1:]\n\n// identify the command (\"foo\" in this case)\ncmd := identifyCommand(args)\n\n// identify the command's flags (\"-x 1 -y 2\" in this case)\ncmdFlags := commandFlags(cmd, flag.Args())\n\n// identifyCommand parses the arguments provided looking for a 'command'\n//\n// this implementation presumes that the format of the arguments will be...\n//\n// \u003cprogram\u003e \u003cflag(s)\u003e \u003ccommand\u003e \u003cflag(s) for command\u003e\n//\nfunc identifyCommand(args []string) string {\n  \t// list of supported/known commands...\n \tcommands := []string{\"foo\", \"bar\", \"baz\"}\n  \n\tcommandIndex := 0\n\tcommandSeen := false\n\n\tfor _, arg := range args {\n\t\tif commandSeen {\n\t\t\tbreak\n\t\t}\n\n\t\tif strings.HasPrefix(arg, \"-\") == true {\n\t\t\tcommandIndex++\n\t\t\tcontinue\n\t\t}\n\n\t\tfor _, cmd := range commands {\n\t\t\tif arg == cmd.Name {\n\t\t\t\tcommandSeen = true\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\n\t\tif !commandSeen {\n\t\t\tcommandIndex++\n\t\t}\n\t}\n\n\tif !commandSeen {\n\t\treturn \"\"\n\t}\n\n\treturn args[commandIndex]\n}\n\n// commandFlags parses out the arguments that are meant for the new flag set.\n//\n// args: flag.Args()\n// cmd: the point in the list of arguments where you want to slice from.\n//\n// Example: app -debug foo -x 1 -y 2\n//\n// the `cmd` would be foo, and so we want to return a slice starting from the flag -x\n// for the FlagSet to parse.\n//\nfunc commandFlags(cmd string, args []string) []string {\n\tfor i, v := range args {\n\t\tif v == cmd {\n\t\t\treturn args[i+1:]\n\t\t}\n\t}\n\n\treturn []string{}\n}\n\n// I've not provided an implementation for commandFlagSet but it basically\n// defines a bunch of flags off a cfs variable and returns a *flag.FlagSet\n//\n// Example: \n// cfs := flag.NewFlagSet(\"foo\", flag.ExitOnError)\n// cfs.String(...)\n//\ncfs := commandFlagSet(cmd, cmdFlags)\n\nerr := cfs.Parse(cmdFlags)\nif err != nil {\n\t// ...\n}\n\n// NOTE: flag.Parse type will also have Visit/VisitAll methods.\n//\ncfs.VisitAll(func(f *flag.Flag) {\n\t// check value of every flag\n})\n```\n/* \ngo run fastly.go diff -foo\n\nUsage of diff:\n  -foo string\n        default (default \"desc\")\n\ngo run fastly.go -debug diff  // enables debug logs \n*/\n\npackage main\n\nimport (\n\t\"flag\"\n\t\"flags\"\n\t\"fmt\"\n\t\"os\"\n\n\t\"github.com/sirupsen/logrus\"\n)\n\n// AppVersion is the application version\nconst AppVersion = \"0.0.1\"\n\nvar logger *logrus.Entry\n\nfunc init() {\n\tlogrus.SetFormatter(\u0026logrus.JSONFormatter{})\n\tlogrus.SetLevel(logrus.InfoLevel)\n\tlogger = logrus.WithFields(logrus.Fields{\n\t\t\"package\": \"main\",\n\t})\n}\n\nfunc main() {\n\tf := flags.New()\n\n\tif *f.Top.Help == true {\n\t\tflag.PrintDefaults()\n\t\tos.Exit(1)\n\t}\n\n\tif *f.Top.Version == true {\n\t\tfmt.Println(AppVersion)\n\t\tos.Exit(1)\n\t}\n\n\tif *f.Top.Debug == true {\n\t\tlogrus.SetLevel(logrus.DebugLevel)\n\t}\n\n\tlogger.Debug(\"application starting\")\n\n\targs := os.Args[1:] // strip first arg `fastly`\n\targ, counter := flags.Check(args)\n\n\tswitch arg {\n\tcase \"diff\":\n\t\tf.Top.Diff.Parse(args[counter:])\n\tcase \"upload\":\n\t\tf.Top.Upload.Parse(args[counter:])\n\tdefault:\n\t\tfmt.Printf(\"%v is not valid command.\\n\", arg)\n\t\tos.Exit(1)\n\t}\n}\n// flags/flags.go\n\npackage flags\n\nimport (\n\t\"flag\"\n\t\"os\"\n\t\"strings\"\n\n\t\"github.com/sirupsen/logrus\"\n)\n\nvar logger *logrus.Entry\n\nfunc init() {\n\tlogger = logrus.WithFields(logrus.Fields{\n\t\t\"package\": \"flags\",\n\t})\n}\n\n// TopLevelFlags defines the common settings across all commands\ntype TopLevelFlags struct {\n\tHelp, Debug, Version                   *bool\n\tToken, Service, Directory, Match, Skip *string\n\tDiff, Upload                           *flag.FlagSet\n}\n\n// SubCommandFlags defines the settings for the subcommands\ntype SubCommandFlags struct {\n\tFoo, Bar *string\n}\n\n// Flags defines type of structure returned to user\ntype Flags struct {\n\tTop TopLevelFlags\n\tSub SubCommandFlags\n}\n\n// New returns defined flags\nfunc New() Flags {\n\ttopLevelFlags := TopLevelFlags{\n\t\tHelp:      flag.Bool(\"help\", false, \"show available flags\"),\n\t\tDebug:     flag.Bool(\"debug\", false, \"show any error/diff output + debug logs\"),\n\t\tVersion:   flag.Bool(\"version\", false, \"show application version\"),\n\t\tToken:     flag.String(\"token\", os.Getenv(\"FASTLY_API_TOKEN\"), \"your fastly api token (fallback: FASTLY_API_TOKEN)\"),\n\t\tService:   flag.String(\"service\", os.Getenv(\"FASTLY_SERVICE_ID\"), \"your service id (fallback: FASTLY_SERVICE_ID)\"),\n\t\tDirectory: flag.String(\"dir\", os.Getenv(\"VCL_DIRECTORY\"), \"vcl directory to compare files against\"),\n\t\tMatch:     flag.String(\"match\", \"\", \"regex for matching vcl directories (will also try: VCL_MATCH_DIRECTORY)\"),\n\t\tSkip:      flag.String(\"skip\", \"^____\", \"regex for skipping vcl directories (will also try: VCL_SKIP_DIRECTORY)\"),\n\t\tDiff:      flag.NewFlagSet(\"diff\", flag.ExitOnError),\n\t\tUpload:    flag.NewFlagSet(\"upload\", flag.ExitOnError),\n\t}\n\tflag.Parse()\n\n\tsubCommandFlags := SubCommandFlags{\n\t\tFoo: topLevelFlags.Diff.String(\"foo\", \"foo is upload only\", \"foo default\"),\n\t\tBar: topLevelFlags.Upload.String(\"bar\", \"bar is upload only\", \"bar default\"),\n\t}\n\n\treturn Flags{\n\t\tTop: topLevelFlags,\n\t\tSub: subCommandFlags,\n\t}\n}\n\n// Check determines if a flag was specified before the subcommand\n// Then returns the subcommand argument value based on the correct index\n// Followed by the index of where the subcommand's flags start in the args list\nfunc Check(args []string) (string, int) {\n\tcounter := 0\n\tsubcommandSeen := false\n\n\tfor _, arg := range args {\n\t\tif subcommandSeen {\n\t\t\tbreak\n\t\t}\n\n\t\tif strings.HasPrefix(arg, \"-\") == true {\n\t\t\tcounter++\n\t\t\tcontinue\n\t\t}\n\n\t\tif arg == \"diff\" || arg == \"upload\" {\n\t\t\tsubcommandSeen = true\n\t\t} else {\n\t\t\tcounter++\n\t\t}\n\t}\n\n\tsubcommandFlagsIndex := counter + 1\n\n\tlogger.WithFields(logrus.Fields{\n\t\t\"args\":       args,\n\t\t\"counter\":    counter,\n\t\t\"subcommand\": args[counter],\n\t\t\"index\":      subcommandFlagsIndex,\n\t}).Debug(\"subcommand selected\")\n\n\treturn args[counter], subcommandFlagsIndex\n}\npackage main\n\nimport (\n\t\"errors\"\n\t\"flag\"\n\t\"fmt\"\n\t\"os\"\n\t\"strings\"\n)\n\nvar (\n\tErrNoArgs       = errors.New(\"no flags or commands provided\")\n\tErrCmdFlagParse = errors.New(\"failed to parse the command flags\")\n)\n\ntype Flag struct {\n\tNameLong  string\n\tNameShort string\n\tDefault   interface{}\n\tUsage     string\n\tValue     interface{}\n}\n\ntype Flags []*Flag\n\ntype Command struct {\n\tName  string\n\tFlags Flags\n}\n\ntype Commands []Command\n\ntype Schema struct {\n\tCommands Commands\n\tFlags    Flags\n}\n\nfunc (s *Schema) Parse() error {\n\targs := os.Args[1:]\n\tif len(args) == 0 {\n\t\treturn ErrNoArgs\n\t}\n\n\tfor _, f := range s.Flags {\n\t\tswitch def := f.Default.(type) {\n\t\tcase bool:\n\t\t\tv, _ := f.Value.(bool)\n\t\t\tflag.BoolVar(\u0026v, f.NameLong, def, f.Usage)\n\t\t\tflag.BoolVar(\u0026v, f.NameShort, def, f.Usage+\" (shorthand)\")\n\t\tcase string:\n\t\t\tv, _ := f.Value.(string)\n\t\t\tflag.StringVar(\u0026v, f.NameLong, def, f.Usage)\n\t\t\tflag.StringVar(\u0026v, f.NameShort, def, f.Usage+\" (shorthand)\")\n\t\tcase int:\n\t\t\tv, _ := f.Value.(int)\n\t\t\tflag.IntVar(\u0026v, f.NameLong, def, f.Usage)\n\t\t\tflag.IntVar(\u0026v, f.NameShort, def, f.Usage+\" (shorthand)\")\n\t\tcase float64:\n\t\t\tv, _ := f.Value.(float64)\n\t\t\tflag.Float64Var(\u0026v, f.NameLong, def, f.Usage)\n\t\t\tflag.Float64Var(\u0026v, f.NameShort, def, f.Usage+\" (shorthand)\")\n\t\t}\n\t}\n\n\tflag.Parse()\n\n\tflag.VisitAll(func(f *flag.Flag) {\n\t\tfor _, sf := range s.Flags {\n\t\t\tif f.Name == sf.NameLong || f.Name == sf.NameShort {\n\t\t\t\tsf.Value = f.Value\n\t\t\t}\n\t\t}\n\t})\n\n\tcmd := s.identifyCommand(args)\n\tcmdFlags := s.commandFlags(cmd, flag.Args())\n\n\tfor _, c := range s.Commands {\n\t\tif c.Name == cmd {\n\t\t\tcfs := flag.NewFlagSet(c.Name, flag.ExitOnError)\n\n\t\t\tfor _, f := range c.Flags {\n\t\t\t\tswitch def := f.Default.(type) {\n\t\t\t\tcase bool:\n\t\t\t\t\tv, _ := f.Value.(bool)\n\t\t\t\t\tcfs.BoolVar(\u0026v, f.NameLong, def, f.Usage)\n\t\t\t\t\tcfs.BoolVar(\u0026v, f.NameShort, def, f.Usage+\" (shorthand)\")\n\t\t\t\tcase string:\n\t\t\t\t\tv, _ := f.Value.(string)\n\t\t\t\t\tcfs.StringVar(\u0026v, f.NameLong, def, f.Usage)\n\t\t\t\t\tcfs.StringVar(\u0026v, f.NameShort, def, f.Usage+\" (shorthand)\")\n\t\t\t\tcase int:\n\t\t\t\t\tv, _ := f.Value.(int)\n\t\t\t\t\tcfs.IntVar(\u0026v, f.NameLong, def, f.Usage)\n\t\t\t\t\tcfs.IntVar(\u0026v, f.NameShort, def, f.Usage+\" (shorthand)\")\n\t\t\t\tcase float64:\n\t\t\t\t\tv, _ := f.Value.(float64)\n\t\t\t\t\tcfs.Float64Var(\u0026v, f.NameLong, def, f.Usage)\n\t\t\t\t\tcfs.Float64Var(\u0026v, f.NameShort, def, f.Usage+\" (shorthand)\")\n\t\t\t\t}\n\t\t\t}\n\n\t\t\terr := cfs.Parse(cmdFlags)\n\t\t\tif err != nil {\n\t\t\t\treturn fmt.Errorf(\"%s %w\", ErrCmdFlagParse, err)\n\t\t\t}\n\n\t\t\tcfs.VisitAll(func(f *flag.Flag) {\n\t\t\t\tfor _, cf := range c.Flags {\n\t\t\t\t\tif cf.NameLong == f.Name || cf.NameShort == f.Name {\n\t\t\t\t\t\tcf.Value = f.Value\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t})\n\n\t\t\tbreak\n\t\t}\n\t}\n\n\treturn nil\n}\n\nfunc (s *Schema) identifyCommand(args []string) string {\n\tcommandIndex := 0\n\tcommandSeen := false\n\n\tfor _, arg := range args {\n\t\tif commandSeen {\n\t\t\tbreak\n\t\t}\n\n\t\tif strings.HasPrefix(arg, \"-\") == true {\n\t\t\tcommandIndex++\n\t\t\tcontinue\n\t\t}\n\n\t\tfor _, cmd := range s.Commands {\n\t\t\tif arg == cmd.Name {\n\t\t\t\tcommandSeen = true\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\n\t\tif !commandSeen {\n\t\t\tcommandIndex++\n\t\t}\n\t}\n\n\tif !commandSeen {\n\t\treturn \"\"\n\t}\n\n\treturn args[commandIndex]\n}\n\nfunc (s *Schema) commandFlags(cmd string, args []string) []string {\n\tfor i, v := range args {\n\t\tif v == cmd {\n\t\t\treturn args[i+1:]\n\t\t}\n\t}\n\n\treturn []string{}\n}\n\nfunc main() {\n\t// NOTE: when using verbose syntax and explicitly naming the Flag struct\n\t// type, then the field `Value` can be omitted. But with the short syntax\n\t// used below the compiler complains and so we have to pass `nil`.\n\t//\n\tflags := Flags{\n\t\t{\"debug\", \"d\", false, \"description\", nil},\n\t\t{\"number\", \"n\", 0, \"description\", nil},\n\t}\n\n\tfooFlags := Flags{\n\t\t{\"AAA\", \"a\", \"\", \"description\", nil},\n\t\t{\"BBB\", \"b\", 0, \"description\", nil},\n\t}\n\n\tbarFlags := Flags{\n\t\t{\"CCC\", \"c\", false, \"description\", nil},\n\t}\n\n\tcommands := Commands{\n\t\t{\"foo\", fooFlags},\n\t\t{\"bar\", barFlags},\n\t\t{\"baz\", nil},\n\t}\n\n\tschema := \u0026Schema{\n\t\tFlags:    flags,\n\t\tCommands: commands,\n\t}\n\n\terr := schema.Parse()\n\tif err != nil {\n\t\tfmt.Printf(\"error parsing schema: %v\\n\", err)\n\t\tos.Exit(1)\n\t}\n\n\t// NOTE: after running the following command we can access the values:\n\t//\n\t// go run test_flags.go -debug -n 123 foo -a foobar -b 666\n\t//\n\tfmt.Printf(\"schema: %+v\\n\", schema)\n\tfmt.Printf(\"schema.Flags[0].Value: %v\\n\", schema.Flags[0].Value)\n\tfmt.Printf(\"schema.Flags[1].Value: %v\\n\", schema.Flags[1].Value)\n\tfmt.Printf(\"schema.Commands[0].Flags[0].Value: %v\\n\", schema.Commands[0].Flags[0].Value)\n\tfmt.Printf(\"schema.Commands[0].Flags[1].Value: %v\\n\", schema.Commands[0].Flags[1].Value)\n\n\t// TODO: figure out better data strucuture for sake of user experience,\n\t// because having to dip into an array is nasty/fugly\n\t//\n}\n","tags":"#tags: golang, go, cli, flags, subcommands, logs, logging"},{"id":"344837ede1d85739fdfa05410db9ffee","title":"[Golang Reflection with Struct] ","content":"package main\n\nimport (\n\t\"fmt\"\n\t\"reflect\"\n)\n\nfunc main() {\n\tf := \"foo\"\n\tb := \"bar\"\n\t\n\tx := struct {\n\t\tFoo *string\n\t\tBar *string\n\t}{\u0026f, \u0026b}\n\n\t// NOTE: pass value as reflect.Indirect(x) if x is a struct pointer\n\tv := reflect.ValueOf(x)\n\n    // prints the value which is the same as %+v on the struct itself and the type is something like *main.struct{...}\n  \tfmt.Printf(\"reflect: %+v (type: %+v)\\n\", v, v.Type())\n\n\tfor i := 0; i \u003c v.NumField(); i++ {\n\t    field := v.Field(i)\n      \n      \t// v.Field == memory address of first struct field\n        fmt.Println(\"Field:\", v.Field, v.FieldByIndex([]int{0}), v.FieldByIndex([]int{0}).Addr())\n      \n\t    // .Interface() will panic on unexported field!\n   \t\tif !field.CanInterface() {\n\t\t\tcontinue\n\t\t}\n      \n        if field.Kind() == reflect.Bool {\n            // do something with a boolean type field\n            // see also: https://golang.org/pkg/reflect/#Kind const iota\n          \n          \tif field.CanSet() {\n\t\t\t\tfield.Set(reflect.ValueOf(true))\n\t\t\t}\n        }\n\n      \tfmt.Printf(\"name: %+v, value: %+v (type: %T, kind: %+v)\\n\",\n\t\t\tv.Type().Field(i).Name, // Name attribute gives us the struct's key\n\t\t\tfield.Elem(), \t// Elem() dereferences the pointer value\n            field.Interface()), // Interface() provides the interface itself (e.g. {Foo: \"foo\", Bar: \"bar\"})\n\t\t    field.Kind() // Kind() give back the type of the field\n\t}\n\t\n\t/*\n\tname: Foo, value: foo (*string)\n\tname: Bar, value: bar (*string)\n\t*/\n}\n","tags":"#go #golang #pointer #struct #reflection #iterate #fields"},{"id":"65205295a2026c0f12fdb51630ec085b","title":"[Bash Column Sort and Sum] ","content":"cat /tmp/foo | column -t 2\u003e/dev/null | sort -k 4 -n -r | awk '{print $4}' | paste -sd+ - | bc\n\n# 40\nA B C 5\nD E F 10\nG H I 1\nJ K L 24\n","tags":"#bash #sort #sum #column"},{"id":"c125817c5409b5a4a5a5bc0a1d448da9","title":"Python extract query string params in order they are specified","content":"# use regex instead of urlparse as it was inconsistent ordering\nparams = re.findall(r'[(\\?|\\\u0026)]([^=]+)', url) \n","tags":""},{"id":"dfae68eccb8c4cdbd0e405fe6bc808cf","title":"[Python CPU and Memory Profiling Tools] ","content":"It is worth considering the variation in load that you get on a normal computer. \n\nMany background tasks are running (e.g. Dropbox, backups) that could impact the CPU and disk resources at random.\n\nTools available:\n\n* `timeit` module: understand behavior of statements and functions\n* `cProfile`: understand which functions in your code take the longest to run (high-level only)\n* `line_profiler`: profiles your chosen functions on a line-by-line basis (granular)\n* `memory_profiler`: chart RAM usage over time on a labelled chart (function level)\n* `heapy`: track all of the objects inside Python’s memory (useful for hunting down memory-leaks)\n* `perf stat`: understand number of instructions executed on CPU and how efficiently the CPU’s caches are utilized\n* CPython: understand Python stack based vm operates (understand why certain coding styles run more slowly than others)\n\n\u003e [Reference article](http://www.marinamele.com/7-tips-to-time-python-scripts-and-control-memory-and-cpu-usage)\n\n### Locating Python Packages\n\n```bash\nfind / -type d -name \u003cpackage_name\u003e\n\n# for example, the result could look like...\n#\n# ./usr/local/lib/python3.6/site-packages/package_name\n```\n\"\"\"This module is for profiling purposes.\"\"\"\n\nfrom pprint import pprint\n\n\ndef factorize_naive(n):\n    \"\"\"\n    Naive factorization method.\n\n    Take integer 'n', return list of factors.\n    \"\"\"\n    if n \u003c 2:\n        return []\n    factors = []\n    p = 2\n\n    while True:\n        if n == 1:\n            return factors\n\n        r = n % p\n        if r == 0:\n            factors.append(p)\n            n = n / p\n        elif p * p \u003e= n:\n            factors.append(n)\n            return factors\n        elif p \u003e 2:\n            # Advance in steps of 2 over odd numbers\n            p += 2\n        else:\n            # If p == 2, get to 3\n            p += 1\n\n    assert False, \"unreachable\"\n\n\ndef serial_factorizer(nums):\n    \"\"\"Process factorials lots of times.\"\"\"\n    return {n: factorize_naive(n) for n in nums}\n\n\nif __name__ == \"__main__\":\n    pprint(serial_factorizer([10000, 100, 4450, 8320, 500000]))\n\n\"\"\"This module is for profiling purposes.\"\"\"\n\nfrom time import time\nfrom pprint import pprint\nfrom functools import wraps\n\n\ndef timefn(fn):\n    \"\"\"Simple timer decorator.\"\"\"\n    @wraps(fn)\n    def measure_time(*args, **kwargs):\n        t1 = time()\n        result = fn(*args, **kwargs)\n        t2 = time()\n        print(f\"@timefn: {fn.__name__} took {str(t2 - t1)} seconds\")\n        return result\n    return measure_time\n\n\n@timefn\ndef factorize_naive(n):\n    \"\"\"\n    Naive factorization method.\n\n    Take integer 'n', return list of factors.\n    \"\"\"\n    if n \u003c 2:\n        return []\n    factors = []\n    p = 2\n\n    while True:\n        if n == 1:\n            return factors\n\n        r = n % p\n        if r == 0:\n            factors.append(p)\n            n = n / p\n        elif p * p \u003e= n:\n            factors.append(n)\n            return factors\n        elif p \u003e 2:\n            # Advance in steps of 2 over odd numbers\n            p += 2\n        else:\n            # If p == 2, get to 3\n            p += 1\n\n    assert False, \"unreachable\"\n\n\ndef serial_factorizer(nums):\n    \"\"\"Process factorials lots of times.\"\"\"\n    return {n: factorize_naive(n) for n in nums}\n\n\nif __name__ == \"__main__\":\n    pprint(serial_factorizer([10000, 100, 4450, 8320, 500000]))\n# python -m timeit -n \u003caverage\u003e -r \u003crepetitions\u003e -s \"\u003cimport your app\u003e\" \"\u003ccode to be run\u003e\"\n#\n# for longer-running functions it can be sensible to specify the number of loops which are averaged (-n 4) and a number of repetitions of the loops (-r 5)\n\npython -m timeit -n 4 -r 5 -s \"from pprint import pprint; import app\" \"pprint(app.serial_factorizer([10000, 100, 4450, 8320, 500000]))\"\npython -m cProfile -s cumulative app.py\npip install memory_profiler\npip install psutil\n\n# From VM...\nmprof run python /app/video_player.py\n\n# From Host...\nulimit -n 1024\nsiege \u003curl\u003e -c 255 -t 30S\nll | grep mprofile | tail -n 1 | awk '{print $9}' | xargs cat | tail -n 1 # locate latest mprofile_\u003ctimestamp\u003e.dat and display its last line\n\n# MEM 36.324219\n\n","tags":"#tags: python, profiling, perf"},{"id":"e824971e3f917d23e5315253f98ece92","title":"[RFC Example Structure] ","content":"\u003e https://goo.gl/njnWEU\n\n# RFC: Template\n\n**Author**: `\u003c...\u003e` (@`\u003c...\u003e`)  \n**Team**: #`\u003c...\u003e` (@`\u003c...\u003e`)  \n**Status**: [proposed|accepted|rejected]\n**Date**: yyyy.mm.dd\n\n## Foreword\n\nThe **purpose** of this document is to propose a strategy for `\u003c...\u003e`. The **goal** is for a solution that is `\u003c...\u003e`. This document serves to **describe** the current state of `\u003c...\u003e`, the **problems** it presents and put forward some **potential solutions**.\n\n## Motivations\n...\n\n## Background\n...\n\n## Participants\n...\n\n## Options\n...\n\n## Considerations\n...\n\n## Questions\n...\n# [RFC](https://en.wikipedia.org/wiki/Request_for_Comments): DIP (Dynamic Input Processing)\n\n**Author**: Mark McDonnell  \n**Team**: #oo-infra-resilience  \n**Status**: proposed  \n**Date**: 2017.08.21\n\n## Abstract\n\n...\n\nThe **purpose** section of an informative abstract should state either the reason for or the primary objectives of the experiment or investigation. The purpose section of an informative abstract might also contain the hypothesis of the experiment.\n\nThe **methodology** section of an informative abstract should describe the techniques used in conducting the experiment. This section should give only as much detail as is necessary to understand the experiment; the abstract should not focus entirely on research methods unless that is the primary focus of the original document.\n\nThe **results** section of an informative abstract should relate the observations and/or data collected during the experiment. This section should be concise and informative, and only the most important results need be included.\n\nThe **conclusion** section of an informative abstract should state the evaluation or analysis of the experiment results. It should also briefly state the implications of these results. This conclusion section might also state whether the driving hypothesis of the experiment was correct.\n\n## Motivation\n\n...\n\n## Proposal\n\n...\n\n## Considerations\n\n...\n\n## References\n\n...\n","tags":"#rfc #example"},{"id":"5fbfe778d38fcf2e77dc0928ec0d6bce","title":"Log to SysLog on the command line (terminal)","content":"logger integralist\n\ncat /var/log/system.log | grep integralist\n# Nov 19 12:34:16 MarkMcDonnell-MBPr markmcdonnell[11781]: integralist\n","tags":""},{"id":"89db69ec07e3ca34495259d4feacb2ae","title":"What's the difference between a router and a modem?","content":"## Modem\n\nA modem is a box that you plug your telephone (or cable) line into. Doing this will provide you with a connection to your ISP (Internet Service Provider) who are the company responsible for providing you with a public IP address so you may connect to the internet.\n\nThe internet is based on the TCP/IP protocol, which means you need a public IP address so that any requests you make for online content has a place to send a response to (e.g. if you open a web browser and make a request for www.google.com then the response needs to know your IP so it can come back to you).\n\n## Router\n\nA router is a box that allows multiple devices to connect to it. By itself it's probably not that useful (unless you configure it so that devices can share folders and files). So a router provides a LAN (local area network). \n\nTypically you'll connect your router to a modem, meaning that every device that connects to the router can connect to the internet. The router uses DHCP to dynamically assign private IPs to your LAN connected devices. \n\nIf someone tries to connect to your router’s public IP address (remember this public IP is provided by your ISP), your router has no idea where it should send that traffic. All your router can do is take the traffic and discard it. This means your router acts as a firewall, discarding unrequested inbound traffic. \n\nAlthough you can configure your router to use \"port forwarding\", so any requests for port 9000 (as an example) could be routed to a local private IP. \n\nBut you'd also need to ensure it was a _static_ private IP, otherwise the local device (which is expected to handle the incoming request coming from outside the LAN) could end up being different each time due to DHCP _dynamically_ assigning private IPs to local devices when they connect † \n\n\u003e † but that in itself is a bit silly because if you had a local web server running (as an example), then you'd want it to _always_ be connected to the router. You wouldn't disconnect the server from the router before bed as people in other timezones might still want to access it; but the principle is still the same: your server might accidentally fail and so when you restart it the connection to the router would give you a different IP, unless you configured it to give you a static IP.\n\n## ISP Provided Public IPs\n\nThere are a limit to the number of IPv4 IPs that can be created (hence the move to IPv6 IPs). ISPs will typically own a range of public IPs and then lease them to each of their customers for a set amount of time.\n\nWhen the lease expires, your modem has to re-negotiate a new public IP (from the pool of public IPs your ISP makes available to its customers). This is typically why if you check a website like http://www.whatsmyip.org/ you'll find after a while (it could be days or months even), that the IP shown will change.\n","tags":""},{"id":"f93386e9f7559e2c38a7a0fbb3e8e498","title":"C vs System Calls and where to find documentation?","content":"## What's the issue?\n\nIt can be confusing sometimes knowing where to look for documentation when dealing with C †\n\n\u003e † that is if you're not a systems engineer, and have no CS degree, nor learnt C\n\nAs an example, you might learn about the `strace` command and start investigating what your Ruby application is up to. In doing so you'll see lots of calls to different functions and you might decide you want to look up the documentation for those functions.\n\nThis could be where your first problem arises. You might think \"Ruby is written in C, so I'll look at the C documentation\" and then come up with nothing. \n\n## So what's going on?\n\nThe key is to remember that the Linux operating system (which your code is very likely running on) is itself written in C. But Linux provides its own set of functions written in C that aren't part of the C language.\n\nSo you might see a function used and wonder why it's not showing up within the C language documentation. That's because it's not part of the C language. The Linux engineers would've created the function within Linux so you need to look at the Linux documentation to find out what it does.\n\n\u003e e.g https://linux.die.net/man/ \n\nSome of these Linux provided functions are known as 'system calls'. If you visit [the above link](https://linux.die.net/man/) you'll see there in 'section 2' a list of all system calls.\n\nAn alternative (searchable) list of syscalls can be found here: https://filippo.io/linux-syscall-table/\n\n## Wrapper functions?\n\nNow what makes this a little more confusing is that the system calls aren't usually directly accessible. So 'section 2' of the Linux documentation may list all the 'system call' documentation, but 'section 3' lists all library functions including what are referred to as 'thin wrapper' functions for the system calls. \n\nFor example, Linux uses a separate library that provides a `fork` function which is a wrapper around the actual system call `fork` equivalent provided by Linux itself. The wrapper function is then also something other applications written in C can utilise.\n\nThis is noted here https://linux.die.net/man/2/intro in the documentation:\n\n\u003e A system call is an entry point into the Linux kernel. Usually, system calls are not invoked directly: instead, most system calls have corresponding C library wrapper functions which perform the steps required in order to invoke the system call. Thus, making a system call look the same as invoking a normal library function.\n\nSo what do these thin wrapper functions do? Well the docs tell us...\n\n\u003e Often the glibc wrapper function is quite thin, doing little work other than copying arguments to the right registers before invoking the system call, and then setting errno appropriately after the system call has returned. Note: system calls indicate a failure by returning a negative error number to the caller; when this happens, the wrapper function negates the returned error number (to make it positive), copies it to errno, and returns -1 to the caller of the wrapper. Sometimes, however, the wrapper function does some extra work _before_ invoking the system call. For example, nowadays there are two related system calls, `truncate` and `truncate64`, and the glibc `truncate()` wrapper function checks which of those system calls are provided by the kernel and determines which should be employed.\n\nUsing `fork` as an example:\n\n- Here is the system call docs: https://linux.die.net/man/2/fork\n- Here is the wrapper docs: https://linux.die.net/man/3/fork\n\nBut where do some of the wrapper equivalents come from? Well, one such provider is glibc; which is [GNU's standard C library](https://en.wikipedia.org/wiki/GNU_C_Library). Which states:\n\n\u003e The C language provides no built-in facilities for performing such common operations as input/output, memory management, string manipulation, and the like. Instead, these facilities are defined in a standard library, which you compile and link with your programs. The GNU C Library, described in this document, defines all of the library functions that are specified by the ISO C standard, as well as additional features specific to POSIX and other derivatives of the Unix operating system, and extensions specific to GNU systems.\n\n[Here's a link also to the standard C library](https://en.wikipedia.org/wiki/C_standard_library) libc if you're interested.\n\n## Direct system call?\n\nWhat if one of the additional C libraries (libc, glibc etc) don't provide a wrapper?\n\nWell in these situations you can make a direct system call!\n\nSee https://linux.die.net/man/2/syscall which states:\n\n\u003e `syscall()` is a small library function that invokes the system call whose assembly language interface has the specified number with the specified arguments. Employing `syscall()` is useful, for example, when invoking a system call that has no wrapper function in the C library.\n","tags":""},{"id":"07f0df8dd810e64d5803720380a852c3","title":"CSS representation of long hand division","content":"\u003cstyle\u003e\n.divisor {\n  border-right: 1px black solid; \n  border-radius: 0px 0px 10px 0px;\n  padding-right: 5px;\n}\n.dividend {\n  border-top: 1px black solid; \n  padding-left: 3px;\n  position: relative;\n}\n.answer {\n  position: absolute;\n  top: -1.5em;\n}\n\u003c/style\u003e\n\n\u003cspan class='divisor'\u003e8\u003c/span\u003e\u003cspan class='dividend'\u003e\u003cspan class='answer'\u003e9(r3)\u003c/span\u003e75\u003c/span\u003e\n\u003cbr\u003e\u003cbr\u003e\n\u003cspan class='divisor'\u003e8\u003c/span\u003e\u003cspan class='dividend'\u003e\u003cspan class='answer'\u003e1(r1)\u003c/span\u003e9\u003c/span\u003e\n\u003cbr\u003e\u003cbr\u003e\n\u003cspan class='divisor'\u003e8\u003c/span\u003e\u003cspan class='dividend'\u003e\u003cspan class='answer'\u003e0(r1)\u003c/span\u003e1\u003c/span\u003e\n","tags":""},{"id":"b0baf6b4b0397e975083491d32927368","title":"Shell: AWS S3 CLI - Logs ","content":"# List files in bucket...\naws s3 ls bf-logs-archive/\n\n# Download file from bucket and decode it...\naws s3 cp \"s3://bf-logs-archive/2017-08-02T08:00:00.000-w7QBJbe2XZtUy5oAAAAA.log.gz\" fastly_logs/ # trailing slash is important! otherwise is copied as filename in current directory\ngzip -d fastly_logs/2017-08-02T08\\:00\\:00.000-w7QBJbe2XZtUy5oAAAAA.log.gz\n\n# http://docs.aws.amazon.com/cli/latest/reference/s3/\n#\n# Recursively copy only the things you want...\n# --recursive --exclude \"*\" --include \"things_you_want\"\n","tags":"#aws #shell #logs"},{"id":"f046375b675f13a44e2aff0a75816bc2","title":"DNS update strategy","content":"## What’s the Best Practice for changing a DNS record?\n\nFor something relatively simple like modifying a single record to a domain, it might feel like overkill to have a “plan” or “strategy” – but given the very public severity of screwing up DNS some caution is warranted. It’s like the old saying: “A packet of prevention is worth a pound of cure.”\n\nThere’s a simple way to limit your mistakes: never update both a DNS record and a TTL for that record at the same time. Ideally you’ll have a process of:\n\n* Drop TTL on the DNS record to something very low a couple of days before you actually need to make the switch. Ex: 300 seconds\n* Change the actual record on your cutover date.\n* Several days after you’ve made the switch, up the TTL to something higher.\n","tags":""},{"id":"59d6a84a7a083a60ebdeceacf6f63cd9","title":"Python Singleton","content":"# singleton.py\n\ninstance = None\n\n\nclass Foo():\n    def __new__(cls, arg):\n        global instance\n        if instance is not None:\n            return instance\n        instance = object.__new__(cls)\n        instance.foo = arg\n        return instance\n\n    def __init__(self, arg):\n        print(self.foo)  # __init__ called each time\n                         # but foo is set only once\n\n# consumer code within a separate module...\n\nf = Foo('a')\nf = Foo('b')\nf = Foo('c')\n\n","tags":""},{"id":"aced055890fa13a82fbae51b23693102","title":"Bits Explained (inc. IPs, CIDR, RAM etc)","content":"## Bit\n\nThe word _bit_ is short for _binary digit_.\n\nA bit is either a `1` (true) or a `0` (false).\n\nComputers only understand the binary format (i.e. base-2)\n\n\u003e We discuss 'base' numbers [below](#base-numbers)\n\n## Byte\n\nA grouping of eight _bits_ is called a _byte_.\n\n## RAM\n\nThe word _ram_ is an acronym for _random access memory_.\n\nIt's non-persistent memory.\n\nMeaning it is lost when your machine is restarted, and persists only for the lifetime of the program using it.\n\nRAM consists of bits, but each _segment_ of memory is actually a grouping of eight bits (which we already know is called a _byte_).\n\nSo in short we would say RAM is made up of bytes.\n\nBytes are uniquely numbered to allow easy lookup of their contents.\n\nA byte's unique number is also referred to as its _address_.\n\n## Visualisation\n\n![Image of what RAM looks like](https://cloud.githubusercontent.com/assets/180050/20210197/19d55bee-a7f0-11e6-95a0-4e1d60b0898a.png)\n\n\u003e if unclear 128 is made by calculating 2 to the power of 7  \n\u003e e.g. `2*2*2*2*2*2*2` = `128`\n\n## Numbers\n\n1 kilobyte (or 1KB) is 1,024 bytes.\n\n1,024 bytes is 8192 bits (`8192/8` = `1024`, so `8*1024` = `8192`)\n\nThe following explanation is taken from \"Beginning C\" by Apress Publishing...\n\n\u003e You might be wondering why we don’t work with simpler, more rounded numbers, such as a thousand, or a million, or a billion. The reason is this: there are 1,024 numbers from 0 to 1,023, and 1,023 happens to be 10 bits that are all 1 in binary: 11 1111 1111, which is a very convenient binary value. So while 1,000 is a very convenient decimal value, it’s actually rather inconvenient in a binary machine—it’s 11 1110 1000, which is not exactly neat and tidy. The kilobyte (1,024 bytes) is therefore defined in a manner that’s convenient for your computer, rather than for you.\n\nSo if we add up `512+256+128+64+32+16+8+4+2+1` (notice this takes the existing 8 bit calculation from the above image and continues it for another two bits) we get `1023`.\n\n## IPs\n\nHere is an example IPv4 IP:\n\n```\n216.27.61.137\n```\n\nIPv4 IPs are expressed in decimal format (with dotted decimal number). \n\n\u003e Note: IPv6 IPs are eight 4-character hexadecimal numbers,  \n\u003e which represent 16 bits each (for a total of 128 bits)\n\nTo translate the above IP into binary form (for the sake of a computer to process it), we need to use the above visualisation to help us. The end result of which would look like this:\n\n```\n11011000.00011011.00111101.10001001\n```\n\nSo to clarify:\n\n- `11011000`: 128 + 64 + 16 + 8 = 216\n- `00011011`: 16 + 8 + 2 + 1 = 27\n- `00111101`: 32 + 16 + 8 + 4 + 1 = 61\n- `10001001`: 128 + 8 + 1 = 137\n\nThis explains why each of the four numbers within the decimal formatted version (i.e. `216.27.61.137`) are called octets, as they represent eight bits (or a 'byte' as we learned earlier) when viewed in binary form.\n\nThis also explains why IPv4 IPs are considered 32-bit numbers, because if you add each of the bits together (i.e. the number of total bits, not the value assigned to each bit) you'll find there are a total of 32 bits that make up the IP.\n\nEach bit can have two different states (1 or zero), meaning the total number of potential combinations per octet can be either 28 or 256. Meaning each octet can contain a potential value between zero and 255. Meaning if we were to combine the four octets, we could potentially have 4,294,967,296 variations.\n\nWe can see the decimal represenation of an IPv4 IP is made up of four base-10 numbers (216, 27, 61, 137). Where each of those four numbers represent the binary equivalent (216=11011000, 27=00011011, 61=00111101, 137=10001001), which is a base-2 representation of a byte (or octet).\n\n\u003e If you're unsure of what base numbers are and how they work, then read on...\n\n## Base Numbers\n\nIt's worth quickly covering what base numbers are as they help us understand the other different protocols we use on a regular basis, such as binary and things like IPs.\n\nAny number can be represented in multiple ways using a different base numbering system.\n\nThere are many numbering systems, but the typical ones we're used to are:\n\n- Base 10 (Decimal)\n- Base 2 (Binary)\n- Base 8 (Octal)\n- Base 16 (Hexadecimal)\n\nThe standard number system we (as humans) are most familiar with is called base-10 and is consists of the following numbers: \n\n```\n0,1,2,3,4,5,6,7,8,9\n```\n\n\u003e Notice there are ten numbers, hence it is called the base-10 system\n\nIf we were to look at a number like `66`, then this would tell us the number is made up of 6 tens and six units.\n\nThese numbers (0-9) represent 'whole numbers', while in the base-10 system we can also use a decimal point to represent decimal fractions of a number (e.g. `1.2`). \n\nBelow is an image, credit to Jenny Eather, that helps us visualise this model:\n\n![base-10 number system](https://cloud.githubusercontent.com/assets/180050/20260105/12b4f740-aa50-11e6-98c9-94083f29732f.png)\n\nThe 'base number' is the number of numbers within the system. So base-10 has 10 numbers (0,1,2,3,4,5,6,7,8,9) where as binary is base-2 because it uses two numbers only (0, 1).\n\nIf you want to know the unit each number in a system represents (we'll use base-10 as the example, thanks to the following visualisation credited to Jenny Eather), then you calculate this with the n power of the base number.\n\n![base-10 example](https://cloud.githubusercontent.com/assets/180050/20260227/99d38f16-aa50-11e6-9ddd-d52900a794ea.png)\n\nSo, as per the above visualisation, we can see:\n\n- 10\u003csup\u003e3\u003c/sup\u003e: `10*10*10`: 1000 (thousands)\n- 10\u003csup\u003e2\u003c/sup\u003e: `10*10`: 100 (hundreds)\n- 10\u003csup\u003e1\u003c/sup\u003e: `10`: 10 (tens)\n- 10\u003csup\u003e0\u003c/sup\u003e: `1`: 1 (unit)\n\nSo in practical terms, if you have a number like `75` and want to represent it as base-10:\n\n- 5 (10\u003csup\u003e0\u003c/sup\u003e: 5 units)\n- 7 (10\u003csup\u003e1\u003c/sup\u003e: 7 tens)\n\nYou can indicate what base you wish to represent a number like so:\n\nn\u003csub\u003eb\u003c/sub\u003e\n\nWhere `n` is the number and `b` is the base you wish to state it is in.\n\nFor example:\n\n75\u003csub\u003e10\u003c/sub\u003e\n\nThis is the number `75` and we're stating the base it represents is `10`. \n\nBut if we wanted the number to be _interpreted_ as a base-8 number (e.g. \"hey bob, here's the number 75 can you convert it into base-8 for me please\") we'd display it as 75\u003csub\u003e8\u003c/sub\u003e.\n\n### Convert Base-10 into Base-2/8\n\nNow let's consider how to convert the number `75` into another base, like base-8. To do so, follow these steps\n\n1. divide the number (75) by the desired base (8) (take note of the remainder: 3)\n2. divide the result (75/8 = 9) and do the same (i.e. divide by the base and take note of the remainder)\n3. keep doing this until the result of dividing the previous answer by the base is zero\n4. now write out the remainders bottom to top, and that's the number in base 8\n\nIn long form this looks like this:\n\n- 75 (number) / 8 (base) = 9 (rounded) with a remainder of 3\n- 9 (previous answer) / 8 (base) = 1 (rounded) with a remainder of 1\n- 1 (previous answer) / 8 (base) = 0 (rounded) with a remainder of 1\n\nMeaning 75 evaluated in base-8 would be `113` (all the remainders concatenated together, 'bottom up')\n\n### Convert Base-10 into Base-16\n\nThe algorithm for converting from base-10 into base-2 and base-8 works basically the same for converting into base-16. But there is one caveat whereby a remainder can be in the double digits, and apparently (for reasons I don't completely understand) we don't want that, and so the number system was designed to replace the six instances where this can occur (the remainders being: 10, 11, 12, 13, 14, 15) with a alpha-numeric equivalent:\n\n- 10-A\n- 11-B\n- 12-C\n- 13-D\n- 14-E\n- 15-F\n\nSo if we want to convert 110\u003csub\u003e10\u003c/sub\u003e into a hexadecimal the outcome of the algorithm would be:\n\n- 110 (number) / 16 (base) = 6 (rounded) with a remainder of 14\n- 6 (previous answer) / 16 (base) = 0 (rounded) with a remainder of 6\n\nWe know that we need to replace `14` (a double digit remainder) with the letter `E` (see above mapping).\n\nMeaning 110 evaluated in base-16 would be `6E`\n\nLet's try it again, but with the number 411\u003csub\u003e10\u003c/sub\u003e:\n\n- 411 (number) / 16 (base) = 25 (rounded) with a remainder of 11\n- 25 (previous answer) / 16 (base) = 1 (rounded) with a remainder of 9\n- 1 (previous answer) / 16 (base) = 0 (rounded) with a remainder of 1\n\nWe know that we need to replace `11` with the letter `B`.\n\nMeaning 411 evaluated in base-16 would be `19B`\n\n### Convert Any Base to Base-10\n\nWhat if you want to convert a base-8 number (let's say `113`, why not) into base-10? The algorithm is to multiple the individual numbers by their associated power of the base and then add the numbers together.\n\nSo here are the base-8 powers:\n\n- 3: 8\u003csup\u003e0\u003c/sup\u003e\n- 1: 8\u003csup\u003e1\u003c/sup\u003e\n- 1: 8\u003csup\u003e2\u003c/sup\u003e\n\nAnd here is the algorithm:\n\n- 3 x 8\u003csup\u003e0\u003c/sup\u003e = 3\n- 1 x 8\u003csup\u003e1\u003c/sup\u003e = 8 (i.e. `1*8`)\n- 1 x 8\u003csup\u003e2\u003c/sup\u003e = 64 (i.e. `1*(8 * 8)`)\n- 3 + 8 + 64 = 75\n\nIf you're dealing with base-16, then again it's the same but the difference is you're translating the letter back into the corresponding number.\n\nLet's convert `19B` from base-16 back into base-10:\n\n- B x 16\u003csup\u003e0\u003c/sup\u003e (11 x 16\u003csup\u003e0\u003c/sup\u003e) = 11\n- 9 x 16\u003csup\u003e1\u003c/sup\u003e = 144\n- 1 x 16\u003csup\u003e2\u003c/sup\u003e = 256\n- 11 + 144 + 256 = 411\n\nLet's try one more conversion between base-16 to base-10. The number is `1A4`:\n\n- 4 x 16\u003csup\u003e0\u003c/sup\u003e = 4\n- A x 16\u003csup\u003e1\u003c/sup\u003e (10 x 16\u003csup\u003e1\u003c/sup\u003e) = 160\n- 1 x 16\u003csup\u003e2\u003c/sup\u003e = 256\n- 4 + 160 + 256 = 420\n\n## CIDR\n\nA CIDR is a range of IP addresses. We can use our understanding of bits, bytes and octets to understand the format of a CIDR.\n\nA CIDR typically resembles something like:\n\n```\n10.0.0.0/n\n```\n\nWhere `n` is given the value 8, 16, 24, or 32 and these represent each of the 8-bit blocks that make up the IP.\n\nIf we want an IP range between `10.0.0.0` and `10.255.255.255`, we'd specify the CIDR as `10.0.0.0/8`.\n\nWhat `8` states is that the last 8 bits of the 32-bit number is accounted for (this being the `10` we've specified in our example). Meaning the rest of the 8-bit segments can be added up to their max of 255 (meaning the last IP in this CIDR range would be `10.255.255.255`).\n\nSimilarly if we want an IP range between `10.0.0.0` and `10.0.255.255`, we'd specify the CIDR as `10.0.0.0/16`.\n\nAgain, `16` states that the next 8-bits segment of the 32-bit number is now accounted for (this being the `0` we've specified in our example `10.0`). Meaning the rest of the 8-bit segments can be added up to their max of 255 (meaning the last IP in this CIDR range would be `10.0.255.255`).\n\nAnd so on...\n\nSo `10.0.0.0/24` gives us an ip range of `10.0.0.0` to `10.0.0.255` (256 IPs). \n\nWhere as `10.0.0.0/32` gives us an ip range of 1 ip (`10.0.0.0` to `10.0.0.0`).\n\n\u003e Note: you can use a tool such as http://www.ipaddressguide.com/cidr to help you generate CIDRs\n\nWe can use the earlier [byte visualisation](#visualisation) table matrix to help us manually calculate a CIDR range.\n\nI've reproduced it below with a HTML table:\n\n\u003e Note: you'll likely need to scroll to the right to see the start of the 32-bit\n\n\u003ctable border=\"1\" id=\"table10\" bordercolor=\"#000080\" style=\"text-align: center; font-family: Verdana; font-size: 8pt; color: #000000\"\u003e\n    \u003ctbody\u003e\n    \u003ctr\u003e\n        \u003cth\u003eIP\u003c/th\u003e\n\n        \u003ctd colspan=\"8\"\u003e10\u003c/td\u003e\n\n        \u003ctd colspan=\"8\"\u003e0\u003c/td\u003e\n\n        \u003ctd colspan=\"8\"\u003e0\u003c/td\u003e\n\n        \u003ctd colspan=\"8\"\u003e1\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n        \u003cth\u003e8 Bit Blocks\u003c/th\u003e\n\n        \u003ctd colspan=\"8\"\u003e8 bits [24-31]\u003c/td\u003e\n\n        \u003ctd colspan=\"8\"\u003e8 bits [16-23]\u003c/td\u003e\n\n        \u003ctd colspan=\"8\"\u003e8 bits [08-15]\u003c/td\u003e\n\n        \u003ctd colspan=\"8\"\u003e8 bits [00-07]\u003c/td\u003e\n      \u003c/tr\u003e\n\n      \u003ctr\u003e\n        \u003cth\u003e32 Bit #\u003c/th\u003e\n\n        \u003ctd\u003e31\u003c/td\u003e\n\n        \u003ctd\u003e30\u003c/td\u003e\n\n        \u003ctd\u003e29\u003c/td\u003e\n\n        \u003ctd\u003e28\u003c/td\u003e\n\n        \u003ctd\u003e27\u003c/td\u003e\n\n        \u003ctd\u003e26\u003c/td\u003e\n\n        \u003ctd\u003e25\u003c/td\u003e\n\n        \u003ctd\u003e24\u003c/td\u003e\n\n        \u003ctd\u003e23\u003c/td\u003e\n\n        \u003ctd\u003e22\u003c/td\u003e\n\n        \u003ctd\u003e21\u003c/td\u003e\n\n        \u003ctd\u003e20\u003c/td\u003e\n\n        \u003ctd\u003e19\u003c/td\u003e\n\n        \u003ctd\u003e18\u003c/td\u003e\n\n        \u003ctd\u003e17\u003c/td\u003e\n\n        \u003ctd\u003e16\u003c/td\u003e\n\n        \u003ctd\u003e15\u003c/td\u003e\n\n        \u003ctd\u003e14\u003c/td\u003e\n\n        \u003ctd\u003e13\u003c/td\u003e\n\n        \u003ctd\u003e12\u003c/td\u003e\n\n        \u003ctd\u003e11\u003c/td\u003e\n\n        \u003ctd\u003e10\u003c/td\u003e\n\n        \u003ctd\u003e09\u003c/td\u003e\n\n        \u003ctd\u003e08\u003c/td\u003e\n\n        \u003ctd\u003e07\u003c/td\u003e\n\n        \u003ctd\u003e06\u003c/td\u003e\n\n        \u003ctd\u003e05\u003c/td\u003e\n\n        \u003ctd\u003e04\u003c/td\u003e\n\n        \u003ctd\u003e03\u003c/td\u003e\n\n        \u003ctd\u003e02\u003c/td\u003e\n\n        \u003ctd\u003e01\u003c/td\u003e\n\n        \u003ctd\u003e00\u003c/td\u003e\n      \u003c/tr\u003e\n\n      \u003ctr\u003e\n        \u003cth\u003eDecimal\u003c/th\u003e\n\n        \u003ctd\u003e128\u003c/td\u003e\n\n        \u003ctd\u003e64\u003c/td\u003e\n\n        \u003ctd\u003e32\u003c/td\u003e\n\n        \u003ctd\u003e16\u003c/td\u003e\n\n        \u003ctd\u003e8\u003c/td\u003e\n\n        \u003ctd\u003e4\u003c/td\u003e\n\n        \u003ctd\u003e2\u003c/td\u003e\n\n        \u003ctd\u003e1\u003c/td\u003e\n\n        \u003ctd\u003e128\u003c/td\u003e\n\n        \u003ctd\u003e64\u003c/td\u003e\n\n        \u003ctd\u003e32\u003c/td\u003e\n\n        \u003ctd\u003e16\u003c/td\u003e\n\n        \u003ctd\u003e8\u003c/td\u003e\n\n        \u003ctd\u003e4\u003c/td\u003e\n\n        \u003ctd\u003e2\u003c/td\u003e\n\n        \u003ctd\u003e1\u003c/td\u003e\n\n        \u003ctd\u003e128\u003c/td\u003e\n\n        \u003ctd\u003e64\u003c/td\u003e\n\n        \u003ctd\u003e32\u003c/td\u003e\n\n        \u003ctd\u003e16\u003c/td\u003e\n\n        \u003ctd\u003e8\u003c/td\u003e\n\n        \u003ctd\u003e4\u003c/td\u003e\n\n        \u003ctd\u003e2\u003c/td\u003e\n\n        \u003ctd\u003e1\u003c/td\u003e\n\n        \u003ctd\u003e128\u003c/td\u003e\n\n        \u003ctd\u003e64\u003c/td\u003e\n\n        \u003ctd\u003e32\u003c/td\u003e\n\n        \u003ctd\u003e16\u003c/td\u003e\n\n        \u003ctd\u003e8\u003c/td\u003e\n\n        \u003ctd\u003e4\u003c/td\u003e\n\n        \u003ctd\u003e2\u003c/td\u003e\n\n        \u003ctd\u003e1\u003c/td\u003e\n      \u003c/tr\u003e\n\n      \u003ctr\u003e\n        \u003cth\u003eBinary\u003c/th\u003e\n\n        \u003ctd\u003e0\u003c/td\u003e\n\n        \u003ctd\u003e0\u003c/td\u003e\n\n        \u003ctd\u003e0\u003c/td\u003e\n\n        \u003ctd\u003e0\u003c/td\u003e\n\n        \u003ctd\u003e\u003cfont color=\"#DC143C\"\u003e1\u003c/font\u003e\u003c/td\u003e\n\n        \u003ctd\u003e0\u003c/td\u003e\n\n        \u003ctd\u003e\u003cfont color=\"#DC143C\"\u003e1\u003c/font\u003e\u003c/td\u003e\n\n        \u003ctd\u003e0\u003c/td\u003e\n\n        \u003ctd\u003e0\u003c/td\u003e\n\n        \u003ctd\u003e0\u003c/td\u003e\n\n        \u003ctd\u003e0\u003c/td\u003e\n\n        \u003ctd\u003e0\u003c/td\u003e\n\n        \u003ctd\u003e0\u003c/td\u003e\n\n        \u003ctd\u003e0\u003c/td\u003e\n\n        \u003ctd\u003e0\u003c/td\u003e\n\n        \u003ctd\u003e0\u003c/td\u003e\n\n        \u003ctd\u003e0\u003c/td\u003e\n\n        \u003ctd\u003e0\u003c/td\u003e\n\n        \u003ctd\u003e0\u003c/td\u003e\n\n        \u003ctd\u003e0\u003c/td\u003e\n\n        \u003ctd\u003e0\u003c/td\u003e\n\n        \u003ctd\u003e0\u003c/td\u003e\n\n        \u003ctd\u003e0\u003c/td\u003e\n\n        \u003ctd\u003e0\u003c/td\u003e\n\n        \u003ctd\u003e0\u003c/td\u003e\n\n        \u003ctd\u003e0\u003c/td\u003e\n\n        \u003ctd\u003e0\u003c/td\u003e\n\n        \u003ctd\u003e0\u003c/td\u003e\n\n        \u003ctd\u003e0\u003c/td\u003e\n\n        \u003ctd\u003e0\u003c/td\u003e\n\n        \u003ctd\u003e0\u003c/td\u003e\n\n        \u003ctd\u003e\u003cfont color=\"#DC143C\"\u003e1\u003c/font\u003e\u003c/td\u003e\n      \u003c/tr\u003e\n    \u003c/tbody\u003e\n  \u003c/table\u003e\n","tags":""},{"id":"51d18f1625cc9cfd524fabd8cb957152","title":"Website Crawler","content":"wget --mirror \\\n     --convert-links \\\n     --adjust-extension \\\n     --page-requisites \\\n     --header=\"Host: www.example.com\" \\\n     --no-parent https://beepboop.cloudfront.net\n","tags":""},{"id":"cc2616ece918fdd8239d16cca62e37de","title":"Mutt View Attachments Script","content":"#!/bin/bash\n#\n# Author:  Eric Gebhart\n#\n# Purpose:  To be called by mutt as indicated by .mailcap to handle mail attachments.\n#\n# Function: Copy the given file to a temporary directory so mutt\n#           Won't delete it before it is read by the application.\n#\n#           Along the way, discern the file type or use the type\n#           That is given.\n#\n#           Finally use 'open' or 'open -a' if the third argument is\n#           given.\n#\n#\n# Arguments:\n#\n#     $1 is the file\n#     $2 is the type - for those times when file magic isn't enough.\n#                      I frequently get html mail that has no extension\n#                      and file can't figure out what it is.\n#\n#                      Set to '-' if you don't want the type to be discerned.\n#                      Many applications can sniff out the type on their own.\n#                      And they do a better job of it too.\n#\n#                      Open Office and MS Office for example.\n#\n#     $3 is open with.  as in open -a 'open with this .app' foo.xls\n#\n# Examples:  These are typical .mailcap entries which use this program.\n#\n#     Image/JPEG; /Users/vdanen/.mutt/view_attachment %s\n#     Image/PNG; /Users/vdanen/.mutt/view_attachment %s\n#     Image/GIF; /Users/vdanen/.mutt/view_attachment %s\n#\n#     Application/PDF; /Users/vdanen/.mutt/view_attachment %s\n#\n#         #This HTML example passes the type because file doesn't always work and\n#         #there aren't always extensions.\n#\n#     text/html; /Users/vdanen/.mutt/view_attachment %s html\n#\n#         # If your Start OpenOffice.org.app is spelled with a space like this one, \u003c--\n#         # then you'll need to precede the space with a \\ .  I found that too painful\n#         # and renamed it with an _.\n#\n#     Application/vnd.ms-excel; /Users/vdanen/.mutt/view_attachment %s \"-\" '/Applications/OpenOffice.org1.1.2/Start_OpenOffice.org.app'\n#     Application/msword; /Users/vdanen/.mutt/view_attachment %s \"-\" '/Applications/OpenOffice.org1.1.2/Start_OpenOffice.org.app'\n#\n#\n# Debugging:  If you have problems set debug to 'yes'.  That will cause a debug file\n#             be written to /tmp/mutt_attach/debug so you can see what is going on.\n#\n# See Also:  The man pages for open, file, basename\n#\n\n# the tmp directory to use.\ntmpdir=\"$HOME/.tmp/mutt_attach\"\n\n# the name of the debug file if debugging is turned on.\ndebug_file=$tmpdir/debug\n\n# debug.  yes or no.\n#debug=\"no\"\ndebug=\"yes\"\n\ntype=$2\nopen_with=$3\n\n# make sure the tmpdir exists.\nmkdir -p $tmpdir\n\n# clean it out.  Remove this if you want the directory\n# to accumulate attachment files.\nrm -f $tmpdir/*\n\n# Mutt puts everything in /tmp by default.\n# This gets the basic filename from the full pathname.\nfilename=`basename $1`\n\n# get rid of the extenson and save the name for later.\nfile=`echo $filename | cut -d\".\" -f1`\n\nif [ $debug = \"yes\" ]; then\n    echo \"1:\" $1 \" 2:\" $2 \" 3:\" $3 \u003e $debug_file\n    echo \"Filename:\"$filename \u003e\u003e $debug_file\n    echo \"File:\"$file \u003e\u003e $debug_file\n    echo \"===========================\" \u003e\u003e $debug_file\nfi\n\n# if the type is empty then try to figure it out.\nif [ -z $type ]; then\n    file  $1\n    type=`file -bi $1 | cut -d\"/\" -f2`\nfi\n\n# if the type is '-' then we don't want to mess with type.\n# Otherwise we are rebuilding the name.  Either from the\n# type that was passed in or from the type we discerned.\nif [ $type = \"-\" ]; then\n    newfile=$filename\nelse\n    newfile=$file.$type\nfi\n\nnewfile=$tmpdir/$newfile\n\n# Copy the file to our new spot so mutt can't delete it\n# before the app has a chance to view it.\ncp $1 $newfile\n\nif [ $debug = \"yes\" ]; then\n    echo \"File:\" $file \"TYPE:\" $type \u003e\u003e $debug_file\n    echo \"Newfile:\" $newfile \u003e\u003e $debug_file\n    echo \"Open With:\" $open_with \u003e\u003e $debug_file\nfi\n\n# If there's no 'open with' then we can let preview do it's thing.\n# Otherwise we've been told what to use.  So do an open -a.\n\nif [ -z $open_with ]; then\n    open $newfile\nelse\n    open -a \"$open_with\" $newfile\nfi\n","tags":""},{"id":"aee36a7e54a4593084157e333ea40a28","title":"Mutt configuration and usage","content":"## Basic Usage\n\nGeneral commands:\n\n- `/`: search\n- `/~b \u003cphrase\u003e`: search inside all message bodies for phrase\n- `/~B \u003cphrase\u003e`: search inside all message bodies (and headers) for phrase\n\nWhilst viewing your inbox, and cursor is over a message:\n\n- `$`: sync changes\n- `d`: delete message\n- `C-d`: delete the whole thread\n- `N`: mark as 'new' (equivalent to it being 'unread')\n- `ENTER`: open message\n- `/~r DD/MM/YYYY`: search for message received on specified date (stops on first match)\n\n\u003e Note: `YYYY` can be omitted but you need `DD/MM`\n\nWhilst viewing a message:\n\n- `i`: exit\n- `d`: delete message\n- `C-d`: delete the whole thread\n- `C-b`: activate urlview\n- `arrow keys (left/right)`: \u003c- next message | -\u003e previous message \n- `SPACE`: scroll down\n- `-`: scroll up\n\n## Multiple Mutts\n\nYou can create an alias for starting Mutt with a different `.muttrc` file:\n\n```sh\nalias muttb=\"mutt -F ~/.muttrc-buzzfeed\"\n```\n\n## Sending email via Vim\n\n```\n:!mutt -s \"your subject\" -a % -- foo@bar.org \u003c /dev/null\n```\n\n\u003e Vim will convert `%` into the current buffer's name  \n\u003e Leave off `\u003c /dev/null` if you wish to edit message body\n# http://www.mutt.org/doc/manual/\n\n# decrypt passwords\nsource \"gpg -d ~/.mutt/passwords.gpg |\"\n\n# Change the following six lines to match your Gmail account details\nset imap_user = \"mark.mcdx@gmail.com\"\nset smtp_url = \"smtp://mark.mcdx@gmail.com@smtp.gmail.com:587/\"\nset smtp_authenticators = \"gssapi:login\"\nset from = \"mark.mcdx@gmail.com\"\nset realname = \"Mark McDonnell\"\n\n# Change the following line to a different editor you prefer.\nset editor = \"vim\"\n\n# Configuration\nset folder = \"imaps://imap.gmail.com:993\"\nset spoolfile = \"+INBOX\" # default view would otherwise be 'All Mail'\nset imap_check_subscribed\nset hostname = gmail.com\nset mail_check = 15\nset timeout = 30\nset imap_keepalive = 300\nset postponed = \"+[GMail]/Drafts\"\nset record = \"+[GMail]/Sent Mail\"\nset trash = \"imaps://imap.gmail.com/[Gmail]/Trash\"\nset header_cache=~/.mutt/cache/headers\nset message_cachedir=~/.mutt/cache/bodies\nset certificate_file=~/.mutt/certificates\nset move = no\nset include = yes # include previous email as quote when replying\nset sort = 'threads'\nset sort_aux = 'reverse-last-date-received'\nset auto_tag = yes\nset pager_stop = yes # prevent opening the next message when reached the end of current message\nignore \"Authentication-Results:\"\nignore \"DomainKey-Signature:\"\nignore \"DKIM-Signature:\"\nhdr_order Date From To Cc\nalternative_order text/plain text/html *\nauto_view text/html\nbind editor \u003cTab\u003e complete-query\nbind editor ^T complete\nbind editor \u003cspace\u003e noop # You need the \"noop\" bind so that the line editor accepts IMAP folders with spaces in their names\nmacro index,pager d \"\u003csave-message\u003e=[Gmail]/Trash\u003center\u003e\u003center\u003e\u003crefresh\u003e\" \"Trash\"\nmacro index gi \"\u003cchange-folder\u003e=INBOX\u003center\u003e\" \"Go to inbox\"\nmacro index ga \"\u003cchange-folder\u003e=[Gmail]/All Mail\u003center\u003e\" \"Go to all mail\"\nmacro index gs \"\u003cchange-folder\u003e=[Gmail]/Starred\u003center\u003e\" \"Go to starred messages\"\nmacro index gd \"\u003cchange-folder\u003e=[Gmail]/Drafts\u003center\u003e\" \"Go to drafts\"\nmacro index,pager gt \"=[Gmail]/Sent Mail\" \"Go to 'Sent Mail'\"\nmacro index,pager gl ?       \"Go to 'Label'\"\nmacro index,pager I  O  \"Mark as read\"\nmacro index,pager U  O  \"Mark as unread\"\n\n# pip install goobook\n# https://gitlab.com/goobook/goobook\nset query_command=\"goobook query %s\"\nmacro index,pager a \"\u003cpipe-message\u003egoobook add\u003creturn\u003e\" \"add sender to google contacts\"\nbind editor \u003cTab\u003e complete-query\n\n# COLORS\ncolor attachment brightmagenta black\ncolor error brightwhite magenta   # errors yell at you in pink/magenta\ncolor hdrdefault yellow black   # headers\ncolor indicator black brightyellow # currently selected message\ncolor markers brightcyan black  # the + for wrapped pager lines\ncolor message brightcyan black  # informational messages, not mail\ncolor normal white black    # plain text\ncolor quoted magenta black  # quoted text\ncolor search brightgreen black # hilite search patterns in the pager\ncolor signature red black    # signature (after \"-- \") is red\ncolor status white red # status bar is yellow *on blue*\ncolor tilde blue black  # ~'s after message body\ncolor tree red black    # thread tree in index menu\ncolor signature brightred black\ncolor underline yellow black\ncolor header cyan black ^(From|Subject): # Important headers\ncolor body green black \"(ftp|http)://[^ ]+\"  # picks up URLs\ncolor body green black [-a-z_0-9.]+@[-a-z_0-9.]+\n\n#  Coloring quoted text - coloring the first 7 levels:\ncolor quoted    cyan black\ncolor quoted1   yellow black\ncolor quoted2   red black\ncolor quoted3   green black\ncolor quoted4   cyan black\ncolor quoted5   yellow black\ncolor quoted6   red black\ncolor quoted7   green black\n\n#  Colorize smileys:  :-)  ;-)  :-/  :-(\ncolor body  yellow black \"[;:]-[)/(|]\"\ncolor body  yellow black \"[;:][)/(|]\"\ncolor body  green black \"[[:alpha:]]\\+://[^ ]*\"\n\ncolor index brightyellow black ~N      # New\ncolor index magenta black ~O           # Old\ncolor index red black ~F\ncolor index blue black ~T\ncolor index red black ~D\n","tags":""},{"id":"3829b02d798a7668d662cdf54ec74d2a","title":"[curl via US proxy] ","content":"curl -s \"https://gimmeproxy.com/api/getProxy?protocol=socks5\u0026country=US\" | jq '.curl' | xargs -I {} curl -sv -o /dev/null -H \"Fastly-Debug:1\" --socks5 {} \"https://www.buzzfeed.com/amphtml/robinedds/can-you-score-full-marks-in-this-capital-city-minefield-quiz\"\n","tags":"#curl #proxy"},{"id":"d0732065f2d230d5e715bc186546bf90","title":"[Wait for multiple Python futures to finish using asyncio.wait()] ","content":"import time\nimport asyncio\nimport requests\n\ndomain = 'http://integralist.co.uk'\na = '{}/foo?run={}'.format(domain, time.time())\nb = '{}/bar?run={}'.format(domain, time.time())\n\nasync def get(url):\n   print('start: ', url)\n   r = requests.get(url)\n   print('done: ', url)\n   return await asyncio.sleep(0, result=r)\n\nasync def get_pages(x, y):\n   tasks = [get(x), get(y)]\n   done, pending = await asyncio.wait(tasks, return_when=FIRST_COMPLETED) # also FIRST_EXCEPTION and ALL_COMPLETED (default)\n   print('\u003e\u003e done: ', done)\n   print('\u003e\u003e pending: ', pending) # will be empty if using default return_when setting\n\nloop = asyncio.get_event_loop()\nloop.run_until_complete(get_pages(a, b))\nloop.close()\n","tags":"#asyncio #wait #concurrency #multiple #requests #httpclient"},{"id":"06f026435f47062562c4280b77399919","title":"Basic Shell Logger","content":"logger() {\n  DT=$(date '+%Y/%m/%d %H:%M:%S')\n  echo \"$DT \u003cyour_service\u003e: $1\"\n}\n\nlogger 'hello'\n# 2016/11/19 12:36:51 \u003cyour_service\u003e: hello\n","tags":""},{"id":"229eaa0a688773e1cb5f5ea03facee6f","title":"Multiple asynchronous HTTP GET requests with Python's aiohttp and asyncio","content":"import time\nimport datetime\nimport asyncio\nimport aiohttp\n\ndomain = 'http://integralist.co.uk'\na = '{}/foo?run={}'.format(domain, time.time())\nb = '{}/bar?run={}'.format(domain, time.time())\n\nasync def get(url):\n    print('GET: ', url)\n    async with aiohttp.ClientSession() as session:\n        async with session.get(url) as response:\n            t = '{0:%H:%M:%S}'.format(datetime.datetime.now())\n            print('Done: {}, {} ({})'.format(t, response.url, response.status))\n\nloop = asyncio.get_event_loop()\ntasks = [\n    asyncio.ensure_future(get(a)),\n    asyncio.ensure_future(get(b))\n]\nloop.run_until_complete(asyncio.wait(tasks))\n","tags":""},{"id":"6c35d4f26c0c7bf5bdce7b95cfa906b3","title":"C Concepts","content":"- [Introduction](#introduction)\n- [Compilers](#compilers)\n- [Hello World](#hello-world)\n- [Constants vs Directives](#constants-vs-directives)\n- [Quotations](#quotations)\n- [Char Type](#char-type)\n- [Null Terminator](#null-terminator)\n- [Pointers](#pointers)\n- [Arrays](#arrays)\n- [Enumerators](#enumerators)\n- [Memory Allocation with different Types](#memory-allocation-with-different-types)\n- [Reallocating Memory](#reallocating-memory)\n- [Function Prototypes](#function-prototypes)\n\n## Introduction\n\nThis isn't a 'How to program in C' tutorial, this is just a grouping of topics/concepts from the C language that I found interesting while learning the language (from the perspective of an already establed developer). Some of the things I make mention of I have used in other languages but I feel are worth covering still as they might not be immediately obvious to everyone.\n\nWhen writing a program in a language like [C](https://en.wikipedia.org/wiki/C_(programming_language)), that by itself is not executable (i.e. you can't run a C file). So you need to convert the C source code into [machine code](https://en.wikipedia.org/wiki/Machine_code) (i.e. something the computer's CPU can understand).\n\nMachine code is as low-level as you can get when interacting with a computer. So the C language is considered a 'higher-level' abstraction to save us from having to write machine code ourselves. A language like [Python](https://www.python.org/) is an even 'higher-level' abstraction to save us from having to write C (i.e. the Python language is actually written in C).\n\nIn order to convert C code into machine code, we need a compiler.\n\n\u003e Strictly speaking you also need a [linker](https://en.wikipedia.org/wiki/Linker_(computing)) which takes multiple compiled objects and places them into a single executable file. Generally speaking, when we say \"compile a C file\", we're really combining two separate processes (compiling and linking) into the single generic term \"compile\"\n\n## Compilers\n\nTo compile C source code into an executable you need a compiler, of which there are many options. The two most popular being LLVM's `clang` and GNU's `gcc`.\n\nYou might find there is a `cc` available, but typically this is aliased to an existing compiler.\n\nAlso, Mac doesn't provide a compiler by default. But if you install X-Code you'll get the LLVM's suite of compilers. Below we see that we get quite a few alias' and all of them point to the same embeded LLVM compiler:\n\n```sh\n$ gcc --version\nConfigured with: --prefix=/Applications/Xcode.app/Contents/Developer/usr --with-gxx-include-dir=/usr/include/c++/4.2.1\nApple LLVM version 8.0.0 (clang-800.0.38)\nTarget: x86_64-apple-darwin15.6.0\nThread model: posix\nInstalledDir: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin\n                                                                   \n$ llvm-gcc --version\nApple LLVM version 8.0.0 (clang-800.0.38)\nTarget: x86_64-apple-darwin15.6.0\nThread model: posix\nInstalledDir: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin\n                                                                   \n$ clang --version\nApple LLVM version 8.0.0 (clang-800.0.38)\nTarget: x86_64-apple-darwin15.6.0\nThread model: posix\nInstalledDir: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin\n                                                                   \n$ cc --version\nApple LLVM version 8.0.0 (clang-800.0.38)\nTarget: x86_64-apple-darwin15.6.0\nThread model: posix\nInstalledDir: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin\n```\n\nThe first two alias' `gcc` and `llvm-gcc` are confusing and a bit misleading as their not GNU's version. They're still the LLVM's compiler but in the first instance (`gcc`) the compiler is configured to use some additional libraries that are provided by c++ \n\nIt's worth noting that even with a plain C file all these alias' work to compile the source code into an executable. It's just they allow you to utilise additional extensions not provided by the standard c language.\n\nLLVM's licensing is BSD, meaning Apple can embed it within their own software that is not GPL-licensed. Typically LLVM's compiler is faster, but in some cases might not support all the same targets as GNU's.\n\n\u003e For more comparison details see http://clang.llvm.org/comparison.html\n\n### C11 support\n\nYou'll find that some functions provided within C aren't safe. They allow for overflow of data because they don't check that the array defined is able to contain the strings being manipulated.\n\nC11 compatible compilers will provide an additional set of string functions that are safe.\n\n```c\n#include \u003cstdio.h\u003e\n\nint main(void)\n{\n  #if defined __STDC_LIB_EXT1__\n    printf(\"Optional functions are defined.\\n\");\n  #else\n    printf(\"Optional functions are not defined.\\n\");\n  #endif\n  \n  return 0;\n}\n```\n\nIf your compiler supports these optional (safe) string functions, then to enable them you need to add a `define` directive that modifies the subsequent header file. But you need to add this directive _before_ you include the preprocessor directive that imports the `string.h` header:\n\n```c\n#define __STDC_WANT_LIB_EXT1__ 1\n#include \u003cstring.h\u003e\n```\n\nIf you don't set `__STDC_WANT_LIB_EXT1__` to `1`, then the header `string.h` will utilise the old (unsafe) string functions.\n\n## Hello World\n\n```c\n#include \u003cstdio.h\u003e          // pre-processor directive to include code file at compile time\n#define NAME \"World\"        // pre-processor directive to substitute any reference to NAME _before_ compilation\n\n// returns an int type and takes in no arguments (void)\nint main(void) {\n  printf(\"hello %s\", NAME); // can't use single quotes\n  return 0;                 // zero indicates no problems\n}\n```\n\n\u003e It's important to note that the directives `#include` and `#define` are 'processed' at the start of the compilation process. This is at the request of the compiler. It'll be one of the compiler's first steps (to pull in the preprocessor and have it ensure the file is setup ready for the reset of the compilation)\n\nYou compile it like so:\n\n```sh\ncc hello-world.c -o hw\n```\n\nNow you have a macOS compatible executable:\n\n```sh\n./hw # prints the message \"Hello World\"\n```\n\n\u003e To cross-compile for another OS (e.g. Linux) then use Docker or a VM\n\n## Constants vs Directives\n\nWe saw in the above 'Hello World' example the use of the directive `#define` which allowed us to use a single identifier (`NAME` in this case) throughout our program. The benefit is that we can change the value once and have it updated everywhere.\n\nBut do not get this confused with a variable. It is not. This is just a sequence of characters that are blindly replaced at the pre-processing stage. The value assigned to `NAME` will be replaced inside your program regardless of whether it's valid code or not. Meaning it could cause the compiler to error in an unclear way.\n\nOn the other hand you can define a proper constant like so:\n\n```c\n#include \u003cstdio.h\u003e\n\nint main(void) {\n  const char NAME[] = \"World\";\n  printf(\"Hello %s\", NAME);\n  return 0;\n}\n```\n\nWhat this gives you is a variable that has an actual type assigned to it. Meaning the compiler will help you identify an incorrect value if necessary much more easily than using the `#define` directive.\n\n## Quotations\n\nIn C single quotes denote a `char` type and double quotes denote a string.\n\nSo if you had the following code:\n\n```c\nchar foo = 'a';\nprintf(\"foo: %s\\n\", foo);\n```\n\nIt would error with:\n\n```\nformat specifies type 'char *' but the argument has type 'char'\n```\n\nTo get it to work you need to provide the memory address location of `foo` using the address-of operator (`\u0026`):\n\n```c\nchar foo = 'a';\nprintf(\"foo: %s\\n\", \u0026foo);\n```\n\nWe'll come back to the `\u0026` operator (and understand what `*` means) later, when we discuss [pointers](#pointers).\n\n## Char Type\n\nWhen creating a variable, and assigning a string to it, the value assigned is really a pointer to a location in memory.\n\nThe `char` type is used when storing characters such as `'a'`, but it also allows storing of strings `\"abc\"`. \n\nWhen assigning a string, the pointer is to an _array_ where each element of the array is a character of the provided string. For example the string `\"abc\"` would be stored in an array that looked something like: \n\n```c\n[\"a\", \"b\", \"c\"]\n```\n\nThis happens even if the string you provide is just one character. Although, depending on your program's design, it could be argued that you should not have assigned a single character string, but instead used single quotes to represent a single `char`. \n\nWhen assigning a character (e.g. `a`) to a variable of type `char` it takes on dual duty. Meaning the char type variable can represent the specific character `a` but really it stores the ASCII integer code that defines that character. \n\nWe can also directly assign an integer instead of `a` to the char type variable, and because of these characteristics we can perform arithmetic on the variable:\n\n```c\n#include \u003cstdio.h\u003e\n\nint main(void) {\n  char foo = 'a';\n  printf(\"foo: %c (%d)\\n\", foo, foo); // a (97)\n  foo = foo + 2;\n  printf(\"foo: %c (%d)\\n\", foo, foo); // c (99)\n  return 0;\n}\n```\n\n## Null Terminator\n\nConsider the following code:\n\n```c\nchar my_string[2] = \"a\";\n```\n\nThe reason we specify a length of 2 is because the underlying array that `my_string` is being pointed towards looks like this:\n\n```c\n[\"a\", \"\\0\"] // yes it has two elements\n```\n\nThe last element is known as the null terminator. When this data is stored in memory, we can now start at the location in memory where it is stored (its _address_) and then step through memory until we reach the null terminator; where we'll then find the end of the string.\n\n\u003e Note: in some cases you can set your variable to be the actual length of the content (e.g. `char my_string[1] = \"a\";`) but in some instances this can cause strange overlaps of data and strictly speaking isn't valid code either\n\n## Pointers\n\nWhen declaring a variable the computer sets aside some memory for the variable. \n\nNext the variable name is linked to the location in memory that was set aside for it. \n\nLastly the value you want to assign to the variable is placed into the relevant location of memory.\n\nLet's consider the following code:\n\n```c\n#include \u003cstdio.h\u003e\n\nint main(void) {\n  int foo = 1;\n  printf(\"foo: %d\\n\", foo);\n\n  int *bar;\n  int bar_val = 1;\n  printf(\"bar_val: %d\\n\", bar_val);\n  bar = \u0026bar_val;\n  printf(\"bar: %p\\n\", bar);\n  int bar_get_val = *bar;\n  printf(\"bar_get_val: %d\\n\", bar_get_val);\n\n  return 0;\n}\n```\n\nSo we see that we create a `foo` variable and assign `1` to it. We then print that integer in the typical way.\n\nNext we make a slightly more convoluted version, but this time we utilise a pointer to help us understand what they do.\n\nHere are each of the steps broken down:\n\n- `int *bar;`: we declare a pointer variable called `bar` of type `int` † (we don't initialize it with a value)\n- `int bar_val = 1;`: we both declare and initialize the variable `bar_val` as type `int`\n- `bar = \u0026bar_val;`: we initialize the pointer variable `bar` to store the memory address location of `bar_val`\n- `int bar_get_val = *bar;`: we dereference the address (i.e. follow the pointer) assigned to `bar`\n\n\u003e † meaning we will be assigning an address to this pointer  \n\u003e and the content at that memory address location will also be of type `int`\n\nThe output of this program is:\n\n```\nfoo: 1\nbar_val: 1\nbar: 0x7fff59a1769c\nbar_get_val: 1\n```\n\nOK, so there are some things that we need to clarify and that's the `*` and `\u0026` operators.\n\n- `*`: value-at-address operator (used when declaring a pointer \u0026 when dereferencing a pointer)\n- `\u0026`: address-of operator (used to reference the memory address of a variable)\n\nThe first thing we should be aware of is that we're not able to print a declared variable that has no value initialized for it. So imagine the following code:\n\n```c\nint *bar;\nprintf(\"bar: %d\\n\", bar);\n```\n\nThis would cause the following compiler error:\n\n```\nformat specifies type 'int' but the argument has type 'int *'\n```\n\nWhich makes sense, as we've declared the variable as the type `*bar`. So we can fix that:\n\n```c\nint *bar;\nprintf(\"bar: %d\\n\", *bar);\n```\n\n\u003e Notice we try to use `*` to dereference the value of `bar`\n\nBut this still errors, but now with:\n\n```\nvariable 'bar' is uninitialized when used here\n```\n\nWhich again makes sense. Nothing more to say about that portion of the code, I just wanted to make it clear what happens when you try to print an uninitialized variable (and also what happens when that variable is a pointer type).\n\nContinuing through the program, the next line of interest is:\n\n```c\nbar = \u0026bar_val;\n```\n\nWhich gives us the actual location in memory for the variable `bar_val` (i.e. `0x7fff59a1769c`). So the value assigned to `bar` isn't `1`, but the address of `1` in memory.\n\nFinally, we declare and initialize the variable `bar_get_val` with the actual value of `1`, and we do that by using `*` to deference the variable `bar` which contains a memory address:\n\n```c\nint bar_get_val = *bar;\n```\n\nThat is `bar` holds a _memory address_, which isn't a concrete value, it's an indirection to somewhere else. Hence we would say `bar` _points_ to the actual value's location and why we use the 'value-at-address' operator to deference the value.\n\nThe following code shows how to print the location in memory of a variable even if it wasn't declared as a pointer, simply by using the address-at operator `\u0026` which itself indicates a pointer to another location:\n\n```c\nchar foo = 'a';\nprintf(\"address of foo: %p\\n\", \u0026foo);\n```\n\nRemember, a memory address isn't the value but a reference to where the value can be found. One analogy I've seen is of your home address on an envelope: the envelope isn't your home, nor is the address written on the envelope. The envelope just indicates where your home can be found.\n\nOne last thing to consider/remember is that C doesn't have a String type. It stores strings in an array data structure. An array will automatically return the address location of the first element to the variable it is assigned to. This is why you may have seen a `char` pointer being assigned a variable _without_ the need to use the `\u0026` operator to get the memory address of that variable (because the variable, in this case an array, already provides a memory address).\n\nThe following example shows this:\n\n```c\nchar message[6] = \"hello\"; // array data structure used and memory location for message[0] returned\nchar *messagePtr = message; // no need to use \u0026message now\nprintf(\"my pointer: %p\\n\", messagePtr);\nprintf(\"my message: %s\\n\", message);\n```\n\n\u003e Note: for comparison of C pointers and Go pointers see https://dave.cheney.net/2014/03/17/pointers-in-go\n\nIn C there are two ways to define a pointer: \n\n1. `char* foo` \n2. `char *foo` \n\nBoth of which are equivalent. \n\nAlthough the first seems like the clearer option (as a newbie would read it: \"define a variable called `foo` of type 'character pointer'\") compared to the second option (which could lead them to think the variable name was `*foo` not `foo`). For me the second option is preferred because otherwise the following code becomes a bit ambiguious:\n\n```c\nchar* foo, bar;\n```\n\nYou might (incorrectly) think this would create two variables, both of type 'character pointer', but really only `foo` is the pointer and `bar` is a normal `char` type.\n\nWhere as using the second format (`char *foo`), this code becomes much clearer:\n\n```c\nchar *foo, bar;\n```\n\nLastly, if you want to create a `const` that happens to be a pointer, then the syntax is as follows:\n\n```c\nint count = 43;\nint *const pcount = \u0026count;\n```\n\nWe prefix the `const` keyword with the value-at operator `*` and not the variable name.\n\n## Arrays\n\nConsider the following code (which is broken by the way):\n\n```c\n#include \u003cstdio.h\u003e\n\nint main(void) {\n  char my_string = \"abc\";\n  printf(\"my_string: %s\", my_string);\n\n  return 0;\n}\n```\n\nThis code has the following compiler error:\n\n```\nincompatible pointer to integer conversion initializing 'char' with an expression of type 'char [4]'\n```\n\nWhat this error tells us is that the variable `my_string` has a type of `char [4]`, meaning it is actually an array (hence the `[4]` syntax) and so we should have declared the variable like so:\n\n```c\nchar my_string[4] = \"abc\";\n```\n\nWe saw why this is earlier when talking about [null terminators](null-terminator). But just to recap, it's because a string should be stored within an array data structure. So we need to declare it as an array data structure.\n\nWe also learned earlier (using this example) why the length of the array is 4 and not 3 (which you may initially have expected which a string of three characters), again to recap: this is because of the extra element added to the array for you \"\\0\" (the null terminator).\n\nSo, the reason I'm talking about arrays is because in the original code above (the one before declaring the variable correctly) there were actually two errors linked together. The second part of the error was:\n\n```\nformat specifies type 'char *' but the argument has type 'char'\n```\n\nWhat this error tells us is that `printf` was expecting a pointer but all it got was something of a `char` type. \n\nWhen declaring the variable as an array, we fix both errors.\n\nBut both these errors has led some people to incorrectly assume that an array is a pointer, when it is not.\n\nLet's recap why this works. \n\nWhen assigning a string, the compiler expects the contents to be stored within an array. Each element within the array is a address to the value given to it in memory. \n\nSo in our example above (i.e. the string `\"abc\"`), `\"a\"` is stored in memory and the address of that memory is placed in `my_string[0]`. Next `\"b\"` is stored in memory and the address of that memory is placed in `my_string[1]` and so on.\n\nA pointer in contrast is a single location in memory, where as an array hold lots of memory addresses.\n\nBecause of this, an array variable automatically points to the first element within the array.\n\nThis is why if you try to `printf` a string, the compiler will complain if you don't provide a pointer. Because it expects a string to have been stored within an array (which our earlier example didn't). But when storing a string inside an array, the variable that is passed to `printf` would _already_ be a pointer, due to it automatically referencing the first array element as its value.\n\n\u003e Interestingly, an array's type is made up of the element type + the overall array dimension. So `int foo[3]` is a different type to `int bar[4]`. Even though the value type `int` is the same, the array dimension (size/length) is different.\n\nAlso, the number of bytes that an array will occupy is the number of elements multiplied by the size of each element.\n\nLastly, you can define and initialize a string _without_ specifying an array dimension (i.e. no size):\n\n```c\nchar foobar[] = \"No dimension provided!\";\n```\n\nIt leaves it up to the compiler to allocate the required dimension. You can only do this when you initialize the variable with a value. You could use `char foobar[];` as there is no value for the compiler to utilise to know how much memory to allocate.\n\n## Enumerators\n\nEnumerators allow you to define new variable types. They automatically assign numerical values to each of the identifiers within the enumerator (although you do also have control over the specific values as well). This concept is best explained by way of example:\n\n```c\n#include \u003cstdio.h\u003e\n\nint main(void) {\n  enum weekend {Saturday, Sunday};     // 0, 1\n  enum weekend today = Sunday;         // 1\n  enum weekend saturday = Saturday;    // 0\n  enum weekend yesterday = today - 1;  // 0 now yesterday is Saturday\n  printf(\"today %d\\n\", today);\n  printf(\"saturday %d\\n\", saturday);\n  printf(\"yesterday %d\\n\", yesterday);\n  return 0;\n}\n```\n\nIf you wish to provide your own values you can:\n\n```c\nenum bool {\n  true = 1,\n  false = 2\n};\n\nenum bool on = true;\nenum bool off = false;\n\nprintf(\"on: %d\", on);   // 1\nprintf(\"off: %d\", off); // 2\n```\n\n## Memory Allocation with different Types\n\n\u003e See [here](http://www.integralist.co.uk/posts/bits.html) for understanding RAM and bits\n\n### Array\n\nConsider the following code:\n\n```c\nint foo[3] = {1,2,3};\nprintf(\"foo variable points to = %p\\n\", foo);\n\nint i = 0;\ndo {\n  printf(\"foo[%u] = %p\\n\", i, (void *)(\u0026foo[i]));\n  i++;\n} while(i \u003c 3);\n\nprintf(\"sizeof(foo) = %lu\\n\", sizeof(foo));\n```\n\nSo in this piece of code we create an array and assign it to `foo`. \n\nNext we print out what the `foo` variable points, which for me outputs:\n\n```\nfoo variable points to = 0x7fff525fd6ac\n```\n\nThen we loop over the `foo` array and print out each element's address, which for me outputs:\n\n```\nfoo[0] = 0x7fff525fd6ac\nfoo[1] = 0x7fff525fd6b0\nfoo[2] = 0x7fff525fd6b4\n```\n\nNotice that the `foo` variable and the first element of the `foo` array are the same value: `0x7fff525fd6ac` which is the address of the memory location for the value `1` assigned to `foo[0]`.\n\n\u003e Note: `(void *)(\u0026foo[i])` is interesting in that we're casting the address to `void`. You don't need to do this unless you're passing a variable that is itself a pointer variable to another variable (e.g. `int foo = 1; int *pFoo = foo`) and for that situation you would cast to `void` to prevent a possible warning from the compiler. When using `%p` it will expect the value to be a pointer type, but in cases where you have a pointer variable assigned an `int` variable, then the type of `\u0026pFoo` would actually be a 'pointer to pointer to int'.\n\nFinally we print the size of the `foo` variable, which outputs:\n\n```\nsizeof(foo) = 12\n```\n\nYou might wonder  where the value `12` comes from? Well, this goes back to how data is stored in memory (i.e. a block of memory is 1 byte; so 8 bits). We defined the type of the array to be `int` and (depending on the compiler) that will be either two bytes, four bytes or eight bytes. \n\nFor most 32 bit systems the size of `int` would be four bytes. You can always use `sizeof(int)` to check:\n\n```c\nprintf(\"sizeof(int): %ld\\n\", sizeof(int)); // 4\n```\n\nSo looking back at our example, we have three array elements, and if each element takes up four bytes then it makes sense the size of the array would be `12` (i.e. `4 + 4 + 4 = 12`).\n\nTo calculate the number of items within the array itself, rather than the number of bytes, you can use:\n\n```c\nsize_t element_count = sizeof foo/sizeof foo[0];\nprintf(\"element_count: %zu\\n\", element_count); // 3\n```\n\n\u003e Note: `%z` is for `size_t` and the `u` prevents a `invalid conversion specifier` error.\n\n### Signed vs Unsigned\n\nIn C you can define an integer to be either `signed` or `unsigned`. The former means the number can be both negative and positive as well as zero. \n\nSo typically, if a number is negative, you'll prefix it with `-`. If the number is positive, then it is just the number. For example, `-1` and `1`. \n\nYou don't need to explicitly provide the `signed` keyword (e.g. `signed int \u003cvar_name\u003e`), it's just implied.\n\nThe latter (`unsigned`) is an integer that can only be positive. So if you need to store an integer and you know the value will always be zero or positive, then you can define it as being unsigned and the compiler can make appropriate optimisations based on that understanding.\n\nSo although the underlying memory allocation is the same for signed or unsigned, the actual values represented are slightly different in that unsigned allows for storing values that are twice the size of signed, because half of signed's values have to account for negatives.\n\n## Reallocating Memory\n\nWith strings you typically define them as follows (i.e. the underlying data structure is an array):\n\n```c\nchar names[20] = \"hello\";\n```\n\nBut this means there is reserved memory that is wasted and if reading from stdin (e.g. user input), then the amount of characters entered could exceed the specified reserved memory allocation.\n\nBelow is an example, given as a [Stack Overflow](http://stackoverflow.com/questions/8164000/how-to-dynamically-allocate-memory-space-for-a-string-and-get-that-string-from-u), that reads each character from stdin and reallocates the memory space if required (it's advised that you should ensure reallocation of memory is done as a multiple; such as double the size):\n\n```c\nchar *getln()\n{\n    char *line = NULL, *tmp = NULL;\n    size_t size = 0, index = 0;\n    int ch = EOF;\n\n    while (ch) {\n        ch = getc(stdin);\n\n        /* Check if we need to stop. */\n        if (ch == EOF || ch == '\\n')\n            ch = 0;\n\n        /* Check if we need to expand. */\n        if (size \u003c= index) {\n            size += CHUNK;\n            tmp = realloc(line, size);\n            if (!tmp) {\n                free(line);\n                line = NULL;\n                break;\n            }\n            line = tmp;\n        }\n\n        /* Actually store the thing. */\n        line[index++] = ch;\n    }\n\n    return line;\n}\n```\n\nThere is a very good blog post that covers the steps in detail here: https://brennan.io/2015/01/16/write-a-shell-in-c/. \n\nThey're effectively the same implementation (in principle), except for the use of `getchar` vs `getc` (the former can only read from stdin, where as `getc` can read from any input stream).\n\n```c\n#define LSH_RL_BUFSIZE 1024\nchar *lsh_read_line(void)\n{\n  int bufsize = LSH_RL_BUFSIZE;\n  int position = 0;\n  char *buffer = malloc(sizeof(char) * bufsize);\n  int c;\n\n  if (!buffer) {\n    fprintf(stderr, \"lsh: allocation error\\n\");\n    exit(EXIT_FAILURE);\n  }\n\n  while (1) {\n    // Read a character\n    c = getchar();\n\n    // If we hit EOF, replace it with a null character and return.\n    if (c == EOF || c == '\\n') {\n      buffer[position] = '\\0';\n      return buffer;\n    } else {\n      buffer[position] = c;\n    }\n    position++;\n\n    // If we have exceeded the buffer, reallocate.\n    if (position \u003e= bufsize) {\n      bufsize += LSH_RL_BUFSIZE;\n      buffer = realloc(buffer, bufsize);\n      if (!buffer) {\n        fprintf(stderr, \"lsh: allocation error\\n\");\n        exit(EXIT_FAILURE);\n      }\n    }\n  }\n}\n```\n\n\u003e Notice `c` variable is declared as an `int` and not a `char`, the author of the blog post makes mention of this as being because `EOF` is an `int` type\n\nThe author then goes on to explain that in more recent releases, there is a much shorter version that can be implemented thanks to the `getline` function:\n\n```c\nchar *lsh_read_line(void)\n{\n  char *line = NULL;\n  ssize_t bufsize = 0; // have getline allocate a buffer for us\n  getline(\u0026line, \u0026bufsize, stdin);\n  return line;\n}\n```\n\n## Function Prototypes\n\nA compiler will error if you try to call a function before it has been defined. This can be mitigated by utilising function prototypes that let you define the signature of the function up front and defer the definition until a later point in time (sort of like defining an interface type):\n\n```c\n// Function prototypes\nint Foo(double data_values[], size_t count);\nint Bar(double *x, size_t n);\n\nint main(void) {\n  int f = Foo(...signature...);\n  int b = Bar(...signature...)\n}\n\n// Definitions for Foo() and Bar()\n```\n","tags":""},{"id":"0d2f7f156aea02fce362523dd4fc185c","title":"Kali Linux Vim + Bash setup","content":"# use VirtualBox's device menu to insert Guest Additions CDROM\n# copy VBoxLinuxAdditions.run from mounted CDROM\n# then eject the CDROM, run the script and then shutdown the VM\n# you'll then go into VirtualBox and setup shared directories etc\n\ncd ~ \u0026\u0026 eject /media/cdrom0\nsudo chmod 755 VBoxLinuxAdditions.run \n./VBoxLinuxAdditions.run\n\ncurl https://raw.githubusercontent.com/git/git/master/contrib/completion/git-prompt.sh -o ~/.git-prompt.sh\n\ncurl https://raw.githubusercontent.com/rcaloras/bash-preexec/master/bash-preexec.sh -o ~/.bash-preexec.sh\n\nmkdir -p ~/.vim/{autoload,bundle,colors}\ncurl -LSso ~/.vim/colors/integralist.vim https://raw.githubusercontent.com/Integralist/dotfiles/master/.vim/colors/integralist.vim\ncurl -LSso ~/.vim/autoload/pathogen.vim https://tpo.pe/pathogen.vim\ncurl -LSso ~/.vim/plugins https://raw.githubusercontent.com/Integralist/dotfiles/master/voom/plugins\ncurl -LSso /usr/local/bin/voom https://raw.githubusercontent.com/airblade/voom/master/voom\nchmod 744 /usr/local/bin/voom\nalias voom='VIM_DIR=~/.vim voom'\n\nsudo apt-get install neovim\nln -s ~/.vim ~/.config/nvim\nln -s ~/.vimrc ~/.config/nvim/init.vim\n\ncurl -LSso ~/googler-completion.bash https://raw.githubusercontent.com/jarun/googler/master/auto-completion/bash/googler-completion.bash\n\napt-get install git\ngit --version\n\nadd-apt-repository ppa:pgolm/the-silver-searcher\napt-get update\napt-get install silversearcher-ag\n\napt-get install tree\n\ncurl https://sift-tool.org/downloads/sift/sift_0.9.0_linux_amd64.tar.gz -o /tmp/sift.tar.gz\ncd /tmp \u0026\u0026 tar xzf sift.tar.gz \u0026\u0026 cp sift/sift /usr/bin/sift\n\nmkdir Developer \u0026\u0026 cd Developer/\nmkdir Python{2,3} \u0026\u0026 cd Python3/\nsudo apt-get install -y make build-essential libssl-dev zlib1g-dev libbz2-dev libreadline-dev libsqlite3-dev wget curl llvm libncurses5-dev libncursesw5-dev xz-utils\ncurl -L https://raw.githubusercontent.com/yyuu/pyenv-installer/master/bin/pyenv-installer | bash\npyenv install 3.5.1\npyenv local 3.5.1 \npip install --upgrade pip\npip install pylint flake8 flake8-quotes pep8-naming\npip install --upgrade neovim\n\ncd ../Python2/\npyenv install 2.7.11\npyenv local 2.7.11\npip install --upgrade pip\npip install pylint flake8 flake8-quotes pep8-naming\npip install --upgrade neovim\n\n# copied modified files back to the host shared directory\ncp ~/.bashrc /media/sf_Developer/.bashrc\ncp ~/.vimrc /media/sf_Developer/.vimrc\n\nsed -i 's/XKBMODEL=\"pc105\"/XKBMODEL=\"macintosh\"/' /etc/default/keyboard # pc105 was old value\nreboot # needed for keyboard to take effect\n#!/usr/bin/env bash\n\n# https://github.com/git/git/blob/master/contrib/completion/git-prompt.sh\nsource ~/.git-prompt.sh\n\n# https://github.com/jarun/googler/blob/master/auto-completion/bash/googler-completion.bash\nsource ~/googler-completion.bash\n\n# tells Readline to perform filename completion in a case-insensitive fashion\nbind \"set completion-ignore-case on\"\n\n# filename matching during completion will treat hyphens and underscores as equivalent\nbind \"set completion-map-case on\"\n\n# will get Readline to display all possible matches for an ambiguous pattern at the first \u003cTab\u003e press instead of at the second\nbind \"set show-all-if-ambiguous on\"\n\n# no bell sound on error\nbind \"set bell-style none\"\n\n# enable emacs like bindings (\u003cC-a\u003e and \u003cC-e\u003e for start and end of line shortcuts)\nset -o emacs\n\n# append to the history file, don't overwrite it\nshopt -s histappend\n\n# save multi-line commands as one command\nshopt -s cmdhist\n\n# no need to type cd (works for .. but not -, although alias -- -='cd -' fixes it)\nshopt -s autocd 2\u003e/dev/null\n\n# autocorrect minor spelling errors\nshopt -s dirspell 2\u003e/dev/null\nshopt -s cdspell 2\u003e/dev/null\n\n# check windows size if windows is resized\nshopt -s checkwinsize 2\u003e/dev/null\n\n# use extra globing features. See man bash, search extglob.\nshopt -s extglob 2\u003e/dev/null\n\n# include .files when globbing.\nshopt -s dotglob 2\u003e/dev/null\n\n# case insensitive globbing\nshopt -s nocaseglob 2\u003e/dev/null\n\n# can be useful to utilise the gnu style error message format\nshopt -s gnu_errfmt 2\u003e/dev/null\n\n# ensure SIGHUP is sent to all jobs when an interactive login shell exits\nshopt -s huponexit 2\u003e/dev/null\n\n# custom environment variables\nexport GITHUB_USER=\"integralist\"\n\n# application configuration\nexport GOOGLER_COLORS=bjdxxy # https://github.com/jarun/googler/\nexport LSCOLORS=\"dxfxcxdxbxegedabagacad\" # http://geoff.greer.fm/lscolors/\nexport MANPAGER=\"less -X\" # Don't clear the screen after quitting a manual page\nexport EDITOR=\"vim\"\n\n# git specific configurations\nexport GIT_PS1_SHOWCOLORHINTS=true\nexport GIT_PS1_SHOWDIRTYSTATE=true     # * for unstaged changes (+ staged but uncommitted changes)\nexport GIT_PS1_SHOWSTASHSTATE=true     # $ for stashed changes\nexport GIT_PS1_SHOWUNTRACKEDFILES=true # % for untracked files\nexport GIT_PS1_SHOWUPSTREAM=\"auto\"     # \u003e for local commits on HEAD not pushed to upstream\n                                       # \u003c for commits on upstream not merged with HEAD\n                                       # = HEAD points to same commit as upstream\n\n# terminal configuration\nexport PROMPT_COMMAND='history -a' # record each line as it gets issued\n\n# history configuration\nexport HISTSIZE=500000\nexport HISTFILESIZE=100000\nexport HISTCONTROL=\"erasedups:ignoreboth\" # avoid duplicate entries\nexport HISTIGNORE=\"\u0026:[ ]*:exit:ls:bg:fg:history\" # don't record some commands\nexport HISTTIMEFORMAT='%F %T ' # useful timestamp format\n\n# force colours\nexport force_color_prompt=yes\n\n# use colour prompt\nexport color_prompt=yes\n\n# \\033[    -\u003e Indicates the beginning of color in the text\n# x;yzm    -\u003e Indicates color code\n# \\033[00m -\u003e Indicates the end of color in the text\n#\n# 00;30 = black\n# 00;31 = red\n# 00;32 = green\n# 00;33 = yellow\n# 00;34 = blue\n# 00;35 = purple\n# 00;36 = cyan\n# 00;37 = grey\n#\n# use 01 for background colour, rather than text colour\n\nfunction prompt_right() {\n  echo -e \"\"\n}\n\nfunction prompt_left() {\n  num_jobs=$(jobs | wc -l)\n\n  if [ \"$num_jobs\" -eq 0 ]; then\n    num_jobs=\"\"\n  else\n    num_jobs=\" (\\j)\"\n  fi\n\n  echo -e \"\\033[00;33m\\u.\\033[00m \\w/$num_jobs\\033[00;31m$(__git_ps1) \\033[00m(\\A)\" # \\A is the current time\n}\n\nfunction prompt() {\n  unset PS1\n  PS1=$(printf \"%s \\$ \" \"$(prompt_left)\")\n}\n\nfunction gms() {\n  git merge --squash \"$1\"\n}\n\nfunction gc {\n  if [ -z \"$1\" ]; then\n    printf \"\\n\\tUse: gc some-existing-branch-name\\n\"\n  else\n    git checkout \"$1\"\n  fi\n}\n\nfunction gcb {\n  if [ -z \"$1\" ]; then\n    printf \"\\n\\tUse: gcb some-new-branch-name (branch will be created)\\n\"\n  else\n    git checkout -b \"$1\"\n  fi\n}\n\n# We use _ to indicate an unused variable\n# Otherwise shellcheck will kick up a stink\n# shellcheck disable=SC2034\nread -r -d '' git_icons \u003c\u003c- EOF\n* unstaged changes\n+ staged but uncommitted changes\n$ stashed changes\n% untracked files\n\u003e local commits on HEAD not pushed to upstream\n\u003c commits on upstream not merged with HEAD\n= HEAD points to same commit as upstream\nEOF\n\n# use `type \u003calias\u003e` to see what is assigned to an alias/fn/builtin/keyword\nalias dotfiles=\"ls -a | grep '^\\.' | grep --invert-match '\\.DS_Store\\|\\.$'\"\nalias getcommit=\"git log -1 | cut -d ' ' -f 2 | head -n 1\"\nalias sshkey=\"ssh-keygen -t rsa -b 4096 -C 'mark.mcdx@gmail.com'\"\nalias ls=\"ls -GpF\"\nalias ll=\"ls -laGpFHh\"\nalias r=\"source ~/.bashrc\"\nalias cm=\"git checkout master\"\nalias c-=\"git checkout -\"\nalias gb=\"git branch\"\nalias gbd=\"git branch -D\"\nalias gcp=\"git cherry-pick -\"\nalias gpr=\"git pull --rebase origin master\"\nalias wat='echo \"$git_icons\"'\nalias wut='echo \"$git_icons\"'\nalias gitupstream=\"echo git branch -u origin/\\\u003cbranch\\\u003e\"\nalias drm='docker rm $(docker ps -a -q)'\nalias drmi='docker rmi $(docker images -q)'\nalias pipall=\"pip freeze --local | grep -v '^\\-e' | cut -d = -f 1  | xargs -n1 pip install -U\"\nalias uid='echo $(uuidgen)'\nalias datesec='date +%s'\n\nexport PATH=\"/root/.pyenv/bin:$PATH\"\neval \"$(pyenv init -)\"\neval \"$(pyenv virtualenv-init -)\"\n\n# https://raw.githubusercontent.com/rcaloras/bash-preexec/master/bash-preexec.sh\nsource ~/.bash-preexec.sh\n\n# preexec executes just BEFORE a command is executed\n# preexec() { echo \"just typed $1\"; }\n\n# precmd executes just AFTER a command is executed, but before the prompt is shown\nprecmd() { prompt; }\n\n# installation of vim plugins using Voom\n\n\" Use the system clipboard\nset clipboard+=unnamed\n\n\" Switch syntax highlighting on\nsyntax on\n\n\" Don't worry about trying to support old school Vi features\nset nocompatible\n\n\" Disable Mouse (this is something that only recently affected me within NeoVim)\n\" Seemed using the mouse to select some text would make NeoVim jump into VISUAL mode?\nset mouse=\n\n\" No backup files\nset nobackup\n\n\" No write backup\nset nowritebackup\n\n\" No swap file\nset noswapfile\n\n\" Command history\nset history=100\n\n\" Always show cursor\nset ruler\n\n\" Show incomplete commands\nset showcmd\n\n\" Incremental searching (search as you type)\nset incsearch\n\n\" Highlight search matches\nset hlsearch\n\n\" Ignore case in search\nset smartcase\n\n\" Make sure any searches /searchPhrase doesn't need the \\c escape character\nset ignorecase\n\n\" A buffer is marked as ‘hidden’ if it has unsaved changes, and it is not currently loaded in a window\n\" If you try and quit Vim while there are hidden buffers, you will raise an error:\n\" E162: No write since last change for buffer “a.txt”\nset hidden\n\n\" Turn word wrap off\nset nowrap\n\n\" Allow backspace to delete end of line, indent and start of line characters\nset backspace=indent,eol,start\n\n\" Convert tabs to spaces\nset expandtab\n\n\" Set tab size in spaces (this is for manual indenting)\nset tabstop=2\n\n\" The number of spaces inserted for a tab (used for auto indenting)\nset shiftwidth=2\n\n\" Turn on line numbers\nset number\n\n\" Highlight tailing whitespace\nset list listchars=tab:\\ \\ ,trail:·\n\n\" Get rid of the delay when pressing O (for example)\n\" http://stackoverflow.com/questions/2158516/vim-delay-before-o-opens-a-new-line\nset timeout timeoutlen=1000 ttimeoutlen=100\n\n\" Always show status bar\nset laststatus=2\n\n\" Set the status line to something useful\nset statusline=%f\\ %m\\ %=L:%l/%L\\ C:%c\\ (%p%%)\n\n\" UTF encoding\nset encoding=utf-8\n\n\" Autoload files that have changed outside of vim\nset autoread\n\n\" Better splits (new windows appear below and to the right)\nset splitbelow\nset splitright\n\n\" Highlight the current line\nset cursorline\n\n\" Ensure Vim doesn't beep at you every time you make a mistype\nset visualbell\n\n\" Visual autocomplete for command menu (e.g. :e ~/path/to/file)\nset wildmenu\n\n\" Redraw only when we need to (i.e. don't redraw when executing a macro)\nset lazyredraw\n\n\" Highlight a matching [{()}] when cursor is placed on start/end character\nset showmatch\n\n\" \u003cC-x\u003e\u003cC-k\u003e for word autocomplete\nset dictionary=/usr/share/dict/words\n\n\" Use Ag for :grep command (would use Sift but it doesn't work well)\nset grepprg=ag\\ --nogroup\\ --nocolor\n\n\" Set built-in file system explorer to use layout similar to the NERDTree plugin\n\" P opens file in previously focused window\n\" o opens file in new horizontal split window\n\" v opens file in new vertical split window\n\" t opens file in new tab split window\nlet g:netrw_liststyle=3\n\nexecute pathogen#infect()\nfiletype plugin indent on\n\nlet g:default_theme=\"gruvbox\"\n\nset background=dark\nexecute 'colorscheme ' . g:default_theme\n\n\" http://pep8.readthedocs.io/en/latest/intro.html#error-codes\n\" https://github.com/PyCQA/pep8-naming\nlet g:neomake_python_flake8_args = neomake#makers#ft#python#flake8()['args'] + ['--ignore', 'N802']\n\n\" http://pylint-messages.wikidot.com/all-codes\n\" http://pylint-messages.wikidot.com/all-messages\nlet g:neomake_python_pylint_args = neomake#makers#ft#python#pylint()['args'] + ['-d', 'missing-docstring,invalid-name']\n\n\" Enable both default Python linters\nlet g:neomake_python_enabled_makers = ['flake8', 'pylint']\n\n\" https://github.com/koalaman/shellcheck/wiki/SC1091\nlet g:neomake_sh_shellcheck_args = neomake#makers#ft#sh#shellcheck()['args'] + ['-e', 'SC1090,SC1091']\nlet g:neomake_bash_enabled_makers = ['shellcheck']\n\n\" General Neomake configuration\nlet g:neomake_open_list=2\nlet g:neomake_list_height=5\nlet g:neomake_verbose=3\n\n\" Run Neomake whenever we enter or write a buffer\nautocmd BufWritePost,BufWinEnter * silent Neomake\n\n\" The following configuration is useful if you don't like\n\" the icons (which are provided by default) for highlighting errors/warnings\n\"\n\" let g:neomake_warning_sign = {\n\"   \\ 'text': 'W',\n\"   \\ 'texthl': 'WarningMsg',\n\"   \\ }\n\" let g:neomake_error_sign = {\n\"   \\ 'text': 'E',\n\"   \\ 'texthl': 'ErrorMsg',\n\"   \\ }\n\n\" vim-go\nlet g:go_fmt_command = \"goimports\"\nlet g:go_metalinter_autosave = 1\nlet g:go_metalinter_autosave_enabled = ['vet', 'golint']\nlet g:go_metalinter_enabled = ['vet', 'golint', 'errcheck']\n\n\" tabular\nmap \u003cLeader\u003ee :Tabularize /=\u003cCR\u003e\nmap \u003cLeader\u003ec :Tabularize /:\u003cCR\u003e\nmap \u003cLeader\u003ees :Tabularize /=\\zs\u003cCR\u003e\nmap \u003cLeader\u003ecs :Tabularize /:\\zs\u003cCR\u003e\n\n\" ctrlp\nmap \u003cleader\u003et \u003cC-p\u003e\nmap \u003cleader\u003ey :CtrlPBuffer\u003cCR\u003e\nlet g:ctrlp_show_hidden=1\nlet g:ctrlp_working_path_mode=0\nlet g:ctrlp_max_height=30\nlet g:ctrlp_arg_map = 1 \" Override \u003cC-o\u003e to provide options for how to open files\nset wildignore+=*/.git/*,*/.hg/*,*/.svn/*.,*/.DS_Store \" Files matched are ignored when expanding wildcards\nlet g:ctrlp_user_command = 'ag %s -l --nocolor -g \"\"' \" Use Ag for searching instead of VimScript (might not work with ctrlp_show_hidden and ctrlp_custom_ignore)\nlet g:ctrlp_custom_ignore = '\\v[\\/]((node_modules)|\\.(git|svn|grunt|sass-cache))$' \" Directories to ignore when fuzzy finding\n\n\" ack\nlet g:ackprg = 'ag --nogroup --nocolor --column'\n\n\" vim-textobj-rubyblock\nruntime macros/matchit.vim\n\n\" vim-commentary\nxmap \u003cleader\u003e\u003cleader\u003e\u003cleader\u003e \u003cPlug\u003eCommentary\nnmap \u003cleader\u003e\u003cleader\u003e\u003cleader\u003e \u003cPlug\u003eCommentary\nomap \u003cleader\u003e\u003cleader\u003e\u003cleader\u003e \u003cPlug\u003eCommentary\nnmap \u003cleader\u003e\u003cleader\u003e\u003cleader\u003e \u003cPlug\u003eCommentaryLine\n\n\" gist\nlet g:github_user = $GITHUB_USER\nlet g:gist_detect_filetype = 1\nlet g:gist_open_browser_after_post = 1\n\n\" camelcase\nmap \u003csilent\u003e w \u003cPlug\u003eCamelCaseMotion_w\nmap \u003csilent\u003e b \u003cPlug\u003eCamelCaseMotion_b\nmap \u003csilent\u003e e \u003cPlug\u003eCamelCaseMotion_e\nsunmap w\nsunmap b\nsunmap e\n\n\" nofrils\nlet g:nofrils_strbackgrounds=1 \" enable highlighting of strings and mispellings\n\n\" NeoVim shortcut for quick terminal exit\n:silent! tnoremap \u003cEsc\u003e \u003cC-\\\u003e\u003cC-n\u003e\n\nfun! StripTrailingWhitespace()\n  \" Don't strip on these filetypes\n  if \u0026ft =~ 'markdown'\n    return\n  endif\n  %s/\\s\\+$//e\nendfun\nautocmd BufWritePre * call StripTrailingWhitespace()\n\nautocmd FileType gitcommit setlocal spell textwidth=72\nautocmd FileType markdown setlocal wrap linebreak nolist textwidth=0 wrapmargin=0 \" http://vim.wikia.com/wiki/Word_wrap_without_line_breaks\nautocmd FileType sh,cucumber,ruby,yaml,zsh,vim setlocal shiftwidth=2 tabstop=2 expandtab\nautocmd FileType php,python setlocal shiftwidth=4 tabstop=4 expandtab\n\n\" See `:h fo-table` for details of formatoptions `t` to force wrapping of text\nautocmd FileType python,ruby,go,sh,javascript setlocal textwidth=79 formatoptions+=t\n\n\" Set different colorscheme for Bash and VimL scripts\nautocmd BufEnter *.sh,*.vimrc,*.txt colorscheme github\nautocmd BufLeave *.sh,*.vimrc,*.txt execute 'set background=dark' | execute 'colorscheme ' . g:default_theme\n\n\" Specify syntax highlighting for specific files\nautocmd Bufread,BufNewFile *.spv set filetype=php\nautocmd Bufread,BufNewFile *.md set filetype=markdown \" Vim interprets .md as 'modula2' otherwise, see :set filetype?\n\n\" Run Goyo plugin on Markdown files for when I'm writing blog posts\nautocmd Bufread,BufEnter *.md,*.txt execute 'normal zR' | execute 'Goyo'\nautocmd BufLeave *.md,*.txt execute 'Goyo!'\n\n\" Automatically reload vimrc when it's saved\n\" autocmd BufWritePost .vimrc so ~/.vimrc\n\n\" Rainbow parenthesis always on!\nautocmd VimEnter * if exists(':RainbowParenthesesToggle') | exe \":RainbowParenthesesToggleAll\" | endif\n\n\" Change colourscheme when diffing\nfun! SetDiffColours()\n  highlight DiffAdd    cterm=bold ctermfg=white ctermbg=DarkGreen\n  highlight DiffDelete cterm=bold ctermfg=white ctermbg=DarkGrey\n  highlight DiffChange cterm=bold ctermfg=white ctermbg=DarkBlue\n  highlight DiffText   cterm=bold ctermfg=white ctermbg=DarkRed\nendfun\nautocmd FilterWritePre * call SetDiffColours()\n\n\" Map § key to :nohlsearch (or :noh for short)\nmap § :nohlsearch\u003cCR\u003e\n","tags":""},{"id":"ea1b8c52414579302c817606d3fe338d","title":"Can't replace or mv a file (e.g. like when using sed -i) when a file is bind mounted with Docker. So Vim to the rescue...","content":"vi -E -s /etc/resolv.conf \u003c\u003c-EOF\n  :1s/^/nameserver 127.0.0.1\\r/\n  :update\n  :quit\nEOF\n","tags":""},{"id":"c8f3bb0bca3ed23ae4b4a2780b05dc7a","title":"Setup DNSMASQ","content":"function configure_dnsmasq {\n  # https://help.ubuntu.com/community/Dnsmasq\n  apt-get install -y dnsmasq\n  sed -i 's/#listen-address=/listen-address=127.0.0.1/' /etc/dnsmasq.conf\n  sed -i 's/#user=/user=root/' /etc/dnsmasq.conf\n  sed -i 's/#prepend domain-name-servers 127.0.0.1;/prepend domain-name-servers 127.0.0.1;/' /etc/dhcp/dhclient.conf\n\n  # You can't use sed -i on a file that's bind mounted by Docker\n  # But you can 'edit' it still...\n  vi -E -s /etc/resolv.conf \u003c\u003c-EOF\n  :1s/^/nameserver 127.0.0.1\\r/\n  :update\n  :quit\nEOF\n\n  echo 'addn-hosts=/etc/hosts' \u003e\u003e /etc/dnsmasq.d/hosts.conf\n  /etc/init.d/dnsmasq restart\n}\nimport yaml\n\n\ndef upstreams(path):\n    with open(path, 'r') as f:\n        config = yaml.load(f)['default']['config']\n        return config['upstreams']\n\n\ndef parse_host(v):\n    return v.split(':')[0]\n\n\ndef sort(ups):\n    s = set()\n    for k, v in ups.items():\n        if isinstance(v, list):\n            for i in v:\n                s.add(parse_host(i))\n        else:\n            s.add(parse_host(v))\n    return s\n\n\ndef update_hosts(dns):\n    with open('/etc/hosts', 'a') as f:\n        f.write('\\n######################## new hosts added by test suite #########################\\n\\n')\n        for host in dns:\n            f.write('127.0.0.1 {}\\n'.format(host))\n\n\ndef show_hosts():\n    print('================================= /etc/hosts ===================================')\n    with open('/etc/hosts', 'r') as f:\n        print(f.read())\n\nupdate_hosts(sort(upstreams('app/config.yml')))\nshow_hosts()\n","tags":""},{"id":"af15ae73da17ec1d8a299aa2ced203e8","title":"Service Orchestration vs Choreography (http://developers.redhat.com/blog/2016/05/26/scalable-microservices-through-messaging/)","content":"- Service Orchestration: Queues \n- Service Choreography: Pub/Sub\n\nThe former requires a service to know about its upstream services.\n\nThe latter allows a service to _not_ know about its upstream services.\n\nThe latter is a cleaner separation of concerns and decoupling, because the upstream services just need to be aware of a potential \"event\" and the original service just needs to know that it has to fire an \"event\".\n","tags":""},{"id":"0d108466742b952398383f331a7a3784","title":"Awk insert before and after regex match","content":"echo -e \"foo\\nbar\\nbaz\" | awk '/bar/ \u0026\u0026 found == 0 {found = 1; print \"---\"; print; print \"---\"} {print}'\n\n# foo\n# ---\n# bar\n# ---\n# bar\n# baz\n","tags":""},{"id":"2bd6ea43e7f617b8b4eb81b45554bd49","title":"Python 2: execute multiple shell cmds and print result","content":"from subprocess import Popen, PIPE\n\ncmd = 'grep \"^name\" /etc/resolv.conf | grep -v \"0.0.0.0\" | cut -d \" \" -f 2'\nresult = Popen(cmd, shell=True, stdout=PIPE)\nprint result.stdout.read()\n","tags":""},{"id":"daed0185d0a26c94417e13d54c189262","title":"Ruby Socket Wrapper (one connection, multiple messages)","content":"```rb\nclass SocketWrapper\n  def self.instance\n    @inst ||= self.new\n  end\n\n  def initialize\n    @messages = Queue.new\n    @socket = TCPSocket.open('192.168.0.25', 2000)\n    Thread.new do\n       loop do\n          @messages \u003c\u003c @parse_message.nil? ? @socket.read : @parse_message.call(@socket.read)\n       end\n    end\n  end\n\n  def parse_message(\u0026block)\n    @parse_message = block\n  end\n\n  def send_message(msg)\n    @socket.write msg\n  end\n\n  def read_messages\n    result = []\n    begin\n      while message = @messages.pop(true)\n        result \u003c\u003c message\n      end\n    rescue ThreadError\n      #raised if queue is empty\n    end\n    result\n  def\nend\n```\n\nIn initializer:\n\n```rb\nSocketWrapper.instance.parse_message do |raw|\n  JSON.parse(raw)\n  # or any other awesome thing with raw\nend\n```\n\nIn Controller:\n\n```rb\nSocketWrapper.instance.send_message('blah blah blah')\n```\n","tags":""},{"id":"a93f6dfe7e1b948666272fd2e64db466","title":"[Python ignore pylint and flake8 linter errors] ","content":"Disable all linting across the entire file:\n\n```py\n# pylint: disable-all (older)\n# pylint: skip-file   (newer)\n# flake8: noqa\n```\n\nDisable specific linting errors across the entire file:\n\n```py\n# pylint: disable=123\n```\n\n\u003e Note: flake8 can't do this, unless you use something like `tox.ini`  \n\u003e So by adding `ignore = F403,E501` in a `[flake8]` section of `setup.cfg` or `tox.ini`\n\u003e I've also seen this to be configurable with a .flake8 file instead of a tox.ini\n\nDisable specific linting errors for specific lines:\n\n```py\nsome_code  # noqa: E731,E123\nsome_code  # noqa pylint: disable=unused-import\n```\n","tags":"#tags: python, linter, ignore, pylint, flake8"},{"id":"1bc8397c9f0d363de15966027ded3dcb","title":"Bash split string by delimiter","content":"IN=\"bla@some.com;john@home.com\"\narrIN=(${IN//;/ })\necho \"${arrIN[@]}\" # foo bar\necho $arrIN # foo\n","tags":""},{"id":"09770231e6b8bab267973c01918b5ea4","title":"Bash shortcut syntax for redirecting stderr to stdout","content":"# |\u0026 combines both stderr and stdout\n\ngo vet |\u0026 revgrep\njshint tests/tests.js |\u0026 tee -a results.txt\n","tags":""},{"id":"f06b7740d0d70f920439ef9595302d1a","title":"Taken from \"Python for Programmers\" https://leanpub.com/pythonforprogrammers","content":"```py\nimport asyncio\nimport time\nfrom concurrent.futures import ProcessPoolExecutor\n\nloop = asyncio.get_event_loop()\nexecutor = ProcessPoolExecutor()\n\ndef slow_cpu_bound(secs): \n    time.sleep(secs)\n    return \"some slowly returned value\"\n\ndef wrapper(secs):\n    # run_in_executor returns a coroutine function\n    return loop.run_in_executor(executor, slow_cpu_bound, secs)\n\nasync def main():\n    resp1, resp2 = await asyncio.gather(wrapper(5), wrapper(5)) \n    print(\"{}, {}\".format(resp1, resp2))\n\nloop.run_until_complete(main())\n```\n\nIn the above example we:\n\n+ tell the event loop to run until the task `main()` has completed\n+ the coroutine function `main()` gathers/waits for two other tasks (`wrapper`)\n+ the `wrapper` function returns a coroutine function (setup by `run_in_executor`)\n+ the `run_in_executor` calls `slow_cpu_bound` and passes an argument to it (using `ProcessPoolExecutor`)\n+ the `slow_cpu_bound` function is CPU bound (notice the use of `time.sleep` to cause blocking behaviour)\n\nNow this example code is ultimately calling a function that sleeps for the specified number of seconds. So we call it twice with 5 both times, meaning the overall time would typically be ten seconds if we were using a single thread (as the thread would be blocked for five seconds, then again for five seconds).\n\n\u003e Note: if you change this example to use `ThreadPoolExecutor` instead of `ProcessPoolExecutor` that is exactly what you’ll see: the overall execution time is ten seconds\n\nRunning this example reveals that the running time is actually only five seconds. This is because both tasks were started within a forked process and not a thread. If they were using threads, then they would have been restricted by the Python’s GIL.\n\nThe benefit of using the asyncio module to handle forked process execution is because it ties in nicely with the other asyncio functionality you are likely going to be already using. It’s much simpler at the point to use than the directly running the lower level `subprocess` module.\n\nNow you might also be interested to see yet another way to do this (still using `ProcessPoolExecutor` but swapping `asyncio.gather` for `asyncio.wait`):\n\n```py\nimport asyncio\nimport time\nfrom concurrent.futures import ProcessPoolExecutor\n\nloop = asyncio.get_event_loop()\nexecutor = ProcessPoolExecutor()\n\ndef slow_cpu_bound(secs):\n    time.sleep(secs)\n    return \"another example\"\n\nasync def main(executor):\n  tasks = [\n      loop.run_in_executor(executor, slow_cpu_bound, 5),\n      loop.run_in_executor(executor, slow_cpu_bound, 5)\n  ]\n  completed, pending = await asyncio.wait(tasks)\n  print(pending) # this would only show tasks that didn't complete\n  results = [f.result() for f in completed]\n  print('results: {!r}'.format(results))\n\nloop.run_until_complete(main(executor))\n```\n\nOne other interesting aspect of these ‘executors’ is that their abstract base class `concurrent.futures.Executor` defines specific functional behaviour such as a `map` function.\n\nWhich is an asynchronous equivalent to the standard library’s own `map` function.\n","tags":""},{"id":"2b272db0bd81124073164d7252743c34","title":"Complex log filtering in Vim","content":"\" clear the 'a' register first\n:let @a = '' \n\n\" append to 'a' register any lines matching 5xx (inc. previous line showing the error)\n:g/\\v5\\d\\d GET/-1,. y A\n\n\" paste from 'a' register\n\"ap\n","tags":""},{"id":"2938b1bee56ab5bcf690c717d42731e9","title":"Ruby WebMock Example","content":"When using WebMock with RSpec:\n\n```rb\nrequire 'webmock'\nrequire 'webmock/rspec'\n\nbefore do\n  WebMock.stub_request(:get, foo_endpoint).to_timeout\n  WebMock.stub_request(:get, bar_endpoint).to_return(:body =\u003e \"bar stuff\")\nend\n```\n\nWhen using WebMock outside of a testing framework don't forget `WebMock.enable!`:\n\n```rb\nrequire \"faraday\"\nrequire \"webmock\"\nrequire \"pry\"\n\nWebMock.enable!\n\nendpoint = \"http://www.beepbeepbeepboop.com\"\n\n# Notice we'll stub ANY type of request (GET, POST, PUT etc)\nWebMock.stub_request(:any, endpoint).to_return(:body =\u003e \"something else\")\n\np Faraday.get(endpoint).body\n```\n","tags":""},{"id":"01fdb84efbcb0bd656783cc96dad74c2","title":"Python Sort List by Dictionary Key","content":"order = {\n    1: 'foo',\n    2: 'bar',\n    3: 'baz'\n}\n\ndef sort_by_key(i):\n    for k, v in order.items():\n        if i == v:\n            return k\n\nsorted(['bar', 'baz', 'foo'], key=sort_by_key) \n\n# ['foo', 'bar', 'baz']\n","tags":""},{"id":"7a66effc75e8dbe6875f7019d118d170","title":"Vim filtering with global command, sorting and then filtering out duplicate lines for unique results","content":"\" Store data we're interested in, inside a capture group and print on separate line\n:%s/\\vGET (\\/.+) H/\\r\\r\\1\\r\\r/\n\n\" Delete any lines that don't start with a forward slash (leaving our capture group output)\n:g!/^\\//d\n\n\" Sort the results and then filter out all duplicates so we have unique results\n:sort u\n","tags":""},{"id":"eacba980ad679b342457ad5698e6cc0d","title":"MapReduce in Python (copied verbatim for posterity from https://www.reddit.com/r/Python/comments/572xtj/i_decided_to_teach_myself_how_mapreduce_works_and/)","content":"#!/usr/bin/env python3\n\nfrom functools import reduce\nfrom itertools import islice\nfrom pprint import pprint\nfrom collections import defaultdict\nfrom concurrent.futures import ProcessPoolExecutor as Pool\n\n\ndef sequencer(data):\n    \"\"\"\n    This sequencer will cut data into smaller chunks of 10 items.\n    \"\"\"\n\n    _data = iter(data)\n    count = 10\n    chunk = True\n\n    while chunk:\n        chunk = list(islice(_data, count))\n\n        if not chunk:\n            break\n\n        yield chunk\n\n\ndef mapper(items):\n    \"\"\"\n    This mapper will sum even and odd numbers separately, and add them to\n    a dictionary with the appropriate category as key.\n    \"\"\"\n\n    output = defaultdict(int)\n\n    for item in items:\n        category = 'odd' if item \u0026 1 else 'even'\n        output[category] += item\n\n    return output\n\n\ndef reducer(target, source):\n    \"\"\"\n    This reducer will go through the dictionary 'source',\n    and add its values to 'target', key by key.\n    \"\"\"\n\n    for key, value in source.items():\n        target[key] += value\n\n    return target\n\n\ndef main():\n    data = range(100)\n\n    number_of_processes = 4\n\n    with Pool(number_of_processes) as pool:\n\n        # Note:\n        # This can start yielding results to the reducer earlier if you instead\n        # import concurrent.futures.as_completed and stop using the map function.\n\n        # Note some more:\n        # You could use ThreadPoolExecutor if your mapper is IO-bound.\n        # One way of achieving this would be to pass the task at hand\n        # off to other machines and wait for them to get back to you.\n\n        result = reduce(reducer, pool.map(mapper, sequencer(data)), defaultdict(int))\n\n    for key, value in result.items():\n        print('sum of %s numbers: %d' % (key, value))\n\n\nif __name__ == '__main__':\n    main()\n","tags":""},{"id":"ca3e89497f57eb47a2df2e4cece3f5ac","title":"Sort an Array according to another Array","content":"a1 = [4, 5, 2, 3, 1]\na2 = [{:id =\u003e 5}, {:id =\u003e 2}, {:id =\u003e 1}, {:id =\u003e 3}, {:id =\u003e 4}]\n\na2.sort_by{|x| a1.index(x[:id])}\n\n=\u003e [{:id=\u003e4}, {:id=\u003e5}, {:id=\u003e2}, {:id=\u003e3}, {:id=\u003e1}]\n","tags":""},{"id":"7db3ea36a575d1bbec223bee208734f5","title":"[Python asyncio] ","content":"Refer to my blog post here:\n\nhttps://www.integralist.co.uk/posts/python-asyncio/\nThe following guide is based on Python 3.8\n\n\u003e asyncio is a library to write concurrent code using the `async`/`await` syntax. -- https://docs.python.org/3.8/library/asyncio.html\n\nThe asyncio module provides both high-level and low-level APIs. Library and Framework developers will be expected to use the low-level APIs, while all other users are encouraged to use the high-level APIs.\n\n## Event Loop\n\nThe core element of all asyncio applications is the 'event loop'. The event loop is what schedules and runs asynchronous tasks (it also handles network IO operations and the running of subprocesses).\n\n## Awaitables\n\nSomething is _awaitable_ if it can be used in an `await` expression.\n\nThere are three main types of awaitables:\n\n1. Coroutines\n2. Tasks\n3. Futures\n\n\u003e Note: Futures is a _low-level_ type and so you shouldn't need to worry about it too much if you're not a library/framework developer (as you should be using the higher-level abstraction APIs instead).\n\n### Coroutines\n\nThere are two closely related terms used here:\n\n- a _coroutine function_: an `async def` function.\n- a _coroutine object_: an object returned by calling a coroutine function.\n\n\u003e Generator based coroutine functions (e.g. those defined by decorating a function with `@asyncio.coroutine`) are superseded by the `async`/`await` syntax, but will continue to be supported _until_ Python 3.10 -- https://docs.python.org/3.8/library/asyncio-task.html#asyncio-generator-based-coro\n\n### Tasks\n\n[Tasks](https://docs.python.org/3.8/library/asyncio-task.html#asyncio.Task) are used to schedule coroutines _concurrently_.\n\nAll asyncio applications will have (at least) a single 'main' entrypoint task that will be scheduled to run immediately on the event loop. This is done using the `asyncio.run` function (see '[Running an asyncio program](#running-an-asyncio-program)'). \n\nA coroutine function is expected to be passed to `asyncio.run`, while _internally_ asyncio will check this using the helper function `coroutines.iscoroutine`. If not a coroutine, then an error is raised, otherwise the coroutine will be passed to `loop.run_until_complete`. The `run_until_complete` function expects a [Future](#future) (see below section) and uses another helper function `futures.isfuture` to check the type provided.\n\nIn older versions of Python you would have used `asyncio.ensure_future` (now considered to be a low-level API) to schedule a coroutine to be executed on the event loop, but with Python 3.7+ this has been superseded by `asyncio.create_task`. \n\nAdditionally, with Python 3.8, the idea of interacting with the event loop directly (e.g. getting the event loop, creating a task with `create_task` and then passing it to the event loop) has been replaced with `asyncio.run`, which abstracts it all away for you (see '[Running an asyncio program](#running-an-asyncio-program)' to understand what that means).\n\nThe following APIs let you see the state of the tasks running on the event loop:\n\n- `asyncio.current_task`\n- `asyncio.all_tasks`\n\n\u003e Note: for other available methods on a Task object please refer to [the documentation](https://docs.python.org/3.8/library/asyncio-task.html#asyncio.Task).\n\n### Futures\n\nA Future is a low-level awaitable object that represents an eventual result of an asynchronous operation.\n\nTo use an analogy: it's like an empty postbox. At _some point_ in the future the postman will arrive and stick a letter into the postbox.\n\nThis API exists to enable callback-based code to be used with `async`/`await`, while [`loop.run_in_executor`](https://docs.python.org/3.8/library/asyncio-eventloop.html#asyncio.loop.run_in_executor) is an example of an asyncio low-level API function that returns a Future (see also some of the APIs listed in [Concurrent Functions](#concurrent-functions)).\n\n\u003e Note: for other available methods on a Future please refer to [the documentation](https://docs.python.org/3.8/library/asyncio-future.html#asyncio.Future).\n\n## Running an asyncio program\n\nThe high-level API (as per Python 3.7+) is:\n\n```python\nimport asyncio\n\nasync def foo():\n    print(\"Foo!\")\n\nasync def hello_world():\n    await foo()  # waits for `foo()` to complete\n    print(\"Hello World!\")\n\nasyncio.run(hello_world())\n```\n\nThe `.run` function always creates a _new_ event loop and _closes_ it at the end. If you were using the lower-level APIs, then this would be something you'd have to handle manually (as demonstrated below).\n\n```python\nloop = asyncio.get_event_loop()\nloop.run_until_complete(hello_world())\nloop.close()\n```\n\n## Concurrent Functions\n\n- `asyncio.gather`: takes a sequence of awaitables, returns an aggregate list of successfully awaited values.\n- `asyncio.shield`: prevent an awaitable object from being cancelled.\n- `asyncio.wait`: wait for a sequence of awaitables, until the given 'condition' is met.\n- `asyncio.wait_for`: wait for a single awaitable, until the given 'timeout' is reached.\n- `asyncio.as_completed`: similar to `gather` but returns Futures that are populated when results are ready.\n\n\u003e Note: `gather` has specific options for handling errors and cancellations. For example, if `return_exceptions: False` then the first exception raised by one of the awaitables is returned to the caller of `gather`, where as if set to `True` then the exceptions are aggregated in the list alonside successful results. If `gather()` is cancelled, all submitted awaitables (that have not completed yet) are also cancelled.\n\n## Deprecated functions\n\n- `@asyncio.coroutine`: removed in Python 3.10\n- `asyncio.sleep`: removed in Python 3.10\n\n\u003e Note: you'll find in most of these APIs a `loop` argument can be provided to enable you to indicate the specific event loop you want to utilize). It seems Python has deprecated this argument in 3.8, and will remove it completely in 3.10.\n\n## Older Examples\n\nSee gist 'comments' section for the following...\n\n- [Chained/Coupled Function Calls](https://gist.github.com/Integralist/7db3ea36a575d1bbec223bee208734f5#gistcomment-1767389)\n- [Futures](https://gist.github.com/Integralist/7db3ea36a575d1bbec223bee208734f5#gistcomment-1767396)\n- [Parallel Execution](https://gist.github.com/Integralist/7db3ea36a575d1bbec223bee208734f5#gistcomment-1767544)\n","tags":"#python #asyncio #helloworld"},{"id":"3f8089345a1236b374a7a5b8a13591a1","title":"The Perfect Developer Qualities","content":"For me the perfect developer (if there is such a person) has these qualities:\n\n- **Friendly**: is respected and liked by all they work with and are always approachable (even in times of stress)\n- **Humble**: has great humilty and is not driven by ego\n- **Calm**: doesn't get emotive within discussions (including discussions that are both in their favour and those that aren't)\n- **Understanding**: appreciates that business requirements do change regularly and that there are no perfect scenarios; so is able to adapt to problematic situations in the appropriate manner\n- **Agile**: recognises when they are potentially moving down a rabbit hole/time sink/yak shave and will successfully re-evaluate the situation and refocus their attention\n- **Patient**: appreciates that no dev is born equal and so varying soft/practical skills will be encountered\n- **Experienced**: has a wide ranging skill set with relevant practical experience and most importantly realises the fundamentals of simple code design and recognised patterns\n- **Consistent**: by being consistent in their development approach they faciliate easier rotation of developers when resources are restricted/restructured\n- **Wise**: knows _when_ and _where_ a particular technology is appropriate to use (and when not appropriate)\n- **Analytical**: is pragmatic and can break down complex problems into logical smaller tasks\n- **Articulate**: able to communicate clearly their ideas to people of all technical levels\n- **Open**: continuous documentation and visibility into design and development progress; ensuring good communication\n- **Reasonable**: understands a problem's sense of proportion; what's important and what isn't (e.g. when something is a big deal and worth pressing; and when it isn't and so not prematurely raising red flags)\n- **Passionate**: enjoys their craft; always keen/open to new experiences and learning new things\n","tags":""},{"id":"ce5ebb37390ab0ae56c9e6e80128fdc2","title":"Python3 HTTP Server.py","content":"import time\nfrom http.server import BaseHTTPRequestHandler, HTTPServer\n\nHOST_NAME = 'localhost'\nPORT_NUMBER = 9000\n\n\nclass MyHandler(BaseHTTPRequestHandler):\n    def do_HEAD(self):\n        self.send_response(200)\n        self.send_header('Content-type', 'text/html')\n        self.end_headers()\n\n    def do_GET(self):\n        paths = {\n            '/foo': {'status': 200},\n            '/bar': {'status': 302},\n            '/baz': {'status': 404},\n            '/qux': {'status': 500}\n        }\n\n        if self.path in paths:\n            self.respond(paths[self.path])\n        else:\n            self.respond({'status': 500})\n\n    def handle_http(self, status_code, path):\n        self.send_response(status_code)\n        self.send_header('Content-type', 'text/html')\n        self.end_headers()\n        content = '''\n        \u003chtml\u003e\u003chead\u003e\u003ctitle\u003eTitle goes here.\u003c/title\u003e\u003c/head\u003e\n        \u003cbody\u003e\u003cp\u003eThis is a test.\u003c/p\u003e\n        \u003cp\u003eYou accessed path: {}\u003c/p\u003e\n        \u003c/body\u003e\u003c/html\u003e\n        '''.format(path)\n        return bytes(content, 'UTF-8')\n\n    def respond(self, opts):\n        response = self.handle_http(opts['status'], self.path)\n        self.wfile.write(response)\n\nif __name__ == '__main__':\n    server_class = HTTPServer\n    httpd = server_class((HOST_NAME, PORT_NUMBER), MyHandler)\n    print(time.asctime(), 'Server Starts - %s:%s' % (HOST_NAME, PORT_NUMBER))\n    try:\n        httpd.serve_forever()\n    except KeyboardInterrupt:\n        pass\n    httpd.server_close()\n    print(time.asctime(), 'Server Stops - %s:%s' % (HOST_NAME, PORT_NUMBER))\n","tags":""},{"id":"cc5b63b4a999cde93f353801d50e5e87","title":"Find and execute using `find` and `-exec` flag","content":"To find some files and execute an additional action on them, use `-exec`:\n\n```bash\nfind . -name *.rb -exec md5 -s {} \\;\n```\n\n\u003e Note: you need `\\;` otherwise you'll get an error\n\u003e about `no terminating \";\" or \"+\"`\n","tags":""},{"id":"01e2ffd00a599069bda33ab64ab37c20","title":"Vim Grep","content":"## Standard Vim Grep\n\nBasic syntax structure:\n\n```viml\n:vimgrep  /\u003csearchTerm\u003e/[gj] \u003c/path/to/project/**/*.rb\u003e\n:lvimgrep /\u003csearchTerm\u003e/[gj] \u003c/path/to/project/*\u003e\n```\n\n\u003e Note: `j` prevents Vim from trying to open the first file match\n\nExample usage (we're searching for any reference to `class` anywhere in the project):\n\n```viml\n:vimgrep /class/gj **/*\n:copen\n```\n\n\u003e Note: `copen` will open Vim's \"quick fix\" window\n\n## Using an alternative search tool\n\nVim provides a `:grep` command, which allows you to utilise a custom search program. \n\nThe default program it uses can be seen by running:\n\n```viml\n:set grepprg\n```\n\nWhich should return:\n\n```viml\ngrepprg=grep -n $* /dev/null\n```\n\nConfiguring Vim to use another program (e.g. [Sift](https://sift-tool.org/))\n\n```viml\n:set grepprg=sift\\ -n\\ -X\\ log\\ --binary-skip\\ $*\n```\n\n\u003e Note: spaces have to be escaped with a backslash `\\`\n\nYou can now use the new program like so (e.g. to find any reference to the word `class` using Sift):\n\n```viml\n:grep class\n:copen\n```\n\n\u003e Note: you still need to open the quick fix window afterwards to utilise the results\n","tags":""},{"id":"38c72374cd37cff9f62c3484aaa58ba2","title":"Docker and StatsD","content":"```bash\ndocker run -d --name graphite -p 80:80 -p 2003:2003 -p 8125:8125/udp hopsoft/graphite-statsd\n```\n\nNow send stats via UDP:\n\n```bash\necho -n \"test:1|g\" | nc -w 1 -u localhost 8125\necho -n \"test:2|g\" | nc -w 1 -u localhost 8125\necho -n \"test:3|g\" | nc -w 1 -u localhost 8125\n```\n\nor\n\n```bash\necho -n \"example:20|c\" | nc -w 1 -u localhost 8125\n```\n\nVisit http://localhost/dashboard then click through to `stats.gauges.test` or `stats.example`\n\n\u003e You can even try sending stats via programming language like Ruby:\n\u003e `require 'socket'; UDPSocket.new.send('test:1|g', 0, 'localhost', '8125')`\n","tags":""},{"id":"957d1a940a582042152194dd9dde0095","title":"keybase.md","content":"### Keybase proof\n\nI hereby claim:\n\n  * I am integralist on github.\n  * I am integralist (https://keybase.io/integralist) on keybase.\n  * I have a public key ASA6EHA2U8cvSwNFRx8fPIOeUHNHJCj44qKMCGAMjx0-Two\n\nTo claim this, I am signing this object:\n\n```json\n{\n    \"body\": {\n        \"key\": {\n            \"eldest_kid\": \"010154d8c3ff5ca85365025f608fe924a35b3ad9654e170c1745e9bc9d4f79625f2e0a\",\n            \"host\": \"keybase.io\",\n            \"kid\": \"01203a10703653c72f4b0345471f1f3c839e5073472428f8e2a28c08600c8f1d3e4f0a\",\n            \"uid\": \"6b4f41e6b68994127ebd6aacffbe0419\",\n            \"username\": \"integralist\"\n        },\n        \"service\": {\n            \"name\": \"github\",\n            \"username\": \"integralist\"\n        },\n        \"type\": \"web_service_binding\",\n        \"version\": 1\n    },\n    \"client\": {\n        \"name\": \"keybase.io go client\",\n        \"version\": \"1.0.14\"\n    },\n    \"ctime\": 1463930414,\n    \"expire_in\": 504576000,\n    \"merkle_root\": {\n        \"ctime\": 1463930401,\n        \"hash\": \"a76066aa4343486245f95dd8681f07b5eeb0104350b8ac2baae0ed91f5d8b3a0159720a0081a6f45d4e4af9bd9d751cee4ac2b0597e844c1bf8f60e02a8202ac\",\n        \"seqno\": 468839\n    },\n    \"prev\": \"15783b9f58bbcbaf928a508ad6a1cc1f6a26e704746098255fe8f2d6fd7c5bd9\",\n    \"seqno\": 10,\n    \"tag\": \"signature\"\n}\n```\n\nwith the key [ASA6EHA2U8cvSwNFRx8fPIOeUHNHJCj44qKMCGAMjx0-Two](https://keybase.io/integralist), yielding the signature:\n\n```\ng6Rib2R5hqhkZXRhY2hlZMOpaGFzaF90eXBlCqNrZXnEIwEgOhBwNlPHL0sDRUcfHzyDnlBzRyQo+OKijAhgDI8dPk8Kp3BheWxvYWTFAvN7ImJvZHkiOnsia2V5Ijp7ImVsZGVzdF9raWQiOiIwMTAxNTRkOGMzZmY1Y2E4NTM2NTAyNWY2MDhmZTkyNGEzNWIzYWQ5NjU0ZTE3MGMxNzQ1ZTliYzlkNGY3OTYyNWYyZTBhIiwiaG9zdCI6ImtleWJhc2UuaW8iLCJraWQiOiIwMTIwM2ExMDcwMzY1M2M3MmY0YjAzNDU0NzFmMWYzYzgzOWU1MDczNDcyNDI4ZjhlMmEyOGMwODYwMGM4ZjFkM2U0ZjBhIiwidWlkIjoiNmI0ZjQxZTZiNjg5OTQxMjdlYmQ2YWFjZmZiZTA0MTkiLCJ1c2VybmFtZSI6ImludGVncmFsaXN0In0sInNlcnZpY2UiOnsibmFtZSI6ImdpdGh1YiIsInVzZXJuYW1lIjoiaW50ZWdyYWxpc3QifSwidHlwZSI6IndlYl9zZXJ2aWNlX2JpbmRpbmciLCJ2ZXJzaW9uIjoxfSwiY2xpZW50Ijp7Im5hbWUiOiJrZXliYXNlLmlvIGdvIGNsaWVudCIsInZlcnNpb24iOiIxLjAuMTQifSwiY3RpbWUiOjE0NjM5MzA0MTQsImV4cGlyZV9pbiI6NTA0NTc2MDAwLCJtZXJrbGVfcm9vdCI6eyJjdGltZSI6MTQ2MzkzMDQwMSwiaGFzaCI6ImE3NjA2NmFhNDM0MzQ4NjI0NWY5NWRkODY4MWYwN2I1ZWViMDEwNDM1MGI4YWMyYmFhZTBlZDkxZjVkOGIzYTAxNTk3MjBhMDA4MWE2ZjQ1ZDRlNGFmOWJkOWQ3NTFjZWU0YWMyYjA1OTdlODQ0YzFiZjhmNjBlMDJhODIwMmFjIiwic2Vxbm8iOjQ2ODgzOX0sInByZXYiOiIxNTc4M2I5ZjU4YmJjYmFmOTI4YTUwOGFkNmExY2MxZjZhMjZlNzA0NzQ2MDk4MjU1ZmU4ZjJkNmZkN2M1YmQ5Iiwic2Vxbm8iOjEwLCJ0YWciOiJzaWduYXR1cmUifaNzaWfEQE6L6+e5vc8cJfY66H1XWtb1w3MmpMURqm9YFv8PGOarOxK4A4ksOi14cBXxz8W4BF+nx6lqmykn41+17oL6ggqoc2lnX3R5cGUgo3RhZ80CAqd2ZXJzaW9uAQ==\n\n```\n\nAnd finally, I am proving ownership of the github account by posting this as a gist.\n\n### My publicly-auditable identity:\n\nhttps://keybase.io/integralist\n\n### From the command line:\n\nConsider the [keybase command line program](https://keybase.io/download).\n\n```bash\n# look me up\nkeybase id integralist\n```\n","tags":""},{"id":"e217429a5da1edcd5d220ed2ccb61f59","title":"Cryptographic Hash Functions","content":"- [Cryptographic Hash Functions](#cryptographic-hash-functions)\n- [Hash Function Examples](#hash-function-examples)\n  - [MD5](#md5)\n  - [Shasum](#shasum)\n  - [OpenSSL](#openssl)\n- [Encryption](#encryption)\n- [Salt](#salt)\n- [MAC](#mac)\n- [HMAC](#hmac)\n- [Checksum](#checksum)\n- [Hash Collisions](#hash-collisions)\n\n## Cryptographic Hash Functions\n\nA cryptographic hash function is a mathematical algorithm that maps data of arbitrary size to a bit string of a fixed size (a hash function) which is designed to also be one-way function, that is, a function which is infeasible to invert.\n\nThe input data is often called the \"message\", and the output (the hash value or \"hash\") is often called the \"message digest\" or simply the \"digest\".\n\nCryptographic hash functions have many information-security applications, notably in digital signatures, message authentication codes (MACs), and other forms of authentication. They can also be used as ordinary hash functions, to index data in hash tables, for fingerprinting, to detect duplicate data or uniquely identify files, and as checksums to detect accidental data corruption.\n\nAn example application of a hash function is password verification. Storing all user passwords as cleartext can result in a massive security breach if the password file is compromised. One way to reduce this danger is to only store the hash digest of each password. To authenticate a user, the password presented by the user is hashed and compared with the stored hash (note that this approach prevents the original passwords from being retrieved if forgotten or lost, and they have to be replaced with new ones). The password is often concatenated with a random, non-secret salt value before the hash function is applied. The salt is stored with the password hash. Because users have different salts, it is not feasible to store tables of precomputed hash values for common passwords.\n\n## Hash Function Examples\n\n### MD5\n\n```bash\nmd5 -s 'hello world'\nmd5 /path/to/file\n```\n\n### Shasum\n\n```bash\necho hello world | shasum\nshasum /path/to/file\n\necho hello world | shasum -a 256\nshasum -a 256 /path/to/file\n```\n\n\u003e Note: the flag `-a` default algorithm is `1` (i.e. SHA1)  \n\u003e \n\u003e Instead of piping a string you can run `shasum` and type string  \n\u003e But you'll need to add a carriage return/line break and then...  \n\u003e Execute `\u003cctrl-d\u003e` (which registers an EOF on standard input)\n\n### OpenSSL\n\n```bash\necho hello world | openssl dgst -md5\necho hello world | openssl dgst -sha1\necho hello world | openssl dgst -sha256\n```\n\n\u003e Note: use `-hmac \"some-key\"` to convert algorithm into a [HMAC](#hmac)\n\n## Encryption\n\nEncryption transforms data from a cleartext to ciphertext and back (given the right keys), and the two texts should roughly correspond to each other in size: big cleartext yields big ciphertext, and so on. \"Encryption\" is a two-way operation.\n\nHashes, on the other hand, compile a stream of data into a small digest (a summarized form: think \"Reader's Digest\"), and it's strictly a one way operation.\n\nThe Advanced Encryption Standard (AES) is a family of ciphers with different key and block sizes. The algorithm described by AES is a symmetric-key algorithm, meaning the same key is used for both encrypting and decrypting the data.\n\nThe downside of symmetrical encryption is the key needs to be transported somehow without being compromised. This is the problem asymmetric encryption solves and is primarily used with online communication (SSL/TLS).\n\n## Salt\n\nA salt is a random, non-secret value which is combined with a password before a hash function is applied.\n\nSalts help combat the use of rainbow tables for cracking passwords. A rainbow table is a large list of pre-computed hashes for commonly used passwords. For a password file without salts, an attacker can go through each entry and look up the hashed password in the rainbow table. If the look-up is considerably faster than the hash function (which it often is), this will considerably speed up cracking the file. However, if the password file is salted, then the rainbow table would have to contain \"salt . password\" pre-hashed. If the salt is long enough and sufficiently random, this is very unlikely. \n\n## MAC\n\nA Message Authentication Code (MAC) is a string of bits that is sent alongside a message. The MAC depends on the message itself and a secret key. No one should be able to compute a MAC without knowing the key. This allows two people who share a secret key to send messages to each without fear that someone else will tamper with the messages. \n\n## HMAC\n\nHMAC is a recipe for turning hash functions (such as MD5 or SHA256) into MACs. So HMAC-MD5 and HMAC-SHA256 are specific MAC algorithms, just like QuickSort is a specific sorting algorithm.\n\n## Checksum\n\nA checksum has a special purpose --- it verifies or checks the integrity of data. \"Good\" checksums are easy to compute, and can detect many types of data corruptions (e.g. one, two, three erroneous bits).\n\nA checksum for a string should include each and every bit, and order matters. This means that \"aaaaaaaaaaba\" would hash the same as \"aaaaaaaaaaab\" where as a checksum could identify the difference.\n\n## Hash Collisions\n\nA hash \"collision\" occurs when two different data inputs generate the same resulting hash. The likelihood of this happening depends on which function you use.\n\nFor example:\n\n- `md5` generates 128-bit hashes\n- `sha1` generates 160-bit hashes\n- `sha2` generates 224, 256, 384, or 512 bit hashes\n\n\u003e Note: [CIDR blocks are constructed from bits as well](https://gist.github.com/Integralist/cff468ba808fbca09602)\n","tags":""},{"id":"5224a227dccd5007a8081a270029c58c","title":"git commit template example file","content":"- Commit your file\n- `git update-index --assume-unchanged \u003cfile\u003e`\n- Allow changes using: `git update-index --no-assume-unchanged \u003cfile\u003e`\n\nThis only works when user executes the command.\n\nSo you'll need to add a note to the repo's README and maybe make it easy by abstracting within a Makefile:\n\n```make\nlock_local_file:\n  git update-index --assume-unchanged ./some/file.json\n```\n","tags":""},{"id":"cf76668bc46d75058ab5f566d96ce74a","title":"Testing Go Web Applications http://www.meetspaceapp.com/2016/05/16/acceptance-testing-go-webapps-with-cookies.html","content":"// package main is used here just for ease of running the demo.\n// In reality, this would be package app\npackage main\n\nimport (\n\t\"flag\"\n\t\"fmt\"\n\t\"log\"\n\t\"net/http\"\n)\n\n// App is our Application's base http.Handler\ntype App struct {\n\t*http.ServeMux\n}\n\n// NewApp constructs a new App and initializes our routing\nfunc NewApp() *App {\n\tmux := http.NewServeMux()\n\tapp := \u0026App{mux}\n\tmux.HandleFunc(\"/\", app.Root)\n\treturn app\n}\n\n// Root is the root page of our application\nfunc (a *App) Root(w http.ResponseWriter, r *http.Request) {\n\tfmt.Fprint(w, \"Hello!\")\n}\n\nvar port = flag.Int(\"port\", 8080, \"Port to serve on\")\n\nfunc main() {\n\tflag.Parse()\n\tlog.Fatal(http.ListenAndServe(fmt.Sprintf(\":%d\", *port), NewApp()))\n}\nfunc TestAppRoot(t *testing.T) {\n\tapp := NewApp()\n\tserver := httptest.NewServer(app)\n\tdefer server.Close()\n\n\tresp, err := http.Get(server.URL + \"/\")\n\tif err != nil {\n\t\tt.Error(err)\n\t}\n\n\tbuf := \u0026bytes.Buffer{}\n\tbuf.ReadFrom(resp.Body)\n\tif strings.Index(buf.String(), \"Hello!\") == -1 {\n\t\tt.Error(\"Root should say hello\")\n\t}\n}\n// Root is the root page of our application\nfunc (a *App) Root(w http.ResponseWriter, r *http.Request) {\n\tvar name string\n\n\tnameCookie, err := r.Cookie(\"name\")\n\tif err == nil {\n\t\tname = nameCookie.Value\n\t} else if err != http.ErrNoCookie {\n\t\thttp.Error(w, err.Error(), http.StatusInternalServerError)\n\t\treturn\n\t}\n\t\n\tt := template.Must(template.New(\"root\").Parse(`\n\t\u003c!doctype html\u003e\n\t\u003chtml\u003e\n\t\u003chead\u003e\u003ctitle\u003egreeter\u003c/title\u003e\u003c/head\u003e\n\t\u003cbody\u003e\n\t{{if .}}\n\t  \u003ch1\u003eHi {{.}}!\u003c/h1\u003e\n\t{{else}}\n\t  \u003ch1\u003eWelcome! Who are you?\u003c/h1\u003e\n\t  \u003cform method=\"POST\" action=\"/name\"\u003e\n\t    \u003cinput type=\"text\" placeholder=\"Your name\" name=\"name\"\u003e\n\t    \u003cinput type=\"submit\" value=\"Set Name\"\u003e\n\t  \u003c/form\u003e\n\t{{end}}\n\t\u003c/body\u003e\n\t\u003c/html\u003e\n\t`))\n\tif err := t.Execute(w, name); err != nil {\n\t\thttp.Error(w, err.Error(), http.StatusInternalServerError)\n\t\treturn\n\t}\n}\n\n// NewApp constructs a new App and initializes our routing\nfunc NewApp() *App {\n\tmux := http.NewServeMux()\n\tapp := \u0026App{mux}\n\tmux.HandleFunc(\"/\", app.Root)\n\tmux.HandleFunc(\"/name\", app.SetName) // \u003c- NEW\n\treturn app\n}\n\nfunc (a *App) SetName(w http.ResponseWriter, r *http.Request) {\n\thttp.SetCookie(w, \u0026http.Cookie{\n\t\tName:     \"name\",\n\t\tValue:    r.FormValue(\"name\"),\n\t\tHttpOnly: true,\n\t\tExpires:  time.Now().Add(24 * 14 * time.Hour),\n\t})\n\thttp.Redirect(w, r, \"/\", http.StatusFound)\n}\nfunc TestSetName(t *testing.T) {\n\tapp := NewApp()\n\tserver := httptest.NewServer(app)\n\tdefer server.Close()\n\n\tjar, err := cookiejar.New(nil)\n\tif err != nil {\n\t\tt.Error(err)\n\t}\n\tclient := \u0026http.Client{Jar: jar}\n\n\tresp, err := client.Get(server.URL + \"/\")\n\tif err != nil {\n\t\tt.Error(err)\n\t}\n\n\tbuf := \u0026bytes.Buffer{}\n\tbuf.ReadFrom(resp.Body)\n\tif strings.Index(buf.String(), \"Welcome\") == -1 {\n\t\tt.Errorf(\"Root should say Welcome!:\\n%s\", buf.String())\n\t}\n\n\tresp, err = client.PostForm(\n        \tserver.URL+\"/name\",\n        \turl.Values{\"name\": {\"Nick\"}},\n        )\n\tif err != nil {\n\t\tt.Error(err)\n\t}\n\n\tbuf.Reset()\n\tbuf.ReadFrom(resp.Body)\n\tif strings.Index(buf.String(), \"Hi Nick!\") == -1 {\n\t\tt.Errorf(\"Root should say Hi Nick!:\\n%s\", buf.String())\n\t}\n}\n","tags":""},{"id":"52d07564bcae1937a76d28377746e0fd","title":"AWS KMS","content":"\u003e Thanks to [Steven Jack](https://twitter.com/stevenjack85) for helping me understand this\n\nThe individual parts of AWS KMS are:\n\n- master key\n- encryptor key (encrypted and unencrypted forms)\n- app's private key\n\n\u003e Note: the \"encryptor\" is a key used to encrypt our private key\n\nHere is a simple example to demonstrate the workflow:\n\n- Create a master key in KMS (how you do this is up to you: SDK, CLI, Console)\n- Locally (via the AWS cli tool or maybe even via a CI) call `GenerateDataKey`\n- When making this call: pass the name of the \"master key\" in KMS to use\n- This results in a temp key `B` (in both unencrypted and encrypted form) being provided\n- We can now encrypt key `A` using the unencrypted `B` key \n- We can discard both the unencrypted `A` and `B` keys (as we now have encrypted versions)\n- We can bake the encrypted keys (`A` and `B`) into our application (as they're encrypted)\n- When our app needs to use key `A`, it needs to decrypt it\n- Our app uses KMS to decrypt the `B` key\n- Our app then uses the resulting unencrypted `B` key to decrypt our `A` encrypted key\n\n---\n\nFurther comments from Steven Jack:\n\nImagine we have a Jenkins CI job that runs every week.  \nIt has IAM perms to call `GenerateDataKey` for a specific master key. \n\nEach week it generates a new random hash for the DB password,  \nget’s the temp encryption key,  \nencrypts it and pushes both the parts needed into a Kubernetes secrets store.\n\nOnce that’s done we simply re-deploy the containers, done.\n\nThe app has decrypt perms for that master key and on boot  \ngive the param it has from the secrets store and get back  \nthe unencrypted key and decrypt its secret, then uses it.\n","tags":""},{"id":"090fb5d3b55694c7b92d32798845eded","title":"Backup all your GitHub Gists (inc. private gists)","content":"## Instructions\n\n- Install this gem: https://github.com/swdyh/gisty\n- Create a new access token in GitHub: https://github.com/settings/tokens\n  - You only need the `gist` box ticked, nothing else necessary\n- Set this: `export GISTY_DIR=\"$HOME/path/where/you/want/gists/saved\"`\n- Set this: `export GISTY_ACCESS_TOKEN=xxxxxxxxxx`\n- Run this: `gisty sync`\n\n...now sit and wait for it to start cloning all your gists into the specified directory\n\n\u003e Use `ls -l | wc -l` to count how many gists you have\n\n## Caveats\n\nThe cloned gists are placed inside folders named after the gist ID so it's not exactly clear what a folder is.\n\nYou can obviously try and search through your gists using something like:\n\n```bash\nfunction search_gists(){\n  local search=*$1*\n  find . -name $search\n}\n\nsearch_gists docker\nsearch_gists aws\n```\n\nBut remember that this is for local backups and not a replacement for GitHub's Gist service\n","tags":""},{"id":"9c7e32a2126ca28722693675f99f2ad9","title":"[Python Custom Exception Handling] ","content":"class CustomError(Exception):\n\tdef __init__(self, exc='exception raised', code=500):\n\t\tsuper().__init__(exc)\n\t\tself.code = code\n        \n    # not needed, but can help when represented as a string\n    def __str__(self):\n        return f'uh-oh the error code is: {self.code}'\n        \nclass NewCustomError(CustomError):\n\tpass\n\ntry:\n\traise CustomError('a thing happened', code=400)\nexcept CustomError as err:\n\tlogging.error(f'msg: {err}, code: {err.code}')\n\nERROR:root:msg: a thing happened, code: 400\n\ntry:\n\traise NewCustomError()\nexcept NewCustomError as err:\n\tlogging.error(f'msg: {err}, code: {err.code}')\n\nERROR:root:msg: exception raised, code: 500\n\n\n\"\"\"\nFrom outside a try/except, use `gen_exc` as a naming convention instead of `exc`\nThis will avoid linting concerns...\n\n    try:\n        response_data = json.loads(response.body)\n    except Exception as exc:\n        msg = 'JSON_PARSING_FAILED'\n        log_exception(exc, msg, body=response.body)\n        raise exceptions.CognitoException(msg, code=extract_status_code(exc))\n\n    if response_data.get('error'):\n        msg = 'TOKEN_EXCHANGE_FAILED'\n        gen_exc = exceptions.CognitoException(msg)\n        log_exception(gen_exc, msg, context=response_data.get('error'))\n        raise gen_exc\n\"\"\"\n\n\n\n\n# basic\n\nclass ArgumentError(Exception):\n    pass\n\ndef foo(x):\n    if x == 123:\n        raise ArgumentError(\"doh!\")\n\n# much more 'custom'\n\nif True:\n  raise CustomError('thing')\n  \nclass CustomError(Exception):\n    '''\n    This does stuff\n    '''\n    def __init__(self, thing):\n        super().__init__('something went wrong')\n        self.thing = thing\n","tags":"#python #custom #exceptions #error #handling"},{"id":"f382f8573900bd1821769be478b81323","title":"Python programmatically check installed module version","content":"python -c \"import jinja2; print jinja2.__version__\"\n\n# In situations like:\n#\n# apt-get -y install python-jinja2\n#\n# ...which install Python and the package Jinja2\n","tags":""},{"id":"5480428f4edcb49ba0fba6dde2c3e9ff","title":"Local Memcache and ElastiCache","content":"## Single Node\n\n- `brew install memcached` (or `docker run -d -p 11211:11211 memcached`)\n- `memcached` (optional `-d` to background \u0026 `-p` to change port)\n- `telnet localhost 11211`\n- `stats`\n- `quit`\n\n\u003e http://blog.elijaa.org/2010/05/21/memcached-telnet-command-summary\n\nNotice the line break for the value (when using `set` or `add` etc) is required...\n\n```\nset foo 0 60 3\nbar\nSTORED\n\nget foo\nVALUE foo 0 3\nbar\nEND\n```\n\n## AWS ElastiCache Cluster Endpoint\n\n- `gem install fake_elasticache`\n- `fake_elasticache` (run in a separate shell as it's run in the foreground)\n- `telnet localhost 11212` (fyi that's a non-standard port)\n- `config get cluster`\n- `quit`\n\n## Go Client\n\nHere's a Go client that interacts with the AWS ElastiCache endpoint and parses out the data.\n\nTo run this script you'll need `memcached` running locally along with `fake_elasticache` which looks up the locally running memcache at the default location of `localhost` and port `11211`.\n\n```go\npackage main\n\nimport (\n\t\"bufio\"\n\t\"fmt\"\n\t\"net\"\n\t\"strconv\"\n\t\"strings\"\n\n\t\"github.com/bradfitz/gomemcache/memcache\"\n)\n\n// Node is a single ElastiCache instance node\ntype Node struct {\n\tURL  string\n\tHost string\n\tIP   string\n\tPort int\n}\n\nfunc main() {\n\tvar response string\n\tvar nodes []Node\n\tvar urls []string\n\n\tconn, err := net.Dial(\"tcp\", \"127.0.0.1:11212\")\n\tif err != nil {\n\t\tfmt.Println(err.Error())\n\t\treturn\n\t}\n\n\tdefer conn.Close()\n\n\tcommand := \"config get cluster\\r\\n\"\n\n\tfmt.Fprintf(conn, command)\n\n\tcount := 0\n\tlocation := 3 // AWS docs suggest that nodes will always be listed on line 3\n\n\tscanner := bufio.NewScanner(conn)\n\tfor scanner.Scan() {\n\t\tcount++\n\t\tif count == location {\n\t\t\tresponse = scanner.Text()\n\t\t}\n\t\tif scanner.Text() == \"END\" {\n\t\t\tbreak\n\t\t}\n\t}\n\tif err := scanner.Err(); err != nil {\n\t\tfmt.Println(err.Error())\n\t\treturn\n\t}\n\n\titems := strings.Split(response, \" \")\n\n\tfor _, v := range items {\n\t\tfields := strings.Split(v, \"|\") // [\"host\", \"ip\", \"port\"]\n\n\t\tport, err := strconv.Atoi(fields[2])\n\t\tif err != nil {\n\t\t\tfmt.Println(err.Error())\n\t\t\treturn\n\t\t}\n\n\t\tnode := Node{fmt.Sprintf(\"%s:%d\", fields[1], port), fields[0], fields[1], port}\n\t\tnodes = append(nodes, node)\n\t\turls = append(urls, node.URL)\n\n\t\tfmt.Printf(\"Host: %s\\n\", node.Host)\n\t\tfmt.Printf(\"IP: %s\\n\", node.IP)\n\t\tfmt.Printf(\"Port: %d\\n\", node.Port)\n\t\tfmt.Printf(\"URL: %s\\n\\n\", node.URL)\n\t}\n\n\tmc := memcache.New(urls...)\n\tmc.Set(\u0026memcache.Item{Key: \"foo\", Value: []byte(\"my value\")})\n\n\tit, err := mc.Get(\"foo\")\n\tif err != nil {\n\t\tfmt.Println(err.Error())\n\t\treturn\n\t}\n\n\tfmt.Printf(\"%+v\", it)\n}\n```\n","tags":""},{"id":"ab995319d287314a45c74d5f49d90c5d","title":"[First Time Flyers] Help for those new to flying ","content":"First time flying? \n\nMaybe you're flying 'by yourself' for the first time? \n\nThe latter is usually scarier as you feel like you should know what to do by now.\n\nFear not. Here's how it works...\n\n1. [Get your flight details](#get-your-flight-details)\n2. [Book car parking](#book-car-parking)\n3. [Get to the airport](#get-to-the-airport)\n4. [Check-in](#check-in)\n5. [Drop off your bags](#drop-off-your-bags)\n6. [Go through Security](#go-through-security)\n7. [Wait a long time](#wait-a-long-time)\n8. [Get on your plane](#get-on-your-plane)\n9. [Land at your destination](#land-at-your-destination)\n10. [Get out of the airport](#get-out-of-the-airport)\n\n## Get your flight details\n\nSo you've booked your flight. Now what?\n\nCheck your email for the details of your booking.\n\nThere's two important bits of information you'll need:\n\n1. booking reference (or flight locator number)\n2. flight number\n\nThe reason you need these details is that they'll let you log into the website of the relevant airline you're flying with.\n\nWhy would you want to do that? Well, it's because it means you can put in any missing details ([ESTA VISA](https://esta.cbp.dhs.gov/), Passport numbers, reserve your seats, check-in etc).\n\nFor example, my last trip I was flying with American Airlines, so I went to their website: https://www.americanairlines.co.uk/ and from there I could locate my flight using the details providing in my booking confirmation email.\n\nNext, find out what airport 'terminal' you're going to be flying out from.\n\nFor example, if you're going to fly from London Heathrow airport (LHR), you can check which 'terminal' you're flying out from [here](http://www.heathrow.com/airport-guide/which-terminal).\n\n## Book car parking\n\nIf you want to also book car parking at the airport you're flying from, then knowing the terminal can be useful information (so you get a parking space nearest to that terminal).\n\nI like to fly out from London Heathrow (LHR) airport as it's easiest for me to drive to.\n\nTo review LHR short stay carparking, click [here](http://www.heathrow.com/transport-and-directions/heathrow-parking/heathrow-short-stay-parking#).  \n\nYou can also manage your LHR account (for car park bookings) [here](https://secure.heathrow.com/lhrcustreg/heathrow/CustomerLogin.aspx).\n\n## Get to the airport\n\nSo you've got your booking and flight details, now what?\n\nWell, you need to get to the airport that you're flying from.\n\nMake sure you get to the airport 2hrs before your flight is scheduled to leave (maybe 3hrs if you're nervous).\n\nWhen you get to the airport, first you'll want to head to \"Departures\".\n\n## Check-in\n\nNow you're at \"Departures\", you need to get your plane ticket (i.e. your \"boarding pass\").\n\nDepending on your airport you'll either talk to a human or the process will be automated by machines.\n\nEither way you look for the airline you're flying with and you \"check-in\" (this is the process of identifying yourself and the flight you've booked, and in return you're given a \"boarding pass\").\n\nNowadays you can \"check-in\" the day before (yes, you can actually \"check-in\" at home while online). If that's what you do, you can choose to either print your boarding pass at home from your own printer or you can just \"check-in\" and choose to pick up your boarding pass from an automated \"check-in\" machine at the airport.\n\nBut realistically, if you're going to check-in from home, then you'll likely just print your boarding pass from there as well.\n\n## Drop off your bags\n\nNow you have your boarding pass you can drop off any luggage you have (i.e. anything larger than a rucksack that you want to have stored on the plane while you fly).\n\nNearby where you \"checked-in\" will be the \"Bag Drop\" associated with the airline you're flying with.\n\nIn order to drop off your luggage you'll need your boarding pass and your passport (to prove who you are and that you're allowed to drop your luggage onto that flight).\n\n## Go through Security\n\nOnce you've dropped your bags off you'll immediately walk towards a \"security check\" zone. This is so the airport authorities can ensure you're not carrying any dangerous weapons onto the plane.\n\nYou'll have to follow their instructions (which could be things like, take off your watch, belt, jacket and put them into a basket to be scanned).\n\nOnce you're through security you're get to the fun part...\n\n## Wait a long time\n\nDepending on how earlier you got to the airport, you'll now have to sit around until it's time to get onto your plane. \n\nFor me, the process of getting my boarding pass, check-in and going through security leaves me approximately 2hrs of sitting around :-( but hey, I get time to sit on my laptop with the airport free wifi and write things like this very article :-)\n\nAt this point you need to look at the large 'departure' screens that show all the flights going out that day. On that screen you'll locate your flight and it'll tell you where your 'gate' is (the gate is where you walk to in order to get on your plane). \n\nIf you're plane isn't ready to fly, then the screen will say something like \"no gate number yet\" (or in some cases it'll tell you when they expect the gate number to be shown; which is handy as I can set a timer on my phone to check back in 2hrs time if that's when they reckon it'll be ready - although I have a habit of looking at the screen on a regular basis in case that number changes).\n\nMy first pro tip is to straight away go to a shop and buy yourself snacks, a magazine or book and a large bottle of water (so you can stay hydrated on your flight). \n\nOne thing of interest to mention here, is that whenever you buy something at the airport you need to have your boarding pass available. I've no idea why, you just need to show the sales person your boarding pass and they'll scan it `¯\\_(ツ)_/¯`\n\nMy second pro tip is to get yourself a seat right in front of the 'departure' boards. This is so you don't have to keep getting up and walking to one in order to see the details of your flight (for nervous passengers this is so much easier as you can constantly glance up at the screen... no, no gate number shown yet).\n\n## Get on your plane\n\nEventually your flight's gate number will be shown on the departure screen. Take note of the number and walk towards that gate.\n\nWhen at that gate you'll again present your boarding pass and passport, and then you'll sit down until the plane is ready for you to board it (this can also take quite some time, so be patient).\n\nYou might also find that the airport staff will only allow certain members to board the plane at a time. Usually disabled people or parents with young children are first. Then rich people who fly first class, and so on down.\n\nI fly economy, as I can't afford rich people seats, so I have to sit around for quite a while.\n\n## Land at your destination\n\nOnce you've landed, and you've departed the plane, you'll need to head to the \"Arrivals\" area of the airport (or look for \"baggage claim\" if you've got luggage on the plane you need to now collect).\n\nOnce in that area, look for your flight number and walk to the zone where your luggage will be made available for you to pick up.\n\nPro tip: tie some colourful material around the handle on your luggage. So many people have black luggage (or luggage of the same colour as you) that it becomes awkard knowing which bag is yours.\n\nSome people place bright stickers on their luggage so they instantly recognise their bags. Other people just buy REALLY bright coloured bags :-)\n\n## Get out of the airport\n\nOnce you've got your luggage you want to head for the airport exits.\n\nBut first you'll need to go through \"passport control\", this is where your destination country checks your passport and ensures you're not a known criminal trying to hide away in their country.\n\nIf you've landed in America you might find that you have to go through multiple security checks.\n\nThe steps are generally...\n\n+ Head towards \"Baggage Claim\"\n+ Clear Immigration first\n+ Get bags from carousel\n+ Pass security on exit\n\nPro tip: be patient, be kind and give honest answers. Don't crack a joke about having a bomb in your bag or anything like that. Security at airports do NOT have a sense of humor. Just smile, answer questions you're asked and you'll be through and out of there in no time.\n\nNow from there you can go about getting to your hotel and enjoying your holiday/trip.\n","tags":"#tags: flight, flying"},{"id":"defcfaed6d59cc27b6e3d951e93e8a54","title":"Bold text in bash output","content":"bold=$(tput bold)\nnormal=$(tput sgr0)\n\necho \"So, ${bold}I'm bolded${normal} but I'm not bolded\"\n","tags":""},{"id":"6776715c2e5f468a303f36dbb52bfec4","title":"Bash Associative Arrays","content":"#!/bin/bash\n\ndeclare -A arr\n\narr=(\n  [foo1.foo.foo]=bar\n  [baz]=qux\n)\n\necho \"${arr[foo1.foo.foo]}\"\n\nfor item in \"${arr[@]}\"\ndo\n  echo \"value: $item\"\ndone\n\ndeclare -A arr2\n\narr2[foo]=bar\narr2[baz]=qux\n\nfor i in \"${!arr2[@]}\"  # access keys with !\ndo\n  echo \"key: $i\"\n  echo \"value: ${arr2[$i]}\"\ndone\n","tags":""},{"id":"81031cc1d99d007afe9cf544dd6595c0","title":"Debugging nginx with custom headers","content":"map \"$http_x_some_custom_header\" $foo {\n  default 0;   # default value\n  \"desktop\" 1; # if header is \"desktop\" then set $foo to 1\n}\n\n# or maybe some variable created via `set` declaration\n# `set $foo bar;`\n\nadd_header X-debug-message \"foo is ${foo}\" always; # always only available from 1.7.5 nginx\n","tags":""},{"id":"3edda4adb44ed6e2177034740936ece6","title":"[Bash function passed an Array] ","content":"#!/bin/bash\n\nfunction accept {\n  local things=(\"${!1}\")\n\n  for thing in \"${things[@]}\"\n  do\n    echo \"thing: $thing\"\n  done\n}\n\nthings=(foo bar baz)\n\naccept things[@]\n","tags":"#bash #array"},{"id":"30f5a0eb07f93c90c8ec7e223a040902","title":"Bash join Array values","content":"# Join Array: Version 1\nfunction join_array {\n  local IFS=\"$1\"\n  shift\n  echo \"$*\"\n}\necho \"joined together v1: $(join_array , a \"b c\" d)\"\n\n# Join Array: Version 2\nfoo=('foo bar' 'foo baz' 'bar baz')\nbar=$(printf \",%s\" \"${foo[@]}\")\nbar=${bar:1} # removes the first , incorrectly added to start of string\necho $bar\necho \"joined together v2: $bar\"\n","tags":""},{"id":"ce3783da8cd0b178be7b8ef6121ee47f","title":"Python EasyDict","content":"class EasyDict(dict):\n    '''\n    No need to specify brackets/quotes for accessing attributes\n    A namedtuple is immutable and so you can't add new attributes\n    This is a hack to work around that restriction by inheriting from `dict`\n    '''\n    __setattr__ = dict.__setitem__\n    __getattr__ = dict.__getitem__\n    __delattr__ = dict.__delitem__\n    def __dir__(self):\n        return list(self.keys())\n        \nd = EasyDict()\nd  # {}\nd.foo  # KeyError: 'foo'\nd.foo = 123\nd.foo  # 123\nd  # {'foo':123}\ndel(d.foo)\nd  # {}\n","tags":""},{"id":"9d56525978e03ea2fcc73bebd9fa983d","title":"Python coloured logs","content":"# Doesn't work well with Papertrail (and possibly other log aggregator services)\n\nimport colorlog\n\nlogger = colorlog.getLogger()  ￼\nlogger.setLevel(colorlog.colorlog.logging.DEBUG)  ￼\n\nhandler = colorlog.StreamHandler()\nhandler.setFormatter(colorlog.ColoredFormatter())  ￼\nlogger.addHandler(handler)\n\nlogger.debug(\"Debug message\")\nlogger.info(\"Information message\")\nlogger.warning(\"Warning message\")\nlogger.error(\"Error message\")\nlogger.critical(\"Critical message\")\n","tags":""},{"id":"09fec74608b3b0a8b2c3cc8202ea19f5","title":"gpg-agent across vm ssh sessions","content":"which gpg-agent \u0026\u0026 {\n    gpg_agent_info_path=\"${HOME}/.gpg-agent-info\"\n    if [ -f \"$gpg_agent_info_path\" ]; then\n        echo \"using existing gpg agent\"\n        . \"${HOME}/.gpg-agent-info\"\n        export GPG_AGENT_INFO\n    else\n        echo \"starting gpg agent\"\n        eval $(gpg-agent --daemon --write-env-file \"$gpg_agent_info_path\")\n    fi\n}\n","tags":""},{"id":"7f0efad70f8e65b69f463bac4cf5cf56","title":"Managing resources with Python Context Managers","content":"files = []\n\nfor _ in range(100000):\n    with open('foo.txt', 'w') as f:\n        files.append(f)\n\nprint(files)\nfiles = []\n\nclass Open():\n    def __init__(self, filename, mode):\n        self.filename = filename\n        self.mode = mode\n\n    def __enter__(self):\n        self.open_file = open(self.filename, self.mode)\n        return self.open_file\n\n    def __exit__(self, *args):\n        self.open_file.close()\n\nfor _ in range(100000):\n    with Open('foo.txt', 'w') as f:\n        files.append(f)\n\nprint(files)\nfrom contextlib import contextmanager\n\nfiles = []\n\n@contextmanager\ndef open_file(path, mode):\n    file = open(path, mode)\n    yield file\n    file.close()\n\nfor _ in range(100000):\n    with open_file('foo.txt', 'w') as f:\n        files.append(f)\n\nprint(files)\nfiles = []\n\nfor _ in range(100000):\n    f = open('foo.txt', 'w')\n    f.close()\n    files.append(f)\n\nprint(files)\n","tags":""},{"id":"10a8dca7bf3c6dbd6faf8609a43905fd","title":"Python Jinja Example","content":"from jinja2 import Template\nt = Template(\"Hello {{ something }}!\")\nt.render(something=\"World\")\n# u'Hello World!'\n","tags":""},{"id":"7ec3f86d4929471151aba5f376b91187","title":"[Docker NGINX Plus] ","content":"```Dockerfile\n# https://www.nginx.com/resources/admin-guide/installing-nginx-plus/#install_debian_ubuntu\nFROM python:3.6.1-slim\n\n# Set the debconf frontend to Noninteractive\nRUN echo 'debconf debconf/frontend select Noninteractive' | debconf-set-selections\nRUN apt-get update \u0026\u0026 apt-get install -y -q wget curl apt-transport-https lsb-release ca-certificates\nRUN python3 --version \u0026\u0026 pip3 --version\n\nCOPY ./requirements.txt /app/\nRUN pip3 install -r /app/requirements.txt\n\n# See scripts/prebuild for details of where cert/key is pulled from\nADD nginx-repo.crt /etc/ssl/nginx/\nADD nginx-repo.key /etc/ssl/nginx/\n\n# Get other files required for installation\nRUN wget -q -O - http://nginx.org/keys/nginx_signing.key | apt-key add -\nRUN wget -q -O /etc/apt/apt.conf.d/90nginx https://cs.nginx.com/static/files/90nginx\n\nRUN printf \"deb https://plus-pkgs.nginx.com/debian `lsb_release -cs` nginx-plus\\n\" \u003e/etc/apt/sources.list.d/nginx-plus.list\n\n# Install NGINX Plus (this will fail without above ^^ cert/key credentials)\n# To find latest version use: apt-cache policy nginx-plus\n# https://www.nginx.com/resources/admin-guide/nginx-plus-releases/\nRUN apt-get update \u0026\u0026 apt-get install -y nginx-plus=1.13.4-1~jessie\n\nADD . /app\n\nCMD python3 /app/template.py nginx.conf.j2 /nginx.conf \u0026\u0026 nginx -c /nginx.conf\n```\n","tags":"#nginx-plus #nginx #docker"},{"id":"77d73b2380e4645b564c28c53fae71fb","title":"Python Asyncio Timing Decorator","content":"import asyncio\nimport time\n\n\ndef timeit(func):\n    async def process(func, *args, **params):\n        if asyncio.iscoroutinefunction(func):\n            print('this function is a coroutine: {}'.format(func.__name__))\n            return await func(*args, **params)\n        else:\n            print('this is not a coroutine')\n            return func(*args, **params)\n\n    async def helper(*args, **params):\n        print('{}.time'.format(func.__name__))\n        start = time.time()\n        result = await process(func, *args, **params)\n\n        # Test normal function route...\n        # result = await process(lambda *a, **p: print(*a, **p), *args, **params)\n\n        print('\u003e\u003e\u003e', time.time() - start)\n        return result\n\n    return helper\n\n\nasync def compute(x, y):\n    print('Compute %s + %s ...' % (x, y))\n    await asyncio.sleep(1.0)  # asyncio.sleep is also a coroutine\n    return x + y\n\n\n@timeit\nasync def print_sum(x, y):\n    result = await compute(x, y)\n    print('%s + %s = %s' % (x, y, result))\n\nloop = asyncio.get_event_loop()\nloop.run_until_complete(print_sum(1, 2))\nloop.close()\n'''\nthis was complicated because of the mocking of objects\nyou need to mock not the source where the module is\nbut mock the full path to where the module (e.g. statsd) is imported and used\nso I import statsd into app/renderer.py so that's where I mock from\n\nI also needed to utilise side_effect for mocking the time builtin\nthis is so that it would return multiple values every time it was called\n'''\n\n# pylint: disable=W0613\n\nimport asyncio\nfrom unittest import mock\nfrom app.renderer import time_it\n\n\nasync def coro(*args, **params):\n    await asyncio.sleep(0)\n    return 'foobar'\n\n\n'''\nThe `loop` argument in each test is provided by tests/conftest.py\n\nPytest looks in every test-directory for a file called conftest.py\nand applies the fixtures and hooks implemented there to all tests within that directory\n'''\n\n\n@mock.patch('app.renderer.time')\n@mock.patch('app.renderer.statsd')\ndef test_sync_time_it(mock_stats, mock_time, loop):\n    async def do_test():\n        mock_time.time.side_effect = [2, 10]\n        expectation = 'foobar'\n        func = lambda *args, **params: 'foobar'\n        ti = time_it(func)\n        result = await ti({}, {})\n        mock_stats.timing.assert_called_with('component.dict.\u003clambda\u003e.time', 8)\n        assert result == expectation\n\n    loop.run_until_complete(do_test())\n\n\n@mock.patch('app.renderer.time')\n@mock.patch('app.renderer.statsd')\ndef test_async_time_it(mock_stats, mock_time, loop):\n    async def do_test():\n        mock_time.time.side_effect = [2, 10]\n        expectation = 'foobar'\n        ti = time_it(coro)\n        result = await ti({}, {})\n        mock_stats.timing.assert_called_with('component.dict.coro.time', 8)\n        assert result == expectation\n\n    loop.run_until_complete(do_test())\nimport asyncio\nimport pytest\n\n'''\n# Following can be useful when running tests in shared environment\n# Alongside multiple other services using this as a shared lib\n#\n# pylint: disable=wrong-import-order\n\nimport pytest\n\ntry:\n    import asyncio\nexcept (ImportError, RuntimeError):\n    pytest.skip('unsupported configuration')\n'''\n\n@pytest.yield_fixture\ndef loop():\n    # Set-up\n    evloop = asyncio.new_event_loop()\n    asyncio.set_event_loop(evloop)\n\n    yield evloop\n\n    # Clean-up\n    evloop.close()\n","tags":""},{"id":"f6ff300dd586d40bf3584183f419b09e","title":"Python2: YAML convert to OrderedDict (http://stackoverflow.com/questions/5121931/in-python-how-can-you-load-yaml-mappings-as-ordereddicts/21912744","content":"from collections import OrderedDict\nimport yaml\nimport yamlordereddictloader\n\nfor data in yaml.load_all('foo: beep\\nbar: 123\\nbaz: 456'):\n    print data\n# {'bar': 123, 'foo': 'beep', 'baz': 456}\n\ndatas = yaml.load(\n    'foo: beep\\nbar: 123\\nbaz: 456',\n    Loader=yamlordereddictloader.Loader\n)\n\nprint datas\n# OrderedDict([('foo', 'beep'), ('bar', 123), ('baz', 456)])\n\n\n# Following works with safe_load\n# And no need for external library `yamlordereddictloader`\ndef ordered_load(stream, loader=yaml.Loader, object_pairs_hook=OrderedDict):\n    class OrderedLoader(loader):\n        pass\n\n    def construct_mapping(loader, node):\n        loader.flatten_mapping(node)\n        return object_pairs_hook(loader.construct_pairs(node))\n\n    OrderedLoader.add_constructor(\n        yaml.resolver.BaseResolver.DEFAULT_MAPPING_TAG,\n        construct_mapping\n    )\n    return yaml.load(stream, OrderedLoader)\n\nprint ordered_load('foo: beep\\nbar: 123\\nbaz: 456', yaml.SafeLoader)\n# OrderedDict([('foo', 'beep'), ('bar', 123), ('baz', 456)])\n","tags":"#21912744)"},{"id":"89aa62c98bd60403fefe3ab1b6eb993e","title":"[Compiling Python] ","content":"\u003e DOCUMENTATION:\n\u003e https://devguide.python.org/setup/#macos-and-os-x\n\nThe `python3-setuptools` package provides the `easy_install3` command, which we can use to install `pip` (not sure why it's not included with Python beta as it normally is with standard releases?)\n\n```bash\napt-get update \u0026\u0026 \\\napt-get install -y -q wget \u0026\u0026 \\\napt-get install -y -q build-essential python3-setuptools \u0026\u0026 \\\napt-get build-dep -y -q python3 \u0026\u0026 \\\nwget https://www.python.org/ftp/python/3.6.0/Python-3.6.0b1.tgz \u0026\u0026 \\\ntar xf Python-3.6.0b1.tgz \u0026\u0026 \\\nrm Python-3.6.0b1.tgz \u0026\u0026 \\\ncd Python-3.6.0b1/ \u0026\u0026 \\\n./configure \u0026\u0026 \\\nmake \u0026\u0026 \\\n./python --version\n```\n\nDon't try to move the `./python` executable into `/usr/local/bin/` as it won't be able to locate the other libraries/modules it links to. If anyone knows how to solve that issue, then please let me know!\n\nPython looks here for packages:\n\n```bash\n./python  \" starts REPL\n\n\u003e\u003e\u003e import sys\n\u003e\u003e\u003e print('\\n'.join(sys.path))\n\n/usr/local/lib/python36.zip\n/Python-3.6.0b1/Lib\n/Python-3.6.0b1/build/lib.linux-x86_64-3.6\n```\n\nSo if we install `Jinja2` we can see where it's installed:\n\n```bash\npip install jinja2\n/usr/local/lib/python3.4/dist-packages | grep -i jin\n```\n\nMeaning we can now modify the `` environment variable to utilise that package. \n\n```bash\nexport PYTHONPATH=\"$PYTHONPATH:/usr/local/lib/python3.4/dist-packages\"\n```\n\nSo now if we open a REPL again with the new Python we can import the package:\n\n```bash\n./python  \" starts REPL\n\n\u003e\u003e\u003e import sys\n\u003e\u003e\u003e print('\\n'.join(sys.path))\n\n/Python-3.6.0b1\n/usr/local/lib/python3.4/dist-packages      \" see it's there \u003c\u003c\n/usr/local/lib/python36.zip\n/Python-3.6.0b1/Lib\n/Python-3.6.0b1/build/lib.linux-x86_64-3.6\n\nimport jinja2  \" this now works √\n```\n\nThe downside to this approach is that the module might not be compatible with the new beta release of Python we've just installed\n\n## Dockerfile\n\n```Dockerfile\nFROM ubuntu:14.04\n\nADD . /app\n\n# Set the debconf frontend to Noninteractive\nRUN echo 'debconf debconf/frontend select Noninteractive' | debconf-set-selections\n\nRUN apt-get update \u0026\u0026 apt-get install -y -q wget curl apt-transport-https lsb-release ca-certificates\n\n# Download and build Python3\n# The `python3-setuptools` package provides the `easy_install3` command\nRUN apt-get install -y -q build-essential python3-setuptools \u0026\u0026 apt-get build-dep -y -q python3 \u0026\u0026 wget https://www.python.org/ftp/python/3.6.0/Python-3.6.0b1.tgz \u0026\u0026 tar xf Python-3.6.0b1.tgz \u0026\u0026 rm Python-3.6.0b1.tgz \u0026\u0026 cd Python-3.6.0b1/ \u0026\u0026 ./configure \u0026\u0026 make \u0026\u0026 ./python --version\nRUN easy_install3 pip \u0026\u0026 pip install jinja2\nENV PYTHONPATH=\"${PYTHONPATH}:/usr/local/lib/python3.4/dist-packages\"\n```\n\n## References\n\n- https://passingcuriosity.com/2015/installing-python-from-source/\n- https://leemendelowitz.github.io/blog/how-does-python-find-packages.html\n- https://www.iram.fr/IRAMFR/GILDAS/doc/html/gildas-python-html/node36.html\n# DOCUMENTATION:\n# https://devguide.python.org/setup/#macos-and-os-x\n\n# GET FILES...\n#\n# wget https://www.python.org/ftp/python/3.9.0/Python-3.9.0a5.tgz\ncurl https://www.python.org/ftp/python/3.9.0/Python-3.9.0a5.tgz -o Python-3.9.0a5.tgz\n\n# UNZIP FILES...\ntar xzvf Python-3.9.0a5.tgz\n\n# CONFIGURE BUILD INFORMATION...\ncd Python-3.9.0a5\n./configure --prefix=$HOME/python-3.9.0a5\n\n# COMPILE PYTHON\nmake\nmake install\n$HOME/python-3.9.0a5/bin/python3.9\n","tags":"#python #compile #manual #install"},{"id":"a3db511b7800f5b5a0bef3aba3c63ea1","title":"Domain Structure","content":"```\nscheme:[//[user:password@]host[:port]][/]path[?query][#fragment]\n```\n","tags":""},{"id":"703869f00ee1ac9267803264f5bb81d0","title":"Papertrail Log Aggregator: Filter 5xx errors","content":"time papertrail --min-time '10 minutes ago' -g rig-web-public | grep -oE '(GET|POST) /.* HTTP/1.1 5[0-9]{2}' | sort | uniq -c\n","tags":""},{"id":"5f92f748a3c73a98b1e51dd3dc9ac0ea","title":"Python calculate difference in dates","content":"published = '1466625902'\nthen = datetime.fromtimestamp(int(published))\nnow = datetime.now()\nelapsed = now - then\nminutes = floor(elapsed.seconds / 60)\nhours = floor(minutes / 60)\n\nreturn '{} days and {} hours ago'.format(elapsed.days, hours)\n","tags":""},{"id":"36621860135c2a265cf7b6eb0f661db5","title":"Netcat in Python","content":"# pylint: disable-all\n# flake8: noqa\n\nimport sys\nimport socket\nimport getopt\nimport threading\nimport subprocess\n\nlisten = command = upload = False\nexecute = target = upload_destination = ''\nport = 0\n\n\ndef usage():\n    print '''\n        netcat.py -t \u003chost\u003e -p \u003cport\u003e\n\n        -l, --listen                (listen on specified host/port)\n        -e, --execute=\u003cfile_to_run\u003e (execute file upon connection)\n        -c, --command               (initialize a shell)\n        -u, --upload=\u003cdestination\u003e  (upload file upon connection)\n    '''\n\n\ndef client_sender(buffer):\n    client = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n\n    try:\n        client.connect((target, port))\n\n        if len(buffer):\n            client.send(buffer)\n\n        while True:\n            recv_len = 1\n            response = ''\n\n            while recv_len:\n                data = client.recv(4096)\n                recv_len = len(data)\n                response += data\n\n                if recv_len \u003c 4096:\n                    break\n\n            print response\n\n            buffer = raw_input('')\n            buffer += '\\n'\n\n            client.send(buffer)\n    except:\n        print 'Exception. Exiting'\n        client.close()\n\n\ndef server_loop():\n    global target\n\n    if not len(target):\n        target = '0.0.0.0'\n\n    server = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n    server.bind((target, port))\n    server.listen(5)\n\n    while True:\n        client_socket, address = server.accept()\n        client_thread = threading.Thread(\n            target=client_handler,\n            args=(client_socket,)\n        )\n        client_thread.start()\n\n\ndef run_command(cmd):\n    command = cmd.rstrip()\n\n    try:\n        output = subprocess.check_output(\n            command,\n            stderr=subprocess.STDOUT,\n            shell=True\n        )\n    except:\n        output = 'Failed to execute command\\r\\n'\n\n    return output\n\n\ndef client_handler(client_socket):\n    global upload, execute, command\n\n    if len(upload_destination):\n        file_buffer = ''\n\n        while True:\n            data = client_socket.recv(1024)\n\n            if not data:\n                break\n            else:\n                file_buffer += data\n\n        try:\n            file_descriptor = open(upload_destination, 'wb')\n            file_descriptor.write(file_buffer)\n            file_descriptor.close()\n\n            client_socket.send('Successfully saved file to {}\\r\\n'.format(upload_destination))\n        except:\n            client_socket.send('Failed to save file to {}\\r\\n'.format(upload_destination))\n\n    if len(execute):\n        output = run_command(execute)\n        client_socket.send(output)\n\n    if command:\n        while True:\n            client_socket.send('\u003cBHP:#\u003e ')\n            cmd_buffer = ''\n\n            while '\\n' not in cmd_buffer:\n                cmd_buffer += client_socket.recv(1024)\n\n            response = run_command(cmd_buffer)\n            client_socket.send(response)\n\n\ndef main():\n    global listen, port, execute, command, upload_destination, target\n\n    if not len(sys.argv[1:]):\n        usage()\n\n    try:\n        opts, args = getopt.getopt(sys.argv[1:], 'hle:t:p:cu:', [\n            'help', 'listen', 'execute', 'target', 'port', 'command', 'upload'\n        ])\n    except getopt.GetoptError as err:\n        print str(err)\n        usage()\n\n    for o, a in opts:\n        if o in ('-h', '--help'):\n            usage()\n        elif o in ('-l', '--listen'):\n            listen = True\n        elif o in ('-e', '--execute'):\n            execute = a\n        elif o in ('-c', '--command'):\n            command = True\n        elif o in ('-u', '--upload'):\n            upload_destination = a\n        elif o in ('-t', '--target'):\n            target = a\n        elif o in ('-p', '--port'):\n            port = int(a)\n        else:\n            assert False, 'Unhandled Option'\n\n    if not listen and len(target) and port \u003e 0:\n        buffer = sys.stdin.read(\n        client_sender(buffer)\n\n    if listen:\n        server_loop()\n\nmain()\n\n\"\"\"\necho -ne 'GET / HTTP/1.1\\r\\nHost: www.google.com\\r\\n\\r\\n' | python netcat.py -t www.google.com -p 80\n\nalso\n\npython netcat.py -l -p 9999 -c        # first  terminal\npython netcat.py -t localhost -p 9999 # second terminal\n\"\"\"\n\n","tags":""},{"id":"b25185f91ebc8a56fe070d499111b447","title":"Python 3: Convert namedtuple into dict so we can convert it to json","content":"import json\nfrom collections import namedtuple\n\nx = namedtuple('_', ['language', 'country', 'locale'])(\n            'en',\n            'en-GV',\n            'en_US'\n        )\n\nnt = x._asdict()\n\nprint('namedtuple:', nt) \n\n# OrderedDict([('language', 'en'), ('country', 'en-GV'), ('locale', 'en_US')])\n\n# Note: if you want to print `nt` as a dict then you'll need to wrap it in a dict(nt) call\n\nz = json.dumps(nt)\n\nprint('json dump:', z)\n\n# {\"language\": \"en\", \"country\": \"en-GV\", \"locale\": \"en_US\"}\n","tags":""},{"id":"868693b4fdaf62ac68df4e6b4370322d","title":"Python Generator Expressions","content":"(x for x in open('super-large.txt'))  # short-hand syntax for a generator ()\n                                      # better performing than a list comprehension []\n                                      # which loads everything into memory all at once\n                                      \nfor line in (x for x in open('super-large.txt')):\n    pass  # execute once for every line\n  \nfor line in (x for x in open('super-large.txt') if int(x) % 100):\n    pass  # execute once every 100 lines (instead of every line)\n","tags":""},{"id":"55d091fad91c2b4c7e9a36b3c798f01a","title":"nginx health check via docker","content":"# docker run --name nginx-container -v $(pwd)/nginx.conf:/etc/nginx/nginx.conf:ro -P -d nginx\n\nuser www-data;\nworker_processes auto;\npid /nginx.pid;\n\nevents {\n  worker_connections 512;\n}\n\nhttp {\n  server {\n    location /health {\n      access_log /dev/stdout;\n      error_log /dev/stdout warn;\n      stub_status on;\n    }\n  }\n}\n","tags":""},{"id":"0b469a51b83eb905b2d202407cffa8b7","title":"Docker Alpine","content":"Dockerfile:\n\n```conf\nFROM nginx:alpine\nRUN apk update \u0026\u0026 apk add curl python\n```\n\nBuild and Execute:\n\n```bash\ndocker build --tag integralist:alpine-testing .\ndocker run -it --name nginx-alpine-test integralist:alpine-testing ash \n```\n\n\u003e Note: no `bash` command in alpine, so use `ash` instead  \n\u003e Unless you `apk add bash` as well\n","tags":""},{"id":"f48288f7133fc6d1769707e5c96d5569","title":"Python stdlib scheduler","content":"import sched\nimport time\nfrom datetime import datetime, timedelta\nscheduler = sched.scheduler(timefunc=time.time)  ￼\n\ndef saytime():  ￼\n    print(time.ctime())\n    scheduler.enter(10, priority=0, action=saytime)  ￼\n\nsaytime()\ntry:\n    scheduler.run(blocking=True)  ￼\nexcept KeyboardInterrupt:\n    print('Stopped')\n","tags":""},{"id":"335cb5bb402bcc7fd0c4c6a88776f08a","title":"Terminal Resize Images with ImageMagick","content":"## Installation\n\n```bash\nbrew install imagemagick\n```\n\n## Commands\n\nThe ImageMagick commands that modify images are `mogrify` and `convert`.\n\nBy default, the `mogrify` command overwrites the existing image with the modified image unless you specify an output folder into which modified image will be saved.\n\nThe `convert` command saves a new modified image and leaves the original unchanged so it is safer to use.\n\n## Add Border\n\n```bash\nmogrify -path Newimage/ -border 1x1 -bordercolor \"#000000\" image.png\n```\n\nor\n\n```bash\nconvert -border 1x1 -bordercolor \"#000000\" image.png Newimage/new-image.png\n```\n\n## Resize\n\nTo reduce an image’s width to 790 pixels while maintaining the aspect ratio, and to avoid increasing the size of the image if it is already smaller than 790 pixels wide, use either of the commands:\n\n```bash\nmogrify -path Newimage/ -resize \"790\u003e\" image.png\n```\n\nor\n\n```bash\nconvert -resize \"790\u003e\" image.png Newimage/image.png\n```\n\n## Change File Type\n\n```bash\nconvert image.png Newimage/image.jpg\n```\n\n## Quality\n\nThe default JPEG qualilty is 92% but you may set it to any value from 0% to 100%.\n\nFor example, to convert all the PNG images in a directory to JPEG with 70% quality, enter the command:\n\n```bash\nconvert -quality 70 image.png Newimage/image.jpg\n```\n\n## Combining Transformations\n\n```bash\nconvert -resize \"790\u003e\" -border 1x1 -bordercolor \"#000000\" -quality 70 image.png converted.jpg\n```\n\nYou can also use wildcards to batch process (but not change format or rename):\n\n```bash\nmogrify -path Newimage/ -resize \"790\u003e\" -border 1x1 -bordercolor \"#000000\" *.*\n```\n\nIf you want to change the format or rename a file in a batch, then you need the `convert` command, but that doesn't handle wildcards so you need to do something like:\n\n```bash\nmkdir Newimage\nfor i in *.png; do convert \"$i\" \"Newimage/${i%.*}.jpg\"; done\n```\n\nTo then combine those transformations:\n\n```bash\nfor i in *.png; do convert -resize \"790\u003e\" -border 1x1 -bordercolor \"#000000\" -quality 70 \"$i\" \"Newimage/${i%.*}.jpg\"; done\n```\n","tags":""},{"id":"3d8e407cbba5bd3539393dfbe7774fe2","title":"Update Homebrew Apache Bench","content":"brew install 'https://raw.github.com/simonair/homebrew-dupes/e5177ef4fc82ae5246842e5a544124722c9e975b/ab.rb'\nbrew test ab\n","tags":""},{"id":"dcf09ce0bdd58c527bc6fa63737dbd4e","title":"Python access the stack trace failed functions","content":"import sys\nimport traceback\nimport logging\n\ndef i_will_fail():\n    raise Exception\n\ndef i_call_the_failing_function():\n    i_will_fail()\n\ntry:\n    i_call_the_failing_function()\nexcept Exception:\n    _, _, tb = sys.exc_info()\n    for frame in traceback.extract_tb(tb):\n        logging.error('Module name: %s; scope name: %s', frame[0], frame[2])\n        \n\"\"\"\nERROR:root:Module name: exception-traceback.py; scope name: \u003cmodule\u003e                                                                                                        \nERROR:root:Module name: exception-traceback.py; scope name: i_call_the_failing_function                                                                                     \nERROR:root:Module name: exception-traceback.py; scope name: i_will_fail  \n\"\"\"\n","tags":""},{"id":"efe0e673ecd02f9a96e9cbc071c5b1b3","title":"SSH port binding","content":"With SSH port binding you can do something like:\n\n```bash\nssh -i developer.pem -L 8081:localhost:8081 ubuntu@52.222.222.22\n```\n\nNow visit `localhost:8081` and it'll connect to the remote instance\n","tags":""},{"id":"b7cc23bbe544428758339b6b8bdbd5b4","title":"Export code into formatted file","content":"# copy code into your clipboard first\n# then execute the following code\npbpaste | highlight --syntax=bash --out-format=rtf --output=/tmp/my-formatted-code.rtf\n","tags":""},{"id":"c6e4f7f6f27ed996e9a9a777c85fd746","title":"Python Binary Search Tree","content":"# Binary Search Tree:\n#\n# Smaller values go to the left\n# Larger values go to the right\n\nclass Node(object):\n    def __init__(self, key, value, parent):\n        self._key = key\n        self._value = value\n        self._parent = parent\n        self._left = None\n        self._right = None\n\n    @property\n    def key(self):\n        return self._key\n\n    @property\n    def value(self):\n        return self._value\n\n    @property\n    def parent(self):\n        return self._parent\n\n    @property\n    def left(self):\n        return self._left\n\n    @property\n    def right(self):\n        return self._right\n\n    @key.setter\n    def key(self, value):\n        self._key = value\n\n    @value.setter\n    def value(self, value):\n        self._value = value\n\n    @parent.setter\n    def parent(self, value):\n        self._parent = value\n\n    @left.setter\n    def left(self, value):\n        self._left = value\n\n    @right.setter\n    def right(self, value):\n        self._right = value\n\n    def is_leaf(self):\n        return not self.right or self.left\n\n    def has_children(self):\n        return self.right or self.left\n\n    def has_both_children(self):\n        return self.right and self.left\n\n    def successor(self):\n        pass\n\n\nclass BinarySearchTree(object):\n    def __init__(self, root=None):\n        self.root = root\n        self.size = 0\n\n    def put(self, key, value):\n        if self.root:\n            self._put(key, value, self.root)\n        else:\n            self.root = Node(key, value, None)\n\n        self.size = self.size + 1\n\n    def _put(self, key, value, current_node):\n        if key \u003c current_node.key:\n            if current_node.left:\n                self._put(key, value, current_node.left)\n            else:\n                current_node.left = Node(key, value, current_node)\n        else:\n            if current_node.right:\n                self._put(key, value, current_node.right)\n            else:\n                current_node.right = Node(key, value, current_node)\n\n    def get(self, key):\n        if self.root:\n            node = self._get(key, self.root)\n            return node.value\n        else:\n            return None\n\n    def _get(self, key, current_node):\n        if not current_node:\n            return None\n        elif current_node.key == key:\n            return current_node\n        elif key \u003c current_node.key:\n            return self._get(key, current_node.left)\n        elif key \u003e current_node.key:\n            return self._get(key, current_node.right)\n        else:\n            return None\n\n    # __contains__ overloads the \"in\" operator\n    def __contains__(self, key):\n        return bool(self._get(key, self.root))\n\n    def delete(self, key):\n        if self.size \u003e 1:\n            node = self._get(key, self.root)\n            if node:\n                self._remove(node)\n                self.size = self.size-1\n            else:\n                print(\"Sorry, the key '{}' wasn't found\".format(key))\n        elif self.size == 1 and self.root.key == key:\n            self.root = None\n            self.size = 1\n        else:\n            print(\"Sorry, the key '{}' wasn't found\".format(key))\n\n    def _remove(self, node):\n        if node.is_leaf():\n            self._remove_leaf(node)\n        elif node.has_both_children():\n            self._remove_with_children(node)\n        else:\n            self._remove_with_child(node)\n\n    def _remove_leaf(self, node):\n        if node == node.parent.left:\n            node.parent.left = None\n        else:\n            node.parent.right = None\n\n    def _remove_with_child(self, node):\n        if node.left:\n            node.left.parent = node.parent\n            node.parent.left = node.left\n        else:\n            node.right.parent = node.parent\n            node.parent.right = node.right\n\n    def _remove_with_children(self, node):\n        successor = self._find_min(node.right) # smallest key in right subtree\n        self._remove(successor)\n        self.put(successor.key, successor.value)\n\n    def _find_min(self, node):\n        current = node\n        while current.left:\n            current = current.left\n        return current\n\n\nif __name__ == \"__main__\":\n    BST = BinarySearchTree()\n    BST.put(5, \"foo\")\n    BST.put(2, \"bar\")\n    BST.put(8, \"baz\")\n    BST.put(15, \"qux\")\n    BST.put(10, \"qiz\")\n    BST.put(1, \"beep\")\n    BST.put(3, \"boop\")\n\n# Binary Search Tree:\n#\n#         (5)\n#        /   \\\n#     (2)     (8)\n#    /   \\       \\\n# (1)     (3)     (15)\n#                /\n#            (10)\n#\n# Visualisation tool:\n#   http://btv.melezinek.cz/binary-search-tree.html\n\n    print(\"10: \", BST.get(10))\n    print(\"5: \", BST.get(5))\n    print(\"8: \", BST.get(8))\n    print(\"3: \", BST.get(3))\n\n    if 15 in BST:\n        print(\"found the key I'm searching for\")\n    else:\n        print(\"didn't find the key\")\n\n    print(\"size: \", BST.size) # 7\n\n    BST.delete(2)\n\n    print(\"size: \", BST.size) # 6\n","tags":""},{"id":"b416501ca4ab98c966e872ba23662e05","title":"Functional Ruby with Lambda/Procs","content":"def responded(req, resp)\n  lambda = method(:extract).to_proc.curry.call(\n    resp.body, resp.env.url, req[:meta].id\n  )\n\n  responses \u003c\u003c {\n    :head       =\u003e lambda.call(\"head\"),\n    :bodyInline =\u003e lambda.call(\"bodyInline\"),\n    :bodyLast   =\u003e lambda.call(\"bodyLast\"),\n    :cached     =\u003e req[:cached]\n  }\nend\n","tags":""},{"id":"20e773f92466fc7508143bfafb55b9d3","title":"Python setup for NeoVim","content":"- `sudo easy_install pip`\n- `pip --version`\n- `pip install --user neovim` (installs plugin that NeoVim can utilise)\n\n\u003e Note: `klen/python-mode` (vim plugin)\n","tags":""},{"id":"592042384d547d0621613f719205b7a2","title":"[Python3 Virtual Environment with virtualenv] ","content":"Use [virtualenv](https://virtualenv.pypa.io/en/latest/) to allow each of your projects to have their own set of dependencies. This is similar to how Ruby has Bundler and Gemfiles so you don't install certain packages globally.\n\n- `sudo pip install virtualenv` (installs it globally; ironic I know but this is OK)\n- `virtualenv env` (`env` is the dir that'll be created; this name is common practice)\n\nAvoid commiting `env` into version control by utilising `.gitignore`\n\n\u003e `virtualenv .` side-steps the folder creation if you really prefer\n\nNow you can install packages using:\n\n- `env/bin/pip install \u003cpackage\u003e`\n\nTo run the Python binary you don't use the system version; instead:\n\n- `env/bin/python \u003c...\u003e`\n\nIf you don't like typing, you can shorten the `env/bin` so it becomes part of your shell's environment:\n\n- `source env/bin/activate`\n\nTo demonstrate:\n\n- `which python` = `/usr/bin/python`\n- `source env/bin/activate`\n- `which python` = `~/Projects/python/foo-project/env/bin/python`\n\n\u003e Use `deactivate` whenever using the same shell to swith between projects\n\n### Switching Python versions\n\nSo `virtualenv` will use the default Python version installed (for me it was `2.7.10`).\n\nTo switch it to using Python 3, execute the following:\n\n```bash\nvirtualenv -p python3 \u003cenv\u003e\n```\n","tags":"#python3"},{"id":"c972802f1601540d59dbc9a3d9c38fb2","title":"ls command behave like tree command","content":"   .\n   |-lib\n   |---composition\n   |-----error\n   |-----page\n   |-----response\n   |-----routing\n   |-----schema\n   |-spec\n   |---composition\n   |-----page\n   |-----response\n   |-----schema\n   |---fixtures\n   |---integration\nls -R | grep \":\" | sed -e 's/://' -e 's/[^-][^\\/]*\\//--/g' -e 's/^/   /' -e 's/-/|/'\n","tags":""},{"id":"aa62485464d512d6c79a92b6d2bb9b2a","title":"Programming Languages - Word Association","content":"## Clojure\n\n- Lisp\n- Functional\n- Immutable\n- Concurrency\n- JVM\n\n## Go\n\n- Network Programming\n- Declarative\n- Fast\n- Binary Executable\n- Simple Language Design\n- Good Tooling\n- Standardised Formatting\n\n## Python\n\n- Consistent\n- Explicit\n- Trusted\n- GIL\n\n## Ruby\n\n- Good standard library\n- Problematic Dependency Management\n- Object-Oriented\n- Functional _aspects_\n- GIL\n- JRuby (Threading)\n\n## Rust\n\n- Systems Programming\n- Functional _looking_\n- Safe\n- Immutable\n- Generics\n- Traits\n- Cargo Vendoring\n","tags":""},{"id":"e7577572c0e8f59cbf34b91173d67dd4","title":"Bash read the user input and react to it","content":"echo \"Hello, what's your name?\"\n\nread users_name\n\necho \"Hi $users_name\"\n\necho \"Do you want to continue? (y)es or (n)o\"\n\nread cont\n\nif [ $cont == \"y\" ] || [ $cont == \"Y\" ] ; then\n  echo \"Cool, let's keep going.\"\nelse\n  echo \"Sorry to see you go. Bye\"\nfi\n\nread -p \"👉  Would you like to to \u003csomething\u003e? (y/N) \" -r\necho\nif [[ $REPLY =~ ^[Nn]$ ]]; then\n  echo \"❌  Stopping setup.\"\n  exit 1\nfi\n","tags":""},{"id":"f832aac00ec710a08049cd070323a3fe","title":"[Python Tornado Yield Multiple Async Requests] ","content":"\"\"\"\nthis uses tornado's own IOLoop (i.e. not asyncio's) and it also uses tornado's own\nconcurrency functions such as `tornado.gen.coroutine` instead of `async/await` as\nthose are native Python3 functions and not compatible with tornado.\n\"\"\"\n\nfrom tornado.gen import coroutine\nfrom tornado.httpclient import AsyncHTTPClient\nfrom tornado.ioloop import IOLoop\n\nAsyncHTTPClient.configure(None, defaults=dict(user_agent=\"IntegralistTesting\"))\nhttp_client = AsyncHTTPClient()\n\n\ndef get_urls():\n    host = \"www.buzzfeed.com\"\n\n    paths = [\n        \"/news\",\n        \"/quizzes\",\n        \"/tvandmovies\",\n        \"/shopping\",\n        \"/celebrity\",\n        \"/videos\",\n        \"/animals\",\n        \"/newsletters\",\n        \"/trending\",\n        \"/valezabakolli/more-bargain-buys-under-6-that-you-might-actua-kmldud9yf\",  # noqa\n    ]\n\n    responses = []\n\n    for path in paths:\n        responses.append(http_client.fetch(f\"https://{host}/{path}\"))\n\n    return responses\n\n\n@coroutine\ndef process_urls():\n    a, b, c, d, e, f, g, h, i, j = yield get_urls()\n\n    for k, v in locals().items():\n        print(f\"var: {k}, {v.effective_url}: {v.code}\")\n\n\nio_loop = IOLoop.current()\nio_loop.run_sync(process_urls)\nimport time\nimport tornado.ioloop\nimport tornado.web\nimport tornado.httpclient\n\nclass MainHandler(tornado.web.RequestHandler):\n    @tornado.gen.coroutine\n    def get(self):\n        first_then = time.time()\n        response = yield single_async_http_request()\n        first_now = time.time()\n\n        print(\"Single HTTP Request: %d\" % round(first_now - first_then))\n        print(response.body)\n\n        second_then = time.time()\n        future_a, future_b = yield [*multiple_async_http_requests()]\n        second_now = time.time()\n\n        print(\"Multiple HTTP Requests: %d\" % round(second_now - second_then))\n        print(future_a.body, future_b.body)\n        print(\"Overall time: %d\" % round(second_now - first_then))\n\n        self.write('...')\n        self.finish()\n\ndef multiple_async_http_requests():\n    http = tornado.httpclient.AsyncHTTPClient()\n    a = http.fetch(\"http://some-slow-responding-server\")\n    b = http.fetch(\"http://some-slow-responding-server\")\n    return a, b\n\n@tornado.gen.coroutine\ndef single_async_http_request():\n    http = tornado.httpclient.AsyncHTTPClient()\n    response = yield http.fetch(\"http://some-slow-responding-server\")\n    return response\n\nif __name__ == \"__main__\":\n    app = tornado.web.Application([\n        (r\"/foo/?\", MainHandler),\n    ])\n    app.listen(8888)\n\n    tornado.ioloop.IOLoop.current().start()\n","tags":"#python #tornado #yield #splat #async #asynchttpclient #locals #vars #variables"},{"id":"3f004c3594bbf8431c15ed6db15809ae","title":"Python TCP Client Server Example","content":"import socket\n\nhostname, sld, tld, port = 'www', 'integralist', 'co.uk', 80\ntarget = '{}.{}.{}'.format(hostname, sld, tld)\n\n# create an ipv4 (AF_INET) socket object using the tcp protocol (SOCK_STREAM)\nclient = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n\n# connect the client\n# client.connect((target, port))\nclient.connect(('0.0.0.0', 9999))\n\n# send some data (in this case a HTTP GET request)\nclient.send('GET /index.html HTTP/1.1\\r\\nHost: {}.{}\\r\\n\\r\\n'.format(sld, tld))\n\n# receive the response data (4096 is recommended buffer size)\nresponse = client.recv(4096)\n\nprint response\nimport socket\nimport threading\n\nbind_ip = '0.0.0.0'\nbind_port = 9999\n\nserver = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\nserver.bind((bind_ip, bind_port))\nserver.listen(5)  # max backlog of connections\n\nprint 'Listening on {}:{}'.format(bind_ip, bind_port)\n\n\ndef handle_client_connection(client_socket):\n    request = client_socket.recv(1024)\n    print 'Received {}'.format(request)\n    client_socket.send('ACK!')\n    client_socket.close()\n\nwhile True:\n    client_sock, address = server.accept()\n    print 'Accepted connection from {}:{}'.format(address[0], address[1])\n    client_handler = threading.Thread(\n        target=handle_client_connection,\n        args=(client_sock,)  # without comma you'd get a... TypeError: handle_client_connection() argument after * must be a sequence, not _socketobject\n    )\n    client_handler.start()\n","tags":""},{"id":"310fa87e707a0d54962545b1d2aeb6ea","title":"Netcat web server","content":"{ echo -ne \"HTTP/1.0 200 OK\\r\\nContent-Length: $(wc -c \u003csome.file)\\r\\n\\r\\n\"; cat some.file; } | nc -l 8080\n","tags":""},{"id":"481b72ab2db5d913a864958f4379ed42","title":"Redirect stdout and stderr","content":"- File descriptor 0 is the standard input (`stdin`).  \n- File descriptor 1 is the standard output (`stdout`).  \n- File descriptor 2 is the standard error (`stderr`).\n\nExample redirection(s)...\n\n```bash\ndocker ps 1\u003e /dev/null 2\u003e\u00261\n```\n\nThe above example will redirect `stdout` (1) to `/dev/null`.\n\nIt then redirects `stderr` (2) to wherever `stdout` is pointing.\n\nAt first, `2\u003e1` may look like a good way to redirect `stderr` to `stdout`. However, it will actually be interpreted as \"redirect stderr to a file named 1\". `\u0026` indicates that what follows is a file descriptor and not a filename. So the construct becomes: `2\u003e\u00261`.\n","tags":""},{"id":"84622bbfbb64a5a2b315a5a35fc3945b","title":"Python Exception Stack Trace Debugging","content":"import traceback\n\ntry:\n    raise ValueError\nexcept:\n    tb = traceback.format_exc()\nelse:\n    tb = \"No error\"\nfinally:\n    print tb\n\n# log the stack\nstack = ''.join(traceback.format_exception(exc_cls, exc_val, exc_traceback))\n","tags":""},{"id":"a2f01ab4aabb786268d5006da5013c9e","title":"Python equivalent to Ruby's Pry (update: use https://docs.python.org/3/library/pdb.html - see also https://pythonconquerstheuniverse.wordpress.com/2009/09/10/debugging-in-python/)","content":"## Basic\n\n```py\nimport code; code.interact(local=locals())\n```\n\n## Advanced\n\nIPython with `embed()`\n\nInstall it with:\n\n```bash\npip install ipython\n```\n\nUse it like so:\n\n```py\nfrom IPython import embed\n\n# Misc code\n\nembed() # this will drop us into IPython\n\n# Misc code\n```\n\nAlthough you can use it directly as well:\n\n```py\nimport IPython\n\nx = \"foo\"\nprint(x)\n\nIPython.embed()\n\nx = \"bar\"\nprint(x)\n```\n","tags":""},{"id":"6f34e23f71340a1a23e846cd2f64cf32","title":"Python Asyncio Loop Forever","content":"import asyncio\n\nasync def listener():\n    while True:\n        message = await sqs.poll()\n        if message:\n            asyncio.ensure_future(handle(message))\n            \nasync def handler(message):\n    await ...\n\nloop = asyncio.get_event_loop()\nasyncio.ensure_future(listener)\nloop.run_forever()\n","tags":""},{"id":"e70e1556656f92b9cb985b939e366973","title":"Git Request Pull","content":"In order to do a single commit pull request (without a GitHub Pull Request interface) - i.e. you'll communicate the diff with another collaborator - then first commit the change to a fork of the repository. \n\nThen run this command:\n\n```git\ngit request-pull -p \u003ccommit-to-start-from\u003e git@github.com:\u003corg\u003e/\u003crepo\u003e.git\n```\n\nThis will generate something like the following:\n\n```git\nThe following changes since commit d30a1ab53b80d35ffef00e9ca168c77798431d1c:\n\n  Starting commit message (2016-04-08 15:27:21 +0100)\n\nare available in the git repository at:\n\n  git@github.com:foo/bar.git \n\nfor you to fetch changes up to 74a6c7433b3197761e69efed1387d17861430b73:\n\n  My Commit Message (2016-04-11 11:46:18 +0100)\n\n----------------------------------------------------------------\nIntegralist (1):\n      My Commit Message\n\n README.md | 2 +-\n 1 file changed, 1 insertion(+), 1 deletion(-)\n\ndiff --git a/README.md b/README.md\nindex d6022e0..8663373 100644\n--- a/README.md\n+++ b/README.md\n@@ -1,4 +1,4 @@\n-\u003ch1 align=\"center\"\u003eOriginal\u003c/h1\u003e\n+\u003ch1 align=\"center\"\u003eNew Title\u003c/h1\u003e\n```\n","tags":""},{"id":"ce71e93f07f9f24030d0420a1969b3cc","title":"Git Workflow","content":"# Git Workflow\n\nWhen using [Git Version Control](https://git-scm.com/) you have quite a few workflow variations. Which one you choose depends on your team and what fits your requirements and usage more appropriately.\n\nHere are some popular options that will be described later in this document:\n\n- [Git 'Centralised' Workflow](#1)\n- [Git 'Feature Branches' Workflow](#2)\n- [Git 'Gitflow' Workflow](#3)\n- [Git 'Single Commit/No Branches' Workflow](#4)\n- [Git 'Rebase Feature Branch Commits' Workflow](#5)\n\n## Expectations\n\nAll of these workflows assume that you have a remote repository and by default the main branch is called `master`.\n\nAlso, we don't cover every possible detail about git and how it works/what certain concepts mean; as we assume a certain level of past experience from the reader. By this I mean, for example, if you don't know what a 'merge conflict' is you'll need to read up on git a bit more first in order to benefit from this document.\n\n## What's not covered?\n\nOne model I've not covered is the \"Git 'Forked Repo' Workflow\", which is based around the concept of developers not having push access to a repository but are able to fork the repo (i.e. make a clone of it). Pull Requests can then be made to the upstream repository that was forked from.\n\nThe reason for not covering this particular workflow is that within the BBC the majority of repositories are private by nature (except for those specifically made to be open-source) and so all developers working on a specific project will be given push access to the relevant private repo. \n\n\u003e Note: although the BBC does not encourage forking of its own private repositories, it does recognise and accept that the forking model is the fundamental and primary concept behind the open-source movement\n\n## Code Reviews\n\nAlthough not directly related to git workflows, it's important to remember that the GitHub model of reviewing code revolves around the idea of a Pull Request, but this is merely a clever abstraction on top of gits own `git request-pull` model which is built around the simple concept that a feature should be encapsulated within a single commit.\n\nThe command `git request-pull` is described in the git manual as follows:\n\n\u003e Summarizes the changes between two commits to the standard output, and includes the given URL in the generated summary.\n\nThis facilitates the ability to post the diff/summary of changes into a mailing list for easy comparison and reasoning before consideration to merging into `master`.\n\nThe only requirement for using the built-in `git request-pull` is that you need to provide a URL for where the commit you're proposing to be reviewed/merged can be pulled from by the owner of the origin repo.\n\nSo in other words, you'll need to have a _fork_ of the origin repo in another git repo that's accessible to the developers you're asking to review your commit. This isn't a problem for most organisations, although it's a little trickier for the BBC as it doesn't encourage forks of its private repositories. Just something to be aware of.\n\n\u003cdiv id=\"1\"\u003e\u003c/div\u003e\n## Git 'Centralised' Workflow\n\n\u003e Summary: everyone works from the `master` branch\n\n- Everyone clones the remote repo and commits changes to `master` locally\n- Local changes are then pushed to the remote repository\n- If someone pushes changes before you, then your push will fail\n- You'll need to pull their changes (`git pull origin master`) first\n- Any merge conflicts will then need to be resolved locally\n- Once merge conflicts are resolved, you can push to the remote\n\n### Pros\n\n- Can be less complex and time consuming than dealing with feature branches (assuming small teams of \u0026lt; 5)\n\n### Cons\n\n- Everyone committing to `master` can be uncomfortable for some teams\n- No categorised history, just multiple isolated commits\n- Merge commits are ugly and make the git history harder to reason about\n\n\u003cdiv id=\"2\"\u003e\u003c/div\u003e\n## Git 'Feature Branches' Workflow\n\n\u003e Summary: everyone works from their own 'feature' branch\n\n- Everyone clones the remote repo and creates a feature branch \n- For example `git checkout -b feat/add-redis-cache`\n- Commits are made to the feature branch locally\n- The feature branch should be pushed to the remote regularly\n- Feature branch is reviewed by other developers\n- Once approved the feature branch is merged into `master` locally\n- The updated `master` branch is then pushed to the remote\n- If someone pushes changes before you to `master`, then your push will fail\n- You'll need to pull their changes (`git pull origin master`) first\n- Any merge conflicts will then need to be resolved locally\n- Once merge conflicts are resolved, you can push to the remote\n\n### Notes\n\nTo reduce the likeliness of a merge conflict, developers should consider updating their `master` branch regularly and merging those changes into their feature branch (e.g. `git merge master`).\n\nDevelopers can also consider pulling `master` directly into their feature branch either by using `git pull origin master` or by using `git pull --rebase origin master` (which will unshift their feature branch commits so that they sit ontop of whatever is inside `master`; meaning the feature branch commits are 'top of the stack').\n\nAlso, when using `--rebase` you do typically experience less conflicts.\n\n### Pros\n\n- Most recognised/utilised workflow model\n- Use of 'short lived' feature branches allow decoupled development\n\n### Cons\n\n- No clean history, just multiple isolated commits\n- Merge commits are ugly and make the git history harder to reason about †\n\n\u003e † this is dependant on your team and your specific workflow  \n\u003e and the details a merge commit provides\n\n\u003cdiv id=\"3\"\u003e\u003c/div\u003e\n## Git 'Gitflow' Workflow\n\nGitflow is an evolution of the 'feature branch' model that adds additional layers to the workflow.\n\nWith Gitflow you have additional branches that interact with each other in different ways:\n\n![Gitflow](https://www.atlassian.com/git/images/tutorials/collaborating/comparing-workflows/gitflow-workflow/05.svg)\n\n- `master`: always deployable to production (`git tag` with release info)\n- `hotfix`: only branch to fork from `master` (for _quick_ patches to production)\n- `develop`: becomes the default branch for all development work\n- `release`: forked off of `develop` once enough 'features' are ready (only hotfixes to this branch until merge with `master`)\n- `feature`: multiple feature branches that are merged back into `develop` when ready\n\n### Pros\n\n- Provides a robust framework for dealing with large codebases\n\n### Cons\n\n- Vastly more complex\n- Multiple moving parts require solid co-ordination\n- No clean history, just multiple isolated commits\n\n\u003cdiv id=\"4\"\u003e\u003c/div\u003e\n## Git 'Single Commit/No Branches' Workflow\n\n\u003e Summary: everyone works from `master`, but 'rebase' commits before push\n\n- Everyone clones the remote repo and commits changes to `master` locally\n- Local changes are rebased interactively (`git rebase -i \u003ccommit\u003e`) into single commit\n- Local changes are then pushed to the remote repository\n- If someone pushes changes before you, then your push will fail\n- You'll need to pull their changes (`git pull origin master`) first\n- Any merge conflicts will then need to be resolved locally\n- Once merge conflicts are resolved, you can push to the remote\n\n### Notes\n\nThe reason you would choose this model is if you were using a traditional `git request-pull` for code reviews, and also it helps to keep your commit history clean and organised.\n\nThis approach ideally benefits small changes and short-lived PRs.\n\n### Pros\n\n- Can be less complex and time consuming than dealing with feature branches (assuming small teams of \u0026lt; 5)\n\n### Cons\n\n- Requires a team comfortable with quick and small feature releases\n- Requires steps that are more complicated for beginner git users (e.g. interactive rebasing)\n- Prone to errors on teams larger than 4 people\n- Unable to work on more than one feature at a time\n\n\u003cdiv id=\"5\"\u003e\u003c/div\u003e\n## Git 'Rebase Feature Branch Commits' Workflow\n\n\u003e Summary: work from a 'feature' branch, but 'rebase' commits before merge\n\n- Everyone clones the remote repo and creates a feature branch \n- For example `git checkout -b feat/add-redis-cache`\n- Commits are made to the feature branch locally\n- The feature branch should be pushed to the remote regularly\n- Feature branch is reviewed by other developers\n- Once approved the feature branch commits are rebased (`git rebase -i master`) into single commit\n- Commit message has specific format (`Closes #1 - Add Redis Cache (Fixes #2)`)\n- Commit is then cherry-picked into `master` (`git cherry-pick -`)\n- The updated `master` branch is then pushed to the remote\n- If someone pushes changes before you to `master`, then your push will fail\n- You'll need to pull their changes (`git pull --rebase origin master`) first\n- Any merge conflicts will then need to be resolved locally\n- Once merge conflicts are resolved, you can push to the remote\n\n### Notes\n\nGitHub specifically offers a feature where by GitHub issues are automatically closed whenever a push to `master` includes the phrase `Fixes #n` (where `n` is the issue number); similarly it'll automatically close a pull request when the commit message in `master` includes the phrase `Closes #n` (where `n` is the pull request number).\n\nAlso, the GitHub user interface now (as of 2016) suppports the ability to squash commits when merging. This might be a preferable option to the above steps.\n\n### Pros\n\n- Use of 'short lived' feature branches allow decoupled development\n- Clean git commit history (no ugly merge commits †)\n- Auto closing of Pull Requests and Issues within GitHub (assuming relevant commit syntax is used ^^)\n- Access to original commit history within GitHub Pull Request interface\n\n\u003e † this is dependant on your team and your specific workflow  \n\u003e and the details a merge commit provides\n\n### Cons\n\n- If a feature branch takes too long to merge, it can become a conflict nightmare\n- Requires steps that are more complicated for beginner git users (e.g. interactive rebasing and cherry picking)\n- Can't access original commit history via a terminal shell\n\n\u003e Note: if branches are deleted from GitHub then eventually the commits will be garbage collected and history lost there as well. So pick this option according to whether it fits your team's long term needs\n\n## References\n\n- [Atlassian: Comparing Workflows](https://www.atlassian.com/git/tutorials/comparing-workflows/centralized-workflow)\n- [Git SCM: Distributed Workflows](https://git-scm.com/book/en/v2/Distributed-Git-Distributed-Workflows)\n- [Git SCM: Contributing to a Project](https://git-scm.com/book/ch5-2.html)\n- [GitHub: Workflow Guide](https://guides.github.com/introduction/flow/)\n- [Integralist: GitHub Workflow](http://www.integralist.co.uk/posts/github-workflow.html)\n","tags":""},{"id":"115d083348cbd6521607eb1bfc03b39a","title":"Python Exception Logging Decorator","content":"import logging\n\ndef exception(func):\n    def wrapper(n):\n        try:\n            return func(n)\n        except Exception as err:\n            logging.error(\"Error: %s\", err)\n            raise\n    return wrapper\n\n@exception\ndef cause_an_error(n):\n    return 1 / n\n\nif __name__ == \"__main__\":\n    try:\n        result = cause_an_error(1) # change to zero to see the failure\n        print(result)\n    except Exception as err:\n        print(err)\n","tags":""},{"id":"e81902245636115169456956244e31a8","title":"Run foreground process in background (odd I know)","content":"nohup cron -f \u0026\n\n# nohup: invoke a utility immune to hangups (ignore SIGHUP \"signal hang up\")\n# cron -f: run cron process in foreground\n# \u0026: run in background\n","tags":""},{"id":"1e2616dc0b165f0edead9bf819d23c1e","title":"Bash rename function","content":"# copies function named $1 to name $2\nrename_function() {\n    declare -F $1 \u003e /dev/null || return 1\n    eval \"$(echo \"${2}()\"; declare -f ${1} | tail -n +2)\"\n}\n\noriginal() {\n  echo \"ORIGINAL\"\n}\n\nrename_function original renamed\n\noriginal() {\n  echo \"DO A NEW THING\"\n  renamed\n}\n\noriginal\n\n# DO A NEW THING\n# ORIGINAL\n","tags":""},{"id":"a15252e33c2bab27c811bc9da7484423","title":"Python 3: Reduce Array/List into Dict","content":"def fn():\n    count = 0\n    \n    def inner(acc, val):\n        nonlocal count \n        count += 1\n        acc[count] = val\n        \n        return acc\n         \n    return inner\n    \nreduce(fn(), ['a', 'b', 'c', 'd'], {})\n\n# {1: 'a', 2: 'b', 3: 'c', 4: 'd'}\n","tags":""},{"id":"e521a0a4eda8f5bfe130283e0f6a60c6","title":"URL Shortener","content":"# https://gist.github.com/zumbojo/1073996\n\n# Simple bijective function\n#   Basically encodes any integer into a base(n) string,\n#     where n is ALPHABET.length.\n#   Based on pseudocode from http://stackoverflow.com/questions/742013/how-to-code-a-url-shortener/742047#742047\n\nALPHABET =\n  \"abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789\".split(//)\n  # make your own alphabet using:\n  # (('a'..'z').to_a + ('A'..'Z').to_a + (0..9).to_a).shuffle.join\n\ndef bijective_encode(i)\n  # from http://refactormycode.com/codes/125-base-62-encoding\n  # with only minor modification\n  return ALPHABET[0] if i == 0\n  s = ''\n  base = ALPHABET.length\n  while i \u003e 0\n    s \u003c\u003c ALPHABET[i.modulo(base)]\n    i /= base\n  end\n  s.reverse\nend\n\ndef bijective_decode(s)\n  # based on base2dec() in Tcl translation \n  # at http://rosettacode.org/wiki/Non-decimal_radices/Convert#Ruby\n  i = 0\n  base = ALPHABET.length\n  s.each_char { |c| i = i * base + ALPHABET.index(c) }\n  i\nend\n\n# Two little demos:\n\n# Encoding ints, decoding them back:\nnum = 125\n(num..(num+10)).each do |i|\n  print i, \" \", bijective_encode(i), \" \", bijective_decode(bijective_encode(i)), \"\\n\"\nend\n\n# Decoding string mentioned in original SO question:\nputs bijective_decode(\"e9a\")\n# https://gist.github.com/bhelx/778542\n\n#!/usr/bin/env python\n\n#\n# Converts any integer into a base [BASE] number. I have chosen 62\n# as it is meant to represent the integers using all the alphanumeric\n# characters, [no special characters] = {0..9}, {A..Z}, {a..z}\n#\n# I plan on using this to shorten the representation of possibly long ids,\n# a la url shortenters\n#\n# saturate()  takes the base 62 key, as a string, and turns it back into an integer\n# dehydrate() takes an integer and turns it into the base 62 string\n#\nimport math\nimport sys\n\nBASE = 62\n\nUPPERCASE_OFFSET = 55\nLOWERCASE_OFFSET = 61\nDIGIT_OFFSET = 48\n\ndef true_ord(char):\n    \"\"\"\n    Turns a digit [char] in character representation\n    from the number system with base [BASE] into an integer.\n    \"\"\"\n    \n    if char.isdigit():\n        return ord(char) - DIGIT_OFFSET\n    elif 'A' \u003c= char \u003c= 'Z':\n        return ord(char) - UPPERCASE_OFFSET\n    elif 'a' \u003c= char \u003c= 'z':\n        return ord(char) - LOWERCASE_OFFSET\n    else:\n        raise ValueError(\"%s is not a valid character\" % char)\n\ndef true_chr(integer):\n    \"\"\"\n    Turns an integer [integer] into digit in base [BASE]\n    as a character representation.\n    \"\"\"\n    if integer \u003c 10:\n        return chr(integer + DIGIT_OFFSET)\n    elif 10 \u003c= integer \u003c= 35:\n        return chr(integer + UPPERCASE_OFFSET)\n    elif 36 \u003c= integer \u003c 62:\n        return chr(integer + LOWERCASE_OFFSET)\n    else:\n        raise ValueError(\"%d is not a valid integer in the range of base %d\" % (integer, BASE))\n\n\ndef saturate(key):\n    \"\"\"\n    Turn the base [BASE] number [key] into an integer\n    \"\"\"\n    int_sum = 0\n    reversed_key = key[::-1]\n    for idx, char in enumerate(reversed_key):\n        int_sum += true_ord(char) * int(math.pow(BASE, idx))\n    return int_sum\n\n\ndef dehydrate(integer):\n    \"\"\"\n    Turn an integer [integer] into a base [BASE] number\n    in string representation\n    \"\"\"\n    \n    # we won't step into the while if integer is 0\n    # so we just solve for that case here\n    if integer == 0:\n        return '0'\n    \n    string = \"\"\n    while integer \u003e 0:\n        remainder = integer % BASE\n        string = true_chr(remainder) + string\n        integer /= BASE\n    return string\n\nif __name__ == '__main__':\n    \n    # not really unit tests just a rough check to see if anything is way off\n    if sys.argv[1] == '-tests':\n        passed_tests = True\n        for i in xrange(0, 1000):\n            passed_tests \u0026= (i == saturate(dehydrate(i)))\n        print passed_tests\n    else:\n        user_input = sys.argv[2]\n        try:\n            if sys.argv[1] == '-s':\n                print saturate(user_input)\n            elif sys.argv[1] == '-d':\n                print dehydrate(int(user_input))\n            else:\n                print \"I don't understand option %s\" % sys.argv[1]\n        except ValueError as e:\n            print e\n","tags":""},{"id":"9bd233b776c9d5d6a3bc5710981d61e8","title":"Coding Best Practices: High Level Principles","content":"# High Level Principles\n\nThe following principles are very 'high-level' and meant to be used as a quick reference guide, as apposed to the other standards/guideline documents which will focus on specific language idioms and design patterns.\n\n- [Iceberg Classes](#iceberg-classes)\n- [Law of Demeter](#law-of-demeter)\n- [Don't Repeat Yourself](#dont-repeat-yourself)\n- [Design Patterns](#design-patterns)\n- [S.O.L.I.D](#solid)\n\n## Iceberg Classes\n\nAn 'iceberg' class is one that has more private methods than public. Typically what happens is the developer builds the class and exposes only the methods that they feel should be public, whilst all implementation details are hidden away in the private methods.\n\n### Problem\n\nThis is fine until it comes to testing (this is especially prevalent when *not* doing test-driven development; i.e. writing tests *after* the class has been created) where by you want to verify specific behaviour works as expected but you're unable to because your behaviour is locked away in private methods.\n\nDevelopers will typically try to either hack around the problem or inject additional context into the class, which makes sense in the test environment but not when the code is run in production.\n\n### Solution\n\nThe solution to this problem is to group together related private behaviour and extract it into a separate class. Naming this new class can be tricky though, as the new class is no longer a noun/object, it is instead very much behavioural (verb/action). If this is proving to be a problem or a concern, then maybe consider instead of creating a class you create a reusable module and include it as runtime instance methods.\n\n\u003e e.g. Ruby offers the ability to mixin behaviour via an `include` statement\n\n## Law of Demeter\n\nThe 'Law of Demeter' simply states that you should reduce the coupling between objects by identifying when you have a thread of context between them. This particular principle has the following rules:\n\n- Your method can call other methods in its class directly\n- Your method can call methods on its own fields directly (but not on the fields’ fields)\n- When your method takes parameters, your method can call methods on those parameters directly\n- When your method creates local objects, that method can call methods on the local objects\n\n### Problem\n\nImagine you have an object `User` and this has two public methods:\n\n1. name\n2. department\n\nYou might have a class that calls `User` and tries to extract their name as well as their department details.\n\nThis could potentially (depending on implementation) be a violation of the law of demeter:\n\n```rb\ndef user_info(user)\n  \"Name: #{user.name}. Dept: #{user.department.name}\"\nend\n```\n\nIn the above example we're violating the law of demeter because we're accessing a field's field (e.g. we send a message to `user.department` and then act on its result by trying to access the nested field `name`).\n\n### Solution\n\nThe `User` class should be modified to expose the department name rather than having an external class/object try to nest inside a data structure to extract that data. In other words, `User` class should have a `department_name` method that knows the context of its own data and exposes it to any consumers of the `User` class.\n\n## Don't Repeat Yourself\n\nMost people know the concept of \"Don't Repeat Yourself\" as the DRY principle.\n\nIn essence it applies to all forms of design, not just code (e.g. architecture, databases, documentation etc), but we'll consider the principle from the point of view of a programmer for now.\n\n### Problem\n\nYou've written some behaviour, or business logic, and you realise that implementation could be used within one or more unrelated areas of your codebase.\n\n### Solution\n\nMove the behaviour/logic into a function, class or module (whatever makes sense for the programming style you write) and make it a reusable entity by injecting its dependencies (e.g. any external references).\n\n## Design Patterns\n\nDesign Patterns are - as the name suggest - a common design/architecture/code 'pattern' that can be applied to a problem in a generalised way. These patterns are typically very abstract and that is their purpose. \n\nThe mistake most people make when learning about design patterns is assuming that they are an explicit solution to a particular problem. They are not. You need to consider the pattern being described and implement the pattern however you feel best suits the problem you're trying to solve.\n\nThere are many official † and unofficial 'design patterns', and in some cases there are concepts (such as [S.O.L.I.D](#solid) - see next section) that sometimes are mistaken for design patterns but really are just coding principles.\n\n\u003e † by 'official' I refer to the classic tech book \"Design patterns: elements of reusable object-oriented software\" and was co-authored by four different people. It is nowadays recognised as being authored by the \"Gang of Four\" and their described patterns are generally known as the \"GoF design patterns\"\n\nFor a list of creational, structural and behavioural design patterns we highly recommend the following resource:\n\n- https://sourcemaking.com/design_patterns\n\nHere are some common design patterns you might want to start learning about initially:\n\n- [Adapter](https://sourcemaking.com/design_patterns/adapter): \n- [Decorator](https://sourcemaking.com/design_patterns/decorator): \n- [Facade](https://sourcemaking.com/design_patterns/facade): \n- [Null Object](https://sourcemaking.com/design_patterns/null_object): \n- [Observer](https://sourcemaking.com/design_patterns/observer): \n- [Strategy](https://sourcemaking.com/design_patterns/strategy): \n- [Template Method](https://sourcemaking.com/design_patterns/template_method): \n\n## S.O.L.I.D\n\nThe S.O.L.I.D principles were named by [Robert C. Martin](https://en.wikipedia.org/wiki/Robert_Cecil_Martin) (highly respected software engineer and co-author of the Agile Manifesto).\n\n- `S`: Single Responsibility Principle\n- `O`: Open/Closed Principle\n- `L`: Liskov Substitution Principle\n- `I`: Interface Segregation Principle\n- `D`: Dependency Inversion Principle\n\nThese principles aim to help you to design and build software that will be easy to maintain and extend.\n\n### Summary of Principles\n\n- `S`: a class should have one, and only one, reason to change\n- `O`: you should be able to extend a class's behavior, without modifying it\n- `L`: derived classes must be substitutable for their base classes\n- `I`: make fine grained interfaces that are client specific.\n- `D`: depend on abstractions not on concrete implementations\n\n### References\n\nFor an example of these principles, then please refer to the following resources:\n\n- [Ruby code examples](https://gist.github.com/Integralist/9482527)\n- [Wikipedia](https://en.wikipedia.org/wiki/SOLID_(object-oriented_design))\n","tags":""},{"id":"9763bded76e7d826535a3caeafc3bdff","title":"Algorithms in Python (modified from the excellent: Grokking Algorithms) - see also http://www.integralist.co.uk/posts/bigo.html for details on understanding Big O notation","content":"'''    \nNotes:\n    The following implementation doesn't pick a pivot at random\n    It instead grabs the middle index\n'''\n\nitems = [10, 5, 2, 3, 7, 0, 9, 12]\nprint(\"Original:\", items)\n\ndef quicksort(arr):\n    if len(arr) \u003c 2:\n        return arr\n    else:\n        middle = round(len(arr) / 2)  # grab the middle index\n        pivot = arr.pop(middle)\n        less = [i for i in arr if i \u003c= pivot]\n        greater = [i for i in arr if i \u003e pivot]\n        return quicksort(less) + [pivot] + quicksort(greater)\n\nprint(\"Sorted:  \", quicksort(items))\n\n\"\"\"\nOriginal: [10, 5, 2, 3, 7, 0, 9, 12]\nSorted:   [0, 2, 3, 5, 7, 9, 10, 12]\n\"\"\"\n'''    \nNotes:\n    The following implementation picks a pivot at random\n    As it should be, per the original definition of the algorithm's design\n'''\n\nfrom random import randrange\n\nitems = [10, 5, 2, 3, 7, 0, 9, 12]\nprint(\"Original:\", items)\n\ndef quicksort(arr):\n    if len(arr) \u003c 2:\n        return arr\n    else:\n        middle = randrange(0, len(arr))  # grab a random index\n        pivot = arr.pop(middle)\n        less = [i for i in arr if i \u003c= pivot]\n        greater = [i for i in arr if i \u003e pivot]\n        return quicksort(less) + [pivot] + quicksort(greater)\n\nprint(\"Sorted:  \", quicksort(items))\n\n\"\"\"\nOriginal: [10, 5, 2, 3, 7, 0, 9, 12]\nSorted:   [0, 2, 3, 5, 7, 9, 10, 12]\n\"\"\"\n'''\nBreadth First Search\n\nDescription:\n    Breadth-first search tells you if there’s a path from A to B.\n    If there’s a path, breadth-first search will find the shortest path.\n    A directed graph has arrows, and the relationship follows the direction of the arrow.\n    Undirected graphs don’t have arrows, and the relationship goes both ways.\n\nExplanation:\n    A graph is made up of 'nodes' and 'edges'.\n    In this algorithm there are no 'weights' to the edges (see: Dijkstra’s algorithm)\n    An directed graph can also be a 'Tree', but an undirected graph cannot.\n    The closest nodes are our 1st 'degree', outer nodes are 2nd, 3rd degrees etc.\n\n    We keep a queue of the 1st degree nodes.\n    Pop the first node off the queue and check if this gives you your 'match'\n\n        'match' being the logic that determines if you can stop searching\n\n    If it doesn't match, then add all the 'neighbours' for that node to the queue.\n    Rinse and Repeat (e.g. pop next 1st degree node, check it, add neighbours...)\n    If the queue is empty, then there were no matches within your network graph.\n\nPerformance:\n    O(V+E)\n\n    It means V for vertices and E for edges.\n    That is, worst case, you have to search the entire graph \u0026 follow every edge.\n    It also includes O(1) for adding new degrees to the queue\n\nNotes:\n    Only provides you with the 'shortest' route, not the 'fastest'\n    For 'fastest' route (i.e. weighted graphs) see Dijkstra’s algorithm\n\n    You need to check people in the order they were added to the search list,\n    so the search list needs to be a queue.\n    Otherwise, you won’t get the shortest path.\n\n    You also need to make sure not to check the same node twice.\n    Some nodes from a degree could share a node in the next outer degree.\n    It doesn't break the algorithm but is a wasteful operation performance-wise.\n'''\n\ngraph = {}\ngraph['you'] = ['alice', 'bob', 'claire']\ngraph['bob'] = ['anuj', 'peggy']\ngraph['alice'] = ['peggy']\ngraph['claire'] = ['thom', 'johnny']\ngraph['anuj'] = []\ngraph['peggy'] = []\ngraph['thom'] = []\ngraph['jonny'] = []\n\n'''\n^^ is your network graph in basic code.\nYou are in the center and you have 3 neighbours.\nWe declare the neighbours for everyone in our data model (dict/hash table).\nWe're looking for someone whose name has 'm' as the last letter.\n'''\n\nfrom collections import deque\n\n\ndef check(key):\n    return key[-1] == 'm'\n\n\ndef search(starting_point):\n    queue = deque()\n    queue += graph[starting_point]  # add starting_point's neighbours initially\n    searched = []  # track items we've already checked\n\n    while queue:\n        item = queue.popleft()\n        if item not in searched:\n            if check(item):\n                print('found a match: {}'.format(item))\n                return True  # we're finished!\n            else:\n                queue += graph[item]  # add this item's neighbours\n                searched.append(item)  # tracked as being checked already\n\n    return False\n\nsearch('you')  # found a match: thom\n'''\nDijkstra's Algorithm\n\nDescription:\n    Tells you the quickest path from A to B within a weighted graph.\n\nExplanation:\n    Create a model of your graph which indicates the following:\n\n        Parent\n        Node\n        Cost\n\n    Get the node closest to the 'start'.\n    Check its neighbours and update the 'Cost' column.\n    If a neighbour's cost is updated, then update the parent's too.\n    Mark this node as 'processed' so you don't end up processing it again.\n\n    For more details on graph terminology see 'Breadth First Search'.\n\nPerformance:\n    O(V+E)\n\n    It means V for vertices and E for edges.\n    That is, worst case, you have to search the entire graph \u0026 follow every edge.\n\nNotes:\n    It doesn't work with 'negative' weighted graphs.\n\nWeighted/Directed Graph Example:\n\n         ---\u003e A ---\u003e\n        |     ^     |\n        6     |     1\n        |     |     |\n    start     3     |--\u003eend\n        |     |     |\n        2     |     5\n        |     |     |\n         ---\u003e B ---\u003e\n\nThe various routes and their costs are:\n\n    * start -\u003e A -\u003e end: 7\n    * start -\u003e B -\u003e end: 7\n    * start -\u003e B -\u003e A -\u003e end: 6\n\nWe can see the last route has more steps but is faster in terms of 'weight'\n'''\n\n#################################\n\n'''\nLet's start to model our graph...\n'''\n\ngraph = {}\n\n# Start has two neighbours 'a' and 'b'\n# So we model that as follows, with their associated edge weights\ngraph['start'] = {}\ngraph['start']['a'] = 6\ngraph['start']['b'] = 2\n\n# A has one neighbour (end)\ngraph['a'] = {}\ngraph['a']['end'] = 1\n\n# B has two neighbours (A and end)\ngraph['b'] = {}\ngraph['b']['a'] = 3\ngraph['b']['end'] = 5\n\n# End has no neighbours\ngraph['end'] = {}\n\n'''\nNow we need a 'costs' hash table...\n'''\n\ncosts = {}\ncosts['a'] = 6\ncosts['b'] = 2\ncosts['end'] = float('inf')  # set to infinity until we know the cost to reach\n\n'''\nNext we need a 'parents' hash table...\n'''\n\nparents = {}\nparents['a'] = 'start'\nparents['b'] = 'start'\nparents['end'] = None  # doesn't have one yet until we choose either 'a' or 'b'\n\n'''\nFinally we need to track which nodes have already been processed...\n'''\n\nprocessed = []\n\n'''\nOh, and one more array for the purpose of displaying the final route.\nIt's not used as part of the core algorithm, but utilised by the 'display_route' function\n'''\n\nroute = []\n\n'''\nHere is the implementation...\n'''\n\n\ndef find_fastest_path():\n    node = find_lowest_cost_node(costs)\n\n    while node is not None:\n        cost = costs[node]\n        neighbours = graph[node]\n\n        for n in neighbours.keys():\n            new_cost = cost + neighbours[n]\n\n            if costs[n] \u003e new_cost:\n                costs[n] = new_cost\n                parents[n] = node\n\n        processed.append(node)\n        node = find_lowest_cost_node(costs)\n\n\ndef find_lowest_cost_node(costs):\n    lowest_cost = float('inf')\n    lowest_cost_node = None\n\n    for node in costs:\n        cost = costs[node]\n        if cost \u003c lowest_cost and node not in processed:\n            lowest_cost = cost\n            lowest_cost_node = node\n\n    return lowest_cost_node\n\n\ndef display_route(node=None):\n    # These vars could be passed into the function\n    # if you wanted dynamic processing...\n\n    start_node = 'start'  # we look for this 'value'\n    end_node = 'end'  # we look for this 'key'\n\n    if node == start_node:  # we're done\n        route.append(node)\n        reverse_route = list(reversed(route))\n        print('Fastest Route: ' + ' -\u003e '.join(reverse_route))\n    elif node is None:  # begin processing (this condition only passes once)\n        end_parent = parents[end_node]  # get the parent node for the end node\n        route.append(end_node)\n        display_route(end_parent)\n    else:\n        parent = parents[node]\n        route.append(node)\n        display_route(parent)\n\nfind_fastest_path()  # mutates global 'costs' \u0026 'parents' arrays\ndisplay_route()  # Fastest Route: start -\u003e b -\u003e a -\u003e end\n- [Binary Search](#file-1-binary-search-py)\n- [Selection Sort](#file-2-selection-sort-py)\n- [Quick Sort (first index)](#file-3-quick-sort-first-index-py)\n- [Quick Sort (middle index)](#file-4-quick-sort-middle-index-py)\n- [Quick Sort (random index)](#file-5-quick-sort-random-index-py)\n- [Breadth First Search](#file-6-breadth-first-search-py)\n- [Dijkstra's Algorithm](#file-7-dijkstra-s-algorithm-py)\n'''\nBinary Search algorithm\n\nDescription:\n    Locate an item within a collection by using a \n    divide and conquer approach.\n\n    In essence, pick the middle of the collection\n    then verify if the value is too high or low\n    and then reduce the sliding window, now pick \n    the middle again - rinse/repeat\n\nPerformance:\n    O(Log₂ n)\n    Logarithmic time\n\nMeaning:\n    12 item collection will take (worst case) ~4 steps\n    to locate the specified index using binary search\n\nNote: collection must be sorted\n'''\n\ncollection = [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 20, 21]  # 12 items\n\n\ndef binary_search(collection, item):\n    print(\"we're looking for:\", item, \"\\n\")\n    print(\"collection:\", collection, \"\\n\")\n\n    start = 0\n    stop = len(collection) - 1\n\n    while start \u003c= stop:\n        middle = round((start + stop) / 2)\n        guess = collection[middle]\n\n        print(\"start: {}\\nstop: {}\\nmiddle: {}\\nguess: {}\\n\".format(start,\n                                                                    stop,\n                                                                    middle,\n                                                                    guess))\n\n        if guess == item:\n            return middle\n        if guess \u003e item:\n            stop = middle - 1\n        else:\n            start = middle + 1\n\n    return None\n\n\nprint(binary_search(collection, 9))  # found at index: 4\n'''\nSelection Sort algorithm\n\nDescription:\n    Sorts an unordered list by looping over the list\n    n number of times and for each loop identifying\n    either the smallest or largest element (which one \n    depends on how you're hoping to sort your list:\n    do you want ascending or descending order)\n\n    You'll end up constructing a new ordered list\n\nPerformance:\n    O(n x n)\n    O(n₂)\n\n    Both forms are equivalent.\n    You effectively loop a number of times to match collection length\n    Then you loop the collection looking for smallest/largest\n    Then you mutate the collection so it's smaller by one\n    \n    So although you're looping over the collection multiple times, \n    you are in fact looping over a slightly smaller collection each time\n\n    Although in reality the notation should be:\n        O(n x n - 1)\n\n    But that is invalid Big O notation, so we use\n    the O(n₂) or O(n x n) instead\n    \n    If your collection is 10 items long then this calculates as:\n        10 * 10 (i.e. 10 to the power of 2) = 100 operations\n        0.1 * 100 = 10 seconds\n    \nNote: to test algorithm in a different order, the\n      quickest change is to turn \u003c into \u003e within \n      the find_smallest function. \n      This would cause program to return [9, 5, 3, 1]\n'''\n\ndef find_smallest(arr):\n    smallest = arr[0]\n    smallest_index = 0\n\n    for i, _ in enumerate(arr):\n        if arr[i] \u003c smallest:\n            smallest = arr[i]\n            smallest_index = i\n\n    return smallest_index\n\ndef selection_sort(arr):\n    temp = []\n\n    for i in range(len(arr)):\n        smallest = find_smallest(arr)\n        temp.append(arr.pop(smallest))\n\n    return temp\n\nprint(selection_sort([5, 9, 3, 1]))  # [1, 3, 5, 9]\n'''\nQuick Sort algorithm\n\nDescription:\n    Sorts an unordered list using recusion and specifically\n    using the D\u0026C (Divide and Conquer) approach to problem solving\n\nExplanation:\n    You pick a 'pivot' (a random array index)\n    You loop the array storing items less than the pivot\n    You loop the array storing items greater than the pivot\n    Assume less and greater are already sorted\n    You can now return 'less' + pivot + 'greater'\n\n    In reality you'll use recursion to then sort both the\n    less and greater arrays using the same algorithm\n\nPerformance:\n    Worst case:\n        O(n x n)\n        O(n₂)\n        \n        If collection is 10 items in length (10 * 10 = 100 operations)\n        \n    Best case:\n        O(n Log₂ n)\n        \n        If collection is 10 items in length (10 * 4 (Log₂10 == 2*2*2*2) = 40 operations)\n\n    Quick Sort's performance depends on the pivot you choose\n\n    In our example code we always pick the zero index as it\n    makes the code simpler, but not necessarily the most performant\n    \nNotes:\n    The following implementation doesn't pick a pivot at random\n    It instead grabs the first index\n'''\n\ndef quicksort(arr):\n    if len(arr) \u003c 2:\n        return arr\n    else:\n        pivot = arr[0]\n        less = [i for i in arr[1:] if i \u003c= pivot]\n        greater = [i for i in arr[1:] if i \u003e pivot]\n        return quicksort(less) + [pivot] + quicksort(greater)\n\nprint(quicksort([10, 5, 2, 3, 7, 0, 9, 12]))  # [0, 2, 3, 5, 7, 9, 10, 12]\n","tags":""},{"id":"ad19a062fde8991e4373","title":"HTTP Status Codes","content":"## Basic workflow\n\n![Basic flow](https://cloud.githubusercontent.com/assets/180050/12266738/b8e5d4fa-b93c-11e5-9c2e-eb81bd1fa813.png)\n\n## 2xx-3xx\n\n![http-2xx-3xx-status-codes](https://cloud.githubusercontent.com/assets/180050/12266737/b8e4fde6-b93c-11e5-916e-3d12ca6749e3.png)\n\n## 4xx\n\n![http-4xx-status-codes](https://cloud.githubusercontent.com/assets/180050/12266736/b8e4a97c-b93c-11e5-8044-822f1930350f.png)\n\n## 5xx\n\n![http-5xx-status-codes](https://cloud.githubusercontent.com/assets/180050/12266739/b8e62112-b93c-11e5-8fa5-9e9dfa73b177.png)\n","tags":""},{"id":"12999021c58e7b4911e3","title":"Install dotfiles and give users options","content":"#!/bin/bash\n#\n# Installs the dotfiles into the user's home directory.\n#\n# NOTE: the bash dotfiles assume a layout of ~/dotfiles\n\nset -e\n\n# Directory in which this script is located.\nDIR=\"$( cd \"$( dirname \"${BASH_SOURCE[0]}\" )\" \u0026\u0026 pwd )\"\n\nfor file in *; do\n  if [ $file = \"README.md\" ]; then\n    continue\n  fi\n\n  sourcefile=\"${DIR}/${file}\"\n  dotfile=\"$HOME/.${file}\"\n\n  if [ -e \"${dotfile}\" ]; then\n    if [ $replace_all ]; then\n      ln -fs \"${sourcefile}\" \"${dotfile}\"\n    else\n      echo -n \"replace ${dotfile}? [ynaq] \"\n      read keypress\n      case \"$keypress\" in\n        \"y\" ) ln -nfs \"${sourcefile}\" \"${dotfile}\" ;;\n        \"n\" ) continue ;;\n        \"a\" )\n          replace_all=\"yes\"\n          ln -nfs \"${file}\" \"${dotfile}\"\n        ;;\n        \"q\" ) exit 0 ;;\n      esac\n    fi\n  else\n    ln -s \"${sourcefile}\" \"${dotfile}\"\n  fi\ndone\n\necho \"Installed dotfiles in $HOME\"\n","tags":""},{"id":"c485a9d3a998edc413ac","title":"Ruby Dynamic JSON Logger session via Lambda","content":"class Logger\n  define_method(:info) do |hash|\n    return if hash.is_a? String\n    @@session = -\u003e { \"n/a\" } unless defined? @@session\n    p @@session.()\n    p hash\n  end\n\n  def self.session(fn)\n    @@session = fn\n  end\nend\n\nlogger = Logger.new\nlogger.info \"hello\"\n\n# At some point AFTER the logger instance has already been created\nLogger.session -\u003e { \"beep\" }\n\nlogger.info :foo =\u003e :bar, :baz =\u003e 123\n","tags":""},{"id":"edd6ab7279fc037d23d2","title":"Bootstrap Mac OS X Configuration","content":"#!/bin/bash\n\n# Enable a form of 'strict mode' for Bash\nset -euo pipefail\nIFS=$'\\n\\t'\n\n# Decrease delay between repeated keys\ndefaults write NSGlobalDomain KeyRepeat -int 0\ndefaults write NSGlobalDomain InitialKeyRepeat -int 10\n\n# Disable smart quotes and dashes\ndefaults write NSGlobalDomain NSAutomaticQuoteSubstitutionEnabled -bool false\ndefaults write NSGlobalDomain NSAutomaticDashSubstitutionEnabled -bool false\ndefaults write com.apple.TextEdit SmartQuotes -bool false\ndefaults write com.apple.TextEdit SmartDashes -bool false\n\n# Configure menu bar clock to something useful\ndefaults write com.apple.menuextra.clock \"DateFormat\" \"EEE d MMM  HH:mm:ss\"\ndefaults write com.apple.menuextra.clock \"FlashDateSeparators\" 0\ndefaults write com.apple.menuextra.clock \"IsAnalog\" 0\n\n# Install xcode\nxcode-select --install\n\n# Install Homebrew\n/usr/bin/ruby -e \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)\"\nbrew update\n\n# Install Bash\nbrew install bash\necho /usr/local/bin/bash | sudo tee -a /etc/shells\nchsh -s /usr/local/bin/bash\n\n# Configure Bash\ncurl -LSso ~/.bashrc https://raw.githubusercontent.com/Integralist/dotfiles/master/.bashrc\n\ncat \u003e ~/.bash_profile \u003c\u003cEOF\nif [ -f $HOME/.bashrc ]; then\n  source ~/.bashrc\n  cd .\nfi\n\nif [ -f $(brew --prefix)/etc/bash_completion ]; then\n  source $(brew --prefix)/etc/bash_completion\nfi\nEOF\n\ncat \u003e ~/.inputrc \u003c\u003cEOF\nTAB: menu-complete\n\"\\e[Z\": \"\\e-1\\C-i\"\nEOF\n\n# Install NeoVim\nbrew tap neovim/neovim \u0026\u0026 brew install --HEAD neovim\n\n# Configure NeoVim/Vim\nmkdir -p ~/.vim/{autoload,bundle}\ncurl -LSso ~/.vim/autoload/pathogen.vim https://tpo.pe/pathogen.vim\ncurl -LSso ~/.vimrc https://raw.githubusercontent.com/Integralist/dotfiles/master/.vimrc\ncurl -LSso ~/usr/local/bin/voom https://raw.githubusercontent.com/airblade/voom/master/voom\nalias voom=\"VIM_DIR=~/.vim voom\"\nvoom\n\nvim -E -s \u003c\u003cEOF\n:set spell\n:quit\nEOF\n\n# Install Curl with OpenSSL and HTTP2\nbrew install curl --with-openssl --with-nghttp2 \u0026\u0026 brew link curl --force\n\n# Install other brew packages\npackages=(\\\n  argon/mas/mas\\\n  bash-completion\\\n  bundler-completion\\\n  docker-compose-completion\\\n  docker-machine\\\n  docker\\\n  gem-completion\\\n  gist\\\n  git\\\n  go\\\n  gpg\\\n  irssi\\\n  leiningen\\\n  mutt\\\n  netcat\\\n  ngrok\\\n  node\\\n  rbenv\\\n  reattach-to-user-namespace\\\n  ruby-build\\\n  siege\\\n  sift\\\n  terminal-notifier\\\n  the_silver_searcher\\\n  tmate\\\n  tmux\\\n  tree\\\n  watch\\\n  wget\\\n  wireshark\\\n)\nfor package in \"${packages[@]}\"\ndo\n  brew install $package\ndone\n\n# Configure Git\ncurl -LSso ~/.git-prompt.sh https://raw.githubusercontent.com/git/git/master/contrib/completion/git-prompt.sh\n\ncat \u003e ~/.gitignore-global \u003c\u003cEOF\n# bundler\n.gem\n.bin\n.ruby-version\nfailed_cukes.sh\n\n# miscellaneous\n*.DS_Store\n.sass-cache\n.grunt\ntags\n*.swp\nlogs\n*.log\n.vagrant*\nEOF\n\ngit config --global alias.lg \"log --graph --pretty=format:'%Cred%h%Creset -%C(yellow)%d%Creset %s %Cgreen(%cr)%Creset' --abbrev-commit --date=relative\"\ngit config --global alias.st status\ngit config --global alias.unstage \"reset HEAD --\"\ngit config --global apply.whitespace nowarn\ngit config --global color.branch.current yellow reverse\ngit config --global color.branch.local yellow\ngit config --global color.branch.remote green\ngit config --global color.commit red\ngit config --global color.diff-highlight.newhighlight=green bold 22\ngit config --global color.diff-highlight.newnormal=green bold\ngit config --global color.diff-highlight.oldhighlight=red bold 52\ngit config --global color.diff-highlight.oldnormal=red bold\ngit config --global color.diff.frag magenta\ngit config --global color.diff.meta yellow\ngit config --global color.diff.new green\ngit config --global color.diff.old red\ngit config --global color.status.added red\ngit config --global color.status.changed blue\ngit config --global color.status.untracked magenta\ngit config --global color.ui true\ngit config --global core.editor nvim\ngit config --global core.excludesfile ~/.gitignore-global\ngit config --global core.ignorecase false\ngit config --global merge.conflictstyle diff3\ngit config --global merge.tool vimdiff\ngit config --global mergetool.prompt true\ngit config --global push.default upstream\ngit config --global url.git@github.com:.insteadof https://github.com/\ngit config --global user.email mark.mcdx@gmail.com\ngit config --global user.name Integralist\n\n# Install applications from Mac App Store\nmas installed 411246225 # Caffeine\nmas installed 458034879 # Dash\nmas installed 549083868 # Display Menu\nmas installed 409789998 # Twitter\n\n# Miscellaneous\necho --color --format documentation --format=Nc \u003e ~/.rspec\ncurl -LSso ~/.tmux.conf https://raw.githubusercontent.com/Integralist/dotfiles/master/.tmux.conf\ncurl -LSso ~/smyck.terminal https://raw.githubusercontent.com/Integralist/dotfiles/master/terminal-themes/Smyck.terminal\nopen ~/smyck.terminal\n","tags":""},{"id":"25ed16d02e1d60b7d0dc","title":"Go running in Lambda: https://gist.github.com/miksago/d1c456d4e235e025791d and http://blog.0x82.com/2014/11/24/aws-lambda-functions-in-go/ and https://github.com/jasonmoo/lambda_proc for more details","content":"Go code for a `hello.go` file:\n\n```go\npackage main\n\nimport (\n  \"fmt\"\n  \"os\"\n)\n\nfunc main() {\n  fmt.Printf(\"HELLO FROM GOLANG WITH ARGS %v\", os.Args)\n}\n```\n\nCompile Go binary:\n\n```bash\nGOOS=linux GOARCH=amd64 go build hello.go\n```\n\nNode Lambda function code for a `handler.js` file:\n\n```js\nvar child_process = require('child_process');\n\nexports.handler = function(event, context) {\n  var proc = spawn('./hello', [ JSON.stringify(event) ], { stdio: 'inherit' });\n\n  proc.on('close', function(code){\n    if(code !== 0) {\n      return context.done(new Error(\"Process exited with non-zero status code\"));\n    }\n\n    context.done(null);\n  });\n}\n```\n\nZip it all up:\n\n```bash\nzip -r lambda.zip hello handler.js\n```\n","tags":""},{"id":"45732badab5a807e1d133dc9ceed315b","title":"Sinatra errors","content":"require \"sinatra/base\"\n\nclass Foo \u003c Sinatra::Base\n  def initialize\n    configure\n    super()\n  end\n\n  get \"/\" do\n    \"hello\"\n  end\n\n  get \"/err\" do\n    404 # shows no content (but go to /foo and you'll see Sinatra 404)\n  end\n\n  get \"/fail\" do\n    fail \"wat?\" # this is rescued by main sinatra error method\n  end\n\n  error do\n    # method typically used to show some kind of response to user\n    # but not in our example here... instead we see what happens if this error method itself fails\n    call_method_that_fails # depending on configure method being run: it should either show a safe Internal Server Error or revealing stack trace\n  end\n\n  private\n\n  def configure\n    self.class.tap do |s|\n      s.configure { s.disable :show_exceptions, :raise_errors }\n    end\n  end\n\n  def call_method_that_fails\n    fail \"wat!?\" # shows different error page but still has backtrace?\n  end\nend\n","tags":""},{"id":"bc08de0c739dbc1f5b68","title":"Bash ask user a question","content":"#!/bin/bash\n#\n# Installs the dotfiles into the user's home directory.\n#\n# NOTE: the bash dotfiles assume a layout of ~/dotfiles\n\nset -e\n\n# Directory in which this script is located.\nDIR=\"$( cd \"$( dirname \"${BASH_SOURCE[0]}\" )\" \u0026\u0026 pwd )\"\n\nfor file in *; do\n  if [ $file = \"README.md\" ]; then\n    continue\n  fi\n\n  sourcefile=\"${DIR}/${file}\"\n  dotfile=\"$HOME/.${file}\"\n\n  if [ -e \"${dotfile}\" ]; then\n    if [ $replace_all ]; then\n      ln -fs \"${sourcefile}\" \"${dotfile}\"\n    else\n      echo -n \"replace ${dotfile}? [ynaq] \"\n      read keypress\n      case \"$keypress\" in\n        \"y\" ) ln -nfs \"${sourcefile}\" \"${dotfile}\" ;;\n        \"n\" ) continue ;;\n        \"a\" )\n          replace_all=\"yes\"\n          ln -nfs \"${file}\" \"${dotfile}\"\n        ;;\n        \"q\" ) exit 0 ;;\n      esac\n    fi\n  else\n    ln -s \"${sourcefile}\" \"${dotfile}\"\n  fi\ndone\n\necho \"Installed dotfiles in $HOME\"\n","tags":""},{"id":"e26339e4d4469471a256317a9bacb8bb","title":"gRPC: a REAL beginners guide","content":"## Compiler\n\nThe `protoc` compiler is written in C++ and needs to be built from source:\n\n\u003e Note: [here](https://github.com/google/protobuf/tree/master/src) details shell dependencies required\n\n- `git clone git@github.com:google/protobuf.git`\n- `./autogen.sh`\n- `./configure`\n- `make # this can take quite a while ~10 mins for me`\n- `make check # this can take quite a while ~10 mins for me`\n- `sudo make install`\n\n## Go Example\n\n- `go get -a github.com/golang/protobuf/protoc-gen-go` (Go plugin for protoc compiler)\n- `git clone https://github.com/grpc/grpc.git`\n- `cd grpc/examples`\n- `mkdir testing-helloworld`\n- `protoc -I ./protos ./protos/helloworld.proto --go_out=plugins=grpc:testing-helloworld`\n\nThis generates:\n\n```\ntesting-helloworld/\n└── helloworld.pb.go\n\n0 directories, 1 file\n```\n\n- `go get -u google.golang.org/grpc/examples/helloworld/greeter_client`\n- `go get -u google.golang.org/grpc/examples/helloworld/greeter_server`\n- `cd $GOPATH/src/google.golang.org/grpc/examples/helloworld`\n- `cd greeter_server \u0026 go run main.go`\n- `cd greeter_client \u0026 go run main.go`\n\n\u003e Note: the client/server you downloaded reference their own pb.go  \n\u003e /src/google.golang.org/grpc/examples/helloworld/helloworld/helloworld.pb.go  \n\u003e If you want, you can create your own client/server code to be sure...  \n\n- `cd grpc/examples` (wherever you originally git cloned the grpc repo)\n- `cp greeter_server.go ./testing-server.go`\n\nReplace the line:\n\n```go\npb \"google.golang.org/grpc/examples/helloworld/helloworld\"\n```\n\nWith:\n\n```go\npb \"github.com/wherever/you/cloned/grpc/examples/testing-helloworld\"\n```\n\nNow you should be able to run:\n\n```go\ngo run testing-server.go\n```\n\nAnd verify using either the existing Go client you downloaded (see above) or an existing Ruby client (see below).\n\n## Ruby Example\n\n- `git clone https://github.com/grpc/grpc.git`\n- `cd grpc/examples/ruby`\n- `bundle install` (includes install of Ruby plugin for protoc)\n- `bundle exec ./greeter_server.rb`\n- `bundle exec ./greeter_client.rb`\n\n## Mixing Server and Client\n\nYou can mix and match servers and clients.\n\ne.g. have a Go server running with a Ruby client connecting, and vice versa\n\n## Custom Services\n\nYou'll find that if you want to write your own proto files and compile them, having the `protoc` compiler itself is not enough. You also need to build grpc (https://github.com/grpc/grpc/blob/master/INSTALL.md) from source too :-/\n\n- `git clone https://github.com/grpc/grpc.git`\n- `cd grpc`\n- `git submodule update --init`\n- `make`\n- `make install`\n","tags":""},{"id":"71e45214734c76652f02","title":"Bash update current line when `echo`ing updating output","content":"Update current line when `echo`ing updating output:\n\n```bash\necho -ne \"Movie $movies - $dir ADDED! \\033[0K\\r\"\n```\n\nHere is a small example that you can run to understand its behaviour:\n\n```bash\n#!/bin/bash\nfor pc in $(seq 1 100); do\n    echo -ne \"$pc%\\033[0K\\r\"\n    sleep 1\ndone\necho\n```\n","tags":""},{"id":"a777d580dbf1c21e6dc27e7668c6f677","title":"Test Rubocop against inline code","content":"Example valid script to test Rubocop against:\n\n```rb\ncat \u003e test.rb \u003c\u003cEOF\n require \"json\"\n p JSON.generate(:foo =\u003e :bar)\nEOF\n```\n\nThen temporarily update the docker run command's volume setting:\n\n```\n--volume $(pwd)/test.rb:/app/test.rb\n```\n","tags":""},{"id":"b9e11ac5819137ff7a86","title":"Apple Curl Issues","content":"brew rm curl # only if you have an earlier verion installed\n\n# work around Apple using their own system's Secure Transport library instead of OpenSSL\nbrew install curl --with-openssl\n\n# use the new brew install of curl\nbrew link curl --force\n","tags":""},{"id":"c167accb81374c134331","title":"WebSockets with Vanilla JS and Ruby Faye","content":"\u003chtml\u003e\n  \u003cbody\u003e\n    \u003cdiv id=\"countdown\"\u003e\u003c/div\u003e\n\n    \u003cbutton id=\"yes\"\u003eYES\u003c/button\u003e\n    \u003cbutton id=\"no\"\u003eNO\u003c/button\u003e\n\n    \u003cscript src=\"ws.js\"\u003e\u003c/script\u003e\n    \u003cscript src=\"countdown.js\"\u003e\u003c/script\u003e\n  \u003c/body\u003e\n\u003c/html\u003e\nfunction log(msg){\n  console.log(\"socket state: %s (%s)\", socket.readyState, msg)\n}\n\nfunction connect(host){\n  return new WebSocket(host)\n}\n\nfunction send(msg) {\n  socket.send(msg)\n}\n\nsocket = connect(\"ws://localhost:9292\")\n\nsocket.onopen = function(){\n  log(\"open\")\n}\n\nsocket.onclose = function(){\n  log(\"close\")\n}\n\nsocket.onmessage = function(msg){\n  json = JSON.parse(msg.data)\n\n  if (\"topic_timeframe\" in json) {\n    window.topicTimeframe = json.topic_timeframe\n  }\n\n  log(msg)\n}\n\nyes = document.getElementById(\"yes\")\nno  = document.getElementById(\"no\")\n\nyes.onclick = function(){\n  send(this.innerHTML)\n}\n\nno.onclick = function(){\n  send(this.innerHTML)\n}\nrequire \"faye/websocket\"\nrequire \"json\"\n\nFaye::WebSocket.load_adapter(\"thin\")\n\n# rackup config.ru -s thin -E production -p 9292\n\nrun -\u003e env do\n  if Faye::WebSocket.websocket?(env)\n    ws = Faye::WebSocket.new(env)\n\n    ws.send(JSON.generate :topic_timeframe =\u003e 15)\n\n    ws.on :message do |event|\n      p \"Message received: #{event.data}\"\n      ws.send(JSON.generate :message_received =\u003e event.data)\n    end\n\n    ws.on :close do |event|\n      p [:close, event.code, event.reason]\n      ws = nil\n    end\n\n    ws.rack_response\n  else\n    [200, {\"Content-Type\" =\u003e \"text/plain\"}, [\"Hello\"]]\n  end\nend\nfunction countdown(timeframe, container){\n  /*\n   * If timeframe is 15 (minutes)\n   * Then that's 900 seconds\n   * If time passed is 1:30\n   * Then that's 90 seconds\n   * 90%900 = 90\n   * 900-90 = 810\n   * 810 seconds is the time left\n   * That's 13 mins 50 seconds\n  */\n\n  minute               = 60\n  date                 = new Date()\n  time                 = date.getMinutes() * minute + date.getSeconds()\n  timeframe_in_seconds = minute * timeframe\n  timeleft             = timeframe_in_seconds - time % timeframe_in_seconds\n  result               = window.parseInt(timeleft / minute) + \":\" + timeleft % minute\n\n  container.innerHTML = result\n}\n\ncontainer = document.getElementById(\"countdown\")\n\nfunction checkTimeoutValue(){\n  window.setTimeout(function(){\n    if (isNaN(window.topicTimeframe)) {\n      checkTimeoutValue()\n    } else {\n      window.setInterval(countdown, 500, window.topicTimeframe, container)\n    }\n  }, 100)\n}\n\ncheckTimeoutValue()\n","tags":""},{"id":"e76b869dd1bc922b658e","title":"Ruby Sinatra Sessions","content":"require \"sinatra\"\n\nenable :sessions\nset :session_secret, \"*\u0026(^B234\"\n\nget \"/\" do\n  id = get_session :foo\n  \"session id: #{id}\\n\"\nend\n\ndef get_session(id)\n  return session[id] unless session[id].nil?\n  session[id] = SecureRandom.uuid\nend\n","tags":""},{"id":"ae6ec15da52edf9efb50","title":"SCP Remote Logs to Local Machine","content":"#!/bin/bash\n#\n# Dependencies:\n# brew install jq\n#\n# Example:\n# /bin/bash ./results.sh \u003ccert_path\u003e \u003ccomponent_name\u003e \u003ccosmos_user\u003e\n#\n# Description:\n# Grabs list of running instances for specified Cosmos component (TEST environment)\n# SCP's known log locations from remote to new local directory\n\n# Enable a form of 'strict mode' for Bash\nset -euo pipefail\nIFS=$'\\n\\t'\n\n# Define our expected variables up front\ncert=${1:-}\ncomponent=${2:-}\nuser=${3:-}\napi=\"https://api.live.bbc.co.uk/cosmos/env/test/component/$component\"\n\nif [ \"$#\" -ne 3 ]; then\n  cat \u003c\u003cEOF\n\nPlease check the arguments are provided correctly:\n  1. cert path (pem)\n  2. component name\n  3. cosmos user\n\nIf you have any curl/cert issues try:\n  brew install curl --with-openssl\n\nIf you have any parsing issues try:\n  brew install jq\nEOF\n\n  exit 1\nfi\n\nlogdir=$(mktemp -d \"$component.logs.XXXX\")\n\ndata=($(curl --silent --cert $cert \"$api/instances\" | jq --raw-output \".[] | .id,.private_ip_address,.launch_time\"))\ndata_len=$((${#data[@]} / 3)) # we know we'll always have a triad of data -\u003e \u003cid\u003e,\u003cip\u003e,\u003claunch_time\u003e\n\nfor ((n = 0; n \u003c $data_len; n++))\ndo\n  ssh_success=false\n  valid=\"current\"\n\n  # parse array indexes needed to extract data\n  id=$(($n * 3))\n  ip=$(($id + 1))\n  ti=$(($id + 2))\n\n  instance_id=${data[$id]}\n  instance_ip=${data[$ip]}\n  launch_time=${data[$ti]}\n\n  printf \"\\n######################################\\n\"\n  printf \"\\nrequesting ssh access for: $instance_id\\n\"\n\n  # use cosmos api to generate ssh access token\n  response=$(curl --silent \\\n                  --cert $cert \\\n                  --header \"Content-Type: application/json\" \\\n                  --request POST \\\n                  --data \"{\\\"instance_id\\\":\\\"$instance_id\\\"}\" \\\n                  \"$api/logins/create\")\n\n  # parse token from api response\n  checkpoint_id=$(echo $response | jq --raw-output .url | cut -d '/' -f 7)\n\n  until $ssh_success\n  do\n    status=$(curl --silent --cert $cert \"$api/login/$checkpoint_id\" | jq --raw-output .status)\n\n    if [ \"$status\" = \"$valid\" ]; then\n      ssh_success=true\n      printf \"\\n\"\n      echo \"ssh access granted for instance $(($n + 1)): $instance_id ($instance_ip)\"\n      printf \"\\n\"\n    else\n      echo -ne \"status == $status               \"\\\\r\n    fi\n  done\n\n  scp -r \"$user@$instance_ip,eu-west-1:/var/log/component/app.log\" \"./$logdir/$launch_time-$instance_ip.log\"\ndone\n\n# removed 'wait' command here and '\u0026' backgrounding of scp process\n# as stdout feedback was getting interleaved and really confusing\n\nprintf \"\\n######################################\\n\\n\"\necho \"all logs copied successfully\"\n","tags":""},{"id":"5658cb218bb50494a1fa","title":"Ruby stdlib debugger","content":"Program `app.rb`:\n\n```rb\ndef foo(msg)\n  result = bar\n  msg\nend\n\ndef bar\n  thing = 123\n  thing\nend\n\nrequire \"debug\" # this is what drops us into the debugger\np foo(:hai)\n```\n\nRun the program as normal:\n\n```bash\nruby app.rb\n```\n\nWe find ourselves not necessarily where we'd expect:\n\n```\nDebug.rb\nEmacs support available.\n\n/Users/M/.rbenv/versions/2.1.2/lib/ruby/2.1.0/rubygems/core_ext/kernel_require.rb:57:        RUBYGEMS_ACTIVATION_MONITOR.enter\n(rdb:1) \n```\n\nSo first thing to do is to check for any breakpoints:\n\n```\nb\n=\u003e No breakpoints\n```\n\nLet's set a breakpoint for our `foo` method (e.g. whenever it's called we'll stop there):\n\n```\nb app.rb:foo\n=\u003e Set breakpoint 1 at app.rb:foo\n```\n\nLet's check the breakpoint was set:\n\n```\nb\n=\u003e Breakpoints:\n     1 app.rb:foo\n```\n\nLet's also set a breakpoint within the `foo` method at line `3` (just after we call the `bar` method and assign its result to `result`):\n\n```\nb app.rb:3\n=\u003e Set breakpoint 2 at app.rb:3\n```\n\nAgain, let's check the breakpoint was set:\n\n```\nb\n=\u003e Breakpoints:\n     1 app.rb:foo\n     2 app.rb:3\n```\n\nLet's remind ourselves where we are before continuing on:\n\n```\nw\n=\u003e #1 /Users/M/.rbenv/versions/2.1.2/lib/ruby/2.1.0/rubygems/core_ext/kernel_require.rb:57:in `require'\n```\n\nIf we forget any debugging commands we can look at the help:\n\n```\nh\n=\u003e Debugger help v.-0.002b\nCommands\n  b[reak] [file:|class:]\u003cline|method\u003e\n  b[reak] [class.]\u003cline|method\u003e\n                             set breakpoint to some position\n  wat[ch] \u003cexpression\u003e       set watchpoint to some expression\n  cat[ch] (\u003cexception\u003e|off)  set catchpoint to an exception\n  b[reak]                    list breakpoints\n  cat[ch]                    show catchpoint\n  del[ete][ nnn]             delete some or all breakpoints\n  disp[lay] \u003cexpression\u003e     add expression into display expression list\n  undisp[lay][ nnn]          delete one particular or all display expressions\n  c[ont]                     run until program ends or hit breakpoint\n  s[tep][ nnn]               step (into methods) one line or till line nnn\n  n[ext][ nnn]               go over one line or till line nnn\n  w[here]                    display frames\n  f[rame]                    alias for where\n  l[ist][ (-|nn-mm)]         list program, - lists backwards\n                             nn-mm lists given lines\n  up[ nn]                    move to higher frame\n  down[ nn]                  move to lower frame\n  fin[ish]                   return to outer frame\n  tr[ace] (on|off)           set trace mode of current thread\n  tr[ace] (on|off) all       set trace mode of all threads\n  q[uit]                     exit from debugger\n  v[ar] g[lobal]             show global variables\n  v[ar] l[ocal]              show local variables\n  v[ar] i[nstance] \u003cobject\u003e  show instance variables of object\n  v[ar] c[onst] \u003cobject\u003e     show constants of object\n  m[ethod] i[nstance] \u003cobj\u003e  show methods of object\n  m[ethod] \u003cclass|module\u003e    show instance methods of class or module\n  th[read] l[ist]            list all threads\n  th[read] c[ur[rent]]       show current thread\n  th[read] [sw[itch]] \u003cnnn\u003e  switch thread context to nnn\n  th[read] stop \u003cnnn\u003e        stop thread nnn\n  th[read] resume \u003cnnn\u003e      resume thread nnn\n  pp expression              evaluate expression and pretty_print its value\n  p expression               evaluate expression and print its value\n  r[estart]                  restart program\n  h[elp]                     print this help\n  \u003ceverything else\u003e          evaluate\n```\n\nLet's just 'continue' to our first breakpoint (which _should_ be the `foo` method being called):\n\n```\nc\n=\u003e Breakpoint 1, foo at app.rb:foo\n   app.rb:1:def foo(msg)\n```\n\nTo be sure where we are let's use `l` again:\n\n```\nl\n[-4, 5] in app.rb\n=\u003e 1  def foo(msg)\n   2    result = bar\n   3    msg\n   4  end\n   5  \n```\n\nIf at this point I enter the expression `msg` (which is the argument incoming into the `foo` method), then I'll get its value:\n\n```\nmsg\n=\u003e :hai\n```\n\nIf I press `c` to continue again we'll reach our next breakpoint:\n\n```\nc\n=\u003e Breakpoint 2, foo at app.rb:3\n   app.rb:3:  msg\n```\n\nIf at this point I enter the expression `result` (which is the variable set within the `foo` method), then I'll get its value that was provided by the `bar` method:\n\n```\nresult\n=\u003e 123\n```\n\nI can check for any local variables scoped/available to me at this point of the program:\n\n```\nv l\n  msg =\u003e :hai\n  result =\u003e 123\n```\n\nBefore we wrap up, let me restart the program so we can go through the process again but take a slightly different route:\n\n```\nr\n=\u003e app.rb:57:\n```\n\n\u003e Note: the line number `57` doesn't actually make any sense to me to be honest\n\nFrom here we can 'continue' `c` to get to our first breakpoint (like we did before), but this time instead of skipping over the call to `bar`, we'll use `s` to 'step' into the method and then `n` to go through the next subsequent lines until our program completes):\n\n```\n(rdb:1) s\napp.rb:2:  result = bar\n(rdb:1) l\n[-3, 6] in app.rb\n   1  def foo(msg)\n=\u003e 2    result = bar\n   3    msg\n   4  end\n   5  \n   6  def bar\n(rdb:1) s\napp.rb:7:  thing = 123\n(rdb:1) l\n[2, 11] in app.rb\n   2    result = bar\n   3    msg\n   4  end\n   5  \n   6  def bar\n=\u003e 7    thing = 123\n   8    thing\n   9  end\n   10  \n   11  require \"debug\"\n(rdb:1) v l\n  thing =\u003e nil\n(rdb:1) n\napp.rb:8:  thing\n(rdb:1) v l\n  thing =\u003e 123\n(rdb:1) n\napp.rb:3:  msg\n(rdb:1) l\n[-2, 7] in app.rb\n   1  def foo(msg)\n   2    result = bar\n=\u003e 3    msg\n   4  end\n   5  \n   6  def bar\n   7    thing = 123\n(rdb:1) result\n123\n(rdb:1) v l\n  msg =\u003e :hai\n  result =\u003e 123\n(rdb:1) n\n:hai\n```\n","tags":""},{"id":"0fc25edb5d9ceeae74cc","title":"Bash Strict Mode (http://redsymbol.net/articles/unofficial-bash-strict-mode/)","content":"#!/bin/bash\nset -euo pipefail\nIFS=$'\\n\\t'\n\n# -e: immediately exit if any command has a non-zero exit status\n# -u: reference to any variable you haven't previously defined is an error\n# -o: prevents errors in a pipeline from being masked\n# IFS new value is less likely to cause confusing bugs when looping arrays or arguments (e.g. $@)\n\n# Example: positional parameters\n# Solution: use 'default value' setup (set default value to an empty string)\n\nname=${1:-}\nif [[ -z \"$name\" ]]; then\n    echo \"usage: $0 NAME\"\n    exit 1\nfi\necho \"Hello, $name\"\n\n# Example: pipeline masking issues\n# Solution: short-circuit with boolean operator\n\ncount=$(grep -c some-string some-file || true)\necho \"count: $count\"\n\n# Solution: disable -e temporarily (in order to get return value)\n\nset +e\ncount=$(grep -c some-string some-file)\nretval=$?\nset -e\n\n# grep's return code is 0 when one or more lines match;\n# 1 if no lines match; and 2 on an error. This pattern\n# lets us distinguish between them.\n\necho \"return value: $retval\"\necho \"count: $count\"\n\n# Example: chaining doesn't stop execution if there's an error\n# Solution: use a block {} to wrap code you want to stop execution if it fails\n\n# first_task \u0026\u0026 second_task \u0026\u0026 third_task\n# next_task\n# ...if second_task fails then third_task doesn't run\n# ...but next_task would\n# ...instead use the following...\n\nfirst_task \u0026\u0026 {\n    second_task\n    third_task\n}\nnext_task\n\n# Example: Avoid inline if statements (always use long form if/then)\n# Notes: inline if statements are issues when they're the last line of the script\n","tags":""},{"id":"72d1f0ab5155c1a27d3f","title":"Ruby Mock Redis","content":"# in your spec helper...\n\nrequire \"pry\"\nrequire \"redis\"\nrequire \"mock_redis\"\n\nRSpec.configure do |config|\n  config.before(:each) do\n    mock_redis = MockRedis.new\n    allow(Redis).to receive(:new).and_return(mock_redis)\n  end\nend\n\n# Also you can do...\n\nrequire 'mock_redis'\n\u003e\u003e mr = MockRedis.new\n\u003e\u003e mr.set('some key', 'some value')\n=\u003e \"OK\"\n\u003e\u003e mr.get('some key')\n=\u003e \"some value\"\n","tags":""},{"id":"45e295b305511005d22e","title":"[Bash Watchtower] ","content":"function cleanup() {\n  local file=$1\n  if [ -f $file ]; then\n    rm $file\n  fi\n}\n\nfunction pull() {\n  local base=$1\n  local urls=(\"${!2}\")\n\n  for resource in \"${urls[@]}\"\n  do\n    curl $base$resource --head \\\n                        --location \\\n                        --silent \\\n                        --output /dev/null \\\n                        --connect-timeout 2 \\\n                        --write-out \"%{url_effective} %{http_code}\\n\" \u0026\n  done\n\n  wait\n}\n\nfunction parse() {\n  local results=$1\n  local remote=https://hooks.slack.com/services/foo/bar/baz\n\n  cat $results | awk '!/200/ { print $2 \": \" $1 }' \u003e temp.txt\n\n  while read line; do\n    curl --header \"Content-Type: application/json\" \\\n         --silent \\\n         --output /dev/null \\\n         --request POST \\\n         --data \"{\\\"text\\\": \\\"$line\\\"}\" $remote \u0026\n  done \u003c temp.txt\n\n  wait\n\n  display temp.txt\n  cleanup temp.txt\n}\n\nfunction display() {\n  printf \"\\n\\n\"\n  cat $1\n  printf \"\\n\\n\"\n}\n\nendpoints=(\n  /newsbeat\n  /newsbeat/popular\n  /newsbeat/topics\n  /newsbeat/topics/entertainment\n  /newsbeat/topics/surgery\n  /newsbeat/article/32792353/im-engaged-but-will-i-ever-be-able-to-marry-my-boyfriend\n)\n\ncleanup results.txt\n\npull http://bbc.co.uk endpoints[@] \u003e\u003e results.txt\npull http://composition.newsbeat.news.cloud.bbc.co.uk endpoints[@] \u003e\u003e results.txt\n\ndisplay results.txt\nparse results.txt\nDepending on if there are failures, Slack should get a notification like:\n\n```\n500: http://www.bbc.co.uk/newsbeat/popular\n500: http://www.bbc.co.uk/newsbeat/topics\n```\n","tags":"#bash #shell #watchtower"},{"id":"05bbbfd6130d16730fcc","title":"Nice Ruby Rack Tests","content":"require 'spec_helper'\nrequire 'rack/test'\n\nmodule Condfig\n  describe Api do\n    include Rack::Test::Methods\n\n    def app\n      Rack::Builder.parse_file('config.ru').first\n    end\n\n    let(:json_data) { { id: 'foo' }.to_json }\n    let(:db_data)   { { id: 'foo' }.to_json.to_s }\n\n    before do\n      allow(ConfigRepository).to receive(:all).and_return(['foo'])\n      allow(ConfigRepository).to receive(:search).and_return(nil)\n      allow(ConfigRepository).to receive(:search).with('foo').and_return(db_data)\n      allow(ConfigRepository).to receive(:store).with('bar', { id: 'bar' }.to_json).and_return(db_data)\n      allow(ConfigRepository).to receive(:remove)\n    end\n\n    describe 'GET /pages' do\n      it 'returns a list of all the available resources' do\n        expected = { foo: { href: 'http://example.org/pages/foo'} }.to_json\n        get '/pages'\n        expect(last_response.body).to eq expected\n      end\n\n      it 'returns an ETag in the header' do\n        get '/pages'\n        expect(last_response.headers['ETag']).to_not be_nil\n      end\n    end\n\n    describe 'GET /pages/:id' do\n      context 'success' do\n        it 'returns a 200 status' do\n          get '/pages/foo'\n          expect(last_response.status).to eq(200)\n        end\n\n        it 'returns an ETag in the header' do\n          get '/pages/foo'\n          expect(last_response.headers['ETag']).to_not be_nil\n        end\n\n        it 'returns a json representation of the page configuration' do\n          get '/pages/foo'\n          expect(last_response.body).to eq(json_data)\n        end\n      end\n\n      context 'failure' do\n        before do\n          expect(ConfigRepository).to receive(:search).and_return(nil)\n        end\n\n        it 'returns a 404 status' do\n          get '/pages/foo'\n          expect(last_response.status).to eq(404)\n        end\n      end\n    end\n\n    describe 'POST /pages' do\n      context 'success' do\n        it 'returns a 201 status' do\n          post '/pages', { 'id' =\u003e 'bar' }.to_json.to_s\n          expect(last_response.status).to eq(201)\n        end\n\n        it 'returns the newly created url in the header location' do\n          post '/pages', { 'id' =\u003e 'bar' }.to_json.to_s\n          expect(last_response.headers['location']).to eq('http://example.org/pages/bar')\n        end\n      end\n\n      context 'failure' do\n        it 'return a 409 if attempting to recreate an existing resource' do\n          post '/pages', { 'id' =\u003e 'foo' }.to_json.to_s\n          expect(last_response.status).to eq(409)\n        end\n\n        it 'return a 400 if data is missing' do\n          post '/pages'\n          expect(last_response.status).to eq(400)\n        end\n\n        it 'return a 400 if data is invalid' do\n          post '/pages', { value: 'missing id..' }.to_json.to_s\n          expect(last_response.status).to eq(400)\n        end\n      end\n    end\n\n    describe 'PUT /pages/foo' do\n      context 'success' do\n        let(:json_data) { { id: 'foo', value: 123 }.to_json }\n\n        before do\n          allow(ConfigRepository).to receive(:store).with('foo', json_data).and_return(db_data)\n        end\n\n        it 'returns a 200 status' do\n          put '/pages/foo', json_data.to_s\n          expect(last_response.status).to eq(200)\n        end\n\n        it 'returns a json representation of the page configuration' do\n          put '/pages/foo', json_data.to_s\n          expect(last_response.body).to eq(json_data)\n        end\n      end\n\n      context 'failure' do\n        it 'return a 400 if data is missing' do\n          put '/pages/foo'\n          expect(last_response.status).to eq(400)\n        end\n\n        it 'return a 400 if data is invalid' do\n          put '/pages/foo', { value: 'missing id..' }.to_json.to_s\n          expect(last_response.status).to eq(400)\n        end\n      end\n    end\n\n    describe 'DELETE /pages/foo' do\n      context 'success' do\n        it 'returns a 204 status' do\n          delete '/pages/foo'\n          expect(last_response.status).to eq(204)\n        end\n      end\n\n      context 'failure' do\n        it 'returns 404 if attempting to delete an nonexistent resource' do\n          delete '/pages/random'\n          expect(last_response.status).to eq(404)\n        end\n      end\n    end\n  end\nend\n","tags":""},{"id":"e6fa5e03254a9309fe27","title":"Ruby Load Path","content":"$: \u003c\u003c File.join(File.dirname(__FILE__), \"lib\")\n","tags":""},{"id":"22520358fced54b3fed5","title":"Microservices","content":"In Summary:\n\n\t⁃\tMicroservices are small autonomous services\n\t⁃\tMicroservices are modeled around business concepts\n\t⁃\tMicroservices encourage a culture of automation\n\t⁃\tMicroservices should be highly observable\n\t⁃\tMicroservices should hide implementation details\n\t⁃\tMicroservices should isolate failure\n\t⁃\tMicroservices should be deployed independently\n\t⁃\tMicroservices should decentralise all the things\n\nThe long list...\n\n\t⁃\tCohesion: group related code together\n\t⁃\tGather together things that change for the same reason\n\t⁃\tSeparate those things that change for different reasons\n\t⁃\tIf behaviour is spread across services, then change in behaviour requires deploying updates to multiple services\n\t⁃\tFocus service boundaries where we can ensure related behaviour is located in one place\n\t⁃\tMicroservices make it obvious where code lives for a given behaviour\n\t⁃\tThus avoiding the problem of a service growing too large\n\t⁃\tAvoid structuring services around technical concepts, aim for business bounded contexts\n\t⁃\tRouting is a business requirement (I want to direct users to somewhere)\n\t⁃\tPage Composition is a business requirement (I want to put a page together for the user)\n\t⁃\tSource of data is a business requirement (I want a place where I can manage by config/templates)\n\t⁃\tEach microservice should be hosted on its own machine (don't pack services together in order to save cost)\n\t⁃\tMultiple micro services on one host means a failure of one impacts the other\n\t⁃\tThis also means you're now unable to scale appropriately for the demands of any one microservice\n\t⁃\tEnsure services are evenly distributed across different regions and availability zones to improve resiliency\n\t⁃\tUtilise Load Balancers to help balance the incoming traffic (as well as SSL termination; as long as services are within a VPC)\n\t⁃\tServices need to change independently of each other\n\t⁃\tServices need to be loosely coupled (e.g. changed \u0026 deployed by themselves without requiring consumers to change)\n\t⁃\tServices should have a clear contract/interface\n\t⁃\tServices should try to be stateless and immutable (idempotent) as this requires much less complexity and facilitates easier scalability\n\t⁃\tOtherwise consuming services can become coupled to an internal representation\n\t⁃\tChoose technology agnostic APIs (e.g. REST over HTTP)\n\t⁃\tThis means avoiding integration technology that dictates what technology stacks we can use to implement our microservice\n\t⁃\tMicroservices allow choosing the right tool for the job\n\t⁃\tMicroservices facilitate SPOF handling (offer a gracefully degraded service when part of the system fails)\n\t⁃\tMicroservices allow us to align architecture with the organisation (focus on team ownership)\n\t⁃\tMicroservices facilitates easy rewriting of services due to small size and well defined boundaries\n\t⁃\tAvoid shared libraries as they can restrict your ability to deploy easily/quickly\n\t⁃\tDon't let shared code leak outside your service boundary (otherwise this introduces a form of coupling)\n\t⁃\tYou also lose technology heterogeneity with libraries (consumer needs to be the same language; e.g. Alephant)\n\t⁃\tDefine good 'principles', followed by good 'practices' that support/guide those principles\n\t⁃\tDifferent teams with different technical 'practices' can then share a common 'principle'\n\t⁃\tIt is essential that we can see a coherent, cross-service view of our system's health\n\t⁃\tThis has to be system-wide, not service-specific\n\t⁃\tInspecting service-specific health is useful only when diagnosing a wider problem\n\t⁃\tAll services should have consistent mechanism for emitting health indicators/metrics as well as logging\n\t⁃\tDown/Upstream services should shield themselves accordingly from other unhealthy services\n\t⁃\tProvide templates (generators; e.g. CloudKit) that allow developers to follow best practices/architectural guidelines easily\n\t⁃\tThe team who creates the templates shouldn't be gatekeepers, they should be open to accepting suggestions/changes\n\t⁃\tAvoid a centralised framework that does too much and affects developer productivity (rather than improve it)\n\t⁃\tMicroservices allow greater ownership from multiple sources\n\t⁃\tBoundaries in code (e.g. think object-orientation) can result in becoming candidates for their own microservices\n\t⁃\tServices can be nested (in an abstraction sense) behind an encompassing service, but can depend on organisational structure\n\t⁃\tGood integration means simplicity. RPC may be good for performance but tightly couples our services with too much context\n\t⁃\tRPC exposes too much internal representation detail and should be avoided unless performance is absolutely critical\n\t⁃\tAlways have interfaces/APIs in front of a data store (e.g. change from relational to nosql should not affect consumers)\n\t⁃\tAsynchronous communication is harder to co-ordinate but offers greater loose coupling (apposed to sync request/response)\n\t⁃\tRPC sometimes causes problems when devs aren't aware calls are 'remote' as appose to 'local' (affecting overall performance)\n\t⁃\tRPC typically isn't versioned and so you could implement a breaking change that requires 'lock-step releases' (i.e. coupling)\n\t⁃\tCollection and central aggregation of as much 'data' (e.g. logs/metrics) as we can get\n\t⁃\tWe do this with logs going into Sumo Logic (I wish for something better than Sumo though)\n\t⁃\tWe also do this with metrics going into CloudWatch and then out into Grafana (we can do better though)\n\t⁃\tAim for consistency in the format for Metrics and Logs to enable the ability to easily filter them via a aggregation service\n\t⁃\tThis is made easier via standardised tools (shared custom logging abstractions; e.g. Alephant Logger)\n\t⁃\tBeing able to generate services with tools pre-baked in is useful, but you have to be careful about centralised authority stagnating progress\n\t⁃\tBut we're still not doing this properly as far as tracing a call appropriately\n\t⁃\tSynthetic Monitoring (e.g. a synthetic transaction): a way to automate a fake request and store outcomes into a test bucket for analysis\n\t⁃\tSynthetic Monitoring can help identify when a service is unable to communicate with/to another service (but is otherwise healthy)\n\t⁃\tMake sure that synthetic testing system doesn't accidentally trigger unwanted 'side-effects' (less of an issue for us just displaying text content)\n\t⁃\tCorrelation IDs: a poor man's \"distributed tracing\" (generate a unique guid and pass it along to all log calls)\n\t⁃\tMight be a clever way to expose a session guid to the logger (suggestion has been via HTTP headers)? \n\t⁃\tRemember that the service needs to pass the header over to the next service as well (this is where a form of consistency - contract - is required)\n\t⁃\tThis maybe a poor man's tracing but it would be supremely useful in tracking a single request from start to finish\n\t⁃\tEspecially considering that most people find Zipkin to be a bit heavyweight \n\t⁃\tCircuit Breakers help handling cascading service failures in a more elegant fashion\n\t⁃\tAggregated network health status visibility system (e.g. my Heka hackday from 2015 or 2014) are recommended\n\t⁃\tAuthentication inside a VPC perimeter can be made more efficient by terminating from the front door and using internal load balancers\n\t⁃\tDownside is if an attacker breaches your internal network then you stand no chance of preventing them reading your network traffic without HTTPS\n\t⁃\tBut I'd argue if your VPC is compromised, you have much bigger issues\n\t⁃\tImplement network segregation (e.g. we do this already via VPC's, but have them on a more granular level; Morph \u0026 Mozart should be/are)\n\t⁃\tWhether the segregation is based on 'team ownership' or 'risk level' is up to your organisation to decide what's more appropriate\n\t⁃\tTightly coupled organisations generally appear to produce tightly coupled software architecture by their natural influence\n\t⁃\tSimilarly, loosely coupled organisations generally appear to produce very modular and loosely coupled software architecture\n\t⁃\tHaving multiple teams trying to manage a code base makes it difficult to communicate, coordinate and to reason about the service\n\t⁃\tDistributed teams need to identify portions of a service that they can take ownership of and introduce clear service boundaries\n\t⁃\tThe tendency for a single team that owns many services to lean towards tight coupling is more and more likely to occur\n\t⁃\tTeam ownership of a service means they can do what they like as long as they don't break contracts/interfaces their consumers rely upon\n\t⁃\tUnless indicated via a versioning system\n\t⁃\tHaving 'feature teams' also doesn't work as it means those teams cross over the responsibility boundaries\n\t⁃\tInternal 'open-source' (IOS) - let's face it: that's Alephant - can help avoid the need for 'feature teams' \n\t⁃\tIOS uses the idea of core custodians but that other teams can help towards pushing a particular service functionality forward and avoid bottlenecking\n\t⁃\tBalance the need for complete automation of scaling against the service requirements (e.g. does a basic dashboard need 100% up time or not?)\n\t⁃\tDegrade your service functionality gracefully (as best you can to suit the requirements of your users/consumers)\n\t⁃\tCascading failures are more likely to be caused by 'slow' responding services than failing ones (monitor and react accordingly)\n\t⁃\tPut timeouts on all 'out-of-process' calls to try and avoid slow services causing bottlenecks and knock-on effects\n\t⁃\tCircuit Breakers help defend your service against upstream services that are having problems\n\t⁃\tPlan for failure (e.g. Chaos Monkey).\n\t⁃\tImplement 'Bulkheads'. These are sections of your code that can be closed off to prevent sinking your entire application\n\t⁃\tBulkheads are subtly different from Circuit Breakers (the former shuts down aspects of your own service; the latter is for upstream services)\n\t⁃\tBulkheads aren't always logic based (e.g. if bad thing happens, disable feature X) they are also part of the software design process\n\t⁃\te.g. the use of different connection pools for each upstream service; if one upstream is slow then only that one part of our service shuts down\n\t⁃\tTeasing apart functionality into microservices is another form of Bulkhead (failing of one microservice shouldn't affect another)\n\t⁃\tTimeouts and Circuit Breakers free up resources when they become constrained\n\t⁃\tBulkheads ensure resources don't become constrained in the first place\n\t⁃\tAvoid designing a system where one service relies on another being up\n\t⁃\te.g. Mozart Composition tries to solve that problem by serving from a page level cache if Morph is unavailable\n\t⁃\tThis also means that much less coordination is needed between services (we become more loosely coupled)\n\t⁃\tDon't be afraid to start again and redesign (the beauty of microservices means a rebuild shouldn't be as costly as for a monolith) \n\t⁃\tIdentify your business model (reads vs writes) and aim to scale your services and resources appropriately\n\t⁃\tImplement caching at as many levels as is appropriate (HTTP, application, CDN etc)\n\t⁃\tYou can even design your system in such a way that high bursts of 'writes' are cached and then flushed at a later stage (\"write-behind cache\")\n\t⁃\tCached writes could be as simple as fire off the data to a queue to be processed asynchronously (depending on your business model)\n\t⁃\tUtilise AutoScaling and its variants (reactive, scheduled) more intelligently to suit your business needs\n\t⁃\te.g. scale down services on a scheduled basis overnight if they're only utilised heavily during office hours (lunch time peak for a news orgs)\n\t⁃\tUnderstand CAP Theorem and what sacrifices (trade-offs) you can make that will best fit your business needs\n\t⁃\tAutomate documentation wherever possible as this allows it to stay fresh (e.g. on code commit trigger documentation automation update)\n\n","tags":""},{"id":"bceec14f23672bf3174c","title":"Print the next line AFTER your pattern has matched with AWK","content":"awk '/\u003cpattern\u003e/{getline; print}' \u003cfilepath\u003e\n","tags":""},{"id":"9f37c7f929b616aa9fdd","title":"chmod and chown explained","content":"```\nr - Read\nw - Write\nx - Execute\n\nu - The owner of the file\ng - The group that the file belongs to\no - Anybody who is not one of the above\na - All users\n\n+ - Add permissions\n- - Remove permissions\n```\n\nSyntax Structure:\n\n```bash\nchmod \u003cpeople\u003e\u003c+/-\u003e\u003cpermissions\u003e\n```\n\nExamples:\n\n- `chmod o-w`: deny others from editing the file\n- `chmod u+rwx` give the owner full control\n- `chmod +rwx` give everyone full control\n- `chmod +x` allow anyone to execute the file\n\nNumericals:\n\n```bash\nchmod 755\n```\n\nEach number represents a different authorisation point...\n\n- `7`: owner\n- `5`: group\n- `5`: everyone else\n\nEach item is the total of the following numbers...\n\n- `4`: read\n- `2`: write\n- `1`: execute\n\nSo `755` means...\n\n- `7`: read, write and execute for the owner\n- `5`: read and execute for the group\n- `5`: read and execute for everyone else\nchown \u003cuser\u003e:\u003cgroup\u003e \u003cfile\u003e\n","tags":""},{"id":"cc6d9574ae6598cf78c5","title":"Ruby Google Calendar API","content":"=begin\nRuby API:\nhttp://www.rubydoc.info/github/google/google-api-ruby-client/Google\n\nGoogle API:\nhttps://developers.google.com/google-apps/calendar/v3/reference/events/insert\n=end\n\nrequire \"google/apis/calendar_v3\"\nrequire \"pry\"\n\nservice = Google::Apis::CalendarV3::CalendarService.new\nservice.client_options.application_name = \"\u003capp-name\u003e\"\nservice.key = \"\u003cserver-api-key\u003e\"\n\ncalendar_id = \"\u003csome-email@gmail.com||primary\u003e\"\n\nresponse = service.list_events(\n  calendar_id,\n  :max_results   =\u003e 30,\n  :single_events =\u003e true,\n  :order_by      =\u003e \"startTime\",\n  :time_min      =\u003e Time.now.iso8601 # e.g. 2016-02-28T18:49:21+00:00\n)\n\nputs \"Upcoming events:\"\nputs \"No upcoming events found\" if response.items.empty?\nresponse.items.each do |event|\n  start = event.start.date || event.start.date_time\n  puts \"- #{event.summary} (#{start})\"\nend\n\nevent = Google::Apis::CalendarV3::Event.new({\n  :summary     =\u003e \"Testing\",\n  :location    =\u003e \"Wherever\",\n  :start       =\u003e {\n    :date_time =\u003e DateTime.parse(\"2016-05-28T09:00:00-07:00\"),\n    :time_zone =\u003e \"America/Los_Angeles\"\n  },\n  :end         =\u003e {\n    :date_time =\u003e DateTime.parse(\"2016-05-28T17:00:00-07:00\"),\n    :time_zone =\u003e \"America/Los_Angeles\"\n  }\n})\n\nresult = service.insert_event(calendar_id, event)\nputs \"Event created: #{result.html_link}\"\n","tags":""},{"id":"00e077ff960d4e15315b","title":"Ruby Bundler Nokogiri Bug","content":"gem install bundler\nbundle config build.nokogiri --use-system-libraries\nbundle install\n","tags":""},{"id":"87852ced09d7918322c0","title":"Git Patch and Apply (see alternative patch generation and applying in reverse: https://gist.github.com/Integralist/13d9f5e8ec197e5e53c6)","content":"# presumes you're on a non-master branch with a set of changes that diff from `master`\n\n# generate single patch file from multiple commits\ngit format-patch master --stdout \u003e foobar.patch\n\n# view stats on the patch file\ngit apply --stat foobar.patch\n\n# test the patch without applying it (zero errors means the patch can be applied cleanly)\ngit apply --check foobar.patch\n\n# apply and 'signoff' the patch (this is a different approach to `git apply`)\n# \n# the new commit messages added to `master` will contain a “Signed-off-by” tag.\ngit am --signoff \u003c foobar.patch\n```bash\ngit format-patch \u003cbase_branch_name\u003e\n```\n\nTypically you'll specify `master`, as you'll be executing this command from your feature branch.\n\nIt'll generate a file for each new commit.\n\nUse the following (`--stdout`) to get all new commits into a single patch file:\n\n```bash\ngit format-patch master --stdout \u003e new-feature.patch\n```\n\nThe patch can then be applied like so:\n\n```bash\ngit checkout review-new-feature\ncat new-feature.patch | git am\n```\n\nor if you received multiple files:\n\n```bash\ncat *.patch | git am\n```\n\nNow you can check the result:\n\n```bash\ngit log --oneline\n```\n\n\u003e Note: this gist is a shortened summary of [this article](https://robots.thoughtbot.com/send-a-patch-to-someone-using-git-format-patch)\n","tags":""},{"id":"df21ee2b5597aa0437e5","title":"Ruby Threads: failing fast","content":"In our code base we spin up some Threads...\n\n```rb\nmetas.map do |meta|\n  Thread.new do\n    fetch(meta, timeout)\n  end\nend.map(\u0026:value)\n```\n\nThe `fetch` function will call some code from within another class which itself internally will throw and catch lots of exceptions. \n\nIn one instance it'll throw an exception that isn't caught by the class, and so it bubbles up to the top level of the application.\n\nThe issue is that although the exception is thrown and is *eventually* rescued by a function in the top level of the application, the current code takes far too long to get there. The reason being: our loop keeps going - regardless of the unhandled exception - until all the other threads have finished (so we **DON'T** \"fail fast\" in this scenario).\n\nThe following code replicates this behaviour and then tries to solve it...\n# SETUP...\n\nclass ::FooError \u003c StandardError\n  def initialize(msg)\n    super \"msg: #{msg}\"\n  end\nend\n\nclass ::BarError \u003c StandardError\n  def initialize(msg)\n    super \"msg: #{msg}\"\n  end\nend\n\ndef foo(i)\n  sleep i; fail ::FooError.new(\"new foo error\")\nrescue ::FooError =\u003e e\n  e\nend\n\ndef bar(i)\n  sleep i; fail ::BarError.new(\"new bar error\") \n  # to see a full length run through, change this to... \n  # sleep i; \"some success value\"\nend\n\n# ACTUAL SOLUTION...\n\nstart = Time.now\n\ntimes = [10, 10, 2].map do |i|\n  Thread.new do\n    begin\n      if i == 2\n        bar(i) # run bar with 2 second sleep\n      else\n        foo(i) # run foo with 10 second sleep\n      end\n    rescue\n      Thread.new { check(times) }\n      Thread.kill(Thread.current)\n    end\n  end\nend\n\ndef check(threads)\n  threads.select { |t| t unless t.alive? }.tap do |result|\n    threads.each { |t| t.kill } if result.size \u003e 0\n  end\nend\n\np times.map { |i| i.value }\n\nfinish = Time.now - start\n\np finish # should be ~2 seconds, definitely not 10! unless you modify the code as indicated above\n","tags":""},{"id":"6217f7b942fb056837e0","title":"Ruby Thread speed and fail fast","content":"[:a, :b, :c].map { |i| \n  Thread.new { \n    sleep 5; i.upcase \n  } \n}.map { |i| i.value }\n\n# If you call `Thread.new {}.value this would cause the overall time to take 15 seconds\n# But calling `.value` once all the threads have completed mean the resulting time takes 5 seconds\n\nThread::abort_on_exception=true\n\n[10, 10, 2].map { |i| \n  Thread.new { \n    sleep i; fail \"a thing\"; \"success\" \n  } \n}.map { |i| i.value }\n\n# `Thread::abort_on_exception=true` causes the thread to fail fast if an exception is raised\n","tags":""},{"id":"5611d411cffe72e39161","title":"Ruby client communicating with Go RPC over a TCP socket","content":"package remote\n\nimport (\n\t\"fmt\"\n\t\"net\"\n\t\"net/rpc\"\n\t\"net/rpc/jsonrpc\"\n)\n\n// Endpoint exposes our RPC over TCP service\nfunc Endpoint() {\n\tcompose := new(Compose)\n\n\trpc.Register(compose)\n\n\tlistener, err := net.Listen(\"tcp\", \":8080\")\n\tif err != nil {\n\t\t// handle error\n\t}\n\n\tfor {\n\t\tconn, err := listener.Accept()\n\t\tif err != nil {\n\t\t\t// handle error\n\t\t}\n\n\t\tgo jsonrpc.ServeConn(conn)\n\t}\n}\npackage remote\n\nimport \"fmt\"\n\n// Args is structured around the client's provided parameters\n// The fields need to be exported too!\ntype Args struct {\n\tFoo string\n\tBar string\n}\n\n// Compose is our RPC functions return type\ntype Compose string\n\n// Details is our exposed RPC function\nfunc (c *Compose) Details(args *Args, reply *string) error {\n\tfmt.Printf(\"Args received: %+v\\n\", args)\n\t*c = \"some value\"\n\t*reply = \"Blah!\"\n\treturn nil\n}\n\n// Args received: \u0026{Foo:Foo! Bar:Bar!}\nrequire \"socket\"\nrequire \"json\"\nrequire \"pry\"\n\nsocket = TCPSocket.new \"localhost\", \"8080\"\n\n# Details of JSON structure can be found here:\n# https://golang.org/src/net/rpc/jsonrpc/client.go#L45\n# Thanks to Albert Hafvenström (@albhaf) for his help\nb = {\n  :method =\u003e \"Compose.Details\",\n  :params =\u003e [{ :Foo =\u003e \"Foo!\", :Bar =\u003e \"Bar!\" }],\n  :id     =\u003e \"0\" # id is just echo'ed back to the client\n}\n\nbinding.pry\n\nsocket.write(JSON.dump(b))\n\np JSON.load(socket.readline)\n\n# =\u003e {\"id\"=\u003e\"0\", \"result\"=\u003e\"Blah!\", \"error\"=\u003enil}\n","tags":""},{"id":"633482ec3d2e75ac2d05","title":"Bash pipestatus","content":"docker run \\\n\t--cpu-shares 1024 \\\n\t--rm=true \\\n\t-v $WORKSPACE:/app \\\n\truby:2.1.2 \\\n    bash -c \"cd /app \u0026\u0026 gem install bundler \u0026\u0026 bundle install --jobs 4 \u0026\u0026 rspec\" | true\n\nTESTS_RESULT=\"${PIPESTATUS[0]}\"\n","tags":""},{"id":"c16c4cc7698cebb8d606","title":"Basic Bash Configuration (superseded by https://gist.github.com/Integralist/970b8e4a595b118acdd3)","content":"# update Bash version\n# apt-get install bash bash-completion\n# brew install bash; echo /usr/local/bin/bash|sudo tee -a /etc/shells; chsh -s /usr/local/bin/bash\n# for mac osx remember to add the following to your ~/.bash_profile\n#\n# if [ -f $HOME/.bashrc ]; then\n#   source ~/.bashrc\n#   cd .\n# fi\n#\n# if [ -f $(brew --prefix)/etc/bash_completion ]; then\n#   source $(brew --prefix)/etc/bash_completion\n# fi\n\n# tells Readline to perform filename completion in a case-insensitive fashion\nbind \"set completion-ignore-case on\"\n\n# filename matching during completion will treat hyphens and underscores as equivalent\nbind \"set completion-map-case on\"\n\n# will get Readline to display all possible matches for an ambiguous pattern at the first \u003cTab\u003e press instead of at the second\nbind \"set show-all-if-ambiguous on\"\n\n# enable vi like bindings (http://blog.sanctum.geek.nz/vi-mode-in-bash/)\nset -o vi\n\n# append to the history file, don't overwrite it\nshopt -s histappend\n\n# save multi-line commands as one command\nshopt -s cmdhist\n\n# record each line as it gets issued\nPROMPT_COMMAND='history -a'\n\n# set a larger history\nHISTSIZE=500000\nHISTFILESIZE=100000\n\n# avoid duplicate entries\nHISTCONTROL=\"erasedups:ignoreboth\"\n\n# don't record some commands\nexport HISTIGNORE=\"\u0026:[ ]*:exit:ls:bg:fg:history\"\n\n# useful timestamp format\nHISTTIMEFORMAT='%F %T '\n\n# no need to type cd (works for .. but not -, although alias -- -='cd -' fixes it)\nshopt -s autocd\n\n# autocorrect minor spelling errors\nshopt -s dirspell\nshopt -s cdspell\n\n# specify other paths to look inside of when autocompleting\nCDPATH=\".:~/Projects\"\n\n# use cd command for variable paths\nshopt -s cdable_vars\nexport dropbox=\"$HOME/Dropbox\"\nexport bbc=\"$HOME/Projects/BBC\"\nexport GITHUB_USER=\"integralist\"\nexport DEV_CERT_PATH=\"$HOME/.pki/bbc\"\nexport DEV_CERT_PEM=\"$HOME/.pki/bbc/Certificate.pem\"\nexport DEV_CERT_P12=\"$HOME/.pki/bbc/Certificate.p12\"\nexport CLOUD_CERT_PEM=\"$HOME/.pki/bbc/cloud-ca.pem\"\nexport GREP_OPTIONS=\"--color=auto\"\nexport GREP_COLOR=\"1;32\"\nexport MANPAGER=\"less -X\" # Don't clear the screen after quitting a manual page\nexport DOCKER_TLS_VERIFY=1\nexport BBC_COSMOS_TOOLS_CERT=$DEV_CERT_PEM\nexport GOPATH=$HOME/Projects/golang\nexport PATH=$HOME/Projects/golang/bin:$PATH\n\n# force colours\nforce_color_prompt=yes\n\n# use colour prompt\ncolor_prompt=yes\n\n# \\e indicates escape sequence (sometimes you'll see \\033)\n# the m indicates you've provided a colour sequence\n#\n# 30: Black\n# 31: Red\n# 32: Green\n# 33: Yellow\n# 34: Blue\n# 35: Purple\n# 36: Cyan\n# 37: White\n#\n# a semicolon allows additional attributes:\n#\n# 0: Normal text\n# 1: Bold or light, depending on terminal\n# 4: Underline text\n#\n# there are also background colours (put before additional attributes with ; separator):\n#\n# 40: Black background\n# 41: Red background\n# 42: Green background\n# 43: Yellow background\n# 44: Blue background\n# 45: Purple background\n# 46: Cyan background\n# 47: White background\n\n# simple left prompt example:\n# PS1='\\e[01;33m\\]\\u:\\[\\e[31m\\]\\w\\[\\e[00m\\] (\\j) (\\A)\\$ '\n\n# Much more complex left AND right solution (http://superuser.com/a/517110)\n# Which also dynamically displays the number of background jobs \\j in the current terminal\n# As well as dynamically displays git branch if available\n\nnum_jobs=$(jobs | wc -l)\n\nif [ $num_jobs -eq 0 ]; then\n  num_jobs=\"\"\nelse\n  num_jobs=\" (\\j)\"\nfi\n\nfunction prompt_right() {\n  # need the correct number of spaces after \\A to allow for 00:00 time display\n  echo -e \"\\e[0;36m\\A   \\e[0m\"\n}\nfunction prompt_left() {\n  echo -e \"\\e[33m\\]\\u. \\[\\e[31m\\]\\w\\[\\e[00m\\]$num_jobs\\e[32m\\]$git_branch\\e[00m\\]\\$ \"\n}\nfunction prompt() {\n    compensate=11\n    PS1=$(printf \"%*s\\r%s\\n\\$ \" \"$(($(tput cols)+${compensate}))\" \"$(prompt_right)\" \"$(prompt_left)\")\n}\n\n# override builtin cd so it also checks current directory for git branch\nfunction cd {\n  builtin cd \"$@\"\n  RET=$?\n\n  # check if we're inside a git repository (hide any errors)\n  $(git rev-parse --is-inside-work-tree \u003e\u0026 /dev/null)\n\n  if [ \"$?\" -eq \"128\" ]; then\n    git_branch=\"\"\n  else\n    git_branch=\" ($(git branch | grep '^*' | cut -d ' ' -f 2))\"\n  fi\n\n  PROMPT_COMMAND=prompt\n\n  return $RET\n}\n\nfunction rubo() {\n  docker run \\\n    --cpu-shares 1024 \\\n    --rm=true \\\n    --volume $(pwd):/app \\\n    bbcnews/rubocop-config --format simple --fail-level F | grep '^F:\\|=='\n}\n\nalias dotfiles=\"ls -a | grep '^\\.' | grep --invert-match '\\.DS_Store\\|\\.$'\"\nalias getcommit=\"git log -1 | cut -d ' ' -f 2 | head -n 1 | pbcopy\"\nalias vp=\"vim +PluginInstall! +qall\"\nalias sshkey=\"ssh-keygen -t rsa -b 4096 -C 'mark.mcdx@gmail.com'\"\nalias irc=\"irssi\"\nalias r=\"source ~/.bashrc\"\n\neval \"$(rbenv init -)\"\neval \"$(docker-machine env dev)\"\n","tags":""},{"id":"74fffc52bb68e2bcd738","title":"[Trap exit and error (defer cleanup execution when bash script fails)] ","content":"#!/bin/bash\n\nset -e\n\nfunction cleanup {\n  echo \"Removing /tmp/foo\"\n  rm  -r /tmp/foo\n}\n\ntrap cleanup EXIT\n# trap cleanup ERR \u003c- so only cleans on errors\nmkdir /tmp/foo\nasdffdsa # fails\n#!/bin/bash\n\nfunction cleanup {\n  echo \"running cleanup $*\"\n}\n\ntrap cleanup EXIT\ntrap 'cleanup uh-oh it went wrong' ERR\n\nasdasdasd # would cause ERR to fire and thus cleanup function would get extra arguments\n\n# otherwise the script would just exit naturally and so the EXIT signal would be handled.\n```bash\nhelp trap\n```\n\nSeems you can also use `trap \u003cfn\u003e RETURN` so the defined function will be called every time the script that's being run has finished executing.\n#! /bin/bash\n\nerr_report() {\n    echo \"Error on line $1\"\n}\n\n# if you wrap the function to be called in a single quote string,\n# then anything following it will be passed to the function!\n#\n# so in the following example we pass the shell's LINENO variable\n# which indicates what the error line was.\n#\n# we then access that via $1 within the err_report function, but\n# we could also have just used $* to reference all arguments passed\n# in case we passed multiple arguments.\ntrap 'err_report $LINENO' ERR\n\necho hello | grep foo  # This is line number 9\n\n# $ ./foo.sh\n# Error on line 9\n","tags":"#bash #trap #catch #errorhandling"},{"id":"35479416b54f2ee51b31","title":"Search for files and pipe into Vim","content":"nvim $(sift -n SomePattern | awk -F : '{ print $1 \" +:\" $2 }')\n","tags":""},{"id":"8ae1882966237fb5e98c","title":"Avoid SSH connection timeout \u0026 freezing of terminal tab","content":"```\n\u003cEnter\u003e~.\n```\n\n\u003e The section \"ESCAPE CHARACTERS\" in the ssh man page explains the underlying details\nAdd the following to your `~/.ssh/config`:\n\n```bash\nHost remotehost\n  HostName remotehost.com\n  ServerAliveInterval 240\n```\n\n`ServerAliveInterval`: Pings server every 4 minutes\n","tags":""},{"id":"1a069f995b3de3836a6c","title":"Apache LogFormat Example","content":"# Add the following contents to:\n# /etc/httpd/conf.d/logging.conf\n\n# Our new log format in structured json style\nLogFormat '{\"apache\":{\"timestamp\":\"%t\",\"status\":\"%\u003es\",\"origin_ip\":\"%{X-Forwarded-For}i\",\"message\":\"%r\",\"user-agent\":\"%{User-Agent}i\"}}' custom\n\n# Note:\n# This is the syntax structure of the LogFormat setting...\n# LogFormat \u003cstring_formatter\u003e \u003clog_format_name\u003e\n\n# You have to tell Apache which log file to use (app.log) and which formatter to use (custom)\nCustomLog \"/var/log/component/app.log\" custom\n\n# Note:\n# This is the syntax structure of the CustomLog setting...\n# CustomLog \u003clog_location\u003e \u003clog_format_name\u003e\n","tags":""},{"id":"aeb52af738eef575b718","title":"[Update all submodules for a repo with a single command] ","content":"# There are two ways to achieve the same thing, the first is more idiomatic (the second is a more general purpose solution).\n\n# 1.\n# Update the registered submodules to match what the superproject expects. [1]\ngit submodule update --init --recursive\n\n# 2.\n# Evaluates an arbitrary shell command in each checked out submodule. [2]\ngit submodule foreach git pull origin master\n\n# Footnotes\n#\n# 1. https://git-scm.com/docs/git-submodule#Documentation/git-submodule.txt-update--init--remote-N--no-fetch--no-recommend-shallow-f--force--checkout--rebase--merge--referenceltrepositorygt--depthltdepthgt--recursive--jobsltngt--no-single-branch--ltpathgt82308203\n# 2. # https://git-scm.com/docs/git-submodule#Documentation/git-submodule.txt-foreach--recursiveltcommandgt\n","tags":"#git #submodules"},{"id":"a49df746e2bd30bff047","title":"Different Linux utility commands (e.g. top, ps, strace, lsof, netstat, ifconfig, iftop, iptraf, tcpdump, wireshark)","content":"## wireshark\n\nWireshark is a network protocol analyzer. \n\nIt lets you see what's happening on your network at a microscopic level.\n\nTo install (Mac OS X):\n\n```bash\nbrew options wireshark           # check for options before installing\nbrew install wireshark --with-qt # install gui version\nbrew install tshark              # terminal oriented version of Wireshark designed for capturing and displaying packets without need for a gui\n```\n\nFor CentOS:\n\n```bash\nyum install wireshark\n```\n\n\u003e With Docker:  \n\u003e `--privileged` required (otherwise: `can't run /usr/sbin/dumpcap: Operation not permitted`)  \n\u003e `--security-opt seccomp:unconfined` is an alternative\n\nOnce you have your pcap formatted file (see [tcpdump](#tcpdump)) you can open Wireshark's gui via your terminal by executing the shell command: `wireshark`\n\nOnce open you can use the gui to select \"Open Capture File\", browse to your pcap file and select it.\n\nNow you can start analysing your network traffic.\n\nYou can automate this process by reading in the capture file directly from the shell:\n\n```bash\nwireshark -r ~/Downloads/tcpdump-tests/0001.pcap\n```\n\nYou can also specify the interface to connect to using `-i` (notice I had to use `sudo` in order to authorise Wireshark):\n\n```bash\nsudo wireshark -i en0\n```\n\nTo see available interfaces execute: `sudo wireshark -D` (again you _need_ `sudo`):\n\n```bash\nCapture-Message: Capture Interface List ...\nCapture-Message: Loading External Capture Interface List ...\n1. en0 (Wi-Fi)\n2. awdl0\n3. bridge0 (Thunderbolt Bridge)\n4. en1 (Thunderbolt 1)\n5. vboxnet1\n6. en2 (Thunderbolt 2)\n7. p2p0\n8. lo0 (Loopback)\n```\n\nEvery time there is (for example) a HTTP request, that might end up being 200 TCP packets, which is difficult to recognize and make sense of manually. But this can be simplified within Wireshark by clicking on Statistics -\u003e Conversations, where it organizes all these disparate packets into TCP sessions.\n\n### tshark\n\nWhen installing Wireshark you'll also get a `tshark` command, which is a command line version of `wireshark`.\n\nSo you can read in your pcap file like so:\n\n```bash\ntshark -r ~/Downloads/tcpdump-tests/0001.pcap\n```\n\nThis will display clearer formatted analysis than `tcpdump -r` provides.\n\n`tcpdump` doesn't know about HTTP or other network protocols. It knows pretty much everything about TCP but it doesn't care what you put inside your TCP packets. `tshark` on the other hand knows all about what's inside your TCP packets.\n\n```bash\nsudo tshark -i any \\\n            -R 'http.request.method == \"GET\"' \\\n            -T fields \\\n            -e http.request.method -e http.request.uri -e ip.dst\n```\n\nThe above filters for just packets which have a `HTTP GET` request in them, and then prints out the request method and the URI for each one.\n\nThe way you filter results is by specifying `-T` and changing to the `fields` value. From there you can use the `-e` flag to specify how to filter data. So if you wanted to filter out all the DNS ttls from a tcpdump of just DNS traffic you could use something like:\n\n```bash\ntshark -r ~/dns-traffic.pcap -T fields -e dns.resp.ttl -e dns.resp.name\n```\n\n\u003e Note: if you open the pcap in wireshark, you can find the filter you need by selecting the data manually via the UI and then right-click'ing and selecting \"Prepare a Filter \u003e Selected\"\nStart up a container (whichever Linux flavour takes your fancy):\n\n```bash\ndocker run -it ubuntu /bin/bash\ndocker run -it centos /bin/bash\n```\n\n- [`top`](#top): check what CPU and Memory running processes are utilising\n- [`ps`](#ps): see what processes are running\n- [`strace`](#strace): monitor interactions between processes\n- [`lsof`](#lsof): list of open files\n- [`netstat`](#netstat): monitoring network traffic\n- [`ifconfig`](#ifconfig): configure or review your network interfaces\n- [`iftop`](#iftop): monitors network traffic and displays table of bandwidth usage\n- [`iptraf`](#iptraf): monitoring network traffic (more visual than `netstat`, but not as detailed)\n- [`tcpdump`](#tcpdump): network packet sniffer\n- [`wireshark/tshark`](#wireshark): network packet sniffer and analyser (create pcaps with `tcpdump` and analyse with `tshark`)\n- [`telnet`](#telnet): utility for communicating with another host\n\n## OSI Model\n\n|   |Layer       |Protocols             |Description|\n|---|:-----------|:---------------------|:----------|\n|7. |Application |`HTTP`, `FTP`, `SMTP` |Window for user app processes|\n|6. |Presentation|`JPEG`, `GIF`, `MPEG` |Format the data to be presented to the Application layer (network translator)|\n|5. |Session     |`RPC`, `SQL`, `NFS`   |Allow session establishment between processes running on different stations|\n|4. |Transport   |`TCP`, `UDP`, `SPX`   |Flow control, ensures all messages are delivered error-free, in sequence, no losses or duplications|\n|3. |Network     |`IP`, `IPX`, `ICMP`   |Routers control operation of subnet, deciding physical path data takes|\n|2. |Data Link   |`PPP/SLIP`            |Provides error-free transfer of data over physical layer|\n|1. |Physical    |`Hub`                 |Physical structure (cables, hubs etc)|\n## ifconfig\n\nThe `ifconfig` command is used to configure a network interface. \n\nFor a breakdown of the following ouput see: http://www.aboutlinux.info/2006/11/ifconfig-dissected-and-demystified.html\n\nIf you don't want to configure a network interface then running the command without any arguments will display existing network interfaces.\n\n```bash\neth0      Link encap:Ethernet  HWaddr 0A:05:1E:A5:6F:FF  \n          inet addr:10.6.4.51  Bcast:10.6.7.255  Mask:255.255.248.0\n          inet6 addr: fe80::805:1eff:fea5:6fff/64 Scope:Link\n          UP BROADCAST RUNNING MULTICAST  MTU:9001  Metric:1\n          RX packets:8776319 errors:0 dropped:0 overruns:0 frame:0\n          TX packets:4212889 errors:0 dropped:0 overruns:0 carrier:0\n          collisions:0 txqueuelen:1000 \n          RX bytes:10239965628 (9.5 GiB)  TX bytes:10967533931 (10.2 GiB)\n          Interrupt:155 \n\nlo        Link encap:Local Loopback  \n          inet addr:127.0.0.1  Mask:255.0.0.0\n          inet6 addr: ::1/128 Scope:Host\n          UP LOOPBACK RUNNING  MTU:65536  Metric:1\n          RX packets:341240 errors:0 dropped:0 overruns:0 frame:0\n          TX packets:341240 errors:0 dropped:0 overruns:0 carrier:0\n          collisions:0 txqueuelen:0 \n          RX bytes:31612016 (30.1 MiB)  TX bytes:31612016 (30.1 MiB)\n```\n\nWe can see above that we have a single Ethernet card (`eth0`) and a loop back interface (`lo`)\n\n\u003e In newer Linux OS' `eth\u003cn\u003e` is replaced by `p2p\u003cn\u003e`\n\nFor more information on Network ips and how they're created then read: https://gist.github.com/Integralist/cff468ba808fbca09602\n## tcpdump\n\n`tcpdump` is a powerful and widely used command-line packets sniffer or package analyzer tool which is used to capture or filter TCP/IP packets that received or transferred over a network on a specific interface\n\nWe can save the output into a pcap file format, that can be viewed by either tcpdump itself or via an open source GUI based tool called Wireshark (Network Protocol Analyzier) that reads tcpdump pcap format files\n\nTo install:\n\n```bash\nyum install tcpdump -y     # CentOS\napt-get install tcpdump -y # Ubuntu\n```\n\n### Usage\n\n- `tcpdump -D`: show available network interfaces\n- `tcpdump -i eth0 -c 5`: capture packets from specific network interface (and only set number of packets)\n- `tcpdump -i eth0 -c 5 -w 0001.pcap`: send output to pcap file\n- `tcpdump -r 0001.pcap`: read back out the pcap file content\n- `tcpdump -n -i eth0 -c 1`: converts dns hostnames into ip addresses instead\n- `tcpdump -n -i eth0 -c 10 tcp`: capture only tcp packets\n- `tcpdump -n -i eth0 -c 10 port 22`: capture packets from specific port (e.g. `22`)\n- `tcpdump -i eth0 src \u003cip\u003e`: capture packets from a specific source ip\n- `tcpdump -i eth0 dst \u003cip\u003e`: capture packets for a specific destination ip\n- `tcpdump -i eth0 src port 80 or dst port 80`: filter all HTTP traffic to or from port 80\n- `tcpdump -i eth0 -s 0`: include contents of each packet (not just the packet header)\n- `tcpdump -vvv -s 0 -l -n port 53 -XX`: watch all DNS traffic (which happens on port 53)\n\n\u003e SCP file from AWS remote to local (run on local machine)  \n\u003e `scp -v -r \u003cuser_name\u003e@\u003cip\u003e,eu-west-1:\u003cremote_path\u003e \u003clocal_path\u003e`  \n\u003e Make sure the local directory exists\n\n### Flags\n\n- `URGENT pointer`: used to identify incoming data as 'urgent'. Such incoming segments do not have to wait until the previous segments are consumed by the receiving end but are sent directly and processed immediately\n- `ACK`: used to acknowledge the successful receipt of packets\n- `Push`: exists to ensure that the data is given the priority (used quite frequently at the beginning and end of a data transfer, affecting the way the data is handled at both ends)\n- `RST`: used when a segment arrives that is not intended for the current connection (remote host rejects packet and resets connection) \n- `SYN`: initially sent when establishing the classic 3-way handshake between two hosts (one sent by Host A and one sent back with ACK by Host B)\n- `FIN`: used to tear down the virtual connections created using the previous flag (SYN)\n\nNote: `FIN` wont necessarily be the last packet sent. For example... \n\n- Host A receives what it believes to be the last data packet\n- So Host A sends a `FIN` to tell Host B it's closing it's connection, along with an `ACK` to acknowledge Host B's last data packet\n- Host B sends an `ACK` to acknowledge receipt of Host A's `FIN`\n- Host B then sends its own `FIN` and `ACK` to close its connection down\n- Host A sends a final `ACK` to acknowledge Host B's last communication was received\n## telnet\n\nTelnet is a Network Protocol and the tool which uses that protocol (i.e `telnet`) is also known as Telnet.\n\nThe `telnet` utility is used for interactive communication to a remote/extern host on a given port. Once the connection to the remote host is established, an HTTP request can be send to the host by typing it in the prompt.\n\nThe following example shows that the google domain carries out a 302 redirect:\n\n```bash\n$ telnet www.google.com 80\nTrying 87.237.19.30...\nConnected to www.google.com.\nEscape character is '^]'.\nGET #q=cars HTTP/1.1                   \n\nHTTP/1.1 302 Found\nLocation: http://www.google.co.uk/?gws_rd=cr\u0026ei=k7BjV-GbFOLOgAbd3JbADw#q=cars\nCache-Control: private\nContent-Type: text/html; charset=UTF-8\nP3P: CP=\"This is not a P3P policy! See https://www.google.com/support/accounts/answer/151657?hl=en for more info.\"\nDate: Fri, 17 Jun 2016 08:10:59 GMT\nServer: gws\nContent-Length: 268\nX-XSS-Protection: 1; mode=block\nX-Frame-Options: SAMEORIGIN\nSet-Cookie: NID=80=R8K0WhuF432ccZzjpchtEPHx-vv1n-9tuoe8P6V2yyNC2h1sd_JB7Q1afFZPo5W9MjvP8UL1ZZ_8UQDHeb3OpGDRNlSNfPkJWqE9JKa9hAJG02wlk7s8eIRy786p7-8U; expires=Sat, 17-Dec-2016 08:10:59 GMT; path=/; domain=.google.com; HttpOnly\n\n\u003cHTML\u003e\u003cHEAD\u003e\u003cmeta http-equiv=\"content-type\" content=\"text/html;charset=utf-8\"\u003e\n\u003cTITLE\u003e302 Moved\u003c/TITLE\u003e\u003c/HEAD\u003e\u003cBODY\u003e\n\u003cH1\u003e302 Moved\u003c/H1\u003e\nThe document has moved\n\u003cA HREF=\"http://www.google.co.uk/?gws_rd=cr\u0026amp;ei=k7BjV-GbFOLOgAbd3JbADw#q=cars\"\u003ehere\u003c/A\u003e.\n\u003c/BODY\u003e\u003c/HTML\u003e\nConnection closed by foreign host.\n```\n\nThe BBC site gives us a 404 not found:\n\n```bash\n$ telnet www.bbc.co.uk 80\nTrying 212.58.244.66...\nConnected to www.bbc.net.uk.\nEscape character is '^]'.\nGET /news HTTP/1.1\n\nHTTP/1.1 404 Not Found\nContent-Type: text/html\nDate: Fri, 17 Jun 2016 08:13:29 GMT\nConnection: Keep-Alive\nContent-Length: 50591\n```\n## iftop\n\niftop does for network usage what top(1) does for CPU usage. It listens to network traffic on a named interface and displays a table of current bandwidth usage by pairs of hosts. Handy for answering the question \"why is our ADSL link so slow?\"\n\nTo install (Ubuntu):\n\n```bash\napt-get update\napt-get install iftop\n```\n\nTo install (CentOS):\n\n```bash\nyum install wget libpcap -y\nwget http://pkgs.repoforge.org/iftop/iftop-0.17-1.el6.rf.x86_64.rpm\nrpm -ivh iftop-0.17-1.el6.rf.x86_64.rpm\n```\n\n- `iftop -P`: show port numbers\n## iptraf\n\nThe `iptraf` tool monitors Inbound and Outbound network traffic passing through a network interface. \n\nWe can monitor various connections like TCP, UDP, ICMP, non-IP counts and also Ethernet load information.\n\nTo install:\n\n```bash\nyum install iptraf     # CentOS\napt-get install iptraf # Ubuntu\n```\n\nOf particular interest is the menu `Statistical breakdowns... \u003e By TCP/UDP port \u003e eth0` which shows packets for all TCP and UDP ports such as `22` for SSH and `443` for HTTPS.\n## lsof\n\nAn open file may be a regular file, a directory, a block special file, a character special file, an executing text reference, a library, a stream or a network file (Internet socket, NFS file or UNIX domain socket)\n\n- `lsof -u \u003cuser\u003e`: filter results by specific user\n- `lsof -i TCP:22 -n`: lists all running processes on port 22 (ssh)\n- `lsof -i 4`: display only IPv4 network files\n## netstat\n\nnetstat (network statistics) is a command-line tool that displays network connections for the Transmission Control Protocol (both incoming and outgoing), routing tables, and a number of network interface and network protocol statistics\n\n- `netstat -a`: show both listening and non-listening sockets (for TCP this means established connections)\n- `netstat -l`: show just listening sockets\n- `netstat -lt`: show just tcp sockets\n- `netstat -lu`: show just udp sockets\n- `netstat -aep`: extend to show the user and also the pids\n- `netstat -aepn`: don't translate host names (e.g. show ip instead)\n- `netstat -aepT`: show host name but don't truncate it\n- `netstat -ax`: show just UNIX domain sockets\n- `netstat -st`: shows summary of connections (useful for identifying TCP connection issues)\n- `netstat -lc \u003cn_seconds\u003e`: continously refreshing every n seconds\n- `netstat -atepn`: nice all-rounder output (see below for example output)\n\n```bash\nActive Internet connections (servers and established)\nProto Recv-Q Send-Q Local Address               Foreign Address             State       User       Inode      PID/Program name   \ntcp        0      0 0.0.0.0:8126                0.0.0.0:*                   LISTEN      0          8934       1071/statsd         \ntcp        0      0 0.0.0.0:8080                0.0.0.0:*                   LISTEN      498        10087      1355/puma 2.14.0 (t \ntcp        0      0 0.0.0.0:22                  0.0.0.0:*                   LISTEN      0          8763       1196/sshd           \ntcp        0      0 127.0.0.1:24220             0.0.0.0:*                   LISTEN      497        9296       1307/ruby           \ntcp        0      0 10.6.4.51:57228             10.6.31.176:6379            ESTABLISHED 498        218757     1355/puma 2.14.0 (t \ntcp        0      0 10.6.4.51:57224             10.6.31.176:6379            ESTABLISHED 498        218743     1355/puma 2.14.0 (t \ntcp        0      0 10.6.4.51:8080              10.6.8.80:48205             ESTABLISHED 498        229190     1355/puma 2.14.0 (t \ntcp        0      0 10.6.4.51:57231             10.6.31.176:6379            ESTABLISHED 498        218766     1355/puma 2.14.0 (t \ntcp        0      0 10.6.4.51:57225             10.6.31.176:6379            ESTABLISHED 498        218747     1355/puma 2.14.0 (t \ntcp        0      0 10.6.4.51:8080              10.6.6.76:51764             ESTABLISHED 498        10111      1355/puma 2.14.0 (t \ntcp       53      0 10.6.4.51:56870             54.231.142.40:443           ESTABLISHED 497        229141     1307/ruby           \ntcp        1      0 127.0.0.1:34704             127.0.0.1:8080              CLOSE_WAIT  48         226010     20286/httpd\n```\n\n- `netstat -r`: shows routing table (see below for example output)\n\n```bash\nKernel IP routing table\nDestination     Gateway         Genmask         Flags   MSS Window  irtt Iface\n10.6.0.0        *               255.255.248.0   U         0 0          0 eth0\nlink-local      *               255.255.0.0     U         0 0          0 eth0\ndefault         ip-xx-x-x-x.eu- 0.0.0.0         UG        0 0          0 eth0\n```\n## ps\n\n- `ps aux`: shows all running processes\n- `ps axjf`: shows ppids (parent process) with nested children pids (`j` = ppid \u0026 `f` = formatting)\n- `pstree -aupn \u003cuser_to_filter_by\u003e`: displays a tree of processes inc. pids and sort by them\n\n\u003e `a` needs to be used with `x` to give you _all_ processes  \n\u003e `u` provides additional output such as `CPU` and `MEM`  \n\u003e so `axu` would be more accurate, but I'm more used to `aux`\n## strace\n\nstrace monitors interactions between processes, such as: system calls, signal deliveries, and changes of process state\n\nInstall `strace` (Ubuntu):\n\n```bash\napt-get install man -y\napt-get install strace\nman strace\n```\n\nInstall `strace` (CentOS):\n\n```bash\nyum install strace -y\n```\n\n\u003e With Docker:  \n\u003e `--privileged` required for `ptrace` to be allowed  \n\u003e `--security-opt seccomp:unconfined` is an alternative\n\n```bash\nstrace \u003cbinary_executable\u003e\n```\n\nThe end of the `strace` output will be the output of the specified binary executable.\n\nFilter results using an 'expression':\n\n```bash\nstrace -e trace=open ls\n```\n\n\u003e specify multiple system calls with comma-separated list  \n\u003e `-e trace=open,read`\n\nAttach `strace` to a running process:\n\n```bash\nstrace -p \u003cprocess_id\u003e\n```\n\n\u003e `ps aux` to locate process id\n\nBe careful with backgrounded processes. If you attach to a backgrounded process running in the same shell instance as your `strace` execution, then you'll be locked up.\n\nWith Docker you can fix this by executing the following within a new shell:\n\n```bash\ndocker exec -it \u003ccontainer_id\u003e /bin/bash\n```\n\nThen `kill -9 \u003cstrace_pid|application_pid\u003e`\n\nAdd a timestamp to your output using `-t`\n\nStatistical summary `-c` displays output in a graphical table:\n\n\u003e output with `-c` comes *after* the binary's output\n\nRedirect and pipe output:\n\n```bash\nstrace php 2\u003e\u00261 | grep php.ini\n```\n## top\n\nThe `top` command displays processor activity and also displays tasks managed by the kernel in real-time.\n\n- `top -u \u003cuser\u003e`: filter processes by those run by specified user\n- `top -n 10`: stops command running after 10 intervals (otherwise runs forever or until `\u003cCtrl-c\u003e`)\n\nThe following key strokes should be executed whilst `top` is running...\n\n- `\u003cShift-o\u003e`: display menu so you can change sorting field\n- `\u003cShift-p\u003e`: changes sorting back to CPU (CPU is already the default behaviour)\n- `z`: toggles on/off ability to have currently running processes highlighted\n- `c`: toggles on/off absolute path for the COMMAND\n- `d`: change interval for screen/data refresh\n- `k`: followed by PID of process you want to kill\n","tags":""},{"id":"9c87172cb418e539dae0","title":"Redis vs Memcache","content":"When deciding between Memcached and Redis, here are a few questions to consider:\n\n- Is object caching your primary goal, for example to offload your database? If so, use \u003cb style=\"color:#298D84\"\u003eMemcached\u003c/b\u003e.\n- Are you interested in as simple a caching model as possible? If so, use \u003cb style=\"color:#298D84\"\u003eMemcached\u003c/b\u003e.\n- Are you planning on running large cache nodes, and require multithreaded performance with utilization of multiple cores? If so, use **Memcached**.\n- Do you want the ability to scale your cache horizontally as you grow? If so, use \u003cb style=\"color:#298D84\"\u003eMemcached\u003c/b\u003e.\n- Does your app need to atomically increment or decrement counters? If so, use either \u003cb style=\"color:#C00\"\u003eRedis\u003c/b\u003e or \u003cb style=\"color:#298D84\"\u003eMemcached\u003c/b\u003e.\n- Are you looking for more advanced data types, such as lists, hashes, and sets? If so, use \u003cb style=\"color:#C00\"\u003eRedis\u003c/b\u003e.\n- Does sorting and ranking datasets in memory help you, such as with leaderboards? If so, use \u003cb style=\"color:#C00\"\u003eRedis\u003c/b\u003e.\n- Are publish and subscribe (pub/sub) capabilities of use to your application? If so, use \u003cb style=\"color:#C00\"\u003eRedis\u003c/b\u003e.\n- Is persistence of your key store important? If so, use \u003cb style=\"color:#C00\"\u003eRedis\u003c/b\u003e.\n","tags":""},{"id":"68f45e3aebccc2f5068e","title":"Restrict Access to pushing updates to an API in the Live environment (except via Jenkins CI) via Apache","content":"#!/bin/bash\n\nENVIRONMENT=`cat /etc/bake-scripts/config.json | python -c 'import sys, json; print json.load(sys.stdin)[\"environment\"]'`\nSSL_TERM=/etc/httpd/conf.d/bbc-httpd-includes/https_vhost/custom/restrict_access.inc\n\nif [ \"$ENVIRONMENT\" == \"live\" ]; then\n\tcat \u003e $SSL_TERM \u003c\u003c-EOF\n\t\t\u003cLocation /\u003e\n\t\t  # Start the rewrite engine...\n\t\t  RewriteEngine on\n\t\t  \n\t\t  # Match only a POST or PUT request (GETs are always allowed through, regardless of environment \u0026 user)\n\t\t  RewriteCond   %{REQUEST_METHOD} POST|PUT\n\t\t  \n\t\t  # Allow this as long as the CommonName on the cert matches \"dev-news-jenkins-agents\" or \"news-jenkins-agents\"\n\t\t  RewriteCond   %{SSL:SSL_CLIENT_S_DN_CN} !^(dev-)?news-jenkins-agents$\n\t\t  \n\t\t  # Match any route (.*) and don't redirect (\"-\") and then 403 ([F])\n\t\t  RewriteRule   .* \"-\" [F]\n\t\t\u003c/Location\u003e\n\tEOF\nfi\n","tags":""},{"id":"57ff3b8c17e918c4e9fe","title":"Redis testing on EC2 instance with CentOS","content":"yum install epel-release -y\nyum install redis -y # gives you the cli tools\n\n# now you can use:\n# http://redis.io/commands\n\nredis-cli -h \u003cendpoint\u003e -p 6379\n# where \u003cendpoint\u003e is something like int-mozart-comp.f7qvra.0001.euw1.cache.amazonaws.com\n# which you can get from the AWS console under \"cache clusters\"\n\nset foo \"bar\"\nget foo\nKeys *    # returns all redis keys\nmonitor   # tails all activity\nttl \u003ckey\u003e # returns current ttl value remaining\n","tags":""},{"id":"584f6a4cf0a607a9da52","title":"[Vegeta load test examples https://github.com/tsenart/vegeta] ","content":"echo \"GET http://google.com\" | vegeta attack -duration=5s -rate=2 -cert=/path/to/certificate.pem | tee results.bin | vegeta report\n\n# you don't have to pipe the data to `vegeta report`, \n# you can instead run it as a separate command...\n#\n# echo \"GET http://google.com\" | vegeta attack -duration=5s | tee results.bin\n# vegeta report results.bin\n#\n# in the vegeta results you might be confused by the `Status Codes` section:\n#\n# e.g. Status Codes  [code:count]             0:45  200:5723  500:33  502:13  503:186\n#\n# ...this just means the code (let's use `200 OK` as an example), was received 5723 times.\n# where as a zero code means there was a problem sending the request.\n\ncat results.bin | vegeta report -reporter=plot \u003e plot.html\n\n# alternative ploting graph approach...\n#\n# vegeta plot -title=Attack%20Results results.bin \u003e results.html\n#\n# ...you can also generate the report as JSON...\n#\n# vegeta report -type=json results.bin\n#\n# to use an external file use `-targets=target.list` where the targets file is...\n#\n# GET http://\u003capplication_url\u003e/list/user/1\n# GET http://\u003capplication_url\u003e/list/user/2\n# GET http://\u003capplication_url\u003e/list/user/3\n#\n# it can also contain POST data...\n#\n# POST http://\u003capplication_url\u003e/create/newuser/\n# Content-Type: application/json\n# @/path/to/newuser.json\n#\n# ...where the file /path/to/newuser.json contains...\n#\n# {\n#  \"name\": \"Peter\";\n#  \"lastname\": \"Smith\";\n#  \"email\": \"psmith@example.com\"\n# }\n","tags":"#go #golang #vegeta #examples #loadtest #benchmark #report"},{"id":"970b8e4a595b118acdd3","title":"Bash Template (an older version with different variations can be found here: https://gist.github.com/Integralist/c16c4cc7698cebb8d606)","content":"# update Bash version\n#\n# brew install bash;\n# echo /usr/local/bin/bash | sudo tee -a /etc/shells\n# chsh -s /usr/local/bin/bash\n#\n# with mac osx remember to add the following to your ~/.bash_profile\n#\n# if [ -f $HOME/.bashrc ]; then\n#   source ~/.bashrc\n#   cd .\n# fi\n#\n# if [ -f $(brew --prefix)/etc/bash_completion ]; then\n#   source $(brew --prefix)/etc/bash_completion\n# fi\n#\n# also create an .inputrc with the following content\n#\n# TAB: menu-complete\n# \"\\e[Z\": \"\\e-1\\C-i\"\n#\n# this allows you to use \u003cC-n\u003e and \u003cC-p\u003e to tab through the ambigious cd suggestions\n\n# https://github.com/git/git/blob/8976500cbbb13270398d3b3e07a17b8cc7bff43f/contrib/completion/git-prompt.sh\nsource ~/.git-prompt.sh\n\n# show asterisk if there are unstaged changes\nexport GIT_PS1_SHOWDIRTYSTATE=true\n\n# tells Readline to perform filename completion in a case-insensitive fashion\nbind \"set completion-ignore-case on\"\n\n# filename matching during completion will treat hyphens and underscores as equivalent\nbind \"set completion-map-case on\"\n\n# will get Readline to display all possible matches for an ambiguous pattern at the first \u003cTab\u003e press instead of at the second\nbind \"set show-all-if-ambiguous on\"\n\n# no bell sound on error\nbind \"set bell-style none\"\n\n# enable vi like bindings (http://blog.sanctum.geek.nz/vi-mode-in-bash/)\nset -o vi\n\n# append to the history file, don't overwrite it\nshopt -s histappend\n\n# save multi-line commands as one command\nshopt -s cmdhist\n\n# record each line as it gets issued\nexport PROMPT_COMMAND='history -a'\n\n# set a larger history\nexport HISTSIZE=500000\nexport HISTFILESIZE=100000\n\n# avoid duplicate entries\nexport HISTCONTROL=\"erasedups:ignoreboth\"\n\n# don't record some commands\nexport HISTIGNORE=\"\u0026:[ ]*:exit:ls:bg:fg:history\"\n\n# useful timestamp format\nexport HISTTIMEFORMAT='%F %T '\n\n# shopt -p\n# will show all available settings\n\n# no need to type cd (works for .. but not -, although alias -- -='cd -' fixes it)\nshopt -s autocd 2\u003e/dev/null\n\n# autocorrect minor spelling errors\nshopt -s dirspell 2\u003e/dev/null\nshopt -s cdspell 2\u003e/dev/null\n\n# check windows size if windows is resized\nshopt -s checkwinsize 2\u003e/dev/null\n\n# use extra globing features. See man bash, search extglob.\nshopt -s extglob 2\u003e/dev/null\n\n# include .files when globbing.\nshopt -s dotglob 2\u003e/dev/null\n\n# specify other paths to look inside of when autocompleting\nCDPATH=\".:~/Projects\"\n\n# environment variables\nexport DROPBOX=\"$HOME/Dropbox\"\nexport BBC=\"$HOME/Projects/BBC\"\nexport GITHUB_USER=\"integralist\"\nexport DEV_CERT_PATH=\"$HOME/.pki/bbc\"\nexport DEV_CERT_PEM=\"$HOME/.pki/bbc/Certificate.pem\"\nexport DEV_CERT_P12=\"$HOME/.pki/bbc/Certificate.p12\"\nexport CLOUD_CERT_PEM=\"$HOME/.pki/bbc/cloud-ca.pem\"\nexport GREP_OPTIONS=\"--color=auto\"\nexport GREP_COLOR=\"1;32\"\nexport MANPAGER=\"less -X\" # Don't clear the screen after quitting a manual page\nexport DOCKER_TLS_VERIFY=1\nexport BBC_COSMOS_TOOLS_CERT=$DEV_CERT_PEM\nexport GOPATH=$HOME/Projects/golang\nexport PATH=$HOME/Projects/golang/bin:$PATH\nexport EDITOR=\"vim\"\nexport GIT_PS1_SHOWCOLORHINTS=true\n\n# Colored man pages\nexport LESS_TERMCAP_mb=$'\\E[01;31m'\nexport LESS_TERMCAP_md=$'\\E[01;31m'\nexport LESS_TERMCAP_me=$'\\E[0m'\nexport LESS_TERMCAP_se=$'\\E[0m'\nexport LESS_TERMCAP_so=$'\\E[01;44;33m'\nexport LESS_TERMCAP_ue=$'\\E[0m'\nexport LESS_TERMCAP_us=$'\\E[01;32m'\n\n# force colours\nforce_color_prompt=yes\n\n# use colour prompt\ncolor_prompt=yes\n\n# \\e indicates escape sequence (sometimes you'll see \\033)\n# the m indicates you've provided a colour sequence\n#\n# 30: Black\n# 31: Red\n# 32: Green\n# 33: Yellow\n# 34: Blue\n# 35: Purple\n# 36: Cyan\n# 37: White\n#\n# a semicolon allows additional attributes:\n#\n# 0: Normal text\n# 1: Bold or light, depending on terminal\n# 4: Underline text\n#\n# there are also background colours (put before additional attributes with ; separator):\n#\n# 40: Black background\n# 41: Red background\n# 42: Green background\n# 43: Yellow background\n# 44: Blue background\n# 45: Purple background\n# 46: Cyan background\n# 47: White background\n\n# simple left prompt example:\n# PS1='\\e[01;33m\\]\\u:\\[\\e[31m\\]\\w\\[\\e[00m\\] (\\j) (\\A)\\$ '\n\n# Much more complex left AND right solution (http://superuser.com/a/517110)\n# Which also dynamically displays the number of background jobs \\j in the current terminal\n# As well as dynamically displays git branch if available\n\nnum_jobs=$(jobs | wc -l)\n\nif [ $num_jobs -eq 0 ]; then\n  num_jobs=\"\"\nelse\n  num_jobs=\" (\\j)\"\nfi\n\nfunction prompt_right() {\n  # need the correct number of spaces after \\A to allow for 00:00 time display\n  # echo -e \"\\e[0;36m\\A   \\e[0m\"\n  echo -e \"\"\n}\nfunction prompt_left() {\n  # __git_ps1 function sourced from ~/.git-prompt.sh\n  echo -e \"\\e[33m\\]\\u. \\[\\e[37m\\]\\w\\[\\e[00m\\]$num_jobs\\e[31m\\]$(__git_ps1)\\e[00m\\] \\e[0;32m\\A\\e[0m\"\n}\nfunction prompt() {\n    compensate=11\n    PS1=$(printf \"%*s\\r%s\\n\\$ \" \"$(($(tput cols)+${compensate}))\" \"$(prompt_right)\" \"$(prompt_left)\")\n}\n\n# override builtin cd so it resets command prompt when changing directories\nfunction cd {\n  builtin cd \"$@\"\n  RET=$?\n\n  PROMPT_COMMAND=prompt\n\n  # After each command, append to the history file and reread it\n  export PROMPT_COMMAND=\"${PROMPT_COMMAND:+$PROMPT_COMMAND$'\\n'}history -a; history -c; history -r\"\n\n  return $RET\n}\n\nfunction rubo() {\n  docker run \\\n    --cpu-shares 1024 \\\n    --rm=true \\\n    --volume $(pwd):/app \\\n    bbcnews/rubocop-config --format simple --fail-level F | grep '^F:\\|=='\n}\n\nalias dotfiles=\"ls -a | grep '^\\.' | grep --invert-match '\\.DS_Store\\|\\.$'\"\nalias getcommit=\"git log -1 | cut -d ' ' -f 2 | head -n 1 | pbcopy\"\nalias vp=\"vim +PluginInstall! +qall\"\nalias sshkey=\"ssh-keygen -t rsa -b 4096 -C 'mark.mcdx@gmail.com'\"\nalias irc=\"irssi\"\nalias ls=\"ls -GpF\"\nalias ll=\"ls -laGpF\"\nalias r=\"source ~/.bashrc\"\n\neval \"$(rbenv init -)\"\neval \"$(docker-machine env dev)\"\n","tags":""},{"id":"95bc6060fbf40d00265e","title":"Flawed Golang concurrency logic: diff below shows the fixed code","content":"func someFunction {\n-\tch := make(chan aggregator.ComponentResponse)\n+\tch = make(chan aggregator.ComponentResponse, len(components.Components))\n\n \tfor i, v := range components.Components {\n \t\twg.Add(1)\n\t\tgo getComponent(i, v)\n-\t\tcr = append(cr, \u003c-ch)\n \t}\n \twg.Wait()\n+\tclose(ch)\n+\n+\tfor component := range ch {\n+\t\tcr = append(cr, component)\n+\t}\n","tags":""},{"id":"e8c418156d2330d53fab","title":"Year in Review 2015","content":"Looking back at what I achieved this year...\n\n- First and foremost: I had the pleasure of working with an incredibly talented team ([@Frost_J](https://twitter.com/Frost_J), [@dblooman](https://twitter.com/dblooman), [@charlierevett](https://twitter.com/charlierevett), [@dan_arnould](https://twitter.com/dan_arnould), [@alxnorton](https://twitter.com/alxnorton))\n- Published the book \"[Programming in Clojure](https://leanpub.com/programming-clojure/)\" and obviously from that process I've enjoyed furthering my exposure and competency within the language\n- Published a popular article about \"[Desigining for Simplicity](http://davidwalsh.name/designing-simplicity)\" for Mozilla star and all-round great dev [David Walsh](http://davidwalsh.name/)\n- My entire team [@BBCNews](https://twitter.com/BBCNews) smashed it's way through the General Elections and getting the [Newsbeat](http://www.bbc.co.uk/newsbeat) product out onto the [AWS platform](https://aws.amazon.com/) (the first *fully* AWS product from BBC News)\n- Co-author/architect for an internal BBC service (along with REST API and supporting CLI tools) that will become the front door to/and future platform for the News product. Built to be scalable, distributed and highly concurrent using Go and Ruby (along with Redis, Circuit Breakers, many different AWS services and all that good stuff)\n- My team [@BBCNews](https://twitter.com/BBCNews) (Frameworks) won the \"Connecting the News\" category at the BBC Hack Day\n- Lots of line management duties and working hard to ensure I get my colleagues promoted into senior roles (hard work with satisfying results)\n- Released an open-source program, written in Go, called (ingeniously...) [Go-Requester](https://github.com/Integralist/Go-Requester). This was a HTTP service that accepted a collection of \"components\", fans-out requests and returns aggregated content to support a component based platform architecture\n- I represented the BBC at the AWS re:Invent 2015 week-long technical conference in Las Vegas. Thanks to [@dblooman](https://twitter.com/dblooman) and [@stevenjack85](https://twitter.com/stevenjack85) for making it not only educational, but a great laugh as well\n- Published a guest article (\"[Building Software with Make](http://www.smashingmagazine.com/2015/10/building-web-applications-with-make/)\") for the popular online resource [Smashing Magazine](http://www.smashingmagazine.com/)\n- Released another [Go based open-source program](https://github.com/Integralist/ufc-event-notifier) aimed at being a long running binary for Mac OS X that scraps a specific sports website looking for an upcoming event, then triggers a native OS notification\n","tags":""},{"id":"b80617d2a70288bacd97","title":"DB migrations","content":"## Renaming or changing the type of a column\n\n- Create a new column\n- Write to both columns\n- Backfill data from the old column to the new column\n- Move reads from the old column to the new column\n- Stop writing to the old column\n- Drop the old column\n\n## Renaming a table\n\n- Create a new table\n- Write to both tables\n- Backfill data from the old table to new table\n- Move reads from the old table to the new table\n- Stop writing to the old table\n- Drop the old table\n\n## Adding a column with a default value\n\n- Add the column without a default value\n- Commit the transaction\n- Backfill the column\n- Add the default value\n","tags":""},{"id":"00450ac1debb0d243a5c","title":"[Datadog Monitoring and Metrics] ","content":"http://thenewstack.io/monitoring-101-collecting-right-data/\n\n## What is a metric?\n\nMetrics capture a value pertaining to your systems at a specific point in time.\n\nMetrics are usually collected once per second, one per minute, or at another regular interval to monitor a system over time.\n\n\u003e For different Metric Data Types and the metric names they produce see https://docs.datadoghq.com/developers/metrics/types/?tab=histogram#metric-types\n\n## Custom Metrics and High-Cardinality Tags\n\nDatadog's pricing structure is to bill custom metrics at $5/month per 100 custom metrics.\n\n**So what constitutes a 'custom metric'?** \n\n\u003e A custom metric is uniquely identified by a combination of a metric name and tag values (including the host tag). — [Datadog](https://docs.datadoghq.com/account_management/billing/custom_metrics/)\n\nThis means a metric like `request.latency` with no tags would be charged as a single 'custom metric'. \n\nWhere as if there were three tags (host, endpoint, status), then with the following combination of unique tag values, we'd end up with four custom metrics:\n\n![custom-metric](https://user-images.githubusercontent.com/180050/80495836-54281480-8960-11ea-9c3c-c9b9498be248.png)\n\nThis demonstrates how we must be careful with the cardinality of any tags we apply to our metrics.\n\nThe situation is made worse when using a `HISTOGRAM` metric type, as it ultimately produces five separate metrics. Meaning the `request.latency` example, if reported as a `HISTOGRAM`, would result in twenty custom metrics (`5 metrics * 4 tag combinations`). \n\n\u003e Note: the problem of the `HISTOGRAM` metric type can be mitigated using a `DISTRIBUTION` metric instead (see following section).\n\n## Metric Types\n\nOverall there are five distinct metric 'types' to be aware of ([docs](https://docs.datadoghq.com/developers/metrics/types/?tab=histogram#metric-types)).\n\nTwo of those metric types require additional clarification with regards to the cost implications associated with instrumenting your code to report metric data.\n\n- `HISTOGRAM`\n- `DISTRIBUTION`\n\n\u003e **Note**: there is also a `TIMER` metric type, which is a subset of `HISTOGRAM` ([docs](https://docs.datadoghq.com/developers/metrics/dogstatsd_metrics_submission/?tab=python#timer)).\n\nThe key differences between `HISTOGRAM` and `DISTRIBUTION` are...\n\n| | `HISTOGRAM` | `DISTRIBUTION` |\n| - | - | - |\n| **Multiple Metrics** | YES | YES |\n| **Percentile Aggregations** | PARTIAL | YES |\n| **Tag Filtering** | NO | YES |\n\n### Multiple Metrics\n\nThe `HISTOGRAM` metric type will generate five unique custom metrics to represent different aggregations: \n\nFor example, if you report a histogram metric `foo.bar`, then this will result in the following metrics being created (representing different aggregation types):\n\n- `foo.bar.avg`\n- `foo.bar.count`\n- `foo.bar.median`\n- `foo.bar.max`\n- `foo.bar.95percentile`\n\nThe `DISTRIBUTION` metric type will generate one metric, but provide multiple aggregations via the Datadog UI. \n\nThe aggregations for a `DISTRIBUTION` metric type are:\n\n- `max`\n- `min`\n- `avg`\n- `sum`\n- `count` \n\nNow although the `DISTRIBUTION` aggregations may well be applied to a 'single' metric, _internally_ Datadog considers each aggregation a _unique_ metric. This means at face value a `DISTRIBUTION` metric type is no more cost effective than a `HISTOGRAM` with regards to the calculation of ['custom metrics'](#custom-metrics-and-high-cardinality-tags) (as they both ultimately yield five individual metrics). But this isn't necessarily the case, as a `DISTRIBUTION` metric type has the added ability to [filter tags](#tag-filtering) thus reducing the number of calculated custom metrics.\n\n### Percentile Aggregations\n\nThe `HISTOGRAM` metric type provides a `95percentile`, while the `DISTRIBUTION` metric type _can_ provide a `p95` along with `p50`, `p75`, `p90` and `p99` but these aggregations need to be manually generated via the [Datadog UI](https://buzzfeed.datadoghq.com/metric/distribution_metrics).\n\nEach percentile aggregation for the `DISTRIBUTION` metric type is internally considered a _unique_ metric and thus is subject to Datadog's custom metric cost implications.\n\n### Tag Filtering\n\nThe `DISTRIBUTION` metric type allows tags to be filtered, thus reducing the potential number of custom metrics Datadog will charge us for. This is not possible with any other metric type.\n\n### Choosing `HISTOGRAM` or `DISTRIBUTION` ?\n\nThe fact that the `DISTRIBUTION` metric type enables tag filtering is an important consideration when choosing between it and a `HISTOGRAM`. This is why the `bf_metrics` timer abstraction (which is used to time your functions and/or code) will use the `DISTRIBUTION` metric type rather than Datadog's `TIMER` metric type (which is a subset of a `HISTOGRAM`).\n\nIt means that we're able to reduce the number of custom metrics while also allowing consumers to opt-in to percentile aggregations if they require them, and to again utilize tag filtering to help constrain the number of custom metrics.\n\nThe `DISTRIBUTION` and `HISTOGRAM` have overlapping aggregations (`count`, `avg`, `max`) which means if you do not require an aggregation outside of those specific ones, then choosing a `DISTRIBUTION` metric type would be better as you can utilize tag filtering to help reduce the number of custom metrics.\n\nIf you do require a percentile aggregation then the trade-off you need to make is between whether a `HISTOGRAM` (with `95percentile` available by default) is more cost effective than a `DISTRIBUTION` which with percentiles added will add up to more individual metrics but with tag filtering available might still end up being more cost effective overall as you can't filter your high-cardinality tags with a `HISTOGRAM`/`TIMER`.\n\n### The `DISTRIBUTION` percentile 'custom metric' conspiracy\n\nThe way Datadog calculates the number of 'custom metrics' is slightly different (and more costly) for percentile aggregations of a `DISTRIBUTION` metric type. \n\nThe `DISTRIBUTION` percentiles take into account every _potentially_ queryable varation of a metric. \n\nImagine your metric has three tags A, B and C. Datadog calculates the number of custom metrics like so:\n\n- each tag value of {A} \n- each tag value of {B}\n- each tag value of {C}\n- each tag value of {A,B}\n- each tag value of {A,C}\n- each tag value of {B,C}\n- each tag value of {A,B,C}\n- {*}\n\nDatadog's rationale for this difference is...\n\n\u003e The reason we have to store percentiles for each potentially queryable tag value combination is to preserve mathematical accuracy of your values; unlike the non-percentile aggregations which can be mathematically accurate when reaggregated (i.e the global max is the maximum of the maxes), you can't calculate the globally accurate p95 by recombining p95s.\n\n---\n\nhttps://docs.datadoghq.com/developers/dogstatsd/data_types/\n\n- Counter: track how many times something happens per N (N: seconds or minutes)\n- Gauge: \"last write wins\"\n- Histogram: when you want to understand the value over time.\n- Distribution: server-side aggregation (+ allows percentile generation for only specific tags).\n\n\u003e **Note**: When thinking about 'guages': imagine many processes sending a gauge for a moment in time. Which one do you record? A histogram can correctly record the distribution of those values.\n\n### Warning about Custom Metrics \n\n\u003e Distribution metrics with percentile aggregations (p50, p75, p90, p95, p99) generate custom metrics or timeseries differently than gauges, counts, histograms, and distributions with nonpercentile aggregations (sum, count, min, max, avg). Because percentiles aren’t reaggregatable, Datadog preserves five timeseries for every potentially queryable tag combination. -- Datadog Docs\n\nUltimately this means that if you used a normal timing metric (which is a sub-set of a histogram) then you'd get five custom metrics created (and for each one you'd have to be mindful of any tags as that will increase the custom metric numbers as we mentioned earlier), but with a distribution metric you're able to have it ignore all tags except for specific tags you specify which can help reduce the number of metrics.\n\n- **Timer metric** (a sub-set of Histogram) generates five custom metrics: `count`, `avg`, `median`, `max`, `95percentile` (each will then be multiplied by the number of unique tag combinations).\n- **Distribution metric** generates five custom metrics (in its default mode, i.e. non-percentile mode): `max`, `min`, `avg`, `sum`, `count` (each will then be multiplied by the number of unique tag combinations). If we calculate percentiles for the distribution metric this results in an additional five custom metrics for the percentiles: `p50`, `p75`, `p90`, `p95`, `p99` (again, each will then be multiplied by the number of unique tag combinations).\n\nMy understanding is that if we recorded a metric called `foo.bar`, then...\n\n- `foo.bar` is itself considered a **_single_** custom metric (multiplied by any available 'tags')\n- while the percentile aggregation will generate five **_additional_** custom metrics (again, multiplied by any available 'tags')\n\n## What should we check?\n\nFor a particular 'work metric' you would check the corresponding 'resource metric'.\n\n| Work Metrics | Resource Metrics | Events |\n|---|---|---|\n| Throughput | Utilization | Code Changes |\n| Success | Saturation | Alerts |\n| Error | Error | Scaling Events |\n| Performance | Availability | ... |\n\nWork metrics indicate the top-level health of your system by measuring its useful output\n\nResource metrics (CPU, memory, disks, and network interfaces) are especially valuable for investigation and diagnosis of resource problems\n\nThere are a few other types of metrics that are neither work nor resource metrics, but that nonetheless may come in handy in diagnosing causes of problems. Common examples include counts of cache hits or database locks\n\nIn addition to metrics, which are collected more or less continuously, some monitoring systems can also capture events: discrete, infrequent occurrences that can provide crucial context for understanding what changed in your system’s behavior\n","tags":"#datadog #metrics #monitoring #cost"},{"id":"2225a8b2c3e12c92757f","title":"Ruby Alephant JSON Logger","content":"require \"alephant/logger\"\nrequire \"pry\"\n\n# Setup logger (mandatory first step)\nAlephant::Logger.setup\n\n# Store off the logger\nlogger = Alephant::Logger.get_logger\n\n# Defaults to app.log\nlogger.info(\"event\" =\u003e \"foo\")\n\n# {\"event\":\"foo\",\"level\":\"info\",\"timestamp\":\"2015-12-18 15:51:47 +0000\"}\ndefine_method(level) do |hash|\n  ...\n  \n  hash[\"timestamp\"] = Time.now.to_s\n  \n  ...\nend\n","tags":""},{"id":"a625dd7d7c0d07bf1ad6","title":"Simple check for git repo in Bash","content":"function git_environment() {\n  $(git rev-parse --is-inside-work-tree \u003e\u0026 /dev/null)\n\n  if [ \"$?\" -eq \"128\" ]; then\n    git_branch=\"\"\n  else\n    git_branch=\" ($(git branch | grep '^*' | cut -d ' ' -f 2))\"\n  fi\n}\n\necho $git_branch\n","tags":""},{"id":"0e277a517fee68153f93","title":"OAuth","content":"OAuth is a mechanism that allows a user to authorize your application to access his/her data from another service without giving you their authentication details.\n\nFor a banking monitoring application (e.g. your application reads the user's banking data and displays it within some useful diagrams), the steps could look something like the following:\n\n1. User requests API action from your application (e.g. show me my spending graph)\n2. Your application requests access to your bank\n3. User's bank service tells the users your application would like access to it\n4. User accepts or declines the request to access your banking data\n5. The bank provides a temporary code to your application\n6. Your app requests a token while passing back the code it was given from the bank\n7. Banking service verifies the code is a match/valid and provides a token\n8. Your app can now request data from the bank using the provided token\n \n## GitHub API\n\n- User is on your website and clicks “login with GitHub” link\n- Your app redirects user to GitHub’s authorization page\n- In that url you specify desired access level and a random secret\n- The user authorizes your app by clicking on a link\n- GitHub redirects to a callback url on your website (which you provided when registering the app with GitHub)\n- In the url handler, extract \"secret\" and \"code\" arguments\n- Your app checks that the secret is the same as the one you sent to GitHub\n- Your app calls another GitHub url to exchange code for access token\n- Your app uses the access token to authenticate your API calls\n\n### Steps for Application\n\n- Register your app with GitHub (https://github.com/settings/applications/new)\n- Set Homepage url to `http://127.0.0.1:5000/`\n- Set authorization callback url to `http://127.0.0.1:5000/github_oauth_cb`\n- In your code specify your `Client ID` and `Client Secret` (provided by GitHub when registering your app)\n\n### Steps for User\n\n- User should be logged into GitHub (if not they'll have to enter their username/password when asked by GitHub)\n- User visits your application (which in this example is a locally running Go application)\n- User clicks on \"Login with GitHub\"\n- User is directed to a GitHub page that asks them to confirm your registered app is OK to access their data\n- User is asked by GitHub to confirm access by entering their password\n- Your application has the token it needs and redirects the user back to the login page (but change this behaviour in your application accordingly)\n\n### Notes\n\nIf you restart your application (see below for code), and the user goes back to the `/login` page, then clicking on the login button will attempt to access the token and realise it already exists and so redirects back to the login page again. Check the console/terminal output for user details that have been printed.\n\nThe user should now be able to see your application listed in their authorized applications: https://github.com/settings/applications\n\n## Application Code\n\nhttps://blog.kowalczyk.info/article/f/Accessing-GitHub-API-from-Go.html\n\n```go\npackage main\n\nimport (\n\t\"fmt\"\n\t\"net/http\"\n\n\t\"github.com/google/go-github/github\"\n\t\"golang.org/x/oauth2\"\n\tgithuboauth \"golang.org/x/oauth2/github\"\n)\n\nvar (\n\t// You must register the app at https://github.com/settings/applications\n\t// Set callback to http://127.0.0.1:5000/github_oauth_cb\n\t// Set ClientId and ClientSecret values taken from GitHub registration page\n\t// Note: revoked the already details\n\toauthConf = \u0026oauth2.Config{\n\t\tClientID:     \"x\",\n\t\tClientSecret: \"x\",\n\t\tScopes:       []string{\"user:email\", \"repo\"},\n\t\tEndpoint:     githuboauth.Endpoint,\n\t}\n\t// random string for oauth2 API calls to protect against CSRF\n\toauthStateString = \"thisshouldberandom\"\n)\n\nconst htmlIndex = `\u003chtml\u003e\u003cbody\u003e\nLogin with \u003ca href=\"/login\"\u003eGitHub\u003c/a\u003e\n\u003c/body\u003e\u003c/html\u003e\n`\n\n// /\nfunc handleMain(w http.ResponseWriter, r *http.Request) {\n\tw.Header().Set(\"Content-Type\", \"text/html; charset=utf-8\")\n\tw.WriteHeader(http.StatusOK)\n\tw.Write([]byte(htmlIndex))\n}\n\n// /login redirects to GitHub’s authorization page:\n// GitHub will show authorization page to your user\n// If the user authorizes your app, GitHub will re-direct to OAuth callback\nfunc handleGitHubLogin(w http.ResponseWriter, r *http.Request) {\n\turl := oauthConf.AuthCodeURL(oauthStateString, oauth2.AccessTypeOnline)\n\thttp.Redirect(w, r, url, http.StatusTemporaryRedirect)\n}\n\n// /github_oauth_cb. Called by GitHub after authorization is granted\n// This handler accesses the GitHub token, and converts the token into a http client\n// We then use that http client to list GitHub information about the user\nfunc handleGitHubCallback(w http.ResponseWriter, r *http.Request) {\n\tstate := r.FormValue(\"state\")\n\tif state != oauthStateString {\n\t\tfmt.Printf(\"invalid oauth state, expected '%s', got '%s'\\n\", oauthStateString, state)\n\t\thttp.Redirect(w, r, \"/\", http.StatusTemporaryRedirect)\n\t\treturn\n\t}\n\n\tcode := r.FormValue(\"code\")\n\ttoken, err := oauthConf.Exchange(oauth2.NoContext, code)\n\tif err != nil {\n\t\tfmt.Printf(\"oauthConf.Exchange() failed with '%s'\\n\", err)\n\t\thttp.Redirect(w, r, \"/\", http.StatusTemporaryRedirect)\n\t\treturn\n\t}\n\n\toauthClient := oauthConf.Client(oauth2.NoContext, token)\n\tclient := github.NewClient(oauthClient)\n\tuser, _, err := client.Users.Get(\"\")\n\tif err != nil {\n\t\tfmt.Printf(\"client.Users.Get() faled with '%s'\\n\", err)\n\t\thttp.Redirect(w, r, \"/\", http.StatusTemporaryRedirect)\n\t\treturn\n\t}\n\tfmt.Printf(\"Logged in as GitHub user: %s\\n\", *user.Login)\n\thttp.Redirect(w, r, \"/\", http.StatusTemporaryRedirect)\n}\n\nfunc main() {\n\thttp.HandleFunc(\"/\", handleMain)\n\thttp.HandleFunc(\"/login\", handleGitHubLogin)\n\thttp.HandleFunc(\"/github_oauth_cb\", handleGitHubCallback)\n\tfmt.Print(\"Started running on http://127.0.0.1:5000\\n\")\n\tfmt.Println(http.ListenAndServe(\":5000\", nil))\n}\n```\n\n## Handling State\n\nIf you want your user state to be persistent, then you would need to store it in a permanent/persistent store; there are lots of options for that (e.g. a distributed redis cluster - so the data is available across machines and allows your web servers to scale horizontally)\n\nThis also means you’ll need to handle your own authentication and / or authorization in your web app to use that persistent data in order to make those upstream requests on behalf of a specific user.\n\nYou could also keep a cookie in the browser (encrypted and hashed) with the token and some basic user info. But I'm not overly confident with using cookies.\n","tags":""},{"id":"c5f3bfa368cb1dc7ce51","title":"Semantic Versioning Explanation","content":"```\n1.2.3-beta.1+meta\n```\n\n- `1`: Major\n- `2`: Minor\n- `3`: Patch\n- `beta.1`: Pre-release\n- `meta`: Metadata\n\n## Major\n\nThe major number is incremented when the API to the package or application changes in backwards incompatible ways.\n\n## Minor\n\nThe minor number is incremented when new features are added to the API without breaking backwards compatibility. If the major number is incremented the minor number returns to 0.\n\n## Patch\n\nThe patch number is incremented when no new features are added but bug fixes are released. If the major or minor numbers are incremented this returns to 0.\n\n## Pre-release\n\nA pre-release is a . separated list of identifiers following a `-`. For example, `1.2.3-beta.1`. These are optional and are only needed for pre-release versions. In this case 1.2.3 would be a release version following a pre-release like `1.2.3-beta.1`.\n\n## Metadata\n\nThe final section of information is build metadata. This is a . separated list of identifiers following a +. This is different from pre-release information and should be ignored when determining precedence.\n","tags":""},{"id":"e785c93566f96e1fcaf4","title":"Ruby Decorator Design Pattern for BBC: with a little imagination you can see how we could store data in S3 instead of \"printing\" it to the screen AND also how we could have some models extend based on a whitelist (as some components you'll want to extend ALL formatters, and other components you'll only want to extend from one or two formatters)","content":"require \"json\"\n\nmodule HtmlFormatter\n  def render\n    p \"\u003cp\u003eHTML content\u003c/p\u003e\"\n    super\n  end\nend\n\nmodule JsonFormatter\n  def render\n    p JSON.generate :foo =\u003e :bar\n    super\n  end\nend\n\nmodule EnvelopeFormatter\n  def render\np \u003c\u003cEOF\n{\n  \"head\": [\n    \"\u003clink ... /\u003e\",\n    \"\u003clink ... /\u003e\",\n    \"\u003cmeta ... /\u003e,\",\n    \"\u003cscript ... /\u003e\"\n  ],\n  \"bodyInline\": \"\u003cp\u003eSome HTML here\u003c/p\u003e\",\n  \"bodyLast\": [\n    \"\u003cscript\u003ealert('script A');\u003c/script\u003e\",\n    \"\u003cscript\u003ealert('script B');\u003c/script\u003e\"\n  ]\n}\nEOF\n    super\n  end\nend\n\nclass Model\n  def render\n    p \"Plain Text\"\n  end\nend\n\ncomponent = Model.new\n\ncomponent.extend(HtmlFormatter)\ncomponent.extend(JsonFormatter)\ncomponent.extend(EnvelopeFormatter)\n\ncomponent.render\n\n=begin\n\"{\\n  \\\"head\\\": [\\n    \\\"\u003clink ... /\u003e\\\",\\n    \\\"\u003clink ... /\u003e\\\",\\n    \\\"\u003cmeta ... /\u003e,\\\",\\n    \\\"\u003cscript ... /\u003e\\\"\\n  ],\\n  \\\"bodyInline\\\": \\\"\u003cp\u003eSome HTML here\u003c/p\u003e\\\",\\n  \\\"bodyLast\\\": [\\n    \\\"\u003cscript\u003ealert('script A');\u003c/script\u003e\\\",\\n    \\\"\u003cscript\u003ealert('script B');\u003c/script\u003e\\\"\\n  ]\\n}\\n\"\n\"{\\\"foo\\\":\\\"bar\\\"}\"\n\n\"\u003cp\u003eHTML content\u003c/p\u003e\"\n\n\"Plain Text\"\n=end\n","tags":""},{"id":"8058ac54088408d9aadc","title":"Ruby Fail vs Raise","content":"## Raise\n\n\u003e Use `raise` instead of `fail` to *rethrow* exceptions\n\nThis means if you catch an error that's been thrown by an external gem/library then you can choose to re-throw it as a different exception (i.e. your own Exception error, named specifically relevant to your application)\n\n## Fail\n\n\u003e Use `fail` instead of `raise` to *signal* exceptions\n\nThis means if you catch an error that's been thrown by your own code (e.g. you've raised a custom error/exception), then this means you don't intend to re-throw the exception as something else, you'll instead deal with that exact exception now\n","tags":""},{"id":"b3621d6ed0f46901f200","title":"Guitar Music Theory","content":"## Table of Contents\n\n- [Strings](#strings)\n- [Fretboard](#fretboard)\n- [Intervals](#intervals)\n  - [Quantity](#quantity)\n  - [Quality](#quality)\n- [Scales](#scales)\n  - [Chromatic](#chromatic)\n  - [Diatonic](#diatonic)\n  - [Major](#major)\n  - [Minor](#minor)\n    - [Natural Minor Scale](#natural-minor-scale)\n    - [Melodic Minor Scale](#melodic-minor-scale)\n    - [Harmonic Minor Scale](#harmonic-minor-scale)\n  - [Pentatonic](#pentatonic)\n    - [Major](#major-1)\n    - [Minor](#minor-1)\n  - [Circle of Fifths](#circle-of-fifths)\n- [Accidentals](#accidentals)\n- [Fret spacing for Intervals](#fret-spacing-for-intervals)\n- [Modes](#modes)\n  - [Ionian](#ionian)\n  - [Dorian](#dorian)\n  - [Phrygian](#phrygian)\n  - [Lydian](#lydian)\n  - [Mixolydian](#mixolydian)\n  - [Aeolian](#aeolian)\n  - [Locrian](#locrian)\n- [Chords](#chords)\n  - [Progressions](#progressions)\n  - [Example Progressions](#example-progressions)\n  - [Formulas](#formulas)\n  - [Sevenths](#sevenths)\n  - [Triads](#triads)\n  - [Augmented/Diminished](#augmenteddiminished)\n  - [Names and Symbols](#names-and-symbols)\n  - [Learning Order](#learning-order)\n  - [Families](#families)\n  - [Relative Chords](#relative-chords)\n- [Timings](#timings)\n- [Example Chords](#example-chords)\n- [Other Chords](#other-chords)\n  - [Power Chords](#power-chords)\n  - [Suspended Chords](#suspended-chords)\n  - [6th](#6th)\n  - [Slash Chords (e.g. C6/9)](#slash-chords-eg-c69)\n  - [Diminished 7th](#diminished-7th)\n  - [9th](#9th)\n  - [11th](#11th)\n  - [13th](#13th)\n- [Voicings, Inversions and Drop Voicings](#voicings-inversions-and-drop-voicings)\n  - [Inversions](#inversions)\n  - [Drop Voicings](#drop-voicings)\n  - [Table Example](#table-example)\n- [Improvisation](#improvisation)\n\n## Strings\n\nLet's start by learning the strings of the guitar.\n\nThere are 6 strings on most traditional guitars † \n\n\u003e † there are also 7 and 8 string guitars nowadays too\n\nFor 6 string guitars you'll have three 'bass' strings and three 'treble' strings.\n\nBass strings have a lower sound, and treble strings provide a higher pitch/sound.\n\nThe strings are numbered 1 to 6 (1 being the highest sounding note and 6 being the lowest sounding note).\n\nThe strings have letters associated with them to indicate the particular note they're tuned to.\n\nSo in a 'standard tuning' the guitar strings would be (counting backwards):\n\n- 6. E (the _low_ E string)\n- 5. A\n- 4. D\n- 3. G\n- 2. B\n- 1. E (the _high_ E string)\n\nThe best way to remember this is to assign a mnemonic such as:\n\n- (E)lephants\n- (A)nd\n- (D)ragons\n- (G)row\n- (B)ig\n- (E)ars\n\nThe above example mnemonic always worked for me, but feel free to choose one that works best for you.\n\nBefore we move on, you just need to know that when discussing the frets on the guitar's fretboard (the 'fret' refers to each of the metal bars that are placed across the guitar's neck underneath the strings), the fret nearest the top of the guitar is the _first_ fret, followed by the second fret and the third fret and onwards. \n\n\u003e **NOTE:** some guitars have more 'frets' than other guitars\n\nOK, now we know the strings of the guitar we'll just jump straight into understanding the guitar's fretboard...\n\n## Fretboard\n\nTo understand the fretboard you need to know that in music there are twelve 'pitches'. \n\nEach one a semi-tone above or below the another.\n\nHere are those 12 tones:\n\n```\nA, A♯, B, C, C♯, D, D♯, E, F, F♯, G, G♯\n```\n\nThe first thing to notice is that the complete musical range is really just the first 7 letters of the alphabet.\n\nThat's easy to memorise :-)\n\nThe next thing to notice is that `B` and `E` are the only notes that have no sharp `♯`. \n\nOK, that's easy to memorise as well.\n\nWith that out of the way, let's get an overview of the fretboard...\n\n| Frets \u003e | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 | 10 | 11 | 12 |\n|---|---|---|---|---|---|---|---|---|---|---|---|---|\n| 1 (**E**) | F | F♯ | G | G♯ | A | A♯ | B | C | C♯ | D | D♯ | E |\n| 2 (**B**) | C | C♯ | D | D♯ | E | F | F♯ | G | G♯ | A | A♯ | B |\n| 3 (**G**) | G♯ | A | A♯ | B | C | C♯ | D | D♯ | E | F | F♯ | G |\n| 4 (**D**) | D♯ | E | F | F♯ | G | G♯ | A | A♯ | B | C | C♯ | D |\n| 5 (**A**) | A♯ | B | C | C♯ | D | D♯ | E | F | F♯ | G | G♯ | A |\n| 6 (**E**) | F | F♯ | G | G♯ | A | A♯ | B | C | C♯ | D | D♯ | E |\n\nI found the best way to learn the fretboard is to find a pattern.\n\n\u003e **NOTE:** print out the above 'overview', grab a pen and look for patterns like you would use a [wordsearch](https://en.wikipedia.org/wiki/Word_search)\n\nOne pattern is to literally count three notes up from the current note. So if you're on A and you want to know the note next to it on the next string (this would be D) then count up three letters from A (i.e. B, C, D). This works well enough but it's a bit slow and also doesn't account for the high treble B string which is tunes a half-step lower. Read on to learn the pattern I use to help me speed up the process of identifying the note on the strings and also accounting for the B string.\n\nThe pattern I used was to learn the notes on the top two strings (the low E and low A strings) and to assign mnemonics to them. This made it easier for me to identify them and then this led me onto discovering that these same adjacent notes also appeared _across_ the fretboard (making it easier for me to figure out where notes appear).\n\nFor example:\n\n- 1st fret \u003e `F|A♯`: I think of the FA cup (a football association)\n- 2nd fret \u003e`F♯|B`: I think of Facebook\n- 3rd fret \u003e`G|C`: I think of Garbage Collection (as in the programming concept)\n- 5th fret \u003e`A|D`: I think of After Death (as in [Anno Domini](https://en.wikipedia.org/wiki/Anno_Domini))\n- 7th fret \u003e `B|E`: As this is just an English word (\"be\"), I always remember B to be followed by an E\n- 8th fret \u003e `C|F`: I think of Cloud Formation (a programming related term)\n- 10th fret \u003e `D|G`: I think of Director General\n- 12th fret `E|A`: I think of the game company EA Sports †\n\nYou might wonder why I don't think of mnemonics for notes such as found on the 4th fret (`G♯|C♯`), 6th fret (`A♯|D♯`), 9th fret (`C♯|F♯`) and the 11th fret (`D♯|G♯`)? Well, that's because I don't need to. If we look at the 3rd fret, as an example, we see `G|C` so I know the next note up from `G` will be `G♯` and so I know on the next adjacent string the `C` will subsequently become `C♯` (and the same applies for the 6th, 9th and 11th frets).\n\nNow, the above mnemonics _won't_ work for you. They work _for me_ because they make sense to me. You need to choose something that makes the most sense for you. A few days of just looking at your guitar randomly throughout the day and identifying the notes on the top two bass strings (or if you're at work: just grabbing a pen and paper and writing down the notes) and you'll have them memorised.\n\n---\n\n† a moment ago I said...\n\n\u003e \"I think of the game company EA Sports\"\n\n...this actually led me to realise, that at the 12th fret the notes would match the name of the strings. These notes were an 'octave' higher than the open string notes (e.g. play the strings without any frets pressed down and you'll hear the 'open' notes). \n\nFrom here I would realised there was a pattern I could use:\n\n\u003e the notes of the top two bass strings would appear in that order across the fretboard!\n\nLet's put this into practice...\n\nIf we look at the 5th fret we see an `A`. \n\nOK, but now can you guess the note on the next string along at the 5th fret? \n\nWell if we've memorised the top two bass strings then yes, we'll know it is a `D`. \n\nFrom there I noticed the note on the _next_ string along after that (we're still at the 5th fret for this example) was a `G` note. Further down the fretboard we already memorised that `D` would be followed by a `G` and here it is again. \n\nThanks to memorising the top two bass strings we see those memorised collection of notes appearing as patterns elsewhere on the fretboard!\n\nOK at this point we're now at a `G`, and we already know that on the low E string when we had a `G` we memorised that a `C` would be next to it. So coming back to the 5th fret of the 4th string, when we come across the `G` note we shouldn't be too surprised to find the adjacent string's 5th fret note (the 3rd treble string) will be a `C` note. \n\nLet's continue on, the 5th fret of the 3rd string should then have an `F` on the adjacent `B` string right? As this is what we memorised from the top two bass strings (`C` is followed by `F`: \"Cloud Formation\" was the mnemonics I used). Well if that's what we were expecting we'd be wrong. It's actually an `E` note and not an `F`!\n\nCrap! Has our pattern failed? No, it hasn't.\n\nThe reason the pattern didn't work for the `B` string is because the `B` string is the black sheep of the family.\n\nLet me explain:\n\nEach string is tuned a 4th higher from the preceding string. But the `B` string is the only string that isn't tuned to a 4th. It's actually a _half step_ lower than expected (i.e. it is flattened) and is tuned to a 3rd degree. \n\nSo where I'd expect a `F` note on the string adjacent to the `C`. If we were to lower the `F` by a half-step we'd actually get an `E` note. \n\nSo in principle the pattern of the adjacent note following the memorised notes from the top two bass strings does kinda hold still, but it means for the `B` string you have to realise the adjacent note will be a half-step lower than the expectation.\n\nNow what happens from here? Well the pattern continues on as it did before.\n\nSo if we now consider the next string along. We're at a `E` note currently on the 5th fret of the `B` string. \n\nThe adjacent string is the high `E` string, and at the fifth fret will be an `A` note. As per our pattern, we memorised \"EA Sports\". We know an `E` will be followed by an `A`. \n\n\u003e The low E and the high E strings have the same notes\n\nFinally, phew, if you're looking at a note on a string and you've already memorised the notes for the top two bass strings then you can also work _backwards_ easily enough. \n\nFor example, if you're looking at the 8th fret of the high E string we'll already know this is a `C` note (as it matches what we've memorised on the low E string). So the note on the adjacent string preceding it (the `B` string), the note will be a `G` (as we've memorised already that `G` is followed by `C`).\n\n---\n\nThis all can take some time to soak in. So what might be useful to you is to look again at the overlay of fretboard notes (see above) and just treat it like a word search puzzle. What _patterns_ do you see that make sense to you? Find something that works and use it.\n\nI personally found that memorising the notes of the top two bass strings, along with the string names, helped me identify a pattern that worked across the fretboard.\n\nOK, so at this point we'll soon have an understanding of the notes on the fretboard and where they appear. But we'll now need to understand the relationship these notes have with a particular musical scale and the language used to define what makes up a musical scale.\n\nThe first step is to understand what an 'interval' is...\n\n## Intervals\n\nAn interval is the musical distance between two notes.\n\nIntervals have two parts:\n\n1. Quantity\n2. Quality\n\n### Quantity\n\nQuantity is the number of scale steps (degrees) in the [major scale](#major).\n\n\u003e **NOTE:** we'll look at what the major scale is and the notes it consists of in the next section, but for now I want you to know that memorising the major scale is important. The biggest help is when you want to construct a chord (even if it's a minor or dominant sounding chord - both we'll discuss later - you'll _still_ use the major scale to construct the chord)\n\nThe sequence of intervals between the notes of the major scale is:\n\n```\nW, W, H, W, W, W, H\n```\n\nThe `W` represents a whole-step, which equates to 2 frets on the guitar fretboard.  \nThe `H` represents a half-step, which equates to 1 fret on the guitar fretboard.\n\nThe following example demonstrates the `A` major scale, showing the quantity (steps/degrees) along with the intervals:\n\n| INTERVALS |   | W | W  | H | W | W  | W  | H |\n| ---       |---|---|--- |---|---|--- |--- |---|\n| **SCALE NOTES**     | A | B | C♯ | D | E | F♯ | G♯ | A |\n| **DEGREES**   | 1 | 2 | 3  | 4 | 5 | 6  | 7  | 8 |\n\nNotice the `A` has no interval. That is because it is the _root_ note. It is what starts the scale. From there you move a set number of degrees (using the specified interval) to make up the rest of `A`'s musical 'scale'.\n\nNow don't worry about why there are specific notes being shown, we'll learn about this in the next section when we look at [scales](#scales) in more depth. But you might be wondering about the `♯` symbol? This is where the second part of an interval comes in, the symbol after the note will indicate the _quality_ of the note being played...\n\n### Quality\n\nThe quality simply finalizes the actual note to be played by either adding/removing a sharp/flat.\n\nIn music, you can take a note such as `A` and either sharpen its tone so it becomes `A♯`; or you can flatten its tone so it becomes `A♭`. The act of sharpening or flattening a note is to move either up or down 1 fret from the note on the guitar's fretboard.\n\n\u003e Later on you'll see that some notes can be named different things even though they have the same tone (or 'sound'). For example an `A♯` can also be referred to as a `B♭`. We'll cover it later in more detail, but the only time it becomes relevant is when you're constructing music on sheet. This is because in some scenarios you could have a chord made up of multiple notes and need to construct a chord that has two `A` notes, which (on sheet music) isn't allowed. So for example, if you needed a chord constructed of both `A` and `A♯` notes, then on sheet music that wouldn't make sense so you would have to write it as `A` and `B♭` instead\n\nTo demonstrate this, look at the 5th fret down from the top of your guitar's fretboard. When pressing your finger down on the low E string at the 5th fret and strumming the string, you'll be playing an `A` note (assuming your guitar is in '[standard tuning](https://en.wikipedia.org/wiki/Standard_tuning)').\n\nIf you now move your finger one fret 'up' (up in this case being towards to the top of your guitar's head), then you would have flattened the `A` note so it sounded lower than before. You'll be playing an 'A flat' `A♭`.\n\nIf (from the 5th fret again) you move your finger one fret 'down' (down in this case being away from the top of your guitar's head), then you would have sharpened the `A` note so it sounded higher in tone than before. You'll be playing an 'A sharp' `A♯`.\n\nThis is the fundamental principle behind the 'quality' of a note being played.\n\nWhich leads us to the next point you should know, which is that there are three *types* of note qualities:\n\n1. Major\n2. Minor\n3. Perfect\n\nHere is the complete quality list...\n\n- Perfect Unison: root note\n- Minor Second: 1 half step\n- Major Second: 2 half steps\n- Minor Third: 3 half steps\n- Major Third: 4 half steps\n- Perfect Fourth: 5 half steps\n- Augmented Fourth / Diminished Fifth (Tritone): 6 half steps\n- Perfect Fifth: 7 half steps\n- Minor Sixth: 8 half steps\n- Major Sixth: 9 half steps\n- Minor Seventh: 10 half steps\n- Major Seventh: 11 half steps\n- Perfect Octave: 12 half steps \n\nTo visualise this, let's look at the guitar. Strings 1 (Low E) to 6 (High E) and each `|` visually represents the string followed by the interval quality...\n \n```\n1    2       3    4    5    6\n-----------------------v flattened string\n| 1  | 4     | m7 | m3 | 5  | 1\n| m2 | a4/d5 | 7  | 3  | m6 | m2\n| 2  | 5     | 1  | 4  | 6  | 2 \n```\n\n\u003e **NOTE:** You'll notice the fifth string (B) is flattened by a half-step.\n\nNow the following information is related to qualities and scales and might not be immediately useful, and so if it's a bit too much to memorise/digest, feel free to come back to it at a later time.\n\nWhen we talk about a scale, we typically talk about a particular 'degree'.\n\nFor example, \"play the 1st (root), 3rd and 5th degrees of the major scale\".\n\nThe 2nd, 3rd, 6th, 7th steps/degrees of the major scale are called 'major':\n\n- Major Second\n  - Equal to playing 1 whole-step from the root note\n- Major Third\n  - Equal to playing 2 whole-steps from the root note\n- Major Sixth\n  - Equal to playing 4 whole-steps and then 1 half-step from the root note\n- Major Seventh\n  - Equal to playing 5 whole-steps and then 1 half-step from the root note\n  \nLook again at the table of intervals/scales/degrees earlier to see how the above information aligns with it.\n\nBut whether something is major can also depend on the scale being played (e.g. C harmonic minor has two flat notes and so they're a Minor Third and a Minor Sixth).\n  \n\u003e The notes of the musical scale appear across all the strings. So for example, the 10th fret (low E string) is a `D` note. We could play the `D` note on the low A string (the 5th string) by pressing down on the A string at the 5th fret. We'll come back to the [notes across the fretboard a later](https://gist.github.com/Integralist/b3621d6ed0f46901f200#fretboard)\n\nThe 1st, 4th, 5th, 8th steps/degrees of the major scale are called perfect in quality:\n\n- Perfect Unison\n  - Unison is the same note played twice (but basically, it's the root note)\n- Perfect Fourth\n  - Every string is a 4th higher than the one below it\n  - Except `B` string which is a Major 3rd higher\n- Perfect Fifth\n  - Same note as found 5 frets on the adjacent (higher) string\n  - Except `B` string whose same note is 4 frets on higher string\n- Perfect Octave\n  - Octave is the name of the same note played at a higher frequency\n\nThe way I tend to remember this is: \n\n\u003e Everything is \"major\" except the 1, 4, 5 progression \n\nIf you don't know what the 1, 4, 5 progression is don't worry as we'll [cover that progression later](#blues). But for now all you need to know is that it is **THE** most well known progression in guitar music (so once you know the numbers you wont forget them). \n\nYou might say now, well what about the 8 (the Perfect Octave) how do you remember that is 'perfect' when it's not part of the 1, 4, 5 progression? Well it's just an octave higher than the 1 so it's generally easy to remember as you already know 1 is in the 1, 4, 5 progression so just think of the octave of 1 (again, don't worry too much about this as it's not really going to make a massive difference in learning how to play guitar at this stage).\n\n## Scales\n\n\u003e It's important to note that scales don't describe any natural phenomenon but are just human invention - you can make up any scale that you want, and even simply ignore the concept of scales, and it won't make a difference.\n\n- [Chromatic](#chromatic)\n- [Diatonic](#diatonic)\n- [Major](#major)\n- [Minor](#minor)\n  - [Natural Minor Scale](#natural-minor-scale)\n  - [Melodic Minor Scale](#melodic-minor-scale)\n  - [Harmonic Minor Scale](#harmonic-minor-scale)\n- [Pentatonic](#pentatonic)\n- [Enharmonic](#enharmonic)\n- [Circle of Fifths](#circle-of-fifths)\n\n### Chromatic\n\nThe chromatic scale is a musical scale with twelve pitches, each a semi-tone above or below another:\n\n```\nA, A♯, B, C, C♯, D, D♯, E, F, F♯, G, G♯\n```\n\n\u003e **NOTE:** all the 'intervals' are half-steps\n\n### Diatonic\n\nThe diatonic scale is a musical scale with seven pitches (also known as 'heptatonic'), that are adjacent to one another on the circle of fifths.\n\n```\nA, B, C, D, E, F, G\n```\n\nThe sharps and flats (which you saw as part of the chromatic scale) are not included as they are 'non-diatonic' notes.\n\nHere are some examples...\n\nThe `B` diatonic scale:\n\n```\nB, C, D, E, F, G, A\n```\n\nThe `C` diatonic scale:\n\n```\nC, D, E, F, G, A, B\n```\n\n### Major\n\nThe major scale (or [Ionian](#ionian) scale), like many musical scales, is made up of seven notes: the eighth duplicates the first at double its frequency, so it is referred to as a 'higher octave' of the same note.\n\nThe simplest major scale to write is C major, as it's the only major scale not to require sharps (♯) or flats (♭):\n\n```\nC, D, E, F, G, A, B\n```\n\nHere is another major scale, but in the key of `B`:\n\n```\nB, C♯, D♯, E, F♯, G♯, A♯, B (octave higher)\n```\n\nHere it is again, shown alongside the major scale intervals:\n\n|  | W | W | H | W | W | W | H |\n|---|---|---|---|---|---|---|---|\n| B | C♯ | D♯ | E | F♯ | G♯ | A♯ | B |\n\nHere is one more example (in the key of `F`) that demonstrates the purpose of both ♯/♭ (see [Accidentals](#accidentals) below):\n\n```\nF, G, A, B♭, C, D, E, F (octave higher)\n```\n\nHere it is again, shown alongside the major scale intervals and degrees:\n\n| INTERVALS |   | W | W | H | W | W | W | H |\n| ---       |---|---|--- |---|---|--- |--- |---|\n| **SCALE**     | F | G | A | B♭ | C | D | E | F |\n| **DEGREES**   | 1 | 2 | 3 | 4 | 5 | 6  | 7  | 8 |\n\nThe important thing to note here is that the scale notes have to be in alphabetical order (meaning you can't have two notes from the same letter). \n\nSo you can see that the half-step from `A` doesn't make sense because that would result in an `A♯`.\n\nSo we need the tone to be a `B`, which means moving a half-step down from there gives us `B♭` not `A♯`.\n\nThis becomes more important when you consider sheet music and how the key signature clef defines the sharps/flats for each note. You can't have a note be both sharp and flat and so flattening the `B` allows the clef to be clear on the tones (although their pitch *sounds* the same they are considered different tones/notes)\n\n### Minor\n\nThe minor scale (or [Aeolian](#aeolian) scale) is one of the diatonic scales.\n\nIt's also more commonly known as the \"natural minor scale\". This is because there are two other forms of minor scale that differ very slightly and so we need a way to identify them. There's also the \"melodic minor scale\" and the \"harmonic minor scale\".\n\n#### Natural Minor Scale\n\nThe `Am` (A minor) scale:\n\n```\nA, B, C, D, E, F, G, A (octave higher)\n```\n\n\u003e **NOTE:** musical notes are typically written \n\u003e with an `m` to indicate a 'minor' \n \nThe sequence of intervals between the notes of a minor scale is:\n\n```\nW, H, W, W, H, W, W\n```\n\n\u003e **NOTE:** these intervals are the same as the major scale,  \n\u003e but notice the last two intervals are now shifted over to the start  \n\nHere is the same intervals represented in notes:\n\n```\n1 2 ♭3 4 5 ♭6 ♭7 8\n```\n\nHere it is again, shown alongside the minor scale intervals and degrees:\n\n| INTERVALS |   | W | H | W| W | H | W | W |\n| ---       |---|---|--- |---|---|--- |--- |---|\n| **SCALE**     | A | B | C | D | E | F | G | A |\n| **DEGREES**   | 1 | 2 | 3 | 4 | 5 | 6  | 7  | 8 |\n\nHere is another minor scale, but in the key of `B`:\n\n```\nB, C♯, D, E, F♯, G, A, B (octave higher)\n```\n\nHere it is again, shown alongside the minor scale intervals and degrees:\n\n| INTERVALS |   | W | H | W| W | H | W | W |\n| ---       |---|---|--- |---|---|--- |--- |---|\n| **SCALE**     | B | C♯ | D | E | F♯ | G | A | B |\n| **DEGREES**   | 1 | 2 | 3 | 4 | 5 | 6  | 7  | 8 |\n\n#### Melodic Minor Scale\n\nW-H-W-W-W-W-H\n\n#### Harmonic Minor Scale\n\nW-H-W-W-H-WH-H\n\n### Pentatonic\n\nA pentatonic scale is a musical scale or mode with five notes per octave in contrast to a heptatonic (seven-note) scale such as the major scale and minor scale.\n\n#### Major\n\nThe major pentatonic scale is the major scale with the 4th and 7th degrees dropped. \n\nBelow is the `Amaj` pentatonic scale to demonstrate the dropped degrees:\n\n|  | W | W | H | W | W | W | H |\n|---|---|---|---|---|---|---|---|\n| A | B | C♯ | D | E | F♯ | G♯ | A |\n| 1 | 2 | 3 | 4 \u003csmall\u003e(dropped)\u003c/small\u003e | 5 | 6 | 7 \u003csmall\u003e(dropped)\u003c/small\u003e |  |\n\nThis results in the `Amaj` pentatonic scale notes:\n\n```\nA, B, C♯, E, F♯\n```\n\n![majorpentatonicpositions](https://github-production-user-asset-6210df.s3.amazonaws.com/180050/270300915-fdb5a8cb-9426-4b73-8f0a-962da0e21bea.gif)\n\n#### Minor\n\nThe minor pentatonic scale is the minor scale with the 2nd and 6th degrees dropped. \n\nBelow is the `Amaj` pentatonic scale to demonstrate the dropped degrees:\n\n|  | W | H | W | W | H | W | W |\n|---|---|---|---|---|---|---|---|\n| A | B | C | D | E | F | G | A |\n| 1 | 2 \u003csmall\u003e(dropped)\u003c/small\u003e | 3 | 4 | 5 | 6 \u003csmall\u003e(dropped)\u003c/small\u003e | 7 |  |\n\nThis results in the `Am` pentatonic scale notes:\n\n```\nA, C, D, E, G\n```\n\n![minorpentatonicpositions](https://github-production-user-asset-6210df.s3.amazonaws.com/180050/270300918-1fd226a5-dffc-478f-b1b6-81557a20f989.gif)\n\n### Circle of Fifths\n\nThe '[circle of fifths](https://en.wikipedia.org/wiki/Circle_of_fifths)' is a visual representation of the relationships among the 12 tones of the chromatic scale. \n\n![Circle of Fifths](https://upload.wikimedia.org/wikipedia/commons/3/33/Circle_of_fifths_deluxe_4.svg)\n\nFor example, if you want to play a `I, IV, V` chord progression in the key of `C` (find out about [chord progressions below](#progressions)), then you can count the intervals (e.g. `1/C, 2/D, 3/E, 4/F, 5/G`) or you can use the circle of fifths.\n\nNotice in the circle of fifths, that a 5th forward is a `V` chord and a 5th backwards is a `IV` chord.\n\nBut how do you know if the chord is a sharp/flat? I'll demonstrate [this below](#progressions)\n\n## Accidentals\n\nAccidentals are made up of:\n\n- Naturals (♮)\n- Flats (♭)\n- Sharps (♯)\n\nIn musical notation, the sharp (♯), flat (♭), and natural (♮) symbols, among others, mark a note of a pitch that is not a member of the scale or mode indicated by the most recently applied [key signature](https://en.wikipedia.org/wiki/Key_signature).\n\nIn practice, the following notes are naturals:\n\n```\nA, B, C, D, E, F, G\n```\n\n\u003e **NOTE:** in sheet music, the key signature will determine the sharp/flats and so you'll typically only see a natural (♮) used to denote that the note is *neither* sharp or flat\n\nWhere as the following notes are sharps/flats:\n\n```\nA♯/B♭, B♯/C B/C♭, C♯/D♭, D♯/E♭, E♯/F E/F♭,\n```\n\n\u003e **NOTE:** the above sharp/flat notes are actually the same note \n\u003e but are named differently depending on context \n\u003e these notes are known as being 'enharmonic'  \n\n## Fret spacing for Intervals\n\nTo move a whole-step on the fretboard you would move up two frets on the same string OR three frets *backwards* on the higher string.\n\n\u003e **NOTE:** two frets backwards for the `B` string\n \nTo move a half-step on the fretboard you would move up one fret on the same string OR four frets *backwards* on the higher string.\n\n\u003e **NOTE:** three frets backwards for the `B` string\n\n## Modes\n\n\u003e Modes are scales which have the same notes (but sound different because of the different relations to the tonic)\n\nThere are seven modes:\n\n1. Ionian (`I`)\n- Dorian (`ii`)\n- Phrygian (`iii`)\n- Lydian (`IV`)\n- Mixolydian (`V`)\n- Aeolian (`vi`)\n- Locrian (`vii`)\n\nYou'll notice below that each mode uses the same major scale, but each mode will shift the first interval to the end.\n\n### Ionian\n\n```\nW, W, H, W, W, W, H\n```\n\n**Description**: This scale is used as base scale from which other modes and scales come\nfrom  \n**Quality**: Happy or Upbeat quality  \n**Musical Styles**: Rock, Country, Jazz, Fusion  \n**Chords**:\tMajor Chords\n\n### Dorian\n\n```\nW, H, W, W, W, H, W\n```\n\n**Description**: This is the major scale with a flat 3rd and 7th note  \n**Quality**: \tJazzy, Sophisticated, Soulful  \n**Musical Styles**:\tJazz, Fusion, Blues, and Rock  \n**Chords**:\tMinor, Minor 7th, Minor 9th\n\n### Phrygian\n\n```\nH, W, W, W, H, W, W\n```\n\n**Description**: This is the major scale with a flat 2nd, 3rd, 6th, and 7th note  \n**Quality**: Spanish Flavor  \n**Musical Styles**:\tFlamenco, Fusion, Speed Metal  \n**Chords**:\tMinor, Minor 7th\n\n### Lydian\n\n```\nW, W, W, H, W, W, H\n```\n\n**Description**: This is the major scale with a sharp 4th note  \n**Quality**: Airy  \n**Musical Styles**:\tJazz, Fusion, Rock, Country  \n**Chords**:\tMajor, Major 7th, Major 9th, Sharp 11th\n\n### Mixolydian\n\n```\nW, W, H, W, W, H, W\n```\n\n**Description**: This is the major scale with a flat 7th note  \n**Quality**: Bluesy  \n**Musical Styles**:\tBlues, Country, Rockabilly, and Rock  \n**Chords**:\t\tDominant Chords\n\n### Aeolian\n\n```\nW, H, W, W, H, W, W\n```\n\n**Description**: This is the major scale with a flat 3rd, 6th, and 7th note  \n**Quality**: Sad, Sorrowful  \n**Musical Styles**:\tPop, Blues, Rock, Heavy Metal, Country, Fusion  \n**Chords**:\tMinor Chords\n\n### Locrian\n\n```\nH, W, W, H, W, W, W\n```\n\n**Description**: This is the major scale with a flat 2nd, 3rd, 5th, 6th, and 7th note  \n**Quality**: Sinister  \n**Musical Styles**:\tJazz, Fusion  \n**Chords**:\tDiminished, Minor 7th Flat Fives\n\n\u003e **NOTE:** for complete breakdown of modes \n\u003e please refer to this [wiki page](https://en.wikipedia.org/wiki/Mode_(music)#Analysis).\n\nHere is an example of the `C` major scale modes:\n\n- Ionian (`I`): `C`\n- Dorian (`ii`): `Dm`\n- Phrygian (`iii`): `Em`\n- Lydian (`IV`): `F`\n- Mixolydian (`V`): `G`\n- Aeolian (`vi`): `Am`\n- Locrian (`vii`): `Bdim`\n\n\u003e **NOTE:** the notes match either major or minor \n\u003e depending on the mode \n\u003e so the Dorian mode is `ii` in Roman numerals  \n\u003e and that indicates minor, where as \n\u003e Lydian is uppercase roman numeral `V` \n\u003e which indicates a major \n\u003e Locrian is always diminished\n\n## Chords\n\n- [Progressions](#progressions)\n- [Example Progressions](#example-progressions)\n- [Formulas](#formulas)\n- [Sevenths](#sevenths)\n- [Triads](#triads)\n- [Augmented/Diminished](#augmenteddiminished)\n- [Names and Symbols](#names-and-symbols)\n- [Learning Order](#learning-order)\n- [Families](#families)\n- [Relative Chords](#relative-chords)\n\nChords consist of notes from the major scale.\n\n### Progressions\n\nChord 'progressions' have functional names:\n\n- `I`: tonic\n- `ii`: supertonic\n- `iii`: mediant\n- `IV`: subdominant\n- `V`: dominant\n- `vi`: submediant\n- `vii`: leading note\n\n\u003e **NOTE:** chords are typically written \n\u003e with an `m` to indicate a 'minor' \n\u003e or a `maj` to indicate a 'major' \n\u003e e.g. `Am` or `Amaj7`\n\nYou'll notice some of the roman numerals are lowercase and some are uppercase. This indicates whether the chord should be a minor or major (or in the case of the seventh, `vii`, it should be a diminished chord):\n\n- Minor: `ii, iii, vi`\n- Major: `I, IV`\n- Dominant: `V`\n- Diminished: `vii`\n\n### Example Progressions\n\n#### Blues\n\nA standard blues chord progression is:\n\n```\nI, IV, V\n```\n\nIn the key of `A` this would be the chords:\n\n- `A`\n- `D`\n- `E`\n\nAs demonstrated below:\n\n| A | B | C | D | E | F | G |\n|---|---|---|---|---|---|---|\n| **I** | ii | iii | **IV** | **V** | vi | vii |\n\n#### Jazz\n\nA standard jazz chord progression is:\n\n```\nii, V, I\n```\n\nIn the key of `A` this would be the chords:\n\n- `Bm`\n- `E`\n- `A`\n\nAs demonstrated below:\n\n| A | B | C | D | E | F | G |\n|---|---|---|---|---|---|---|\n| **I** | **ii** | iii | IV | **V** | vi | vii |\n\n#### Choose a progression\n\nImagine you want to play a `I, IV, V` progression in the key of `B`. Well, the simplest way to find the chords is to count the fourth and fifth numbers like so:\n\n| 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 |\n|---|---|---|---|---|---|---|---|\n| B | C | D | E | F | G | A | B |\n| √ |   |   | √ | √ |   |   |   |\n\nBut this isn't correct. The 2nd, 3rd and 5th chords are actually sharps! So how can you tell if that's the case?\n\nWell, the solution is determined by the major scale intervals, like so:\n\n| 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 |\n|---|---|---|---|---|---|---|---|\n| B | C♯ | D♯ | E | F♯ | G | A | B |\n| √ |   |   | √ | √ |   |   |   |\n|   | W | W | H | W | W | W | H |\n\n\u003e **NOTE:** a whole-step from `E` is `F#`\n\n### Formulas\n\nIn order to determine the notes that make up a particular chord (and whether those notes should be a sharp or flat tone), we need to utilise intervals/degrees to find the notes and *THEN* flatten them.\n\nBelow are some examples. Try it. Count the intervals/degress in the major scale (e.g. `W, W, H, W, W, W, H`) and then write down the notes you find and *THEN* flatten them.\n\n\u003e **NOTE:** you'll see [further below](#triads) that  \n\u003e Major == `1, 3, 5`  \n\u003e Minor == `1, ♭3, 5`  \n\u003e Diminished == `1, ♭3, ♭5`\n\n#### C \u003csmall\u003e(i.e. major)\u003c/small\u003e\n\n| 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 |\n|---|---|---|---|---|---|---|---|\n| **\u003cu\u003eC\u003c/u\u003e** | D | **\u003cu\u003eE\u003c/u\u003e** | F | **\u003cu\u003eG\u003c/u\u003e** | A | B | C |\n| R | W | W | H | W | W | W | H |\n\n#### Cm \u003csmall\u003e(i.e. minor)\u003c/small\u003e\n\n| 1 | 2 | ♭3 | 4 | 5 | 6 | 7 | 8 |\n|---|---|---|---|---|---|---|---|\n| **\u003cu\u003eC\u003c/u\u003e** | D | **\u003cu\u003eE♭\u003c/u\u003e** | F | **\u003cu\u003eG\u003c/u\u003e** | A | B | C |\n| R | W | W | H | W | W | W | H |\n\n\u003e Minors have a flattened 3rd  \n\u003e so although we say `E♭`,  \n\u003e it's also referred to as `D♯`\n\n#### A \u003csmall\u003e(i.e. major)\u003c/small\u003e\n\n| 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 |\n|---|---|---|---|---|---|---|---|\n| **\u003cu\u003eA\u003c/u\u003e** | B | **\u003cu\u003eC♯\u003c/u\u003e** | D | **\u003cu\u003eE\u003c/u\u003e** | F♯ | G♯ | A |\n| R | W | W | H | W | W | W | H |\n\n#### Am \u003csmall\u003e(i.e. minor)\u003c/small\u003e\n\n| 1 | 2 | ♭3 | 4 | 5 | 6 | 7 | 8 |\n|---|---|---|---|---|---|---|---|\n| **\u003cu\u003eA\u003c/u\u003e** | B | **\u003cu\u003eC\u003c/u\u003e** | D | **\u003cu\u003eE\u003c/u\u003e** | F♯ | G♯ | A |\n| R | W | W | H | W | W | W | H |\n\n\u003e A whole step from `B` is 4 semi-tones `C♯`  \n\u003e We then flatten the note to `C`  \n\u003e As per the requirement for a minor chord (flat 3rd)\n\n#### Adim \u003csmall\u003e(i.e. diminished)\u003c/small\u003e\n\n| 1 | 2 | ♭3 | 4 | ♭5 | 6 | 7 | 8 |\n|---|---|---|---|---|---|---|---|\n| **\u003cu\u003eA\u003c/u\u003e** | B | **\u003cu\u003eC\u003c/u\u003e** | D | **\u003cu\u003eE♭\u003c/u\u003e** | F♯ | G♯ | A |\n| R | W | W | H | W | W | W | H |\n\n\u003e Diminished chords have a flattened 3rd and 5th  \n\u003e A whole step from `B` is 4 semi-tones `C♯`  \n\u003e We then flatten the note to `C`  \n\u003e And the 5th note from `E` to `E♭`  \n\u003e As per the requirement for a diminished chord\n\n#### General pattern\n\nWhen constructing the notes for a major chord we'll find the following pattern applies:\n\n- 4 semi-tones/half-tones between 1st and 3rd \n- 7 semi-tones/half-tones between 1st and 5th\n- 11 semi-tones/half-tones between 1st and 7th\n\nWhere as, if it's a minor chord, then we'll find a slightly modified pattern applies:\n\n- 3 semi-tones/half-tones between 1st and 3rd \n- 6 semi-tones/half-tones between 1st and 5th\n- 10 semi-tones/half-tones between 1st and 7th\n\n\u003e **NOTE:** this is more 'for interest' than a recommendation to remember\n\n### Sevenths\n\n| Major 7 | Dominant 7 | Minor 7 | Minor 7 ♭5 |\n|---|---|---|---|\n| `1, 3, 5, 7` | `1, 3, 5, ♭7` | `1, ♭3, 5, ♭7` | `1, ♭3, ♭5, ♭7` |\n\nIn music theory, the half-diminished seventh chord—also known as a half-diminished chord or a minor seventh flat five (m7♭5)—is formed by a root note, a minor third, a diminished fifth, and a minor seventh. Its consecutive intervals are minor 3rd, minor 3rd, major 3rd.\n\n\u003e **NOTE:** any major 7th chord can be substituted for a minor 7th chord built on the 3rd of the original chord (this will provide a major 9th _sound_; e.g. musicians will often play an E minor 7th instead of a C major 7th in order to create a C major 9 harmony)\n\n### Triads\n\nWe saw these [earlier in the section on Formulas](#formulas), but just to recap them:\n\n| Major | Minor |\n|---|---|\n| `1, 3, 5` | `1, ♭3, 5`|\n\n### Augmented/Diminished\n\nHere are the formulas for both an Augmented Triad and a Diminished Triad:\n\n- Augmented Triad: `1, 3, ♯5`\n- Diminished Triad: `1, 3, ♭5`\n\nAugmented and Diminished seventh chords are the same as Augmented and Diminished triads but with a flat seventh note added:\n\n- Augmented Seventh: `1, 3, ♯5, ♭7`\n- Diminished Seventh: `1, 3, ♭5, ♭♭7`\n\n\u003e **NOTE:** in the case of the diminished seventh, the 7th is lowered _another_ half-tone\n\n#### Other comments on this type of chord\n\nTo augment an interval you must increase its size (moving the notes farther apart).\n\nTo diminish an interval you must decrease its size (moving the notes closer together).\n\nWith *augmented* chords you should:\n\n- Raise the note by ½ when ascending\n- Drop the note by ½ when descending\n\nWith *diminished* chords you should:\n\n- Drop the note by ½ when ascending\n- Raise the note by ½ when descending\n\nA major 2nd, 3rd, 6th, 7th become *augmented* in quality when they're increased by a half-step in size (or *minor* when decreased, and then *diminished* if decreased again).\n\nA perfect 1st (unison), 4th, 5th, 8th (Octave) become 'either' *augmented* or *diminished* in quality when they're increased or decreased by a half-step.\n\nWhen changing the quality of an interval/degree that already has an accidental, you might end up seeing *double* accidentals, like ♭♭ and ♯♯. This is rare, but theorectically correct.\n\n### Names and Symbols\n\nWhen you see chords written down, you'll see a variety of different names and symbols used. \n\nA great resource for this particular topic is Wikipedia's [page on the topic of names/symbols](https://en.wikipedia.org/wiki/Chord_names_and_symbols_(popular_music))\n\nThe following examples are some common ones (I'm using a C that includes a seventh note for my examples):\n\n- Major (`1, 3, 5, 7`): `Cmaj7`, `CM7`, `CΔ7`\n- Minor (`1, ♭3, 5, ♭7`): `Cmin7`, `Cm7`, `C−7`\n- Dominant (`1, 3, 5, ♭7`): `CDom7`, `C7`\n- Augmented (`1, 3, ♯5 ♯7`): `Caug7`, `C+7`\n- Diminished (`1, ♭3, ♭5, ♭♭7`): `Cdim7`, `C♭7`, `C°7`, `Co7`\n- Half Diminished/Minor Seventh Flat 5 (`1, ♭3, ♭5, ♭7`): `Cø7`, `CØ7` \n- Minor-Major Seventh (`1, ♭3, 5, 7`): `Cm(M7)`, `Cm(maj7)`, `Cmin(maj7)`, `Cmin(M7)` †\n\n\u003e † see minor-major seventh [Wikipedia](https://en.wikipedia.org/wiki/Minor_major_seventh_chord) page for _lots_ of extra names/symbols\n\n### Learning Order\n\nThe following order is thought to be a sensible approach to learning each chord type:\n\n1. Major 7 / Minor 7\n- Major / Minor\n- Dominant 7\n- Minor 7 ♭5\n- Augmented / Diminished\n\n### Families\n\nThere are three tonal families:\n\n1. Tonic: 1, 3, 6\n2. Sub-Dominant: 2, 4\n3. Dominant: 5, 7\n\nAny of these family chords can be substituted with another chord from their family (inc. [different voicings \u0026 inversions](#voicings-inversions-and-drop-voicings)).\n\n\u003e **NOTE:** Sub-Dominant is considered a 'passing' family that tries to bridge the gap between the other two\n\nThis means, for example, you could decide to swap a 1 chord for a 3rd or 6th chord. \n\nSo if we look back at an earlier section called '[progressions](#progressions)', there we described how a 1 chord of a progression (the root) is typically major in quality, a 3rd within the progression is minor in quality and a 6th is also minor/diminished in quality. \n\nConsider again our wish to swap a 1 for a 3rd or 6th. If our chord progression was a standard 1, 4, 5 progression in the key of `C`, then this would be the chords `Cmaj7, Fmaj7, G7`. So based on our new knowledge of chord 'families', we now know that we can swap the `Cmaj7` for either a `Em7` (3rd) or a `Am7` (6th).\n\n### Relative Chords\n\nRelative chords (and scales) are those that have (_almost_ †) the same notes but differ in tone by their major and minor qualities.\n\nWith relative chords you can substitute a major for its relative minor (and vice versa) without too drastically changing the tone of the song or its progression.\n\n\u003e This is really useful theory to know about, because in some songs (especially Jazz) you'll at some point hit a confusing set of chords that don't appear to match up to the progression the music sheet is telling you the song is using. It's likely in these situations that the questionable chord has been swapped for its relative chord (e.g. you're expecting to see a Cmaj7 but the music sheet says to play an Amin7)\n\nOne way to identify a chord's relative minor (or major) equivalent is to use the [Circle of Fifths](#circle-of-fifths).\n\nHere follows is an explanation of the how _and_ why of relative chords...\n\nIf you're playing a major scale and you want to identify its relative minor scale, you look at the 6th interval of the major scale (`Root (1), W (2), W (3), H (4), W (5), W (6), W (7), H (8/Octave)`) and that will give you the relative minor scale (e.g. C major's scale 6th interval is an A, so A minor scale is the relative minor scale).\n\nSimilarly, if you're playing a minor scale and you want to identify its relative major scale, you look at the 3rd interval of the minor scale (`Root (1), W (2), H (3), W (4), W (5), H (6), W (7), W (8/Octave)`) and that will give you the relative major scale (e.g. A minor's scale 3rd interval is a C, so C major scale is the relative major scale).\n\nOn the fretboard you can figure this out very quickly by using the low E string (the 6th string). So for finding the relative minor you can simply move 3 notes _down_ from the major note (these are half steps and don't include the major note itself). For finding the relative major you can simply move 3 notes _up_ from the minor note (these are half steps and don't include the minor note itself).  \n\nTo understand _why_ specifically the 3rd and 6th intervals, then look back at the [previous section on 'Families'](#families) which shows the 'tonic' family consists of 1, 3 and 6.\n\nHere also is a useful video that demonstrates this concept: https://www.youtube.com/watch?v=FJQ3aux1v5Q\n\n\u003e † here's an example of how the notes aren't _quite_ the same, but almost:  \n\u003e Cmaj7 vs Am7 (the only difference is that the C's 7th note - `B` - becomes the root `A` note in Am7)  \n\u003e Directly below is a comparison of the notes of each of these chords...\n\n#### Cmaj7\n\n```\n1, 3, 5, 7\nC, E, G, B\n```\n\n#### Am7\n\n```\n1, ♭3, 5, ♭7\nA, C, E, G\n```\n\n## Timings\n\n- 4 beats per bar/measure:  \n  `1, 2, 3, 4`\n- 8 beats per bar/measure:  \n  `1 \u0026, 2 \u0026, 3 \u0026, 4 \u0026`\n- 12 beats per bar/measure:  \n  `1 trip let, 2 trip let, 3 trip let, 4 trip let`\n- 16 beats per bar/measure:  \n  `1 e \u0026 ah, 2 e \u0026 ah, 3 e \u0026 ah, 4 e \u0026 ah`\n\n## Example Chords\n\nRemember that the notes in the tables are flattened as per the minor/dominant requirements, but _after_ we've gone through and calculated all the notes as per the major scale.\n\nSo for example `Am7`. We calculate the notes as per the major scale (`A\tB\tC♯ D E F♯ G♯ A`), _then_ we flatten the 3rd and 7th notes (`A\tB\t[C] D E F♯ [G] A`).\n\n### Amaj7\n\n\u003e `1, 3, 5, 7`  \n\u003e `A, C♯, E, G♯`\n\n| 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 |\n|---|---|---|---|---|---|---|---|\n| **\u003cu\u003eA\u003c/u\u003e** | B | **\u003cu\u003eC♯\u003c/u\u003e** | D | **\u003cu\u003eE\u003c/u\u003e** | F♯ | **\u003cu\u003eG♯\u003c/u\u003e** | A |\n| R | W | W | H | W | W | W | H |\n\n### Am7\n\n\u003e `1, ♭3, 5, ♭7`  \n\u003e `A, C, E, G`\n\n| 1 | 2 | ♭3 | 4 | 5 | 6 | ♭7 | 8 |\n|---|---|---|---|---|---|---|---|\n| **\u003cu\u003eA\u003c/u\u003e** | B | **\u003cu\u003eC\u003c/u\u003e** | D | **\u003cu\u003eE\u003c/u\u003e** | F♯ | **\u003cu\u003eG\u003c/u\u003e** | A |\n| R | W | W | H | W | W | W | H |\n\n### A7 (dominant)\n\n\u003e `1, 3, 5, ♭7`  \n\u003e `A, C♯, E, G`\n\n| 1 | 2 | 3 | 4 | 5 | 6 | ♭7 | 8 |\n|---|---|---|---|---|---|---|---|\n| **\u003cu\u003eA\u003c/u\u003e** | B | **\u003cu\u003eC♯\u003c/u\u003e** | D | **\u003cu\u003eE\u003c/u\u003e** | F♯ | **\u003cu\u003eG\u003c/u\u003e** | A |\n| R | W | W | H | W | W | W | H |\n\n### Bmaj7\n\n\u003e `1, 3, 5, 7`  \n\u003e `B, D♯, F♯, A♯`\n\n| 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 |\n|---|---|---|---|---|---|---|---|\n| **\u003cu\u003eB\u003c/u\u003e** | C♯ | **\u003cu\u003eD♯\u003c/u\u003e** | E | **\u003cu\u003eF♯\u003c/u\u003e** | G♯ | **\u003cu\u003eA♯\u003c/u\u003e** | B |\n| R | W | W | H | W | W | W | H |\n\n### Bm7\n\n\u003e `1, ♭3, 5, ♭7`  \n\u003e `B, D, F♯, A`\n\n| 1 | 2 | ♭3 | 4 | 5 | 6 | ♭7 | 8 |\n|---|---|---|---|---|---|---|---|\n| **\u003cu\u003eB\u003c/u\u003e** | C♯ | **\u003cu\u003eD\u003c/u\u003e** | E | **\u003cu\u003eF♯\u003c/u\u003e** | G♯ | **\u003cu\u003eA\u003c/u\u003e** | B |\n| R | W | W | H | W | W | W | H |\n\n### B7 (dominant)\n\n\u003e `1, 3, 5, ♭7`  \n\u003e `B, D♯, F♯, A`\n\n| 1 | 2 | 3 | 4 | 5 | 6 | ♭7 | 8 |\n|---|---|---|---|---|---|---|---|\n| **\u003cu\u003eB\u003c/u\u003e** | C♯ | **\u003cu\u003eD♯\u003c/u\u003e** | E | **\u003cu\u003eF♯\u003c/u\u003e** | G♯ | **\u003cu\u003eA\u003c/u\u003e** | B |\n| R | W | W | H | W | W | W | H |\n\n### Cmaj7\n\n\u003e `1, 3, 5, 7`  \n\u003e `C, E, G, B`\n\n| 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 |\n|---|---|---|---|---|---|---|---|\n| **\u003cu\u003eC\u003c/u\u003e** | D | **\u003cu\u003eE\u003c/u\u003e** | F | **\u003cu\u003eG\u003c/u\u003e** | A | **\u003cu\u003eB\u003c/u\u003e** | C |\n| R | W | W | H | W | W | W | H |\n\n### Cm7\n\n\u003e `1, ♭3, 5, ♭7`  \n\u003e `C, E♭, G, B♭`\n\n| 1 | 2 | ♭3 | 4 | 5 | 6 | ♭7 | 8 |\n|---|---|---|---|---|---|---|---|\n| **\u003cu\u003eC\u003c/u\u003e** | D | **\u003cu\u003eE♭\u003c/u\u003e** | F | **\u003cu\u003eG\u003c/u\u003e** | A | **\u003cu\u003eB♭\u003c/u\u003e** | C |\n| R | W | W | H | W | W | W | H |\n\n### C7 (dominant)\n\n\u003e `1, 3, 5, ♭7`  \n\u003e `C, E, G, B♭`\n\n| 1 | 2 | 3 | 4 | 5 | 6 | ♭7 | 8 |\n|---|---|---|---|---|---|---|---|\n| **\u003cu\u003eC\u003c/u\u003e** | D | **\u003cu\u003eE\u003c/u\u003e** | F | **\u003cu\u003eG\u003c/u\u003e** | A | **\u003cu\u003eB♭\u003c/u\u003e** | C |\n| R | W | W | H | W | W | W | H |\n\n### Dmaj7\n\n\u003e `1, 3, 5, 7`  \n\u003e `D, F♯, A, C♯`\n\n| 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 |\n|---|---|---|---|---|---|---|---|\n| **\u003cu\u003eD\u003c/u\u003e** | E | **\u003cu\u003eF♯\u003c/u\u003e** | G | **\u003cu\u003eA\u003c/u\u003e** | B | **\u003cu\u003eC♯\u003c/u\u003e** | D |\n| R | W | W | H | W | W | W | H |\n\n### Dm7\n\n\u003e `1, ♭3, 5, ♭7`  \n\u003e `D, F, A, C`\n\n| 1 | 2 | ♭3 | 4 | 5 | 6 | ♭7 | 8 |\n|---|---|---|---|---|---|---|---|\n| **\u003cu\u003eD\u003c/u\u003e** | E | **\u003cu\u003eF\u003c/u\u003e** | G | **\u003cu\u003eA\u003c/u\u003e** | B | **\u003cu\u003eC\u003c/u\u003e** | D |\n| R | W | W | H | W | W | W | H |\n\n### D7 (dominant)\n\n\u003e `1, 3, 5, ♭7`  \n\u003e `D, F♯, A, C`\n\n| 1 | 2 | 3 | 4 | 5 | 6 | ♭7 | 8 |\n|---|---|---|---|---|---|---|---|\n| **\u003cu\u003eD\u003c/u\u003e** | E | **\u003cu\u003eF♯\u003c/u\u003e** | G | **\u003cu\u003eA\u003c/u\u003e** | B | **\u003cu\u003eC\u003c/u\u003e** | D |\n| R | W | W | H | W | W | W | H |\n\n### Emaj7\n\n\u003e `1, 3, 5, 7`  \n\u003e `E, G♯, B, D♯`\n\n| 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 |\n|---|---|---|---|---|---|---|---|\n| **\u003cu\u003eE\u003c/u\u003e** | F♯ | **\u003cu\u003eG♯\u003c/u\u003e** | A | **\u003cu\u003eB\u003c/u\u003e** | C♯ | **\u003cu\u003eD♯\u003c/u\u003e** | E |\n| R | W | W | H | W | W | W | H |\n\n### Em7\n\n\u003e `1, ♭3, 5, ♭7`  \n\u003e `E, G, B, D`\n\n| 1 | 2 | ♭3 | 4 | 5 | 6 | ♭7 | 8 |\n|---|---|---|---|---|---|---|---|\n| **\u003cu\u003eE\u003c/u\u003e** | F♯ | **\u003cu\u003eG\u003c/u\u003e** | A | **\u003cu\u003eB\u003c/u\u003e** | C♯ | **\u003cu\u003eD\u003c/u\u003e** | E |\n| R | W | W | H | W | W | W | H |\n\n### E7 (dominant)\n\n\u003e `1, 3, 5, ♭7`  \n\u003e `E, G♯, B, D`\n\n| 1 | 2 | 3 | 4 | 5 | 6 | ♭7 | 8 |\n|---|---|---|---|---|---|---|---|\n| **\u003cu\u003eE\u003c/u\u003e** | F♯ | **\u003cu\u003eG♯\u003c/u\u003e** | A | **\u003cu\u003eB\u003c/u\u003e** | C♯ | **\u003cu\u003eD\u003c/u\u003e** | E |\n| R | W | W | H | W | W | W | H |\n\n### Fmaj7\n\n\u003e `1, 3, 5, 7`  \n\u003e `F, A, C, E`\n\n| 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 |\n|---|---|---|---|---|---|---|---|\n| **\u003cu\u003eF\u003c/u\u003e** | G | **\u003cu\u003eA\u003c/u\u003e** | B♭ | **\u003cu\u003eC\u003c/u\u003e** | D | **\u003cu\u003eE\u003c/u\u003e** | F |\n| R | W | W | H | W | W | W | H |\n\n### Fm7\n\n\u003e `1, ♭3, 5, ♭7`  \n\u003e `F A♭ C E♭`\n\n| 1 | 2 | ♭3 | 4 | 5 | 6 | ♭7 | 8 |\n|---|---|---|---|---|---|---|---|\n| **\u003cu\u003eF\u003c/u\u003e** | G | **\u003cu\u003eA♭\u003c/u\u003e** | B♭ | **\u003cu\u003eC\u003c/u\u003e** | D | **\u003cu\u003eE♭\u003c/u\u003e** | F |\n| R | W | W | H | W | W | W | H |\n\n### F7 (dominant)\n\n\u003e `1, 3, 5, ♭7`  \n\u003e `F A C E♭`\n\n| 1 | 2 | 3 | 4 | 5 | 6 | ♭7 | 8 |\n|---|---|---|---|---|---|---|---|\n| **\u003cu\u003eF\u003c/u\u003e** | G | **\u003cu\u003eA\u003c/u\u003e** | B♭ | **\u003cu\u003eC\u003c/u\u003e** | D | **\u003cu\u003eE♭\u003c/u\u003e** | F |\n| R | W | W | H | W | W | W | H |\n\n### Gmaj7\n\n\u003e `1, 3, 5, 7`  \n\u003e `G B D F♯`\n\n| 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 |\n|---|---|---|---|---|---|---|---|\n| **\u003cu\u003eG\u003c/u\u003e** | A | **\u003cu\u003eB\u003c/u\u003e** | C | **\u003cu\u003eD\u003c/u\u003e** | E | **\u003cu\u003eF♯\u003c/u\u003e** | G |\n| R | W | W | H | W | W | W | H |\n\n### Gm7\n\n\u003e `1, ♭3, 5, ♭7`  \n\u003e `G B♭ D F`\n\n| 1 | 2 | ♭3 | 4 | 5 | 6 | ♭7 | 8 |\n|---|---|---|---|---|---|---|---|\n| **\u003cu\u003eG\u003c/u\u003e** | A | **\u003cu\u003eB♭\u003c/u\u003e** | C | **\u003cu\u003eD\u003c/u\u003e** | E | **\u003cu\u003eF\u003c/u\u003e** | G |\n| R | W | W | H | W | W | W | H |\n\n### G7 (dominant)\n\n\u003e `1, 3, 5, ♭7`  \n\u003e `G B D F`\n\n| 1 | 2 | 3 | 4 | 5 | 6 | ♭7 | 8 |\n|---|---|---|---|---|---|---|---|\n| **\u003cu\u003eG\u003c/u\u003e** | A | **\u003cu\u003eB\u003c/u\u003e** | C | **\u003cu\u003eD\u003c/u\u003e** | E | **\u003cu\u003eF\u003c/u\u003e** | G |\n| R | W | W | H | W | W | W | H |\n\n### Patterns?\n\n```\nA C E G\n        B D F A\n  C E G B\n          D F A C\n    E G B D\n            F A C E\n      G B D F\n```\n\n## Other Chords\n\n### Power Chords\n\nA 'power chord' is really just a 'fifth chord'.\n\nSo, for example, if you wanted a `C` power chord you would say `C5`.\n\nThey are made up of the root of the key and its fifth.\n\nBut you can also make the sound a little 'fuller' by repeating the root.\n\n### Suspended Chords\n\nA 'suspended chord' is typically one where the 3rd degree is omitted and replaced with either a perfect fourth or a major second. So you might see it defined as a 'suspended 4th' or 'suspended 2nd'.\n\nSuspended chords are neither major nor minor in tone (as that is typically determined by the 3rd degree).\n\nThe purpose of these types of chords is to allow a smoother transition between major and minor scales.\n\nIf you see a chord defined as (for example) `G7sus` then it likely suggests including _both_ the 2nd and 4th degrees. Otherwise you'll typically see an explicit `G7sus4` or `G7sus2`. In the case of `G7sus`, the way to play that on the guitar would require dropping not only the 3rd but also the 5th (which is a fairly neutral tone so is fairly safe to substitute).\n\n### 6th\n\nA sixth chord has the following intervals:\n\n```\n1, 3, 5, 6\n```\n\nIt's like a major 7th but just swap the 7th for a 6th.\n\n\u003e **NOTE:** although the 6th and 13th notes sit at equivalent intervals (i.e. an octave apart), the term 13th (`1, 3, 5, ♭7, 9, 11, 13`) is used for dominant chords, and 6 is used for major family chords to help differentiate them on a leadsheet\n\n#### The 6th's Chord Name/Symbol\n\nA Cmaj6 (`1, 3, 5, 6`) can be written as C6. But don't confuse this for a _dominant_ chord.\n\nAlthough a major triad with a flattened 7th note is considered 'dominant' in tone and is written (for example) as C7; there is no such 'dominant' for a 6th note chord. \n\nBy this we mean, typically you don't see a major chord with a flat 6th. Although, _really_, there are no boundaries in music that can't/shouldn't be crossed. It's obviously a decision that is completely up to the guitarist/musician to play that collection of notes if they so choose to.\n\n### Slash Chords (e.g. C6/9)\n\nTypically when you see a slash chord you think of [inversions](#inversions) (see later in this doc), but in some instances it is used as a shorter syntax for an 'add' style chord. So with `C6/9` this indicates a Cmaj6 with an added 9th note.\n\n### Diminished 7th\n\n\u003e **NOTE:** we saw this [earlier](#augmenteddiminished); what follows is just a recap\n\nThe diminished seventh is made up of a diminished triad (i.e. a minor triad with a lowered fifth: `1, ♭3, ♭5`) and a diminished seventh interval. \n\nThe diminished seventh interval is a minor seventh that has been lowered a half note (identical to a straightforward sixth).\n\nSo in practice it's `1, ♭3, ♭5, 6` (or possibly more correctly would be to say: `1, ♭3, ♭5, ♭♭7`).\n\nThis chords have a dissonant sound. They have lots of tension and so are primarily used in Jazz.\n\n### 9th\n\nThe easiest way to make a ninth is to raise the root by a single tone so it becomes the 2nd interval. So although a 9th is actually the 2nd degree one octave higher, by playing the 2nd you're at least getting the 9th _quality_ into the chord sound.\n\nThis is also ok if the root note is handled by the bass player. \n\nOtherwise if you still need the root sound, then you'll need to add the ninth to your 7th chord (`1, 3, 5, 7, 9`). Just remember the 5th is a neutral note and can be safely dropped to make adding a 9th a little easier.\n\nDon't also forget relative chords. If you have a minor or major 7th chord that you want to make into a 9th, then you can consider swapping the chord for its relative minor or major as the relative chord might be easier to play with a 9th.\n\n### 11th\n\nTo make an eleventh chord you can substitute the 5th (as it's a fairly neutral tone) by lowering it a whole tone to a 4th.\n\nRemember the 5th, when played an octave higher, is really a 12th degree.\n\nSimilarly by lowering to a 4th you get a 11th at an octave higher.\n\n### 13th\n\nTo make an thirteenth chord you can substitute the 5th (as it's a fairly neutral tone) by raising it a whole tone to a 6th.\n\nRemember the 5th, when played an octave higher, is really a 12th degree.\n\nSimilarly by raising to a 6th you get a 13th at an octave higher.\n\n## Voicings, Inversions and Drop Voicings\n\nIn simple terms, a 'voicing' is a guitar chord that is played in a different position.\n\nInversions are where you play the notes of a chord, but change the 'bass' note to no longer be the root note.\n\nDrop Voicings are a further extension of this idea, where you move the nth highest note to be the bass note.\n\nThe fundamental difference between inversions and drop voicings are described in more detail below, but it's important to realise that the order of notes (beyond the bass note) can be played in any order so you will find a dizzying array of voicing options.\n\nOne last thing to comment on is that on the guitar most of these voicings are (close to) unplayable because they would require very wide stretches. This is where 'drop' voicings come into play as they are easier to play on a guitar. \n\nIn practice this is what is meant by 'closed voicings' and 'open voicings'. The former is where the notes are within the same octave; where as the latter means the notes after the bass are spread out over a large octave range.\n\n### Inversions\n\nThere are n number of inversions for a chord. \n\nSo a triad has 3 inversions (as there are 3 notes that make up a triad chord). \n\nSo that's 3 different *voicings* for a triad chord you can play. \n\nWhere as a Seventh chord has 4 inversions (as there are typically 4 notes that make up a seventh chord). \n\nSo that's 4 different *voicings* for a seventh chord you can play.\n\nWith inversions we always have a 'root' inversion, followed by a numbered inversion for the remaining number of notes.\n\nSo a triad (3 notes) will have:\n\n1. Root inversion\n2. 1st inversion\n3. 2nd inversion\n\nWhere as a seventh (4 notes) will have:\n\n1. Root inversion\n2. 1st inversion\n3. 2nd inversion\n4. 3rd inversion\n\nIf our chord is Cmaj7 then its intervals looks like `1, 3, 5, 7`. Meaning, our numbered inversions - remember an inversion is just changing the bass note - will no longer have `C` as the bass note but whichever note we've moved into the bass note position.\n\nBUT (and importantly), when moving the selected note into the bass position, we must re-order the remaining notes.\n\n\u003e **NOTE:** don't worry, we demonstrate a real example of this [below](#table-example)\n\n### Drop Voicings\n\nA drop voicing changes the bass note - much like an inversion does - but it has a different process for deciding which note to move into the bass position. Where with inversions we move up the intervals one by one from the low end, the drop voicings are determined by their name and start from the high end of the notes rather than the low end.\n\nSo if you had a 'Drop 2' voicing then you'd pick the second *highest* note from the chord and move that into the bass position. Effectively we 'drop' the note down an octave.\n\nNow the additional difference is that we *don't* re-order the remaining notes\n\n\u003e **NOTE:** again, don't worry, we demonstrate a real example of this [below](#table-example)\n\n### Table Example\n\nThe following table will hopefully demonstrate the above concepts better. \n\nWe'll be using a Drop 2 Voicing on the Cmaj7 chord.\n\nThe table will show what the standard 'inversions' for a Cmaj7 look like, and then the Drop 2 Voicings that you can get out of it as well. \n\nEffectively the thing I would like you to come away with after reading this is:  \n\"wow, I have many different variations and tones I can achieve with just one chord\"\n\n| Voicing        | Intervals  | Drop 2 Intervals | Notes for Cmaj7 | Drop 2 Degrees |\n| -------------- | ---------- | ---------------- | --------------- | -------------- |\n| Root inversion | 1, 3, 5, 7 | 5, 1, 3, 7       | C, E, G, B      | G, C, E, B     |\n| 1st inversion  | 3, 5, 7, 1 | 7, 3, 5, 1       | E, G, B, C      | B, E, G, C     |\n| 2nd inversion  | 5, 7, 1, 3 | 1, 5, 7, 3       | G, B, C, E      | C, G, B, E     |\n| 3rd inversion  | 7, 1, 3, 5 | 3, 7, 1, 5       | B, C, E, G      | E, B, C, G     |\n\n## Improvisation\n\nThere are three levels of tension:\n\n1. Chord notes\n2. Scale notes\n3. Remaining notes\n\nWhen playing over a `C` chord you want to play notes that are found in the `C` chord (`C` 1st, `E` 3rd, `G` 5th), and you can resolve to any of those notes and things will sound fine. But that alone doesn't sound very advanced so you need to introduce some tension.\n\nThe next level of tension to add are the `C` scale notes that aren't part of the `C` chord (`D` 2nd, `F` 4th, `A` 6th, `B` 7th), and you add these as 'passing notes': so notes that you hit before resolving to a chord note. This helps your improvisation sound better but there's still more tension you can add.\n\nFinally the last level of tension is to add are any notes that remain from the 12 notes available in the scale that aren't either a chord note, nor a scale note (`A♯`, `C♯`, `D♯`, `F♯`, `G♯`).\n","tags":""},{"id":"f5856b94e002bcfd4ce7","title":"RPC: Remote Procedure Call","content":"RPC is a way of connecting two separate services via a raw TCP socket\n\n\u003e Note: SOAP, Thrift, REST APIs, message queues such as RabbitMQ, and key value stores such as Etcd are examples of other tools and protocols\n\n## Basic outline\n\nThe fundamental principle is, you define an RPC service:\n\n- Write a function\n- Add some RPC configuration\n- Register our function as a RPC service\n- Start the service and have it listen for messages on a specific port\n\nFrom here we have a client service that calls the RPC service:\n\n- Write code which calls RPC function\n- Call the function via a specific ip/port\n- The 'message' is passed over as valid JSON\n\n## JSON-RPC\n\nThe client JSON could look like:\n\n- `method`: name of method/service\n- `params`: Array of arguments to be passed\n- `id`: usually an integer; makes it easier for client to know which request it got a response to (if the RPC calls are done asynchroneously)\n \n```json\n{\"method\": \"Arith.Multiply\", \"params\": [{\"A\": 2, \"B\": 3}], \"id\": 1}\n```\n\nThe RPC server JSON response could look like:\n\n- `result`: contains return value of method called (`null` if error ocurred)\n- `error`: if error occurred, indicates error code or error message, otherwise `null`\n- `id`: the id of the request it is responding to\n\n```json\n{\"result\": 6, \"error\": null, \"id\": 1}\n```\n","tags":""},{"id":"f3ce36ed840eda63f8e8","title":"Docker Compose: Example Ruby Application","content":"api:\n  build: ./\n  restart: \"always\"\n  command: \"/bin/bash -c 'source /bootstrap.sh'\"\n  ports:\n    - \"8080:9292\"\n  volumes:\n    - \"./docker-bootstrap-app.sh:/bootstrap.sh\"\n    - \"./src:/app\"\n  links:\n    - \"db\"\n  labels:\n    uk.co.bbci.api.mozart: \"true\"\n\ndb:\n  image: \"postgres\"\n  container_name: \"local_postgres\"\n  environment:\n    - \"POSTGRES_DB=mozart\"\n    - \"POSTGRES_PASSWORD=mysecretpassword\"\n  ports:\n    - \"5000:5432\"\n  labels:\n    uk.co.bbci.db.mozart: \"true\"\nFROM ruby:2.1.2\nMAINTAINER Mark McDonnell \u003cmark.mcdonnell@bbc.co.uk\u003e\n\nLABEL uk.co.bbci.api.mozart=\"true\"\n\nRUN mkdir /app\nWORKDIR /app\n\nADD src/Gemfile /app/Gemfile\nRUN bundle install --retry 10 --jobs 4\n\nEXPOSE 9292\n#!/bin/bash\n\na=$(bundle check)\nb=\"The Gemfile's dependencies are satisfied\"\n\nif [ \"$a\" != \"$b\" ]; then\n  # building the image locally on a poor network\n  # can result in gems not being installed\n  bundle install --retry 10\nfi\n\nbundle exec sequel -E -m db/migrations/ postgres://$(echo \"postgres:$DB_ENV_POSTGRES_PASSWORD@$DB_PORT_5432_TCP_ADDR:$DB_PORT_5432_TCP_PORT/$DB_ENV_POSTGRES_DB\")\nbundle exec rackup config.ru -p 9292 -o 0.0.0.0\n","tags":""},{"id":"1e0b704fd3c008399cae","title":"Faraday TLS Connection","content":"require \"faraday\"\nrequire \"openssl\"\n\nclass Connection\n  def initialize(cert, key, host = nil)\n    if cert.nil? || key.nil?\n      @connection = Faraday.new host\n    else\n      @connection = ssl_connection(cert, key, host)\n    end\n  end\n\n  def get(path)\n    connection.get path\n  end\n\n  private\n\n  attr_reader :connection\n\n  def client_key(key)\n    OpenSSL::PKey::RSA.new File.read(key)\n  end\n\n  def client_cert(cert)\n    OpenSSL::X509::Certificate.new File.read(cert)\n  end\n\n  def ssl_connection(cert, key, host)\n    Faraday.new(host, :ssl =\u003e ssl_options(cert, key))\n  end\n\n  def ssl_options(cert, key)\n    {\n      :client_cert =\u003e client_cert(cert),\n      :client_key  =\u003e client_key(key),\n      :verify      =\u003e false,\n      :version     =\u003e \"TLSv1\"\n    }\n  end\nend\n","tags":""},{"id":"a0acc2b0b0fe2c2860a9","title":"tree exclude directories","content":"tree -I 'Godeps|Gododir'\n","tags":""},{"id":"0f773d286e0e3692a0aa","title":"[Programming types: imperative vs declarative vs structured] ","content":"**Imperative programming**:  \nTelling the \"machine\" **_how_** to do something, and as a result what you want to happen will happen.  \nGo is imperative in nature as some common language abstractions (e.g. `Array#map`) are absent and encourages an explicit imperative programming style.\n\n\u003e **NOTE**: [Procedural programming](https://en.wikipedia.org/wiki/Programming_paradigm) is derived from 'imperative' programming and is named as such because it groups instructions into 'procedures'.\n\n**Declarative programming**:  \nTelling the \"machine\" what you would like to happen, and let the computer figure out how to do it.  \nFunctional Programming and its abstractions (e.g. `Array#map` instead of `for`) allow you to focus on **_what_** we want to happen rather than **_how_** to iterate the object.\n\n**Structured programming**:  \nMakes extensive use of subroutines, block structures, `for` and `while` loops.  \nObject-Oriented Programming is an extension of this.\n","tags":"#types #procedural #imperative #declarative #structured"},{"id":"69ef5e1465744364843c","title":"SCP examples (local to remote and remote to local)","content":"To SCP [go-wrk](https://github.com/tsliwowicz/go-wrk) onto a server for executing (this is if you can't be bothered to bake a version of go-wrk into the application RPM):\n\n- Generate the binary (`GOOS=linux GOARCH=amd64 go build` from directory where source code is located)\n- SSH into the Cosmos instance and create an empty file (e.g. `cd /app \u0026\u0026 touch go-wrk`)\n- From your local machine SCP the Linux binary of go-wrk (e.g. `scp -v \u003c/path/to/go-wrk\u003e mark_mcdonnell@\u003cip\u003e,eu-west-1:/app/`)\n- From remote machine move the binary to an accessible path (e.g. `mv go-wrk /usr/bin/`)\n- Then set the mode (e.g. `chmod 755 /usr/bin/go-wrk`)\n\n\u003e or instead you could copy the file into `/home/mark_mcdonnell`\n# Execute the following command from your local machine\nscp -v -r mark_mcdonnell@10.6.6.149,eu-west-1:/app/ /Users/M/Projects/Foo/Bar\n","tags":""},{"id":"121a664d6f93b82dcd53","title":"Kubernetes Essentials","content":"## Components\n\n- Master\n  - API server\n  - Controller manager\n  - Scheduler\n  - Etcd cluster\n- Node\n  - Kubelet\n  - Network proxy\n- Pod\n- Replication Controller\n- Services\n- Labels\n- Volumes\n- Kubectl\n\n## Master\n\nThe \"master\" is a cluster-wide set of services (such as the API server, which `kubectl` interacts with) which allow Kubernetes to manage our cluster of Nodes.\n\n## Node\n\nNodes run pods. Nodes are also managed by the master services.\n\nEach Node needs a Kubelet. The master sends orders to the kubelet which it uses to interact with pod containers.\n\nEach Node also needs a proxy which provides simple load balancing (kube-proxy)\n\n## Pods\n\nPods are groups of containers, co-located on the same host.\n\nEach Pod gets its own dedicated IP (these IPs change as pods are created/killed).\n\nPods can be assigned labels.\n\n## Replication Controllers\n\nRCs handle the lifecycle of the pods, ensuring they match the specification. \n\nIf there are too few, it'll create more. If there are too many, it'll kill those over the threshold.\n\n## Services\n\n\u003e Services are collections of pods that are exposed with a single and stable name and network address. The service provides load balancing to the underlying pods, with or without an external load balancer\n\nServices are an abstraction. They define a way of accessing a set of pods.\n\nIn a practical sense, a 'service' is a REST endpoint, created by POST'ing a definition file to the Kubernetes \"API server\":\n\n```json\n{\n    \"kind\": \"Service\",\n    \"apiVersion\": \"v1\",\n    \"metadata\": {\n        \"name\": \"my-service\"\n    },\n    \"spec\": {\n        \"selector\": {\n            \"app\": \"MyApp\"\n        },\n        \"ports\": [\n            {\n                \"protocol\": \"TCP\",\n                \"port\": 80,\n                \"targetPort\": 9376\n            }\n        ]\n    }\n}\n```\n\nThe pods targeted by a service, are done so by utilising labels (in the above example our service is grouping together a set of pods that have been labelled `MyApp`).\n\nIf a set of pods come up and down, it doesn't matter that their ip addresses have changed because our new 'service' (abstraction) hides this detail and gives us a single entry point to access the pods the service manages.\n\nThe service is given an ip address (also known as a \"cluster IP\") allowing other nodes/pods to query it in order to locate other pods.\n\n## Labels\n\nThese are key-value pairs.\n\nReplication Controllers use them for \"service discovery\".\n\n## Volumes\n\nA volume is a directory, mounted into a container for the purpose of storing state.\n\n## Kubectl\n\nCommand line tool, which allows you to: add/delete Nodes, Pods and Replication Controllers.\n\n---\n\n## Local Set-up\n\nA local set-up requires creating a \"standalone cluster\"\n","tags":""},{"id":"59cfb4f4e6185a9c7107","title":"Access Instance and Class level methods (one example using `new`)","content":"class Foo\n  protected\n\n  def self.hello\n    \"world\"\n  end\nend\n\nclass Bar \u003c Foo\n  def self.speak\n    puts hello\n  end\n  \n  def speak\n    puts hello\n  end\n\n  private\n\n  def hello\n    self.class.superclass.method(:hello).call\n  end\nend\n\nb = Bar.new\nb.speak   # =\u003e \"world\"\nBar.speak # =\u003e \"world\"\n","tags":""},{"id":"72161a96641fa4a0033d","title":"Install Redis CLI on AWS Instance","content":"- `ssh 10.6.11.62,eu-west-1`\n- `sudo yum install gcc`\n- `sudo yum install wget`\n- `wget http://download.redis.io/redis-stable.tar.gz`\n- `tar xvzf redis-stable.tar.gz`\n- `cd redis-stable`\n- `make`\n- `src/redis-cli -h mycachecluster.eaogs8.0001.usw2.cache.amazonaws.com -p 6379`\n\nNow run redis commands:\n\n- `Keys *`: list all keys\n- `set foo \"bar\"`: set a new key\n- `get foo`: get a specific key\n","tags":""},{"id":"43574477639b327e1d8a","title":"Demonstrating the set-up of CoreOS and how to utilise Etcd along with Systemd and Fleet","content":"## Getting started\n\n- `git clone git@github.com:coreos/coreos-vagrant.git`\n- `mv user-data.sample user-data`\n- Change `etcd2` to have the following content:\n\n```ini\nadvertise-client-urls: http://$public_ipv4:2379,http://$public_ipv4:4001\ninitial-advertise-peer-urls: http://$private_ipv4:2380\nlisten-client-urls: http://0.0.0.0:2379,http://0.0.0.0:4001\nlisten-peer-urls: http://$private_ipv4:2380,http://$private_ipv4:7001\ninitial-cluster-token: core-01_etcd\ninitial-cluster: core-01=http://$private_ipv4:2380\ninitial-cluster-state: new\n```\n\n## Services\n\n- Systemd: CoreOS's init system\n- Etcd: distributed key-value store\n- Fleet: distributed init system (ties together systemd and etcd; NOT a container orchestrator)\n\n## Setup\n\n```bash\n# Access the CoreOS VM\nvagrant up\nvagrant ssh\n\n# Check etcd and fleet are running\nsystemctl status etcd2\nsystemctl status fleet\n\n# Check installed version of Docker\ndocker version\n```\n\n## Etcd\n\n```bash\n# Verify Host/VM access to etcd\netcdctl set /foo bar\netcdctl get /foo\netcdctl rm  /foo\netcdctl set /foo-dir/foo-key \"foo value\"\netcdctl set /foo-dir/bar-key \"bar value\"\netcdctl ls  /foo-dir --recursive # works without --recursive and also with -recursive ?\netcdctl get /foo-dir/foo-key\n```\n\n## HTTP API\n\n\u003e Etcd has an HTTP API  \n\u003e The API always responds with JSON  \n\u003e e.g. `{\"action\":\"get\",\"node\":{\"key\":\"/baz\",\"value\":\"qux\",\"modifiedIndex\":884,\"createdIndex\":884}}`  \n\u003e It is useful for client apps and host containers that don't have etcdctl installed\n\n```bash\n# Verify HTTP API access to etcd\ncurl --location --request PUT http://127.0.0.1:2379/v2/keys/baz --data value=\"qux\"\ncurl --location http://127.0.0.1:2379/v2/keys/baz\ncurl --location --request DELETE http://127.0.0.1:2379/v2/keys/baz\n\n# Check docker0 interface IP\necho \"$(ifconfig docker0 | awk '/\\\u003cinet\\\u003e/ { print $2 }'):2379\"\n\n# Run a container from the Alpine Linux distro and access etcd from within it\ndocker run -it alpine ash # that's not a typo \"ash\" is correct\napk update \u0026\u0026 apk add curl\ncurl --location http://\u003cdocker0 interface IP\u003e:2379/v2/keys/\n```\n\n## Watching\n\n```bash\n# Watch etcd for changes (requires two terminal shells)\netcdctl mkdir /foo-data\netcdctl watch /foo-data --recursive # unlike `ls` you MUST use --recursive flag (-recursive also works?)\netcdctl watch /foo-data --recursive --forever\n```\n\nFrom a second terminal shell...\n\n```bash\nvagrant ssh\netcdctl set /foo-data/can-you-see-me-now yes\n```\n\n## TTLs\n\n```bash\n# Verify etcd's TTL feature\netcdctl set /my-ttl \"I'm expiring in 30 seconds...\" --ttl 30\netcdctl get /my-ttl\n```\n\n...30 seconds later...\n\n```bash\netcdctl get /my-ttl\n```\n\n## SystemD\n\n\u003e Control of 'unit' files/services are on a per machine basis  \n\u003e So only use for simple tasks\n\n```bash\n# Verify systemd's unit file setup for managing container processes\nsudo vi /etc/systemd/system/hello.service\n```\n\nAdd following content to `hello.service`:\n\n```ini\n[Unit]\nDescription=HelloWorld\n# this unit will only start after docker.service\nAfter=docker.service\nRequires=docker.service\n\n[Service]\nTimeoutStartSec=0\n# busybox image will be pulled from docker public registry\nExecStartPre=/usr/bin/docker pull busybox\n# we use rm just in case the container with the name \"busybox1\" is left\nExecStartPre=-/usr/bin/docker rm busybox1\n# we start docker container\nExecStart=/usr/bin/docker run --rm --name busybox1 busybox /bin/sh -c \"while true; do echo Hello World; sleep 1; done\"\n# we stop docker container when systemctl stop is used\nExecStop=/usr/bin/docker stop busybox1\n\n[Install]\nWantedBy=multi-user.target\n```\n\nEnable the service:\n\n\u003e This creates a symlink from an internal user directory to the main system directory\n\n```bash\nsudo systemctl enable /etc/systemd/system/hello.service\n```\n\nStart the service:\n\n\u003e It can take a few seconds to complete as it has to pull a docker image from DockerHub\n\n```bash\nsudo systemctl start hello.service\n```\n\nVerify the service:\n\n```bash\njournalctl -f -u hello.service\n```\n\nResponds with tailed output:\n\n```bash\n-- Logs begin at Thu 2015-10-29 08:42:56 UTC. --\nOct 29 09:29:07 core-01 docker[2119]: Hello World\nOct 29 09:29:08 core-01 docker[2119]: Hello World\nOct 29 09:29:09 core-01 docker[2119]: Hello World\nOct 29 09:29:10 core-01 docker[2119]: Hello World\nOct 29 09:29:11 core-01 docker[2119]: Hello World\nOct 29 09:29:12 core-01 docker[2119]: Hello World\nOct 29 09:29:13 core-01 docker[2119]: Hello World\n```\n\n\u003e `docker ps` will also show the container is running\n\nCheck the status of the service:\n\n```bash\nsudo systemctl status hello.service\n```\n\nStop the service:\n\n```bash\nsudo systemctl stop hello.service\n```\n\nKill the service:\n\n\u003e This doesn't stop the container!  \n\u003e Check `docker ps` and you'll see it still running  \n\u003e Also `journalctl -f -u hello.service` will show logs still coming from the container\n\n```bash\nsudo systemctl kill hello.service\n```\n\nRestart the service:\n\n```bash\nsudo systemctl daemon-reload # only needed if you've changed the service file\nsudo systemctl restart hello.service\n```\n\nDisable the service:\n\n```bash\nsudo systemctl disable hello.service\n```\n\n## Fleet\n\n\u003e Fleet is a cluster manager that controls Systemd at the cluster level  \n\u003e It can still be used on a single machine\n\nFleet unit files are the same as Systemd unit files, but with additional properties that help them identify in the context of a cluster. The only other difference between them is that there is no `[Install]` in the fleet unit files, as this is replaced with `[X-Fleet]`.\n\nLet's see what machines are available:\n\n```bash\nfleetctl list-machines\n```\n\nWhich responds with:\n\n```\nMACHINE     IP            METADATA\n46acb6e7... 172.17.8.101  -\n```\n\nFleet unit files can be placed any where on the system and then 'submitted' to fleet.\n\nCreate the following fleet unit file twice (change the description and url to ping) and name the files `ping.1.service` and `ping.2.service`:\n\n\u003e e.g. for the second version you could use  \n\u003e `Description=Ping BBC`  \n\u003e `ExecStart=/usr/bin/ping bbc.co.uk`\n\n```ini\n[Unit]\nDescription=Ping Google\n\n[Service]\nExecStart=/usr/bin/ping google.com\n\n[X-Fleet]\n```\n\n\u003e We keep `X-Fleet` empty because with one machine, specifying other settings will cause things to break (I've yet to figure out why?)\n\n\"Conflicts\" prevents the unit being collocated with the other unit using glob-matching. Where \"MachineMetadata\" can be used to determine if an instance in the cluster is acceptable. For example:\n\n```ini\n# Allow a cluster instance to run this unit \n# Only if they have region set to one of these values\nMachineMetadata=region=us-east-1\nMachineMetadata=region=us-west-1\n```\n\nOr alternatively bundle multiple requirements into a single item:\n\n```ini\nMachineMetadata=\"region=us-east-1\" \"diskType=SSD\"\n```\n\nSubmit the fleet unit files:\n\n```bash\nfleetctl submit ping.1.service\nfleetctl submit ping.2.service\n```\n\nReview list of unit files available:\n\n```bash\nfleetctl list-unit-files\n```\n\nWhich responds with:\n\n```\nUNIT            HASH    DSTATE    STATE     TARGET\nping.1.service  4764f30 inactive  inactive  -\nping.2.service  683fbdc inactive  inactive  -\n```\n\nYou can remove services from the fleet using `destroy`:\n\n```bash\nfleetctl destroy ping.1.service\nfleetctl destroy ping.2.service\n```\n\nTo start the fleet services:\n\n```bash\nfleetctl start ping.1.service\nfleetctl start ping.2.service\n```\n\nNow listing the unit files again:\n\n```bash\nUNIT            HASH    DSTATE    STATE     TARGET\nping.1.service  4c2ca38 launched  launched  46acb6e7.../172.17.8.101\nping.2.service  86f264e launched  launched  46acb6e7.../172.17.8.101\n```\n\nYou can also verify the services are running using `journalctl`:\n\n```bash\njournalctl -f -u ping.1.service\njournalctl -f -u ping.2.service\n```\n\n## Cloud Config vs User Data\n\nWhen using Vagrant to set-up a local cluster, you'll have a `user-data` file, which is really a `cloud-config` file in the cloud world.\n\nWhen using Vagrant you'll also have a `config.rb` which is used to construct the cloud-config file by manipulating the local `user-data` file.\n\n## Creating files on all clusters\n\n```yaml\nwrite_files:\n  - path: /home/core/test.txt\n    permissions: 0644\n    owner: core\n    content: |\n      Beep Boop\n```\n\nThen run the following commands:\n\n`vagrant provision \u0026\u0026 vagrant reload`\n\n\u003e Note: make sure it's not nested inside the top-level `coreos` section! as it won't work\n\n## Added metadata to all clusters\n\n```yaml\ncoreos:\n  fleet:\n    metadata: cluster=vagrant\n```\n\nThen SSH into the instance (e.g. `vagrant ssh core-01`) and then run:\n\n```bash\nfleetctl list-machines\n```\n\nWhich responds with:\n\n```\nMACHINE\t\t  IP\t\t        METADATA\n5fcf399b...\t172.17.8.101\tcluster=vagrant\n987c97e7...\t172.17.8.102\tcluster=vagrant\nc15aed24...\t172.17.8.103\tcluster=vagrant\n```\n\n## Schedule a new fleet/service for the cluster\n\n- `cd coreos-vagrant-localcluster \u0026\u0026 vagrant up`\n- `vagrant ssh core-03`\n- `vi hello-cluster.service` (see below)\n- `fleetctl start hello-cluster.service`\n- `journalctl -u hello-cluster.service -f`\n\n### hello-cluster.service\n\n```ini\n[Unit]\n[Service]\nExecStart=/usr/bin/bash -c \"while true; do echo 'Hello Cluster'; sleep 1; done\"\n```\n\n### Response from `fleetctl` command\n\n```\nUnit hello-cluster.service inactive\nUnit hello-cluster.service launched on 5fcf399b.../172.17.8.101\n```\n","tags":""},{"id":"63d1491144aa80cd6fb1","title":"HTTP Security Headers","content":"https://scotthelme.co.uk/how-widely-used-are-security-based-http-response-headers/\n\nhttps://securityheaders.io/\n\n```\nContent-Security-Policy\nContent-Security-Policy-Report-Only\nX-Webkit-Content-Security-Policy\nX-Content-Security-Policy\nPublic-Key-Pins\nPublic-Key-Pins-Report-Only\nStrict-Transport-Security\nX-Content-Type-Options\nX-Frame-Options\nX-XSS-Protection\nX-Download-Options\nX-Permitted-Cross-Domain-Policies\n```\n","tags":""},{"id":"d7543ea8624750e80f9a","title":"Senior Ruby Programmer: Job Spec","content":"- **Role**: Senior Ruby Programmer\n- **Division**: Digital\n- **Department**: News\n- **Grade**: 8\n- **Location**: London\n- **Contract**: Permanent\n- **Reports to**: Technical Lead, News Frameworks\n\n## Context\n\nThe BBC News Frameworks team is responsible for designing and developing web services and tooling utilised by the wider BBC engineering teams. We're looking for a Senior Ruby Programmer to help lead the technical design and development of product requirements.\n\nIf you're passionate about solid object-oriented code design, investigating emerging web technologies and building highly scalable micro services for the future of the BBC News platform, then we'd love to hear from you.\n\nIf you don’t currently match the job spec completely then don’t let this dissuade you from applying. We’re looking for intelligent people who are quick to learn and adapt. The BBC is the perfect place to do just that: we invest heavily in helping our engineers to grow in all aspects of their career.\n\n## Purpose of the role\n\nThe primary focus at this stage is on the evolution of our internal \"page composition as a service\" (CAAS) platform, codename: Mozart. Mozart is a collection of decoupled micro services designed to parse routing information and to render components required for the page being requested using dynamic configuration.\n\nWe're almost at our initial v1 milestone and are considering requirements for v2, which you'll be heavily invoiced with its design and conception as well as joining the discussion amongst senior technical architects in order to ensure a robust and scalable system. \n\nYou'll be working with the Ruby programming language, as well as a little Go, and utilising technologies such as Docker to help keep the local development workflow fluid.\n\n## Responsibilities\n\n- Design, build, and maintain efficient, reusable, and reliable Ruby code\n- Ensure the best possible performance, quality, and responsiveness of the applications\n- Identify bottlenecks and bugs, and devise solutions to these problems\n- Help maintain code quality, organization, and automatization\n- Have excellent communication skills and ability to translate complex technical topics to stakeholders\n- Mentor other developers wherever necessary/appropriate\n\n## Required skills\n\n- Excellent understanding of the Ruby syntax and its nuances\n- Solid understanding of object-oriented programming\n- Proficient understanding of the Git VCS\n- Understanding of fundamental design principles behind a scalable application\n- Ability to write reusable Ruby libraries that may be used in expressive ways\n- Familiarity with Rack and Sinatra\n- Familiarity with different caching levels and applicability\n- Familiarity with continuous integration\n- Familiarity with concepts such as Testing and RESTful services\n- Familiarity with AWS (e.g. SQS, DynamoDB, ElastiCache, S3, EC2, ELB, CloudFormation)\n- Familiarity with Agile processes\n\n## Desirables\n\nThese are 'nice to haves' but not essential:\n\n- Familiarity with TLS and client cert authentication\n- Familiarity with logging and monitoring solutions\n- Familiarity with designing micro service architectures\n- Familiarity with Docker\n- Familiarity with the Go programming language\n- Familiarity with Kubernetes, Meso, Docker Swarm and other orchestration systems\n\n## Competencies\n \n1. **Analytical thinking**: able to simplify complex problems, process projects into component parts, explore and evaluate them systematically. Able to identify causal relationships and construct frameworks, for problem solving and/or development\n\n2. **Decision making**: is ready and able to take the initiative, originate action and be responsible for the consequences of the decisions made\n\n3. **Imagination/creative thinking**: is able to transform creative ideas/impulses into practical reality; can look at existing situations and problems in novel ways and come up with creative solutions\n\n4. **Resilience**: can maintain personal effectiveness by managing own emotions in the face of pressure, set backs or when dealing with provocative situations. Can demonstrate an approach to work that is characterised by commitment and motivation.\n\n5. **Influencing and Persuading**: ability to present sound arguments that convince others of their point ofview. Ability to form effective working relationships with a wide rangeof contacts.\n\n6. **Communication**: the ability to get one’s message understood clearly by adopting a range of styles, tools and techniques appropriate to the audience and the nature of the information.\n\n7. **Managing Relationships**: able to build and maintain effective working relationships with a range of people; team working\n\n8. **Problem Solving**: able to simplify complex problems, processes or projects into component parts, explore and evaluate them systematically. Able to identify causal relationships, and construct frameworks, for decision making and problem-solving. Transforms proposals/ideas into practical reality.\n","tags":""},{"id":"8079e79c5eb4e7b88183","title":"Example script that uses the `\u0026` trick (typically used to convert an object to a proc; e.g. https://gist.github.com/Integralist/11206577) to convert a method (retrieved using `method()`) to a proc so it can be utilised by another method","content":"def hello(\u0026block)\n  block.call if block_given?\nend\n\ndef world\n  \"world\"\nend\n\nhello                  # =\u003e nil\nhello { \"world\" }      # =\u003e \"world\"\nhello(\u0026method(:world)) # =\u003e \"world\"\n","tags":""},{"id":"e69c50d02f0edf086dbd","title":"[Caching strategies and headers] (see also http://fideloper.com/api-etag-conditional-get) ","content":"## Page Level Cache\n\n- Varnish\n- Nginx\n- CloudFront\n\n## Application Cache\n\n- In-memory service (e.g. Redis, Memcache - typically via AWS ElastiCache)\n- In-memory application (e.g. raw hash data structure managed by the app)\n\n### Redis or Memcache?\n\nThe answer is that it depends on your use case.\n\nMemcache:\n\n- Scales horizontally, meaning you can dynamically add new nodes to it, but each node will have a cold cache. So it can be more problematic than you realise when scaling to meet demand\n- Memcache is _very_ simple. It does in-memory caching and that's it. So if you have some simple items you'd like to cache to improve performance then Memcache is probably what you want\n\nRedis:\n\n- Scales vertically, meaning you have to change the instance 'type', and so at _some_ point you're going to reach a size limit and have to resort to data sharding across multiple Redis instances (e.g. one Redis for blog posts, and one Redis for Comments)\n- Read replicas are available to solve the problem that Memcache has with cold cache startup (not completely avoidable, but read replicas pretty much helps mitigate this)\n- Complex data structures, pub sub, a whole host of features are available that Memcache doesn't have\n\n## HTTP Cache\n\nThese are handled by HTTP headers/status code sent back with the server response\n\ne.g. `Cache-Control: private,max-age=30`\n\n### Configuration\n\n- `Cache-Control`\n  - `public`: means the response is the same for everyone and the data can be cached in browser or proxy stores. It’s the default behavior, so it’s not necessary to set it\n  - `private`: responses are intended for a single user. For example, the URL `https://myapp.com/messages` returns a set of messages unique to each logged-in user, even though both of them use the same URL. Therefore, the browser can cache the response, but proxy server caching is not permitted\n  - `max-age`: used with `public` and `private` and specifies the maximum time in seconds a response remains valid. For example, `max-age=60` indicates the browser/proxy can cache the data for one minute before making a new request (e.g. `Cache-Control: private,max-age=30`)\n  - `s-maxage`: for some cdn/proxy caches this is the same as `Surrogate-Control`, except the header is not stripped and will be respected by the cdn/proxy caches (including any caches between the cdn and the browser), but not the browser itself.\n  - `must-revalidate`: indicates that the freshness information must be obeyed strictly. Stale content cannot be served under any circumstance\n  - `no-transform`: tells caches that they are not allowed to modify the received content for performance reasons under any circumstances. This means, for instance, that the cache is not able to send compressed versions of content it did not receive from the origin server compressed and is not allowed\n  - `no-store`: stops the browser and all proxy servers caching the returned data. Every request will therefore incur a trip back to the server\n  - `no-cache`: specifies that any cached content must be re-validated on each request before being served to a client. This, in effect, marks the content as stale immediately, but allows it to use revalidation techniques to avoid re-downloading the entire item again. The browser/proxy will make a server request and pass back `Last-Modified` (date/time) and/or an Etag (response hash/checksum) in the header. These are present on subsequent requests and, if the response has not changed, the server returns a `304 Not Modified` status, which instructs the browser/proxy to use its own cached data. Otherwise, the new data is passed back with a `200 OK` status\n- `Expires`: (*deprecated*) sets a time in the future when the content will expire (probably best used only as a fall back; prefer use of `Cache-Control`)\n- `Etag`: the origin can provide a unique Etag for an item when it initially serves the content. When a cache needs to validate the content it has on-hand upon expiration, it can send back the Etag it has for the content. The origin will either tell the cache that the content is the same, or send the updated content (with the new Etag)\n- `Last-Modified`: specifies the last time that the item was modified. This may be used as part of the validation strategy to ensure fresh content\n- `Content-Length`: while not specifically involved in caching, the `Content-Length` header is important to set when defining caching policies. Certain software will refuse to cache content if it does not know in advanced the size of the content it will need to reserve space for\n- `Vary`: provides you with the ability to store different versions of the same content at the expense of diluting the entries in the cache. A cache typically uses the requested host and the path to the resource as the key with which to store the cache item. The Vary header can be used to tell caches to pay attention to an additional header when deciding whether a request is for the same item. This is most commonly used to tell caches to key by the Accept-Encoding header as well, so that the cache will know to differentiate between compressed and uncompressed content\n\n\u003e References: [W3C Specification](http://www.w3.org/Protocols/rfc2616/rfc2616-sec14.html) and [MDN docs](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Cache-Control)\n\n### no-store, no-cache, must-revalidate\n\nThese headers require a little _extra_ clarification.\n\nUnlike max-age, the no-store, no-cache and must-revalidate directives are about instructing caches to not cache a resource. However, they differ in subtle ways.\n\nno-store is pretty self-explanatory, and in fact, it does even a little more than the name suggests. When present, a HTTP/1.1 compliant cache must not attempt to store anything, and must also take actions to delete any copy it might have, either in memory, or stored on disk.\n\nThe no-cache directive, on the other hand, is arguably much less self-explanatory. This directive actually means to never use a local copy without first validating with the origin server. By doing so, it prevents all possibility of a cache hit, even with fresh resources.\n\nTo put it another way, the no-cache directive says that caches must revalidate their representations with the origin server. But then comes another directive, awkwardly named… must-revalidate.\n\nIf this starts to get confusing for you, rest assured, you are not alone. If what one wants is not to cache, it has to use no-store instead of no-cache. And if what one wants is to always revalidate, it has to use no-cache instead of must-revalidate.\n\nConfusing, indeed.\n\nAs for the must-revalidate directive, it is used to forbid a cache to serve a stale resource. If a resource is fresh, must-revalidate perfectly allows a cache to serve it without forcing any revalidation, unlike with no-store and no-cache. That’s why this header should always be used with a max-age directive, to indicate a desire to cache a resource for some time and when it’s become stale, enforce a revalidation.\n\nWhen it comes to these last three directives, we find the choice of words to describe each of them particularly confusing: no-store and no-cache are expressed negatively whereas must-revalidate is expressed positively. Their differences would probably be more obvious if they were to be expressed in the same fashion.\n\nTherefore, it is helpful to think about each of them expressed in terms of what is not allowed:\n\n    no-store: never store anything\n    no-cache: never cache hit\n    must-revalidate: never serve stale\n    \n### stale-while-revalidate\n\nIt's important to note that the ability for a cache to 'serve stale' while _revalidating_ (i.e. to see if there is a fresher version of the cached content) is reliant upon the origin providing either a `ETag` or `Last-Modified` header. If neither of these headers are sent, then the cache will not be able to update either the object's _age_ (i.e. reset it back to zero once the content is refreshed), nor its 'grace' period (i.e. how long it will be able to serve it stale) and so this will result in the cache/proxy having to make a _full_ request for content from the origin server.\n\nEach header would cause the browser/cache to issue a conditional header request using a different header itself, for example:\n\n- ETag: `If-None-Match`\n- Last-Modified: `If-Modified-Since`\n\n\u003e Reference: https://developer.mozilla.org/en-US/docs/Web/HTTP/Caching#Cache_validation\n\nThe `If-None-Match` HTTP request header makes the request conditional. For GET and HEAD methods, the server will send back the requested resource, with a 200 status, only if it doesn't have an ETag matching the given ones. For other methods, the request will be processed only if the eventually existing resource's ETag doesn't match any of the values listed.\n\n```bash\n# typically is a HEAD request\ncurl -v --head --header 'If-None-Match: \"e54f84f5ccb54dcf20dc2802ce8b8fae6f477f8e\"' https://example.com\n\n# works with GET requests too\ncurl -svo /dev/null --header 'If-None-Match: \"e54f84f5ccb54dcf20dc2802ce8b8fae6f477f8e\"' https://example.com\n```\n\nThe `If-Modified-Since` request HTTP header makes the request conditional: the server will send back the requested resource, with a 200 status, only if it has been last modified after the given date. If the request has not been modified since, the response will be a 304 without any body.\n\nIt should also be noted that the official [W3C specification](https://www.w3.org/Protocols/rfc2616/rfc2616-sec13.html#sec13.3.4) provides 'rules' for when to use ETag vs Last-Modified. In summary...\n\n\u003e the preferred behavior for an HTTP/1.1 origin server is to send both a strong entity tag and a Last-Modified value. \n\nBelow is a sequence diagram (paste it into https://sequencediagram.org/ to see it properly) which demonstrates the `stale-while-revalidate` flow using ETags as the revalidation mechanism...\n\n```\ntitle Fastly stale-while-revalidate (ETag example)\n\nClient-\u003eCDN: GET /foo\nCDN--\u003eCDN: CACHE MISS\nCDN-\u003eOrigin: GET /foo\nOrigin--\u003eOrigin: generate response\\n(and hash response for ETag comparison)\nOrigin-\u003eCDN: 200 OK\\n**Content-Length**:\u003cN\u003e\\n**ETag**: XYZ\\n**Cache-Control**: no-store, must-revalidate\\n**Surrogate-Control**: max-age=1day, stale-while-revalidate=1day, stale-if-error=1year\nnote over CDN: cache response\nCDN-\u003eClient: 200 OK\n\nnote over Client #yellow: max-age TTL expires\n\nClient-\u003eCDN:GET /foo\nCDN--\u003eCDN: CACHE MISS\n\ngroup asynchronous request flow\n  CDN-\u003eOrigin: GET /foo\\n**If-None-Match**: XYZ\n  Origin--\u003eOrigin: generate response\\n(and hash response for ETag comparison)\n  Origin-\u003eCDN: 304 Not Modified\\n**Content-Length**:0\n  note over CDN: cached object not updated\nend\n\nCDN-\u003eClient: 200 OK (stale content)\nnote over CDN #pink:even though we'll serve stale to client\\nwhile asynchronously trying to update\\nour expired cache object, this still\\nmeans we'll end up hitting the origin\\nagain until we get fresh content.\\n\\nthis is helped by Fastly's ability to do\\n\"request collapsing\" so for multiple\\nclient requests only one will reach the\\norigin while the remaining will receive\\na stale response.\n\nClient-\u003eCDN:GET /foo\nCDN--\u003eCDN: CACHE MISS\nCDN-\u003eOrigin: GET /foo\\n**If-None-Match**: XYZ\nOrigin--\u003eOrigin: generate response\\n(and hash response for ETag comparison)\nOrigin-\u003eCDN: 200 OK\\n**Content-Length**:\u003cN\u003e\\n**ETag**: XYZ\\n**Cache-Control**: no-store, must-revalidate\\n**Surrogate-Control**: max-age=1day, stale-while-revalidate=1day, stale-if-error=1year\nnote over CDN: cached object updated with fresh max-age\\nand stale-while-revalidate, stale-if-error TTLs\n```\n\n### surrogate/cache-control and proxies\n\nthe behaviour of specific `Cache-Control` values when also used alongside `Surrogate-Control` headers can become confusing so we've documented them below...\n\n- Disable Client Caching: `Cache-Control: no-store, must-revalidate`, you can now set `Surrogate-Control` for proxies ([docs](https://docs.fastly.com/guides/tutorials/cache-control-tutorial#applying-different-cache-rules-for-fastly-and-browsers))\n- Disable CDN Caching: `Cache-Control: private` ([docs](https://docs.fastly.com/guides/tutorials/cache-control-tutorial#do-not-cache))\n- Disable ALL Caching: `Cache-Control: no-cache, no-store, private, must-revalidate, max-age=0, max-stale=0, post-check=0, pre-check=0` + `Pragma: no-cache` + `Expires: 0` ([docs](https://docs.fastly.com/guides/debugging/temporarily-disabling-caching))\n","tags":"#cache #caching #headers #stale #revalidate #memcache #redis #varnish #nginx #fastly #cdn #if-none-match #conditional #http"},{"id":"2bd037f7450bbf7b9f10","title":"Basic Vim config for when ssh'ed onto an EC2 instance (yum install vim -y)","content":"alias vi='vi -c \"set nocompatible\" -c \"set number\" -c \"set cursorline\" -c \"set expandtab\" -c \"set hlsearch\" -c \"set visualbell\" -c \"set tabstop=2\" -c \"set shiftwidth=2\" -c \"syntax on\"'\nset nocompatible number cursorline expandtab hlsearch visualbell tabstop=2 shiftwidth=2\nsyntax on\n\n\" Stops odd issues like using arrow keys in insert mode will send key sequences that are misinterpreted by vi\n\" Turn on line numbers\n\" Highlight the current line\n\" Convert tabs to spaces\n\" Highlight all search matches\n\" Stop Vim from beeping at you when you make a mistake\n\" Set tab size in spaces (this is for manual indenting)\n\" The number of spaces inserted for a tab (used for auto indenting)\n\" Enable basic syntax highlighting\n# You can also do the following:\necho set nocompatible number cursorline expandtab hlsearch visualbell tabstop=2 shiftwidth=2 \u003e\u003e ~/.vimrc\necho syntax on \u003e\u003e ~/.vimrc\n","tags":""},{"id":"cff468ba808fbca09602","title":"Networking CIDR explained","content":"The table at the bottom of this gist was copied from: http://software77.net/cidr-101.html\n\n`10.0.0.0` is a 32 bit number split into four 8 bit groups (8, 16, 24, 32)\n\n\u003e Note: 1 byte == 8 bits (so `10` representing a single byte)\n\nWhere `n` (below) is given the value 8, 16, 24, or 32\n\n```\n10.0.0.0/n\n```\n\n`8` states the first 8 bits is accounted for (by the `10` we've specified).  \nMeaning the rest can be added up to their max of 255 (`10.255.255.255`)\n\n`16` states the first 16 bits is accounted for (by the `10.0` we've specified).  \nMeaning the rest can be added up to their max of 255 (`10.0.255.255`)\n\n`24` states the first 24 bits is accounted for (by the `10.0.0` we've specified).  \nMeaning the rest can be added up to their max of 255 (`10.0.0.255`)\n\n`32` states the first 32 bits is accounted for (by the `10.0.0.0` we've specified).  \nMeaning the rest can be added up to their max of 255 (`10.0.0.0`)\n\n## Example: `10.0.0.1`\n\n\u003ctable border=\"1\" id=\"table10\" bordercolor=\"#000080\" style=\"text-align: center; font-family: Verdana; font-size: 8pt; color: #000000\"\u003e\u003ctbody\u003e\u003ctr\u003e\u003ctd\u003e\u003cb\u003eIP\u003c/b\u003e\u003c/td\u003e\u003ctd colspan=\"8\"\u003e10\u003c/td\u003e\u003ctd colspan=\"8\"\u003e0\u003c/td\u003e\u003ctd colspan=\"8\"\u003e0\u003c/td\u003e\u003ctd colspan=\"8\"\u003e1\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e\u003cb\u003e8 Bit Blocks\u003c/b\u003e\u003c/td\u003e\u003ctd colspan=\"8\"\u003e8 bits [24-31]\u003c/td\u003e\u003ctd colspan=\"8\"\u003e8 bits [16-23]\u003c/td\u003e\u003ctd colspan=\"8\"\u003e8 bits [08-15]\u003c/td\u003e\u003ctd colspan=\"8\"\u003e8 bits [00-07]\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\n\t\t\t\t\t\t\u003ctd\u003e\u003cb\u003eBit #\u003c/b\u003e\u003c/td\u003e\n\t\t\t\t\t\t\u003ctd\u003e31\u003c/td\u003e\u003ctd\u003e30\u003c/td\u003e\u003ctd\u003e29\u003c/td\u003e\u003ctd\u003e28\u003c/td\u003e\u003ctd\u003e27\u003c/td\u003e\u003ctd\u003e26\u003c/td\u003e\u003ctd\u003e25\u003c/td\u003e\u003ctd\u003e24\u003c/td\u003e\u003ctd\u003e23\u003c/td\u003e\u003ctd\u003e22\u003c/td\u003e\u003ctd\u003e21\u003c/td\u003e\u003ctd\u003e20\u003c/td\u003e\u003ctd\u003e19\u003c/td\u003e\u003ctd\u003e18\u003c/td\u003e\u003ctd\u003e17\u003c/td\u003e\u003ctd\u003e16\u003c/td\u003e\u003ctd\u003e15\u003c/td\u003e\u003ctd\u003e14\u003c/td\u003e\u003ctd\u003e13\u003c/td\u003e\u003ctd\u003e12\u003c/td\u003e\u003ctd\u003e11\u003c/td\u003e\u003ctd\u003e10\u003c/td\u003e\u003ctd\u003e09\u003c/td\u003e\u003ctd\u003e08\u003c/td\u003e\u003ctd\u003e07\u003c/td\u003e\u003ctd\u003e06\u003c/td\u003e\u003ctd\u003e05\u003c/td\u003e\u003ctd\u003e04\u003c/td\u003e\u003ctd\u003e03\u003c/td\u003e\u003ctd\u003e02\u003c/td\u003e\u003ctd\u003e01\u003c/td\u003e\u003ctd\u003e00\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e\u003cb\u003eDecimal \u003c/b\u003e\u003c/td\u003e\u003ctd\u003e128\u003c/td\u003e\u003ctd\u003e64\u003c/td\u003e\u003ctd\u003e32\u003c/td\u003e\n\t\t\t\t\u003ctd\u003e16\u003c/td\u003e\u003ctd\u003e8\u003c/td\u003e\u003ctd\u003e4\u003c/td\u003e\u003ctd\u003e2\u003c/td\u003e\u003ctd\u003e1\u003c/td\u003e\u003ctd\u003e128\u003c/td\u003e\u003ctd\u003e64\u003c/td\u003e\u003ctd\u003e32\u003c/td\u003e\u003ctd\u003e16\u003c/td\u003e\u003ctd\u003e8\u003c/td\u003e\u003ctd\u003e4\u003c/td\u003e\u003ctd\u003e2\u003c/td\u003e\u003ctd\u003e1\u003c/td\u003e\u003ctd\u003e128\u003c/td\u003e\u003ctd\u003e64\u003c/td\u003e\u003ctd\u003e32\u003c/td\u003e\u003ctd\u003e16\u003c/td\u003e\u003ctd\u003e8\u003c/td\u003e\u003ctd\u003e4\u003c/td\u003e\u003ctd\u003e2\u003c/td\u003e\u003ctd\u003e1\u003c/td\u003e\u003ctd\u003e128\u003c/td\u003e\u003ctd\u003e64\u003c/td\u003e\u003ctd\u003e32\u003c/td\u003e\u003ctd\u003e16\u003c/td\u003e\u003ctd\u003e8\u003c/td\u003e\u003ctd\u003e4\u003c/td\u003e\u003ctd\u003e2\u003c/td\u003e\u003ctd\u003e1\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e\u003cb\u003eBinary\u003c/b\u003e\u003c/td\u003e\u003ctd\u003e0\u003c/td\u003e\u003ctd\u003e0\u003c/td\u003e\u003ctd\u003e0\u003c/td\u003e\u003ctd\u003e0\u003c/td\u003e\u003ctd\u003e\u003cb\u003e\u003cfont color=\"#DC143C\"\u003e1\u003c/font\u003e\u003c/b\u003e\u003c/td\u003e\u003ctd\u003e0\u003c/td\u003e\u003ctd\u003e\u003cb\u003e\u003cfont color=\"#DC143C\"\u003e1\u003c/font\u003e\u003c/b\u003e\u003c/td\u003e\u003ctd\u003e0\u003c/td\u003e\u003ctd\u003e0\u003c/td\u003e\u003ctd\u003e0\u003c/td\u003e\u003ctd\u003e0\u003c/td\u003e\u003ctd\u003e0\u003c/td\u003e\u003ctd\u003e0\u003c/td\u003e\u003ctd\u003e0\u003c/td\u003e\u003ctd\u003e0\u003c/td\u003e\u003ctd\u003e0\u003c/td\u003e\u003ctd\u003e0\u003c/td\u003e\u003ctd\u003e0\u003c/td\u003e\u003ctd\u003e0\u003c/td\u003e\u003ctd\u003e0\u003c/td\u003e\u003ctd\u003e0\u003c/td\u003e\u003ctd\u003e0\u003c/td\u003e\u003ctd\u003e0\u003c/td\u003e\u003ctd\u003e0\u003c/td\u003e\u003ctd\u003e0\u003c/td\u003e\u003ctd\u003e0\u003c/td\u003e\u003ctd\u003e0\u003c/td\u003e\u003ctd\u003e0\u003c/td\u003e\u003ctd\u003e0\u003c/td\u003e\u003ctd\u003e0\u003c/td\u003e\u003ctd\u003e0\u003c/td\u003e\u003ctd\u003e\u003cb\u003e\u003cfont color=\"#DC143C\"\u003e1\u003c/font\u003e\u003c/b\u003e\u003c/td\u003e\u003c/tr\u003e\u003c/tbody\u003e\u003c/table\u003e\n\t\t\t\t\t\n\u003e Notice the binary row marks `1` for the decimal numbers that add up to the specified byte  \n\u003e e.g. if you want `254` then you have `1` in all of the binary columns (under decimal) except the `1` at the end\n","tags":""},{"id":"7ddef5afaeeff601fc72","title":"[REST design: PUT vs POST] ","content":"**UPDATE Dec 2020**\n\nHTTP Method | Description\n------------|------------\n`GET`       | To _read_ a single or collection resource.\n`POST`      | To _create_ a resource.\n`PUT`       | To _entirely replace_ a resource.\n`PATCH`     | To _partially_ update a resource.\n`DELETE`    | To _delete_ a resource.\n\n\u003e See more at: [restcookbook.com](http://restcookbook.com/HTTP%20Methods/put-vs-post/#sthash.uH9tVV9x.dpuf), [restapitutorial.com](https://www.restapitutorial.com/lessons/httpmethods.html) and this blog post on [best practices](https://hackernoon.com/restful-api-designing-guidelines-the-best-practices-60e1d954e7c9).\n\n## PUT\n\nUse PUT when you can update a resource completely through a specific resource. For instance, if you know that an article resides at http://example.org/article/1234, you can PUT a new resource representation of this article directly through a PUT on this URL.\n\n## POST\n\nIf you do not know the actual resource location, for instance, when you add a new article, but do not have any idea where to store it, you can POST it to an URL, and let the server decide the actual URL.\n\n\u003e Note: there must always be a body param passed to the server when executing a POST or a PUT operation. Meaning you only pass enough information in the URL to identify the resource and not including any data for that resource. For example, this is bad: `/user/\u003cid\u003e/username/\u003cnew_username\u003e` but this is ok: `/user/\u003cid\u003e/username` upon which you'll then pass the new username as the body param: `curl --method PUT --header 'Content-Type: application/json' --data '{\"username\": \"foobar\"}' https://api.example.com/user/id/123/username`.\n","tags":"#REST #API #PUT #POST #DELETE #GET #methods #http"},{"id":"23fe68c35bb2907bdc44","title":"Ruby: get class name and method name","content":"class Foo\n  def initialize\n    p \"#{self.class.name}##{__method__}\"\n  end\nend\n\nFoo.new # =\u003e Foo#initialize\n","tags":""},{"id":"a4c88da0e30d7053d1b6","title":"Best Practice Code Design and Architecture","content":"## Types\n\nThere are a few different *types* of programming languages and each has their own idioms and best practices. It would be appropriate to first identify what these types are so you can recognise roughly where your language sits.\n\n- **Imperative programming**: telling the \"machine\" how to do something, and as a result what you want to happen will happen  \n  \u003e [Go](https://golang.org/) is a language that is imperative in nature as some abstractions - such as `Array#map` - are removed from the language and means it tends to encourage a particular explicit, concrete, and imperative programming style\n\n- **Declarative programming**: telling the \"machine\" what you would like to happen, and let the computer figure out how to do it  \n  \u003e Functional Programming and abstractions such as `Array#map` instead of `for` allow us to focus on *what* we want to happen rather than *how*\n\n- **Structured programming**: makes extensive use of subroutines, block structures, `for` and `while` loops etc  \n  \u003e Object-Oriented Programming is an extension of this\n\n## Before we get started...\n\nNone of the following are concrete recommendations. Just ideas, things for you and your team to consider.\n\n## General comments\n\n- Ask yourself all the time: \"can this thing be moved? does it have well defined boundaries?\"\n- Realise that 'simplicity' is not the same as 'easy'\n  - Easy is short term and most times can introduce additional complexity\n  - Simplicity allows for easy while avoiding complexity\n  - Much like 'complexity' is not the same as 'complicated'\n  - Recognise when you're over-engineering a problem with too much tech (go back to basics)\n\n## Code Design Best Practices\n\n\u003e Some of these will be cliches and others painfully obvious, but such is life\n\nAim to...\n\n- Design your code to allow future changes to be easily made\n  - Quoting Kent Beck: \"make the change easy, then make the easy change\"\n- Build loosely coupled applications and code that allows them to result in highly cohesive collaboration\n  - Functional Programming is usually a good demonstration of this (e.g. lots of reusable functions)\n- Be DRY (Don’t repeat yourself)\n  - But don't try to write your abstractions too quickly\n  - Allow patterns of reuse to show themselves, and *then* abstract\n- Utilise [design patterns](https://sourcemaking.com/design_patterns) where appropriate\n  - Don't necessarily *start* with a design pattern unless the problem you're solving is very common\n- Understand the [S.O.L.I.D principles](https://gist.github.com/Integralist/9482527)\n  - Even if OOP isn't necessarily your primary flavour\n  - Contracts and Interfaces allow for much greater flexibility\n    - e.g. \"Program to an 'interface', not an 'implementation'\"\n  - Injection of dependencies frees your objects/functions from unecessary context\n- Do not chain calls (i.e. [Law of Demeter](https://practicingruby.com/articles/temporal-coupling-and-the-law-of-demeter))\n- Refactor code regularly\n  - Every time you touch a file, leave it in a better state than you found it\n- Consider YAGNI (you aren’t going to need it)\n  - Be mindful of potential problems that could be around the corner\n  - But don't solve problems you don't have yet\n- Avoid Premature Optimization\n  - Measure your code's performance *before* you start trying to rewrite code that will have no measurable effect for your users\n\n## Architecture Best Practices\n\nAim to...\n\n- Decouple your services and behaviour\n  - This could be SOA or Microservices, doesn't really matter that much\n  - Pick whichever style is most appropriate to your project and team\n- Scale *out*, not *up*\n  - Horizontally scaling demonstrates a nice separation of services/behaviours\n  - More flexible than simply throwing more hardware at the problem\n- Design for resiliency\n  - Utilise mechanisms that faciliate graceful failure\n  - This might be utilising asynchronous queues over a typical HTTP/TCP request cycle\n  - This could include visualising your system architecture and identifying a [caching strategy](https://gist.github.com/Integralist/e69c50d02f0edf086dbd)\n  - For distributed/concurrent applications be mindful of issues such as \"eventual consistency\", efficient use of thread pools with blocking I/O processes, and 'even workflow distribution' problems\n- Design for performance\n  - Again, caching strategies would be useful\n  - Load test often and automate the process as much as possible\n    - e.g. you could run a mini-load test on every new 'release' or 'push to master' to measure perf degradation\n  - Downgrade your protocols where appropriate\n    - Do you need HTTP? Maybe a low-level RPC call and/or TCP server would be better suited?\n    - Maybe using an asynchronous distributed queue would increase performance as well as faciliate decoupling\n  - If working on a client-side application consider a \"performance budget\" and set-up automated notifications to keep track of it\n- Automate as much as possible\n- Consider the use of containers to allow for easier reproduction of running services\n## What do we want to achieve?\n\nWe want two documents:\n\n1. To inform developers on how they should behave and conduct themselves within a professional organisation\n2. To inform developers on what is considered to be good code design/architectural choices\n\nWe want developers to use these documents as a reference and to uphold the values they instill. \n\nFor the code quality, that doesn't mean we are gate-keepers trying to 'enforce' these as hardened rules. These should be seen as guidelines and best practice recommendations.\n\nFor the document to define how developers behave, see further below for my thoughts on that (i.e. the section \"What level of authority does it carry?\")\n\n## What is a \"community driven model\"?\n\nSimply: developers can open a \"pull request\" on either document and from that start a discussion around the change they wish to make.\n\nWe would want to document a template for when opening a PR (so we ensure both consistency, as well as a well thought out proposal). What goes into that template will need to be discussed and agreed upon by tech leads/architects.\n\n## What is a \"code of conduct\"/\"statement of values\"?\n\nAs mentioned in the section \"What do we want to achieve?\"...\n\n\u003e To inform developers on how they should behave and conduct themselves within a professional organisation\n\n## What is a \"code quality document\"?\n\nAs mentioned in the section \"What do we want to achieve?\"...\n\n\u003e To inform developers on what is considered to be good code design/architectural choices\n\n## What level of authority does it carry?\n\nAuthority depends on the document being discussed...\n\n### Code Quality\n\nAuthority could mean two things here:\n\n1. Trust\n2. Enforcement\n\nFor the 'trust', this should come from the collective agreement between tech leads and architects that the items listed are good and should be adhered to wherever possible.\n\nFor the 'enforcement', we can't realistically enforce teams to follow these concepts. Nor can we expect a tech lead to have their eye over every piece of code that gets committed to master; so we can't expect to enforce this on even a 'team by team' basis.\n\nThe best we can hope for, or at least work hard towards, is a pro-active engineering culture where we all think and do the best we can on the project/code we're working on/with. So following these guidelines then becomes a healthy/positive experience.\n\n### Values\n\nThe values should be enforced by the BBC and the engineering manager or someone like Robin Pembrooke (Head of News).\n\nWe should take these values seriously and every member of every team should be able to recognise when they're being violated and take responsibility for members of our own teams. Yes this is a big ask for some people, but you can't have one person (e.g. a tech lead) trying to handle this by themselves; least of all because they won't be around all the time to see it happening.\n\n## How is it written?\n\nIt should be written by tech leads and architects, with contributions from the developers.\n\nAny amendments or new additions should be discussed and at least collectively agreed upon by the tech leads/architects. But at least this will be an open discussion that developers can be involved with and feel they're able to impact upon the outcome.\n\n## When is it used?\n\nAs mentioned in the section \"What do we want to achieve?\"...\n\n\u003e We want developers to use these documents as a reference and to uphold the values they instill\n\nThe more both documents are viewed and looked at, the more common place their values will become and the need to reference them becomes less (that's the dreamy ideal at least).\n","tags":""},{"id":"c7e23300cf1e95c9c750","title":"List remote NPM dependencies","content":"npm-remote-ls -f true\n\n# vim the result to clean up for uniq command\n\ncat deps | uniq | wc -l\n","tags":""},{"id":"644095f06ec4eb8651a8","title":"irssi irc connecting to network and joining a channel (and identify yourself if you seen an error about joining a channel)","content":"- `/connect irc.freenode.net 8001`\n- `/join #nginx`\n- `/msg NickServ IDENTIFY \u003caccount\u003e \u003cpassword\u003e` †\n- `/msg \u003cperson\u003e \u003cmsg\u003e` to start a private message\n\n\u003e † `/msg NickServe IDENTITY Integralist \u003cpassword\u003e`  \n\u003e or `/msg nickserv SENDPASS Integralist` to change password (sends link to your email)  \n\u003e Commands Reference: http://www.deepspace.org/nickserv.htm#REGISTER  \n\u003e Freenode Help: https://freenode.net/kb/answer/registration\n\nWith irssi open you can do:\n\n- `/server add -network Freenode -auto irc.freenode.net`\n- `/server list` (to show it has set it up and configured it to `autoconnect`)\n- `/channel add -auto #nginx Freenode`\n- `/channel add -auto #go-nuts Freenode`\n- `/channel add -auto #rust-beginners Freenode`\n- `/channel list` (to show it has set it up and configured it to `autojoin`)\n\nFor more information: https://joost.vunderink.net/blog/2012/07/01/irssi-tricks-join-channels-automatically/\n\nBelow is a simple `~/.irssi/config` example:\n\n```bash\nservers = (\n  {\n    address = \"irc.freenode.net\";\n    chatnet = \"Freenode\";\n    port = \"8001\";\n    autoconnect = \"Yes\";\n  },\n);\n\nchatnets = {\n  Freenode = {\n    type = \"IRC\";\n    max_kicks = \"1\";\n    max_msgs = \"4\";\n    max_whois = \"1\";\n  };\n};\n\nchannels = (\n  { name = \"#nginx\"; chatnet = \"Freenode\"; autojoin = \"Yes\"; },\n  { name = \"#go-nuts\"; chatnet = \"Freenode\"; autojoin = \"Yes\"; },\n  { name = \"#rust-beginners\"; chatnet = \"Freenode\"; autojoin = \"Yes\"; },\n);\n\naliases = {\n  C = \"CLEAR\";\n  EXIT = \"QUIT\";\n  GOTO = \"SCROLLBACK GOTO\";\n  HL = \"HILIGHT\";\n  HOST = \"USERHOST\";\n  J = \"JOIN\";\n  K = \"KICK\";\n  LEAVE = \"PART\";\n  M = \"MSG\";\n  N = \"NAMES\";\n  P = \"PART\";\n  Q = \"QUERY\";\n  SAY = \"MSG *\";\n  SBAR = \"STATUSBAR\";\n  T = \"TOPIC\";\n  W = \"WHO\";\n  WC = \"WINDOW CLOSE\";\n  WG = \"WINDOW GOTO\";\n  WI = \"WHOIS\";\n  WII = \"WHOIS $0 $0\";\n  WL = \"WINDOW LIST\";\n  WN = \"WINDOW NEW HIDDEN\";\n  WQUERY = \"QUERY -window\";\n  1 = \"WINDOW GOTO 1\";\n  2 = \"WINDOW GOTO 2\";\n  3 = \"WINDOW GOTO 3\";\n  4 = \"WINDOW GOTO 4\";\n  5 = \"WINDOW GOTO 5\";\n  6 = \"WINDOW GOTO 6\";\n  7 = \"WINDOW GOTO 7\";\n  8 = \"WINDOW GOTO 8\";\n  9 = \"WINDOW GOTO 9\";\n  10 = \"WINDOW GOTO 10\";\n  11 = \"WINDOW GOTO 11\";\n  12 = \"WINDOW GOTO 12\";\n  13 = \"WINDOW GOTO 13\";\n  14 = \"WINDOW GOTO 14\";\n  15 = \"WINDOW GOTO 15\";\n  16 = \"WINDOW GOTO 16\";\n  17 = \"WINDOW GOTO 17\";\n  18 = \"WINDOW GOTO 18\";\n  19 = \"WINDOW GOTO 19\";\n  20 = \"WINDOW GOTO 20\";\n  21 = \"WINDOW GOTO 21\";\n  22 = \"WINDOW GOTO 22\";\n  23 = \"WINDOW GOTO 23\";\n  24 = \"WINDOW GOTO 24\";\n  25 = \"WINDOW GOTO 25\";\n  26 = \"WINDOW GOTO 26\";\n  27 = \"WINDOW GOTO 27\";\n  28 = \"WINDOW GOTO 28\";\n  29 = \"WINDOW GOTO 29\";\n  30 = \"WINDOW GOTO 30\";\n  31 = \"WINDOW GOTO 31\";\n  32 = \"WINDOW GOTO 32\";\n  33 = \"WINDOW GOTO 33\";\n  34 = \"WINDOW GOTO 34\";\n  35 = \"WINDOW GOTO 35\";\n  36 = \"WINDOW GOTO 36\";\n  37 = \"WINDOW GOTO 37\";\n  38 = \"WINDOW GOTO 38\";\n  39 = \"WINDOW GOTO 39\";\n  40 = \"WINDOW GOTO 40\";\n  41 = \"WINDOW GOTO 41\";\n  42 = \"WINDOW GOTO 42\";\n  43 = \"WINDOW GOTO 43\";\n  44 = \"WINDOW GOTO 44\";\n  45 = \"WINDOW GOTO 45\";\n  46 = \"WINDOW GOTO 46\";\n  47 = \"WINDOW GOTO 47\";\n  48 = \"WINDOW GOTO 48\";\n  49 = \"WINDOW GOTO 49\";\n  50 = \"WINDOW GOTO 50\";\n  51 = \"WINDOW GOTO 51\";\n  52 = \"WINDOW GOTO 52\";\n  53 = \"WINDOW GOTO 53\";\n  54 = \"WINDOW GOTO 54\";\n  55 = \"WINDOW GOTO 55\";\n  56 = \"WINDOW GOTO 56\";\n  57 = \"WINDOW GOTO 57\";\n  58 = \"WINDOW GOTO 58\";\n  59 = \"WINDOW GOTO 59\";\n  60 = \"WINDOW GOTO 60\";\n  61 = \"WINDOW GOTO 61\";\n  62 = \"WINDOW GOTO 62\";\n  63 = \"WINDOW GOTO 63\";\n  64 = \"WINDOW GOTO 64\";\n  65 = \"WINDOW GOTO 65\";\n  66 = \"WINDOW GOTO 66\";\n  67 = \"WINDOW GOTO 67\";\n  68 = \"WINDOW GOTO 68\";\n  69 = \"WINDOW GOTO 69\";\n  70 = \"WINDOW GOTO 70\";\n  71 = \"WINDOW GOTO 71\";\n  72 = \"WINDOW GOTO 72\";\n  73 = \"WINDOW GOTO 73\";\n  74 = \"WINDOW GOTO 74\";\n  75 = \"WINDOW GOTO 75\";\n  76 = \"WINDOW GOTO 76\";\n  77 = \"WINDOW GOTO 77\";\n  78 = \"WINDOW GOTO 78\";\n  79 = \"WINDOW GOTO 79\";\n  80 = \"WINDOW GOTO 80\";\n  81 = \"WINDOW GOTO 81\";\n  82 = \"WINDOW GOTO 82\";\n  83 = \"WINDOW GOTO 83\";\n  84 = \"WINDOW GOTO 84\";\n  85 = \"WINDOW GOTO 85\";\n  86 = \"WINDOW GOTO 86\";\n  87 = \"WINDOW GOTO 87\";\n  88 = \"WINDOW GOTO 88\";\n  89 = \"WINDOW GOTO 89\";\n  90 = \"WINDOW GOTO 90\";\n  91 = \"WINDOW GOTO 91\";\n  92 = \"WINDOW GOTO 92\";\n  93 = \"WINDOW GOTO 93\";\n  94 = \"WINDOW GOTO 94\";\n  95 = \"WINDOW GOTO 95\";\n  96 = \"WINDOW GOTO 96\";\n  97 = \"WINDOW GOTO 97\";\n  98 = \"WINDOW GOTO 98\";\n  99 = \"WINDOW GOTO 99\";\n};\n\nstatusbar = {\n  items = {\n    barstart = \"{sbstart}\";\n    barend = \"{sbend}\";\n\n    topicbarstart = \"{topicsbstart}\";\n    topicbarend = \"{topicsbend}\";\n\n    time = \"{sb $Z}\";\n    user = \"{sb {sbnickmode $cumode}$N{sbmode $usermode}{sbaway $A}}\";\n\n    window = \"{sb $winref:$tag/$itemname{sbmode $M}}\";\n    window_empty = \"{sb $winref{sbservertag $tag}}\";\n\n    prompt = \"{prompt $[.15]itemname}\";\n    prompt_empty = \"{prompt $winname}\";\n\n    topic = \" $topic\";\n    topic_empty = \" Irssi v$J - http://www.irssi.org\";\n\n    lag = \"{sb Lag: $0-}\";\n    act = \"{sb Act: $0-}\";\n    more = \"-- more --\";\n  };\n\n  default = {\n    window = {\n      disabled = \"no\";\n      type = \"window\";\n      placement = \"bottom\";\n      position = \"1\";\n      visible = \"active\";\n      items = {\n        barstart = { priority = \"100\"; };\n        time = { };\n        user = { };\n        window = { };\n        window_empty = { };\n        lag = { priority = \"-1\"; };\n        act = { priority = \"10\"; };\n        more = { priority = \"-1\"; alignment = \"right\"; };\n        barend = { priority = \"100\"; alignment = \"right\"; };\n      };\n    };\n\n    window_inact = {\n      type = \"window\";\n      placement = \"bottom\";\n      position = \"1\";\n      visible = \"inactive\";\n      items = {\n        barstart = { priority = \"100\"; };\n        window = { };\n        window_empty = { };\n        more = { priority = \"-1\"; alignment = \"right\"; };\n        barend = { priority = \"100\"; alignment = \"right\"; };\n      };\n    };\n\n    prompt = {\n      type = \"root\";\n      placement = \"bottom\";\n      position = \"100\";\n      visible = \"always\";\n      items = {\n        prompt = { priority = \"-1\"; };\n        prompt_empty = { priority = \"-1\"; };\n        input = { priority = \"10\"; };\n      };\n    };\n\n    topic = {\n      type = \"root\";\n      placement = \"top\";\n      position = \"1\";\n      visible = \"always\";\n      items = {\n        topicbarstart = { priority = \"100\"; };\n        topic = { };\n        topic_empty = { };\n        topicbarend = { priority = \"100\"; alignment = \"right\"; };\n      };\n    };\n  };\n};\n\nsettings = {\n  core = {\n    real_name = \"Mark McDonnell\";\n    user_name = \"Integralist\";\n    nick = \"Integralist\";\n  };\n  \"fe-text\" = { actlist_sort = \"refnum\"; };\n};\n```\n","tags":""},{"id":"f4eabcda00379fc7c0de","title":"Sift example that demonstrates how to ignore a directory and also display the line numbers whilst using a regex pattern with a word boundary","content":"# https://sift-tool.org/\n# https://github.com/svent/sift\n# brew install sift\n\nsift --exclude-dirs 'Godeps' --line-number '\\bint\\b'\n","tags":""},{"id":"4e84af31c483d0f5a182","title":"Code of Conduct (Template)","content":"# Code of Conduct\n\n\u003e A code of conduct is a set of rules outlining the social norms and rules and responsibilities of, or proper practices for, an individual, party or organization\n\n## Summary\n\nThe {NAME} is dedicated to providing a harassment-free working environment for all, regardless of gender, sexual orientation, disability, physical appearance, body size, race, or religion. We do not tolerate harassment of any form. All communication should be appropriate for a professional audience including people of many different backgrounds. \n\nSexual language and imagery is not appropriate for any communication and/or talks. Be kind and do not insult or put down others. Behave professionally. Remember that harassment and sexist, racist, or exclusionary jokes are not appropriate for {NAME}. Staff violating these rules should be reported to an appropriate line manager.\n\nThese are the values to which people in the {NAME} community should aspire:\n\n- Be friendly and welcoming\n- Be patient\n  - Remember that people have varying communication styles and that not everyone is using their native language. (Meaning and tone can be lost in translation.) \n- Be thoughtful\n  - Productive communication requires effort. Think about how your words will be interpreted.\n  - Remember that sometimes it is best to refrain entirely from commenting. \n- Be respectful\n  - In particular, respect differences of opinion. \n- Be charitable\n  - Interpret the arguments of others in good faith, do not seek to disagree.\n  - When we do disagree, try to understand why. \n- Avoid destructive behavior:\n  - Derailing: stay on topic; if you want to talk about something else, start a new conversation.\n  - Unconstructive criticism: don't merely decry the current state of affairs; offer—or at least solicit—suggestions as to how things may be improved.\n  - Snarking (pithy, unproductive, sniping comments)\n  - Discussing potentially offensive or sensitive issues; this all too often leads to unnecessary conflict.\n  - Microaggressions: brief and commonplace verbal, behavioral and environmental indignities that communicate hostile, derogatory or negative slights and insults to a person or group. \n\nPeople are complicated. You should expect to be misunderstood and to misunderstand others; when this inevitably occurs, resist the urge to be defensive or assign blame. Try not to take offense where no offense was intended. Give people the benefit of the doubt. Even if the intent was to provoke, do not rise to it. It is the responsibility of all parties to de-escalate conflict when it arises. \n\n## Reporting an incident\n\nIncidents that violate the Code of Conduct are extremely damaging to the {NAME}, and they will not be tolerated. The silver lining is that, in many cases, these incidents present a chance for the offenders, and the teams at large, to grow, learn, and become better. \n\n\u003e The following should be handled by a line manager who has been informed of the incident\n\nTry to get as much of the incident in written form. The important information to gather include the following:\n\n- Name and team of the participant doing the harassing\n- The location in which the incident occurred\n- The behavior that was in violation\n- The approximate time of the behavior\n- The circumstances surrounding the incident\n- Other people involved in the incident\n\nDepending on the severity/details of the incident, please follow these guidelines:\n\n- If there is any general threat to staff or any other doubts, summon security or police\n- Offer the victim a private place to sit\n- Ask \"is there a friend or trusted person who you would like to be with you?\" (if so, arrange for someone to fetch this person)\n- Ask them \"how can I help?\"\n- Provide them with your list of emergency contacts if they need help later\n- If everyone is presently physically safe, involve the police or security only at a victim's request\n\nThere are also some guidelines as to what not to do as an initial response:\n\n- Do not overtly invite them to withdraw the complaint or mention that withdrawal is OK. This suggests that you want them to do so, and is therefore coercive. \"If you're OK with pursuing the complaint\" suggests that you are by default pursuing it and is not coercive.\n- Do not ask for their advice on how to deal with the complaint. This is a staff responsibility.\n- Do not offer them input into penalties. This is the staff's responsibility.\n\nThe line manager who is handling the reported offence should find out the following:\n\n- What happened?\n- Are we doing anything about it?\n- Who is doing those things?\n- When are they doing them?\n\nAfter the above has been identified and discussed, have an appropriate line manager communicate with the alleged harasser. Make sure to inform them of what has been reported about them.\n\nAllow the alleged harasser to give their side of the story. After this point, if the report stands, let the alleged harasser know what actions will be taken against them.\n\nSome things for the staff to consider when dealing with Code of Conduct offenders:\n\n- Warning the harasser to cease their behaviour and that any further reports will result in sanctions\n- Requiring that the harasser avoid any interaction with, and physical proximity to, their victim until a resolution or course of action has been decided upon\n- Requiring that the harasser not volunteer for future events your organisation runs (either indefinitely or for a certain time period)\n- Depending on the severity/details of the incident, requiring that the harasser immediately be sent home\n- Depending on the severity/details of the incident, removing a harasser from membership of relevant {NAME} organisations\n- Depending on the severity/details of the incident, publishing an account of the harassment and calling for the resignation of the harasser from their responsibilities (usually pursued by people without formal authority: may be called for if the harasser is a team leader, or refuses to stand aside from the conflict of interest)\n\nGive accused staff members a place to appeal to if there is one, but in the meantime the report stands. Keep in mind that it is not a good idea to encourage an apology from the harasser.\n\nIt is very important how we deal with the incident publicly. Our policy is to make sure that everyone aware of the initial incident is also made aware that it is not according to policy and that official action has been taken - while still respecting the privacy of individual staff members. When speaking to individuals (those who are aware of the incident, but were not involved with the incident) about the incident it is a good idea to keep the details out.\n\nDepending on the incident, the head of responsible department, or designate, may decide to make one or more public announcements. If necessary, this will be done with a short announcement either during the plenary and/or through other channels. No one other than the head of responsible department or someone delegated authority from them should make any announcements. No personal information about either party will be disclosed as part of this process.\n\nIf some members of staff were angered by the incident, it is best to apologise to them that the incident occurred to begin with. If there are residual hard feelings, suggest to them to write an email to the responsible head of department. It will be dealt with accordingly.\n\n## Attribution\n\nThis Code of Conduct was adapted from both [Golang](https://golang.org/conduct) and the [Golang UK Conference](http://golanguk.com/conduct/).\n","tags":""},{"id":"e2a129d5f4fa04bf4c8b","title":"Ruby parsing of complex nested data structures from the Query String","content":"require \"rack\"\nrequire \"cgi\"\nrequire \"addressable/uri\"\nrequire \"pry\"\n\nclass HelloWorldApp\n  def self.call(env)\n    p CGI.parse(env[\"QUERY_STRING\"]) # {\"a\"=\u003e[\"a\"], \"b[c]\"=\u003e[\"c\"], \"b[d]\"=\u003e[\"d\"]}\n\n    uri = Addressable::URI.parse(env[\"REQUEST_URI\"])\n    p uri.query_values # {\"a\"=\u003e\"a\", \"b[c]\"=\u003e\"c\", \"b[d]\"=\u003e\"d\"}\n\n    binding.pry\n    [200, {}, \"Hello World\"]\n  end\nend\n\nRack::Server.start :app =\u003e HelloWorldApp\n\n# http://localhost:8080/?a=a\u0026b[0][c]=c\u0026b[0][d]=d\u0026b[1][e]=e\u0026b[1][f]=f\n","tags":""},{"id":"d16db70821e2a4c57bb0","title":"HTTP/2 notes (taken from https://www.nginx.com/wp-content/uploads/2015/09/NGINX_HTTP2_White_Paper_v4.pdf)","content":"## General features\n\nHTTP/2 adds five key features:\n\n- Single, Persistent Connection - Only one connection is used for each web page, as\nshown in the figure. The same connection is used as long as the web page is open.\n- Multiplexing - Requests and replies are prioritized and multiplexed onto separate\nstreams within the single connection. When the connection is stable, “head of line\nblocking” - making every transfer wait for all previous transfers to complete - is\neliminated.\n- Header Compression and Binary Encoding - Headers are compressed using a new,\nseparate, secure standard, HPACK compression, which reduces the amount of data\ncrossing the network. Header information is sent in compact, binary format, not as\nplain text.\n- Prioritization - Requests are assigned levels of dependency and requests at the same\nlevel are prioritized. The server uses this information to order and assign resources to\nfulfilling requests.\n- SSL Encryption - HTTP/2 allows you to add SSL support with, in some cases, no\nperformance penalty, making your site more secure.\n\n## SSL\n\nHow does HTTP/2 overcome the performance overhead imposed by SSL on HTTP/1.x? There\nare four key techniques:\n\n1. Having a single connection minimizes SSL handshaking.\n2. Headers are compressed, reducing the time needed to send them.\n3. Multiplexing means file transfers don’t wait on other requests.\n4. Files don’t need to be in-lined, concatenated, or sprited, so caching can work\noptimally.\n\nWhen compared to a non-SSL implementation, there is still SSL performance overhead for\nauthenticating the single connection and for encrypting and decrypting data, but this remaining overhead should be more or less offset by the performance improvements in HTTP/2.\n\n\u003e Note: The HTTP/2 specification also includes server push, in which the server sends files listed in a page’s HTML before they’re requested\n","tags":""},{"id":"0c12b8233666b443b29e","title":"Convert a P12 into a PEM and vice versa","content":"# Convert p12 to pem\nopenssl pkcs12 -in certificate.p12 -out certificate.pem -clcerts -nodes\n\n# Convert pem to p12\nopenssl pkcs12 -export -in certificate.pem -out certificate.p12 -passout pass:password\n","tags":""},{"id":"acda6e7647e0e23a001c","title":"Use Docker to setup a Ruby application to use a private gem server. The reason I'm documenting this is because Ruby's Bundler gem is notoriously problematic using SSL","content":"FROM ruby:2.1.2\nMAINTAINER Foo Bar \u003cfoo.bar@gmail.com\u003e\n\n# Create directory for code\nRUN mkdir /app\n\n# Set current working directory\nWORKDIR /app\n\n# Add Gemfile\nADD src/Gemfile /app/Gemfile\n\n# Change Gemfile to use a private gem server and remove :git path refs\nRUN sed -i -e 's/:git.*//' /app/Gemfile\nRUN sed -i 's/rubygems\\.org/my-private-gem-server.foobar\\.com/' /app/Gemfile\nRUN sed -i -e 's/\",$/\"/g' /app/Gemfile\n\n# Add ca cert\nADD dev.pem /home/root/dev.pem\nADD ca.pem /home/root/ca.pem\n\n# Environment variables for Bundler SSL support\nENV BUNDLE_SSL_CLIENT_CERT=/home/root/dev.pem\nENV BUNDLE_SSL_CA_CERT=/home/root/ca.pem\nENV HOME=/home/root\n\n# Create .gemrc SSL file\nRUN echo \":ssl_client_cert: /home/root/dev.pem\" \u003e /home/root/.gemrc\nRUN echo \":ssl_ca_cert: /home/root/ca.pem\" \u003e\u003e /home/root/.gemrc\n\n# Create gem credentials file\nRUN mkdir -p /home/root/.gem\nRUN echo \"---\" \u003e /home/root/.gem/credentials\nRUN echo \":rubygems_api_key: value_ignored\" \u003e\u003e /home/root/.gem/credentials\nRUN chmod 600 /home/root/.gem/credentials\n\n# Install gems\nRUN bundle install --jobs 4\n","tags":""},{"id":"16b2354277bd8dac01d8","title":"Jenkins CI -\u003e GitHub API","content":"printf \"\\nPOST result to GitHub\\n\\n\"\n\nif [ $(cat RUBOCOP_RESULT) == \"0\" ]; then\n  RESULT=\"success\"\nelse\n  RESULT=\"failure\"\nfi\n\nGITHUB_TOKEN=$(cat /etc/github_access_token)\nGITHUB_STATUS_API=\"https://api.github.com/repos/FOO-ORG/FOO-REPO/contents/PATH/TO/status.sh\"\n\ncurl --silent --location --header \"Accept: application/vnd.github.v3.raw\" --user $GITHUB_TOKEN:x-oauth-basic \\\n  $GITHUB_STATUS_API | bash -e -s -- \"composition\" $GIT_COMMIT \"Rubocop\" $RESULT \"jenkins/rubocop\"\n#!/bin/bash\n\nfunction setStatus()\n{\n  local REPO=$1\n  local COMMIT_HASH=$2\n  local MESSAGE=$3\n  local TYPE=pending\n  local GITHUB_TOKEN=$(cat /etc/github_access_token)\n  local CONTEXT=continuous-integration/jenkins\n\n  if [ ! -z \"$4\" ]; then\n    TYPE=$4\n  fi\n\n  if [ ! -z \"$5\" ]; then\n    CONTEXT=$5\n  fi\n\n  GITHUB_STATUS_ENDPOINT=https://api.github.com/repos/FOO-ORG/$REPO/statuses\n  STATUS=\"{\\\"state\\\": \\\"$TYPE\\\",\\\"target_url\\\": \\\"$BUILD_URL\\\",\\\"description\\\": \\\"$MESSAGE\\\",\\\"context\\\": \\\"$CONTEXT\\\"}\"\n  curl -u FOOUSER:$GITHUB_TOKEN -X POST -d \"$STATUS\" --header 'Content-Type: application/json' $GITHUB_STATUS_ENDPOINT/$COMMIT_HASH \u003e /dev/null\n}\n\nsetStatus \"$1\" \"$2\" \"$3\" \"$4\" \"$5\"\n","tags":""},{"id":"4d465b2f0e0c3a03db38","title":"Regular Expression that matches Camel Cased words","content":"Running example -\u003e http://regexr.com/3bjko\n\nFoobarbaz Some other stuff (no match)\nfoobarbaz some other stuff (no match)\nFooBarBaz Some Other Stuff (matches Stuff)\nFooBarBazQux Foo (matches Foo)\nFoo (matches Foo)\nFooBarBaz (matches FooBarBaz)\n","tags":""},{"id":"c94349404471165b8f8a","title":"Get HTTP Status Code","content":"curl -s -o /dev/null -w \"%{http_code}\" http://www.example.org/\n","tags":""},{"id":"70f17466b7056403b05d","title":"[curl performance timing] ","content":"# Run from the directory containing a curl-format.txt file (see below for file content)\ncurl -w \"@curl-format.txt\" -o /dev/null -s http://google.com/\n\n# you don't have to use an external file\ncurl -w  \"%{time_starttransfer}\\n\" -o /dev/null -s http://google.com/\n\n# you can use `ntimes` to try curl'ing endpoint multiple times\n# go get github.com/yuya-takeyama/ntimes\nntimes 100 -- curl -w  \"%{time_starttransfer}\\n\" -o /dev/null -s http://google.com/\n\n# now you can pipe results to the `percentile` command to figure out the various percentiles\n# go get github.com/yuya-takeyama/percentile\nntimes 100 -- curl -w  \"%{time_starttransfer}\\n\" -o /dev/null -s http://google.com/ | percentile\n\n# might be worth using `curl`'s --compressed option\n\\n\n            time_namelookup:  %{time_namelookup}\\n\n               time_connect:  %{time_connect}\\n\n            time_appconnect:  %{time_appconnect}\\n\n           time_pretransfer:  %{time_pretransfer}\\n\n              time_redirect:  %{time_redirect}\\n\n         time_starttransfer:  %{time_starttransfer}\\n\n                            ----------\\n\n                 time_total:  %{time_total}\\n\n\\n\n","tags":"#curl #performance #monitoring"},{"id":"e36796c130b4bf6b356c","title":"`curl -s -L bit.ly/\u003cyour_bitly\u003e  | bash` \u003c- bit.ly should point to a private gist that pulls content from a public S3 bucket","content":"#!/bin/bash\n\nfunction os_error {\n  echo \"ERROR: This script only installs \u003cname_of_binary\u003e on OSX (Darwin_x86_64) at the moment.  Visit Github to download the executable\"\n  exit 1\n}\n\necho -e \"Installing \u003cNAME_OF_BINARY\u003e:\\n\"\n\necho -n \" \u003e Checking OS compatibility... \"\nif [ \"$(uname -s)\" != \"Darwin\" -o \"$(uname -m)\" != \"x86_64\" ]; then\n  os_error\nelse\n  echo \"DONE\"\nfi\n\necho -n \" \u003e Fetching binary from S3... \"\ncurl -s -L https://\u003clocation_in_s3\u003e \u003e /usr/local/bin/\u003cname_of_binary\u003e\necho \"DONE\"\n\necho \" \u003e Save to /usr/local/bin/\u003cname_of_binary\u003e... DONE\"\n\necho -n \" \u003e Add execute permissions... \"\nchmod +x /usr/local/bin/\u003cname_of_binary\u003e\necho -e \"DONE\\n\"\n\necho -e \"Installation complete.\\n\"\n\necho \"Try: \u003cname_of_binary\u003e --help\"\n","tags":""},{"id":"6a39f1181b02edf4fdd6","title":"Dockerfile that demonstrates how to use Supervisord.org","content":"FROM golang:1.5-onbuild\n\nRUN apt-get update \u0026\u0026 \\\n   apt-get -y upgrade \u0026\u0026 \\\n   apt-get -y install supervisor \u0026\u0026 \\\n   mkdir -p /var/log/supervisor \u0026\u0026 \\\n   mkdir -p /etc/supervisor/conf.d\n\nADD supervisor/supervisor.conf /etc/supervisor.conf\nADD supervisor/godo-watch.conf /etc/supervisor/conf.d/godo-watch.conf\n\nRUN [\"go\", \"get\", \"-u\", \"gopkg.in/godo.v1/cmd/godo\"]\n\nCMD [\"supervisord\", \"-c\", \"/etc/supervisor.conf\"]\n[program:godo]\ncommand=/bin/bash -c \"cd ~/go/src/foo-project \u0026\u0026 /go/bin/godo watch-server --watch\"\n\n\n[supervisord]\nnodaemon=true\n\n[include]\nfiles = /etc/supervisor/conf.d/*.conf\n","tags":""},{"id":"147104c868f171f7604e","title":"AWS Assume Role","content":"#! /bin/bash\n#\n# Dependencies:\n#   brew install jq\n#\n# Example:\n#   source aws-assume-role\n#   alias aws-assume-role=\"source aws-assume-role\"\n#\n# Notes:\n#   Remove .sh file extension and move file to a location available to your $PATH\n#   chmod +x \u003cfile\u003e\n\nunset AWS_SESSION_TOKEN\nexport AWS_ACCESS_KEY_ID=\u003cyour_user_access_key\u003e\nexport AWS_SECRET_ACCESS_KEY=\u003cyour_user_secret_key\u003e\n\naws_assume_account=${1:-755368653476}\naws_assume_role=${2:-Administrators}\naws_assume_session=${3:-temp}\n\n# Note: ${var} instead of $var avoids bug with substitution deleting characters\necho \"arn:aws:iam::${aws_assume_account}:role/${aws_assume_role}\"\n\ntemp_role=$(aws sts assume-role \\\n                    --role-arn \"arn:aws:iam::${aws_assume_account}:role/${aws_assume_role}\" \\\n                    --role-session-name \"${aws_assume_session}\")\n\necho $aws_assume_account\necho $aws_assume_role\necho $aws_assume_session\n\n# Note: xargs strips the containing quotes which is essential for the export to work\nexport AWS_ACCESS_KEY_ID=$(echo $temp_role | jq .Credentials.AccessKeyId | xargs)\nexport AWS_SECRET_ACCESS_KEY=$(echo $temp_role | jq .Credentials.SecretAccessKey | xargs)\nexport AWS_SESSION_TOKEN=$(echo $temp_role | jq .Credentials.SessionToken | xargs)\n\nenv | grep -i AWS_\n","tags":""},{"id":"8236c15562389b10b576","title":"Demonstrates how to use Sumo Logic query language","content":"Take log message and parse as JSON (create new column `jsonobj`):\n\n```bash\nparse \"*\" as jsonobj\n```\n\nTake new `jsonobj` column and create a new column for the specified key in the JSON:\n\n```bash\njson field=jsonobj \"my-obj-key\"\n```\n\nAllow extracting multiple keys from the json object:\n  \n```bash\njson field=jsonobj \"event\", \"url\" as event, url\n```  \n\nExtract a regex match:\n\n```bash\nparse regex field=url \"cps/asset/(?\u003casset_id\u003e[^?]+)\"\n```\n\n\u003e Requires the use of a named capturing group  \n\u003e `(?\u003cyour_name\u003epattern_here)`\n\nIndicate case insensitivity with `(?i)`:\n\n```bash\n(?\u003ca_match\u003e(?i)topics)\n```\n\nParse contents out from the default `message` column:\n\n```bash\n_collector=Mozart | where component=\"mozart-routing\" | where environment=\"int\" | parse \"HTTPD*\" as Apache\n```\n\nYou can use a different format as well:\n\n```bash\n(_collector=Mozart) environment = \"live\" component = \"mozart-composition\"\n```\n_collector=Newsbeat AND read_feed | where environment = \"live\" | where component = \"newsbeat-most-popular-renderer\"\n\n_collector=Mozart | where component=\"mozart-composition\" | where environment=\"int\" | parse \"*\" as jsonobj | json field=jsonobj \"event\" | where event=\"ComponentLoaded\"\n\n_collector= Newsbeat | parse \"*\" as jsonobj | json field=jsonobj \"event\", \"url\" as event, url | where component=\"newsbeat-article-renderer\" | parse regex field=url \"cps/asset/(?\u003casset_id\u003e[^?]+)\"\n\n_collector= Newsbeat | parse \"*\" as jsonobj | json field=jsonobj \"event\", \"url\" as event, url | where component=\"newsbeat-article-renderer\" | parse regex field=event \"(?\u003ca_match\u003e(?i)topics)\"\n","tags":""},{"id":"354984f84b5dfec8a7c6","title":"Docker Machine on Mac OS X","content":"## VirtualBox\n\n- https://www.docker.com/toolbox\n- `docker-machine create --driver virtualbox dev`\n- `docker-machine env dev` (add values to `~/.zshrc`)\n  - e.g. `echo eval \"$(docker-machine env dev)\" \u003e\u003e ~/.zshrc`\n- `docker-machine ls`\n- `docker ps` (might need to re-source `.zshrc` file; e.g. `. ~/.zshrc`)\n- `docker run hello-world`\n- `docker-machine ip dev`\n- `docker-machine stop dev`\n- `docker-machine start dev`\n- `docker-machine \u003ccommand\u003e --help`\n\n---\n\n## VMWare Fusion\n\n- `docker-machine rm dev`\n- `docker-machine create --driver=vmwarefusion dev`\n- `docker-machine create --driver vmwarefusion --vmwarefusion-cpu-count 2 --vmwarefusion-disk-size 80000 --vmwarefusion-memory-size 4096 default`\n\n\u003e http://blog.javabien.net/2015/08/20/better-docker-on-osx-with-docker-machine-boot2docker-and-vmware/\n","tags":""},{"id":"e4f2fd44affa4bf901e5","title":"If a shell command returns an exit status then you'll find that in a CI environment that the job will immediately fail. To resolve this you should capture the error and then pipe the result and then use PIPESTATUS instead","content":"docker run \\\n  --rm \\\n  --cpu-shares 1024 \\\n  -v $WORKSPACE:/app \\\n  bbcnews/rubocop-config --fail-level F 2\u003e\u00261 | true\n    \nRUBOCOP_RESULT=\"${PIPESTATUS[0]}\"\n\n# Similar, but different use case where we need to use $? to get result of last command\n\ndocker run \\\n  --rm \\\n  --cpu-shares 1024 \\\n  -v $WORKSPACE:/app \\\n  ruby:2.1.2 \\\n  bash -c \"cd /app \u0026\u0026 gem install bundler \u0026\u0026 bundle install --jobs 4 \u0026\u0026 rspec\" 2\u003e\u00261\n\nTESTS_RESULT=\"$?\"\n","tags":""},{"id":"8247ac875ed6d556198b","title":"Test Files for Composition Example","content":"{\n  \"html\": \"\",\n  \"css\": \"\",\n  \"javascript\": \"\",\n  \"meta\": \"\u003cmeta name=\\\"viewport\\\" content=\\\"width=device-width, initial-scale=1.0\\\" /\u003e     \u003c!--orb.ws.require.lib--\u003e \u003cscript type=\\\"text/javascript\\\"\u003e/*\u003c![CDATA[*/ if (typeof window.define !== 'function' || typeof window.require !== 'function') { document.write('\u003cscript class=\\\"js-require-lib\\\" src=\\\"http://static.bbci.co.uk/frameworks/requirejs/lib.js\\\"\u003e\u003c'+'/script\u003e'); } /*]]\u003e*/\u003c/script\u003e \u003cscript type=\\\"text/javascript\\\"\u003e  bbcRequireMap = {\\\"jquery-1\\\":\\\"http://static.bbci.co.uk/frameworks/jquery/0.3.0/sharedmodules/jquery-1.7.2\\\", \\\"jquery-1.4\\\":\\\"http://static.bbci.co.uk/frameworks/jquery/0.3.0/sharedmodules/jquery-1.4\\\", \\\"jquery-1.9\\\":\\\"http://static.bbci.co.uk/frameworks/jquery/0.3.0/sharedmodules/jquery-1.9.1\\\", \\\"swfobject-2\\\":\\\"http://static.bbci.co.uk/frameworks/swfobject/0.1.10/sharedmodules/swfobject-2\\\", \\\"demi-1\\\":\\\"http://static.bbci.co.uk/frameworks/demi/0.10.0/sharedmodules/demi-1\\\", \\\"gelui-1\\\":\\\"http://static.bbci.co.uk/frameworks/gelui/0.9.13/sharedmodules/gelui-1\\\", \\\"cssp!gelui-1/overlay\\\":\\\"http://static.bbci.co.uk/frameworks/gelui/0.9.13/sharedmodules/gelui-1/overlay.css\\\", \\\"istats-1\\\":\\\"http://static.bbci.co.uk/frameworks/istats/0.26.31/modules/istats-1\\\", \\\"relay-1\\\":\\\"http://static.bbci.co.uk/frameworks/relay/0.2.6/sharedmodules/relay-1\\\", \\\"clock-1\\\":\\\"http://static.bbci.co.uk/frameworks/clock/0.1.9/sharedmodules/clock-1\\\", \\\"canvas-clock-1\\\":\\\"http://static.bbci.co.uk/frameworks/clock/0.1.9/sharedmodules/canvas-clock-1\\\", \\\"cssp!clock-1\\\":\\\"http://static.bbci.co.uk/frameworks/clock/0.1.9/sharedmodules/clock-1.css\\\", \\\"jssignals-1\\\":\\\"http://static.bbci.co.uk/frameworks/jssignals/0.3.6/modules/jssignals-1\\\", \\\"jcarousel-1\\\":\\\"http://static.bbci.co.uk/frameworks/jcarousel/0.1.10/modules/jcarousel-1\\\", \\\"bump-3\\\":\\\"//emp.bbci.co.uk/emp/bump-3/bump-3\\\"}; require({ baseUrl: 'http://static.bbci.co.uk/', paths: bbcRequireMap, waitSeconds: 30 }); \u003c/script\u003e   \u003cscript type=\\\"text/javascript\\\"\u003e/*\u003c![CDATA[*/ if (typeof bbccookies_flag === 'undefined') { bbccookies_flag = 'ON'; } showCTA_flag = true; cta_enabled = (showCTA_flag \u0026\u0026 (bbccookies_flag === 'ON')); (function(){var e=\\\"ckns_policy\\\",m=\\\"Thu, 01 Jan 1970 00:00:00 GMT\\\",k={ads:true,personalisation:true,performance:true,necessary:true};function f(p){if(f.cache[p]){return f.cache[p]}var o=p.split(\\\"/\\\"),q=[\\\"\\\"];do{q.unshift((o.join(\\\"/\\\")||\\\"/\\\"));o.pop()}while(q[0]!==\\\"/\\\");f.cache[p]=q;return q}f.cache={};function a(p){if(a.cache[p]){return a.cache[p]}var q=p.split(\\\".\\\"),o=[];while(q.length\u0026\u0026\\\"|co.uk|com|\\\".indexOf(\\\"|\\\"+q.join(\\\".\\\")+\\\"|\\\")===-1){if(q.length){o.push(q.join(\\\".\\\"))}q.shift()}f.cache[p]=o;return o}a.cache={};function i(o,t,p){var z=[\\\"\\\"].concat(a(window.location.hostname)),w=f(window.location.pathname),y=\\\"\\\",r,x;for(var s=0,v=z.length;s\u003cv;s++){r=z[s];for(var q=0,u=w.length;q\u003cu;q++){x=w[q];y=o+\\\"=\\\"+t+\\\";\\\"+(r?\\\"domain=\\\"+r+\\\";\\\":\\\"\\\")+(x?\\\"path=\\\"+x+\\\";\\\":\\\"\\\")+(p?\\\"expires=\\\"+p+\\\";\\\":\\\"\\\");bbccookies.set(y,true)}}}window.bbccookies={POLICY_REFRESH_DATE_MILLIS:new Date(2015,4,21,0,0,0,0).getTime(),POLICY_EXPIRY_COOKIENAME:\\\"ckns_policy_exp\\\",_setEverywhere:i,cookiesEnabled:function(){var o=\\\"ckns_testcookie\\\"+Math.floor(Math.random()*100000);this.set(o+\\\"=1\\\");if(this.get().indexOf(o)\u003e-1){g(o);return true}return false},set:function(o){return document.cookie=o},get:function(){return document.cookie},getCrumb:function(o){if(!o){return null}return decodeURIComponent(document.cookie.replace(new RegExp(\\\"(?:(?:^|.*;)\\\\\\\\s*\\\"+encodeURIComponent(o).replace(/[\\\\-\\\\.\\\\+\\\\*]/g,\\\"\\\\\\\\$\u0026\\\")+\\\"\\\\\\\\s*\\\\\\\\=\\\\\\\\s*([^;]*).*$)|^.*$\\\"),\\\"$1\\\"))||null},policyRequiresRefresh:function(){var p=new Date();p.setHours(0);p.setMinutes(0);p.setSeconds(0);p.setMilliseconds(0);if(bbccookies.POLICY_REFRESH_DATE_MILLIS\u003c=p.getTime()){var o=bbccookies.getCrumb(bbccookies.POLICY_EXPIRY_COOKIENAME);if(o){o=new Date(parseInt(o));o.setYear(o.getFullYear()-1);return bbccookies.POLICY_REFRESH_DATE_MILLIS\u003e=o.getTime()}else{return true}}else{return false}},_setPolicy:function(o){return h.apply(this,arguments)},readPolicy:function(){return b.apply(this,arguments)},_deletePolicy:function(){i(e,\\\"\\\",m)},isAllowed:function(){return true},_isConfirmed:function(){return c()!==null},_acceptsAll:function(){var o=b();return o\u0026\u0026!(j(o).indexOf(\\\"0\\\")\u003e-1)},_getCookieName:function(){return d.apply(this,arguments)},_showPrompt:function(){var o=((!this._isConfirmed()||this.policyRequiresRefresh())\u0026\u0026window.cta_enabled\u0026\u0026this.cookiesEnabled()\u0026\u0026!window.bbccookies_disable);return(window.orb\u0026\u0026window.orb.fig)?o\u0026\u0026(window.orb.fig(\\\"no\\\")||window.orb.fig(\\\"ck\\\")):o}};bbccookies._getPolicy=bbccookies.readPolicy;function d(p){var o=(\\\"\\\"+p).match(/^([^=]+)(?==)/);return(o\u0026\u0026o.length?o[0]:\\\"\\\")}function j(o){return\\\"\\\"+(o.ads?1:0)+(o.personalisation?1:0)+(o.performance?1:0)}function h(s){if(typeof s===\\\"undefined\\\"){s=k}if(typeof arguments[0]===\\\"string\\\"){var p=arguments[0],r=arguments[1];if(p===\\\"necessary\\\"){r=true}s=b();s[p]=r}else{if(typeof arguments[0]===\\\"object\\\"){s.necessary=true}}var q=new Date();q.setYear(q.getFullYear()+1);bbccookies.set(e+\\\"=\\\"+j(s)+\\\";domain=bbc.co.uk;path=/;expires=\\\"+q.toUTCString()+\\\";\\\");bbccookies.set(e+\\\"=\\\"+j(s)+\\\";domain=bbc.com;path=/;expires=\\\"+q.toUTCString()+\\\";\\\");var o=new Date(q.getTime());o.setMonth(o.getMonth()+1);bbccookies.set(bbccookies.POLICY_EXPIRY_COOKIENAME+\\\"=\\\"+q.getTime()+\\\";domain=bbc.co.uk;path=/;expires=\\\"+o.toUTCString()+\\\";\\\");bbccookies.set(bbccookies.POLICY_EXPIRY_COOKIENAME+\\\"=\\\"+q.getTime()+\\\";domain=bbc.com;path=/;expires=\\\"+o.toUTCString()+\\\";\\\");return s}function l(o){if(o===null){return null}var p=o.split(\\\"\\\");return{ads:!!+p[0],personalisation:!!+p[1],performance:!!+p[2],necessary:true}}function c(){var o=new RegExp(\\\"(?:^|; ?)\\\"+e+\\\"=(\\\\\\\\d\\\\\\\\d\\\\\\\\d)($|;)\\\"),p=document.cookie.match(o);if(!p){return null}return p[1]}function b(o){var p=l(c());if(!p){p=k}if(o){return p[o]}else{return p}}function g(o){return document.cookie=o+\\\"=;expires=\\\"+m+\\\";\\\"}function n(){var o='\u003cscript type=\\\"text/javascript\\\" src=\\\"http://static.bbci.co.uk/frameworks/bbccookies/0.6.11/script/bbccookies.js\\\"\u003e\u003c\\\\/script\u003e';if(window.bbccookies_flag===\\\"ON\\\"\u0026\u0026!bbccookies._acceptsAll()\u0026\u0026!window.bbccookies_disable){document.write(o)}}n()})(); /*]]\u003e*/\u003c/script\u003e \u003cscript type=\\\"text/javascript\\\"\u003e/*\u003c![CDATA[*/\\n(function(){window.fig=window.fig||{};window.fig.manager={include:function(a){a=a||window;var e=a.document,g=e.cookie,b=g.match(/(?:^|; ?)ckns_orb_fig=([^;]+)/);if(!b\u0026\u0026g.indexOf(\\\"ckns_orb_nofig=1\\\")\u003e-1){this.setFig(a,{no:1})}else{if(b){b=this.deserialise(decodeURIComponent(RegExp.$1));this.setFig(a,b)}e.write('\u003cscript src=\\\"https://fig.bbc.co.uk/frameworks/fig/1/fig.js\\\"\u003e\u003c'+\\\"/script\u003e\\\")}},confirm:function(a){a=a||window;if(a.orb\u0026\u0026a.orb.fig\u0026\u0026a.orb.fig(\\\"no\\\")){this.setNoFigCookie(a)}if(a.orb===undefined||a.orb.fig===undefined){this.setFig(a,{no:1});this.setNoFigCookie(a)}},setNoFigCookie:function(a){a.document.cookie=\\\"ckns_orb_nofig=1; expires=\\\"+new Date(new Date().getTime()+1000*60*10).toGMTString()+\\\";\\\"},setFig:function(a,b){(function(){var c=b;a.orb=a.orb||{};a.orb.fig=function(d){return(arguments.length)?c[d]:c}})()},deserialise:function(b){var a={};b.replace(/([a-z]{2}):([0-9]+)/g,function(){a[RegExp.$1]=+RegExp.$2});return a}}})();fig.manager.include();/*]]\u003e*/\u003c/script\u003e\\n \\n\u003c!--[if (gt IE 8) | (IEMobile)]\u003e\u003c!--\u003e\\n\u003clink rel=\\\"stylesheet\\\" href=\\\"http://static.bbci.co.uk/frameworks/barlesque/2.84.11/orb/4/style/orb.css\\\"\u003e\\n\u003c!--\u003c![endif]--\u003e\\n\\n\u003c!--[if (lt IE 9) \u0026 (!IEMobile)]\u003e\\n\u003clink rel=\\\"stylesheet\\\" href=\\\"http://static.bbci.co.uk/frameworks/barlesque/2.84.11/orb/4/style/orb-ie.css\\\"\u003e\\n\u003c![endif]--\u003e\\n\\n  \u003cscript type=\\\"text/javascript\\\"\u003e/*\u003c![CDATA[*/ (function(undefined){if(!window.bbc){window.bbc={}}var ROLLING_PERIOD_DAYS=30;window.bbc.Mandolin=function(id,segments,opts){var now=new Date().getTime(),storedItem,DEFAULT_START=now,DEFAULT_RATE=1,COOKIE_NAME=\\\"ckpf_mandolin\\\";opts=opts||{};this._id=id;this._segmentSet=segments;this._store=new window.window.bbc.Mandolin.Storage(COOKIE_NAME);this._opts=opts;this._rate=(opts.rate!==undefined)?+opts.rate:DEFAULT_RATE;this._startTs=(opts.start!==undefined)?new Date(opts.start).getTime():new Date(DEFAULT_START).getTime();this._endTs=(opts.end!==undefined)?new Date(opts.end).getTime():daysFromNow(ROLLING_PERIOD_DAYS);this._signupEndTs=(opts.signupEnd!==undefined)?new Date(opts.signupEnd).getTime():this._endTs;this._segment=null;if(typeof id!==\\\"string\\\"){throw new Error(\\\"Invalid Argument: id must be defined and be a string\\\")}if(Object.prototype.toString.call(segments)!==\\\"[object Array]\\\"){throw new Error(\\\"Invalid Argument: Segments are required.\\\")}if(opts.rate!==undefined\u0026\u0026(opts.rate\u003c0||opts.rate\u003e1)){throw new Error(\\\"Invalid Argument: Rate must be between 0 and 1.\\\")}if(this._startTs\u003ethis._endTs){throw new Error(\\\"Invalid Argument: end date must occur after start date.\\\")}if(!(this._startTs\u003cthis._signupEndTs\u0026\u0026this._signupEndTs\u003c=this._endTs)){throw new Error(\\\"Invalid Argument: SignupEnd must be between start and end date\\\")}removeExpired.call(this,now);var overrides=window.bbccookies.get().match(/ckns_mandolin_setSegments=([^;]+)/);if(overrides!==null){eval(\\\"overrides = \\\"+decodeURIComponent(RegExp.$1)+\\\";\\\");if(overrides[this._id]\u0026\u0026this._segmentSet.indexOf(overrides[this._id])==-1){throw new Error(\\\"Invalid Override: overridden segment should exist in segments array\\\")}}if(overrides!==null\u0026\u0026overrides[this._id]){this._segment=overrides[this._id]}else{if((storedItem=this._store.getItem(this._id))){this._segment=storedItem.segment}else{if(this._startTs\u003c=now\u0026\u0026now\u003cthis._signupEndTs\u0026\u0026now\u003c=this._endTs\u0026\u0026this._store.isEnabled()===true){this._segment=pick(segments,this._rate);if(opts.end===undefined){this._store.setItem(this._id,{segment:this._segment})}else{this._store.setItem(this._id,{segment:this._segment,end:this._endTs})}log.call(this,\\\"mandolin_segment\\\")}}}log.call(this,\\\"mandolin_view\\\")};window.bbc.Mandolin.prototype.getSegment=function(){return this._segment};function log(actionType,params){var that=this;require([\\\"istats-1\\\"],function(istats){istats.log(actionType,that._id+\\\":\\\"+that._segment,params?params:{})})}function removeExpired(expires){var items=this._store.getItems(),expiresInt=+expires;for(var key in items){if(items[key].end!==undefined\u0026\u0026+items[key].end\u003cexpiresInt){this._store.removeItem(key)}}}function getLastExpirationDate(data){var winner=0,rollingExpire=daysFromNow(ROLLING_PERIOD_DAYS);for(var key in data){if(data[key].end===undefined\u0026\u0026rollingExpire\u003ewinner){winner=rollingExpire}else{if(+data[key].end\u003ewinner){winner=+data[key].end}}}return(winner)?new Date(winner):new Date(rollingExpire)}window.bbc.Mandolin.prototype.log=function(params){log.call(this,\\\"mandolin_log\\\",params)};window.bbc.Mandolin.prototype.convert=function(params){log.call(this,\\\"mandolin_convert\\\",params);this.convert=function(){}};function daysFromNow(n){var endDate;endDate=new Date().getTime()+(n*60*60*24)*1000;return endDate}function pick(segments,rate){var picked,min=0,max=segments.length-1;if(typeof rate===\\\"number\\\"\u0026\u0026Math.random()\u003erate){return null}do{picked=Math.floor(Math.random()*(max-min+1))+min}while(picked\u003emax);return segments[picked]}window.bbc.Mandolin.Storage=function(name){validateCookieName(name);this._cookieName=name;this._isEnabled=(bbccookies.isAllowed(this._cookieName)===true\u0026\u0026bbccookies.cookiesEnabled()===true)};window.bbc.Mandolin.Storage.prototype.setItem=function(key,value){var storeData=this.getItems();storeData[key]=value;this.save(storeData);return value};window.bbc.Mandolin.Storage.prototype.isEnabled=function(){return this._isEnabled};window.bbc.Mandolin.Storage.prototype.getItem=function(key){var storeData=this.getItems();return storeData[key]};window.bbc.Mandolin.Storage.prototype.removeItem=function(key){var storeData=this.getItems();delete storeData[key];this.save(storeData)};window.bbc.Mandolin.Storage.prototype.getItems=function(){return deserialise(this.readCookie(this._cookieName)||\\\"\\\")};window.bbc.Mandolin.Storage.prototype.save=function(data){window.bbccookies.set(this._cookieName+\\\"=\\\"+encodeURIComponent(serialise(data))+\\\"; expires=\\\"+getLastExpirationDate(data).toUTCString()+\\\";\\\")};window.bbc.Mandolin.Storage.prototype.readCookie=function(name){var nameEq=name+\\\"=\\\",ca=window.bbccookies.get().split(\\\"; \\\"),i,c;validateCookieName(name);for(i=0;i\u003cca.length;i++){c=ca[i];if(c.indexOf(nameEq)===0){return decodeURIComponent(c.substring(nameEq.length,c.length))}}return null};function serialise(o){var str=\\\"\\\";for(var p in o){if(o.hasOwnProperty(p)){str+='\\\"'+p+'\\\"'+\\\":\\\"+(typeof o[p]===\\\"object\\\"?(o[p]===null?\\\"null\\\":\\\"{\\\"+serialise(o[p])+\\\"}\\\"):'\\\"'+o[p].toString()+'\\\"')+\\\",\\\"}}return str.replace(/,\\\\}/g,\\\"}\\\").replace(/,$/g,\\\"\\\")}function deserialise(str){var o;str=\\\"{\\\"+str+\\\"}\\\";if(!validateSerialisation(str)){throw\\\"Invalid input provided for deserialisation.\\\"}eval(\\\"o = \\\"+str);return o}var validateSerialisation=(function(){var OBJECT_TOKEN=\\\"\u003cObject\u003e\\\",ESCAPED_CHAR='\\\"\\\\\\\\n\\\\\\\\r\\\\\\\\u2028\\\\\\\\u2029\\\\\\\\u000A\\\\\\\\u000D\\\\\\\\u005C',ALLOWED_CHAR=\\\"([^\\\"+ESCAPED_CHAR+\\\"]|\\\\\\\\\\\\\\\\[\\\"+ESCAPED_CHAR+\\\"])\\\",KEY='\\\"'+ALLOWED_CHAR+'+\\\"',VALUE='(null|\\\"'+ALLOWED_CHAR+'*\\\"|'+OBJECT_TOKEN+\\\")\\\",KEY_VALUE=KEY+\\\":\\\"+VALUE,KEY_VALUE_SEQUENCE=\\\"(\\\"+KEY_VALUE+\\\",)*\\\"+KEY_VALUE,OBJECT_LITERAL=\\\"({}|{\\\"+KEY_VALUE_SEQUENCE+\\\"})\\\",objectPattern=new RegExp(OBJECT_LITERAL,\\\"g\\\");return function(str){if(str.indexOf(OBJECT_TOKEN)!==-1){return false}while(str.match(objectPattern)){str=str.replace(objectPattern,OBJECT_TOKEN)}return str===OBJECT_TOKEN}})();function validateCookieName(name){if(name.match(/ ,;/)){throw\\\"Illegal name provided, must be valid in browser cookie.\\\"}}})(); /*]]\u003e*/\u003c/script\u003e  \u003cscript type=\\\"text/javascript\\\"\u003e  document.documentElement.className += (document.documentElement.className? ' ' : '') + 'orb-js';  fig.manager.confirm(); \u003c/script\u003e \u003cscript src=\\\"http://static.bbci.co.uk/frameworks/barlesque/2.84.11/orb/4/script/orb/api.min.js\\\"\u003e\u003c/script\u003e \u003cscript type=\\\"text/javascript\\\"\u003e var blq = { environment: function() { return 'live'; } } \u003c/script\u003e   \u003cscript type=\\\"text/javascript\\\"\u003e /*\u003c![CDATA[*/ function oqsSurveyManager(w, flag) { if (flag !== 'OFF') { w.document.write('\u003cscript type=\\\"text/javascript\\\" src=\\\"http://static.bbci.co.uk/frameworks/barlesque/2.84.11/orb/4/script/vendor/edr.js\\\"\u003e\u003c'+'/script\u003e'); } } oqsSurveyManager(window, 'ON'); /*]]\u003e*/ \u003c/script\u003e  \u003cscript type=\\\"text/javascript\\\"\u003e /* \u003c![CDATA[ */ define('id-statusbar-config', { 'translation_signedout': \\\"Sign in\\\", 'translation_signedin': \\\"Your account\\\", 'use_overlay' : false, 'signin_url' : \\\"https://ssl.bbc.co.uk/id/signin\\\", 'locale' : \\\"en-GB\\\", 'policyname' : \\\"\\\", 'ptrt' : \\\"http://www.bbc.co.uk/\\\" }); /* ]]\u003e */ \u003c/script\u003e   \u003cscript type=\\\"text/javascript\\\"\u003e require(['istats-1'], function(istats){ if (typeof(document) != 'undefined' \u0026\u0026 typeof(document.cookie) != 'undefined') { var cookieAphidMatch = document.cookie.match(/ckpf_APHID=([^;]*)/); if (cookieAphidMatch \u0026\u0026 typeof(cookieAphidMatch[1]) == 'string') { istats.addLabels({'bbc_hid': cookieAphidMatch[1]}); } } })(); \u003c/script\u003e    \u003cscript type=\\\"text/javascript\\\"\u003e (function () { if (! window.require) { throw new Error('idcta: could not find require module'); } var map = {}; map['idapp-1'] = 'http://static.bbci.co.uk/idapp/0.70.90/modules/idapp/idapp-1'; map['idcta/idcta-1'] = 'http://static.bbci.co.uk/id/0.32.00/modules/idcta/idcta-1'; map['idcta/idCookie'] = 'http://static.bbci.co.uk/id/0.32.00/modules/idcta/idCookie'; map['idcta/overlayManager'] = 'http://static.bbci.co.uk/id/0.32.00/modules/idcta/overlayManager'; require({paths: map}); define('id-config', {\\\"idapp\\\":{\\\"version\\\":\\\"0.70.90\\\",\\\"hostname\\\":\\\"ssl.bbc.co.uk\\\",\\\"insecurehostname\\\":\\\"www.bbc.co.uk\\\",\\\"tld\\\":\\\"bbc.co.uk\\\"},\\\"idtranslations\\\":{\\\"version\\\":\\\"0.33.9\\\"},\\\"identity\\\":{\\\"baseUrl\\\":\\\"https:\\\\/\\\\/talkback.live.bbc.co.uk\\\\/identity\\\",\\\"cookieAgeDays\\\":730,\\\"accessTokenCookieName\\\":\\\"ckns_IDA-ATKN\\\"},\\\"pathway\\\":{\\\"name\\\":null,\\\"staticAssetUrl\\\":\\\"http:\\\\/\\\\/static.bbci.co.uk\\\\/idapp\\\\/0.70.90\\\\/modules\\\\/idapp\\\\/idapp-1\\\\/View.css\\\"},\\\"idpurl\\\":false}); })(); \u003c/script\u003e   \u003cscript type=\\\"text/javascript\\\"\u003e/*\u003c![CDATA[*/\\n    window.bbcFlagpoles_istats = 'ON';\\n    window.orb = window.orb || {};\\n\\n    /*]]\u003e*/\u003c/script\u003e\\n            \u003c!-- BBCDOTCOM template: responsive webservice  --\u003e\\n        \u003c!-- BBCDOTCOM head --\u003e\u003cscript type=\\\"text/javascript\\\"\u003e /*\u003c![CDATA[*/ var _sf_startpt = (new Date()).getTime(); /*]]\u003e*/ \u003c/script\u003e\u003cstyle type=\\\"text/css\\\"\u003e.bbccom_display_none{display:none;}\u003c/style\u003e\u003cscript type=\\\"text/javascript\\\"\u003e /*\u003c![CDATA[*/ var bbcdotcomConfig, googletag = googletag || {}; googletag.cmd = googletag.cmd || []; var bbcdotcom = false; (function(){ if(typeof require !== 'undefined') { require({ paths:{ \\\"bbcdotcom\\\":\\\"http://static.bbci.co.uk/bbcdotcom/0.3.328/script\\\" } }); } })(); /*]]\u003e*/ \u003c/script\u003e\u003cscript type=\\\"text/javascript\\\"\u003e /*\u003c![CDATA[*/ var bbcdotcom = { adverts: { keyValues: { set: function() {} } }, advert: { write: function () {}, show: function () {}, isActive: function () { return false; }, layout: function() { return { reset: function() {} } } }, config: { init: function() {}, isActive: function() {}, setSections: function() {}, isAdsEnabled: function() {}, setAdsEnabled: function() {}, isAnalyticsEnabled: function() {}, setAnalyticsEnabled: function() {}, setAssetPrefix: function() {}, setJsPrefix: function() {}, setSwfPrefix: function() {}, setCssPrefix: function() {}, setConfig: function() {}, getAssetPrefix: function() {}, getJsPrefix: function () {}, getSwfPrefix: function () {}, getCssPrefix: function () {} }, survey: { init: function(){ return false; } }, data: {}, init: function() {}, objects: function(str) { return false; }, locale: { set: function() {}, get: function() {} }, setAdKeyValue: function() {}, utils: { addEvent: function() {}, addHtmlTagClass: function() {}, log: function () {} }, addLoadEvent: function() {} }; /*]]\u003e*/ \u003c/script\u003e\u003cscript type=\\\"text/javascript\\\"\u003e /*\u003c![CDATA[*/ (function(){ if (typeof orb !== 'undefined' \u0026\u0026 typeof orb.fig === 'function') { if (orb.fig('ad') \u0026\u0026 orb.fig('uk') == 0) { bbcdotcom.data = { ads: (orb.fig('ad') ? 1 : 0), stats: (orb.fig('uk') == 0 ? 1 : 0), statsProvider: orb.fig('ap') }; } } else { document.write('\u003cscript type=\\\"text/javascript\\\" src=\\\"'+('https:' == document.location.protocol ? 'https://ssl.bbc.com' : 'http://tps.bbc.com')+'/wwscripts/data\\\"\u003e\\\\x3C/script\u003e'); } })(); /*]]\u003e*/ \u003c/script\u003e\u003cscript type=\\\"text/javascript\\\"\u003e /*\u003c![CDATA[*/ (function(){ if (typeof orb === 'undefined' || typeof orb.fig !== 'function') { bbcdotcom.data = { ads: bbcdotcom.data.a, stats: bbcdotcom.data.b, statsProvider: bbcdotcom.data.c }; } if (bbcdotcom.data.ads == 1) { document.write('\u003cscript type=\\\"text/javascript\\\" src=\\\"'+('https:' == document.location.protocol ? 'https://ssl.bbc.co.uk' : 'http://www.bbc.co.uk')+'/wwscripts/flag\\\"\u003e\\\\x3C/script\u003e'); } })(); /*]]\u003e*/ \u003c/script\u003e\u003cscript type=\\\"text/javascript\\\"\u003e /*\u003c![CDATA[*/ (function(){ if (window.bbcdotcom \u0026\u0026 (typeof bbcdotcom.flag == 'undefined' || (typeof bbcdotcom.data.ads !== 'undefined' \u0026\u0026 bbcdotcom.flag.a != 1))) { bbcdotcom.data.ads = 0; } if (/[?|\u0026]ads/.test(window.location.href) || /(^|; )ads=on; /.test(document.cookie) || /; ads=on(; |$)/.test(document.cookie)) { bbcdotcom.data.ads = 1; bbcdotcom.data.stats = 1; } if (window.bbcdotcom \u0026\u0026 (bbcdotcom.data.ads == 1 || bbcdotcom.data.stats == 1)) { bbcdotcom.assetPrefix = \\\"http://static.bbci.co.uk/bbcdotcom/0.3.328/\\\"; document.write('\u003clink rel=\\\"stylesheet\\\" type=\\\"text/css\\\" href=\\\"http://static.bbci.co.uk/bbcdotcom/0.3.328/style/orb/bbccom.css\\\" /\u003e'); (function() { var useSSL = 'https:' == document.location.protocol; var src = (useSSL ? 'https:' : 'http:') + '//www.googletagservices.com/tag/js/gpt.js'; document.write('\u003cscr' + 'ipt src=\\\"' + src + '\\\"\u003e\\\\x3C/script\u003e'); })(); if (/(sandbox|int)(.dev)*.bbc.co*/.test(window.location.href) || /[?|\u0026]ads-debug/.test(window.location.href) || document.cookie.indexOf('ads-debug=') !== -1) { document.write('\u003cscript type=\\\"text/javascript\\\" src=\\\"http://static.bbci.co.uk/bbcdotcom/0.3.328/script/orb/individual.js\\\"\u003e\\\\x3C/script\u003e'); } else { document.write('\u003cscript type=\\\"text/javascript\\\" src=\\\"http://static.bbci.co.uk/bbcdotcom/0.3.328/script/orb/bbcdotcom.js\\\"\u003e\\\\x3C/script\u003e'); } if(/[\\\\\\\\?\u0026]ads=([^\u0026#]*)/.test(window.location.href)) { document.write('\u003cscript type=\\\"text/javascript\\\" src=\\\"http://static.bbci.co.uk/bbcdotcom/0.3.328/script/orb/adverts/adSuites.js\\\"\u003e\\\\x3C/script\u003e'); } } })(); /*]]\u003e*/ \u003c/script\u003e\u003cscript type=\\\"text/javascript\\\"\u003e /*\u003c![CDATA[*/ (function(){ if (window.bbcdotcom \u0026\u0026 (bbcdotcom.data.ads == 1 || bbcdotcom.data.stats == 1)) { bbcdotcomConfig = {\\\"adFormat\\\":\\\"standard\\\",\\\"adKeyword\\\":\\\"\\\",\\\"adMode\\\":\\\"smart\\\",\\\"adsEnabled\\\":true,\\\"appAnalyticsSections\\\":\\\"\\\",\\\"asyncEnabled\\\":false,\\\"disableInitialLoad\\\":false,\\\"advertInfoPageUrl\\\":\\\"http:\\\\/\\\\/www.bbc.co.uk\\\\/faqs\\\\/online\\\\/adverts_general\\\",\\\"advertisementText\\\":\\\"Advertisement\\\",\\\"analyticsEnabled\\\":true,\\\"appName\\\":\\\"barlesque\\\",\\\"assetPrefix\\\":\\\"http:\\\\/\\\\/static.bbci.co.uk\\\\/bbcdotcom\\\\/0.3.328\\\\/\\\",\\\"continuousPlayEnabled\\\":false,\\\"customAdParams\\\":[],\\\"customStatsParams\\\":[],\\\"headline\\\":\\\"\\\",\\\"id\\\":\\\"\\\",\\\"inAssociationWithText\\\":\\\"in association with\\\",\\\"keywords\\\":\\\"\\\",\\\"language\\\":\\\"\\\",\\\"orbTransitional\\\":false,\\\"outbrainEnabled\\\":true,\\\"palEnv\\\":\\\"live\\\",\\\"productName\\\":\\\"\\\",\\\"sections\\\":[],\\\"siteCatalystEnabled\\\":true,\\\"comScoreEnabled\\\":true,\\\"slots\\\":\\\"\\\",\\\"sponsoredByText\\\":\\\"is sponsored by\\\",\\\"adsByGoogleText\\\":\\\"Ads by Google\\\",\\\"summary\\\":\\\"\\\",\\\"type\\\":\\\"\\\",\\\"staticBase\\\":\\\"\\\\/bbcdotcom\\\",\\\"staticHost\\\":\\\"http:\\\\/\\\\/static.bbci.co.uk\\\",\\\"staticVersion\\\":\\\"0.3.328\\\",\\\"staticPrefix\\\":\\\"http:\\\\/\\\\/static.bbci.co.uk\\\\/bbcdotcom\\\\/0.3.328\\\",\\\"dataHttp\\\":\\\"tps.bbc.com\\\",\\\"dataHttps\\\":\\\"ssl.bbc.com\\\",\\\"flagHttp\\\":\\\"www.bbc.co.uk\\\",\\\"flagHttps\\\":\\\"ssl.bbc.co.uk\\\",\\\"analyticsHttp\\\":\\\"sa.bbc.com\\\",\\\"analyticsHttps\\\":\\\"ssa.bbc.com\\\"}; bbcdotcom.config.init(bbcdotcomConfig, bbcdotcom.data, window.location, window.document); bbcdotcom.config.setAssetPrefix(\\\"http://static.bbci.co.uk/bbcdotcom/0.3.328/\\\"); document.write('\u003c!--[if IE 7]\u003e\u003cscript type=\\\"text/javascript\\\"\u003ebbcdotcom.config.setIE7(true);\\\\x3C/script\u003e\u003c![endif]--\u003e'); document.write('\u003c!--[if IE 8]\u003e\u003cscript type=\\\"text/javascript\\\"\u003ebbcdotcom.config.setIE8(true);\\\\x3C/script\u003e\u003c![endif]--\u003e'); document.write('\u003c!--[if IE 9]\u003e\u003cscript type=\\\"text/javascript\\\"\u003ebbcdotcom.config.setIE9(true);\\\\x3C/script\u003e\u003c![endif]--\u003e'); if (/[?|\u0026]ex-dp/.test(window.location.href) || document.cookie.indexOf('ex-dp=') !== -1) { bbcdotcom.utils.addHtmlTagClass('bbcdotcom-ex-dp'); } } })(); /*]]\u003e*/ \u003c/script\u003e\"\n}\n{\n  \"html\": \"\u003ch1\u003eMy Title\u003c/h1\u003e\",\n  \"css\": \"\u003clink rel='stylesheet' src='https://s3-eu-west-1.amazonaws.com/shared-application-buckets-public-1pmfwo80l61it/composition-example/assets/css/title.css'\u003e\",\n  \"javascript\": \"\u003cscript\u003ealert('Hello from Title component');\u003c/script\u003e\",\n  \"meta\": \"\u003cmeta name='author' content='BBC News'\u003e\"\n}\n{\n  \"html\": \"\u003ch2\u003eMy Article\u003c/h2\u003e\",\n  \"css\": \"\u003clink rel='stylesheet' src='https://s3-eu-west-1.amazonaws.com/shared-application-buckets-public-1pmfwo80l61it/composition-example/assets/css/article.css'\u003e\",\n  \"javascript\": \"\u003cscript\u003ealert('Hello from Article component');\u003c/script\u003e\",\n  \"meta\": \"\u003cmeta name='author' content='BBC News Editorial'\u003e\"\n}\n{\n  \"html\": \"\u003c!-- BBCDOTCOM bodyFirst --\u003e\u003cdiv id=\\\"bbccom_interstitial_ad\\\" class=\\\"bbccom_display_none\\\"\u003e\u003c/div\u003e\u003cdiv id=\\\"bbccom_interstitial\\\" class=\\\"bbccom_display_none\\\"\u003e\u003cscript type=\\\"text/javascript\\\"\u003e /*\u003c![CDATA[*/ (function() { if (window.bbcdotcom \u0026\u0026 bbcdotcom.config.isActive('ads')) { googletag.cmd.push(function() { googletag.display('bbccom_interstitial'); }); } }()); /*]]\u003e*/ \u003c/script\u003e\u003c/div\u003e\u003cdiv id=\\\"bbccom_wallpaper_ad\\\" class=\\\"bbccom_display_none\\\"\u003e\u003c/div\u003e\u003cdiv id=\\\"bbccom_wallpaper\\\" class=\\\"bbccom_display_none\\\"\u003e\u003cscript type=\\\"text/javascript\\\"\u003e /*\u003c![CDATA[*/ (function() { var wallpaper; if (window.bbcdotcom \u0026\u0026 bbcdotcom.config.isActive('ads')) { if (bbcdotcom.config.isAsync()) { googletag.cmd.push(function() { googletag.display('bbccom_wallpaper'); }); } else { googletag.display(\\\"wallpaper\\\"); } wallpaper = bbcdotcom.adverts.adRegister.getAd('wallpaper'); if (wallpaper !== null \u0026\u0026 wallpaper !== undefined) { wallpaper.setDomElement('bbccom_wallpaper'); } } }()); /*]]\u003e*/ \u003c/script\u003e\u003c/div\u003e\u003cscript type=\\\"text/javascript\\\"\u003e /*\u003c![CDATA[*/ (function() { if (window.bbcdotcom \u0026\u0026 bbcdotcom.config.isActive('ads')) { document.write(unescape('%3Cscript id=\\\"gnlAdsEnabled\\\" class=\\\"bbccom_display_none\\\"%3E%3C/script%3E')); } if (window.bbcdotcom \u0026\u0026 bbcdotcom.config.isActive('analytics')) { document.write(unescape('%3Cscript id=\\\"gnlAnalyticsEnabled\\\" class=\\\"bbccom_display_none\\\"%3E%3C/script%3E')); } if (window.bbcdotcom \u0026\u0026 bbcdotcom.config.isActive('continuousPlay')) { document.write(unescape('%3Cscript id=\\\"gnlContinuousPlayEnabled\\\" class=\\\"bbccom_display_none\\\"%3E%3C/script%3E')); } }()); /*]]\u003e*/ \u003c/script\u003e \u003cdiv id=\\\"blq-global\\\"\u003e \u003cdiv id=\\\"blq-pre-mast\\\"\u003e  \u003c/div\u003e \u003c/div\u003e  \u003cscript type=\\\"text/html\\\" id=\\\"blq-bbccookies-tmpl\\\"\u003e\u003c![CDATA[ \u003csection\u003e \u003cdiv id=\\\"bbccookies\\\" class=\\\"bbccookies-banner orb-banner-wrapper bbccookies-d\\\"\u003e \u003cdiv id=\\\"bbccookies-prompt\\\" class=\\\"orb-banner b-g-p b-r b-f\\\"\u003e \u003ch2 class=\\\"orb-banner-title\\\"\u003e Cookies on the BBC website \u003c/h2\u003e \u003cp class=\\\"orb-banner-content\\\" dir=\\\"ltr\\\"\u003e The BBC has updated its cookie policy. We use cookies to ensure that we give you the best experience on our website. This includes cookies from third party social media websites if you visit a page which contains embedded content from social media. Such third party cookies may track your use of the BBC website.\u003cspan class=\\\"bbccookies-international-message\\\"\u003e We and our partners also use cookies to ensure we show you advertising that is relevant to you.\u003c/span\u003e If you continue without changing your settings, we'll assume that you are happy to receive all cookies on the BBC website. However, you can change your cookie settings at any time. \u003c/p\u003e \u003cul class=\\\"orb-banner-options\\\"\u003e \u003cli id=\\\"bbccookies-continue\\\"\u003e \u003cbutton type=\\\"button\\\" id=\\\"bbccookies-continue-button\\\"\u003eContinue\u003c/button\u003e \u003c/li\u003e \u003cli id=\\\"bbccookies-settings\\\"\u003e \u003ca href=\\\"/privacy/cookies/managing/cookie-settings.html\\\"\u003eChange settings\u003c/a\u003e \u003c/li\u003e \u003cli id=\\\"bbccookies-more\\\"\u003e\u003ca href=\\\"/privacy/cookies/bbc\\\"\u003eFind out more\u003c/a\u003e\u003c/li\u003e\u003c/ul\u003e \u003c/div\u003e \u003c/div\u003e \u003c/section\u003e ]]\u003e\u003c/script\u003e \u003cscript type=\\\"text/javascript\\\"\u003e/*\u003c![CDATA[*/ (function(){if(bbccookies._showPrompt()){var g=document,b=g.getElementById(\\\"blq-pre-mast\\\"),e=g.getElementById(\\\"blq-bbccookies-tmpl\\\"),a,f;if(b\u0026\u0026g.createElement){a=g.createElement(\\\"div\\\");f=e.innerHTML;f=f.replace(\\\"\u003c\\\"+\\\"![CDATA[\\\",\\\"\\\").replace(\\\"]]\\\"+\\\"\u003e\\\",\\\"\\\");a.innerHTML=f;b.appendChild(a);blqCookieContinueButton=g.getElementById(\\\"bbccookies-continue-button\\\");blqCookieContinueButton.onclick=function(){a.parentNode.removeChild(a);return false};bbccookies._setPolicy(bbccookies.readPolicy())}var c=g.getElementById(\\\"bbccookies\\\");if(c\u0026\u0026!window.orb.fig(\\\"uk\\\")){c.className=c.className.replace(/\\\\bbbccookies-d\\\\b/,\\\"\\\");c.className=c.className+(\\\" bbccookies-w\\\")}}})(); /*]]\u003e*/\u003c/script\u003e   \u003cscript type=\\\"text/javascript\\\"\u003e/*\u003c![CDATA[*/ if (bbccookies.isAllowed('s1')) { var istatsTrackingUrl = '//sa.bbc.co.uk/bbc/bbc/s?name=frameworks.barlesque.orb.webservice.json.page\u0026pal_route=webserviceapi\u0026ml_name=barlesque\u0026app_type=responsive\u0026language=en-GB\u0026ml_version=0.26.31\u0026pal_webapp=barlesque\u0026prod_name=frameworks\u0026app_name=frameworks'; require(['istats-1'], function (istats) {  istats.addCollector({'name': 'default', 'url': '//sa.bbc.co.uk/bbc/bbc/s', 'seperator': '\u0026' }); var counterName = (window.istats_countername) ? window.istats_countername : istatsTrackingUrl.match(/[\\\\?\u0026]name=([^\u0026]*)/i)[1]; istats.setCountername(counterName);  if (/\\\\bIDENTITY=/.test(document.cookie)) { istats.addLabels({'bbc_identity': '1'}); } if (/\\\\bckns_policy=\\\\d\\\\d0/.test(document.cookie)) { istats.addLabels({'ns_nc': '1'}); } var c = (document.cookie.match(/\\\\bckns_policy=(\\\\d\\\\d\\\\d)/) || []).pop() || ''; var screenWidthAndHeight = 'unavailable'; if (window.screen \u0026\u0026 screen.width \u0026\u0026 screen.height) { screenWidthAndHeight = screen.width + 'x' + screen.height; } istats.addLabels('pal_route=webserviceapi\u0026ml_name=barlesque\u0026app_type=responsive\u0026language=en-GB\u0026ml_version=0.26.31\u0026pal_webapp=barlesque\u0026prod_name=frameworks\u0026app_name=frameworks'); istats.addLabels({  'blq_s': '4d', 'blq_r': '2.7', 'blq_v': 'default', 'blq_e': 'pal',  'bbc_mc': (c ? 'ad' + c.charAt(0) + 'ps' + c.charAt(1) + 'pf' + c.charAt(2) : 'not_set'), 'screen_resolution': screenWidthAndHeight, 'ns_referrer': encodeURI(((window.orb.referrer) ? window.orb.referrer : document.referrer)) } );  istats.invoke(); }); } /*]]\u003e*/\u003c/script\u003e  \u003c!-- Begin iStats 20100118 (UX-CMC 1.1009.3) --\u003e \u003cscript type=\\\"text/javascript\\\"\u003e/*\u003c![CDATA[*/ if (bbccookies.isAllowed('s1')) { (function () { require(['istats-1'], function (istats) { istatsTrackingUrl = istats.getDefaultURL(); if (istats.isEnabled() \u0026\u0026 bbcFlagpoles_istats === 'ON') { sitestat(istatsTrackingUrl); } else { window.ns_pixelUrl = istatsTrackingUrl; /* used by Flash library to track */ } function sitestat(n) { var j = document, f = j.location, b = \\\"\\\"; if (j.cookie.indexOf(\\\"st_ux=\\\") != -1) { var k = j.cookie.split(\\\";\\\"); var e = \\\"st_ux\\\", h = document.domain, a = \\\"/\\\"; if (typeof ns_ != \\\"undefined\\\" \u0026\u0026 typeof ns_.ux != \\\"undefined\\\") { e = ns_.ux.cName || e; h = ns_.ux.cDomain || h; a = ns_.ux.cPath || a } for (var g = 0, f = k.length; g \u003c f; g++) { var m = k[g].indexOf(\\\"st_ux=\\\"); if (m != -1) { b = \\\"\u0026\\\" + decodeURI(k[g].substring(m + 6)) } } bbccookies.set(e + \\\"=; expires=\\\" + new Date(new Date().getTime() - 60).toGMTString() + \\\"; path=\\\" + a + \\\"; domain=\\\" + h); } window.ns_pixelUrl = n;  } }); })(); } else { window.istats = {enabled: false}; } /*]]\u003e*/\u003c/script\u003e \u003cnoscript\u003e\u003cp style=\\\"position: absolute; top: -999em;\\\"\u003e\u003cimg src=\\\"//sa.bbc.co.uk/bbc/bbc/s?name=frameworks.barlesque.orb.webservice.json.page\u0026amp;pal_route=webserviceapi\u0026amp;ml_name=barlesque\u0026amp;app_type=responsive\u0026amp;language=en-GB\u0026amp;ml_version=0.26.31\u0026amp;pal_webapp=barlesque\u0026amp;prod_name=frameworks\u0026amp;app_name=frameworks\u0026amp;blq_js_enabled=0\u0026amp;blq_s=4d\u0026amp;blq_r=2.7\u0026amp;blq_v=default\u0026amp;blq_e=pal \\\" height=\\\"1\\\" width=\\\"1\\\" alt=\\\"\\\"/\u003e\u003c/p\u003e\u003c/noscript\u003e \u003c!-- End iStats (UX-CMC) --\u003e  \\n \u003c!--[if (gt IE 8) | (IEMobile)]\u003e\u003c!--\u003e \u003cheader id=\\\"orb-banner\\\" role=\\\"banner\\\"\u003e \u003c!--\u003c![endif]--\u003e \u003c!--[if (lt IE 9) \u0026 (!IEMobile)]\u003e \u003c![if (IE 8)]\u003e \u003cheader id=\\\"orb-banner\\\" role=\\\"banner\\\" class=\\\"orb-old-ie orb-ie8\\\"\u003e \u003c![endif]\u003e \u003c![if (IE 7)]\u003e \u003cheader id=\\\"orb-banner\\\" role=\\\"banner\\\" class=\\\"orb-old-ie orb-ie7\\\"\u003e \u003c![endif]\u003e \u003c![if (IE 6)]\u003e \u003cheader id=\\\"orb-banner\\\" role=\\\"banner\\\" class=\\\"orb-old-ie orb-ie6\\\"\u003e \u003c![endif]\u003e \u003c![endif]--\u003e \u003cdiv id=\\\"orb-header\\\"  class=\\\"orb-nav-pri orb-nav-pri-white orb-nav-empty\\\"  \u003e \u003cdiv class=\\\"orb-nav-pri-container b-r b-g-p\\\"\u003e \u003cdiv class=\\\"orb-nav-section orb-nav-blocks\\\"\u003e \u003ca href=\\\"/\\\"\u003e \u003cimg  src=\\\"http://static.bbci.co.uk/frameworks/barlesque/2.84.11/orb/4/img/bbc-blocks-dark.png\\\" width=\\\"84\\\" height=\\\"24\\\" alt=\\\"BBC\\\" /\u003e \u003c/a\u003e \u003c/div\u003e \u003csection\u003e \u003cdiv class=\\\"orb-skip-links\\\"\u003e \u003ch2\u003eAccessibility links\u003c/h2\u003e \u003cul\u003e  \u003cli\u003e\u003ca id=\\\"orb-accessibility-help\\\" href=\\\"/accessibility/\\\"\u003eAccessibility Help\u003c/a\u003e\u003c/li\u003e \u003c/ul\u003e \u003c/div\u003e \u003c/section\u003e  \u003cdiv class=\\\"orb-nav-section orb-nav-id orb-nav-focus orb-nav-id-default\\\"\u003e     \u003ca id=\\\"idcta-link\\\" href=\\\"https://ssl.bbc.co.uk/id/status\\\"\u003e\u003cimg id=\\\"idcta-image\\\" src=\\\"http://static.bbci.co.uk/id/0.32.00/img/bbcid_orb_signin_dark.png\\\" alt=\\\"\\\" width=\\\"18\\\" height=\\\"18\\\" /\u003e\u003cspan id=\\\"idcta-username\\\"\u003eBBC iD\u003c/span\u003e\u003c/a\u003e                \u003c/div\u003e  \u003cnav role=\\\"navigation\\\" class=\\\"orb-nav\\\"\u003e \u003cdiv class=\\\"orb-nav-section orb-nav-links orb-nav-focus\\\" id=\\\"orb-nav-links\\\"\u003e \u003ch2\u003eBBC navigation\u003c/h2\u003e \u003cul\u003e    \u003cli  class=\\\"orb-nav-news orb-d\\\"  \u003e \u003ca href=\\\"http://www.bbc.co.uk/news/\\\"\u003eNews\u003c/a\u003e \u003c/li\u003e    \u003cli  class=\\\"orb-nav-newsdotcom orb-w\\\"  \u003e \u003ca href=\\\"http://www.bbc.com/news/\\\"\u003eNews\u003c/a\u003e \u003c/li\u003e    \u003cli  class=\\\"orb-nav-sport\\\"  \u003e \u003ca href=\\\"/sport/\\\"\u003eSport\u003c/a\u003e \u003c/li\u003e    \u003cli  class=\\\"orb-nav-weather\\\"  \u003e \u003ca href=\\\"/weather/\\\"\u003eWeather\u003c/a\u003e \u003c/li\u003e    \u003cli  class=\\\"orb-nav-shop orb-w\\\"  \u003e \u003ca href=\\\"http://shop.bbc.com/\\\"\u003eShop\u003c/a\u003e \u003c/li\u003e    \u003cli  class=\\\"orb-nav-earthdotcom orb-w\\\"  \u003e \u003ca href=\\\"http://www.bbc.com/earth/\\\"\u003eEarth\u003c/a\u003e \u003c/li\u003e    \u003cli  class=\\\"orb-nav-travel-dotcom orb-w\\\"  \u003e \u003ca href=\\\"http://www.bbc.com/travel/\\\"\u003eTravel\u003c/a\u003e \u003c/li\u003e    \u003cli  class=\\\"orb-nav-capital orb-w\\\"  \u003e \u003ca href=\\\"http://www.bbc.com/capital/\\\"\u003eCapital\u003c/a\u003e \u003c/li\u003e    \u003cli  class=\\\"orb-nav-iplayer orb-d\\\"  \u003e \u003ca href=\\\"/iplayer/\\\"\u003eiPlayer\u003c/a\u003e \u003c/li\u003e    \u003cli  class=\\\"orb-nav-culture orb-w\\\"  \u003e \u003ca href=\\\"http://www.bbc.com/culture/\\\"\u003eCulture\u003c/a\u003e \u003c/li\u003e    \u003cli  class=\\\"orb-nav-autos orb-w\\\"  \u003e \u003ca href=\\\"http://www.bbc.com/autos/\\\"\u003eAutos\u003c/a\u003e \u003c/li\u003e    \u003cli  class=\\\"orb-nav-future orb-w\\\"  \u003e \u003ca href=\\\"http://www.bbc.com/future/\\\"\u003eFuture\u003c/a\u003e \u003c/li\u003e    \u003cli  class=\\\"orb-nav-tv\\\"  \u003e \u003ca href=\\\"/tv/\\\"\u003eTV\u003c/a\u003e \u003c/li\u003e    \u003cli  class=\\\"orb-nav-radio\\\"  \u003e \u003ca href=\\\"/radio/\\\"\u003eRadio\u003c/a\u003e \u003c/li\u003e    \u003cli  class=\\\"orb-nav-cbbc\\\"  \u003e \u003ca href=\\\"/cbbc\\\"\u003eCBBC\u003c/a\u003e \u003c/li\u003e    \u003cli  class=\\\"orb-nav-cbeebies\\\"  \u003e \u003ca href=\\\"/cbeebies\\\"\u003eCBeebies\u003c/a\u003e \u003c/li\u003e    \u003cli  class=\\\"orb-nav-arts orb-d\\\"  \u003e \u003ca href=\\\"/arts/\\\"\u003eArts\u003c/a\u003e \u003c/li\u003e    \u003cli  \u003e \u003ca href=\\\"/ww1/\\\"\u003eWW1\u003c/a\u003e \u003c/li\u003e    \u003cli  class=\\\"orb-nav-food\\\"  \u003e \u003ca href=\\\"/food/\\\"\u003eFood\u003c/a\u003e \u003c/li\u003e    \u003cli  \u003e \u003ca href=\\\"/iwonder\\\"\u003eiWonder\u003c/a\u003e \u003c/li\u003e    \u003cli  \u003e \u003ca href=\\\"/education\\\"\u003eBitesize\u003c/a\u003e \u003c/li\u003e    \u003cli  class=\\\"orb-nav-music\\\"  \u003e \u003ca href=\\\"/music/\\\"\u003eMusic\u003c/a\u003e \u003c/li\u003e    \u003cli  class=\\\"orb-nav-nature orb-w\\\"  \u003e \u003ca href=\\\"/nature/\\\"\u003eNature\u003c/a\u003e \u003c/li\u003e    \u003cli  class=\\\"orb-nav-earth orb-d\\\"  \u003e \u003ca href=\\\"http://www.bbc.com/earth/\\\"\u003eEarth\u003c/a\u003e \u003c/li\u003e    \u003cli  class=\\\"orb-nav-local\\\"  \u003e \u003ca href=\\\"/local/\\\"\u003eLocal\u003c/a\u003e \u003c/li\u003e    \u003cli  class=\\\"orb-nav-travel orb-d\\\"  \u003e \u003ca href=\\\"/travel/\\\"\u003eTravel\u003c/a\u003e \u003c/li\u003e    \u003cli id=\\\"orb-nav-more\\\"\u003e\u003ca href=\\\"#orb-footer\\\" data-alt=\\\"More\\\"\u003eMenu\u003cspan class=\\\"orb-icon orb-icon-arrow\\\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/li\u003e \u003c/ul\u003e \u003c/div\u003e \u003c/nav\u003e \u003cdiv class=\\\"orb-nav-section orb-nav-search\\\"\u003e \u003ca href=\\\"http://search.bbc.co.uk/search\\\"\u003e \u003cimg  src=\\\"http://static.bbci.co.uk/frameworks/barlesque/2.84.11/orb/4/img/orb-search-dark.png\\\" width=\\\"18\\\" height=\\\"18\\\" alt=\\\"Search the BBC\\\" /\u003e \u003c/a\u003e \u003cform class=\\\"b-f\\\" id=\\\"orb-search-form\\\" role=\\\"search\\\" method=\\\"get\\\" action=\\\"http://search.bbc.co.uk/search\\\" accept-charset=\\\"utf-8\\\"\u003e \u003cdiv\u003e   \u003clabel for=\\\"orb-search-q\\\"\u003eSearch the BBC\u003c/label\u003e \u003cinput id=\\\"orb-search-q\\\" type=\\\"text\\\" name=\\\"q\\\" placeholder=\\\"Search\\\" /\u003e \u003cinput type=\\\"image\\\" id=\\\"orb-search-button\\\" src=\\\"http://static.bbci.co.uk/frameworks/barlesque/2.84.11/orb/4/img/orb-search-dark.png\\\" width=\\\"17\\\" height=\\\"17\\\" alt=\\\"Search the BBC\\\" /\u003e \u003cinput type=\\\"hidden\\\" name=\\\"suggid\\\" id=\\\"orb-search-suggid\\\" /\u003e \u003c/div\u003e \u003c/form\u003e \u003c/div\u003e \u003c/div\u003e \u003cdiv id=\\\"orb-panels\\\"  \u003e \u003cscript type=\\\"text/template\\\" id=\\\"orb-panel-template\\\"\u003e\u003c![CDATA[ \u003cdiv id=\\\"orb-panel-\u003c%= panelname %\u003e\\\" class=\\\"orb-panel\\\" aria-labelledby=\\\"orb-nav-\u003c%= panelname %\u003e\\\"\u003e \u003cdiv class=\\\"orb-panel-content b-g-p b-r\\\"\u003e \u003c%= panelcontent %\u003e \u003c/div\u003e \u003c/div\u003e ]]\u003e\u003c/script\u003e \u003c/div\u003e \u003c/div\u003e \u003c/header\u003e \u003c!-- Styling hook for shared modules only --\u003e \u003cdiv id=\\\"orb-modules\\\"\u003e\",\n  \"css\": \"\",\n  \"javascript\": \"\",\n  \"meta\": \"\"\n}\n{\n  \"html\": \"\u003c/div\u003e \u003cdiv id=\\\"orb-footer\\\"  class=\\\"orb-footer orb-footer-grey  orb-footer-promo-legacy \\\" \u003e  \u003caside role=\\\"complementary\\\"\u003e \u003cdiv id=\\\"orb-aside\\\" class=\\\"orb-nav-sec b-r b-g-p\\\"\u003e \u003cdiv class=\\\"orb-footer-inner\\\" role=\\\"navigation\\\"\u003e  \u003ch2 class=\\\"orb-footer-lead\\\"\u003eExplore the BBC\u003c/h2\u003e   \u003cdiv id=\\\"orb-footer-promo\\\" class=\\\"orb-d\\\"\u003e\u003c/div\u003e  \u003cdiv class=\\\"orb-footer-primary-links\\\"\u003e \u003cul\u003e    \u003cli  class=\\\"orb-nav-news orb-d\\\"  \u003e \u003ca href=\\\"http://www.bbc.co.uk/news/\\\"\u003eNews\u003c/a\u003e \u003c/li\u003e    \u003cli  class=\\\"orb-nav-newsdotcom orb-w\\\"  \u003e \u003ca href=\\\"http://www.bbc.com/news/\\\"\u003eNews\u003c/a\u003e \u003c/li\u003e    \u003cli  class=\\\"orb-nav-sport\\\"  \u003e \u003ca href=\\\"/sport/\\\"\u003eSport\u003c/a\u003e \u003c/li\u003e    \u003cli  class=\\\"orb-nav-weather\\\"  \u003e \u003ca href=\\\"/weather/\\\"\u003eWeather\u003c/a\u003e \u003c/li\u003e    \u003cli  class=\\\"orb-nav-shop orb-w\\\"  \u003e \u003ca href=\\\"http://shop.bbc.com/\\\"\u003eShop\u003c/a\u003e \u003c/li\u003e    \u003cli  class=\\\"orb-nav-earthdotcom orb-w\\\"  \u003e \u003ca href=\\\"http://www.bbc.com/earth/\\\"\u003eEarth\u003c/a\u003e \u003c/li\u003e    \u003cli  class=\\\"orb-nav-travel-dotcom orb-w\\\"  \u003e \u003ca href=\\\"http://www.bbc.com/travel/\\\"\u003eTravel\u003c/a\u003e \u003c/li\u003e    \u003cli  class=\\\"orb-nav-capital orb-w\\\"  \u003e \u003ca href=\\\"http://www.bbc.com/capital/\\\"\u003eCapital\u003c/a\u003e \u003c/li\u003e    \u003cli  class=\\\"orb-nav-iplayer orb-d\\\"  \u003e \u003ca href=\\\"/iplayer/\\\"\u003eiPlayer\u003c/a\u003e \u003c/li\u003e    \u003cli  class=\\\"orb-nav-culture orb-w\\\"  \u003e \u003ca href=\\\"http://www.bbc.com/culture/\\\"\u003eCulture\u003c/a\u003e \u003c/li\u003e    \u003cli  class=\\\"orb-nav-autos orb-w\\\"  \u003e \u003ca href=\\\"http://www.bbc.com/autos/\\\"\u003eAutos\u003c/a\u003e \u003c/li\u003e    \u003cli  class=\\\"orb-nav-future orb-w\\\"  \u003e \u003ca href=\\\"http://www.bbc.com/future/\\\"\u003eFuture\u003c/a\u003e \u003c/li\u003e    \u003cli  class=\\\"orb-nav-tv\\\"  \u003e \u003ca href=\\\"/tv/\\\"\u003eTV\u003c/a\u003e \u003c/li\u003e    \u003cli  class=\\\"orb-nav-radio\\\"  \u003e \u003ca href=\\\"/radio/\\\"\u003eRadio\u003c/a\u003e \u003c/li\u003e    \u003cli  class=\\\"orb-nav-cbbc\\\"  \u003e \u003ca href=\\\"/cbbc\\\"\u003eCBBC\u003c/a\u003e \u003c/li\u003e    \u003cli  class=\\\"orb-nav-cbeebies\\\"  \u003e \u003ca href=\\\"/cbeebies\\\"\u003eCBeebies\u003c/a\u003e \u003c/li\u003e    \u003cli  class=\\\"orb-nav-arts orb-d\\\"  \u003e \u003ca href=\\\"/arts/\\\"\u003eArts\u003c/a\u003e \u003c/li\u003e    \u003cli  \u003e \u003ca href=\\\"/ww1/\\\"\u003eWW1\u003c/a\u003e \u003c/li\u003e    \u003cli  class=\\\"orb-nav-food\\\"  \u003e \u003ca href=\\\"/food/\\\"\u003eFood\u003c/a\u003e \u003c/li\u003e    \u003cli  \u003e \u003ca href=\\\"/iwonder\\\"\u003eiWonder\u003c/a\u003e \u003c/li\u003e    \u003cli  \u003e \u003ca href=\\\"/education\\\"\u003eBitesize\u003c/a\u003e \u003c/li\u003e    \u003cli  class=\\\"orb-nav-music\\\"  \u003e \u003ca href=\\\"/music/\\\"\u003eMusic\u003c/a\u003e \u003c/li\u003e    \u003cli  class=\\\"orb-nav-nature orb-w\\\"  \u003e \u003ca href=\\\"/nature/\\\"\u003eNature\u003c/a\u003e \u003c/li\u003e    \u003cli  class=\\\"orb-nav-earth orb-d\\\"  \u003e \u003ca href=\\\"http://www.bbc.com/earth/\\\"\u003eEarth\u003c/a\u003e \u003c/li\u003e    \u003cli  class=\\\"orb-nav-local\\\"  \u003e \u003ca href=\\\"/local/\\\"\u003eLocal\u003c/a\u003e \u003c/li\u003e    \u003cli  class=\\\"orb-nav-travel orb-d\\\"  \u003e \u003ca href=\\\"/travel/\\\"\u003eTravel\u003c/a\u003e \u003c/li\u003e    \u003c/ul\u003e \u003c/div\u003e \u003c/div\u003e \u003c/div\u003e \u003c/aside\u003e \u003cfooter role=\\\"contentinfo\\\"\u003e \u003cdiv id=\\\"orb-contentinfo\\\" class=\\\"orb-nav-sec b-r b-g-p\\\"\u003e \u003cdiv class=\\\"orb-footer-inner\\\"\u003e \u003cul\u003e        \u003cli  \u003e \u003ca href=\\\"/terms/\\\"\u003eTerms of Use\u003c/a\u003e \u003c/li\u003e    \u003cli  \u003e \u003ca href=\\\"/aboutthebbc/\\\"\u003eAbout the BBC\u003c/a\u003e \u003c/li\u003e    \u003cli  \u003e \u003ca href=\\\"/privacy/\\\"\u003ePrivacy Policy\u003c/a\u003e \u003c/li\u003e    \u003cli  \u003e \u003ca href=\\\"/privacy/cookies/about\\\"\u003eCookies\u003c/a\u003e \u003c/li\u003e    \u003cli  \u003e \u003ca href=\\\"/accessibility/\\\"\u003eAccessibility Help\u003c/a\u003e \u003c/li\u003e    \u003cli  \u003e \u003ca href=\\\"/guidance/\\\"\u003eParental Guidance\u003c/a\u003e \u003c/li\u003e    \u003cli  \u003e \u003ca href=\\\"/contact/\\\"\u003eContact the BBC\u003c/a\u003e \u003c/li\u003e        \u003c/ul\u003e \u003csmall\u003e \u003cspan class=\\\"orb-hilight\\\"\u003eCopyright \u0026copy; 2015 BBC.\u003c/span\u003e The BBC is not responsible for the content of external sites. \u003ca href=\\\"/help/web/links/\\\" class=\\\"orb-hilight\\\"\u003eRead about our approach to external linking.\u003c/a\u003e \u003c/small\u003e \u003c/div\u003e \u003c/div\u003e \u003c/footer\u003e \u003c/div\u003e     \u003c!-- BBCDOTCOM bodyLast --\u003e\u003cdiv class=\\\"bbccom_display_none\\\"\u003e\u003cscript type=\\\"text/javascript\\\"\u003e /*\u003c![CDATA[*/ if (window.bbcdotcom \u0026\u0026 window.bbcdotcom.analytics) { bbcdotcom.analytics.page(); } if (window.bbcdotcom \u0026\u0026 bbcdotcom.currencyProviders) { bbcdotcom.currencyProviders.write(); } /*]]\u003e*/ \u003c/script\u003e\u003cscript type=\\\"text/javascript\\\"\u003e /*\u003c![CDATA[*/ if (window.bbcdotcom \u0026\u0026 bbcdotcom.currencyProviders) { bbcdotcom.currencyProviders.postWrite(); } /*]]\u003e*/ \u003c/script\u003e\u003cscript type=\\\"text/javascript\\\"\u003e /*\u003c![CDATA[*/ /** * ASNYC waits to make any gpt requests until the bottom of the page */ /*]]\u003e*/ \u003c/script\u003e\u003cscript type=\\\"text/javascript\\\"\u003e /*\u003c![CDATA[*/ if (window.bbcdotcom \u0026\u0026 bbcdotcom.data \u0026\u0026 bbcdotcom.data.stats \u0026\u0026 bbcdotcom.data.stats === 1 \u0026\u0026 bbcdotcom.utils \u0026\u0026 window.location.pathname === '/' \u0026\u0026 window.bbccookies \u0026\u0026 bbccookies.readPolicy('performance') ) { var wwhpEdition = bbcdotcom.utils.getMetaPropertyContent('wwhp-edition'); var _sf_async_config={}; /** CONFIGURATION START **/ _sf_async_config.uid = 50924; _sf_async_config.domain = \\\"bbc.co.uk\\\"; _sf_async_config.title = \\\"Homepage\\\"+(wwhpEdition !== '' ? ' - '+wwhpEdition : ''); _sf_async_config.sections = \\\"Homepage\\\"+(wwhpEdition !== '' ? ', Homepage - '+wwhpEdition : ''); _sf_async_config.region = wwhpEdition; _sf_async_config.path = \\\"/\\\"+(wwhpEdition !== '' ? '?'+wwhpEdition : ''); /** CONFIGURATION END **/ (function(){ function loadChartbeat() { window._sf_endpt=(new Date()).getTime(); var e = document.createElement(\\\"script\\\"); e.setAttribute(\\\"language\\\", \\\"javascript\\\"); e.setAttribute(\\\"type\\\", \\\"text/javascript\\\"); e.setAttribute('src', '//static.chartbeat.com/js/chartbeat.js'); document.body.appendChild(e); } var oldonload = window.onload; window.onload = (typeof window.onload != \\\"function\\\") ? loadChartbeat : function() { oldonload(); loadChartbeat(); }; })(); } /*]]\u003e*/ \u003c/script\u003e\u003c/div\u003e \u003c!-- BBCDOTCOM all code in page --\u003e  \u003cscript type=\\\"text/javascript\\\"\u003e document.write('\u003c' + 'script id=\\\"orb-js-script\\\" data-assetpath=\\\"http://static.bbci.co.uk/frameworks/barlesque/2.84.11/orb/4/\\\" src=\\\"http://static.bbci.co.uk/frameworks/barlesque/2.84.11/orb/4/script' + (( document.cookie.indexOf('ckns_debugorbjs') \u003e -1 )? '-debug' : '') + '/orb.js\\\"\u003e\u003c' + '/script\u003e'); \u003c/script\u003e  \u003cscript type=\\\"text/javascript\\\"\u003e (function() {\\n    'use strict';\\n\\n    var promoManager = {\\n        url: '',\\n        segments: ['a', 'b'],\\n        promoLoaded: false,\\n                makeUrl: function (variant, theme, win) {\\n            var loc = win? win.location : window.location,\\n                proto = loc.protocol,\\n                host = loc.host,\\n                url = proto + '//' + ((proto.match(/s:/i) \u0026\u0026 !host.match(/^www\\\\.(int|test)\\\\./i))? 'ssl.' : 'www.'),\\n                themes = ['light', 'dark'];\\n\\n            if ( host.match(/^(?:www|ssl)\\\\.(int|test|stage|live)\\\\.bbc\\\\./i) ) {\\n                url += RegExp.$1 + '.';\\n            }\\n            else if ( host.match(/^pal\\\\.sandbox\\\\./i) ) {\\n                url += 'test.';\\n            }\\n\\n                        theme = themes[ +(theme === themes[0]) ];\\n\\n           return url + 'bbc.co.uk/navpromo/' + variant + '/' + theme;\\n        },\\n                validSegment: function (segment) {\\n            var validSegments = this.segments;\\n\\n            for (var i = 0, len = validSegments.length; i \u003c len; i++) {\\n                if (validSegments[i] === segment) {\\n                    return segment;\\n                }\\n            }\\n\\n            return validSegments[0];\\n        },\\n                init: function(node) {\\n            var disabledByCookie = (document.cookie.indexOf('ckns_orb_nopromo=1') \u003e -1),\\n                orbFullWidth     = (document.getElementById('orb-aside').offsetWidth \u003e= 1008),\\n                that = this;\\n\\n            if (window.promomanagerOverride) {\\n                for (var p in promomanagerOverride) {\\n                    that[p] = promomanagerOverride[p];\\n                }\\n            }\\n\\n            if ( window.orb.fig('uk') \u0026\u0026 orbFullWidth \u0026\u0026 !disabledByCookie ) {\\n                require(['orb/async/_footerpromo', 'istats-1'], function(promo, istats) {\\n                                        var mandolinEndDate = new Date().getTime() + (7 * 60 * 60 * 24) * 1000,\\n                        mandolin = new bbc.Mandolin('footer-promo', that.segments, {rate: 0.2, end: mandolinEndDate}),\\n                        segmentToRequest = that.validSegment(mandolin.getSegment());\\n\\n                    that.url = (window.promomanagerOverride || that).makeUrl(segmentToRequest, 'light');\\n\\n                    if (that.url) {\\n                        promo.load(that.url, node, {\\n                                                          onSuccess: function(e) {\\n                                istats.addLabels({ 'campaignID': e.campaignID });\\n                                if (segmentToRequest === mandolin.getSegment()) {\\n                                    istats.addLabels({ 'promo_id_segment': e.campaignID + ':' + mandolin.getSegment() });\\n                                }\\n                                istats.track('internal', {region: node, linkLocation : 'orb-footer-promo'});\\n\\n                                istats.log('display', 'orb-footer-promo-displayed', {campaignID : e.campaignID, testVariant: segmentToRequest});\\n                                node.className = node.className + ' orb-footer-promo-loaded';\\n                                promoManager.promoLoaded = true;\\n                                promoManager.event('promo-loaded').fire(e);\\n                             },\\n                             onError: function() {\\n                                istats.log('error', 'orb-footer-promo-failed');\\n                                document.cookie = 'ckns_orb_nopromo=1; expires=' + new Date(new Date().getTime() + 1000 * 60 * 10).toGMTString() + ';';\\n                             }\\n                        });\\n                    }\\n                });\\n            }\\n        }\\n    };\\n\\n\\n    define('orb/promomanager', ['orb/lib/_event'], function (event) {\\n        event.mixin(promoManager);\\n        return promoManager;\\n    });\\n\\n    require(['orb/promomanager'], function (promoManager) {\\n        promoManager.init(document.getElementById('orb-footer-promo'));\\n    })\\n})();\\n \u003c/script\u003e   \u003cscript type=\\\"text/javascript\\\"\u003e if (typeof require !== 'undefined') { require(['istats-1'], function(istats){ istats.track('external', { region: document.getElementsByTagName('body')[0] }); istats.track('download', { region: document.getElementsByTagName('body')[0] }); }); }  \u003c/script\u003e\",\n  \"css\": \"\",\n  \"javascript\": \"\",\n  \"meta\": \"\"\n}\n","tags":""},{"id":"eb7bf0d8f3b7d9958f13","title":"Zsh and Bash Array Shift (remove first item from the Array)","content":"array=(foo, bar, baz)\necho ${array[@]} # =\u003e foo, bar, baz\n\narray=(\"${array[@]:1}\")\necho ${array[@]} # =\u003e bar, baz\n\narray=(\"${array[@]:1}\")\necho ${array[@]} # =\u003e baz\narray=(foo, bar, baz)\necho $array # =\u003e foo, bar, baz\n\narray=(\"${(@)array:1}\")\necho $array # =\u003e bar, baz\n\narray=(\"${(@)array:1}\")\necho $array # =\u003e baz\n\n# UPDATE: this works as well and is less confusing syntax\narray=(${array:1})\n","tags":""},{"id":"e5906e3dd84b1088decf","title":"Building a Go program via Docker","content":"docker run -\\\n  -rm=true \\\n  -v $WORKSPACE/src:/gopath/src/github.com/foo/bar/src \\\n  -v $WORKSPACE/src:/app \\\n  -e \"GOPATH=/gopath\" \\\n  -w /app golang:1.5 sh \\\n  -c 'CGO_ENABLED=0 go build -a --installsuffix cgo --ldflags=\\\"-s\\\" -o bar'\n  \n# Refactor:\n# Set the working directory to `/gopath/src/github.com/foo/bar/src\n# Which means you don't need the second volume mount to /app\n\ndocker run \\\n  -v \"$PWD\":/go/src/github.com/integralist/go-requester \\\n  -w /go/src/github.com/integralist/go-requester \\\n  -p 8080:8080 \\\n  golang:latest go run requester.go\n","tags":""},{"id":"2e381839f67447a178f9","title":"git merge --squash brings in your changes but doesn't create a commit. Instead it will stage your changes so you can create a fresh commit for it (avoiding ugly merge commits showing in GitHub when using a standard git merge)","content":"git merge --squash \u003cbranch|commit\u003e # only works with single commits\n\n# When specifying a commit hash, this is still different from something like\n# `git cherry-pick` because that would create a commit where as --squash simply\n# copies the changes into your staging area\n","tags":""},{"id":"403d7985d22d58080722","title":"[Bash Array Looping] ","content":"#!/usr/bin/env bash\nlanguages=(\"bash\" \"go\" \"javascript\" \"php\" \"python\" \"ruby\" \"rust\" \"typescript-fetch\")\nfor lang in \"${languages[@]}\";\ndo\n  for filename in .source-cache/.api-documentation/schemas/*;\n  do\n    name=$(basename $filename | cut -f 1 -d '.')\n    openapi-generator generate -i \"${filename}\" -g \"${lang}\" -o \"/tmp/api-code-gen/${lang}/${name}/\"\n  done\ndone\n\n###############################################################################################################\n\ncomponents=(newsbeat-editorial-feed-renderer \\\n            newsbeat-latest-feed-renderer \\\n            newsbeat-most-popular-renderer \\\n            newsbeat-topic-renderer)\n\nips=()\n\nfor item in \"${components[@]}\"\ndo\n  # echo \"Y N Y N\" passes each item sequentially through to further command prompts\n  # e.g. our command prompts us to choose instance id\n  ips+=$(echo \"1\" | bundle exec bbc-cosmos-tools component ssh $item --env=live | grep -E -o \"\\d+\\.\\d+\\.\\d+\\.\\d+\")\ndone\n\necho ${#ips[@]} # count the length of the array\necho $ips\n\n# Alternative way to loop array in bash\nfor ip in $ips\ndo\n  ssh $ip,eu-west-1 id # placing command after ssh prevents tty to drop into session\ndone\n","tags":"#bash #shell #loop #code #gen"},{"id":"8ee681ac96a9c28fcb71","title":"Super basic concurrency based HTTP requester","content":"require \"faraday\"\nrequire \"json\"\n\nraw_json = \u003c\u003c-eos\n{\n  \"components\": [\n    {\n      \"id\": \"header\",\n      \"url\": \"https://gist.githubusercontent.com/revett/445ba84972156834a5df/raw/cb407f8c5348fb59d0448bd2b5573464e466cbc8/header.json\"\n    },\n    {\n      \"id\": \"title\",\n      \"url\": \"https://gist.githubusercontent.com/revett/445ba84972156834a5df/raw/cb407f8c5348fb59d0448bd2b5573464e466cbc8/title.json\"\n    },\n    {\n      \"id\": \"sidebar\",\n      \"url\": \"https://gist.githubusercontent.com/revett/445ba84972156834a5df/raw/cb407f8c5348fb59d0448bd2b5573464e466cbc8/sidebar.json\"\n    },\n    {\n      \"id\": \"footer\",\n      \"url\": \"https://gist.githubusercontent.com/revett/445ba84972156834a5df/raw/cb407f8c5348fb59d0448bd2b5573464e466cbc8/footer.json\"\n    },\n    {\n      \"id\": \"image\",\n      \"url\": \"https://gist.githubusercontent.com/revett/445ba84972156834a5df/raw/cb407f8c5348fb59d0448bd2b5573464e466cbc8/image.json\"\n    }\n  ]\n}\neos\n\noverall_status   = \"success\"\ncomponent_status = \"success\"\nthreads          = []\njson             = JSON.parse(raw_json)\ncomponents       = json[\"components\"]\n\ncomponents.size.times do |i|\n  threads \u003c\u003c Thread.new do\n    time_start = Time.now\n\n    url            = components[i-1][\"url\"]\n    response       = Faraday.get url\n\n    time_end = Time.now\n\n    overall_status = component_status = \"failure\" if response.status != 200 || (time_end-time_start) \u003e 2\n\n    {\n      :id     =\u003e components[i-1][\"id\"],\n      :status =\u003e component_status,\n      :body   =\u003e JSON.parse(response.body)[\"content\"]\n    }\n  end\nend\n\nthreads.each { |t| t.join }\n\nresult = {\n  :status     =\u003e overall_status,\n  :components =\u003e threads.map { |t| t.value }\n}\n\np JSON.generate(result)\n{\"status\"=\u003e\"success\",\n \"components\"=\u003e\n  [{\"id\"=\u003e\"image\",\n    \"status\"=\u003e\"success\",\n    \"body\"=\u003e\n     \"\u003cp\u003ePellentesque habitant morbi tristique senectus et netus et malesuada fames ac turpis egestas. Vestibulum tortor quam, feugiat vitae, ultricies eget, tempor sit amet, ante. Donec eu libero sit amet quam egestas semper. Aenean ultricies mi vitae est. Mauris placerat eleifend leo.\u003c/p\u003e\"},\n   {\"id\"=\u003e\"header\",\n    \"status\"=\u003e\"success\",\n    \"body\"=\u003e\n     \"\u003cp\u003ePellentesque habitant morbi tristique senectus et netus et malesuada fames ac turpis egestas. Vestibulum tortor quam, feugiat vitae, ultricies eget, tempor sit amet, ante. Donec eu libero sit amet quam egestas semper. Aenean ultricies mi vitae est. Mauris placerat eleifend leo.\u003c/p\u003e\"},\n   {\"id\"=\u003e\"title\",\n    \"status\"=\u003e\"success\",\n    \"body\"=\u003e\n     \"\u003cp\u003ePellentesque habitant morbi tristique senectus et netus et malesuada fames ac turpis egestas. Vestibulum tortor quam, feugiat vitae, ultricies eget, tempor sit amet, ante. Donec eu libero sit amet quam egestas semper. Aenean ultricies mi vitae est. Mauris placerat eleifend leo.\u003c/p\u003e\"},\n   {\"id\"=\u003e\"sidebar\",\n    \"status\"=\u003e\"success\",\n    \"body\"=\u003e\n     \"\u003cp\u003ePellentesque habitant morbi tristique senectus et netus et malesuada fames ac turpis egestas. Vestibulum tortor quam, feugiat vitae, ultricies eget, tempor sit amet, ante. Donec eu libero sit amet quam egestas semper. Aenean ultricies mi vitae est. Mauris placerat eleifend leo.\u003c/p\u003e\"},\n   {\"id\"=\u003e\"footer\",\n    \"status\"=\u003e\"success\",\n    \"body\"=\u003e\n     \"\u003cp\u003ePellentesque habitant morbi tristique senectus et netus et malesuada fames ac turpis egestas. Vestibulum tortor quam, feugiat vitae, ultricies eget, tempor sit amet, ante. Donec eu libero sit amet quam egestas semper. Aenean ultricies mi vitae est. Mauris placerat eleifend leo.\u003c/p\u003e\"}]}\n","tags":""},{"id":"e9ea91ef026ed698c5f9","title":"Modify Boot2Docker to default specific arguments when executing the docker command","content":"- Enter VM SSH: `boot2docker ssh`\n- Locate profile: `sudo vi /var/lib/boot2docker/profile` \n  - Add: `EXTRA_ARGS=\"--insecure-registry registry.example.com\"`\n- Restart Docker Service: `sudo /etc/init.d/docker restart`\n- Leave VM SSH: `exit`\n- Update VM: `boot2docker up`\n","tags":""},{"id":"c0a412d184fbf01f41e6","title":"How encryption with certificates and public/private keys work","content":"## PKI\n\n- PKI is based upon two keys (public and private)\n- Data can be securely encrypted using either the public or private keys\n- Data can only be decrypted when using the opposite key to that which encrypted the data\n- Use a Key Generator (e.g. `ssh-keygen`) to create your public/private keys\n- These keys are typically stored in `~/.ssh/`\n  - `id_rsa` (private key; do not share! typically used to decrypt data)\n  - `id_rsa.pub` (public key; typically used to encrypt data)  \n    \n    \u003e Note: any data encrypted with a private key can be decrypted using the public key (and vice versa)\n\n    - A public key can be *generated* from a private key (not the other way around)\n\n## SSL\n\n- Data sent back and forth inside the browser can be encrypted using the Secure-Socket Layer (SSL) protocol\n- SSL uses public-key cryptography (PKI)\n\n## SSH Authentication with PKI\n\n- The public key should be added to `.ssh/authorized_keys` on all computers where the user wishes to log in\n  - The remote computer encrypts data with your public key\n  - Your private key decrypts the data when logging in (thus proving your identity)\n\n## RSA\n\n- This is the cryptography system\n- [Examples of generating keypairs using OpenSSL](http://en.wikibooks.org/wiki/Cryptography/Generate_a_keypair_using_OpenSSL)\n\n## Registration Authority (RA)\n\n- RAs are companies in the business of allowing the public to trust an organisation's encryption keys\n- If a website want's their encrypted website to be trusted, then they'll go to the RA (see \"Banking\" example below)\n\n### Root Certificate Authority (CA)\n\n- CA is nothing more than another public/private key pair (created by an RA)\n- The RA’s private key is (as you can imagine) private\n- The RA’s public key is available to everyone\n  - All computers sold, have a copy of these public root certificates\n- The RA’s private key is used to sign (encrypt) an organisation’s public key\n- A users web browser should be able to use the RA’s public key (CA cert) to decrypt an organisations public key when visiting that website\n  - Thus proving the organisation's key can be trusted (and hasn't been tampered with -\u003e see \"Banking\" example below)\n\n## Self-signed certificate\n\n- There is a hierarchy of CA certificates, the highest ranking CA's certificate can't be verified by anyone (as they're the top of the chain) and so it must be \"self-signed\" (these are also referred to as \"root certificates\")\n- You may wish to test your new SSL implementation while the CA is signing your certificate, and so \"self-signing\" is a temporary measure for testing your web service\n- [Update by [@sthulb](https://github.com/sthulb)] Self signed certs are common in enterprises, for example it could be perceived that a company can trust a self signed cert more than a publicly signed cert since they can guarantee the entire CA chain\n\n## Example: Email Signing\n\n- Alice uses Bob’s public key to send him a message\n- Bob’s public key is public, so how does he know Alice really sent the message?\n- RSA can be used to “sign a message”\n- Alice can prove who she is by sending Bob a signed message\n- Alice encrypts the message (using her private key), thus producing a hash\n- This hash is attached to the email as a “signature”\n- Bob uses the same hashing algorithm (using Alice’s public key) to encrypt the original (unencrypted) message, thus producing a hash\n- If the hash Bob creates matches the hash sent along with the message then we know Alice really sent the email (i.e. the sender was in possesion of Alice’s private key)\n\n## Example: Banking Website\n\n- A bank wishes to encrypt their website that you use to manage your account\n- The bank wants to use a 3rd party to verify the authenticity of their private/public keypair\n  - Without this the user will see a “untrusted” warning in their web browser\n- The bank sends their public key to an RA\n- The bank pays the RA to sign (i.e. encrypt) their public key, using the RAs private key\n- Your web browser visits the banks website and is given the banks encrypted public key\n- Your web browser looks up the CA (which is installed on your computer) and decrypts the banks public key\n- Your web browser can now use the bank’s (now decrypted) public key to encrypt any data you send to it\n- The bank is the only person who has their private key and so are the only people able to decrypt your web browser’s message\n  - And vice versa, the bank can now send messages encrypted using their private key, as your web browser has the (decrypted) public key allowing you to decrypt any further encrypted messages from the bank\n\n## File Formats\n\n\u003e Note: the list below has been partially copied/modified from an answer here: http://serverfault.com/a/9717 as well as other sources\n\n- `.pem` is a container format that may include just the public certificate (such as with Apache installs, and CA certificate files `/etc/ssl/certs`), or may include an entire certificate chain including public key, private key, and root certificates. The name is from Privacy Enhanced Email, a failed method for secure email but the container format it used lives on, and is a base64 translation of the x509 ASN.1 keys (i.e. X.509 certificate).\n- `.key` is a PEM *formatted* file containing just the private-key of a specific certificate and is merely a conventional name and not a standardized one. In Apache installs, this frequently resides in `/etc/ssl/private`. The rights on these files are very important, and some programs will refuse to load these certificates if they are set wrong.\n- `.p12` (also `.pkcs12` and `.pfx`) is a password protected container format that contains both public and private certificate pairs. Unlike `.pem` files, this container is fully encrypted. OpenSSL can turn this into a `.pem` file with both public and private keys: `openssl pkcs12 -in file-to-convert.p12 -out converted-file.pem -nodes`\n- `.cert` (also `.cer` and `.crt`) is a `.pem` formatted file with a different extension, one that is recognized by Windows Explorer as a certificate, which `.pem` is not.\n- `cacert.pem` is a collection of trusted root certification authorities\n","tags":""},{"id":"bb1b1623e5229455fd7f","title":"Multiline Curl PUT'ing of data with no extra processing (thanks to --data-binary flag). We also use @ with a hyphen, so @- (the hyphen indicates input from stdin)","content":"curl -E $DEV_CERT_PEM https://api.our-service.com/component/component-name/configuration --header 'Content-Type: application/json' --request PUT --data-binary @- \u003c\u003cBODY\n[\n    {\n        \"key\": \"git_ssh_private_key\",\n        \"value\": \"$(cat pri.key)\",\n        \"secure\": true\n    },\n    {\n        \"key\": \"git_ssh_public_key\",\n        \"value\": \"$(cat pub.key)\",\n        \"secure\": true\n    },\n    {\n        \"key\": \"jenkins_master_internal_hostname\",\n        \"value\": \"foo.bar.jenkins.baz.qux.my-domain.com\"\n    },\n    {\n        \"key\": \"cloudwatch_log_group_name\",\n        \"value\": \"live-foo-bar-jenkins-baz-main-JenkinsAgentsLogGroup-qux\"\n    },\n    {\n        \"key\": \"docker_registry_hostname\",\n        \"value\": \"https://jenkins.foobar.my-domain.com\"\n    }\n]\nBODY\n","tags":""},{"id":"b4169a24ec0c55f00fde","title":"Benchmark MRI vs JRuby","content":"require \"net/http\"\n\nnum_iterations = 20\nnum_threads    = 4\ntotal_time     = 0.0\n\n# Try requesting a URL 200 times, on 4 separate threads, 20 times\nnum_iterations.times do |iter|\n  threads = []\n  time_start = Time.now\n\n  num_threads.times do |n|\n    p \"Thread: #{n}\"\n    threads \u003c\u003c Thread.new(n) do |t|\n      200.times do |i|\n        Net::HTTP.get(URI.parse(\"http://www.google.com/\"))\n        p \"Iteration: #{i}\"\n      end\n    end\n  end\n\n  threads.each { |thread| thread.join }\n  p \"Done\"\n\n  time_end = Time.now\n  time_ms = (time_end - time_start) * 1000\n  puts \"TEST #{iter}: Time elapsed = #{time_ms}ms\"\n  total_time += time_ms\nend\n\nputs \"Average completion time: #{total_time/num_iterations}\"\n","tags":""},{"id":"d8f9ff562bc9d2454543","title":"Basic Ruby exception and error handling","content":"class SomeCustomException \u003c StandardError\n  def initialize(msg = \"Some default error message\")\n    super\n  end\nend\n\ndef this_will_fail\n  raise SomeCustomException.new(\"This will be the error message\")\nrescue SomeCustomException =\u003e e\n  p e.message # =\u003e This will be the error message\nend\n","tags":""},{"id":"8b9e15be0a3dd175ab19","title":"Sinatra and Docker","content":"source \"https://rubygems.org/\"\n\ngem \"puma\"\ngem \"sinatra\"\nrequire \"sinatra/base\"\n\nclass App \u003c Sinatra::Base\n  set :bind, \"0.0.0.0\"\n\n  get \"/\" do\n    \"\u003cp\u003eThis is \u003ci\u003edynamic\u003c/i\u003e content served via puma: #{rand(36**6).to_s(36)}\"\n  end\nend\nrequire \"sinatra\"\nrequire \"./app.rb\"\n\nrun App\nFROM ruby\nRUN mkdir -p /app\nWORKDIR /app\nCOPY Gemfile /app/\nRUN bundle install --quiet\nCOPY . /app\nEXPOSE 5000\nENTRYPOINT [\"rackup\"]\nCMD [\"--host\", \"0.0.0.0\", \"-p\", \"5000\"]\n","tags":""},{"id":"0cad5acc795175e53393","title":"Building an RPM https://github.com/integralist/simple-rpm","content":"See my working application (and additional notes) here:\n\nhttps://github.com/integralist/simple-rpm\n\n\u003e Other information that led to the above repository, can be found below\n\n## References\n\n- http://www.rpm.org/max-rpm/s1-rpm-anywhere-different-build-area.html\n- http://www.tldp.org/HOWTO/RPM-HOWTO/build.html\n- https://fedoraproject.org/wiki/How_to_create_an_RPM_package\n- http://www.thegeekstuff.com/2015/02/rpm-build-package-example/\n- https://github.com/darnould/simple-rpm\n\n## Folders\n\n| Macro Name       | Name                    | Location               | Purpose |\n|:-----------------|:------------------------|:-----------------------|:------- |\n| `%_specdir`      | Specification directory | `~/rpmbuild/SPECS`     | RPM specifications (`.spec`) files |\n| `%_sourcedir`    | Source directory        | `~/rpmbuild/SOURCES`   | Pristine source package (e.g. tarballs) and patches |\n| `%_builddir`     | Build directory         | `~/rpmbuild/BUILD`     | Source files are unpacked and compiled in a subdirectory underneath this. |\n| `%_buildrootdir` | Build root directory    | `~/rpmbuild/BUILDROOT` | Files are installed under here during the `%install` stage. |\n| `%_rpmdir`       | Binary RPM directory    | `~/rpmbuild/RPMS`      | Binary RPMs are created and stored under here. |\n| `%_srcrpmdir`    | Source RPM directory    | `~/rpmbuild/SRPMS`     | Source RPMs are created and stored here. |\n\n## Setup\n\n```bash\nmkdir -p ~/rpmbuild/{RPMS,SRPMS,BUILD,SOURCES,SPECS,tmp}\n\ncat \u003c\u003cEOF \u003e~/.rpmmacros\n%_topdir   %(echo $HOME)/rpmbuild\n%_tmppath  %{_topdir}/tmp\nEOF\n\ncd ~/rpmbuild\n```\n\n## Tarball your project\n\n```bash\nmkdir foo-1.0\nmkdir -p foo-1.0/usr/bin\nmkdir -p foo-1.0/etc/foo\ninstall -m 755 foo foo-1.0/usr/bin\ninstall -m 644 foo.conf foo-1.0/etc/foo/\n\ntar -zcvf foo-1.0.tar.gz foo-1.0/\n```\n\n## Copy to SOURCES\n\n```bash\ncp foo-1.0.tar.gz SOURCES/\n\ncat \u003c\u003cEOF \u003e SPECS/foo.spec\n# Don't try fancy stuff like debuginfo, which is useless on binary-only\n# packages. Don't strip binary too\n# Be sure buildpolicy set to do nothing\n%define        __spec_install_post %{nil}\n%define          debug_package %{nil}\n%define        __os_install_post %{_dbpath}/brp-compress\n\nSummary: A very simple toy bin rpm package\nName: foo\nVersion: 1.0\nRelease: 1\nLicense: GPL+\nGroup: Development/Tools\nSOURCE0 : %{name}-%{version}.tar.gz\nURL: http://foo.company.com/\n\nBuildRoot: %{_tmppath}/%{name}-%{version}-%{release}-root\n\n%description\n%{summary}\n\n%prep\n%setup -q\n\n%build\n# Empty section.\n\n%install\nrm -rf %{buildroot}\nmkdir -p  %{buildroot}\n\n# in builddir\ncp -a * %{buildroot}\n\n\n%clean\nrm -rf %{buildroot}\n\n\n%files\n%defattr(-,root,root,-)\n%config(noreplace) %{_sysconfdir}/%{name}/%{name}.conf\n%{_bindir}/*\n\n%changelog\n* Thu Apr 24 2009  Elia Pinto \u003cdevzero2000@rpm5.org\u003e 1.0-1\n- First Build\n\nEOF\n```\n\n## Build\n\n```bash\nrpmbuild -ba SPECS/foo.spec\n```\n\n## Directory Structure\n\nSimple example of what the directory structure looks like and means in practice...\n\n```\n.\n├── BUILD\n├── RPMS\n├── SOURCES\n│   ├── http://cache.ruby-lang.org/pub/ruby/ruby-2.1.2.tar.gz\n├── SPECS\n│   ├── ruby.spec\n├── SRPMS\n```\n\nThe BUILD folder is where all files go which are created during a build of the package when you create the rpm.  \n\nIf the package builds correctly then any rpm(s) created will go into the RPMS and SRPMS folders.  \n\nThe SRPMS directory only contains source rpms.  \n\nSpec files are basically instructions on how the rpm is built and they go in the SPECS folder.  \n\nThe source tar file should go into the SOURCES directory along with any patches.\n\n## Miscellaneous Information\n\n- Spec file naming convention: `\u003cpackage_name\u003e-\u003cversion_number\u003e-\u003crelease_number\u003e.spec`\n- Spec files reference SOURCEs as `Source0`, `Source1`\n- Spec file uses `%{variable_name}` to dereference values\n  - Variables are case insensitive; e.g. `%{foo}` matches `Foo` variable\n","tags":""},{"id":"1f905931c7aa6d760489","title":"AWS Lambda using Ruby (via uploaded compiled binary of MRI)","content":"console.log('Loading function');\n\nvar exec = require('child_process').exec,\n    child;\n\nexports.handler = function(event, context) {\n    exec('/var/task/ruby/bin/ruby /var/task/foo.rb', function (error, stdout, stderr) {\n        console.log('stderr:', stderr);\n        console.log('stdout: ' + stdout);\n        context.done(null, stdout);\n    });\n};\n","tags":""},{"id":"5cfd5c884b0f2c0c5d11","title":"nginx and ruby","content":"FROM ruby\nRUN mkdir -p /app\nWORKDIR /app\nCOPY Gemfile /app/\nRUN bundle install --quiet\nCOPY . /app\nEXPOSE 5000\nENTRYPOINT [\"rackup\"]\nCMD [\"--host\", \"0.0.0.0\", \"-p\", \"5000\"]\nsource \"https://rubygems.org/\"\n\ngem \"puma\"\ngem \"sinatra\"\nrequire \"sinatra\"\nrequire \"./app.rb\"\n\nrun App\nFROM nginx\nCOPY nginx.conf /etc/nginx/\nCOPY public /static\nEXPOSE 80\nhttp {\n    sendfile on;\n    tcp_nopush on;\n    tcp_nodelay on;\n    keepalive_timeout 5;\n\n    gzip on;\n    gzip_vary on;\n    gzip_min_length 500;\n    gzip_disable \"MSIE [1-6]\\.(?!.*SV1)\";\n    gzip_types text/plain text/css text/javascript;\n\n    upstream app {\n        # fail_timeout=0 means we always retry an upstream even if it failed\n        # frontend is an alias set-up by Docker inside /etc/hosts\n        server frontend:8080 fail_timeout=0;\n    }\n\n    server {\n        listen 80;\n        server_name localhost;\n\n        access_log /static/var/log/nginx_access.log;\n        error_log /static/var/log/nginx_error.log;\n\n        root /static;\n\n        # Attempt to serve files via nginx first\n        # If match not found then pass request to upstream app (via @app location)\n        try_files $uri/index.html $uri @app;\n\n        location @app {\n            proxy_set_header X-Real-IP $remote_addr;\n            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n            proxy_set_header Host $http_host;\n            proxy_redirect off;\n\n            # enable this if you forward HTTPS traffic to unicorn,\n            # this helps Rack set the proper URL scheme for doing redirects:\n            # proxy_set_header X-Forwarded-Proto $scheme;\n\n            proxy_pass http://app;\n        }\n\n        error_page 500 502 503 504 /static/500.html;\n        client_max_body_size 4G;\n        keepalive_timeout 10;\n    }\n}\n\u003ch1\u003e500 Error Page!?!\u003c/h1\u003e\nfrontend:\n  image: ./front-end\n  ports:\n    - \"8080:5000\"\n\nproxy:\n  image: ./proxy\n  ports:\n    - \"80:80\"\n  links:\n    - frontend\nrequire \"sinatra/base\"\n\nclass App \u003c Sinatra::Base\n  set :bind, \"0.0.0.0\"\n\n  get \"/\" do\n    \"\u003cp\u003eThis is \u003ci\u003edynamic\u003c/i\u003e content served via puma: #{rand(36**6).to_s(36)}\"\n  end\nend\n\u003cp\u003eThis is \u003ci\u003estatic\u003c/i\u003e content served via nginx: abc123\u003c/p\u003e\n","tags":""},{"id":"9e9be437bf4ef6f79e4d","title":"Docker container for a better curl than found natively on Mac OSX","content":"docker run -it -v /path/to/certs/:/var/cert speg03/curl \n  --request PUT \"http://domain.com/endpoint\" \n  --header \"Content-Type: application/json\" \n  --data '{ \"foo\": \"bar\" }' \n  --cert /var/cert/Certificate.pem\n","tags":""},{"id":"160dbf75898bcf9cc4a6","title":"Siege load/stress testing utility (https://www.joedog.org/siege-manual/)","content":"# Updated by Siege 3.1.3, January-11-2016\n# Copyright 2000-2015 by Jeffrey Fulmer, et al.\n# \n# Siege configuration file -- edit as necessary\n# For more information about configuring and running\n# this program, visit: http://www.joedog.org/\n\n#\n# Variable declarations. You can set variables here \n# for use in the directives below. Example:\n# PROXY = proxy.joedog.org\n# Reference variables inside ${} or $(), example: \n# proxy-host = ${PROXY} \n# You can also reference ENVIRONMENT variables without\n# actually declaring them, example:\n# logfile = $(HOME)/var/siege.log\n\n#\n# Verbose mode\n#\n# Signify verbose mode, true turns on verbose output\n# ex: verbose = true|false\n#\nverbose = true\n\n#\n# Quiet mode\n#\n# When true, this turns off verbose and standard output.\n# You'll still see the opening announcement and the final\n# stats if you're running a siege but -g/--get will be\n# extremely quiet. This was added primarily for scripting\n# ex: quiet = true|false\n#\nquiet = false\n\n#\n# Get method - select an HTTP method to use when siege \n# is set to get mode, siege -g/--get URL. You may select\n# GET or HEAD.  The default method is HEAD. As expected\n# HEAD prints just the headers and GET prints the entire \n# page. \n#\n# NOTE: This only applies when siege is invoked with\n# -g/--get.  All other requests methods will be made\n# on the basis of the URL. \n# \n# example: gmethod = GET\n# \ngmethod = HEAD\n\n\n#\n# CSV Verbose format: with this option, you can choose \n# to format verbose output in traditional siege format \n# or comma separated format. The latter will allow you \n# to redirect output to a file for import into a spread\n# sheet, i.e., siege \u003e file.csv \n# ex: csv = true|false (default false)\n#\n# csv = true\n\n#\n# Timestamp format: with this option, you can choose to\n# print a timestamp each line of output\n# example: timestamp = true|false (default false)\n#\n# sample: [Sat, 2010-11-20 10:39:13] HTTP/1.1 200   0.12 secs:    4003 bytes ==\u003e / \n# \n# timestamp = true\n\n#\n# Full URL verbose format: By default siege displays\n# the URL path and not the full URL. With this option, \n# you # can instruct siege to show the complete URL.\n# ex: fullurl = true|false (default false)\n# \n# fullurl = true\n\n#\n# Display id: in verbose mode, display the siege user\n# id associated with the HTTP transaction information\n# ex: display-id = true|false\n#\n# display-id = \n\n#\n# Limit: This directive places a cap on the number of\n# threads siege will generate. The default value is 255 \n# because out of the box apache is configured to handle\n# 256 clients. If you schedule more clients than apache\n# can handle, requests will back up and you'll make a \n# mess. DO NOT INCREASE THIS NUMBER UNLESS YOU CONFIGURED\n# APACHE TO HANLDE MORE THAN 256 SIMULTANEOUS REQUESTS\n# ex: limit = 1023 (default is 255)\n# \nlimit = 255\n\n#\n# Show logfile location.  By default, siege displays the\n# logfile location at the end of every run when logging\n# You can turn this message off with this directive.\n# ex: show-logfile = false\n#\nshow-logfile = true\n\n#\n# Default logging status, true turns logging on.\n# ex: logging = true|false\n#\nlogging = true\n\n#\n# Logfile, the default siege logfile is $PREFIX/var/siege.log\n# This directive allows you to choose an alternative log file.\n# Environment variables may be used as shown in the examples:\n# ex: logfile = /home/jeff/var/log/siege.log\n#     logfile = ${HOME}/var/log/siege.log\n#     logfile = ${LOGFILE}\n#\n# logfile = \n\n#\n# HTTP protocol.  Options HTTP/1.1 and HTTP/1.0.\n# Some webservers have broken implementation of the\n# 1.1 protocol which skews throughput evaluations.\n# If you notice some siege clients hanging for\n# extended periods of time, change this to HTTP/1.0\n# ex: protocol = HTTP/1.1\n#     protocol = HTTP/1.0\n#\nprotocol = HTTP/1.1\n\n#\n# Chunked encoding is required by HTTP/1.1 protocol\n# but siege allows you to turn it off as desired.\n# \n# ex: chunked = true \n# \nchunked = true\n\n# \n# Cache revalidation.\n# Siege supports cache revalidation for both ETag and \n# Last-modified headers. If a copy is still fresh, the \n# server responds with 304. \n# HTTP/1.1 200   0.00 secs:    2326 bytes ==\u003e /apache_pb.gif\n# HTTP/1.1 304   0.00 secs:       0 bytes ==\u003e /apache_pb.gif\n# HTTP/1.1 304   0.00 secs:       0 bytes ==\u003e /apache_pb.gif\n# \n# ex: cache = true\n#\ncache = false\n\n#\n# Connection directive. Options \"close\" and \"keep-alive\"\n# Starting with release 2.57b3, siege implements persistent \n# connections in accordance to RFC 2068 using both chunked\n# encoding and content-length directives to determine the \n# page size. To run siege with persistent connections set\n# the connection directive to keep-alive. (Default close)\n# CAUTION: use the keep-alive directive with care.\n# DOUBLE CAUTION: this directive does not work well on HPUX\n# TRIPLE CAUTION: don't use keep-alives until further notice\n# ex: connection = close\n#     connection = keep-alive\n#\nconnection = close\n\n#\n# Default number of simulated  concurrent users\n# ex: concurrent = 25\n#\nconcurrent = 15\n\n#\n# Default duration of the siege.  The right hand argument has\n# a modifier which specifies the time units, H=hours, M=minutes,\n# and S=seconds. If a modifier is not specified, then minutes \n# are assumed.\n# ex: time = 50M\n#\n# time =\n\n#\n# Repetitions.  The length of siege may be specified in client\n# reps rather then a time duration.  Instead of specifying a time\n# span, you can tell each siege instance to hit the server X number\n# of times.  So if you chose 'reps = 20' and you've selected 10 \n# concurrent users, then siege will hit the server 200 times.\n# ex: reps = 20\n#\n# reps = \n\n#\n# Default URLs file, set at configuration time, the default\n# file is PREFIX/etc/urls.txt.  So if you configured siege\n# with --prefix=/usr/local then the urls.txt file is installed\n# int /usr/local/etc/urls.txt.  Use the \"file = \" directive to\n# configure an alternative URLs file. You may use environment\n# variables as shown in the examples below:\n# ex: file = /export/home/jdfulmer/MYURLS.txt\n#     file = $HOME/etc/urls.txt\n#     file = $URLSFILE\n#\n# file =\n\n#\n# Default URL, this is a single URL that you want to test. This\n# is usually set at the command line with the -u option.  When\n# used, this option overrides the urls.txt (-f FILE/--file=FILE)\n# option. You will HAVE to comment this out for in order to use\n# the urls.txt file option.\n#\n# NOTE: you may do the same thing by passing a URL to siege at \n# the command line: siege -c10 -r10 \"www.joedog.org/\"\n# Generally, it's a good idea to wrap a command line URL in quotes\n#\n# ex: url = https://shemp.whoohoo.com/docs/index.jsp\n#\n# url =\n\n#\n# Default delay between each request by a single thread. This \n# value is not included in the request time. If a thread sleeps \n# for two seconds then completes a 0.5 second request, the time\n# of the request is 0.5 seconds, not 2.5 seconds.\n#\n# ex: delay = 0.5\n#\ndelay = 1\n\n#\n# Connection timeout value. Set the value in seconds for \n# socket connection timeouts. The default value is 30 seconds.\n# ex: timeout = 30\n#\n# timeout = \n\n#\n# Session expiration: This directive allows you to delete all\n# cookies after you pass through the URLs. This means siege will\n# grab a new session with each run through its URLs. The default\n# value is false.\n# ex: expire-session = true\n#\n# expire-session = \n\n#\n# Cookie support: by default siege accepts cookies. This directive\n# is available to disable that support. Set cookies to 'false' to\n# refuse cookies. Set it to 'true' to accept them. The default value \n# is true.\n# ex: cookies = false\n#\n# cookies = \n\n#\n# Failures: This is the number of total connection failures allowed\n# before siege aborts. Connection failures (timeouts, socket failures, \n# etc.) are combined with 400 and 500 level errors in the final stats, \n# but those errors do not count against the abort total.  If you set \n# this total to 10, then siege will abort after ten socket timeouts, \n# but it will NOT abort after ten 404s. This is designed to prevent \n# a run-away mess on an unattended siege. The default value is 1024\n# ex: failures = 50\n#\n# failures = \n\n#\n# Internet simulation. If true, siege clients will hit\n# the URLs in the urls.txt file randomly, thereby simulating\n# internet usage.  If false, siege will run through the \n# urls.txt file in order from first to last and back again.\n# ex: internet = true\n#\ninternet = false\n\n#\n# Default benchmarking value, If true, there is NO delay\n# between server requests, siege runs as fast as the web\n# server and the network will let it.  Set this to false \n# for load testing.\n# ex: benchmark = true\n# \nbenchmark = false\n\n#\n# Set the siege User-Agent to identify yourself at the\n# host, the default is: JoeDog/1.00 [en] (X11; I; Siege #.##) \n# But that wreaks of corporate techno speak.  Feel free\n# to make it more interesting :-)  Since Limey is recovering\n# from minor surgery as I write this, I'll dedicate the \n# example to him...\n#\n# ex: user-agent = Limey The Bulldog\n# \n# user-agent =\n\n#\n# Accept-encoding. This option allows you to specify \n# acceptable encodings returned by the server. Use this\n# directive to turn on compression. By default we accept\n# gzip compression.\n#\n# ex: accept-encoding = *\n#     accept-encoding = gzip\n#     accept-encoding = compress;q=0.5;gzip;q=1\naccept-encoding = gzip\n\n#\n# URL escaping was added in version 3.0.3. You may use this\n# directive to turn off this experimental feature. By default\n# this feature is active by default starting with v3.0.3\n#\n# http://www.joedog.org/jukebox.php?band=the days of new\n# becomes:\n# http://www.joedog.org/jukebox.php?band=the%20days%20of%20the%20new \n#\n# ex: url-escaping = false\n#\nurl-escaping = true\n\n#\n# TURN OFF THAT ANNOYING SPINNER!\n# Siege spawns a thread and runs a spinner to entertain you\n# as it collects and computes its stats. If you don't like \n# this feature, you may turn it off here. Your JoeDog loves \n# this feature but he understands that it may not render well\n# in your particular terminal.  It's on by default because who\n# doesn't love a good spinner! \n#\n# ex: spinner = false \n#\nspinner = true\n\n#\n# WWW-Authenticate. Currently siege supports two types\n# of HTTP authentication: digest and basic. It has partial \n# support for Microsoft's NTLM but in practice that only \n# works with the -g/--get option. (as of siege 3.1.1)\n# \n# When siege makes a request for a page that requires user\n# authentication, it will search its logins for a matching\n# realm. If it finds credentials for a realm, it will attempt\n# to login with that username and password.\n#\n# If it fails to match the realm, it will use its default login\n# credentials (which are designated with the keyword \"all\" or no\n# specified realm. \n#\n# If you do not supply a realm, then it will default to \"all\"\n# which instructs siege to send as default.\n# \n# You may enter many logins with each on its own separate line. \n# The only limitation is memory and realm name. You can't use the\n# same realm name more than once.  \n#\n# ex: login = jdfulmer:topsecret:Admin\n#     login = jeff:supersecret:all \n#     login = jeff:supersecret\n#\n# login = \n\n#\n# Login URL. This is the first URL to be hit by every siege\n# client. This feature was designed to allow you to login to \n# a server and establish a session. It will only be hit once\n# so if you need to hit this URL more then once, make sure it\n# also appears in your urls.txt file. \n#\n# ex: login-url = http://eos.haha.com/login.jsp POST name=jeff\u0026pass=foo\n#\n# Siege versions after 2.69 support multi logins; you can configure \n# them with multiple login-url directives. Place each one on a separate \n# line. Siege loops through each login then starts again at the beginning \n# after it uses the last one. If you have more users than login-urls, then \n# siege starts reassigning ones that have already been used. \n# \n# ex: login-url = http://www.haha.com/login.php?name=homer\u0026pass=whoohoo\n#     login-url = http://www.haha.com/login.php?name=marge\u0026pass=ohhomie\n#     login-url = http://www.haha.com/login.php?name=bart\u0026pass=eatMyShorts\n#\n# login-url = \n\n#\n# FTP login - This directive provides one of two ways \n# to login to an ftp server. You may also set credentials \n# in RFC-1738 format: ftp://user:pass@host.com/ink.jpg\n#\n# The format is USER:PASS:HOST separated by colon ':'\n# The host field is optional. If you don't set a host,\n# then siege will send the same user:pass to every FTP\n# server. You may use this directive MULTIPLE times. \n# Siege will store each instance in memory and send the\n# appropriate credentials at login time depending on the\n# hostname in the URL.\n#\n# ex: ftp-login: jdfulmer:whoohoo:ftp.joedog.org\n#     ftp-login: jdfulmer:password\n#\n# ftp-login = \n\n# \n# FTP unique - This directive determines whether siege \n# will upload files with the same name (and therefore \n# overwrite whatever is on disk) or upload files each with a\n# unique name. If true, siege will rewrite the file name with \n# a timestamp in its name, i.e., p.jpg =\u003e p-3086060432.jpg\n# The default value is true.\n#\n# ex: unique = false\n# \nunique = true\n\n#\n# ssl-cert\n# This optional feature allows you to specify a path to a client\n# certificate. It is not neccessary to specify a certificate in\n# order to use https. If you don't know why you would want one, \n# then you probably don't need this feature.  Use openssl to \n# generate a certificate and key with the following command:\n#   $ openssl req -nodes -new -days 365 -newkey rsa:1024 \\\n#                 -keyout key.pem -out cert.pem\n# Specify a path to cert.pem as follows:\n# ex: ssl-cert = /home/jeff/.certs/cert.pem\n#\n# ssl-cert = \n \n#\n# ssl-key\n# Use this option to specify the key you generated with the command\n# above. ex: ssl-key = /home/jeff/.certs/key.pem \n# You may actually skip this option and combine both your cert and \n# your key in a single file:\n#   $ cat key.pem \u003e client.pem\n#   $ cat cert.pem \u003e\u003e client.pem\n# Now set the path for ssl-cert:\n# ex: ssl-cert = /home/jeff/.certs/client.pem\n# (in this scenario, you comment out ssl-key)\n#\n# ssl-key = \n\n#\n# ssl-timeout \n# This option sets a connection timeout for the ssl library\n# ex: ssl-timeout = 30\n# \n# ssl-timeout = \n\n#\n# ssl-ciphers\n# You can use this feature to select a specific ssl cipher\n# for HTTPs. To view the ones available with your library run\n# the following command: openssl ciphers\n# ex: ssl-ciphers = EXP-RC4-MD5\n#\n# ssl-ciphers = \n\n#\n# Proxy Host. You can use siege to test a proxy server but\n# you need to configure it to use one. You'll need to name\n# a proxy host and the port it's listening one. The settings\n# are proxy-host and proxy-port. The following example shows\n# how to use them.\n# ex: proxy-host = proxy.joedog.org\n#     proxy-port = 3123\n#\n# proxy-host =\n# proxy-port =\n\n#\n# Proxy-Authenticate. When scout hits a proxy server which\n# requires username and password authentication, it will this\n# username and password to the server. The format is username,\n# password and optional realm each separated by a colon. You\n# may enter more than one proxy-login as long as each one has\n# a different realm. If you do not enter a realm, then scout\n# will send that login information to all proxy challenges. If\n# you have more than one proxy-login, then scout will attempt\n# to match the login to the realm.\n# ex: proxy-login: jeff:secret:corporate\n#     proxy-login: jeff:whoohoo\n#\n# proxy-login = \n\n#\n# Redirection support.  This option allows to to control\n# whether a Location: hint will be followed.  Most users\n# will want to follow redirection information, but sometimes\n# it's desired to just get the Location information.\n#\n# ex: follow-location = false\n#\n# follow-location = \n\n# Zero-length data.  siege can be configured to disregard\n# results in which zero bytes are read after the headers.\n# Alternatively, such results can be counted in the final\n# tally of outcomes.\n#\n# ex: zero-data-ok = false \n#\n# zero-data-ok =\n\n#\n# end of siegerc\n# brew install siege\n\n# -c/--concurrent == number of concurrent requests\n# -r/--reps == number of times to run the test\n\nsiege -c 10 -r 10 -b \"http://www.domain.com/\"\n\n# Note: doesn't always work with SSL endpoints with self-signed certs\n#       using Apache Ab in a Docker container seems to do the trick though\n#       see https://gist.github.com/Integralist/01815f7abc7d18a97341\n\nsiege --header \"Content-Type: application/json\" \\\n      --get \\\n      --concurrent 2\\\n      --reps 5\\\n      'https://requester.mozart.int.api.bbci.co.uk/collect POST {\"components\":[{\"id\":\"A\",\"endpoint\":\"https://morph.int.api.bbci.co.uk/data/orb-webservice-header\",\"must_succeed\":true}]}'\n      \n# `--get` is useful for debugging purposes as it returns the HEADERS from the POST\n# the above POST will send 10 requests in total\n\n# One-liner\nsiege -H \"Content-Type: application/json\" -g -c 2 -r 5 'https://requester.mozart.int.api.bbci.co.uk/collect POST {\"components\":[{\"id\":\"A\",\"endpoint\":\"https://morph.int.api.bbci.co.uk/data/orb-webservice-header\",\"must_succeed\":true}]}'\n\n# There are more options available when using a `.siegerc` file...\n# the other flags stop working once you specify -R\nsiege -R .siegerc -H \"Content-Type: application/json\" 'https://requester.mozart.int.api.bbci.co.uk/collect POST {\"components\":[{\"id\":\"A\",\"endpoint\":\"https://morph.int.api.bbci.co.uk/data/orb-webservice-header\",\"must_succeed\":true}]}'\n\n# Auto generate a .siegerc file\nsiege.config\n\n# View current settings in the .siegerc file\nsiege -C\n","tags":""},{"id":"749153aa53fea7168e7e","title":"Array flatten function written in ES6 syntax","content":"const flattenTco = ([first, ...rest], accumulator) =\u003e \n  (first === undefined)\n    ? accumulator\n    : (Array.isArray(first))\n      ? flattenTco([...first, ...rest])\n      : flattenTco(rest, accumulator.concat(first))\n  \nconst flatten = (n) =\u003e flattenTco(n, []);\n  \nconsole.log(flatten([[1,[2,[[3]]]],4,[5,[[[6]]]]]))\n","tags":""},{"id":"1745beb7b1607caf36f1","title":"[Sed Insert Append + Prefix and Suffix] ","content":"# Use `sed` to insert/append content around a match \n#\n# Note: has to be specific version of Sed\n#       I've found GNU Sed `gsed` works on my Mac but the system Sed doesn't\n\necho \"foo bar baz\" | gsed '/foo/i ---'\necho \"foo bar baz\" | gsed '/foo/a ---'\n\necho \"foo bar baz\" \u003e words.txt\ngsed '/foo/i ---' words\ngsed '/foo/a ---' words\n\n# Insert output\n#\n# ---\n# foo bar baz\n\n# Append output\n#\n# foo bar baz\n# ---\n\n$ echo -e \"foo\\nbar\\nbaz\" | sed 's/.*/PREFIX-\u0026-SUFFIX/'\nPREFIX-foo-SUFFIX\nPREFIX-bar-SUFFIX\nPREFIX-baz-SUFFIX\n","tags":"#sed #bash #insert #append #prefix #suffix"},{"id":"db10e8e8a6ec2ca8515d","title":"Optimise image size using Ruby","content":"desc \"Compress jpg images\"\ntask :compress_images do\n  images = Dir.glob(\"path/to/images/*.jpg\")\n  images.each do |image|\n    puts \"Compressing #{image}\"\n    system(\"convert -strip -interlace Plane -quality 45% #{image} #{image}\")\n  end\nend\n","tags":""},{"id":"f701ff1065a751387cb1","title":"Example of a slightly complex search/filter query for Elasticsearch (the - before message means NOT)","content":"# https://lucene.apache.org/core/2_9_4/queryparsersyntax.html\n\n# Grouping AND along with OR statement\n\n(message:\"ERROR\" OR message:\"WARN\") AND (-message:\"placeholder\")\n\n# Match anything except: GET /\n\n* AND -message:\"GET /\"\n\n# Match error logs \"E,\" but ignore those that include \"Failed Headline Fetch\" or \"GET /\" or \"INFO\"\n\nmessage:\"E,\" AND -message:\"Failed Headline Fetch\" AND -message:\"GET /\" AND -message:\"INFO\"\n\n# Specify a timeframe\n\nmessage:\"E,\" AND -message:\"Failed Headline Fetch\" AND @timestamp: [2015-06-11T10:00:00 TO 2015-06-11T21:00:00]\n","tags":""},{"id":"2e3c083cb4d16bfb5779","title":"This is a nice concise where to extract the successful match within a capture group using Ruby: http://ruby-doc.org/core-2.2.0/String.html","content":"\"HTTP/123456 999\"[/^HTTP\\/[\\d\\.]+ ([\\d]{3})/, 1] # =\u003e 999\n","tags":"#method-i-5B-5D"},{"id":"4fe392b768bf94d23abc","title":"Clojure Macros cheat sheet","content":"# Clojure Macros cheat sheet\n\n### Defining macros\n\n```clj\n(defmacro macro-name [\u0026 args] \n\t...)\n```\n\n### Quoting\n\nQuoting prevents the form following the single-quote sign from being evaluated:\n\n```clj\nuser=\u003e (def my-list '(1 2 3))\n```\n\n### Syntax-quote\n\nLike quote in that it prevents the evaluation of the form following its operator (`). The difference is that it attempts to namespace-qualify all symbols in the given form:\n\n```clj\nuser=\u003e `(+ my-list) \n;; (clojure.core/+ user/my-list)\n```\n\n### Unquoting\n\nIn a quoted form, unquote (~) forces the evaluation of the form following it at macro-expansion time:\n\n```clj\nuser=\u003e `(+ ~my-list) \n;;(clojure.core/+ (1 2 3))\n```\n\n### Unquote-splicing\n\nIn a quoted form, unquote-splicing (~@) forces the evaluation of the form - which is assumed to be a list - and _unpacks_ its content in the position it is used:\n\n```clj\nuser=\u003e `(+ ~@my-list) \n;; (clojure.core/+ 1 2 3)\n```\n\n### Debugging\n\nThe built-in `macroexpand` function expands the given quoted form until it doesn't represent a macro any longer:\n\n```clj\nuser=\u003e  (macroexpand '(cond \n                        (even? 2) \"even\"\n                        :else \"odd\"))\n               \n;; (if (even? 2)\n;;   \"even\"\n;;   (clojure.core/cond :else \"odd\"))               \n```\n\nSometimes it's useful to recursively expand macros until the form can't be expanded further. The function `macroexpand-all` from the `clojure.walk` namespace does just that:\n\n```clj\nuser=\u003e (require '[clojure.walk :as w])\nuser=\u003e (w/macroexpand-all '(cond\n                            (even? 2) \"even\"\n                            :else \"odd\"))\n                            \n;; (if (even? 2)\n;;   \"even\"\n;;   (if :else \"odd\" nil))\n```\n","tags":""},{"id":"bdb68d0b499bc502be11","title":"Clojure talking to Spurious","content":"(ns spurious-aws-sdk-helper.core\n  (:use [amazonica.aws.s3]))\n\n(def credentials {:access-key \"development_access\"\n                  :secret-key \"development_secret\"\n                  :endpoint \"s3.spurious.localhost:49154\"\n                  :client-config {:protocol \"http\"}})\n\n(set-s3client-options credentials :path-style-access true)\n(create-bucket credentials \"testing\")\n(ns spurious-aws-sdk-helper.core\n  (:use [amazonica.aws.s3]\n        [clojure.pprint :only [print-table]])\n  (:require [amazonica.core :refer [defcredential get-credentials ex-\u003emap]]\n            [clojure.reflect :as r]))\n\n(defn env [name]\n  (System/getenv name))\n\n(prn (env \"GREETING\"))\n\n(def credentials {:access-key \"development_access\"\n                  :secret-key \"development_secret\"\n                  :endpoint \"s3.spurious.localhost:49154\"\n                  :client-config {:protocol \"http\"}})\n\n; use reflection to see methods on a class\n; get-credentials for cred returns BasicAWSCredentials class\n(print-table\n  (:members\n    (r/reflect (get-credentials (defcredential \"development_access\" \"development_secret\" \"eu-west-1\")))))\n\n; display all public functions from a specified namespace and the current namespace\n(keys (ns-publics 'amazonica.aws.s3))\n(keys (ns-publics *ns*))\n\n(try\n  (set-s3client-options credentials :path-style-access true)\n  (create-bucket credentials \"testing\")\n  (catch Exception e\n    (clojure.pprint/write (ex-\u003emap e))))\n\n; to prevent having to pass around `credentials` to every function call we could just call `defcredential` once\n","tags":""},{"id":"3db095cb29dc6ae7625c","title":"Reading \"Programming Concurrency on the JVM\" I found an example (which I've modified below) using Clojure to solve a classic concurrency dilemma by using the STM to help keep things sane.","content":"; we need to have 1000 (or more) across both accounts\n; if we have less than a 1000 then there is a violation\n\n(def current-account (ref 500))\n(def savings-account (ref 600))\n\n; the `alter` function allows us to modify a reference (`@from` in this case\n; which points to either the reference `current-account` or `savings-account`)\n\n(defn unsafe-withdraw [from constraint amount]\n  (dosync\n    (let [total (+ @from @constraint)]\n      (Thread/sleep 1000) ; blocks \u0026 so allows context switch to other future(thread) to start\n      (if (\u003e= (- total amount) 1000)\n        (alter from - amount)\n        (println \"Sorry, can't withdraw due to constraint violation\")))))\n\n(defn safe-withdraw [from constraint amount]\n  (dosync\n    (let [total (+ @from (ensure constraint))] ; the `ensure` function is the secret sauce!\n                                               ; also notice we don't deference the value (@constraint)\n      (Thread/sleep 1000)\n      (if (\u003e= (- total amount) 1000)\n        (alter from - amount)\n        (println \"Sorry, can't withdraw due to constraint violation\")))))\n\n; `ensure` let's us tell a transaction (remember `dosync` is using the STM)\n; to watch a variable that is read and not modified.\n; STM will ensure writes are comitted only if the values we've read have not\n; changed outside the transaction. It'll then retry the transaction otherwise.\n\n; UNSAFE EXAMPLE EXECUTION\n\n(println \"UNSAFE: BEFORE\")\n(println \"Current Account balance is\" @current-account)\n(println \"Savings Account balance is\" @savings-account)\n(println \"Total balance is\" (+ @current-account @savings-account))\n\n(future (unsafe-withdraw current-account savings-account 100))\n(future (unsafe-withdraw savings-account current-account 100))\n\n(Thread/sleep 2000) ; allowing enough time for both futures(threads) to complete\n\n(println \"UNSAFE: AFTER\")\n(println \"Current Account balance is\" @current-account)\n(println \"Savings Account balance is\" @savings-account)\n(println \"Total balance is\" (+ @current-account @savings-account))\n\n; OUTPUT (notice our code is not thread-safe as we've violated the account requirements)...\n\n; UNSAFE: BEFORE\n; Current Account balance is 500\n; Savings Account balance is 600\n; Total balance is 1100\n\n; UNSAFE: AFTER\n; Current Account balance is 400\n; Savings Account balance is 500\n; Total balance is 900\n\n; ...WE'RE UNDER A 1000 ACROSS BOTH ACCOUNTS :-(\n\n\n; SAFE EXAMPLE EXECUTION\n\n(dosync (ref-set current-account 500)) ; reset value\n(dosync (ref-set savings-account 600)) ; reset value\n\n(println \"SAFE: BEFORE\")\n(println \"Current Account balance is\" @current-account)\n(println \"Savings Account balance is\" @savings-account)\n(println \"Total balance is\" (+ @current-account @savings-account))\n\n(future (safe-withdraw current-account savings-account 100))\n(future (safe-withdraw savings-account current-account 100))\n\n(Thread/sleep 2000) ; allowing enough time for both futures(threads) to complete\n\n(println \"SAFE: AFTER\")\n(println \"Current Account balance is\" @current-account)\n(println \"Savings Account balance is\" @savings-account)\n(println \"Total balance is\" (+ @current-account @savings-account))\n\n; OUTPUT (notice our code is now thread-safe)...\n\n; SAFE: BEFORE\n; Current Account balance is 500\n; Savings Account balance is 600\n; Total balance is 1100\n\n; SAFE: AFTER\n; Current Account balance is 400\n; Savings Account balance is 600\n; Total balance is 1000\n\n; ...ONLY ISSUE IS THAT IT SEEMS LIKE THE STM HASN'T RETRIED THE TRANSACTION?\n; BECAUSE THERE IS NO WARNING MESSAGE PRINTED (AS PER THE `ELSE` STATEMENT)\n; ALSO! MOST OF THE TIME THE BALANCE STAYS AS 1100 (NOTHING DEDUCTED FROM EITHER ACCOUNT)\n; AND ON THE RARE OCCASION THE SAVINGS ACCOUNT WILL BE DEDUCTED FROM RATHER THAN THE CURRENT ACCOUNT\n","tags":""},{"id":"62a2b3e41c27ec680cbf","title":"Spawning Actors in Celluloid","content":"// Taken from http://uberfork.com/post/30510463110/spawning-actors-in-celluloid\n\nThere are four built-in classes that help managing Actor instances:\n\n1. Actor\n2. Supervisor\n3. PoolManager\n4. SupervisionGroup\n\n```ruby\nclass Cat\n  include Celluloid\n  class DeadCatError \u003c StandardError; end\n \n  def initialize name=nil\n    @name = name\n    @lives_left = 9\n  end\n  \n  def spray\n    † if @lives_left == 0\n \n    # spraying is dangerous\n    # http://www.youtube.com/watch?v=uIbkLjjlMV8 \n    @lives_left -= 1\n  end\n \n  def †\n    who = if name\n      \"known as '#{@name}'\"\n    else\n      \"unknown vagrant\"\n    end\n    raise DeadCatError, \"Yet another cat in heaven.. (#{who})\"\n  end\nend\n```\n\n// Each time a cat sprays it will loose one of its lives. When a cat sprays too often, it will just die*.\n\nThe simpliest example to use an Actor is just to call Actor.new, like using a plain Ruby object. This works totally fine, until the Actor thread dies, because then it won’t come back by itself. Instead it is up to you to catch such a case and deal with it.\n\n```ruby\n# instantiate a cat object named 'Garfield' within its own actor thread\ncat = Cat.new 'Garfield'\n \n# blocking (the main thread waits until the cat has finished..)\ncat.spray\n \n# non-blocking\ncat.spray!\n \n# cats do what cats do\n7.times { cat.spray } \n \n# this will kill the actor thread (because spraying ain't petty crime!)\n# however, when using the non-blocking call the main thread won't receive\n# any exceptions raised within the actor thread (even a dead actor call is not\n# harmful)\ncat.spray!\n \n# false, the actor thread died\nputs cat.alive?\n```\n\nWhen you don’t like to loose your Actor instance and you want to have it respawn automatically you can just use the Actor.supervise method. This will spawn a second thread that respawns the Actor thread every time it dies.\n\n```ruby\n# here there are two threads, one for the actor and one for the supervisor, that\n# will respawn the actor if the actor dies\nCat.supervise_as :cat, 'Garfield'\n \ncats_died = 0\n50.times do\n  begin\n    Celluloid::Actor[:cat].spray\n  rescue Cat::DeadCatError =\u003e e\n    cats_died += 1\n    sleep 0.05 # wait a bit to let respawn take place\n  end\nend\n \n# when cat actors die, the supervisor will respawn..\nputs cats_died # more than 1\n```\n\nSometimes you may not want just one Actor instance but whole group. This can be useful when you want to gain performance by parallelization. You can do this easily by using the Actor.pool method to spawn a PoolManager instance. The PoolManager will then spawn multiple Actor threads of the same Actor class.  Similar to using the Supervisor the PoolManager will also respawn Actor threads if they fail. For maximum performance the default pool size matches the size of CPU cores your system provides. \n\n```ruby\n# a pool of actors spawns one additional thread for the pool manager. the pool\n# manager then spawns (and respawns in case of failure) the actor threads.\n# per default the pool size (the number of actor threads) is equal to the number\n# of cpu cores.\ngang_of_cats = Cat.pool size: 2\n \ncats_died = 0\n50.times do\n  begin\n    gang_of_cats.spray\n  rescue Cat::DeadCatError =\u003e e\n    cats_died += 1\n    sleep 0.05\n  end\nend\n \nputs cats_died # more than 1\n```\n\nFinally there is the SupervisionGroup. In contrast to the previous examples the SupervisionGroup is designed to be used as a base class. It offers a declarative approach to combine a set of actors to a group together and make them depend on each other. So if one member of the group dies, the whole group will die. Of course, you can also add whole pool of Actors to the group. Hereby the group would only become dependent on the PoolManager itself. So when the PoolManager dies, the group dies. But when a member of the pool dies, it is respawned by the PoolManager. The following examples illustrates this.\n\n```ruby\n# define a gang of cats with a leader\nclass CatGangWithLeader \u003c Celluloid::SupervisionGroup\n  # this\n  supervise Cat, as: :alpha_leader, args: 'Garfield'\n  supervise Cat, as: :gang_of_cats, size: 2, method: 'pool'\nend\n \n# this starts 5 threads in total:\n#   - 2x for the alpha leader (supervisor + actor)\n#   - 3x for the gang member (supervisor + 2x actor)\nCatGangWithLeader.run!\nsleep 0.05\n \nalpha_leader_died = 0\nmember_died = 0\n \n200.times do\n  begin\n    # most of the time a member will be used\n    if rand \u003e 0.1\n      Celluloid::Actor[:gang_of_cats].spray\n    else\n      Celluloid::Actor[:alpha_leader].spray\n    end\n \n  # as soon as the alpha leader dies, the whole supervision group is dead\n  # then this error will happen and we can stop the loop\n  rescue Celluloid::DeadActorError =\u003e e\n    break\n  rescue Cat::DeadCatError =\u003e e\n    if e.message =~ /Garfield/\n      alpha_leader_died += 1\n    else\n      member_died += 1\n    end\n    sleep 0.01\n  end\nend\n \n# this is a strange or interesting behaviour. death of a vagrant (a pool member)\n# usally happens more than 1 time (max. 20). but as soon as the leader dies, the \n# whole supervision group dies and the loop ends. so the typical ratio is 9:1.\nputs \"The gang members died #{member_died} times.\\n\"\\\n     \"The leader (Garfield) died #{alpha_leader_died} times.\"\n```\n","tags":""},{"id":"12b3f1370dbc1530ad0b","title":"Rust Cargo Guardfile","content":"require \"terminal-notifier-guard\"\n\nguard :shell do\n  watch(/src\\/(.*\\/)?(.*)\\.rs$/) do |path, folder, file|\n    p \"Path: #{path}\"\n    p \"Folder: #{folder}\"\n    p \"File: #{file}\"\n\n    binary_name = `sed -ne 's/name = \"\\\\(.*\\\\)\"/\\\\1/p' Cargo.toml | tail -n 1`\n\n    `cargo build \u0026\u0026 ./target/#{binary_name}`\n  end\nend\n\n","tags":""},{"id":"6843e2cb448d879aa5a6","title":"Rust Guardfile","content":"require \"terminal-notifier-guard\"\n\nguard :shell do\n  watch(/(.*)\\/(.*)\\.rs$/) do |path, folder|\n    puts \"Compiling: #{folder}/main.rs\"\n    `rustc #{folder}/main.rs`\n  end\nend\n","tags":""},{"id":"e24848ee273fe4adab2c","title":"VimScript custom function that triggers tmux pane to open specified gem contents within Vim","content":"\" Open specified gem in a tmux split pane\n\" e.g. :OpenGem cloby\n\nfun! GemPath(gem)\n  let testing = system(\"bundle show \" . a:gem)\n  return substitute(testing, \"\\n\", \"\", \"\")\nendfun\n\n:command -nargs=1 OpenGem execute \":!tmux splitw 'echo \" . GemPath(\u003cf-args\u003e) . \" | xargs vim'; tmux select-pane -U; tmux send-keys 'C-m'; tmux select-pane -D\"\n","tags":""},{"id":"77877126a0b13766f0de","title":"[Tech Books: Recommended Reading] ","content":"## Algorithms\n\n- [Grokking Algorithms: An illustrated guide](https://www.manning.com/books/grokking-algorithms)\n\n## Best Practices\n\n- [Clean Code: A Handbook of Agile Software Craftsmanship](http://www.amazon.co.uk/Clean-Code-Handbook-Software-Craftsmanship/dp/0132350882/ref=wl_it_dp_o_pC_nS_nC?ie=UTF8\u0026colid=1KPZ4BNV1OMC4\u0026coliid=I1GJ3Q25TNFKN1)\n- [The Clean Coder: A Code of Conduct for Professional Programmers](http://www.amazon.co.uk/The-Clean-Coder-Professional-Programmers/dp/0137081073/ref=wl_it_dp_o_pC_S_nC?ie=UTF8\u0026colid=1KPZ4BNV1OMC4\u0026coliid=IJUCNB9OWB7H8)\n\n## Client-Side\n\n- [CSS: The Definitive Guide](http://www.amazon.co.uk/CSS-Definitive-Guide-Eric-Meyer/dp/0596527330/ref=sr_1_1?ie=UTF8\u0026qid=1427038313\u0026sr=8-1\u0026keywords=css+the+definitive+guide)\n- [Don't Make Me Think: A Common Sense Approach to Web Usability](http://www.amazon.co.uk/Dont-Make-Me-Think-Usability/dp/0321965515/ref=sr_1_1?ie=UTF8\u0026qid=1427038352\u0026sr=8-1\u0026keywords=dont+make+me+think)\n- [Even Faster Web Sites: Performance Best Practices for Web Developers](http://www.amazon.co.uk/Even-Faster-Web-Sites-Performance/dp/0596522304/ref=sr_1_1?ie=UTF8\u0026qid=1427038718\u0026sr=8-1\u0026keywords=even+faster+websites)\n- [High Performance Web Sites: Essential Knowledge for Front-End Engineers](http://www.amazon.co.uk/High-Performance-Web-Sites-Essential/dp/0596529309/ref=sr_1_1?ie=UTF8\u0026qid=1427038697\u0026sr=8-1\u0026keywords=High+Performance+Websites)\n- [Mobile First](http://abookapart.com/products/mobile-first)\n- [Responsible Responsive Design](http://abookapart.com/products/responsible-responsive-design)\n- [Responsive Web Design](http://abookapart.com/products/responsive-web-design)\n\n## Clojure\n\n- [Clojure for the Brave and True](http://www.amazon.co.uk/Clojure-Brave-True-Ultimate-Programmer/dp/1593275919/ref=sr_1_1?ie=UTF8\u0026qid=1427038088\u0026sr=8-1\u0026keywords=clojure+for+the+brave+and+true)\n- [Quick Clojure](https://www.apress.com/gb/book/9781484229514)\n- [The Joy of Clojure](http://www.amazon.co.uk/Joy-Clojure-Michael-Fogus/dp/1617291412/ref=sr_1_1?ie=UTF8\u0026qid=1427038071\u0026sr=8-1\u0026keywords=joy+of+clojure)\n\n## Communication\n\n- [Radical Candor: care personally and challenge directly](https://www.radicalcandor.com/)\n- [Nonviolent Communication](https://www.nonviolentcommunication.com/)\n- [Authentic Communication](https://www.soundstrue.com/store/authentic-communication.html)\n\n## Concurrency\n\n- [Programming Concurrency on the JVM: Mastering Synchronization, STM, and Actors](http://www.amazon.co.uk/Programming-Concurrency-JVM-Mastering-Synchronization/dp/193435676X)\n- [Seven Concurrency Models in Seven Weeks: When Threads Unravel](http://www.amazon.co.uk/Seven-Concurrency-Models-Weeks-Programmers/dp/1937785653/ref=sr_1_1?ie=UTF8\u0026qid=1427038041\u0026sr=8-1\u0026keywords=7+concurrency+models)\n\n## Culture\n\n- [Conscious Business: How to build value through values](https://www.soundstrue.com/store/conscious-business-4036.html)\n- [Powerful: building a culture of freedom and responsibility](http://pattymccord.com/book/)\n\n## Functional Programming\n\n- [Functional Programming Patterns in Scala and Clojure](http://www.amazon.co.uk/Functional-Programming-Patterns-Scala-Clojure/dp/1937785475/ref=sr_1_1?ie=UTF8\u0026qid=1427039601\u0026sr=8-1\u0026keywords=functional+programming+patterns+in+scala+and+clojure)\n- [Functional Programming in Scala](http://www.amazon.co.uk/Functional-Programming-Scala-Paul-Chiusano/dp/1617290653/ref=sr_1_1?ie=UTF8\u0026qid=1427039625\u0026sr=8-1\u0026keywords=functional+programming+in+scala)\n\n## Go\n\n- [The Go Programming Language](http://www.amazon.co.uk/Programming-Language-Addison-Wesley-Professional-Computing/dp/0134190440/ref=sr_1_1?s=books\u0026ie=UTF8\u0026qid=1453287896\u0026sr=1-1\u0026keywords=go+programming+language)\n\n## JavaScript\n\n- [Eloquent JavaScript: A Modern Introduction to Programming](http://www.amazon.co.uk/Eloquent-JavaScript-Modern-Introduction-Programming/dp/1593275846/ref=sr_1_1?ie=UTF8\u0026qid=1427038759\u0026sr=8-1\u0026keywords=eloquent+javascript)\n- [High Performance JavaScript (Build Faster Web Application Interfaces)](http://www.amazon.co.uk/Performance-JavaScript-Faster-Application-Interfaces/dp/059680279X/ref=sr_1_1?ie=UTF8\u0026qid=1427038840\u0026sr=8-1\u0026keywords=high+performance+javascript)\n- [JavaScript: The Good Parts](http://www.amazon.co.uk/JavaScript-Good-Parts-Douglas-Crockford/dp/0596517742/ref=sr_1_1?ie=UTF8\u0026qid=1427038785\u0026sr=8-1\u0026keywords=javascript+the+good+parts)\n- [Test Driven JavaScript Development](http://www.amazon.co.uk/Driven-JavaScript-Development-Developers-Library/dp/0321683919/ref=sr_1_1?ie=UTF8\u0026qid=1427038811\u0026sr=8-1\u0026keywords=test-driven+javascript+development)\n\n## Management\n\n- [The Manager's Path](http://shop.oreilly.com/product/0636920056843.do)\n- [Managing Humans: Biting and Humorous Tales of a Software Engineering Manager](http://managinghumans.com/pitch.html)\n\n## Patterns\n\n- [Mastering Regular Expressions](http://www.amazon.co.uk/Mastering-Regular-Expressions-Jeffrey-Paperback/dp/B006DVFVTU/ref=sr_1_5?ie=UTF8\u0026qid=1427038873\u0026sr=8-5\u0026keywords=mastering+regular+expressions)\n \n## PHP\n\n- [Practical Design Patterns in PHP](http://practicaldesignpatternsinphp.com/)\n \n## Python\n\n- [Effective Python](http://www.effectivepython.com/)\n\n## Ruby\n\n- [Beginning Ruby: From Novice to Professional](http://www.amazon.co.uk/Beginning-Ruby-Novice-Professional-Experts/dp/1430223634/ref=sr_1_1?ie=UTF8\u0026qid=1427038449\u0026sr=8-1\u0026keywords=beginning+ruby)\n- [Design Patterns in Ruby](http://www.amazon.co.uk/Design-Patterns-Ruby-Addison-Wesley-Professional/dp/0321490452/ref=wl_it_dp_o_pd_S_nC?ie=UTF8\u0026colid=1KPZ4BNV1OMC4\u0026coliid=I3ETXUMF5SXAB1)\n- [Metaprogramming Ruby](http://www.amazon.co.uk/Metaprogramming-Ruby-Program-Like-Facets/dp/1941222129/ref=sr_1_1?ie=UTF8\u0026qid=1427038474\u0026sr=8-1\u0026keywords=metaprogramming+ruby)\n- [Practical Object Oriented Design in Ruby](http://www.amazon.co.uk/Practical-Object-Oriented-Design-Ruby/dp/0321721330/ref=sr_1_1?ie=UTF8\u0026qid=1427038609\u0026sr=8-1\u0026keywords=practical+object-oriented+design+in+ruby)\n- [Refactoring: Ruby Edition](http://www.amazon.co.uk/Refactoring-Ruby-Addison-Wesley-Professional-ebook/dp/B002TIOYWG/ref=sr_1_1?ie=UTF8\u0026qid=1385646915\u0026sr=8-1\u0026keywords=ruby+refactoring)\n- [Sinatra - Up and Running](http://www.amazon.co.uk/Sinatra-Up-Running-Alan-Harris/dp/1449304230/ref=sr_1_1?ie=UTF8\u0026qid=1385656124\u0026sr=8-1\u0026keywords=Sinatra+-+Up+and+Running)\n\n## Rust\n\n- [Programming Rust](https://www.oreilly.com/library/view/programming-rust-2nd/9781492052586/)\n\n## Shell\n\n- [Classic Shell Scripting](http://shop.oreilly.com/product/9780596005955.do)\n\n## System Design, Networking and Security\n\n- [Amazon Web Services in Action](http://www.amazon.co.uk/Amazon-Web-Services-Action-Andreas-Wittig/dp/1617292885/ref=sr_1_1?s=books\u0026ie=UTF8\u0026qid=1453287921\u0026sr=1-1\u0026keywords=aws+in+action)\n- [Building Microservices](http://www.amazon.co.uk/Building-Microservices-Sam-Newman/dp/1491950358/ref=sr_1_1?ie=UTF8\u0026qid=1427039585\u0026sr=8-1\u0026keywords=Building+Microservices)\n- [Bulletproof SSL and TLS](http://www.amazon.co.uk/Bulletproof-SSL-TLS-Ivan-Ristic/dp/1907117040/ref=sr_1_1?ie=UTF8\u0026qid=1427038544\u0026sr=8-1\u0026keywords=Bulletproof+SSL+and+TLS)\n- [High Performance Browser Networking](http://www.amazon.co.uk/High-Performance-Browser-Networking-performance/dp/1449344763/ref=sr_1_1?ie=UTF8\u0026qid=1427039463\u0026sr=8-1\u0026keywords=high+performance+browser+networking)\n- [The Practice of Cloud System Administration: Volume 2: Designing and Operating Large Distributed Systems](http://www.amazon.co.uk/Practice-Cloud-System-Administration-Distributed/dp/032194318X/ref=sr_1_1?ie=UTF8\u0026qid=1427039519\u0026sr=8-1\u0026keywords=the+practice+of+cloud+system+administration)\n\n## Testing\n\n- [Growing Object Oriented Software Guided by Tests](http://www.amazon.co.uk/Growing-Object-Oriented-Software-Guided-Signature/dp/0321503627/ref=sr_1_1?ie=UTF8\u0026qid=1385655342\u0026sr=8-1\u0026keywords=Growing+Object+Oriented+Software+Guided+by+Tests)\n\n## Tools\n\n- [Pro Vim](http://www.amazon.co.uk/Pro-Vim-Mark-McDonnell/dp/1484202511/ref=sr_1_1?ie=UTF8\u0026qid=1427038180\u0026sr=8-1\u0026keywords=pro+vim)\n- [Vagrant: Up and Running](http://shop.oreilly.com/product/0636920026358.do)\n- [Version Control with Git: Powerful tools and techniques for collaborative software development](http://www.amazon.co.uk/Version-Control-Git-collaborative-development/dp/1449316387/ref=sr_1_1?ie=UTF8\u0026qid=1385647089\u0026sr=8-1\u0026keywords=version+control+with+git)\n","tags":"#reading #books #list"},{"id":"3822807d3c91281af22d","title":"Rubocop: ignore/disable features + example configuration yaml","content":"require \"mustache\"\n\nmodule Composition\n  module Page\n    class Model \u003c Mustache\n      def initialize(components, template)\n        @components = components\n        self.template = template.source\n        super()\n      end\n\n      def head\n        components.map(\u0026:head).flatten.join(\"\\n\")\n      end\n\n      # rubocop:disable MethodName, InlineComment\n      def bodyInline\n        components.map(\u0026:bodyInline).join(\"\\n\")\n      end\n\n      def bodyLast\n        components.map(\u0026:bodyLast).flatten.join(\"\\n\")\n      end\n      # rubocop:enable MethodName, InlineComment\n\n      private\n\n      attr_reader :components\n    end\n  end\nend\nLint/SpaceBeforeFirstArg:\n  Severity: fatal\n  Enabled: true\n \nLint/RescueException:\n  Severity: fatal\n  Enabled: true\n \nLint/UnusedBlockArgument:\n  Severity: fatal\n  Enabled: true\n \nMetrics/LineLength:\n  Severity: fatal\n  Enabled: true\n \nMetrics/MethodLength:\n  Severity: convention\n  Enabled: true\n  Max: 5\n \nStyle/AlignHash:\n  Severity: fatal\n  Enabled: true\n  EnforcedHashRocketStyle: table\n \nStyle/AlignParameters:\n  Severity: fatal\n  Enabled: true\n  EnforcedStyle: with_fixed_indentation\n \nStyle/BracesAroundHashParameters:\n  Severity: fatal\n  Enabled: true\n \nClassAndModuleChildren:\n  Severity: fatal\n  Enabled: true\n \nStyle/ConstantName:\n  Severity: fatal\n  Enabled: true\n \nStyle/Documentation:\n  Enabled: false\n \nStyle/EmptyLinesAroundClassBody:\n  Severity: fatal\n  Enabled: true\n \nStyle/ExtraSpacing:\n  Enabled: false\n \nStyle/FileName:\n  Enabled: false\n \nStyle/HashSyntax:\n  Severity: fatal\n  Enabled: true\n  EnforcedStyle: hash_rockets\n \nStyle/IndentationConsistency:\n  Severity: fatal\n  Enabled: true\n \nStyle/IndentationWidth:\n  Severity: fatal\n  Enabled: true\n \nStyle/IndentHash:\n  Severity: fatal\n  Enabled: true\n \nStyle/InlineComment:\n  Severity: fatal\n  Enabled: true\n \nStyle/LineEndConcatenation:\n  Severity: fatal\n  Enabled: true\n \nStyle/MethodName:\n  Severity: fatal\n  Enabled: true\n \nStyle/MultilineTernaryOperator:\n  Enabled: false\n \nStyle/NegatedIf:\n  Severity: fatal\n  Enabled: true\n \nStyle/Not:\n  Severity: fatal\n  Enabled: true\n \nStyle/SpaceInsideHashLiteralBraces:\n  Severity: fatal\n  Enabled: true\n \nStyle/StringLiterals:\n  Severity: fatal\n  Enabled: true\n  EnforcedStyle: double_quotes\n \nStyle/TrailingBlankLines:\n  Severity: fatal\n  Enabled: true\n \nStyle/TrailingWhitespace:\n  Severity: fatal\n  Enabled: true\n \nStyle/VariableName:\n  Severity: fatal\n  Enabled: true\n","tags":""},{"id":"9d9a28e7c0e07fa8fd52","title":"POST data via curl command using CERT and password","content":"curl --verbose \\ \n     --header \"Content-Type: application/json\" \\\n     --request POST \\\n     --data '{\"foo\":\"bar\"}' \\\n     --insecure \\\n     --cert $DEV_CERT_P12:{password} \\\n     https://domain.com/path/to/endpoint\n","tags":""},{"id":"6d8c6e44d79e0ca17579","title":"Ruby DI Container Example (Dim)","content":"require \"dim\" # gem install dim\n\nmodule Hai\n  class Container \u003c Dim::Container\n    def initialize\n      super\n      setup\n    end\n\n    private\n\n    def setup\n      register(:foo) do |c|\n        #\n      end\n    end\n  end\nend\n","tags":""},{"id":"708fe5cda56a7bc958ad","title":"Year in Review 2014","content":"Looking back at what I achieved this year...\n\n- I published two books with Apress:\n  - [Pro Vim](http://www.amazon.co.uk/Pro-Vim-Mark-McDonnell/dp/1484202511/ref=sr_1_1)\n  - [tmux Taster](http://www.amazon.co.uk/tmux-Taster-Mark-McDonnell/dp/1484207769/ref=pd_sim_sbs_b_1)\n- Worked on BBC News Elections and Scottish Referendum back-end architecture and development with JRuby and AWS\n- Organised public event with [Sandi Metz](https://twitter.com/sandimetz) at [BBC New Broadcasting House](http://www.bbc.co.uk/broadcastinghouse/)\n  - Specifically getting a special thanks from Sandi in her opening story about her parents response to our invitation to speak at the BBC\n- Co-designed and built cloud based distributed load test tool with [David Blooman](https://twitter.com/dblooman)\n- Co-designed and built a CI workflow around static asset compilation with [Steven Jack](https://twitter.com/stevenjack85) and [Daniel Arnould](https://twitter.com/dan_arnould)\n- Hacking on [Steven Jack](https://twitter.com/stevenjack85)'s excellent cloud tooling gem (built specifically for BBC)\n- Having fun understanding the problem space of both concurrency and distributed systems design and implementation\n- Became technical lead/principal engineer for the BBC News Frameworks team\n  - But in reality that means nothing without an unbelievably solid team of extremely talented engineers to help make things happen:\n    - [Steven Jack](https://twitter.com/stevenjack85)\n    - [Daniel Arnould](https://twitter.com/dan_arnould)\n    - [Charlie Revett](https://twitter.com/charlierevett)\n    - [David Blooman](https://twitter.com/dblooman)\n- Co-designed and built [Market Data](http://m.bbc.co.uk/news/business/markets/europe/lse_ukx) back-end utilising the [Alephant Framework](https://github.com/BBC-News/alephant)\n- Worked on updating the [Alephant Framework](https://github.com/BBC-News/alephant) example applications\n  - Alephant was originally conceived by the massively talented [Robert Kenny](https://twitter.com/kenturamon)\n- Working in an environment that (albeit slowly and not entirely perfected - e.g. no automated rollbacks) has reached a state of Continuous Delivery.\n- Had fun playing with [Steven Jack](https://twitter.com/stevenjack85)'s great [Spurious](https://github.com/stevenjack/spurious) project \n  - Spurious is a toolset allowing development against a subset of AWS resources locally\n- Co-designed a new version of BBC Newsbeat that is cloud based, distributed and utilising the [Alephant Framework](https://github.com/BBC-News/alephant)\n- Won some awards:\n  - Best Public Relations of the Year (for my books [Pro Vim](http://www.apress.com/9781484202517) and [tmux Taster](http://www.apress.com/9781484207765))\n  - Most innovative use of Technology\n    - I accepted this award for the BBC News Frameworks team, but in reality it is shared between both [Steven Jack](https://twitter.com/stevenjack85) and [David Blooman](https://twitter.com/dblooman) for their great contributions to tooling built around [Docker](https://www.docker.com/)\n- Currently building a Trello to JIRA (and vice-versa) AWS based application to help synchronise data between these two platforms\n  - This is likely to be abstracted/generalised into an open-source project at some point in the future (as other organisations may find this type of tool useful)\n- Very happy to be working within a team that challenges itself to investigate and re-evaluate its stance on specific programming techniques and principles. This is a very encouraging and motivational team and I'm proud to be a part of it.\n","tags":""},{"id":"1fbbe4dafc77200c0bed","title":"Ruby: override `new` constructor method using meta programming","content":"module Bar\n  module ClassMethods\n    # `new` is a class method on the `Class` object\n    # It then uses `send` to access `initialize` which would otherwise be a private instance method\n    # So it can be overridden by extending the your class with a new `new` class method\n    def new(*args, \u0026block)\n      super\n      p \"new constructor defined\"\n    end\n  end\n\n  class \u003c\u003c self\n    def included(klass)\n      p \"#{klass} is the class that's including #{self}\"\n      klass.extend(ClassMethods)\n    end\n  end\nend\n\nclass Foo\n  include Bar\n\n  def initialize\n    p \"Foo constructor\"\n  end\nend\n\nFoo.new\n\n# \"Foo is the class that's including Bar\"\n# \"Foo constructor\"\n# \"new constructor defined\"\n","tags":""},{"id":"7b9034a9a961bcf76b0d","title":"Fix EC2 Timezone issues","content":"#!/bin/bash\nln -sf /usr/share/zoneinfo/Europe/London /etc/localtime\n","tags":""},{"id":"21cc5b702beb276054b0","title":"Concurrency: JRuby vs MRI","content":"**JRuby 1.7.12** (Puma):  \n2.0790 seconds\n\n**MRI 2.1.3p242** (Unicorn):  \n30.9189 seconds\n\n\u003e Note: these are using the default settings for both Puma and Unicorn\n\n### Update\n\n**MRI 2.1.3p242** (Unicorn - when configured with 8 processors**):  \n12.8673 seconds\n\n\u003e **see the following Unicorn config which is executed using  \n\u003e `bundle exec unicorn -c unicorn_config.rb`\n# Unicorn forks multiple OS processes within each dyno to allow an app to\n# support multiple concurrent requests without requiring them to be thread-safe\nworker_processes Integer(ENV[\"WEB_CONCURRENCY\"] || 8)\n\n# To ensure your application’s requests do not tie up your app with zombie processes when the server timeouts early\ntimeout 30\n\n# Preloading your application reduces the startup time of individual Unicorn\n# worker_processes and allows you to manage the external connections of each\n# individual worker using the before_fork and after_fork calls\npreload_app true\n\nbefore_fork do |server, worker|\n  Signal.trap 'TERM' do\n    puts 'Unicorn master intercepting TERM and sending myself QUIT instead'\n    Process.kill 'QUIT', Process.pid\n  end\nend\n\nafter_fork do |server, worker|\n  Signal.trap 'TERM' do\n    puts 'Unicorn worker intercepting TERM and doing nothing. Wait for master to send QUIT'\n  end\nend\nrequire \"thread\"\n\nmodule ConcurrencyTest\n  def self.run!\n    mutex       = Mutex.new\n    limit       = 1200\n    shared_data = 0\n\n    # Create 1200 Threads\n    # Each Thread will attempt to increment the shared data/memory\n    # Each Thread continues until the shared data/memory is equal to the defined limit\n\n    (1..limit).map do\n      Thread.new do\n        i = 0\n\n        while i \u003c limit\n          i += 1\n          mutex.synchronize { shared_data += 1 }\n        end\n      end\n    end.each { |t| t.join }\n\n    raise shared_data.to_s if shared_data != limit * limit\n\n    shared_data.to_s\n  end\nend\n# These results were based on running the script from the shell\n\n# System Ruby: 2.0.0p481\ntime ruby test.rb\nruby test.rb  16.11s user 237.43s system 206% cpu 2:02.63 total\n\n# MRI: 2.1.3p242\ntime ruby test.rb\nruby test.rb  15.90s user 263.46s system 194% cpu 2:23.70 total\n\n# JRuby 1.7.12\ntime ruby test.rb\nruby test.rb  15.93s user 14.35s system 280% cpu 10.778 total\n\n# UPDATE: I modified test.rb to be wrapped in a module for the purposes of testing within a web application\nrequire_relative \"../test\"\n\nrun -\u003e env do\n  [200, {\"Content-Type\" =\u003e \"text/html\"}, [ConcurrencyTest::run!]]\nend\n","tags":""},{"id":"741c2577e97fd8e466a4","title":"Clojure Thread State","content":"(def current-account (ref 500))\n(def savings-account (ref 600))\n\n(println (str \"current-account:\" current-account))\n(println (str \"savings-account:\" savings-account))\n\n(defn withdraw [from constraint amount]\n  (dosync\n    (let [total (+ @from (ensure constraint))]\n      (Thread/sleep 1000)\n      (println (str (Thread/currentThread) \" - \" (.isInterrupted (Thread/currentThread)) \"\\n\"))\n      (println (str (Thread/currentThread) \" - \" (.getState (Thread/currentThread)) \"\\n\"))\n      (println (str (Thread/currentThread) \" - \" (.getPriority (Thread/currentThread)) \"\\n\"))\n      (if (\u003e= (- total amount) 1000)\n        (alter from - amount)\n        (println \"Sorry, can't withdraw due to constraint violation\\n\")))))\n\n(println \"STATE BEFORE MODIFYING\")\n(println \"Current Account balance is\" @current-account)\n(println \"Savings Account balance is\" @savings-account)\n(println \"Total balance is\" (+ @current-account @savings-account))\n\n(future (withdraw current-account savings-account 100))\n(future (withdraw savings-account current-account 100))\n\n(Thread/sleep 4000)\n\n(println \"STATE AFTER MODIFYING\")\n(println \"Current Account balance is\" @current-account)\n(println \"Savings Account balance is\" @savings-account)\n(println \"Total balance is\" (+ @current-account @savings-account))\n","tags":""},{"id":"8437127809c10ca964ca","title":"Ruby Meta Programming: Dynamically create Class methods with values populated from YAML config","content":"CERT_PATH: \"/Users/markmcdonnell/.pki/Certificate.pem\"\nCA_PATH: \"/Users/markmcdonnell/.pki/ca.pem\"\nDEV_KEY: \"12345a6b78d90e1f2gh345ijk6l78m90\"\nMEMBER_TOKEN: \"00000a0b00d00e0f0gh000ijk0l00m00\"\nJIRA_ENDPOINT: \"https://jira.domain.com/rest/api/2\"\nTRELLO_BOARD: \"Tasks\"\nTRELLO_BACKLOG: \"Up Next\"\nTRELLO_INPROGRESS: \"In Progress\"\nmodule Jello\n  class Config\n    class \u003c\u003c self\n      private\n\n      def create_methods(items)\n        items.each do |item|\n          define_singleton_method item.downcase do\n            @@config[item]\n          end\n        end\n      end\n\n      def get_config\n        @@config ||= YAML.load(File.read \"config/development.yaml\")\n      end\n    end\n\n    create_methods get_config.keys\n  end\nend\n\n# Just verify that things that shouldn't be accessible, definitely aren't accessible\n\nJello::Config.get_config\n# NoMethodError: private method `get_config' called for Jello::Config:Class\n\nJello::Config.config\n# NoMethodError: undefined method `config' for Jello::Config:Class\n\nJello::Config.DEV_KEY\n# NoMethodError: undefined method `DEV_KEY' for Jello::Config:Class\n\nJello::Config.dev_key\n# \"12345a6b78d90e1f2gh345ijk6l78m90\" (not real dev key obviously)\n","tags":""},{"id":"6912a6ad05754dc0e9dc","title":"RSpec described_class","content":"# https://www.relishapp.com/rspec/rspec-core/docs/metadata/described-class\n\nRSpec.describe Fixnum do\n  it \"is available as described_class\" do\n    expect(described_class).to eq(Fixnum)\n  end\nend\n\nmodule Foo\n  module Bar\n    class Baz\n      def initialize(msg = \"hello\")\n        puts msg\n      end\n    end\n  end\nend\n\ndescribe Foo::Bar::Baz do\n  subject { described_class.new(\"hi\") }\n  \n  # The subject is implicitly a new instance of what's in the describe block.\n  # But it wont know what to pass to the constructor, \n  # so in this example we override the implicit subject\nend\n","tags":""},{"id":"40f9f61537b2f7d471a6","title":"Terminal go back up one line","content":"http://stackoverflow.com/questions/6939673/go-back-up-a-line-in-a-linux-console\n\n\u003e I know I can go back the line and overwrite its contents with \\r.  \nNow how can I go up into the previous line to change that?\n\nThe basic solution involves: `\\x1B[1F` (which effectively is an [ANSI Escape Code](http://en.wikipedia.org/wiki/ANSI_escape_code): `Esc [ 1 F`)\n\nBut in context of a Ruby CLI script: `print \"\\r\\x1B[1F\\x1B[1F\"`\n","tags":""},{"id":"e10f8e1370f977fd6573","title":"DynamoDB Update Document","content":"require \"aws-sdk\"\nrequire \"thread\" # for Mutex\n\nclass DynamoTest\n  attr_reader :table_name, :client\n  \n  def initialize\n    @mutex      = Mutex.new\n    @client     = AWS::DynamoDB::Client::V20120810.new\n    @table_name = \"foo\"\n    \n    put_stuff\n  end\n  \n  def put_stuff(ident, value) # value == \"my_content\"\n    current_sequence = sequence_for(ident) # ident == \"my_primary_key\"\n    \n    @mutex.synchronize do\n      client.put_item({\n        :table_name =\u003e table_name,\n        :item =\u003e {\n          'key' =\u003e {\n            'S' =\u003e ident\n          },\n          'value' =\u003e {\n            'N' =\u003e value.to_s\n          }\n        },\n        # The conditions of our \"put\" operation:\n        # If the \"key\" isn't NULL (i.e. it exists) then our condition has failed\n        # This means we only want to put the item if it doesn't already exist\n        # Also, The \"value\" we're putting needs to be a numeric value greater than the current sequence value.\n        :expected =\u003e {\n          'key' =\u003e {\n            :comparison_operator =\u003e 'NULL'\n          },\n          'value' =\u003e {\n            :comparison_operator =\u003e 'GE',\n            :attribute_value_list =\u003e [\n              { 'N' =\u003e current_sequence.to_s }\n            ]\n          }\n        },\n        :conditional_operator =\u003e 'OR'\n      })\n    end\n  end\n  \n  def sequence_for(ident)\n    data = client.get_item(\n      item_payload(ident)\n    )\n\n    data.length \u003e 0 ? data[:item][\"value\"][:n].to_i : 0\n  end\n  \n  def item_payload(ident)\n    {\n      :table_name =\u003e table_name,\n      :key =\u003e {\n        'key' =\u003e {\n          'S' =\u003e ident.to_s\n        }\n      }\n    }\n  end\nend\n","tags":""},{"id":"9f9f2215e001b15ac492","title":"DynamoDB (using Spurious)","content":"# http://boot2docker.io/\n# https://github.com/stevenjack/spurious\n\nboot2docker init\nboot2docker up\nspurious-server start\nspurious init\nspurious start\nAWS_REGION: \"eu-west-1\"\nAWS_ACCESS_KEY_ID: \"development_access\"\nAWS_SECRET_ACCESS_KEY: \"development_secret\"\n\nDYNAMO_DB: \"development_db\"\n# https://github.com/BBC-News/alephant-harness can automate the below set-up when using Spurious\n# API Documentation http://docs.aws.amazon.com/amazondynamodb/latest/APIReference/API_Operations.html\n# Ruby SDK API Documentation http://docs.aws.amazon.com/AWSRubySDK/latest/frames.html#!AWS/DynamoDB/Client/V20120810.html\n\nrequire \"aws-sdk\"\nrequire \"dotenv\"\nrequire \"spurious/ruby/awssdk/helper\"\n\nSpurious::Ruby::Awssdk::Helper.configure\n# =\u003e \u003cAWS::Core::Configuration\u003e\n\nDotenv.load(\n  File.join(\n    File.dirname(__FILE__), \"config\", \"development\", \"env.yaml\"\n  )\n)\n# =\u003e {\"AWS_REGION\"=\u003e\"eu-west-1\", \"AWS_ACCESS_KEY_ID\"=\u003e\"development_access\", \"AWS_SECRET_ACCESS_KEY\"=\u003e\"development_secret\", \"DYNAMO_DB\"=\u003e\"development_db\"}\n\ndyn = AWS::DynamoDB::Client.new :api_version =\u003e \"2012-08-10\"\n# dyn = AWS::DynamoDB::Client::V20120810.new\n# =\u003e #\u003cAWS::DynamoDB::Client::V20120810\u003e\n\ndyn.create_table({\n  # This section requires us to define our primary key \n  # Which will be called \"item_id\" and it must be a numerical value\n  :attribute_definitions =\u003e [\n    { :attribute_name =\u003e \"item_id\", :attribute_type =\u003e \"N\" }\n  ],\n  :table_name =\u003e \"my_books\",\n  # The primary key will be a simple Hash key (not a Hash/Range which requires both key types to be provided)\n  # The attributes defined above must be included in the :key_schema Array\n  :key_schema =\u003e [\n    { :attribute_name =\u003e \"item_id\", :key_type =\u003e \"HASH\" }\n  ],\n  :provisioned_throughput =\u003e {\n    :read_capacity_units  =\u003e 10,\n    :write_capacity_units =\u003e 10\n  }\n})\n# =\u003e {:table_description=\u003e{:attribute_definitions=\u003e[{:attribute_name=\u003e\"item_id\", :attribute_type=\u003e\"N\"}], :table_name=\u003e\"my_books\", :key_schema=\u003e[{:attribute_name=\u003e\"item_id\", :key_type=\u003e\"HASH\"}], :table_status=\u003e\"ACTIVE\", :creation_date_time=\u003e2014-11-24 16:59:47 +0000, :provisioned_throughput=\u003e{:number_of_decreases_today=\u003e0, :read_capacity_units=\u003e10, :write_capacity_units=\u003e10}, :table_size_bytes=\u003e0, :item_count=\u003e0}}\n\ndyn.list_tables\n# =\u003e {:table_names=\u003e[\"my_books\"]}\n\ndyn.scan :table_name =\u003e \"my_books\"\n# =\u003e {:member=\u003e[], :count=\u003e0, :scanned_count=\u003e0}\n\ndyn.put_item(\n  :table_name =\u003e \"my_books\",\n  :item =\u003e {\n    \"item_id\" =\u003e { \"N\" =\u003e \"1\" }, # oddly this needs to be a String and not a strict Integer?\n    \"item_title\" =\u003e { \"S\" =\u003e \"My Book Title\"},\n    \"item_released\" =\u003e { \"B\" =\u003e \"false\" }\n  }\n)\n# Note: if you use an \"item_id\" that already exists, then the item will be updated.\n#       Unless you use the \"expected\" conditional feature\n\ndyn.put_item(\n  :table_name =\u003e \"my_books\",\n  :item =\u003e {\n    \"item_id\" =\u003e { \"N\" =\u003e \"1\" }, # oddly this needs to be a String and not a strict Integer?\n    \"item_title\" =\u003e { \"S\" =\u003e \"My Book Title\"},\n    \"item_released\" =\u003e { \"B\" =\u003e \"false\" }\n  },\n  # The :expected key specifies the conditions of our \"put\" operation.\n  # If \"item_id\" isn't NULL (i.e. it exists) then our condition has failed.\n  # This means we only write the value when the key \"item_id\" hasn't been set.\n  :expected =\u003e {\n    \"item_id\" =\u003e { :comparison_operator =\u003e \"NULL\" }\n  }\n)\n# AWS::DynamoDB::Errors::ConditionalCheckFailedException: The conditional check failed\n\ndyn.scan :table_name =\u003e \"my_books\"\n# =\u003e {:member=\u003e[{\"item_id\"=\u003e{:n=\u003e\"1\"}, \"item_title\"=\u003e{:s=\u003e\"My Book Title\"}, \"item_released\"=\u003e{:b=\u003e\"false\"}}], :count=\u003e1, :scanned_count=\u003e1}\n\ndyn.query :table_name =\u003e \"my_books\", :consistent_read =\u003e true, :key_conditions =\u003e {\n  \"item_id\" =\u003e {\n    :comparison_operator =\u003e \"EQ\",\n    :attribute_value_list =\u003e [{ \"n\" =\u003e \"1\" }]\n  },\n  \"item_title\" =\u003e {\n    :comparison_operator =\u003e \"EQ\",\n    :attribute_value_list =\u003e [{ \"s\" =\u003e \"My Book Title\" }]\n  }\n}\n# =\u003e {:member=\u003e[{\"item_id\"=\u003e{:n=\u003e\"1\"}, \"item_title\"=\u003e{:s=\u003e\"My Book Title\"}, \"item_released\"=\u003e{:b=\u003e\"false\"}}], :count=\u003e1, :scanned_count=\u003e1}\n\ndyn.query :table_name =\u003e \"my_books\", \n  :consistent_read =\u003e true, \n  :select =\u003e \"SPECIFIC_ATTRIBUTES\",\n  :attributes_to_get =\u003e [\"item_title\"],\n  :key_conditions =\u003e {\n  \"item_id\" =\u003e {\n    :comparison_operator =\u003e \"EQ\",\n    :attribute_value_list =\u003e [{ \"n\" =\u003e \"1\" }]\n  },\n  \"item_title\" =\u003e {\n    :comparison_operator =\u003e \"EQ\",\n    :attribute_value_list =\u003e [{ \"s\" =\u003e \"My Book Title\" }]\n  }\n}\n# =\u003e {:member=\u003e[{\"item_title\"=\u003e{:s=\u003e\"My Book Title\"}}], :count=\u003e1, :scanned_count=\u003e1}\n\ndyn.delete_item(\n  :table_name =\u003e \"my_books\",\n  :key =\u003e {\n    \"item_id\" =\u003e { \"n\" =\u003e \"1\" }\n  }\n)\n# =\u003e {:member=\u003e[], :count=\u003e0, :scanned_count=\u003e0}\n","tags":""},{"id":"ad1a9536d19b142f11d3","title":"Rack Middleware","content":"```ruby\nuse Rack::Lint # gives more descriptive error messages when responses aren't valid\n\nclass LogIt\n  def initialize(app)\n    @app = app\n  end\n  def call(env)\n    status, headers, body  = @app.call(env)\n    body.map { |chunk| p \"LogIt: #{chunk}\" }\n    [status, headers, body]\n  end\nend\n\nclass Upper\n  def initialize(app)\n    @app = app\n  end\n  def call(env)\n    # Execute our main application (store off its return value)\n    status, headers, body  = @app.call(env)\n\n    # Transform the returned value(s)\n    # Remember the body is an Array\n    upcased_body = body.map { |chunk| chunk.upcase }\n\n    # Return the newly filtered response\n    [status, headers, upcased_body]\n  end\nend\n\nuse LogIt # Does nothing with uppercase'd response, just logs it to stdout\nuse Upper # Modifies response to be uppercase\n\nrun -\u003e env {[200, {\"Content-Type\" =\u003e \"text/html\"}, [\"\u003ch1\u003eHello World\u003c/h1\u003e\"]]}\n```\n\nConsider the following config.ru file...\n\n```ruby\nclass A\n  def self.call(env)\n    [200, {\"Content-Type\" =\u003e \"text/html\"}, [\"\u003ch1\u003eHello World\u003c/h1\u003e\"]]\n  end\nend\nuse D # pass C into this middleware third  (D runs C and manipulates the response from C)\nuse C # pass B into this middleware second (C runs B and manipulates the response from B)\nuse B # pass A into this middleware first  (B runs A and manipulates the response from A)\nrun A\n```\n\n...this is effectively the same as...\n\n```ruby\nclass A\n  def self.call(env)\n    [200, {\"Content-Type\" =\u003e \"text/html\"}, [\"\u003ch1\u003eHello World\u003c/h1\u003e\"]]\n  end\nend\n\napp = Rack::Builder.new do\n  use D # pass C into this middleware third  (D runs C and manipulates the response from C)\n  use C # pass B into this middleware second (C runs B and manipulates the response from B)\n  use B # pass A into this middleware first  (B runs A and manipulates the response from A)\n  run A\nend\n```\n\n...this is because the built-in `rackup` command is a standalone Rack::Builder runner\n","tags":""},{"id":"c3d0c9dd88629d2835f4","title":"Ruby Array subset methods (intersection, difference, union)","content":"trello = [\"a\", \"b\", \"c\"]\njira   = [\"d\", \"c\", \"e\"]\n\n# - is the difference\n# \u0026 is the intersection\n# | is the union\n\ntrello - jira # [\"a\", \"b\"]                -\u003e a and b exist in trello but not jira\ntrello \u0026 jira # [\"c\"]                     -\u003e c exists in both trello and jira\ntrello | jira # [\"a\", \"b\", \"c\", \"d\", \"e\"] -\u003e both arrays have been joined\n","tags":""},{"id":"4537e399bf987b4635f1","title":"Executing the Clojure STM within JRuby (code modified from \"Programming Concurrency on the JVM\")","content":"$CLASSPATH \u003c\u003c \"clojure-1.6.0/clojure-1.6.0.jar\" # Downloaded from http://clojure.org/downloads\n\nrequire \"java\"\njava_import \"clojure.lang.Ref\"\njava_import \"clojure.lang.LockingTransaction\"\n\nclass Account\n  attr_reader :name\n\n  def initialize(name, initial_balance)\n    @name    = name\n    @balance = Ref.new initial_balance\n  end\n\n  def balance\n    @balance.deref\n  end\n\n  def deposit(amount)\n    LockingTransaction.run_in_transaction do\n      if amount \u003e 0\n        @balance.set @balance.deref + amount\n        p \"Deposited $#{amount} into account #{@name}\"\n      else\n        raise \"The amount must be greater than zero\"\n      end\n    end\n  end\n\n  def withdraw(amount)\n    LockingTransaction.run_in_transaction do\n      if amount \u003e 0 \u0026\u0026 @balance.deref \u003e= amount\n        @balance.set @balance.deref - amount\n      else\n        raise \"Can't withdraw $#{amount}; balance is $#{@balance.deref}\"\n      end\n    end\n  end\nend\n\ndef transfer(from, to, amount)\n  LockingTransaction.run_in_transaction do\n    to.deposit amount\n    from.withdraw amount\n  end\nend\n\ndef transfer_and_print(from, to, amount)\n  begin\n    transfer from, to, amount\n  rescue StandardError =\u003e e\n    p \"Transfer failed: #{e}\"\n  end\n\n  p \"Balance of 'from' account (#{from.name}) is $#{from.balance}\"\n  p \"Balance of 'to' account (#{to.name}) is $#{to.balance}\"\nend\n\naccount1 = Account.new 1, 2000\naccount2 = Account.new 2, 100\n\np \"account1 balance is $#{account1.balance}\"\np \"account2 balance is $#{account2.balance}\"\np \"---\"\n\ntransfer_and_print account1, account2, 500\np \"---\"\ntransfer_and_print account1, account2, 5000\n\"account1 balance is $2000\"\n\"account2 balance is $100\"\n\"---\"\n\"Deposited $500 into account 2\"\n\"Balance of 'from' account (1) is $1500\"\n\"Balance of 'to' account (2) is $600\"\n\"---\"\n\"Deposited $5000 into account 2\"\n\"Transfer failed: Can't withdraw $5000; balance is $1500\"\n\"Balance of 'from' account (1) is $1500\"\n\"Balance of 'to' account (2) is $600\"\n","tags":""},{"id":"6ba8b3effc03aa47ab93","title":"Clojure deftype, defrecord, defprotocol","content":"; Interface\n(defprotocol MyInterface \n  (foo [this]) ; `this` is required to let the interface refer to the class\n  (bar [this] [this x] [this x y] [this x y z])) ; multi-arity method signature defined\n\n; `deftype` dynamically generates compiled bytecode for the specified identifier (e.g. MyClass)\n(deftype MyClass [a b c]\n  MyInterface ; implement the specified protocol (i.e. interface)\n    \n    ; each function's scope is defined by \n    ; the object provided as the first argument\n    ; i.e. something that is of the `MyClass` type\n    (foo [this] a)\n    (bar [this] b)\n    (bar [this x] (+ c x))\n    (bar [this x y] (+ c x y))\n    (bar [this x y z] (+ c x y z)))\n\n(def obj (MyClass. 1 2 3))\n\n(prn (foo obj))       ; 1\n(prn (bar obj))       ; 2\n(prn (bar obj 1))     ; 4 (3 + )\n(prn (bar obj 1 2))   ; 6 (3 + 1 + 2)\n(prn (bar obj 1 2 3)) ; 9 (3 + 1 + 2 + 3)\n- `defprotocol`: defines an interface\n- `deftype`: create a bare-bones object which implements a protocol\n- `defrecord`: creates an immutable persistent map which implements a protocol\n\nTypically you'll use `defrecord` (or even a basic `map`);  \nunless you need some specific Java inter-op,  \nwhere by you'll want to use `deftype` instead.\n\n\u003e Note: `defprotocol` allows you to add new abstractions in a clean way\nRather than (like OOP) having polymorphism on the class itself,\npolymorphic functions are created in namespaces.\nMeaning different namespaces can implement different functionality\n; Interface\n; Note: it doesn't make much sense to apply an interface to a defrecord\n;       considering a defrecord is just a map\n(defprotocol Bazzer\n  \"This is an interface that states a `baz` method should be implemented\"\n  (baz [this] [a b])) ; you can define multi arity interface, but seemingly can't implement it on a defrecord?\n                      ; instead use `extend-protocol` for those situations\n                      ; see following example\n\n(extend-protocol Bazzer\n  Object ; the return type determines if symbols referenced (e.g. a and b) can be resolved\n         ; if not defined (or the wrong type) then errors can occur\n  (baz\n    ([a] 1)\n    ([a b] 2)))\n\n(prn (baz \"any value and I'll return 1\"))        ; 1\n(prn (baz \"any two values\" \"and I'll return 2\")) ; 2\n\n; Constructor\n(defrecord Foo [a b]\n  Bazzer ; enforces the interface (but the error thrown without this defined, doesn't actually clarify)\n  (baz [this] \"Foo Bazzer\")) ; associate a function with our `defrecord` map\n\n; Constructor\n(defrecord Bar [a b] Bazzer\n  (baz [this] (str \"Bar Bazzer -\u003e \" a \" / \" b)))\n\n; Either pass in each argument to the constructor separately\n(def foo (-\u003eFoo :bar :baz)) ; user.Foo{:a :bar, :b :baz}\n\n; Or pass a single argument with keys that align with the class' required parameters\n(def bar (map-\u003eBar {:a 1 :b 2})) ; user.Foo{:a 1, :b 2}\n\n(prn bar)      ; user.Foo{:a 1, :b 2}\n(prn (:a foo)) ; :bar\n(prn (:b foo)) ; :baz\n\n; mutate and return\n(prn (assoc foo :b :qux)) ; user.Foo{:a :bar, :b :qux}\n\n; but the source is immutable\n(prn foo) ; user.Foo{:a :bar, :b :baz}\n\n(:b (assoc foo :b :qux)) ; :qux\n\n(def basil (Foo. \"hai\" \"hi\"))\n(def baril (Bar. \"boo\" \"yah\"))\n(prn (baz basil)) ; \"Foo Bazzer\"\"\n(prn (baz baril)) ; \"Bar Bazzer -\u003e boo / yah\"\"\n; (prn (baz baril :a :b))\n","tags":""},{"id":"e9a7c7fdc7244f7854ad","title":"Trello API","content":"# gem install ruby-trello\n# https://github.com/jeremytregunna/ruby-trello\nrequire \"trello\"\n\n# https://trello.com/app-key\n# https://trello.com/1/authorize?key=PUBLIC_KEY\u0026id=123456\u0026name=ResponsiveFrameworks\u0026expiration=never\u0026response_type=token\u0026scope=read,write\n# id=123456 is the Board ID\n\nTrello.configure do |config|\n  config.developer_public_key = \"xxx\"\n  config.member_token = \"xxx\"\nend\n\np 'BOARDS'\nTrello::Board.all.each do |b|\n  p \"#{b.name} - #{b.id}\"\nend\n\nputs\np \"LISTS ON TASKS BOARD\"\nTrello::Board.find('547c636a43dfe0b3776d12ac').lists.each do |l|\n  p \"#{l.name} - #{l.id}\"\nend\n\nputs\np \"CARDS IN PROGRESS\"\nTrello::List.find('547c63a4936189b46b2d03bb').cards.each do |c|\n  p c.name\nend\n\nputs\np \"CARDS UP NEXT\"\nTrello::List.find('547c639c42d17a096cde6fb3').cards.each do |c|\n  p \"Name: #{c.name}\"\n  p \"Description: #{c.desc}\"\n  c.member_ids.each { |m| p \"Member: #{m}\" }\n  c.card_labels.each { |l| p \"Label: #{l['name']}\" }\nend\n\nputs\np \"MEMBER\"\np Trello::Member.find(\"547c682e0557130608796e02\").full_name\n\n","tags":""},{"id":"bb8760d11a03c88da151","title":"Ruby: private class level methods","content":"class Foo\n  class \u003c\u003c self\n    def bar\n      p \"im public\"\n    end\n    \n    private\n    def baz\n      p \"im private\"\n    end\n  end\nend\n\nFoo.bar # =\u003e im public\nFoo.baz # =\u003e NoMethodError: private method `baz' called for Foo:Class\nclass Foo\n  def self.bar\n    p \"im public\"\n  end\n  \n  private\n  def self.baz\n    p \"im private\"\n  end\nend\n\nFoo.bar # =\u003e im public\nFoo.baz # =\u003e im private\n","tags":""},{"id":"53f6dc643fd0227c6606","title":"Golang Essentials","content":"- [Install](#install)\n- [Shell exports](#shell-exports)\n- [Directory explanations](#directory-explanations)\n- [Automatic Imports](#automatic-imports)\n- [Private repo access](#private-repo-access)\n- [Guard (automatic go run)](#guard-automatic-go-run)\n- [Godo](#godo)\n- [Spurious](#spurious)\n- [AWS SDK with Go (inc. some old possibly broken examples)](#aws-sdk-with-go)\n- [Build and Compilation](#build-and-compilation)\n- [Dependency information with `go list`](#dependency-information-with-go-list)\n- [Dependencies with godeps](#dependencies-with-godeps)\n- [Dependencies with gb](#dependencies-with-gb)\n- [Dependencies with glide](#dependencies-with-glide)\n- [Documentation](#documentation)\n- [Testing](#testing)\n- [Logging](#logging)\n- [Bits, Bytes, Runes](#bits-bytes-runes)\n- [Code Examples](#code-examples)\n  - [Init](#init)\n  - [New vs Make](#new-vs-make)\n  - [Custom Types](#custom-types)\n  - [Function Types](#function-types)\n  - [Structure: Var vs Type](#struct-var-vs-type)\n  - [Reference vs Value](#reference-vs-value)\n  - [See all methods of a \u0026lt;Type\u0026gt;](#see-all-methods-of-a-type) \n  - [Set time](#set-time)\n  - [Convert Struct into JSON](#convert-struct-into-json)\n  - [Extract only JSON you need](#extract-only-json-you-need)\n  - [Nested JSON handling](#nested-json-handling)\n  - [Pretty Printing JSON String](#pretty-printing-json-string)\n  - [Nested YAML handling](#nested-yaml-handling)\n  - [Unknown YAML Structure](#unknown-yaml-structure)\n  - [Sorting Structs](#sorting-structs)\n  - [Read User Input](#read-users-input)\n  - [Web Server](#web-server)\n  - [Middleware](#middleware)\n  - [Sessions](#sessions)\n  - [HTTP Requests with Timeouts](#http-requests-with-timeouts)\n  - [S3 GetObject](#s3-getobject)\n  - [Compile time variables](#compile-time-variables)\n  - [TLS HTTP Request](#tls-http-request)\n  - [Custom HTTP Request](#custom-http-request)\n  - [HTTP GET Web Page](#http-get-web-page)\n  - [Pointers](#pointers)\n  - [Array Pointer](#array-pointer)\n  - [Type Assertion](#type-assertion)\n  - [Line Count](#line-count)\n  - [Measuring time](#measuring-time)\n  - [Reading a file in chunks](#reading-a-file-in-chunks)\n  - [Time and Channels](#time-and-channels)\n  - [Quit a Channel](#quit-a-channel)\n  - [Starting and Stopping things with Channels](#starting-and-stopping-things-with-channels)\n  - [Channel Pipelines](#channel-pipelines)\n  - [Templating](#templating)\n  - [Error handling with context](#error-handling-with-context)\n  - [Socket programming with TCP server](#socket-programming-with-tcp-server)\n  - [Comparing maps](#comparing-maps)\n  - [Embedded Structs](#embedded-structs)\n  - [Zip File Contents](#zip-file-contents)\n  - [OAuth](https://gist.github.com/Integralist/0e277a517fee68153f93)\n  - [RPC](#rpc)\n  - [Enumerator IOTA](#enumerator-iota)\n  - [FizzBuzz](#fizzbuzz)\n  - [Execute Shell Command](#execute-shell-command)\n  - [New Instance Idiom](#new-instance-idiom)\n  - [Mutating Values](#mutating-values)\n  - [Draining Connections](#draining-connections)\n\n## Install\n\n```bash\nbrew install go\n```\n\n## Shell exports\n\n- `export GOPATH=~/path/to/your/golang/projects`\n- `export PATH=~/path/to/your/golang/projects/bin:$PATH`\n\n\u003e Note: the latter item allows you to locally build and execute Go based binaries\n\n## Directory explanations\n\nBy default you store all your Golang projects within a single directory. This will be fixed in a future Go release as the developers recognise it can be problematic sometimes.\n\nSo within the `$GOPATH` directory workspace there should be three directories:\n\n- `src`: holds source code\n- `pkg`: holds compiled bits\n- `bin`: holds executables\n\n\u003e Note: I very rarely even look at the `pkg` or `bin` directories\n\nBut for now, make sure you have any new Go project you work on placed inside the following directory structure...\n\n```\n└── src\n    ├── github.com\n    │   ├── \u003cyour_username\u003e\n    │   │   └── \u003cyour_repo_name\u003e\n```\n\n## Automatic Imports\n\n`go get golang.org/x/tools/cmd/goimports`\n\nNow either run `goimports` from the shell OR use vim-go plugin with `:GoImports` for the buffer you're working with\n\n## Private repo access\n\n`go get` uses https; so instead force it to use ssh:\n\n```bash\ngit config --global url.\"git@github.com:\".insteadOf \"https://github.com/\"\n```\n\n\u003e Note you can restrict it to a specific organisation as well:  \n\u003e `git config --global url.\"git@github.com:foo/\".insteadOf \"https://github.com/foo/\"`\n\nSo when you want a private repository: `git@github.com:foo/private.git`\n\nYou can run:\n\n```bash\ngo get github.com/foo/private\n```\n\n## Guard (automatic `go run`)\n\n**UPDATE**: this isn't good practice. Instead use [Godo](https://github.com/go-godo/godo) (see below for example)\n\n~~Follow this guide (https://gist.github.com/Integralist/b675a263897680e02fbd) for using Guard to get real-time notifications for when changes occur in your Go programming files, and automatically trigger `go run`.~~\n\n## Godo\n\nExample taken from my own project [go-requester](https://github.com/Integralist/Go-Requester)\n\n```go\npackage main\n\nimport (\n\t\"fmt\"\n\t\"os\"\n\n\tdo \"gopkg.in/godo.v2\"\n)\n\nfunc tasks(p *do.Project) {\n\tif pwd, err := os.Getwd(); err == nil {\n\t\tdo.Env = fmt.Sprintf(\"GOPATH=%s/vendor::$GOPATH\", pwd)\n\t}\n\n\tp.Task(\"server\", nil, func(c *do.Context) {\n\t\tc.Start(\"main.go ./config/page.yaml\", do.M{\"$in\": \"./\"})\n\t}).Src(\"**/*.go\")\n}\n\nfunc main() {\n\tdo.Godo(tasks)\n}\n```\n\n## Spurious\n\nIf you need [Spurious](https://github.com/spurious-io/spurious) set-up then update the `aws.config` accordingly:\n\n```Go\n_dyn := dynamodb.New(\u0026aws.Config{\n    Region:     \"eu-west-1\",\n    DisableSSL: true,\n    Endpoint:   \"dynamodb.spurious.localhost:32770\", // change port number to appropriate value\n})\n\n_s3 := s3.New(\u0026aws.Config{\n    Region:           \"eu-west-1\",\n    Endpoint:         \"s3.spurious.localhost:32769\", // change port number to appropriate value\n    DisableSSL:       true,\n    S3ForcePathStyle: true,\n})\n```\n\n\u003e Note: remember to set the AWS environment variables in your shell so Dynamo can pick them up (all other spurious services are fine without them)\n\n```bash\nexport AWS_ACCESS_KEY_ID=development_access; export AWS_SECRET_ACCESS_KEY=development_secret; go run application.go\n```\n\nTo populate your Spurious set-up you can use Ruby like so: https://gist.github.com/Integralist/58b25f860773d8d2dd3f\n\n## AWS SDK with Go\n\n### STS Assume Role\n\nUsage:\n\n```\n\u003cbinary_name\u003e \u003caws_account_id\u003e \u003caws_role\u003e\n```\n\nCode:\n\n```go\npackage main\n\nimport (\n\t\"fmt\"\n\t\"log\"\n\t\"os\"\n\n\t\"github.com/aws/aws-sdk-go/aws\"\n\t\"github.com/aws/aws-sdk-go/aws/session\"\n\t\"github.com/aws/aws-sdk-go/service/sts\"\n)\n\nvar (\n\taccessKey = os.Getenv(\"AWS_ACCESS_KEY_ID\")\n\tsecretKey = os.Getenv(\"AWS_SECRET_ACCESS_KEY\")\n\tregion    = os.Getenv(\"AWS_REGION\")\n)\n\nfunc main() {\n\targs := os.Args[1:]\n\taccount := args[0]\n\trole := args[1]\n\n\tsess := session.New(\n\t\t\u0026aws.Config{\n\t\t\tRegion: aws.String(region),\n\t\t},\n\t)\n\n\tsvc := sts.New(sess)\n\n\toutput, err := svc.AssumeRole(\u0026sts.AssumeRoleInput{\n\t\tRoleArn:         aws.String(fmt.Sprintf(\"arn:aws:iam::%s:role/%s\", account, role)),\n\t\tRoleSessionName: aws.String(\"temp\"),\n\t})\n\tif err != nil {\n\t\tlog.Fatalf(\"Unable to assume role: %v\", err.Error())\n\t}\n\n\tos.Setenv(\"AWS_ACCESS_KEY_ID\", aws.StringValue(output.Credentials.AccessKeyId))\n\tos.Setenv(\"AWS_SECRET_ACCESS_KEY\", aws.StringValue(output.Credentials.SecretAccessKey))\n\tos.Setenv(\"AWS_SESSION_TOKEN\", aws.StringValue(output.Credentials.SessionToken))\n\n\tfmt.Printf(\"AWS_ACCESS_KEY_ID: %s\\n\", os.Getenv(\"AWS_ACCESS_KEY_ID\"))\n\tfmt.Printf(\"AWS_SECRET_ACCESS_KEY: %s\\n\", os.Getenv(\"AWS_SECRET_ACCESS_KEY\"))\n\tfmt.Printf(\"AWS_SESSION_TOKEN: %s\\n\", os.Getenv(\"AWS_SESSION_TOKEN\"))\n}\n```\n\n### Create SQS queue\n\nUsage:\n\n```\ngo run local/create.go -queue \"producer\"\n```\n\nCode:\n\n```go\npackage main\n\nimport (\n\t\"encoding/json\"\n\t\"flag\"\n\t\"fmt\"\n\t\"log\"\n\t\"os\"\n\t\"os/exec\"\n\n\t\"github.com/aws/aws-sdk-go/aws\"\n\t\"github.com/aws/aws-sdk-go/aws/awserr\"\n\t\"github.com/aws/aws-sdk-go/aws/session\"\n\t\"github.com/aws/aws-sdk-go/service/sqs\"\n)\n\ntype network []struct {\n\tHost     string\n\tHostPort string\n}\n\ntype spurious struct {\n\tSqs    network `json:\"spurious-sqs\"`\n\tS3     network `json:\"spurious-s3\"`\n\tDynamo network `json:\"spurious-dynamo\"`\n}\n\nvar (\n\tsvc          *sqs.SQS\n\tqueueName    string\n\tregionName   string\n\tendpointName string\n\tcmdOut       []byte\n\terr          error\n\tspur         spurious\n)\n\nvar region = flag.String(\"region\", \"eu-west-1\", \"Name of region to create the resource within\")\nvar queue = flag.String(\"queue\", \"producer\", \"Name of queue to be created\")\nvar endpoint = flag.String(\"endpoint\", \"\", \"Spurious endpoint\")\n\nfunc init() {\n\tflag.Parse()\n\n\tqueueName = *queue\n\tregionName = *region\n\tendpointName = *endpoint\n\n\tif endpointName == \"\" {\n\t\tcmdName := \"spurious\"\n\t\tcmdArgs := []string{\"ports\", \"--json\"}\n\t\tif cmdOut, err = exec.Command(cmdName, cmdArgs...).Output(); err != nil {\n\t\t\tfmt.Fprintln(os.Stderr, \"There was an error running 'spurious ports --json' command: \", err)\n\t\t\tos.Exit(1)\n\t\t}\n\n\t\tjson.Unmarshal(cmdOut, \u0026spur)\n\t\tendpointName = spur.Sqs[0].Host + \":\" + spur.Sqs[0].HostPort\n\t}\n\n\tsvc = sqs.New(\n\t\tsession.New(),\n\t\t\u0026aws.Config{\n\t\t\tRegion:     aws.String(regionName),\n\t\t\tDisableSSL: aws.Bool(true),\n\t\t\tEndpoint:   aws.String(endpointName),\n\t\t})\n}\n\nfunc main() {\n\tparams := \u0026sqs.CreateQueueInput{\n\t\tQueueName: aws.String(queueName),\n\t}\n\n\tresp, err := svc.CreateQueue(params)\n\n\tif err != nil {\n\t\tif awsErr, ok := err.(awserr.Error); ok {\n\t\t\t// Get error details\n\t\t\tlog.Println(\"Error:\", awsErr.Code(), awsErr.Message())\n\n\t\t\t// Prints out full error message, including original error if there was one.\n\t\t\tlog.Println(\"Error:\", awsErr.Error())\n\n\t\t\t// Get original error\n\t\t\tif origErr := awsErr.OrigErr(); origErr != nil {\n\t\t\t\t// operate on original error.\n\t\t\t}\n\t\t} else {\n\t\t\tfmt.Println(err.Error())\n\t\t}\n\t}\n\n\tfmt.Println(resp)\n}\n```\n\n### Possibly Broken Examples\n\n**UPDATE** the following code examples are now old and probably don't work any more\n\nIn the below code we use `go` blocks for parallelising \"copy\" requests to S3, which is thread-safe because we're not mutating any values. But we can't quite get away with that inside the `getS3Locations` function as we need to mutate a slice (and that's not thread-safe) so we then use an interesting pattern where by we use channels to synchronise the data after the parallelisation.\n\n\u003e Note: DynamoDB specifically is confusing.  \n\u003e Also, for printing Structs use: `fmt.Printf(\"%+v\", myStruct)` (ensures the keys are included)\n\n```go\npackage main\n\nimport (\n\t\"fmt\"\n\t\"github.com/awslabs/aws-sdk-go/aws\"\n\t\"github.com/awslabs/aws-sdk-go/service/dynamodb\"\n\t\"github.com/awslabs/aws-sdk-go/service/s3\"\n\t\"os\"\n\t\"strings\"\n\t\"sync\"\n)\n\nfunc sequencerTableRecords(sequencer string) *dynamodb.ScanOutput {\n\tsvc := dynamodb.New(\u0026aws.Config{\n\t\tRegion: \"eu-west-1\",\n\t\tDisableSSL: true,\n\t\tEndpoint:   \"dynamodb.spurious.localhost:32791\",\n\t})\n\n\tparams := \u0026dynamodb.ScanInput{\n\t\tTableName: aws.String(sequencer),\n\t}\n\n\tresp, err := svc.Scan(params)\n\n\tif awserr := aws.Error(err); awserr != nil {\n\t\t// A service error occurred.\n\t\tfmt.Println(\"Error:\", awserr.Code, awserr.Message)\n\t} else if err != nil {\n\t\t// A non-service error occurred.\n\t\tpanic(err)\n\t}\n\n\treturn resp\n}\n\nfunc getComponentVersions(records *dynamodb.ScanOutput) map[string]string {\n\tcomponents := make(map[string]string)\n\n\tfor _, items := range records.Items {\n\t\titem := *items\n\t\tcomponents[*item[\"key\"].S] = *item[\"value\"].N\n\t}\n\n\treturn components\n}\n\nfunc getS3Locations(components map[string]string, s3Path string, lookup string) map[string]string {\n\tsvc := dynamodb.New(\u0026aws.Config{\n\t\tRegion: \"eu-west-1\",\n\t\tDisableSSL: true,\n\t\tEndpoint:   \"dynamodb.spurious.localhost:32791\",\n\t})\n\n\tcollectedLocations := []*dynamodb.QueryOutput{}\n\n\tc := make(chan *dynamodb.QueryOutput, len(components))\n\tdone := make(chan int, len(components))\n\tlocations := make(map[string]string)\n\n\t// Parallelise retrieval of data from DynamoDB\n\tfor componentKey, componentVersion := range components {\n\t\tgo func(componentKey, componentVersion string) {\n\t\t\tparams := \u0026dynamodb.QueryInput{\n\t\t\t\tTableName:      aws.String(lookup),\n\t\t\t\tConsistentRead: aws.Boolean(true),\n\t\t\t\tSelect:         aws.String(\"SPECIFIC_ATTRIBUTES\"),\n\t\t\t\tAttributesToGet: []*string{\n\t\t\t\t\taws.String(\"component_key\"),\n\t\t\t\t\taws.String(\"location\"),\n\t\t\t\t},\n\t\t\t\tKeyConditions: \u0026map[string]*dynamodb.Condition{\n\t\t\t\t\t\"component_key\": \u0026dynamodb.Condition{\n\t\t\t\t\t\tComparisonOperator: aws.String(\"EQ\"),\n\t\t\t\t\t\tAttributeValueList: []*dynamodb.AttributeValue{\n\t\t\t\t\t\t\t\u0026dynamodb.AttributeValue{\n\t\t\t\t\t\t\t\tS: aws.String(componentKey),\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t\t\"batch_version\": \u0026dynamodb.Condition{\n\t\t\t\t\t\tComparisonOperator: aws.String(\"EQ\"),\n\t\t\t\t\t\tAttributeValueList: []*dynamodb.AttributeValue{\n\t\t\t\t\t\t\t\u0026dynamodb.AttributeValue{\n\t\t\t\t\t\t\t\tN: aws.String(componentVersion),\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t}\n\n\t\t\tresp, err := svc.Query(params)\n\n\t\t\tif awserr := aws.Error(err); awserr != nil {\n\t\t\t\t// A service error occurred.\n\t\t\t\tfmt.Println(\"Error:\", awserr.Code, awserr.Message)\n\t\t\t} else if err != nil {\n\t\t\t\t// A non-service error occurred.\n\t\t\t\tpanic(err)\n\t\t\t} else {\n\t\t\t\tc \u003c- resp\n\t\t\t\tdone \u003c- 1\n\t\t\t}\n\t\t}(componentKey, componentVersion)\n\t}\n\n\t// Wait until all data is successfully collated from DynamoDB\n\tfor i := len(components); i \u003e 0; {\n\t\tselect {\n\t\tcase item := \u003c-c:\n\t\t\tcollectedLocations = append(collectedLocations, item)\n\t\tcase \u003c-done:\n\t\t\ti--\n\t\t}\n\t}\n\n\tfor _, items := range collectedLocations {\n\t\titem := *items\n\t\tref := *item.Items[0]\n\t\tcomponentLocation := s3Path + *ref[\"location\"].S\n\t\tcomponentKey := extractComponentFromKey(*ref[\"component_key\"].S)\n\n\t\tlocations[componentKey] = componentLocation\n\t}\n\n\treturn locations\n}\n\nfunc extractComponentFromKey(componentKey string) string {\n\treturn strings.Split(componentKey, \"/\")[0]\n}\n\nfunc copyS3DataToNewLocation(event string, s3Bucket string, s3Locations map[string]string) {\n\tsvc := s3.New(\u0026aws.Config{\n\t\tRegion: \"eu-west-1\",\n\t\tEndpoint:         \"s3.spurious.localhost:32790\",\n\t\tDisableSSL:       true,\n\t\tS3ForcePathStyle: true,\n\t})\n\n\tvar wg sync.WaitGroup\n\n\tfor component, location := range s3Locations {\n\t\tdestination := \"archive/\" + event + \"/\" + component\n\n\t\twg.Add(1)\n\n\t\tgo func(location, destination string) {\n\t\t\tdefer wg.Done()\n\n\t\t\t// fmt.Println(s3Bucket)\n\t\t\t// fmt.Println(s3Bucket + \"/\" + location)\n\t\t\t// fmt.Println(destination)\n\n\t\t\tparams := \u0026s3.CopyObjectInput{\n\t\t\t\tBucket:     aws.String(s3Bucket),\n\t\t\t\tCopySource: aws.String(s3Bucket + \"/\" + location),\n\t\t\t\tKey:        aws.String(destination),\n\t\t\t}\n\n\t\t\t_, err := svc.CopyObject(params)\n\n\t\t\tif awserr := aws.Error(err); awserr != nil {\n\t\t\t\t// A service error occurred.\n\t\t\t\tfmt.Println(\"Error:\", awserr.Code, awserr.Message)\n\t\t\t} else if err != nil {\n\t\t\t\t// A non-service error occurred.\n\t\t\t\tpanic(err)\n\t\t\t}\n\t\t}(location, destination)\n\t}\n\n\twg.Wait()\n}\n\nfunc main() {\n\tevent := os.Args[1]\n\ts3Bucket := os.Args[2]\n\ts3Path := os.Args[3]\n\tsequencer := os.Args[4]\n\tlookup := os.Args[5]\n\n\tsequence_records := sequencerTableRecords(sequencer)\n\tcomponents := getComponentVersions(sequence_records)\n\ts3Locations := getS3Locations(components, s3Path, lookup)\n\n\tcopyS3DataToNewLocation(event, s3Bucket, s3Locations)\n}\n```\n\nIn above example there are API issues with DynamoDB - after about 6 requests a second the API errors. If you flatten out the requests so they are no longer running highly concurrently, then the speed of it slows down so badly that AWS Lambda (which is running the binary) times out. Meaning we need to do things differently... i.e. we need to request all S3 objects instead and partition/filter the unique values from that instead:\n\n\u003e Note: S3 objects are listed alphabetically\n\n```go\nfunc getS3ObjectSubset(bucket, source, marker string) *s3.ListObjectsOutput {\n\tsvc := s3.New(\u0026aws.Config{\n\t\tRegion: \"eu-west-1\",\n\t})\n\n\tparams := \u0026s3.ListObjectsInput{\n\t\tBucket: aws.String(bucket),\n\t\tPrefix: aws.String(source),\n\t\tMarker: aws.String(marker),\n\t}\n\n\tresp, err := svc.ListObjects(params)\n\n\tif awserr := aws.Error(err); awserr != nil {\n\t\tfmt.Println(\"Error:\", awserr.Code, awserr.Message)\n\t} else if err != nil {\n\t\tpanic(err)\n\t}\n\n\treturn resp\n}\n\nfunc main() {\n\tbucket := os.Args[1] // some-bucket\n\tsource := os.Args[2] // some/object/path/to/prefix\n\tmarker := \"\"         // means to start off from the very first object (overwritten)\n\n\tvar resp *s3.ListObjectsOutput\n\n\tprocessing := true\n\n\tcollectedObjects := []*s3.ListObjectsOutput{}\n\n\tfor processing {\n\t\tresp = getS3ObjectSubset(bucket, source, marker)\n\t\tcollectedObjects = append(collectedObjects, resp)\n\t\tmarker = *resp.Contents[len(resp.Contents)-1].Key\n\n\t\tif *resp.IsTruncated == false {\n\t\t\tprocessing = false\n\t\t}\n\t}\n\n\tfor _, s3SubSet := range collectedObjects {\n\t\tfor _, items := range s3SubSet.Contents {\n\t\t\tfmt.Println(*items.Key)\n\t\t}\n\t}\n}\n```\n\n## Build and Compilation\n\n### 1.5+\n\n```bash\nGOOS=darwin GOARCH=386 go build foo.go\n```\n\nHere is a quick reference:\n\n```\n$GOOS     $GOARCH\ndarwin    386      -- 32 bit MacOSX\ndarwin    amd64    -- 64 bit MacOSX\nfreebsd   386\nfreebsd   amd64\nlinux     386      -- 32 bit Linux\nlinux     amd64    -- 64 bit Linux\nlinux     arm      -- RISC Linux\nnetbsd    386\nnetbsd    amd64\nopenbsd   386\nopenbsd   amd64\nplan9     386\nwindows   386      -- 32 bit Windows\nwindows   amd64    -- 64 bit Windows\n```\n\n### Gox\n\nOne time only commands:\n\n- `go get github.com/mitchellh/gox`\n- `gox -build-toolchain` (only necessary for 1.4.x and lower)\n\nCompilation (example is for AWS Lambda usage where only a single binary is needed):\n\n- `gox -osarch=\"linux/amd64\" -osarch=\"darwin/amd64\" -osarch=\"windows/amd64\" -output=\"foobar.{{.OS}}\"`\n\nThis will generate three files:\n\n1. `foobar.darwin`\n2. `foobar.linux`\n3. `foobar.windows.exe`\n\n### Other information\n\nUse the `-a` flag when running `go build`.\n\nIn short, if you dont' use `go build -a -v .` then Go won't know if any packages are missing (you can find the gory details [here](https://medium.com/@felixge/why-you-should-use-go-build-a-or-gb-c469157d5c1b#.jf5orcwrj))\n\n## Dependency information with `go list`\n\nTo see a list of dependencies for a given Go package you can utilise the `go list` command:\n\n```bash\ngo list -json strconv \n```\n\nWhich returns:\n\n```json\n{\n\t\"Dir\": \"/usr/local/Cellar/go/1.5.2/libexec/src/strconv\",\n\t\"ImportPath\": \"strconv\",\n\t\"Name\": \"strconv\",\n\t\"Doc\": \"Package strconv implements conversions to and from string representations of basic data types.\",\n\t\"Target\": \"/usr/local/Cellar/go/1.5.2/libexec/pkg/darwin_amd64/strconv.a\",\n\t\"Goroot\": true,\n\t\"Standard\": true,\n\t\"Root\": \"/usr/local/Cellar/go/1.5.2/libexec\",\n\t\"GoFiles\": [\n\t\t\"atob.go\",\n\t\t\"atof.go\",\n\t\t\"atoi.go\",\n\t\t\"decimal.go\",\n\t\t\"doc.go\",\n\t\t\"extfloat.go\",\n\t\t\"ftoa.go\",\n\t\t\"isprint.go\",\n\t\t\"itoa.go\",\n\t\t\"quote.go\"\n\t],\n\t\"IgnoredGoFiles\": [\n\t\t\"makeisprint.go\"\n\t],\n\t\"Imports\": [\n\t\t\"errors\",\n\t\t\"math\",\n\t\t\"unicode/utf8\"\n\t],\n\t\"Deps\": [\n\t\t\"errors\",\n\t\t\"math\",\n\t\t\"runtime\",\n\t\t\"unicode/utf8\",\n\t\t\"unsafe\"\n\t],\n\t\"TestGoFiles\": [\n\t\t\"internal_test.go\"\n\t],\n\t\"XTestGoFiles\": [\n\t\t\"atob_test.go\",\n\t\t\"atof_test.go\",\n\t\t\"atoi_test.go\",\n\t\t\"decimal_test.go\",\n\t\t\"example_test.go\",\n\t\t\"fp_test.go\",\n\t\t\"ftoa_test.go\",\n\t\t\"itoa_test.go\",\n\t\t\"quote_test.go\",\n\t\t\"strconv_test.go\"\n\t],\n\t\"XTestImports\": [\n\t\t\"bufio\",\n\t\t\"bytes\",\n\t\t\"errors\",\n\t\t\"fmt\",\n\t\t\"log\",\n\t\t\"math\",\n\t\t\"math/rand\",\n\t\t\"os\",\n\t\t\"reflect\",\n\t\t\"runtime\",\n\t\t\"strconv\",\n\t\t\"strings\",\n\t\t\"testing\",\n\t\t\"time\",\n\t\t\"unicode\"\n\t]\n}\n```\n\nIf you don't specify the `-json` flag then the default behaviour is to filter out the `ImportPath` field from the above JSON output. For example:\n\n```bash\ngo list strconv\n```\n\nWill return just the import path `strconv`.\n\n\u003e Documentation: `go help list | less`\n\nYou can also utilise Go's templating functionality on the returned JSON object by adding the `-f` flag:\n\n```bash\ngo list -f '{{join .Deps \" \"}}' strconv\n```\n\nWhich filters out the `Deps` field, joins up all items it contains using whitespace and subsequently returns:\n\n```\nerrors math runtime unicode/utf8 unsafe\n```\n\nYou can do more complex things such as:\n\n```bash\ngo list -f '{{.ImportPath}} -\u003e {{join .Imports \" \"}}' compress/...\n```\n\nWhich will return something like:\n\n```\ncompress/bzip2 -\u003e bufio io sort\ncompress/flate -\u003e bufio fmt io math sort strconv\ncompress/gzip -\u003e bufio compress/flate errors fmt hash hash/crc32 io time\ncompress/lzw -\u003e bufio errors fmt io\ncompress/zlib -\u003e bufio compress/flate errors fmt hash hash/adler32 io\n```\n\n## Dependencies with godeps\n\nWhen running `go get \u003cdependency\u003e` locally, Go will stick the dependency in the folder defined by your `$GOPATH` variable. So when you build your code into a binary using `go build \u003cscript\u003e` it'll bake the dependencies into the binary (i.e. the binary is statically linked).\n\nBut if someone pulls down your repo and tries to do a build they'll need to have a network connection to pull down the dependencies, as their `$GOPATH` might not have those dependencies yet (unless the user manually executes `go get` for each dependency required). Also the dependencies they subsequently pull down could be a more recent (and untested version) of each dependency.\n\nSo to make this situation better we can use http://godoc.org/github.com/tools/godep (https://github.com/tools/godep) which sticks all your dependencies within a `Godeps` folder inside your project directory. You can then use `godep save -r ./...` to automatically update all your references to point to that local folder. \n\n\u003e Note: you might need to remove the `Godeps` folder and run `go get` if you get strange conflicts. The `./...` means to target all `.go` files\n\nThis way users who clone your repo don't need an internet connection to pull the dependencies, as they already have them. But also they'll have the correct versions of the dependencies. This acts like a `Gemfile.lock` as you would typically find in the Ruby world.\n\n```bash\nfind . -name '*.go' -exec \\\nsed -i '' 's/github\\.com\\/bbc\\/mozart\\-config\\-api\\/src\\/Godeps\\/_workspace\\/src\\///' {} \\;\n```\n\n## Dependencies with gb\n\n```bash\ngo get -u github.com/constabulary/gb/...\ngb vendor fetch \u003cpkg\u003e\ngb build all\n```\n\nYou'll need the following structure:\n\n```bash\n├── src\n│   ├── foo\n│   │   └── main.go\n└── vendor\n    ├── manifest\n    └── src\n```\n\nThe `vendor` directory is auto-generated by the `gb vendor fetch \u003cpkg\u003e` command.\n\n## Dependencies with glide\n\nThis is now my preferred dependency management tool, as it works just like existing tools in other languages (e.g. Ruby's Bundler or Node's NPM) and so consistency is a plus.\n\nIt also provides the ability (like gb) to not commit dependencies but have specific versions vendored when running a simple command.\n\n```bash\ngo get github.com/Masterminds/glide\nexport GO15VENDOREXPERIMENT=1       # or use 1.6\nglide init                          # generates glide.yaml\nglide install                       # installs from lock file (creates it if not found)\nglide update                        # updates dependencies and updates lock file\nglide list                          # shows vendored deps\ngo test $(glide novendor)           # test only your package (not vendored packages)\n```\n\n\u003e Note: to add a new dependency `glide get \u003cpkg_name\u003e`\n\n## Documentation\n\n`Godoc` is the original implementation for viewing documentation. Previous to `Godoc` there was `go doc`, but that was removed and then added *back* with totally different functionality.\n\nThe syntax structure for `go doc` is as follows:\n\n```\ngo doc \u003cpkg\u003e\ngo doc \u003csym\u003e[.\u003cmethod\u003e]\ngo doc [\u003cpkg\u003e].\u003csym\u003e[.\u003cmethod\u003e]\n```\n\nHere are some examples of using `go doc`:\n\n```\ngo doc json # same as go doc encoding/json\ngo doc json.Number\ngo doc json.Number.Float64\n```\n\nHere is the same but using `godoc` (where the syntax structure is `godoc \u003cpkg\u003e \u003csymbol\u003e`):\n\n```\ngodoc encoding/json # unlike \"go doc json\", \"godoc json\" doesn't work as it's not a fully qualified path\ngodoc encoding/json Number\ngodoc -src builtin make | less\n```\n\n\u003e Unlike with `go doc`, `godoc` doesn't allow filtering by `\u003cmethod\u003e`  \n\u003e It only goes as far as `\u003cpkg\u003e \u003csymbol\u003e`  \n\u003e \n\u003e You can use `\u003cpkg\u003e \u003csymbol\u003e \u003cmethod\u003e`  \n\u003e and the method will be included in the results  \n\u003e but you'll need to search for the method manually  \n\u003e `godoc -src net/http Request ParseForm | less`  \n\u003e here is a similar result using `go doc`    \n\u003e `go doc http.Request.ParseForm | less`\n\nThe purpose of `go doc` was to provide a simplistic cli documentation viewer, where as `Godoc` has many more features available.\n\nThe `go doc` command also works not only with Go's own library's but your own custom packages as well.\n\nThere are some differences in what is returned though between `godoc` and `go doc` (mainly the latter is more succinct/compact so you can find the functions/types you're after and then you can expand into those once you've found them; `godoc` is harder to sift through on the command line)...\n\n### `godoc encoding/json Encoder`\n\n```\ntype Encoder struct {\n    // contains filtered or unexported fields\n}\n    An Encoder writes JSON objects to an output stream.\n\nfunc NewEncoder(w io.Writer) *Encoder\n    NewEncoder returns a new encoder that writes to w.\n\nfunc (enc *Encoder) Encode(v interface{}) error\n    Encode writes the JSON encoding of v to the stream, followed by a\n    newline character.\n\n    See the documentation for Marshal for details about the conversion of Go\n    values to JSON.\n```\n\n### `go doc encoding/json Encoder`\n\n```\ntype Encoder struct {\n        // Has unexported fields.\n}\n\n    An Encoder writes JSON objects to an output stream.\n\nfunc NewEncoder(w io.Writer) *Encoder\nfunc (enc *Encoder) Encode(v interface{}) error\n```\n\n\u003e Notice the functions don't have their documentation notes printed with `go doc`\n\nOne other thing `godoc` has over `go doc` is the ability to view the source code using the `-src` flag:\n\n```\ngodoc -src builtin make | less\n```\n\nThe `godoc` tool also has a full browser documentation suite available and allows you to generate HTML documentation for your project...\n\n### Full Browser Documentation\n\nStart a local documentation server and allow indexing (which takes a few minutes; you have to just keep trying the search until it's done)\n\n```\ngodoc -http ':6060' -index\n```\n\nYou can then open a new terminal pane and search via cli if you prefer (rather than open up a browser to http://localhost:6060/)\n\n```\ngodoc -q tls | less\n```\n\nYou can also have the playground available if you need it in the browser, but it does require an internet connection to compile:\n\n```\ngodoc -http ':6060' -play\n```\n\n## Testing\n\n\u003e Note: see also [examples here](https://gist.github.com/Integralist/cf76668bc46d75058ab5f566d96ce74a)\n\nTest files are placed in the same directory as the file/package being tested. The convention is to use the same file name but suffix it with `_test`. So `foo.go` would have another file next to it called `foo_test.go`.\n\nRun the tests: `go test -v ./...`\n\nYou can also run a specific test like so: `go test -v command/config_test.go command/config.go`\n\n\u003e Note: remember that your test file should have the same package name as your code being tested. This means the test file will have access to all the public functions and variables of that package (and so subsequently it'll have access to the code being tested)\n\nHere's our program:\n\n```go\npackage main\n\nimport \"fmt\"\n\ntype FooIO interface {\n\tRead() string\n}\n\ntype Foo struct{}\n\nfunc (f *Foo) Read() string {\n\treturn \"We READ something from disk\"\n}\n\nfunc Stuff(f FooIO) string {\n\treturn f.Read()\n}\n\nfunc main() {\n\tfoo := \u0026Foo{}\n\tcontents := Stuff(foo)\n\tfmt.Println(contents)\n}\n```\n\nHere's our test:\n\n```go\npackage main\n\nimport (\n\t\"testing\"\n\n\t\"github.com/stretchr/testify/assert\"\n)\n\ntype FakeFoo struct{}\n\nfunc (s *FakeFoo) Read() string {\n\treturn \"We 'pretend' to READ something from disk\"\n}\n\nfunc TestSomething(t *testing.T) {\n\tassert := assert.New(t)\n\n\tfoo := \u0026FakeFoo{}\n\tcontents := Stuff(foo)\n\n\tassert.Equal(contents, \"We 'pretend' to READ something from disk\")\n}\n```\n\n### Test Examples\n\nFaking HTTP and WebServers can be a bit tricky:\n\n```go\npackage requester\n\nimport (\n\t\"bytes\"\n\t\"encoding/json\"\n\t\"fmt\"\n\t\"io/ioutil\"\n\t\"net/http\"\n\t\"net/http/httptest\"\n\t\"os\"\n\t\"strconv\"\n\t\"testing\"\n\t\"time\"\n\n\t\"github.com/bbc/mozart-requester/src/aggregator\"\n\t\"github.com/julienschmidt/httprouter\"\n)\n\nfunc TestSuccessResponse(t *testing.T) {\n\tupstream := httptest.NewServer(http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tw.Header().Set(\"Content-Type\", \"application/json\")\n\t\tfmt.Fprintln(w, `{\"head\":[ \"foo\" ],\"bodyInline\":\"bar\",\"bodyLast\":[ \"baz\" ]}`)\n\t}))\n\tdefer upstream.Close()\n\n\trouter := httptest.NewServer(http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tProcess(w, r, httprouter.Params{})\n\t}))\n\tdefer router.Close()\n\n\tvar config = []byte(fmt.Sprintf(`{\n\t\t\"components\":[\n\t\t\t{\"id\":\"foo\",\"endpoint\":\"%s\",\"must_succeed\":true},\n\t\t\t{\"id\":\"bar\",\"endpoint\":\"%s\",\"must_succeed\":true}\n\t\t]\n\t}`, upstream.URL, upstream.URL))\n\n\treq, err := http.NewRequest(\"POST\", router.URL, bytes.NewBuffer(config))\n\n\tclient := \u0026http.Client{}\n\tresp, err := client.Do(req)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\n\tdefer resp.Body.Close()\n\tbody, _ := ioutil.ReadAll(resp.Body)\n\n\tvar result aggregator.Result\n\tjson.Unmarshal(body, \u0026result)\n\n\texpectedStatus := \"success\"\n\tif result.Summary != expectedStatus {\n\t\tt.Errorf(\"The response:\\n '%s'\\ndidn't match the expectation:\\n '%s'\", result.Summary, expectedStatus)\n\t}\n\n\texpectedLength := 2\n\tif len(result.Components) != expectedLength {\n\t\tt.Errorf(\"The response:\\n '%d'\\ndidn't match the expectation:\\n '%d'\", len(result.Components), expectedLength)\n\t}\n}\n\nfunc TestFailureResponse(t *testing.T) {\n\thealthyUpstream := httptest.NewServer(http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tw.Header().Set(\"Content-Type\", \"application/json\")\n\t\tfmt.Fprintln(w, `{\"head\":[ \"foo\" ],\"bodyInline\":\"bar\",\"bodyLast\":[ \"baz\" ]}`)\n\t}))\n\tdefer healthyUpstream.Close()\n\n\tfailingUpstream := httptest.NewServer(http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tw.Header().Set(\"Content-Type\", \"text/plain; charset=utf-8\")\n\t\tw.WriteHeader(http.StatusNotFound)\n\t\tfmt.Fprintln(w, \"404 page not found\")\n\t}))\n\tdefer failingUpstream.Close()\n\n\trouter := httptest.NewServer(http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tProcess(w, r, httprouter.Params{})\n\t}))\n\tdefer router.Close()\n\n\tvar config = []byte(fmt.Sprintf(`{\n\t\t\"components\":[\n\t\t\t{\"id\":\"foo\",\"endpoint\":\"%s\",\"must_succeed\":true},\n\t\t\t{\"id\":\"bar\",\"endpoint\":\"%s\",\"must_succeed\":true}\n\t\t]\n\t}`, healthyUpstream.URL, failingUpstream.URL))\n\n\treq, err := http.NewRequest(\"POST\", router.URL, bytes.NewBuffer(config))\n\n\tclient := \u0026http.Client{}\n\tresp, err := client.Do(req)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\n\tdefer resp.Body.Close()\n\tbody, _ := ioutil.ReadAll(resp.Body)\n\n\tvar result aggregator.Result\n\tjson.Unmarshal(body, \u0026result)\n\n\texpectedSummary := \"failure\"\n\tif result.Summary != expectedSummary {\n\t\tt.Errorf(\"The response:\\n '%s'\\ndidn't match the expectation:\\n '%s'\", result.Summary, expectedSummary)\n\t}\n\n\texpectedLength := 2\n\tif len(result.Components) != expectedLength {\n\t\tt.Errorf(\"The response length:\\n '%d'\\ndidn't match the expectation:\\n '%d'\", len(result.Components), expectedLength)\n\t}\n\n\texpectedStatus := []int{}\n\tfor _, value := range result.Components {\n\t\tif value.Status == 404 {\n\t\t\texpectedStatus = append(expectedStatus, value.Status)\n\t\t}\n\t}\n\tif len(expectedStatus) \u003c 1 || len(expectedStatus) \u003e 1 {\n\t\tt.Errorf(\"The response length:\\n '%d'\\ndidn't match the expectation:\\n '%d'\", len(expectedStatus), 1)\n\t}\n}\n\nfunc TestSlowResponse(t *testing.T) {\n\thealthyUpstream := httptest.NewServer(http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tw.Header().Set(\"Content-Type\", \"application/json\")\n\t\tfmt.Fprintln(w, `{\"head\":[ \"foo\" ],\"bodyInline\":\"bar\",\"bodyLast\":[ \"baz\" ]}`)\n\t}))\n\tdefer healthyUpstream.Close()\n\n\tslowUpstream := httptest.NewServer(http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\ttimeout, err := strconv.Atoi(os.Getenv(\"COMPONENT_TIMEOUT\"))\n\t\tif err != nil {\n\t\t\tt.Errorf(\"COMPONENT_TIMEOUT: %s\", err.Error())\n\t\t}\n\t\ttime.Sleep(time.Duration(timeout) * time.Millisecond)\n\t\tw.Header().Set(\"Content-Type\", \"application/json\")\n\t\tfmt.Fprintln(w, `{\"head\":[ \"foo\" ],\"bodyInline\":\"bar\",\"bodyLast\":[ \"baz\" ]}`)\n\t}))\n\tdefer slowUpstream.Close()\n\n\trouter := httptest.NewServer(http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tProcess(w, r, httprouter.Params{})\n\t}))\n\tdefer router.Close()\n\n\tvar config = []byte(fmt.Sprintf(`{\n\t\t\"components\":[\n\t\t\t{\"id\":\"foo\",\"endpoint\":\"%s\",\"must_succeed\":true},\n\t\t\t{\"id\":\"bar\",\"endpoint\":\"%s\",\"must_succeed\":true}\n\t\t]\n\t}`, healthyUpstream.URL, slowUpstream.URL))\n\n\treq, err := http.NewRequest(\"POST\", router.URL, bytes.NewBuffer(config))\n\n\tclient := \u0026http.Client{}\n\tresp, err := client.Do(req)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\n\tdefer resp.Body.Close()\n\tbody, _ := ioutil.ReadAll(resp.Body)\n\n\tvar result aggregator.Result\n\tjson.Unmarshal(body, \u0026result)\n\n\texpectedStatus := 408\n\tfor _, value := range result.Components {\n\t\tif value.ID == \"bar\" \u0026\u0026 value.Status != expectedStatus {\n\t\t\tt.Errorf(\"The response:\\n '%d'\\ndidn't match the expectation:\\n '%d'\", value.Status, expectedStatus)\n\t\t}\n\t}\n\n\texpectedSummary := \"failure\"\n\tif result.Summary != expectedSummary {\n\t\tt.Errorf(\"The response:\\n '%s'\\ndidn't match the expectation:\\n '%s'\", result.Summary, expectedSummary)\n\t}\n}\n```\n\nI typically run my tests using Make, but it ultimately looks like this: \n\n```\npushd src \u0026\u0026 APP_ENV=test COMPONENT_TIMEOUT=100 go test -v $(glide novendor) \u0026\u0026 popd\n```\n\nHere's another example of a test needing to fake things:\n\n```go\npackage retriever\n\nimport (\n\t\"bytes\"\n\t\"io/ioutil\"\n\t\"net/http\"\n\t\"strings\"\n\t\"testing\"\n\n\t\"github.com/PuerkitoBio/goquery\"\n)\n\nconst href = \"http://bar.com/\"\nconst url = \"http://foo.com/\"\n\nvar body string\n\nfunc fakeNewDocument(url string) (*goquery.Document, error) {\n\tbody = strings.Replace(body, \"{}\", href, 1)\n\n\tresp := \u0026http.Response{\n\t\tStatus:        \"200 OK\",\n\t\tStatusCode:    200,\n\t\tProto:         \"HTTP/1.0\",\n\t\tProtoMajor:    1,\n\t\tProtoMinor:    0,\n\t\tBody:          ioutil.NopCloser(bytes.NewBufferString(body)),\n\t\tContentLength: int64(len(body)),\n\t\tRequest:       \u0026http.Request{},\n\t}\n\n\treturn goquery.NewDocumentFromResponse(resp)\n}\n\nfunc TestRetrieveReturnValue(t *testing.T) {\n\t// {} interpolated with constant's value\n\tbody = `\n\t\t\u003chtml\u003e\n\t\t\t\u003cbody\u003e\n\t\t\t\t\u003cdiv class=\"productInfo\"\u003e\n\t\t\t\t\t\u003ca href=\"{}\"\u003eBar\u003c/a\u003e\n\t\t\t\t\u003c/div\u003e\n\t\t\t\u003c/body\u003e\n\t\t\u003chtml\u003e\n\t`\n\tcoll, _ := Retrieve(url, fakeNewDocument)\n\n\tif response := coll[0]; response != href {\n\t\tt.Errorf(\"The response:\\n '%s'\\ndidn't match the expectation:\\n '%s'\", response, href)\n\t}\n}\n\nfunc TestRetrieveMissingAttributeReturnsEmptySlice(t *testing.T) {\n\t// href attribute is missing from anchor element\n\tbody = `\n\t\t\u003chtml\u003e\n\t\t\t\u003cbody\u003e\n\t\t\t\t\u003cdiv class=\"productInfo\"\u003e\n\t\t\t\t\t\u003ca\u003eBar\u003c/a\u003e\n\t\t\t\t\u003c/div\u003e\n\t\t\t\u003c/body\u003e\n\t\t\u003chtml\u003e\n\t`\n\tcoll, _ := Retrieve(url, fakeNewDocument)\n\n\tif response := coll; len(response) \u003e 0 {\n\t\tt.Errorf(\"The response:\\n '%s'\\ndidn't match the expectation:\\n '%s'\", response, \"[http://bar.com/]\")\n\t}\n}\n```\n\nAnd...\n\n```go\npackage scraper\n\nimport \"testing\"\n\nfunc TestScrapeResults(t *testing.T) {\n\tgetItem = func(url string) {\n\t\tdefer wg.Done()\n\n\t\tch \u003c- Item{\n\t\t\t\"FooTitle\",\n\t\t\t\"FooSize\",\n\t\t\t\"10.00\",\n\t\t\t\"FooDescription\",\n\t\t}\n\t}\n\n\turls := []string{\n\t\t\"http://foo.com/\",\n\t\t\"http://bar.com/\",\n\t\t\"http://baz.com/\",\n\t}\n\n\tresult := Scrape(urls)\n\tfirst := result.Items[0]\n\n\tvar suite = []struct {\n\t\tresponse string\n\t\texpected string\n\t}{\n\t\t{first.Title, \"FooTitle\"},\n\t\t{first.Size, \"FooSize\"},\n\t\t{first.UnitPrice, \"10.00\"},\n\t\t{first.Description, \"FooDescription\"},\n\t\t{result.Total, \"30.00\"},\n\t}\n\n\tfor _, v := range suite {\n\t\tif v.response != v.expected {\n\t\t\terr(v.response, v.expected, t)\n\t\t}\n\t}\n}\n\nfunc err(response, expected string, t *testing.T) {\n\tt.Errorf(\"The response:\\n '%s'\\ndidn't match the expectation:\\n '%s'\", response, expected)\n}\n```\n\n## Logging\n\nUsing the standard Logger:\n\n```go\ninfo := log.New(os.Stdout, \"STUFF: \", log.Ldate|log.Ltime|log.Lshortfile)\ninfo.Println(\"Starting up!!!\")\n\nf, e := os.Create(\"test.log\")\nif e != nil {\n\tlog.Fatal(\"Failed to create log file\")\n}\n\nlogfile := log.New(f, \"STUFF: \", log.Ldate|log.Ltime|log.Lshortfile)\nlogfile.Println(\"Starting up!!!\")\n```\n\nUsing Logrus:\n\n```go\npackage main\n\nimport (\n\t\"os\"\n\n\tlog \"github.com/Sirupsen/logrus\"\n)\n\nfunc main() {\n\t// Standard stdout ASCII logging\n\tlog.WithFields(log.Fields{\n\t\t\"animal\": \"walrus\",\n\t}).Info(\"A walrus appears\")\n\n\t// JSON style structured logging\n\tlog.SetFormatter(\u0026log.JSONFormatter{})\n\tf, e := os.Create(\"logs\")\n\tif e != nil {\n\t\tlog.Fatal(\"Failed to create log file\")\n\t}\n\tlog.SetOutput(f)\n\tlog.WithFields(log.Fields{\n\t\t\"animal\": \"walrus\",\n\t\t\"size\":   10,\n\t}).Info(\"A group of walrus emerges from the ocean\")\n\t/*\n\t\t\t{\n\t\t\t\t\"animal\": \"walrus\",\n\t\t\t\t\"level\": \"info\",\n\t\t\t\t\"msg\": \"A group of walrus emerges from the ocean\",\n\t\t    \"size\": 10,\n\t\t\t\t\"time\": \"2015-12-22T13:58:46Z\"\n\t\t\t}\n\t*/\n}\n```\n\n## Bits, Bytes, Runes\n\nhttps://pythonconquerstheuniverse.wordpress.com/2010/05/30/unicode-beginners-introduction-for-dummies-made-simple/\n\nA Unicode \"code point\" (e.g. `0021` which is equal to `!`) is known in Go as a \"Rune\".\n\n\u003e Note: a Rune is actually a synonym for Go's `int32` type\n\nA Unicode \"code point\" is made up of a single byte.\n\nComputers think in 8-bit bytes (i.e. a single byte is 8 bits).\n\nWith 8 bits you can make 256 different bit combinations. But Unicode has way more than 256 characters (it holds code points/characters for every language in the world, so yes a *lot* more than 256).\n\n- 1 bytes = 08 bits\n- 2 bytes = 16 bits\n- 3 bytes = 24 bits\n- 4 bytes = 32 bits\n\nWe could represent a Unicode \"code point\" with a single Rune (`int32`) but not all code points require a full 32 bits and so you'd be wasting lots of space. For example, ASCII only requires 8 bits (or 1 byte) per character.\n\nUTF-8 is a solution to this problem. It uses 8-bit encoding, but one of the bits will be a pointer to another location to continue the bit sequence so the program can identify the overall character being encoded. This allows all Unicode code points to be encoded in 1 to 4 bytes but without the need for all the storage required of a 32 bit set-up.\n\nSo as you can now see, UTF-8 is able to use multiple bytes (up to 4) to represent a single Unicode code point. \n\nFor example, `[E4 B8 96]` are three separate bytes that make up a single Chinese character.\n\nA string is made up of individual bytes, but not every character in the string is necessarily mapped to a single byte (also ASCII charters like `\\n` and `\\t` are considered a byte each)\n\n\u003e Note: a Rune can consist of multiple bytes (so it's not *exactly* identical to a Unicode \"code point\")\n\n```go\npackage main\n\nimport (\n\t\"fmt\"\n\t\"unicode/utf8\"\n)\n\nfunc main() {\n\thello := \"您好 world\"\n\n\tfmt.Printf(\"hex digits: % x\\n\", hello) // hex digits: e6 82 a8 e5 a5 bd 20 77 6f 72 6c 64\n\n\t// e6 82 a8 e5 a5 bd == 您好\n\t// 20                == \u003cwhite space character\u003e\n\t// 77 6f 72 6c 64    == world\n\n\tr := []rune(hello)\n\n\tfmt.Printf(\"UFT-8 encoding of each rune: %x\\n\", r) // UFT-8 encoding of each rune: [60a8 597d 20 77 6f 72 6c 64]\n\n\t// 60a8 597d      == 您好\n\t// 20             == \u003cwhite space character\u003e\n\t// 77 6f 72 6c 64 == world\n\n\tfmt.Println(len(hello)) // 12\n\n\t// Looks like 'hello' stores 8 characters, but the 2 chinese characters represent more than 2 bytes each\n\t// Instead we'd need to count the Runes...\n\n\tfmt.Println(utf8.RuneCountInString(hello)) // 8\n\t\n\t// The DecodeRuneInString method also returns the number of bytes each Rune occupies...\n\t\n\trune1, size := utf8.DecodeRuneInString(\"您\")\n\tfmt.Printf(\"Rune: %v\\nRune's Byte Size: %v\\n\", rune1, size) \n\t\n\t// Rune: 24744\n\t// Rune's Byte Size: 3\n\t\n\trune2, size := utf8.DecodeRuneInString(\"好\")\n\tfmt.Printf(\"Rune: %v\\nRune's Byte Size: %v\\n\", rune2, size) \n\t\n\t// Rune: 22909 (type: int32)\n\t// Rune's Byte Size: 3\n\t\n\t// Type conversion from a integer to a string yields not a stringified number but the UTF-8 representation of that Rune...\n\t\n\tfmt.Println(string(rune1))  // 您\n\tfmt.Println(string(rune2))  // 好\n\tfmt.Println(string(r))      // 您好 world\n\tfmt.Println(string(65))     // A\n\n\t// Use 0x prefix to denote a UTF-8 encoding...\n\t\n\tfmt.Println(string(0x60a8)) // 您\n\tfmt.Println(string(0x597d)) // 好\n}\n```\n\n## Code Examples\n\n### Init\n\nWhen you load a package in Go, only the public functions and variables are exposed for the caller to utilise. So if you need a package to execute some bootstrapping code at the point of it being _loaded_, then you'll need to stick it inside of an `init` function.\n\n\u003e Note: you can have multiple `init` functions inside a package \n\u003e e.g. one per file within the package namespace\n\nBut be careful with race conditions! \n\nI've hit an issue where we had:\n\n- `main.go`\n  - `foo.go` (loaded by `main.go`)\n    - `bar.go` (loaded by `foo.go`)\n\nEach one of these packages had its own `init` function and ultimately the `bar.go`'s `init` function was being run first, followed by the `foo.go`'s `init` function and finally followed by the `main.go`'s `init` function.\n\nThe reason this was an issue was because `main.go` was loading some environment variables needed by `bar.go` but those variables weren't available by the time the `bar.go` was running (as that happened _before_ `main.go`'s `init` function had executed.\n\nThe solution was to rename all the `init` functions to `Init` and explicitly call them to bootstrap the package when needed (i.e. they didn't automatically bootstrap themselves and find themselves in a race condition)\n\n### New vs Make\n\n- `func new(Type) *Type`: allocate memory for custom-user type\n- `func make(Type, size IntegerType) Type`: allocate memory for builtin types (Slice, Map, Chan)\n\n```go\npackage main\n\nimport \"fmt\"\n\nfunc main() {\n\tfoo := make(map[string]string)\n\tfmt.Println(foo) // map[]\n\tfoo[\"k1\"] = \"bar\"\n\tfmt.Println(foo) // map[k1:bar]\n\tfmt.Println(foo[\"k1\"]) // bar\n\t\n\ttype bar [5]int\n\tb := new(bar)\n\tfmt.Println(b) // \u0026[0 0 0 0 0]\n\tb[0] = 1\n\tfmt.Println(b) // \u0026[1 0 0 0 0]\n}\n```\n\n### Custom Types\n\n```go\npackage main\n\nimport (\n\t\"bytes\"\n\t\"fmt\"\n)\n\ntype path []byte // our custom Type\n\n// method attached to our custom Type\nfunc (p *path) TruncateAtFinalSlash() {\n\ti := bytes.LastIndex(*p, []byte(\"/\"))\n\n\tif i \u003e= 0 {\n\t\t*p = (*p)[0:i]\n\t}\n}\n\nfunc main() {\n\tpathName := path(\"/usr/bin/tso\") // Conversion from string to path.\n\n\tpathName.TruncateAtFinalSlash()\n\n\tfmt.Printf(\"%s\\n\", pathName)\n}\n```\n\nAlternative example:\n\n```go\npackage main\n\nimport \"fmt\"\n\ntype foo [5]int\n\nfunc main() {\n\tf := new(foo)\n\tfmt.Println(f) // \u0026[0 0 0 0 0]\n\tf[0] = 1\n\tfmt.Println(f) // \u0026[1 0 0 0 0]\n\tf.Bar()\n\tfmt.Println(f) // \u0026[1 2 0 0 0]\n\n\t// We can coerce custom types like we can with built-in types\n\tb := foo([5]int{9, 9, 9})\n\tfmt.Println(b) // [9 9 9 0 0]\n\t\n\t// Check the types\n\tfmt.Printf(\"%T\\n\", b)               // main.foo\n\tfmt.Printf(\"%T\\n\", [5]int{9, 9, 9}) // [5]int\n}\n\nfunc (f *foo) Bar() {\n\tf[1] = 2\n}\n```\n\n### Function Types\n\n```go\npackage main\n\nimport \"fmt\"\n\ntype Foo func(int, string)\n\nfunc (f Foo) Bar(s string) {\n\tfmt.Printf(\"s: %s\\n\", s)\n}\n\nfunc FooIt(x int, y string) {\n\tfmt.Printf(\"x: %d - y: %s\\n\", x, y)\n}\n\n// We HAVE to define the incoming type of \"fn\"\n// Which in this case is a Foo type\nfunc TestIt(fn Foo) {\n\tfn(99, \"problems\")\n}\n\n// We could do this without defining a func type\n// But as you can see, this is a bit ugly\n// Plus if we need this function passed around a lot\n// then it means a lot of duplicated effort \n// typing the signature over and over\nfunc TestItManually(fn func(int, string)) {\n\tfn(100, \"problems\")\n}\n\nfunc main() {\n\t// Here we're just demonstrating passing around the FooIt function\n\t// It demonstrates first-class function support in Go\n\t// But also that we can ensure the function passed around has the expected signature\n\tTestIt(FooIt)\n\tTestItManually(FooIt)\n\t\n\tx := Foo(FooIt) // Convert our function into a Foo type\n\tx(0, \"hai\")     // Now we can execute it as we would FooIt itself\n\t\n\tFooIt(1, \"bye\")\n\t\n\t// Notice the types are different\n\t// FooIt is just a function with a signature (no known type associated with it)\n\t// Where as \"x\" is of known type \"Foo\"\n\tfmt.Printf(\"%T\\n\", FooIt) // func(int, string)\n\tfmt.Printf(\"%T\\n\", x)     // main.Foo\n\t\n\t// But we'll see that the function \"x\" \n\t// which was converted into a Foo type\n\t// now has access to a Bar method\n\t// Although FooIt has a matching signature, it's not a Foo type\n\t// and so it doesn't have a Bar method available\n\tx.Bar(\"we have a Bar method\")\n\t\n\t// We can't even execute:\n\t// FooIt.Bar(\"we don't have a Bar method\")\n\t// Because the compiler will stop us\n}\n```\n\n### Struct: Var vs Type\n\nA variable of Struct type doesn't need to be instantiated like a type struct:\n\n```go\npackage main\n\nimport \"fmt\"\n\nvar data struct {\n\tA string\n\tB string\n}\n\ntype data2 struct {\n\tA string\n\tB string\n}\n\nfunc main() {\n\tdata.A = \"Hai\"\n\tdata.B = \"Bai\"\n\t\n\tfmt.Printf(\n\t\t\"%#v, %+v, %+v\", \n\t\tdata.A, \n\t\tdata.B, \n\t\tdata2{A: \"abc\", B: \"def\"}\n\t)\n\t// \"Hai\", Bai, {A:abc B:def}\n}\n```\n\n### Reference vs Value\n\nMap data structures are passed by reference, rather than a copied value\n\n```go\npackage main\n\nimport \"fmt\"\n\nfunc main() {\n\tm := make(map[string]int)\n\tfmt.Println(\"main before, m = \", m)\n\tfoo(m)\n\tfmt.Println(\"main after, m = \", m)\n}\n\nfunc foo(m map[string]int) {\n\tfmt.Println(\"foo before, m = \", m)\n\tm[\"hai\"] = 123\n\tfmt.Println(\"foo after, m = \", m)\n}\n```\n\nIn fact, anything with `make` is a reference, as well as any explicit interface\n\n### See all methods of a \u0026lt;Type\u0026gt;\n\n```go\nerrType := reflect.TypeOf(err)\nfor i := 0; i \u003c errType.NumMethod(); i++ {\n  method := errType.Method(i)\n  fmt.Println(method.Name)\n}\n```\n\n### Set time\n\n```go\nnow := time.Now()\nfmt.Println(now)\nexpiration := now.Add(time.Hour * 24 * 30)\nfmt.Println(\"Thirty days from now will be : \", expiration)\n```\n\n### Convert Struct into JSON\n\n```go\npackage main\n\nimport (\n\t\"encoding/json\"\n\t\"fmt\"\n\t\"os\"\n\t\"time\"\n)\n\nfunc main() {\n\ttype Message struct {\n\t\tSequence  int    `json:\"sequence\"`\n\t\tTitle     string `json:\"title\"`\n\t\tTimestamp time.Time   `json:\"timestamp\"`\n\t}\n\tmsg := Message{1, \"Foobar\", time.Now()}\n\tb, err := json.Marshal(msg)\n\tif err != nil {\n\t\tfmt.Println(\"error:\", err)\n\t}\n\tos.Stdout.Write(b)\n}\n```\n\n### Extract only JSON you need\n\nhttps://medium.com/the-hoard/using-golang-and-json-for-kafka-consumption-with-high-throughput-4cae28e08f90#.7rcmae71b\n\nEffectively the solution is:\n\n```go\n/*\nimagine our variable 'bytes' contains some JSON with lots of fields\nwe only want the fields 'type' and 'id' \nwe should get our provider of data to transform everything else inside a 'data' field\n\ne.g.\n\n{\n  “id”: “numero uno”,\n  “type”: “transaction”,\n  // data is the JSON msg from above\n  “data”: { \n    “id”: “numero uno”,\n    “type”: “transaction”,\n    // … a whole bunch of dynamic fields\n    “amount”: “1000”,\n    “currency”: “usd”,\n    // … etc.\n   }\n}\n*/\n\ntype Message struct {\n  ID string `json:”id”`\n  Type string `json:”type”`\n  Data json.RawMessage `json:”data”`\n}\n\nvar m Message\njson.Unmarshal(bytes, \u0026m)\nes.Index(index, m.Type, m.ID, \"\", \"\", nil, m.Data, false)\n```\n\nThis way we only decode the id and type, so we're being performant, and then we pass the original raw JSON onto our next service (e.g. `es` ElasticSearch) to do with what they please.\n\n### Nested JSON handling\n\n```go\npackage main\n\nimport (\n\t\"encoding/json\"\n\t\"fmt\"\n)\n\ntype Component struct {\n\tComponents []struct {\n\t\tId  string `json:\"id\"`\n\t\tUrl string `json:\"url\"`\n\t} `json:\"components\"`\n}\n\nfunc main() {\n\tvar c Component\n\n\tb := []byte(`{\"components\":[{\"id\":\"google\",\"url\":\"http://google.com/\"},{\"id\":\"integralist\",\"url\":\"http://integralist.co.uk/\"},{\"id\":\"sloooow\",\"url\":\"http://stevesouders.com/cuzillion/?c0=hj1hfff5_0_f\u0026c1=hc1hfff2_0_f\u0026t=1439190969678\"}]}`)\n\n\tjson.Unmarshal(b, \u0026c)\n\t\n\tfmt.Printf(\"%+v\", c.Components[0]) // {Id:google Url:http://google.com/}\n}\n```\n\n### Pretty Printing JSON String\n\n```go\npackage main\n\nimport (\n\t\"encoding/json\"\n\t\"fmt\"\n\t\"os\"\n)\n\nfunc main() {\n\ttype ColorGroup struct {\n\t\tID     int\n\t\tName   string\n\t\tColors []string\n\t}\n\tgroup := ColorGroup{\n\t\tID:     1,\n\t\tName:   \"Reds\",\n\t\tColors: []string{\"Crimson\", \"Red\", \"Ruby\", \"Maroon\"},\n\t}\n\tb, err := json.MarshalIndent(group, \"\", \"    \")\n\tif err != nil {\n\t\tfmt.Println(\"error:\", err)\n\t}\n\tos.Stdout.Write(b)\n}\n```\n\n### Nested YAML handling\n\n```go\npackage main\n\nimport (\n\t\"fmt\"\n\n\t\"gopkg.in/yaml.v2\"\n)\n\ntype ComponentYaml struct {\n\tId  string `yaml:\"id\"`\n\tUrl string `yaml:\"url\"`\n}\n\ntype ComponentsYamlList struct {\n\tComponents []ComponentYaml `yaml:\"components\"`\n}\n\nfunc main() {\n\tvar y ComponentsYamlList\n\n\tyaml.Unmarshal([]byte(\"components:\\n  - id: google\\n    url: http://google.com\\n  - id: integralist\\n    url: http://integralist.co.uk\"), \u0026y)\n\n\tfmt.Println(y)\n}\n```\n\n### Unknown YAML Structure\n\n```go\npackage main\n\nimport (\n\t\"encoding/json\"\n\t\"fmt\"\n\t\"os\"\n\n\t\"gopkg.in/yaml.v2\"\n)\n\nvar yml = []byte(`\n- key: foo\n  value: bar\n  secret: false\n- key: beep\n  value: boop\n  secret: true\n`)\n\ntype Data struct {\n\tItems []map[string]interface{}\n}\n\nfunc main() {\n\ty := []map[string]interface{}{}\n\n\tif err := yaml.Unmarshal(yml, \u0026y); err == nil {\n\t\tfmt.Printf(\"%#v\\n\", y)\n\t} else {\n\t\tfmt.Println(err.Error())\n\t}\n\n\tmyYaml := Data{Items: y}\n\n\tjson.NewEncoder(os.Stdout).Encode(myYaml.Items)\n}\n```\n\n### Sorting Structs\n\n```go\npackage main\n\nimport (\n\t\"fmt\"\n\t\"sort\"\n)\n\ntype vals []Value\n\ntype Value struct {\n\tKey string\n\tValue string\n\tSecure bool\n}\n\n// Satisfy the Sort interface\nfunc (v vals) Len() int      { return len(v) }\nfunc (v vals) Swap(i, j int) { v[i], v[j] = v[j], v[i] }\nfunc (v vals) Less(i, j int) bool { \n\treturn v[i].Key \u003c v[j].Key \n}\n\nfunc main() {\n\torig := vals{\n\t\t{\"CK\", \"BV\", false},\n\t\t{\"DK\", \"AV\", true},\n\t\t{\"AK\", \"CV\", false},\n\t\t{\"BK\", \"DV\", true},\n\t}\n\t\n\tfmt.Printf(\"%+v\\n\\n\", orig)\n\tsort.Sort(orig)\n\tfmt.Printf(\"%+v\\n\\n\", orig)\n}\n```\n\nHere is a similar version that sorts by name and age:\n\n```go\npackage main\n\nimport (\n\t\"fmt\"\n\t\"sort\"\n)\n\ntype person struct {\n\tName string\n\tAge  int\n}\n\ntype byName []person\n\nfunc (p byName) Len() int {\n\treturn len(p)\n}\nfunc (p byName) Less(i, j int) bool {\n\treturn p[i].Name \u003c p[j].Name\n}\nfunc (p byName) Swap(i, j int) {\n\tp[i], p[j] = p[j], p[i]\n}\n\ntype byAge []person\n\nfunc (p byAge) Len() int {\n\treturn len(p)\n}\nfunc (p byAge) Less(i, j int) bool {\n\treturn p[i].Age \u003c p[j].Age\n}\nfunc (p byAge) Swap(i, j int) {\n\tp[i], p[j] = p[j], p[i]\n}\n\nfunc main() {\n\tkids := []person{\n\t\t{\"Jill\", 9},\n\t\t{\"Jack\", 10},\n\t}\n\n\tsort.Sort(byName(kids))\n\tfmt.Println(kids)\n\n\tsort.Sort(byAge(kids))\n\tfmt.Println(kids)\n}\n```\n\nWhich results in:\n\n```\n[{Jack 10} {Jill 9}]\n[{Jill 9} {Jack 10}]\n```\n\n### Read Users Input\n\n```go\nreader := bufio.NewReader(os.Stdin)\nfmt.Print(\"Enter text: \")\ntext, _ := reader.ReadString('\\n')\nfmt.Println(text)\n```\n\n### Web Server\n\nThe Go web server design relies on a struct to map routes (URLs) to functions.\n\nYou can define your own struct (prefilled for example) and pass it into `ListenAndServe`. But typically `nil` is used, which means an empty struct is used by default.\n\nAt this point most people will use either `HandleFunc` or `Handle` to register their specified request path so it maps to a specific handler function (this is added to the default struct called `DefaultServeMux`):\n\n```go\npackage main\n\nimport (\n    \"fmt\"\n    \"net/http\"\n)\n\nfunc handler(w http.ResponseWriter, r *http.Request) {\n    fmt.Fprintf(w, \"Hi there, I love %s!\", r.URL.Path[1:])\n}\n\nfunc main() {\n    http.HandleFunc(\"/\", handler)\n    http.ListenAndServe(\":8080\", nil)\n}\n```\n\nThere is a difference between `HandleFunc` and `Handle`. The latter takes a type that has a `ServeHTTP` method associated to it (we'll see an example in a moment of what this looks like). The former is an abstraction layer that allows an incompatible function (one that doesn't have a `ServeHTTP` method) to be used as a handler. \n\nThe way `HandleFunc` works is that it wraps the provided function in a call to `HandlerFunc` (see below for example). In this example `HandlerFunc` is a type of `func`, and this type defines the expected function signature and return value(s). \n\nWhat it states is that a compatible function should have the following signature: `ResponseWriter, *Request`, and it also attaches the method `ServeHTTP` to the type `HandlerFunc`. \n\nNow we can understand that when `HandleFunc` is called and passed our arbitrary function, we call the `HandlerFunc` func type and pass it our function, subsequently *converting* the incoming function so it is now of the type `HandlerFunc` and will now have gained a `ServeHTTP` function which allows it to satisfy the `Handle` interface.\n\nFinally, our `HandleFunc` - once finished adpating the incoming user function - will internally call the `Handle` function and pass it the adapted function, which now satisfies the interface required by `Handle`.\n\nThe actual implementation looks like the following (I've cobbled together all the separate pieces, it doesn't necessarily appear like this in the source code):\n\n```go\n// We define an interface that states\n// if the object has a ServeHTTP method\n// then it satisfies this interface\ntype Handler interface {\n  ServeHTTP(ResponseWriter, *Request)\n}\n\n// The func type works a bit like an interface\n// So if your own user-defined function has a matching signature\n// then your function is considered a `HandlerFunc` and will acquire a `ServeHTTP` method\n// See directly below for where ServeHTTP is attached to this func type\ntype HandlerFunc func(ResponseWriter, *Request)\n\n// Once the provided function is converted to the HandlerFunc type\n// it'll mean it has the `ServeHTTP` function available\nfunc (f HandlerFunc) ServeHTTP(w ResponseWriter, r *Request) {\n    f(w, r)\n}\n\n// This is the abstraction function our client code calls...\nfunc (mux *ServeMux) HandleFunc(pattern string, handler func(ResponseWriter, *Request)) {\n    // Here is where we \"adapt\" the incoming function so it is given a ServeHTTP method\n    // We do this by passing it to the HandlerFunc func type\n    mux.Handle(pattern, HandlerFunc(handler))\n}\n\n// Finally, this is the function that's passed our \"adapted/converted\" handler function\n// The 'handler' passed in now fulfills the 'Handler' interface that says it needs a 'ServeHTTP' method\nfunc (mux *ServeMux) Handle(pattern string, handler Handler) {\n    ...do all the things...\n}\n```\n\nThis allows the arbitrary function to be used for handling the requested URL.\n\nBelow is an example for using `handle` instead of `handleFunc`:\n\n```go\npackage main\n\nimport (\n\t\"fmt\"\n\t\"net/http\"\n)\n\ntype String string\n\nfunc (s String) ServeHTTP(\n\tw http.ResponseWriter,\n\tr *http.Request) {\n\tfmt.Fprint(w, s)\n}\n\ntype Struct struct {\n\tGreeting string\n\tPunct    string\n\tWho      string\n}\n\nfunc (s Struct) ServeHTTP(\n\tw http.ResponseWriter,\n\tr *http.Request) {\n\tfmt.Fprint(w, s.Greeting, s.Punct, s.Who)\n}\n\nfunc main() {\n\thttp.Handle(\"/string\", String(\"I'm a frayed knot.\"))\n\thttp.Handle(\"/struct\", \u0026Struct{\"Hello\", \":\", \"Gophers!\"})\n\thttp.ListenAndServe(\"localhost:4000\", nil)\n}\n```\n\nNow visit `http://localhost:4000/string` and `http://localhost:4000/struct` to see the appropriate output\n\n### Middleware\n\nThis code was modified from https://medium.com/@matryer/writing-middleware-in-golang-and-how-go-makes-it-so-much-fun-4375c1246e81\n\n```go\npackage main\n\nimport (\n\t\"fmt\"\n\t\"log\"\n\t\"net/http\"\n\t\"os\"\n)\n\ntype data struct {\n\tGreeting string\n\tPunct    string\n\tWho      string\n}\n\nfunc (s data) ServeHTTP(w http.ResponseWriter, r *http.Request) {\n\tfmt.Fprint(w, s.Greeting, s.Punct, s.Who)\n}\n\ntype adapter func(http.Handler) http.Handler\n\nfunc adapt(h http.Handler, adapters ...adapter) http.Handler {\n\t// Ideally you'd do this in reverse\n\t// to ensure the order of the middleware\n\t// matches their specified order\n\tfor _, adapter := range adapters {\n\t\th = adapter(h)\n\t}\n\treturn h\n}\n\nfunc notify(logger *log.Logger) adapter {\n\treturn func(h http.Handler) http.Handler {\n\t\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\t\tlogger.Println(\"before\")\n\t\t\tdefer logger.Println(\"after\")\n\t\t\th.ServeHTTP(w, r)\n\t\t})\n\t}\n}\n\nfunc doSomething() adapter {\n\treturn func(h http.Handler) http.Handler {\n\t\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\t\tfmt.Println(\"before\")\n\t\t\tdefer fmt.Println(\"after\")\n\t\t\th.ServeHTTP(w, r)\n\t\t})\n\t}\n}\n\nfunc main() {\n\thttp.Handle(\"/hello\", \u0026data{\"Hello\", \" \", \"Gophers!\"})\n\n\tlogger := log.New(os.Stdout, \"server: \", log.Lshortfile)\n\n\thttp.Handle(\"/hello-with-middleware\", adapt(\n\t\t\u0026data{\"Hello\", \" \", \"Gophers!\"},\n\t\tnotify(logger), // runs second\n\t\tdoSomething(), // runs first\n\t))\n\n\thttp.ListenAndServe(\"localhost:4000\", nil)\n}\n```\n\nThis code will run a web server with two valid endpoints:\n\n1. `/hello`\n2. `/hello-with-middleware`\n\nThe client sees the same output but the latter endpoint produces the following stdout output:\n\n```\nbefore\nserver: middleware.go:35: before\nserver: middleware.go:38: after\nafter\n```\n\n### Sessions\n\n```go\npackage main\n\nimport (\n\t\"fmt\"\n\t\"net/http\"\n\t\"time\"\n)\n\nconst cookiePrefix = \"integralist-example-cookie-\"\n\nfunc main() {\n\thttp.HandleFunc(\"/\", login)\n\thttp.HandleFunc(\"/admin\", admin)\n\thttp.HandleFunc(\"/logout\", logout)\n\thttp.ListenAndServe(\"localhost:4000\", nil)\n}\n\nfunc login(w http.ResponseWriter, r *http.Request) {\n\tif r.Method == \"GET\" {\n\t\tfmt.Fprintf(w, `\n\u003chtml\u003e\n  \u003cbody\u003e\n    \u003cform method=\"POST\"\u003e\n      Username: \u003cinput type=\"text\" name=\"username\"\u003e\n      \u003cbr /\u003e\n      Password: \u003cinput type=\"password\" name=\"password\"\u003e\n      \u003cbr /\u003e\n      \u003cinput type=\"submit\" value=\"Login\"\u003e\n  \u003c/body\u003e\n\u003c/html\u003e\n`)\n\t}\n\n\tif r.Method == \"POST\" {\n\t\tusername := r.FormValue(\"username\")\n\t\tpassword := r.FormValue(\"password\")\n\n\t\tif username == \"admin\" \u0026\u0026 password == \"password\" {\n\t\t\thttp.SetCookie(w, \u0026http.Cookie{\n\t\t\t\tName:  cookiePrefix + \"user\",\n\t\t\t\tValue: username,\n\t\t\t})\n\t\t\thttp.Redirect(w, r, \"/admin\", 302)\n\t\t} else {\n\t\t\tfmt.Fprintf(w, `\n\u003chtml\u003e\n  \u003cbody\u003e\n\t\tLogin details were incorrect. Sorry, \u003ca href=\"/\"\u003etry again\u003c/a\u003e\n  \u003c/body\u003e\n\u003c/html\u003e\n`)\n\t\t}\n\t}\n}\n\nfunc logout(w http.ResponseWriter, r *http.Request) {\n\thttp.SetCookie(w, \u0026http.Cookie{\n\t\tName:    cookiePrefix + \"user\",\n\t\tValue:   \"\",\n\t\tExpires: time.Now(),\n\t})\n\n\thttp.Redirect(w, r, \"/\", 302)\n}\n\nfunc admin(w http.ResponseWriter, r *http.Request) {\n\tcookie, err := r.Cookie(cookiePrefix + \"user\")\n\tif err != nil {\n\t\thttp.Redirect(w, r, \"/\", 401) // Unauthorized\n\t\treturn\n\t}\n\n\tfmt.Fprintf(w, `\n\u003chtml\u003e\n  \u003cbody\u003e\n\t  Logged into admin area as: %s\u003cbr\u003e\u003cbr\u003e\n\t\t\u003ca href=\"/logout\"\u003eLogout\u003c/a\u003e\n  \u003c/body\u003e\n\u003c/html\u003e\n`, cookie.Value)\n}\n```\n\n### HTTP Requests with Timeouts\n\n```go\n// Wait for 1.5 release to be able to verify timeout error (bug in language)\n// Use -race flag https://blog.golang.org/race-detector to detect race conditions\n\npackage main\n\nimport (\n\t\"encoding/json\"\n\t\"fmt\"\n\t\"io/ioutil\"\n\t\"net/http\"\n\t\"sync\"\n\t\"time\"\n\n\t\"gopkg.in/yaml.v2\"\n)\n\ntype ComponentYaml struct {\n\tId  string `yaml:\"id\"`\n\tUrl string `yaml:\"url\"`\n}\n\ntype Component struct {\n\tId  string `json:\"id\"`\n\tUrl string `json:\"url\"`\n}\n\ntype ComponentsYamlList struct {\n\tComponents []ComponentYaml `yaml:\"components\"`\n}\n\ntype ComponentsList struct {\n\tComponents []Component `json:\"components\"`\n}\n\ntype ComponentResponse struct {\n\tId     string\n\tStatus int\n\tBody   string\n}\n\ntype Result struct {\n\tStatus     string\n\tComponents []ComponentResponse\n}\n\nvar overallStatus string = \"success\"\n\nfunc getComponents() []byte {\n\treturn []byte(`{\"components\":[{\"id\":\"local\",\"url\":\"http://localhost:8080/pugs\"},{\"id\":\"google\",\"url\":\"http://google.com/\"},{\"id\":\"integralist\",\"url\":\"http://integralist.co.uk/\"},{\"id\":\"sloooow\",\"url\":\"http://stevesouders.com/cuzillion/?c0=hj1hfff30_5_f\u0026t=1439194716962\"}]}`)\n}\n\nfunc getComponent(wg *sync.WaitGroup, client *http.Client, i int, v Component, ch chan ComponentResponse) {\n\tdefer wg.Done()\n\n\tresp, err := client.Get(v.Url)\n\n\tif err != nil {\n\t\tfmt.Printf(\"Problem getting the response: %s\\n\\n\", err)\n\n\t\tch \u003c- ComponentResponse{\n\t\t\tv.Id, 500, err.Error(),\n\t\t}\n\t} else {\n\t\tdefer resp.Body.Close()\n\t\tcontents, err := ioutil.ReadAll(resp.Body)\n\t\tif err != nil {\n\t\t\tfmt.Printf(\"Problem reading the body for %s -\u003e %s\\n\", v.Id, err)\n\t\t}\n\n\t\tch \u003c- ComponentResponse{\n\t\t\tv.Id, resp.StatusCode, string(contents),\n\t\t}\n\t}\n}\n\nfunc main() {\n\tvar cr []ComponentResponse\n\tvar c ComponentsList\n\tvar y ComponentsYamlList\n\n\tch := make(chan ComponentResponse)\n\tb := getComponents() // to be read from a file\n\n\tyaml.Unmarshal([]byte(\"components:\\n  - id: google\\n    url: http://google.com\\n  - id: integralist\\n    url: http://integralist.co.uk\"), \u0026y)\n\tjson.Unmarshal(b, \u0026c)\n\n\ttimeout := time.Duration(1 * time.Second)\n\tclient := http.Client{\n\t\tTimeout: timeout,\n\t}\n\n\tvar wg sync.WaitGroup\n\tfor i, v := range c.Components {\n\t\twg.Add(1)\n\t\tgo getComponent(\u0026wg, \u0026client, i, v, ch)\n\t\tcr = append(cr, \u003c-ch)\n\t}\n\twg.Wait()\n\n\tj, err := json.Marshal(Result{overallStatus, cr})\n\tif err != nil {\n\t\tfmt.Printf(\"Problem converting to JSON: %s\\n\", err)\n\t\treturn\n\t}\n\n\tfmt.Println(string(j))\n\tfmt.Println(y)\n}\n```\n\n### S3 GetObject\n\n```go\nimport (\n\t\"fmt\"\n\t\"io/ioutil\"\n\t\"net/http\"\n\n\t\"github.com/BBC-News/mozart-config-api/src/logger\"\n\t\"github.com/aws/aws-sdk-go/aws\"\n\t\"github.com/aws/aws-sdk-go/aws/awserr\"\n\t\"github.com/aws/aws-sdk-go/service/s3\"\n)\n\nfunc HandleStatusRequest(w http.ResponseWriter, r *http.Request) {\n\tfmt.Fprint(w, \"ok\")\n}\n\nfunc HandleGetRequest(w http.ResponseWriter, r *http.Request) {\n\tsvc := s3.New(\u0026aws.Config{\n\t\tRegion:           aws.String(\"eu-west-1\"),\n\t\tEndpoint:         aws.String(\"s3.spurious.localhost:32769\"),\n\t\tDisableSSL:       aws.Bool(true),\n\t\tS3ForcePathStyle: aws.Bool(true),\n\t})\n\n\tparams := \u0026s3.GetObjectInput{\n\t\tBucket: aws.String(\"int-mozart-config-api\"),\n\t\tKey:    aws.String(\"/v1/int/news/foo.json\"),\n\t}\n\n\tresp, err := svc.GetObject(params)\n\n\t// ABSTRACT INTO A FUNCTION IN A NAMESPACE!\n\tif err != nil {\n\t\tif awsErr, ok := err.(awserr.Error); ok {\n\t\t\t// Generic AWS Error with Code, Message, and original error (if any)\n\t\t\tfmt.Println(\"1. \", awsErr.Code(), awsErr.Message(), awsErr.OrigErr())\n\t\t\tif reqErr, ok := err.(awserr.RequestFailure); ok {\n\t\t\t\t// A service error occurred\n\t\t\t\tfmt.Println(\"2. \", reqErr.StatusCode(), reqErr.RequestID())\n\t\t\t}\n\t\t} else {\n\t\t\tfmt.Println(\"3. \", err.Error())\n\t\t}\n\t}\n\n\tdata, err := ioutil.ReadAll(resp.Body)\n\n\tif err != nil {\n\t\tfmt.Println(\"Error reading content\", err)\n\t}\n\n\tfmt.Println(data) // =\u003e []byte\n\tfmt.Println(string(data[:]))\n\n\tw.Header().Set(\"Content-Type\", \"application/json\")\n\tw.Write(data)\n\tlogger.Metric(\"200 response\")\n}\n```\n\n### Compile time variables\n\n```go\nvar (\n    Version   string\n    BuildTime string\n)\n```\n\nNow build the project using: \n\n```bash\ngo build -ldflags \"-X github.com/\u003cuser\u003e/\u003cproject\u003e/core.Version=1.0.0 -X github.com/\u003cuser\u003e/\u003cproject\u003e/core.BuildTime=2015-10-03T11:08:49+0200\" main.go\n```\n\n### TLS HTTP Request\n\n```go\npackage requester\n\nimport (\n\t\"crypto/tls\"\n\t\"crypto/x509\"\n\t\"flag\"\n\t\"io/ioutil\"\n\t\"log\"\n\t\"net/http\"\n)\n\nvar (\n\tcertFile = flag.String(\"cert\", \"/etc/pki/tls/certs/client.crt\", \"A PEM eoncoded certificate file.\")\n\tkeyFile  = flag.String(\"key\", \"/etc/pki/tls/private/client.key\", \"A PEM encoded private key file.\")\n\tcaFile   = flag.String(\"CA\", \"/etc/ca/cloud-ca.pem\", \"A PEM eoncoded CA's certificate file.\")\n)\n\nfunc SecureClient() *http.Client {\n\t// Load client cert\n\tcert, err := tls.LoadX509KeyPair(*certFile, *keyFile)\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\n\t// Load CA cert\n\tcaCert, err := ioutil.ReadFile(*caFile)\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\tcaCertPool := x509.NewCertPool()\n\tcaCertPool.AppendCertsFromPEM(caCert)\n\n\t// Setup HTTPS client\n\ttlsConfig := \u0026tls.Config{\n\t\tCertificates:       []tls.Certificate{cert},\n\t\tRootCAs:            caCertPool,\n\t\tInsecureSkipVerify: true,\n\t}\n\ttlsConfig.BuildNameToCertificate()\n\ttransport := \u0026http.Transport{TLSClientConfig: tlsConfig}\n\tclient := \u0026http.Client{Transport: transport}\n\n\treturn client\n}\n```\n\nAnd to use it...\n\n```go\nclient := requester.SecureClient()\n\n// GET\nresp, err := client.Get(someEndpoint)\n\n// POST\nreq, err := http.NewRequest(\"POST\", someEndpoint, bytes.NewBuffer(jsonStr))\nreq.Header.Set(\"Content-Type\", \"application/json\")\nresp, err := client.Do(req)\n```\n\n### Custom HTTP Request\n\nGo doesn't provide abstractions for all the various HTTP request types, so for things like `PUT` you have to implement it yourself. The following is an example that creates a secure (TLS/HTTPS) `PUT` abstraction...\n\n```go\nfunc SecurePut(url, contentType string, configFile io.Reader) (*http.Response, error) {\n\tclient := \u0026http.Client{Transport: configureTLS()}\n\treq, err := http.NewRequest(\"PUT\", url, configFile)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treq.Header.Add(\"Content-Type\", contentType)\n\tresp, err := client.Do(req)\n\n\treturn resp, err\n}\n\nfunc configureTLS() *http.Transport {\n\tcertFilePath := \"path/to/cert\"\n\tkeyFilePath := \"path/to/privateKey\"\n\tcaPath := \"path/to/ca\"\n\n\t// Load client cert\n\tcert, err := tls.LoadX509KeyPair(certFilePath, keyFilePath)\n\tif err != nil {\n\t\tmsg := fmt.Sprintf(\"Error loading developer cert, path: \\\"%s\\\"\", certFilePath)\n\t\toutput.Error(msg)\n\t}\n\n\t// Load CA cert\n\tcaCert, err := ioutil.ReadFile(caPath)\n\tif err != nil {\n\t\tmsg := fmt.Sprintf(\"Error loading CA cert, path: \\\"%s\\\"\", caPath)\n\t\toutput.Error(msg)\n\t}\n\tcaCertPool := x509.NewCertPool()\n\tcaCertPool.AppendCertsFromPEM(caCert)\n\n\t// Setup HTTPS client\n\ttlsConfig := \u0026tls.Config{\n\t\tCertificates:       []tls.Certificate{cert},\n\t\tRootCAs:            caCertPool,\n\t\tInsecureSkipVerify: true,\n\t}\n\ttlsConfig.BuildNameToCertificate()\n\n\treturn \u0026http.Transport{TLSClientConfig: tlsConfig}\n}\n```\n\n### HTTP GET Web Page\n\n```go\npackage main\n\nimport (\n\t\"fmt\"\n\t\"io/ioutil\"\n\t\"net/http\"\n\t\"os\"\n)\n\nfunc main() {\n\tresponse, err := http.Get(\"http://www.integralist.co.uk/\")\n\tif err != nil {\n\t\tfmt.Println(err.Error())\n\t\tos.Exit(1)\n\t}\n\n\tdefer response.Body.Close()\n\n\tcontents, err := ioutil.ReadAll(response.Body)\n\tif err != nil {\n\t\tfmt.Println(err.Error())\n\t\tos.Exit(1)\n\t}\n\n\tfmt.Println(string(contents))\n}\n```\n\n### Pointers\n\n```go\npackage main\n\nimport \"fmt\"\n\n// Point stores co-ordinates\ntype Point struct {\n\tx int\n\ty int\n}\n\n// If receiver (Point) isn't set to a pointer (*Point) \n// then the struct's field value won't be updated outside the method\nfunc (p *Point) scaleBy(factor int) {\n\tfmt.Printf(\"scaleBy (before modification): %+v\\n\", p)\n\n\t// Don't need to derefence (*) struct fields\n\t// Compiler will perform an implicit \u0026p for you\n\t// You only need to dereference in standard functions when a argument pointer is required (see below Array Pointer example)\n\tp.x *= factor\n\tp.y *= factor\n\n\tfmt.Printf(\"scaleBy (after modification): %+v\\n\", p)\n}\n\nfunc main() {\n\t// Doesn't matter if we do or don't get the address space (\u0026) for foo/bar's Point\n\tfoo := \u0026Point{1, 2}\n\tbar := \u0026Point{6, 8}\n\n\tfmt.Printf(\"Main foo.x: %+v\\n\", foo.x)\n\tfmt.Printf(\"Main bar.x: %+v\\n\", bar.x)\n\n\tfoo.scaleBy(5)\n\tbar.scaleBy(5)\n\n\tfmt.Printf(\"Main foo.x: %+v\\n\", foo.x)\n\tfmt.Printf(\"Main foo.y: %+v\\n\", foo.y)\n\n\tfmt.Printf(\"Main bar.x: %+v\\n\", bar.x)\n\tfmt.Printf(\"Main bar.y: %+v\\n\", bar.y)\n}\n```\n\n\u003e Note: compiler can only apply implicit dereference for variables and struct fields  \n\u003e this wouldn't work `Point{1, 2}.scaleBy(5)`\n\nResults in the following output:\n\n```\nMain foo.x: 1\nMain bar.x: 6\nscaleBy (before modification): \u0026{x:1 y:2}\nscaleBy (after modification): \u0026{x:5 y:10}\nscaleBy (before modification): \u0026{x:6 y:8}\nscaleBy (after modification): \u0026{x:30 y:40}\nMain foo.x: 5\nMain foo.y: 10\nMain bar.x: 30\nMain bar.y: 40\n```\n\n### Array Pointer\n\nDeference an Array pointer so you can mutate the original Array values:\n\n```go\npackage main\n\nimport \"fmt\"\n\nfunc main() {  \n    x := [3]int{1,2,3}\n\n    func(arr *[3]int) {\n        (*arr)[0] = 7\n        fmt.Println(arr) //prints \u0026[7 2 3]\n    }(\u0026x)\n\n    fmt.Println(x) //prints [7 2 3]\n}\n```\n\nAlternatively you can utilise a Slice instead of an Array, as the slice 'header' already has a 'pointer' to an underlying Array:\n\n```go\npackage main\n\nimport \"fmt\"\n\nfunc main() {  \n    x := []int{1,2,3}\n\n    func(arr []int) {\n        arr[0] = 7\n        fmt.Println(arr) //prints [7 2 3]\n    }(x)\n\n    fmt.Println(x) //prints [7 2 3]\n}\n```\n\n### Type Assertion\n\n```go\nif e, ok := err.(net.Error); ok \u0026\u0026 e.Timeout() {\n\t//\n}\n\ntype argError struct {\n    arg  int\n    prob string\n}\n\nfunc (e *argError) Error() string {\n    return fmt.Sprintf(\"%d - %s\", e.arg, e.prob)\n}\n\nif ae, ok := e.(*argError); ok {\n\t//\n}\n```\n\n### Line Count\n\nDemonstrates how to use `bufio` package to scan a file and read it line by line, and then how to increment a map integer value using the shortcut `map[key]++`. Finally, demonstrates nested maps and ranging over them:\n\n```go\npackage main\n\nimport (\n\t\"bufio\"\n\t\"fmt\"\n\t\"os\"\n)\n\nfunc main() {\n\tcounts := make(map[string]map[string]int)\n\tfiles := os.Args[1:]\n\tif len(files) == 0 {\n\t\tcountLines(os.Stdin, \"n/a\", counts)\n\t} else {\n\t\tfor _, arg := range files {\n\t\t\tf, err := os.Open(arg)\n\t\t\tif err != nil {\n\t\t\t\tfmt.Fprintf(os.Stderr, \"dup2: %v\\n\", err)\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tcountLines(f, arg, counts)\n\t\t\tf.Close()\n\t\t}\n\t}\n\tfor key, nestedMap := range counts {\n\t\tfmt.Printf(\"Text: %s\\n\", key)\n\t\tfor filename, count := range nestedMap {\n\t\t\tfmt.Printf(\"\\tFile: %s\\n\\tCount: %d\\n\", filename, count)\n\t\t}\n\t\tfmt.Println(\"\")\n\t}\n}\n\nfunc countLines(f *os.File, filename string, counts map[string]map[string]int) {\n\tinput := bufio.NewScanner(f)\n\tfor input.Scan() {\n\t\tif val, ok := counts[input.Text()]; ok {\n\t\t\tval[filename]++\n\t\t} else {\n\t\t\tinner := make(map[string]int)\n\t\t\tinner[filename]++\n\t\t\tcounts[input.Text()] = inner\n\t\t}\n\t}\n}\n```\n\n### Measuring time\n\n```go\npackage main\n\nimport (\n\t\"fmt\"\n\t\"time\"\n)\n\n// Sleep requires a Duration\n// time has set of constants we can use (lowest is 1 Duration)\n// Second constant is an abstraction over the other constants\nfunc main() {\n\tstart := time.Now()\n\ttime.Sleep(time.Duration(5) * time.Second) // sleep 5 seconds\n\tsecs := time.Since(start).Seconds()\n\n\tfmt.Printf(\"Time spent: %f seconds\", secs)\n}\n```\n\n### Reading a file in chunks\n\n```go\npackage main\n\nimport (\n\t\"fmt\"\n\t\"log\"\n\t\"os\"\n)\n\nfunc main() {\n\t// Create file (truncates file if it already exists)\n\tfile, err := os.Create(\"created.txt\")\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\n\t// Populate byte slice with some content\n\tb := make([]byte, 0)\n\tfor i := 0; i \u003c 5; i++ {\n\t\tb = append(b, '!')\n\t\tb = append(b, '\\n')\n\t\t// notice single quotes for Rune rather than double quote for String\n\t}\n\tfor i := 0; i \u003c 5; i++ {\n\t\tb = append(b, '?')\n\t\tb = append(b, '\\n')\n\t\t// notice single quotes for Rune rather than double quote for String\n\t}\n\tfor i := 0; i \u003c 5; i++ {\n\t\tb = append(b, '%')\n\t\tb = append(b, '\\n')\n\t\t// notice single quotes for Rune rather than double quote for String\n\t}\n\n\t// Write file contents\n\tbytesWritten, err := file.Write(b)\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\tfmt.Printf(\"Bytes written: %+v\\n\", bytesWritten)\n\n\t// Although getting the bytes written was useful for us\n\t// in this example, you might need to get total bytes\n\t// which can be done by copying file contents into dev/null\n    // io.Copy(ioutil.Discard, resp.Body)\n\n\t// Get current offset\n\t// 1st arg is how much to seek forward/backwards by\n\t// 2nd arg is relative to different settings\n\t// \t\t0 == relative to start of file\n\t// \t\t1 == current offset\n\t// \t\t2 == relative to end of file\n\tcurrentOffset, err := file.Seek(0, 1)\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\tfmt.Printf(\"Current offset: %d\\n\", currentOffset)\n\tfile.Seek(-currentOffset, 1) // Return to start of file for next Read\n\n\t// Read buffered view of file\n\tdata := make([]byte, 10, bytesWritten) // create slice with underlying Array capacity set to total file bytes size\n\teof := false\n\tfor !eof {\n\t\tcount, err := file.Read(data)\n\t\tif err != nil {\n\t\t\teof = true\n\t\t}\n\t\tfmt.Printf(\"read %d bytes: %q\\n\", count, data[:count])\n\t}\n}\n```\n\n### Time and Channels\n\nBasic example that pauses execution until the timer has expired (you would use this over a `timer.Sleep` because you can cancel a timer before it has expired;):\n\n```go\npackage main\n\nimport (\n\t\"fmt\"\n\t\"time\"\n)\n\nfunc main() {\n\ttimer := time.NewTimer(time.Second * 2)\n\n\t\u003c-timer.C // pauses for two seconds\n\n\tfmt.Println(\"Timer expired\")\n}\n```\n\nExample of cancelling the timer:\n\n```go\npackage main\n\nimport (\n\t\"fmt\"\n\t\"time\"\n)\n\nfunc main() {\n\ttimer := time.NewTimer(time.Second * 2)\n\n\t// Expensive process run in a separate thread\n\tgo func() {\n\t\t\u003c-timer.C\n\t\tfmt.Println(\"Timer expired\")\n\t}()\n\n\tstop := timer.Stop() // cancel the timer\n\tfmt.Println(stop)    // true\n}\n```\n\nWe can do a similar thing with Timers:\n\n```go\npackage main\n\nimport (\n\t\"fmt\"\n\t\"time\"\n)\n\nfunc main() {\n\tticker := time.NewTicker(time.Millisecond * 500)\n\n\t// Repetitive process\n\tgo func() {\n\t\t// Range over the channel rather than pull from it\n\t\tfor t := range ticker.C {\n\t\t\tfmt.Println(\"Tick:\", t)\n\t\t}\n\t}()\n\n\t// Stop ticker after three ticks/intervals\n\ttime.Sleep(time.Millisecond * 1500)\n\tticker.Stop()\n}\n```\n\nWe can combine all these items together with a `select` statement like so:\n\n```go\npackage main\n\nimport \"time\"\nimport \"fmt\"\n\nfunc main() {\n\ttimeChan := time.NewTimer(time.Second).C\n\ttickChan := time.NewTicker(time.Millisecond * 400).C\n\n\t// Used to signify we're done with this program\n\tdoneChan := make(chan bool)\n\n\t// Sleep for two seconds, then notify the channel we're done\n\tgo func() {\n\t\ttime.Sleep(time.Second * 2)\n\t\tdoneChan \u003c- true\n\t}()\n\n\tfor {\n\t\tselect {\n\t\tcase \u003c-timeChan:\n\t\t\tfmt.Println(\"Timer expired\")\n\t\tcase \u003c-tickChan:\n\t\t\tfmt.Println(\"Ticker ticked\")\n\t\tcase \u003c-doneChan:\n\t\t\tfmt.Println(\"Done\")\n\t\t\treturn\n\t\t}\n\t}\n}\n```\n\nThe output of this program would be something like:\n\n```\nTicker ticked\nTicker ticked\nTimer expired\nTicker ticked\nTicker ticked\nDone\n```\n\n### Quit a Channel\n\nI would imagine that for most cases you'll want to use a `time.NewTimer` as seen in previous examples if you want to stop a goroutine that's processing a long running program. The following example is more for stopping a goroutine that's running code at a set interval (although using `time.NewTicker` would probably be more appropriate):\n\n```go\npackage main\n\nimport (\n\t\"fmt\"\n\t\"time\"\n)\n\nfunc main() {\n\tquit := make(chan bool)\n\n\t// Run a piece of code at a set interval\n\tgo func() {\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase \u003c-quit:\n\t\t\t\treturn\n\t\t\tdefault:\n\t\t\t\tfmt.Println(\"Not ready to stop this goroutine\")\n\t\t\t\ttime.Sleep(time.Millisecond * 100)\n\t\t\t}\n\t\t}\n\t}()\n\n\t// Do other stuff for two seconds\n\ttime.Sleep(time.Second * 2)\n\n\t// Quit goroutine\n\tquit \u003c- true\n\n\tfmt.Println(\"Goroutine was stopped\")\n}\n```\n\n### Starting and Stopping things with Channels\n\nStarting a goroutine:\n\n```go\npackage main\n\nimport (\n\t\"fmt\"\n\t\"time\"\n)\n\nfunc main() {\n\t// Use a struct type channel as it clarifies your intent\n\t// Which is this channel is used for 'signalling'\n\tstart := make(chan struct{})\n\n\tfor i := 0; i \u003c 10000; i++ {\n\t\tgo func() {\n\t\t\t\u003c-start // wait for the start channel to be closed\n\t\t\tfmt.Println(\"do stuff\")\n\t\t}()\n\t}\n\n\t// at this point, all goroutines are ready to go\n\t// we just need to tell them to start by\n\t// closing the start channel\n\tclose(start)\n\n\tfmt.Println(\"Let's pause briefly to give goroutines time to execute\")\n\n\ttime.Sleep(time.Millisecond * 10)\n}\n```\n\nStopping a goroutine:\n\n```go\npackage main\n\nimport (\n\t\"fmt\"\n\t\"time\"\n)\n\nfunc main() {\n\t// Use a struct type channel as it clarifies your intent\n\t// Which is this channel is used for 'signalling'\n\tdone := make(chan struct{})\n\n\t// Long running process put onto a thread\n\tgo func() {\n\t\tfmt.Println(\"Inside thread doing expensive processing\")\n\t\ttime.Sleep(time.Second * 5)\n\t\tclose(done)\n\t}()\n\n\tfmt.Println(\"Do other things\")\n\n\t// Wait for long running process to finish\n\t\u003c-done\n\n\tfmt.Println(\"Do more things\")\n}\n```\n\n### Channel Pipelines\n\nThe principle of a pipeline, is to take data from one function and pass it into another function, that receiving function will process the received data and then that result is returned and subsequently passed onto another function... rinse and repeat for however long your pipeline needs to be.\n\nIn the below example (copied from [here](https://blog.gopheracademy.com/advent-2015/automi-stream-processing-over-go-channels/)) demonstrates how a set of functions accept a channel and return a channel and so channels is the 'data' that is passed around the pipeline functions:\n\n```go\npackage main\n\nimport \"fmt\"\nimport \"sync\"\n\nfunc ingest() \u003c-chan []string {\n\tout := make(chan []string)\n\tgo func() {\n\t\tout \u003c- []string{\"aaaa\", \"bbb\"}\n\t\tout \u003c- []string{\"cccccc\", \"dddddd\"}\n\t\tout \u003c- []string{\"e\", \"fffff\", \"g\"}\n\t\tclose(out)\n\t}()\n\treturn out\n}\n\nfunc process(concurrency int, in \u003c-chan []string) \u003c-chan int {\n\tvar wg sync.WaitGroup\n\twg.Add(concurrency)\n\n\tout := make(chan int)\n\n\twork := func() {\n\t\tfor data := range in {\n\t\t\tfor _, word := range data {\n\t\t\t\tout \u003c- len(word)\n\t\t\t}\n\t\t}\n\t\twg.Done()\n\n\t}\n\n\tgo func() {\n\t\tfor i := 0; i \u003c concurrency; i++ {\n\t\t\tgo work()\n\t\t}\n\n\t}()\n\n\tgo func() {\n\t\twg.Wait()\n\t\tclose(out)\n\t}()\n\treturn out\n}\n\nfunc store(in \u003c-chan int) \u003c-chan struct{} {\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tdefer close(done)\n\t\tfor data := range in {\n\t\t\tfmt.Println(data)\n\t\t}\n\t}()\n\treturn done\n}\n\nfunc main() {\n\t// stage 1 ingest data from source\n\tin := ingest()\n\n\t// stage 2 - process data\n\treduced := process(4, in)\n\n\t// stage 3 - store\n\t\u003c-store(reduced)\n}\n```\n\n### Templating\n\nHere is a basic program that uses a Struct for its data source:\n\n```go\npackage main\n\nimport (\n\t\"log\"\n\t\"os\"\n\t\"text/template\"\n)\n\ntype dataSource struct {\n\tBaz int\n}\n\nfunc (ds dataSource) Foo() string {\n\treturn \"I am foo\"\n}\n\nfunc (ds dataSource) Bar() string {\n\treturn \"I am bar\"\n}\n\nconst templ = `\n\tFoo: {{.Foo}}\n\tPiping: {{.Bar | printf \"Bar: %s\"}}\n\tFunction: {{.Baz | qux}}\n`\n\nfunc qux(baz int) int {\n\treturn baz * 2\n}\n\n// template.Must handles parsing errors better\nvar setupTemplate = template.Must(\n\ttemplate.New(\"whatever\").\n\t\tFuncs(template.FuncMap{\"qux\": qux}).\n\t\tParse(templ),\n)\n\nfunc main() {\n\tds := dataSource{5}\n\n\tif err := setupTemplate.Execute(os.Stdout, ds); err != nil {\n\t\tlog.Fatal(err)\n\t}\n}\n```\n\n\u003e Note: `printf` is a built-in function for templating and is functionally equivalent to `fmt.Sprintf`\n\nProgram output:\n\n```\nFoo: I am foo\nPiping: Bar: I am bar\nFunction: 10\n```\n\nHere is a HTML templating version:\n\n```go\npackage main\n\nimport (\n\t\"html/template\"\n\t\"log\"\n\t\"os\"\n)\n\nvar data struct {\n\tA string        // untrusted plain text\n\tB template.HTML // trusted HTML\n}\n\nconst templ = `\u003cp\u003eA: {{.A}}\u003c/p\u003e\u003cp\u003eB: {{.B}}\u003c/p\u003e`\n\nfunc main() {\n\tt := template.Must(template.New(\"escape\").Parse(templ))\n\n\tdata.A = \"\u003cb\u003eHello\u003c/b\u003e\"\n\tdata.B = \"\u003cb\u003eHello\u003c/b\u003e\"\n\n\tif err := t.Execute(os.Stdout, data); err != nil {\n\t\tlog.Fatal(err)\n\t}\n}\n```\n\nThe output would be:\n\n```\n\u003cp\u003eA: \u0026lt;b\u0026gt;Hello\u0026lt;/b\u0026gt;\u003c/p\u003e\n\u003cp\u003eB: \u003cb\u003eHello\u003c/b\u003e\u003c/p\u003e\n```\n\n### Error handling with context\n\nThe following code outputs: \n\n```\nThis is our custom error with some more context prefixed: oh noes!\n```\n\n```go\npackage main\n\nimport (\n\t\"errors\"\n\t\"fmt\"\n)\n\ntype errWithContext struct {\n\terr error\n\tmsg string\n}\n\nfunc (e errWithContext) Error() string {\n\treturn e.msg + \": \" + e.err.Error()\n}\n\nfunc triggerError() (bool, error) {\n\treturn false, errors.New(\"oh noes!\")\n}\n\nfunc main() {\n\tvar e *errWithContext\n\n\t_, err := triggerError()\n\tif err != nil {\n\t\te = \u0026errWithContext{\n\t\t\terr,\n\t\t\t\"This is our custom error with some more context prefixed\",\n\t\t}\n\t}\n\n\tfmt.Print(e.Error())\n}\n```\n\n### Socket programming with TCP server\n\nThere are two main types of sockets:\n\n1. STREAM sockets (e.g. TCP)\n2. DATAGRAM sockets (e.g. UDP)\n\n\u003e Note: a \"unix domain socket\" is actually a physical file  \n\u003e it's useful for local (same host) data communication\n\nThe principle steps behind a socket is:\n\n- Create the socket\n- Bind the socket to an address (e.g. `127.0.0.1:80`)\n- Listen for socket connections\n- Accept the socket connection\n\nThere are two main packages in our below example: `server.go` and `client.go`. \n\nRun both of them in separate terminals (e.g. `go run ...`)\n\nThen for the `client.go` type your message followed by a new line, for example:\n\n```\nHello World\nMessage from server: HELLO WORLD\n```\n\nWhilst in the `server.go` terminal you should see:\n\n```\nStarting TCP server...\nMessage Received: Hello World\n```\n\nThe code for this program is as follows:\n\nserver.go\n\n```go\npackage main\n\nimport (\n\t\"bufio\"\n\t\"fmt\"\n\t\"net\"\n\t\"strings\"\n)\n\nfunc main() {\n\tfmt.Println(\"Starting TCP server...\")\n\n\t// Listen on all network interfaces (e.g. 0.0.0.0)\n\t// Documentation: godoc net Listener | less\n\tlistener, _ := net.Listen(\"tcp\", \":8081\")\n\n\t// Accept connection on the port we specified (see above)\n\tconnection, _ := listener.Accept()\n\n\t// Handle incoming connections forever\n\tfor {\n\t\t// Listen for message to process ending in newline (\\n)\n\t\t// Note: single quotes needed for type byte (double quotes is a string)\n\t\tmessage, _ := bufio.NewReader(connection).ReadString('\\n')\n\n\t\t// Output message received\n\t\tfmt.Println(\"Message Received:\", string(message))\n\n\t\t// Do something with the message (e.g. uppercase it)\n\t\tnewmessage := strings.ToUpper(message)\n\n\t\t// Send new string back to client\n\t\tconnection.Write([]byte(newmessage + \"\\n\"))\n\t}\n}\n```\n\nclient.go\n\n```go\npackage main\n\nimport (\n\t\"bufio\"\n\t\"fmt\"\n\t\"net\"\n\t\"os\"\n)\n\nfunc main() {\n\t// Open socket connection to a locally runnning TCP server\n\tconnection, _ := net.Dial(\"tcp\", \"127.0.0.1:8081\")\n\n\t// Handle incoming responses\n\tfor {\n\t\t// Read the input\n\t\treader := bufio.NewReader(os.Stdin)\n\n\t\t// Message to be sent\n\t\t// Note: single quotes needed for type byte (double quotes is a string)\n\t\t// Documentation: godoc bufio ReadString | less\n\t\t// ReadString reads until the first occurrence of the delimiter \\n in the input\n\t\ttext, _ := reader.ReadString('\\n')\n\n\t\t// Send message to open Socket\n\t\tfmt.Fprintf(connection, text+\"\\n\")\n\n\t\t// Listen for response\n\t\t// Note: single quotes needed for type byte (double quotes is a string)\n\t\tmessage, _ := bufio.NewReader(connection).ReadString('\\n')\n\n\t\tfmt.Println(\"Message from server: \" + message)\n\t}\n}\n```\n\n### Comparing maps\n\nThis code demonstrates how to be careful about false positives!\n\n```go\npackage main\n\nimport \"fmt\"\n\nfunc equal(x, y map[string]int) bool {\n\tif len(x) != len(y) {\n\t\t// fail fast\n\t\treturn false\n\t}\n\n\tfor k, xv := range x {\n\t\t// Verify \"missing\" key and \"present but zero\" key value\n\t\tif yv, ok := y[k]; !ok || yv != xv {\n\t\t\treturn false\n\t\t}\n\t\t\n\t\t/*\n\t\t// The following condition would incorrectly return \"true\" for the below example comparison!\n\t\t// This is because the empty value for an int type is a zero, while the actual value of x's key is zero\n\t\tif xv != y[k] {\n\t\t\treturn false\n\t\t}\n\t\t*/\n\t}\n\n\treturn true\n}\n\nfunc main() {\n\tfmt.Println(\n\t\tequal(map[string]int{\"A\": 0}, map[string]int{\"B\": 42}),\n\t)\n}\n```\n\n### Embedded Structs\n\nThe first example demonstrates a 'named' field utilising an embedded Struct:\n\n```go\npackage main\n\nimport \"fmt\"\n\ntype Point struct {\n\tX, Y int\n}\n\ntype Circle struct {\n\tCenter Point // named embeded field\n\tRadius int\n}\n\ntype Wheel struct {\n\tCircle Circle // named embeded field\n\tSpokes int\n}\n\nfunc main() {\n\tvar w Wheel\n\tw.Circle.Center.X = 8\n\tw.Circle.Center.Y = 8\n\tw.Circle.Radius = 5\n\tw.Spokes = 20\n\n\tfmt.Printf(\"%+v\", w)\n}\n```\n\nWhich prints:\n\n```\n{Circle:{Center:{X:8 Y:8} Radius:5} Spokes:20}\n```\n\nThe second example demonstrates an 'anonymous' field instead:\n\n```go\npackage main\n\nimport \"fmt\"\n\ntype Point struct {\n\tX, Y int\n}\n\ntype Circle struct {\n\tPoint\n\tRadius int\n}\n\ntype Wheel struct {\n\tCircle\n\tSpokes int\n}\n\nfunc main() {\n\tvar w Wheel\n\tw.X = 8       // w.Circle.Point.X\n\tw.Y = 8       // w.Circle.Point.Y\n\tw.Radius = 5  // w.Circle.Radius\n\tw.Spokes = 20\n\n\tfmt.Printf(\"%+v\", w)\n}\n```\n\nWhich prints:\n\n```\n{Circle:{Point:{X:8 Y:8} Radius:5} Spokes:20}\n```\n\n\u003e Note: anonymous fields don't work shorthand literal Struct\n\nThe following example demonstrates how methods of a composited object can be accessed from the consuming object:\n\n```go\npackage main\n\nimport \"fmt\"\n\ntype Point struct {\n\tX, Y int\n}\n\nfunc (p Point) foo() {\n\tfmt.Printf(\"foo: %+v\\n\", p)\n}\n\ntype Circle struct {\n\tPoint\n\tRadius int\n}\n\ntype Wheel struct {\n\tCircle\n\tSpokes int\n}\n\nfunc main() {\n\tvar w Wheel\n\tw.X = 8      // w.Circle.Point.X\n\tw.Y = 8      // w.Circle.Point.Y\n\tw.foo()      // w.Circle.Point.foo()\n\tw.Radius = 5 // w.Circle.Radius\n\tw.Spokes = 20\n\n\tfmt.Printf(\"%+v\", w)\n}\n```\n\nWhich prints:\n\n```\nfoo: {X:8 Y:8}\n{Circle:{Point:{X:8 Y:8} Radius:5} Spokes:20}\n```\n\nHere is a more practical example that demonstrates how embedded functionality can make code more expressive:\n\n```go\npackage main\n\nimport (\n\t\"fmt\"\n\t\"sync\"\n)\n\n// Anonymous struct\nvar cache = struct {\n\tsync.Mutex\n\tmapping map[string]string\n}{\n\tmapping: make(map[string]string), // initial zero value for map\n}\n\nfunc setValue() {\n\tcache.Lock()\n\tcache.mapping[\"foo\"] = \"bar\"\n\tcache.Unlock()\n}\n\nfunc main() {\n\tsetValue()\n\n\tcache.Lock()\n\tv := cache.mapping[\"foo\"]\n\tcache.Unlock()\n\n\tfmt.Printf(\"v: %s\", v)\n}\n```\n\n### Zip File Contents\n\n```go\npackage main\n\nimport (\n\t\"compress/zlib\"\n\t\"io\"\n\t\"log\"\n\t\"os\"\n)\n\nfunc main() {\n\tvar err error\n\n\t// This defends against an error preventing `defer` from being called\n\t// As log.Fatal otherwise calls `os.Exit`\n\tdefer func() {\n\t\tif err != nil {\n\t\t\tlog.Fatalln(\"\\nDeferred log: \\n\", err)\n\t\t}\n\t}()\n\n\tsrc, err := os.Create(\"source.txt\")\n\tif err != nil {\n\t\treturn\n\t}\n\tsrc.WriteString(\"source content\")\n\tsrc.Close()\n\n\tdest, err := os.Create(\"new.txt\")\n\tif err != nil {\n\t\treturn\n\t}\n\n\topenSrc, err := os.Open(\"source.txt\")\n\tif err != nil {\n\t\treturn\n\t}\n\n\tzdest := zlib.NewWriter(dest)\n\tif _, err := io.Copy(zdest, openSrc); err != nil {\n\t\treturn\n\t}\n\n\t// Close these explicitly\n\tzdest.Close()\n\tdest.Close()\n\n\tn, err := os.Open(\"new.txt\")\n\tif err != nil {\n\t\treturn\n\t}\n\n\tr, err := zlib.NewReader(n)\n\tif err != nil {\n\t\treturn\n\t}\n\tdefer r.Close()\n\tio.Copy(os.Stdout, r)\n\n\terr = os.Remove(\"source.txt\")\n\tif err != nil {\n\t\treturn\n\t}\n\n\terr = os.Remove(\"new.txt\")\n\tif err != nil {\n\t\treturn\n\t}\n}\n```\n\n### RPC\n\nFor details of what RPC means, see: https://gist.github.com/Integralist/f5856b94e002bcfd4ce7\n\nOnly methods that satisfy these criteria will be made available for remote access; other methods will be ignored:\n\n- the method's type is exported.\n- the method is exported.\n- the method has two arguments, both exported (or builtin) types.\n- the method's second argument is a pointer.\n- the method has return type error.\n\nIn effect, the method must look schematically like\n\n```go\nfunc (t *T) MethodName(argType T1, replyType *T2) error\n```\n\nThe setup for a simple RPC example is:\n\n1. Create remote package Foo that will consist of functions to be made available via RPC\n2. Create remote package that will expose package Foo\n3. Create client package that connects to remote via RPC\n\nThere are two variations:\n\n1. RPC over HTTP\n2. RPC over TCP\n\n#### HTTP\n\nSo here is the package that consists of functions to be made available via RPC:\n\n```go\npackage remote\n\nimport \"fmt\"\n\n// Args is a data structure for the incoming arguments\ntype Args struct {\n\tA, B int\n}\n\n// Arith is our functions return type\ntype Arith int\n\n// Multiply does simply multiplication on provided arguments\nfunc (t *Arith) Multiply(args *Args, reply *int) error {\n\tfmt.Printf(\"Args received: %+v\\n\", args)\n\t*reply = args.A * args.B\n\treturn nil\n}\n```\n\nHere is the remote package that exposes the other package of functionality:\n\n```go\npackage main\n\nimport (\n\t\"log\"\n\t\"net\"\n\t\"net/rpc\"\n\n\t\"github.com/integralist/rpc/remote\"\n)\n\nfunc main() {\n\tarith := new(remote.Arith)\n\n\trpc.Register(arith)\n\trpc.HandleHTTP()\n\n\tl, e := net.Listen(\"tcp\", \":1234\")\n\tif e != nil {\n\t\tlog.Fatal(\"listen error:\", e)\n\t}\n\n\trpc.Accept(l)\n}\n```\n\nHere is our client code for connecting to our remote package via RPC:\n\n```go\npackage main\n\nimport (\n\t\"fmt\"\n\t\"log\"\n\t\"net\"\n\t\"net/rpc\"\n\t\"time\"\n)\n\ntype args struct {\n\tA, B int\n}\n\nfunc main() {\n\tconn, err := net.DialTimeout(\"tcp\", \"localhost:1234\", time.Minute)\n\tif err != nil {\n\t\tlog.Fatal(\"dialing:\", err)\n\t}\n\n\tclient := rpc.NewClient(conn)\n\n\tvar reply int\n\n\te := client.Call(\"Arith.Multiply\", \u0026args{4, 2}, \u0026reply)\n\tif e != nil {\n\t\tlog.Fatalf(\"Something went wrong: %s\", err.Error())\n\t}\n\n\tfmt.Printf(\"The reply pointer value has been changed to: %d\", reply)\n}\n```\n\n#### TCP\n\nRemote RPC Function:\n\n```go\npackage remote\n\nimport \"fmt\"\n\n// Compose is our RPC functions return type\ntype Compose string\n\n// Details is our exposed RPC function\nfunc (c *Compose) Details(arg string, reply *string) error {\n\tfmt.Printf(\"Arg received: %+v\\n\", arg)\n\t*c = \"some value\"\n\t*reply = \"Blah!\"\n\treturn nil\n}\n```\n\nRemote RPC Endpoint Exposed:\n\n```go\npackage remote\n\nimport (\n\t\"fmt\"\n\t\"net\"\n\t\"net/rpc\"\n\n\t\"github.com/bbc/mozart-api-common/logger\"\n)\n\n// Endpoint exposes our RPC over TCP service\nfunc Endpoint() {\n\tcompose := new(Compose)\n\n\trpc.Register(compose)\n\t// rpc.HandleHTTP()\n\n\tlistener, err := net.Listen(\"tcp\", \":8080\")\n\tif err != nil {\n\t\tlogMessage := map[string]interface{}{\n\t\t\t\"event\":   \"FailedTCPListenerConnection\",\n\t\t\t\"message\": fmt.Sprintf(\"Listener failed to open TCP port 8080: %v\", err),\n\t\t}\n\t\tlogger.Error(logMessage)\n\t}\n\n\t// rpc.Accept(listener)\n\tfor {\n\t\tconn, err := listener.Accept()\n\t\tif err != nil {\n\t\t\tlogMessage := map[string]interface{}{\n\t\t\t\t\"event\":   \"FailedTPCIncomingConnection\",\n\t\t\t\t\"message\": fmt.Sprintf(\"Listener failed to accept an incoming connection: %v\", err),\n\t\t\t}\n\t\t\tlogger.Error(logMessage)\n\t\t}\n\n\t\tgo rpc.ServeConn(conn)\n\t}\n}\n```\n\nClient Connection over TCP to Remote RPC function:\n\n```go\npackage main\n\nimport (\n\t\"fmt\"\n\t\"log\"\n\t\"net/rpc\"\n)\n\nfunc main() {\n\tclient, err := rpc.Dial(\"tcp\", \"localhost:8080\")\n\tif err != nil {\n\t\tlog.Fatal(\"dialing:\", err)\n\t}\n\n\tvar reply string\n\n\te := client.Call(\"Compose.Details\", \"my string\", \u0026reply)\n\tif e != nil {\n\t\tlog.Fatalf(\"Something went wrong: %v\", e.Error())\n\t}\n\n\tfmt.Printf(\"The 'reply' pointer value has been changed to: %s\", reply)\n}\n```\n\n#### JSON RPC\n\nThere is another option (which is required if using another programming language to communicate with your Go RPC service), that is to turn your RPC into a JSON RPC.\n\n\u003e This is because the standard net/rpc uses https://golang.org/pkg/encoding/gob/  \n\u003e Which is a Go specific streaming binary format\n\nEffectively just use the same example as above but make the following changes:\n\n- `net/rpc` to `net/rpc/jsonrpc`\n- `rpc.Dial` to `jsonrpc.Dial`\n- `rpc.ServeConn` to `jsonrpc.ServeConn`\n\nNow your clients can connect via a TCP socket and pass over JSON, as shown in Ruby below:\n\n```ruby\nrequire \"socket\"\nrequire \"json\"\n\nsocket = TCPSocket.new \"localhost\", \"8080\"\n\n# Details of JSON structure can be found here:\n# https://golang.org/src/net/rpc/jsonrpc/client.go#L45\n# Thanks to Albert Hafvenström (@albhaf) for his help\nb = {\n  :method =\u003e \"Compose.Details\",\n  :params =\u003e [{ :Foo =\u003e \"Foo!\", :Bar =\u003e \"Bar!\" }],\n  :id     =\u003e \"0\" # id is just echo'ed back to the client\n}\n\nsocket.write(JSON.dump(b))\n\np JSON.load(socket.readline)\n\n# =\u003e {\"id\"=\u003e\"0\", \"result\"=\u003e\"Blah!\", \"error\"=\u003enil}\n```\n\nHere is an updated Go RPC:\n\n```go\npackage remote\n\nimport \"fmt\"\n\n// Args is structured around the client's provided parameters\n// The fields need to be exported too!\ntype Args struct {\n\tFoo string\n\tBar string\n}\n\n// Compose is our RPC functions return type\ntype Compose string\n\n// Details is our exposed RPC function\nfunc (c *Compose) Details(args *Args, reply *string) error {\n\tfmt.Printf(\"Args received: %+v\\n\", args)\n\t*c = \"some value\"\n\t*reply = \"Blah!\"\n\treturn nil\n}\n```\n\n### Enumerator IOTA\n\nWithin a constant declaration, the predeclared identifier `iota` represents successive untyped integer constants. It is reset to 0 whenever the reserved word `const` appears in the source.\n\n```go\npackage main\n\nimport \"fmt\"\n\nconst (\n\tfoo = iota // 0\n\tbar\n\t_ // skip this value\n\tbaz\n)\n\nconst (\n\tbeep = iota // 0 (reset)\n\tboop\n)\n\nfunc main() {\n\tfmt.Println(foo, bar, baz) // 0 1 3\n\tfmt.Println(beep, boop)    // 0 1\n}\n```\n\n### FizzBuzz\n\n```go\npackage main\n\nimport \"fmt\"\n\nfunc main() {\n\tfor i := 1; i \u003c= 100; i++ {\n\t\tif i%3 == 0 \u0026\u0026 i%5 == 0 {\n\t\t\tfmt.Printf(\"%d FizzBuzz\\n\", i)\n\t\t} else if i%3 == 0 {\n\t\t\tfmt.Printf(\"%d Fizz\\n\", i)\n\t\t} else if i%5 == 0 {\n\t\t\tfmt.Printf(\"%d Buzz\\n\", i)\n\t\t} else {\n\t\t\tfmt.Println(i)\n\t\t}\n\t}\n}\n```\n\n### Execute Shell Command\n\n```go\nvar (\n  cmdOut []byte\n  err    error\n)\ncmdName := \"spurious\"\ncmdArgs := []string{\"ports\", \"--json\"}\nif cmdOut, err = exec.Command(cmdName, cmdArgs...).Output(); err != nil {\n  fmt.Fprintln(os.Stderr, \"There was an error running 'spurious ports --json' command: \", err)\n  os.Exit(1)\n}\nfmt.Println(string(cmdOut))\n```\n\n### New Instance Idiom\n\n```go\npackage main\n\nimport \"fmt\"\n\ntype Sqs struct {\n\tfoo string\n}\n\nfunc (s *Sqs) create() {\n\tfmt.Println(\"I'll create stuff\")\n}\n\nfunc NewSqs() *Sqs {\n\treturn \u0026Sqs{\"bop\"}\n}\n\nfunc main() {\n\ts := NewSqs()\n\tfmt.Println(s.foo)\n\ts.create()\n}\n```\n\n### Mutating Values\n\n```go\npackage main\n\nimport \"fmt\"\n\ntype Compose string\n\nfunc (c *Compose) Details() string {\n\t*c = \"beep boop\"\n\treturn fmt.Sprintf(\"Here are your details: %v\", *c)\n}\n\nfunc main() {\n\tvar c Compose\n\tc = \"hai\"\n\tfmt.Printf(\"c: %+v\\n\", c) // c\n\tfmt.Println(c.Details())\n\tfmt.Printf(\"c: %+v\\n\", c) // beep boop\n}\n```\n\n### Draining Connections\n\nWhen using `json.NewDecoder`:\n\n```go\nfunc main() {\n    http.HandleFunc(\"/\", func(w http.ResponseWriter, r *http.Request) {\n        var u User\n        if r.Body == nil {\n            http.Error(w, \"Please send a request body\", 400)\n            return\n        }\n        err := json.NewDecoder(r.Body).Decode(\u0026u)\n        if err != nil {\n            http.Error(w, err.Error(), 400)\n            return\n        }\n        fmt.Println(u.Id)\n    })\n    log.Fatal(http.ListenAndServe(\":8080\", nil))\n}\n```\n\n...it doesn't read the response Body completely. So when closing the response you might get an error as a stray `\\n` could be present later on. You'll need to drain the response instead:\n\n```go\ndefer func() {\n  io.CopyN(ioutil.Discard, r.Body, 512)\n  r.Body.Close()\n}()\n```\n\n\u003e Note: https://github.com/google/go-github/pull/317\n","tags":""},{"id":"29580a0cf6d17ef2f446","title":"JS \"pass by\"","content":"function passPrimitive(arg) {\n    arg = \"new\"\n}\n\nfunction passArray(arg) {\n    arg.push(\"new\")\n}\n\nfunction passObject(arg) {\n    arg.x = \"y\"\n}\n\nfunction functionPropertyAttributes(arg) {\n    arg = [\"completely\", \"new\", \"array\"]\n}\n\nvar primitive = 123\npassPrimitive(primitive) // primitive is still = 123 (primitives are passed by value)\n\nvar array = [\"x\", \"y\", \"z\"]\npassArray(array) // array is now = [\"x\", \"y\", \"z\", \"new\"] as we passed a reference\n\nvar object = { \"key\": \"value\" }\npassObject(object) // =\u003e object is now = { \"key\": \"value\", \"x\": \"y\" } as we passed a reference\n\nvar another_array = [\"a\", \"b\", \"c\"]\nfunctionPropertyAttributes(another_array) \n// =\u003e another_array is still = [\"a\", \"b\", \"c\"] as we didn't modify the referenced Array passed to the function\n// In this example we assigned a new Array to a local variable \"arg\" rather than modifying the referenced object\n\n/*\nPrimitives are passed by value\nObjects/Arrays (which are just objects) are passed by reference\n*/\n","tags":""},{"id":"b675a263897680e02fbd","title":"Go Guardfile: `bundle exec guard`","content":"source \"https://rubygems.org\"\n\ngem \"guard\"\ngem \"guard-shell\"\ngem \"terminal-notifier\" # brew upgrade terminal-notifier\ngem \"terminal-notifier-guard\"\nrequire \"terminal-notifier-guard\"\n\nguard :shell do\n  watch(/(.*).go/) do |m|\n    puts \"m: #{m}\" # m: [\"file-that-was-modified\", \"folder-file-sits-inside\"]\n    \n    issues = \"\"\n\n    `golint #{m.first}`.tap { |res| issues = res }\n\n    puts \"\\nissues:\\n#{issues}\" unless issues.empty?\n\n    `go run #{m.first}` if issues.empty?\n  end\nend\n\n","tags":""},{"id":"a6f9e207314a91da13f5","title":"Ruby Gems Docker","content":"cp -r /Users/markmcdonnell/.gem/jruby/1.9.3/gems ./src/.gems\n\nexport GEM_PATH=\"/foo/src/.gems\"\n\ndocker run -v /Users/markmcdonnell/Code/foo:/foo \\\n           -w /foo/src \\\n           -e \"GEM_HOME=$GEM_PATH\" \\\n           -e \"GEM_PATH=$GEM_PATH\" \\\n           jruby:1.7 sh \\\n           -c \"gem install bundler \u0026\u0026 bundle install \u0026\u0026 ruby bar.rb\"\n","tags":""},{"id":"a83752c51a4736230d85","title":"Ruby Faraday SSL","content":"require \"faraday\"\nrequire \"openssl\"\n\nconnection = Faraday.new \"https://some.domain.co.uk:443\", :ssl =\u003e {\n  :client_cert =\u003e OpenSSL::X509::Certificate.new(File.read(ENV[\"DEV_CERT_PEM\"])),\n  :client_key  =\u003e OpenSSL::PKey::RSA.new(File.read(ENV[\"DEV_CERT_PEM\"])),\n  :verify =\u003e false\n}\n\nresponse = connection.get \"my/endpoint/for/some/domain\"\nbody = response.body\n","tags":""},{"id":"6c8bfed1550ec8b9933e","title":"Netcat","content":"Install the netcat `nc` command with Homebrew (otherwise Mac OS X version is really old and the interface is different):\n\n```bash\nbrew install netcat\n```\n\nUse netcat to listen for incoming TCP connections on port 3000:\n\n```bash\nnc -l -p 3000\n```\n\n\u003e Note: old versions of netcat consider using `-l` and `-p` incorrect usage  \n\u003e e.g. this would work instead for old versions of netcat `nc -l 3000`\n\nThis instance of netcat is considered a \"listener\" and is now waiting for a connection. \n\nOnce you connect to the listener, the connection will act like a channel/pipe.\n\nUse netcat to establish a TCP connection (run in a new terminal window so as to not conflict with listening netcat instance):\n\n```bash\nnc localhost 3000\n```\n\nYou've set up both ends of the TCP connection. If you type into one of those terminal windows and hit `\u003cEnter\u003e`, you should see whatever you typed appear in the other window. Any data put through one end of the pipe will appear at the other end of the pipe.\n\nExecute `\u003cCtrl-c\u003e` to stop both netcat instances.\n\nNow, to send a HTTP request we'll need two terminal windows again. In the first we'll again be listening on port 3000:\n\n```bash\nnc -l -p 3000\n```\n\nBut this time in the other terminal window we'll use `curl` to send a HTTP request to our `localhost:3000` that netcat has set-up:\n\n```bash\ncurl http://127.0.0.1:3000/\n```\n\nNow in the listening netcat terminal window simply type the following HTML code, then press `\u003cEnter\u003e` (that's important, it doesn't work otherwise) and then stop the netcat instance by executing `\u003cCtrl-c\u003e` to see the HTML response sent back to the other terminal window where you made the initial `curl` request (you can do this in your browser as well if you want to see the HTML actually rendered):\n\n```bash\n\u003ch1\u003ehello world\u003c/h1\u003e\n```\n\nIf you try this from both the terminal and from a proper browser request, you'll notice a slight difference between sending a `curl` request and sending a HTTP request from your browser:\n\n**curl request**:\n\n```bash\nGET / HTTP/1.1\nUser-Agent: curl/7.37.1\nHost: 127.0.0.1:3000\nAccept: */*\n```\n\n**browser request**:\n\n```bash\nGET / HTTP/1.1\nHost: 127.0.0.1:3000\nConnection: keep-alive\nCache-Control: max-age=0\nAccept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8\nUser-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/38.0.2125.122 Safari/537.36\nDNT: 1\nAccept-Encoding: gzip,deflate,sdch\nAccept-Language: en-US,en;q=0.8\n```\n","tags":""},{"id":"52156c512704dd7bc5c2","title":"[Manually compile Vim] ","content":"# The build-dep command means to install all dependencies for Vim, so that we can build it\nsudo apt-get build-dep vim\n\n# Download Vim source code\nsudo apt-get install mercurial\nhg clone https://vim.googlecode.com/hg/ vim\n\n# Compile vim\ncd vim/src\n\n./configure \\\n\t--enable-perlinterp=dynamic \\\n\t--enable-pythoninterp=dynamic \\\n\t--enable-rubyinterp=dynamic \\\n\t--enable-cscope \\\n\t--enable-gui=auto \\\n\t--enable-gtk2-check \\\n\t--enable-gnome-check \\\n\t--with-features=huge \\\n\t--with-x \\\n\t--with-python-config-dir=/usr/lib/python2.7/config*\n\nmake \u0026\u0026 sudo make install\n\n# Set vim as system-wide default\nsudo update-alternatives --install /usr/bin/editor editor /usr/local/bin/vim 1\nsudo update-alternatives --config editor\n\n# `view` is Vim but read-only mode (similar to `vim -R`)\nsudo update-alternatives --install /usr/bin/view view /usr/local/bin/view 1\nsudo update-alternatives --config view\n\ncd ../../\n\n# Cleanup\nrm -r vim\n\n# ENABLED FEATURES:\n# +arabic\n# +file_in_path\n# +mouse_sgr\n# +tag_binary\n# +autocmd\n# +find_in_path\n# -mouse_sysmouse\n# +tag_old_static\n# +balloon_eval\n# +float\n# +mouse_urxvt\n# -tag_any_white\n# +browse\n# +folding\n# +mouse_xterm\n# -tcl\n# ++builtin_terms\n# -footer\n# +multi_byte\n# +terminfo\n# +byte_offset\n# +fork()\n# +multi_lang\n# +termresponse\n# +cindent\n# +gettext \n# -mzscheme \n# +textobjects \n# +clientserver \n# -hangul_input \n# +netbeans_intg \n# +title \n# +clipboard \n# +iconv \n# +path_extra \n# +toolbar \n# +cmdline_compl \n# +insert_expand \n# +perl/dyn \n# +user_commands \n# +cmdline_hist \n# +jumplist \n# +persistent_undo \n# +vertsplit \n# +cmdline_info \n# +keymap \n# +postscript \n# +virtualedit \n# +comments \n# +langmap \n# +printer \n# +visual \n# +conceal \n# +libcall \n# +profile \n# +visualextra \n# +cryptv \n# +linebreak \n# +python/dyn \n# +viminfo \n# +cscope \n# +lispindent \n# -python3 \n# +vreplace \n# +cursorbind \n# +listcmds \n# +quickfix \n# +wildignore \n# +cursorshape \n# +localmap \n# +reltime \n# +wildmenu \n# +dialog_con_gui \n# -lua \n# +rightleft \n# +windows \n# +diff \n# +menu \n# +ruby/dyn \n# +writebackup \n# +digraphs \n# +mksession \n# +scrollbind \n# +X11 \n# +dnd \n# +modify_fname \n# +signs \n# -xfontset \n# -ebcdic \n# +mouse \n# +smartindent \n# +xim \n# +emacs_tags \n# +mouseshape \n# -sniff \n# +xsmp_interact \n# +eval \n# +mouse_dec \n# +startuptime \n# +xterm_clipboard \n# +ex_extra \n# +mouse_gpm \n# +statusline \n# -xterm_save \n# +extra_search \n# -mouse_jsbterm \n# -sun_workshop\n# +farsi \n# +mouse_netterm \n# +syntax\nFROM golang:1.8\n\nRUN apt-get update -y\nRUN apt-get install -y wget git ncurses-dev\n\nWORKDIR /tmp\nRUN git clone https://github.com/vim/vim.git\nRUN cd vim \u0026\u0026 make \u0026\u0026 make install\nThe key ingredient for getting compilation of vim to work is to tell the compilation script which Python3 version you want to use, but that telling it what to use by itself won't work if it's trying to use 'cached' layers (kinda like Docker caches operations in layers to make future runs quicker).\n\nSo now whenever I'm compiling Vim I'm cleaning out the cache (see the first line in the below script)...\n\n```bash\nmake clean distclean\n\n./configure --with-features=huge \\\n  --enable-multibyte \\\n  --enable-rubyinterp=yes \\\n  --enable-python3interp=yes \\\n  --with-python3-command=/usr/local/Cellar/python/3.7.7/Frameworks/Python.framework/Versions/3.7/bin/python3.7 \\\n  --with-python3-config-dir=/usr/local/Cellar/python/3.7.7/Frameworks/Python.framework/Versions/3.7/lib/python3.7/config-3.7m-darwin/ \\\n  --enable-perlinterp=yes \\\n  --enable-luainterp=yes \\\n  --enable-gui=gtk2 \\\n  --enable-cscope \\\n  --prefix=/usr/local\n\nmake \u0026\u0026 make install\n```\n\nThe key flags are...\n\n- ` --enable-python3interp=yes`: tell the compilation you want Python3 support\n- `--with-python3-command`: give it a path to a Python3 interpreter/binary (†)\n- `--with-python3-config-dir`: a configuration directory used by the version of Python3 you want to use.\n\n\u003e † e.g. if I run that full path in my terminal shell it'll actually run the Python3 REPL so I know it's a valid path to provide.\n","tags":"#tags: vim, compile"},{"id":"24da7316dee1ba00bd66","title":"JIRA API creating a ticket/issue","content":"require 'restclient'\nrequire 'json'\n \nclass Client\n  def self.client\n    @client ||= RestClient::Resource.new('https://jira.mydomain.com/rest/api/latest/issue/',\n      \"ssl_version\": 'TLSv1',\n      \"ssl_client_cert\": OpenSSL::X509::Certificate.new(File.read('certificate.pem')),\n      \"ssl_client_key\": OpenSSL::PKey::RSA.new(File.read('certificate.pem'), ''),\n      \"ssl_ca_file\": 'ca.pem',\n      \"verify_ssl\": OpenSSL::SSL::VERIFY_NONE,\n      \"content_type\": 'application/json'\n    )\n  end\n \n  def self.post\n    client.post(File.read('test.json'), content_type: 'application/json', accept: :json)\n  end\nend\n \nputs Client.post\n{\n    \"fields\": {\n       \"project\":\n       {\n          \"key\": \"NEWS\"\n       },\n       \"summary\": \"This is a test please ignore\",\n       \"description\": \"Creating an issue using Jira's REST API\",\n       \"issuetype\": {\n          \"name\": \"Backlog Item\"\n       }\n   }\n}\n","tags":""},{"id":"66aa5635fb388934822c","title":"Ruby JSON Schema Generator and Validator","content":"require \"faraday\"\nrequire \"json-schema\"\nrequire \"json-schema-generator\"\n\nconnection = Faraday.new \"http://some.domain.co.uk\"\nresponse   = connection.get \"some/endpoint\"\nbody       = response.body\nfixture    = IO.read \"path/to/my/fixture/data.json\"\nschema     = JSON::SchemaGenerator.generate \"my schema\", body, { :schema_version =\u003e \"draft3\" }\nresults    = JSON::Validator.fully_validate schema, fixture\n","tags":""},{"id":"e4cc5e0816fbb6b64142","title":"Server-Sent Events in Ruby","content":"require \"json\"\nrequire \"sinatra/base\"\n\nclass ApplicationController \u003c Sinatra::Base\n  helpers ApplicationHelper\n\n  set :views, File.expand_path(\"../../views\", __FILE__)\n  set :public_folder, File.expand_path(\"../../\", __FILE__)\n  set :server, :thin\n  connections = []\n\n  before do\n    request.path_info.sub! %r{/$}, \"\"\n  end\n\n  not_found do\n    title \"Not found!\"\n    erb :not_found\n  end\n\n  error do\n    title \"Error\"\n    erb :error\n  end\n\n  get \"/\" do\n    erb :home\n  end\n\n  get \"/status\" do\n    \"ok\"\n  end\n\n  post \"/update\" do\n    json = request.body.read # can't read `params` as we're not POST'ing key/value pairs\n\n    connections.each do |out|\n      out \u003c\u003c \"id: #{Time.now}\\n\" +\n             \"event: ping\\n\" +\n             \"data: #{json}\\n\\n\" unless out.closed?\n    end\n  end\n\n  get \"/healthcheck\", provides: \"text/event-stream\" do\n    stream :keep_open do |out|\n      connections \u003c\u003c out\n\n      # `callback` is executed each time a stream connection closes\n      out.callback {\n        connections.delete(out)\n      }\n    end\n  end\nend\nvar evtSource = new EventSource(\"/healthcheck\");\n\nevtSource.onmessage = function(e) {\n    console.log(\"onmessage\", e.data);\n};\n\nevtSource.addEventListener(\"ping\", function(e) {\n    console.log(\"ping\", e.data);\n}, false);\n\nevtSource.onerror = function(e) {\n    console.log(\"error\", e);\n};\ncurl -v -H \"Content-Type: application/json\" -X POST -d '{\"foo\":\"bar\"}' http://127.0.0.1:9292/update\n","tags":""},{"id":"11282503","title":"Loop recursively through a multi-level array using the SPL (Standard PHP Library) RecursiveArrayIterator","content":"\u003c?php\n    $multilevelArray = array(\n        \"a\" =\u003e array(\n            \"i\"   =\u003e \"aa\",\n            \"ii\"  =\u003e \"bb\",\n            \"url\" =\u003e \"http://www.integralist.co.uk/\",\n            \"iii\" =\u003e \"cc\"\n        ),\n        \"b\"   =\u003e \"c\",\n        \"url\" =\u003e \"http://www.github.com/\"\n    );\n    $counter = 0;\n    $array_obj = new RecursiveIteratorIterator(new RecursiveArrayIterator($multilevelArray));\n\n    foreach($array_obj as $key =\u003e $value) {\n        if ($key == 'url') {\n            $counter++;\n        }\n    }\n\n    echo $counter; // =\u003e 2\n?\u003e\n","tags":""},{"id":"11376734","title":"Clojure destructuring using `let` (which allows local storage inside of a function, we would say a local \"variable\" but that would be misleading because all data is immutable in Clojure)","content":"In Clojure you can apply destructuring within either a `let` binding list; function parameter list or even a macro.\n\nA simple example would be:\n\n```clj\n(def coords [5 7]) ; define a symbol \"coords\" that points to a vector [5 7]\n(let [[x y] coords] (println \"x:\" x \"y:\" y))\n; =\u003e x: 5 y: 7\n```\n\nAnother simple example (this time using the `\u0026` rest operator) would be:\n\n```clj\n(def indexes [1 2 3])\n(let [[x \u0026 more] indexes] (println \"x:\" x \"more:\" more))\n; =\u003e x: 1 more: (2 3)\n```\n\nA complex example (which utilises `:as e` to assign the entire item being destructured into `e`):\n\n```clj\n(def indexes [1 2 3 4 5 6 7])\n(let [[a b c \u0026 d :as e] indexes]\n  [a b c d e])\n; =\u003e [1 2 3 (4 5 6 7) [1 2 3 4 5 6 7]]\n```\n\nAlthough possible to do nested destructuring, it is advised not to nest as it can become too complex:\n\n```clj\n(def nested [[1 2][3 4]])\n(let [[[x1 y1][x2 y2]] nested]\n  [x1 x2 y1 y2])\n; =\u003e [1 3 2 4]\n```\n\nHere is an example that uses `:or` to provide default values for keys that can't be found in the data being destructured (you'll notice that the `b` key wasn't provided and so we received the default value of `22` instead):\n\n```clj\n(def a-map {:a 1 :c 3})\n(let [{a :a, b :b, c :c, :as original-data :or {a 11 b 22 c 33}} a-map]\n  [a b c original-data])\n; =\u003e [1 22 3 {:a 1, :c 3}]\n```\n\nIn the following example we see the use of `:keys` as a shortcut way of not having to redefine the same keys ourselves (typically when destructuring data you'll end up saying something like \"give me the value for key 'a' and just put it in this other place called 'a'\" - so Clojure provides a shortcut for that). This example also demonstrates what happens if no default is provided:\n\n```clj\n(def a-map {:a 1 :c 3})\n(let [{:keys [a b c]} a-map]\n  [a b c])\n; =\u003e [1 nil 3]\n```\n\nNested map destructuring (whatever the type is - in this example a map - use that syntax to delve deeper into the structure):\n\n```clj\n(def test {:params {:foo \"bar\" :baz \"qux\"}})\n(let [{{foo :foo} :params} test] \n  (prn foo))\n```\n","tags":""},{"id":"971b4192aa5c8ef7bae4","title":"Download and Install htop command","content":"http://pkgs.repoforge.org/htop/ curl \\\n-L http://pkgs.repoforge.org/htop/htop-1.0.3-1.el6.rf.x86_64.rpm \\\n-o /tmp/test.rpm \u0026\u0026 \\\nsudo rpm -i /tmp/test.rpm \u0026\u0026 \\\nhtop\n\ncurl -L http://pkgs.repoforge.org/htop/htop-1.0.2-1.el6.rf.x86_64.rpm -o /tmp/test.rpm  \u0026\u0026 sudo rpm -i /tmp/test.rpm \u0026\u0026 htop\n","tags":""},{"id":"11394651","title":"Clojure's \"Thread First\" and \"Thread Last\" macros","content":"In Clojure macros are executed *before* code is evaluated. Macros allow us to manipulate the program being compiled. There are two macros in particular that I like to demonstrate why this is useful:\n\n- Thread First `-\u003e`\n- Thread Last `-\u003e\u003e`\n\n\u003e Note: in Clojure sequence data structures (lists \u0026 vectors) are usually the last item in an argument list; where as map data structures are usually the first argument in an argument list\n\n## Thread First\n\nOur original program requires us to effectively read it \"inside out\":\n\n```clj\n(dissoc\n  (assoc \n    {:name \"Jonathan\" :password \"secret\"} \n    :nickname \"Jon\") \n  :password)\n\n; =\u003e {:nickname \"Jon\", :name \"Jonathan\"}\n```\n\nBut as humans we prefer to read things the other way around (this is where Thread First can help):\n\n```clj\n(-\u003e {:name \"Jonathan\" :password \"secret\"}\n    (assoc :nickname \"Jon\")\n    (dissoc :password))\n\n; =\u003e {:nickname \"Jon\", :name \"Jonathan\"} \n```\n\nAs you can see, we're telling it to pass the map data structure as the first argument to each of the subsequent lists to be processed. This allows us to read the code in a more natural flow. But as macros are run *before* code is evaluated, Clojure will receive it in its original form and evaluate that original code.\n\n## Thread Last\n\nThis macro works the same way but for sequences (see the `Note` above).\n\n```clj\n(reduce + (filter odd? (map inc (range 10))))\n\n; you can write it long form if you prefer:\n(reduce + \n  (filter odd? \n    (map inc \n      (range 10))))\n\n; =\u003e 25\n```\n\nAnd now rewritten in a more natural flow...\n\n```clj\n(-\u003e\u003e (range 10) (map inc) (filter odd?) (reduce +))\n\n; you can write it long form if you prefer:\n(-\u003e\u003e (range 10)\n     (map inc)\n     (filter odd?)\n     (reduce +))\n\n; =\u003e 25\n```\n","tags":""},{"id":"9251201","title":"In Ruby using the `\u003c\u003c` operator as a method identifier has special meaning. It allows us to call the method without using a period (so we can do `foo \u003c\u003c \"abc\"` and not have to do `foo.\u003c\u003c \"abc\"`)","content":"class Foo\n  def \u003c\u003c(something)\n    puts something\n  end\n\n  def say(something)\n    puts something\n  end\nend\n\nfoo = Foo.new\n\nfoo.\u003c\u003c(\"hi\") # =\u003e hi\nfoo.\u003c\u003c \"hi\"  # =\u003e hi\nfoo \u003c\u003c \"hi\"  # =\u003e hi\n\nfoo.say(\"hi\") # =\u003e hi\nfoo.say \"hi\"  # =\u003e hi\nfoo say \"hi\"  # =\u003e NoMethodError: undefined method `say' for main:Object\n","tags":""},{"id":"9346221","title":"[Example of POST'ing data via Curl command] ","content":"curl -v \\\n     -H \"Content-Type: application/json\" \\\n     -X POST \\\n     -d '{\"components\":[{\"component\":\"election_data/england_council_list\",\"variant\":\"GS1000008\"},{\"component\":\"election_data/england_council_results_table\",\"variant\":\"GS1000008\"}]}' \\\n     http://localhost:9292/post/component/england_council_results\n     \n# -d data can also be urlencoded form params like so:\n\ncurl -v -H 'X-Auth-Token:123' -d \"foo=bar\u0026beep=boop\" https://api.example.com/some/thing\n- `-v` == verbose\n- `-H` == mime type\n- `-X` == header\n- `-d` == data\n","tags":"#curl #post #body"},{"id":"9251386","title":"Passing through key and value to a reduce method block rather than just the item","content":"# As expected the output is the key, then the value...\n\n({ :key =\u003e :value, :foo =\u003e :bar }).reduce([]) { |pass_through, item|\n  puts item\n}\n\n# key\n# value\n# foo\n# bar\n\n# The following example is better, as we get the key AND value passed through at once...\n\n({ :key =\u003e :value, :foo =\u003e :bar }).reduce([]) { |pass_through, (item_key, item_val) |\n  puts \"#{item_key} / #{item_val}\"\n}\n\n# key / value\n# foo / bar\n","tags":""},{"id":"7974887","title":"S.O.L.I.D principles","content":"# S.O.L.I.D principles\n\n- [Single Responsibility Principle](#single-responsibility-principle)\n- [Open/Closed Principle](#openclosed-principle)\n- [Liskov Substitution Principle](#liskov-substitution-principle)\n- [Interface Segregation Principle](#interface-segregation-principle)\n- [Dependency Inversion Principle](#dependency-inversion-principle)\n\n## Single Responsibility Principle\n\nA class or method should have no more than one responsibility. If it has more than one responsibility then use the relevant refactoring technique(s) to extract the functionality into its own class or method.\n\n## Open/Closed Principle\n\nAn object should be 'open to extension' but 'closed for modification'.\n\nHere is a class that violates this principle...\n\n```ruby\nrequire 'json'\n\nclass Report\n  def body\n    { :a =\u003e 'Anna', :b =\u003e 'Bob', :c =\u003e 'Chris' }\n  end\n\n  def print\n    body.to_json\n  end\nend\n```\n\n...it violates the principle because if we want to extend the class to report the data in a different format, we can't without modifying the source class.\n\nTo fix this we can use dependency injection...\n\n```ruby\nrequire 'json'\n\nclass Report\n  def body\n    { :a =\u003e 'Anna', :b =\u003e 'Bob', :c =\u003e 'Chris' }\n  end\n\n  def print(formatter: JSONFormatter.new)\n    formatter.format(body)\n  end\nend\n\nreport = Report.new\nreport.print(formatter: XMLFormatter.new)\n```\n\n...notice we inject a specific class to handle the required formatting. \n\nThis means we can extend the class without modifying it.\n\n## Liskov Substitution Principle\n\nThis principle only applies to code that uses inheritance. The reason why is because the principle states a subtype must be substitutable/interchangeable for their base class.\n\nThe benefit of this principle is that when code is interchangeable, it becomes more reusable.\n\nThe following code violates this principle...\n\n```ruby\nclass Animal\n  def walk\n     # do some walking\n  end\nend\n\nclass Cat \u003c Animal\n  def run\n    # do some cat style running\n  end\nend\n```\n\n...it violates the principle because the subclass implements a `run` method that doesn't appear in the base class.\n\nThe solution is based on the use of interfaces, but as Ruby doesn't implement interfaces or abstract classes we instead create empty methods for each part of the proposed interface. \n\n```ruby\nclass Animal\n  def walk\n     # do some walking\n  end\n\n  def run\n     raise NotImplementedError\n  end\nend\n\nclass Cat \u003c Animal\n  def run\n    # do some cat style running\n  end\nend\n```\n\n## Interface Segregation Principle\n\nIf a class uses an interface, then that interface should only contain methods or properties used by its consumers. If the interface has too much functionality then any change to the interface will effect more consumers than it probably needs to (meaning more chance for errors to occur).\n\nTake a look at the following code...\n\n```ruby\nclass Car\n  def open; end\n  def start_engine; end\n  def change_engine; end\nend\n\nclass Driver\n  def drive\n    # use `Car.open` and `Car.start_engine`\n  end\nend\n\nclass Mechanic\n  def do_stuff\n    # use `Car.change_engine`\n  end\nend\n```\n\n...this code violates the principle because the `Car` class has methods that are partially used by both `Driver` and `Mechanic`.\n\nTo fix this we split our interface into two interfaces...\n\n```ruby\nclass Car\n  def open; end\n  def start_engine; end\nend\n\nclass CarInternals\n  def change_engine; end\nend\n\nclass Driver\n  def drive\n    # use `Car.open` and `Car.start_engine`\n  end\nend\n\nclass Mechanic\n  def do_stuff\n    # use `CarInternals.change_engine`\n  end\nend\n```\n\n## Dependency Inversion Principle\n\nObjects should depend on abstractions. If they do so then the implementation of the abstractions can be changed without safely without affecting the code consuming the abstractions.\n\nOne way to conform to this principle is to use \"dependency injection\", which we saw this used in the solution for OCP (Open/Closed Principle).\n\nDependency Injection is one part of the solution. See this example: https://gist.github.com/Integralist/5763515 and you'll notice that DIP relies on the use of Interfaces (or in Ruby's case \"duck typing\") to decouple the consuming code and the injected dependency (e.g. using an Interface allows any object that implements that interface to be injected into the consuming object).\n","tags":""},{"id":"9041051","title":"How to clone a Hash (in Ruby) and modify the cloned hash without affecting the original object","content":"# This is the ONLY way I've found that works \n# All other suggested solutions (see below examples) don't actually work\n# And as an extra bonus: this deep copies as well!\n\ndef deep_copy(o)\n  Marshal.load(Marshal.dump(o))\nend\ndef test(some_data)\n  some_data.each { |k, v| some_data.tap { |d| d[k].upcase! } }\nend\n\nblah = { :foo =\u003e 'bar' }\n\nblah_clone = blah.clone # cloning the hash so we affect the clone and not the original\n\ntest(blah_clone) # cloned hash has been changed as expected =\u003e {:foo=\u003e\"BAR\"}\n\nblah # shouldn't be touched but =\u003e {:foo=\u003e\"BAR\"}\n\n#########################################################################################\n\n# I've also tried the following (straight copied from a stack overflow answer which is supposed to work but doesn't)...\n\ndef copyhash(inputhash)\n  h = Hash.new\n  inputhash.each do |pair|\n    h.store(pair[0], pair[1])\n  end\n  return h\nend\n\noriginal = { :key =\u003e 'foobar' }\ntest = copyhash(original)\ntest[:key].upcase!\n\ntest # =\u003e {:key=\u003e\"FOOBAR\"}\noriginal # =\u003e {:key=\u003e\"FOOBAR\"}\n\n#########################################################################################\n\n# The following also doesn't work...\n\noriginal = { :key =\u003e 'foobar' }\n\ntest = Hash[original]\n\noriginal.object_id # =\u003e 2262\ntest.object_id     # =\u003e 2268\n\ntest[:key].upcase! # =\u003e \"FOOBAR\"\n\ntest     =\u003e {:key=\u003e\"FOOBAR\"}\noriginal =\u003e {:key=\u003e\"FOOBAR\"}\n\n#########################################################################################\n\n# The following also doesn't work...\n\nh0 = {  \"John\"=\u003e\"Adams\",\"Thomas\"=\u003e\"Jefferson\",\"Johny\"=\u003e\"Appleseed\"}\nh1 = h0.inject({}) do |new, (name, value)| \n    new[name] = value;\n    new \nend\n\nh1[\"John\"].upcase!\n\nh0[\"John\"] # =\u003e \"ADAMS\"\nh1[\"John\"] # =\u003e \"ADAMS\"\n\n#########################################################################################\n\n\n","tags":""},{"id":"11246383","title":"JS Tail Call Optimisation","content":"## The problem\n\nIf a function calls itself recursively then the JavaScript engine has to create a new 'stack' (i.e. allocate a chunk of memory) to keep track of the function's arguments.\n\nLet's look at an example of this happening:\n\n```js\nfunction sum(x, y) {\n    if (y \u003e 0) {\n      return sum(x + 1, y - 1);\n    } else {\n      return x;\n    }\n}\n\nsum(1, 10); // =\u003e 11\n```\n\nIn the above code, the JavaScript engine has to create a new stack for each recursive call. \n\nThis happens because the original call to the `sum` function (i.e. `sum(1, 10)`) doesn't complete until the very *last* call to `sum` returns the value of `x`. Then `x` is returned to the caller and that caller returns `x` to its caller, all the way back to the very first call to `sum` where by it returns the result of the line `return sum(x + 1, y - 1);` (which ultimately was the value of `x` passed along from the last call to `sum`).\n\nIf we create a stack deep enough (e.g. `sum(1, 100000)`) then the JavaScript engine will throw a `RangeError: Maximum call stack size exceeded`.\n\n## The solution\n\nThe fix to this problem is to use fewer stacks. \n\nTo achieve this we could rewrite the code to not be recursive; so in other words: use a loop!\n\nThe problem with using a loop is that it's not as elegant (or clean/easy to read) as the recursive style of functional programming.\n\nAnother solution is to use a type of functional pattern called \"trampolining\". Let's take a look at one implementation of it...\n\n## Example solution\n\n```js\nfunction tco(f) {\n    var value;\n    var active = false;\n    var accumulated = [];\n\n    return function accumulator() {\n        accumulated.push(arguments);\n\n        if (!active) {\n            active = true;\n\n            while (accumulated.length) {\n                value = f.apply(this, accumulated.shift());\n            }\n\n            active = false;\n\n            return value;\n        }\n    }\n}\n\nvar sum = tco(function(x, y) {\n    if (y \u003e 0) {\n      return sum(x + 1, y - 1)\n    }\n    else {\n      return x\n    }\n});\n\nsum(1, 100000) // =\u003e 100001\n```\n\nHere we've written a `tco` function which wraps around the same code we had previously.\n\n## Explanation\n\nThis could take some time to wrap your head around (lord knows it took me long enough), so if you don't get it the first time around then it's probably best to execute the above code via your browsers developer tools and use a `debugger` statement to step through the code whilst reading this explanation...\n\n\u003e Note: the above code is an abstraction I found here: https://gist.github.com/Gozala/1697037. It makes tail call optimising any function really easy.\n\n- We store the result of calling `tco` (wrapped around our code) into the `sum` variable.\n- The `sum` variable is now a function expression that when called (e.g. `sum(1, 10)`) will execute the `accumulator` function that `tco` returned.\n- The `accumulator` is a closure (meaning when we call `sum` the `accumulator` will have access to the variables defined inside of `tco` -\u003e `value`, `active` and `accumulated`; as well as our own code which is accessible via the identifier `f`).\n- When we call `sum` for the first time (e.g. `sum(1, 10)`) we indirectly execute `accumulator`.\n- The first thing we do inside of `accumulator` is push the arguments object (and Array-like object) into the `accumulated` Array (so the `accumulated` will now have a length of 1).\n- It's worth knowing that the `accumulated` Array only ever has 1 item inside of it (as we'll soon see).\n- The `active` variable by default is `false`. So as `accumulator` is called for the first time, we end up inside the `if` conditional, and then reset `active` to `true`.\n- Now we get to a `while` loop (we're still calling functions recursively, as you'll see in a moment; but this is a very clean loop compared to an ugly for loop with lots of operators/operands).\n- The `while` loop simply checks whether the `accumulated` Array has any content. If it does then we call the `f` function and pass through the arguments that were inside `accumulated[0]` (for the first run of this function that would've been `[1, 10]`).\n- When we pass the contents of `accumulated[0]` we use the `shift` Array method to actually remove it from the `accumulated` Array so it now has a length of zero.\n- If we ignore for a moment the code inside the loop; on the next iteration of this loop the condition of `accumulated.length` will fail and so we would end up setting `active` to `false` and ultimately return to `sum` the value of the variable `value`.\n- This is where it gets confusing, but hold tight!\n- The `f` function is our own code. Our own code calls the `sum` function (which indirectly calls the `accumulator` function).\n\n**The secret sauce to this entire chunk of code is coming up!**\n\n- If our code returns `x` then the `while` loop will stop (I'll explain why in a moment). \n- If our code can't return `x` (notice our code has a conditional check to see if `y` is greater than zero, if it is then we return `x`, otherwise...) we call `sum` again and pass through modified arguments. \n- This time when we call `sum` we don't get inside of the `if` conditional because `active` is already set to `true`. \n- So the purpose of calling `sum` from inside our own code is simply to allow us to store the newly modified arguments inside the `accumulated` Array. \n- The `sum` function then returns `undefined` (as we weren't able to move into the `if` conditional)\n- The flow of control then throws us back into the original `while` loop (that's still going, it hasn't stopped yet) and `undefined` is what's stored into the `value` variable.\n- At this point the `accumulated` Array has once again got some content and so the `while` loop's condition passes once more.\n- And *that* is where the recursive magic happens. At some point our code is going to call `sum` with the `y` argument set to zero meaning that when the `accumulator` function calls our code the condition `y \u003e 0` will fail and so we return the value of `x` (which has been incremented each time along the way).\n- When that happens, `x` is returned and assigned as the value to the `value` variable, and so our code never called `sum` and thus the `accumulated` Array is never modified again; meaning the `while` loop condition inside the `accumulator` function will fail and thus the `accumulator` function will end returning whatever value is stored inside the `value` variable (which in this example is the value of `x`).\n\n## Alternative implementations?\n\nThere is another implementation I've seen which is much simpler to understand but not necessarily as easy to abstract like the `tco` method above. \n\nLet's take a look at the code first (note: my explanation assumes an understanding of the `this` keyword and changing its context, if you're unsure then read more about it [here](https://github.com/getify/You-Dont-Know-JS/blob/master/this%20\u0026%20object%20prototypes/README.md)):\n\n```js\nfunction trampoline(f) {\n    while (f \u0026\u0026 f instanceof Function) {\n        f = f();\n    }\n    return f;\n}\n\nfunction sum(x, y) {\n    function recur(x, y) {\n        if (y \u003e 0) {\n          return recur.bind(null, x + 1, y - 1);\n        } else {\n          return x;\n        }\n    }\n\n    return trampoline(recur.bind(null, x, y));\n}\n\nsum(1, 10); // =\u003e 11\n```\n\nIt breaks down like this...\n\n- We call `sum(1, 10)`.\n- Our `sum` function ultimately returns a value. In this case whatever is returned by calling the `trampoline` function.\n- The `trampoline` function accepts a *reference* to a function as its argument (it's important to understand it needs a *reference* to a function; doing `return trampoline(recur(x, y))` wouldn't work as that would end up just passing the result of calling `recur(x, y)` to the `trampoline` function).\n- So we use `Function#bind` to pass a reference to the `recur` function (we use `null` as the `this` binding because it doesn't matter what the context the function executes in as we don't use the function as a constructor).\n- When we execute `sum(1, 10)` we pass the reference to the internal `recur` method to the `trampoline` function.\n- The `trampoline` function checks if we passed a function and if so we execute the function and store its return value inside the `f` variable.\n- If what we pass into the `trampoline` function isn't a function then we assume it's the end (i.e. accumulated) value and we just return the value straight back to the `sum` function which returns that value as the accumulated value.\n- Inside the `recur` function we check to see if `y` is greater than zero, and if it is we modify the `x` and `y` values (like we did in the previous example) and then return another reference to the `recur` function but this time with the modified `x` and `y` values.\n- Inside the `trampoline` function the newly referenced function is assigned to the `f` variable and the `while` loop on its next iteration checks to see if `f` is indeed a function or not. If it is (which it would be in this instance) we again execute the function (which is now `recur(2, 9)`) and the whole process starts again.\n- Until of course we reach the point where `y` is set to zero. Then when the `trampoline` function executes the function reference (`recur`) and inside the `if` conditional fails (as `y` is now zero and no longer greater than zero) and so we return the accumulated `x` value; which then gets sent back and stored in the `f` variable inside the `trampoline` function.\n- On the next iteration of the `while` loop, `f` is now a value and not a function and so the `while` loop ends and the accumulated value is returned to the `sum` function which returns that as its accumulated value.\n*The following is copied directly from: http://aphyr.com/tags/Clojure-from-the-ground-up and it provides an alternative explanation of the problem/solution. I've commented the Clojure code heavily for those unfamiliar with it.*\n\nEvery time you call a function, the arguments for that function are stored in memory, in a region called the stack. They remain there for as long as the function is being called (including any deeper function calls).\n\nBelow is a Clojure example (both commented and non-commented version):\n\n```clojure\n; define a multi-arity function (different code branches depending on args provided when called)\n(defn sum\n  ; arity branch 1\n  ; accepts a single argument: numbers\n  ([numbers]\n   ; the following expression/form is the body of the function\n   ; here we re-call the sum function again but provide two arguments (so we will reach the 2nd branch)\n   ; this is a defensive way to ensure a function is called correctly\n   (sum 0 numbers))\n  ; arity branch 2\n  ; accepts two arguments: subtotal and numbers\n  ; the subtotal argument acts as an 'accumulator'\n  ([subtotal numbers]\n   ; the following expression/form is the body of the function\n   ; we define an if condition (a special kind of conditional that does two things)\n   ; if the expression (first numbers) returns something truthy then store that in the n let\n   ; so we can use it within the if statement (otherwise the value of n is nil)\n   (if-let [n (first numbers)]\n     ; if condition is truthy...\n     ; recursively call this current function using the recur function\n     ; we pass in the result of two sub expressions (+ subtotal n) and (rest numbers)\n     (recur (+ subtotal n) (rest numbers))\n     ; if condition is falsey...\n     subtotal)))\n```\n\n```clojure\n(defn sum\n  ([numbers]\n   (sum 0 numbers))\n  ([subtotal numbers]\n   (if-let [n (first numbers)]\n     (recur (+ subtotal n) (rest numbers))\n     subtotal)))\n```\n\nThe result of which is...\n\n```clojure\nuser=\u003e (sum (range 100000))\n4999950000\n```\n\nWe’ve added an additional parameter to the function. In its two-argument form, sum now takes an accumulator, subtotal, which represents the count so far. In addition, recur has taken the place of sum. \n\nNotice, however, that the final expression to be evaluated is not `+`, but `sum (viz recur)` itself. We don’t need to hang on to any of the variables in this function any more, because the final return value won’t depend on them. \n\n`recur` hints to the Clojure compiler that we don’t need to hold on to the stack, and can re-use that space for other things. This is called a tail-recursive function, and it requires only a single stack frame no matter how deep the recursive calls go.\n","tags":""},{"id":"9001836","title":"Demonstrate how to handle bubbling errors by consolidating them (modified from: http://blog.ponyfoo.com/2013/07/12/teach-yourself-nodejs-in-10-steps)","content":"function sum(a, b, done) {\n    // we convert this otherwise sync function into an async function\n    // note: this forces itself into the next event loop\n    //       we should use setImmediate instead which places it at \n    //       the bottom of the current event loop stack\n    process.nextTick(function() {\n        // `done` is the callback function passed into `sum`\n        done(null, a + b)\n    });\n}\n\nfunction then(err, result) {\n    if (err) throw err\n\n    // `console.log` is an alias to stdout plus automatically adds a new line\n    // but I prefer the long format just to be explicit\n    process.stdout.write('Result: ' + result + '\\n'); // the new line prevents the shell from displaying an ugly % character\n}\n\n// if we use the typical style of error handling\n// where we throw an error from the callback handler\n// then the following example wouldn't work that great\n// because we'd be throwing multiple errors up the stack.\n// it's better if we consolidate the error handling in one place.\n// see the use of the `then` function which does this consolidation.\nsum(1, 2, function(err, result) {\n    if (err) return then(err)\n\n    sum(result, 3, function(err, result) {\n        if (err) return then(err)\n\n        then(null, result);\n    });\n});\n\n","tags":""},{"id":"8954316","title":"Ruby HEREDOC but not worrying about the crappy spacing","content":"\u003c\u003c-FOO.gsub /^\\s+/, \"\"\n    abc\n        def\n            ghi\n    jkl\nFOO\n","tags":""},{"id":"8433187","title":"Example of importing Java libraries into JRuby","content":"puts \"java.lang.System::out.println('Hello World')\"\nputs java.lang.System::out.println(\"Hello World\") # =\u003e Hello World (notice Ruby and Java on one line is possible)\n\nputs \"java.lang.System.out.println('Hello World')\"\nputs java.lang.System.out.println(\"Hello World\") # =\u003e Hello World (notice module/package syntax :: is replaceable with dot)\n\nputs \"java.lang.System::out.println 'Hello World'\"\nputs java.lang.System::out.println \"Hello World\" # =\u003e Can be Rubyistic with our code (notice no parenthesis required to execute method)\n\nputs \"java.lang.Math.methods\"\nprint java.lang.Math.methods\n\nputs \"\\n\\njava_import java.lang.System\"\nputs \"System.out.println('We've been imported')\"\njava_import java.lang.System\nputs System.out.println(\"We've been imported\")\n\nputs \"Certain Constants `java.lang.Math` can conflict with Ruby's\"\nputs \"So rename them...\"\nputs 'java_import(\"java.lang.Math\") { |package, name| \"J#{name}\" }'\nputs \"Note: you can also pass in an Array of packages\"\njava_import('java.lang.Math') { |package, name| \"J#{name}\" }\nputs JMath::PI\n\nputs \"\\nJMath.ancestors\"\nprint JMath.ancestors\n\nputs \"\\n\\nLots of good stuff in the GitHub Wiki: Calling Java from JRuby https://github.com/jruby/jruby/wiki/CallingJavaFromJRuby\"\n\n","tags":""},{"id":"8685823","title":"npm in-house registry cache using nginx","content":"`.npmrc`\n\n```\nregistry = \"http://npm.some-domain.com/\"\n```\n\n```nginx\nproxy_cache_path /app/npm/data levels=1:2 keys_zone=npm:20m max_size=1000m inactive=3d;\nproxy_temp_path /app/npm/tmp;\n\nserver {\n   listen 80;\n   server_name npm.some-domain.com;\n   location / {\n     proxy_pass https://registry.npmjs.org/;\n     proxy_cache npm;\n     proxy_cache_valid 200 302 3d;\n     proxy_cache_valid 404 1m;\n     sub_filter 'registry.npmjs.org' 'npm.some-domain.com';\n     sub_filter_once off;\n     sub_filter_types application/json;\n   }\n }\n```\n","tags":""},{"id":"9001300","title":"Web Scraping with NodeJS (copied from http://www.storminthecastle.com/2013/08/25/use-node-js-to-extract-data-from-the-web-for-fun-and-profit/)","content":"{\n  \"name\": \"WebScraping\",\n  \"main\": \"scrap.js\",\n  \"dependencies\": {\n    \"cheerio\": \"~0.13.1\"\n  }\n}\nvar http = require('http');\n\nfunction download(url, callback) {\n    http.get(url, function(res) {\n        var data = '';\n\n        res.on('data', function(chunk) {\n            data += chunk;\n        });\n\n        res.on('end', function() {\n            callback(data);\n        });\n    }).on('error', function() {\n        callback(null)\n    });\n}\n\nmodule.exports = download;\nvar cheerio  = require('cheerio'); // converts string into dom tree and provides querying (and other) methods\nvar download = require('./scrap.js');\n\ndownload('http://www.integralist.co.uk/', function(data) {\n    if (data) {\n        var $ = cheerio.load(data)\n\n        $('h2').each(function(index, item) {\n            console.log($(item).text());\n        });\n    }\n    else console.log('error');\n});\n","tags":""},{"id":"8566704","title":"Looking at the Thread API in Ruby","content":"threads = []\n\n10.times do |i|\n  puts \"Creating a new Thread (#{i} of 10):\\n\\n\"\n  thread = Thread.new do\n    # When you create a thread,\n    # it can access any variables that are within scope\n    # at that point.\n    # Any local variables that are then created\n    # within the thread are entirely local to that thread.\n    10.times do |j|\n      puts \"Inside Thread #{i} (#{j} of 10)\\n\\n\"\n      sleep rand(2)\n    end\n  end\n\n  # we'll keep track of all our threads\n  threads \u003c\u003c thread\nend\n\n# The join method makes the main program wait\n# until a thread’s execution is complete before continuing.\n# In this way, you make sure all the threads are complete\n# before exiting.\nthreads.each { |thread| thread.join }\n\n# We can provide a timeout for our threads\n# Below is a one second timeout\n# thread.join(1)\n\n# Thread.list holds a global list of threads\n# Thread.list includes Thread.main\n# Thread.current is the currently executing thread\n# Thread.stop only pauses the thread (t.status == 'sleep')\n# Thread.run resumes a stopped thread\n# Thread.kill(thread) causes that thread to exit\n# Thread.exit\n# Thread.pass passes control to another thread\n# Thread.abort_on_exception = true (all threads will abort)\n# t.value is the returned value from a finished thread\n\n","tags":""},{"id":"8560960","title":"Refactor this Ruby code...","content":"root        = Pathname.new(__FILE__).dirname.parent\nconfig_path = root + 'config'\nconfig_file = (config_path + 'env.development.yaml').realdirpath\njson_file   = (config_path + 'app_config.json').realdirpath\n\n# Overwrite the `env.development.yaml` content with\n# your own specific path to `app_config.json`\nif ENV['APP_ENV'] == 'development'\n  config_location_pattern = /(?\u003c=APP_CONFIG_LOCATION: ')[^']+/\n  content = File.read(config_file).sub!(config_location_pattern, \"#{json_file}\")\n\n  File.open(config_file, 'w') do |file|\n    file.write(content)\n  end\nend\n","tags":""},{"id":"8999306","title":"Variety of different Capybara configurations, tips and tricks","content":"Capybara.default_wait_time = 20\nCapybara.default_host = DEFAULT_HOST\nCapybara.app = Capybara.app_host = DEFAULT_HOST\n\nCapybara.configure do |config|\n  config.match = :prefer_exact\n  config.ignore_hidden_elements = false\nend\n\nCapybara.run_server = false\nCapybara.current_driver = :mechanize\n\nclass Capybara::Mechanize::Browser \u003c Capybara::RackTest::Browser\n  def default_user_agent\n    \"cucumber\"\n  end\nend\n\nCapybara.register_driver :mechanize_with_test_user_agent do |app|\n  driver = Capybara::Mechanize::Driver.new(app)\n  driver.browser.agent.user_agent = \"cucumber\"\n\n  driver\nend\n\nCapybara.register_driver :selenium do |app|\n  Capybara::Selenium::Driver.new(app, :browser =\u003e :chrome, :args =\u003e [\"--user-agent=cucumber\"])\nend\n\nCapybara.register_driver :mechanize_with_test_user_agent_and_adverts do |app|\n  driver = Capybara::Mechanize::Driver.new(app)\n  driver.browser.agent.user_agent = \"cucumber\"\n  driver.browser.agent.request_headers = {\"X-Advert-Override\" =\u003e \"true\"}\n\n  driver\nend\n\nmodule Capybara::Poltergeist\n  class Client\n    private\n    def redirect_stdout\n      prev = STDOUT.dup\n      prev.autoclose = false\n      $stdout = @write_io\n      STDOUT.reopen(@write_io)\n\n      prev = STDERR.dup\n      prev.autoclose = false\n      $stderr = @write_io\n      STDERR.reopen(@write_io)\n      yield\n    ensure\n      STDOUT.reopen(prev)\n      $stdout = STDOUT\n      STDERR.reopen(prev)\n      $stderr = STDERR\n    end\n  end\nend\n\nclass WarningSuppressor\n  class \u003c\u003c self\n    def write(message)\n      if message =~ /QFont::setPixelSize: Pixel size \u003c= 0/ || message =~/CoreText performance note:/ then 0 else puts(message);1;end\n    end\n  end\nend\n\nCapybara.register_driver :poltergeist do |app|\n  driver = Capybara::Poltergeist::Driver.new(app, {\n    :inspector =\u003e true,\n    :timeout =\u003e 60,\n    :js_errors =\u003e false,\n    :phantomjs_options =\u003e ['--load-images=no'],\n    :phantomjs_logger =\u003e WarningSuppressor\n  })\n\n  driver\nend\n\nCapybara.register_driver :poltergeist_images do |app|\n  driver = Capybara::Poltergeist::Driver.new(app, {\n    :inspector =\u003e true,\n    :timeout =\u003e 60,\n    :js_errors =\u003e false,\n    :phantomjs_logger =\u003e WarningSuppressor\n  })\n\n  driver\nend\n\nCapybara.default_driver = :mechanize_with_test_user_agent\n\ndef setup_poltergeist(with_images = nil)\n  Capybara.current_driver = with_images.nil? ? :poltergeist : :poltergeist_images\n\n  page.driver.headers = {\n    \"User-Agent\" =\u003e \"cucumber\"\n  }\n\n  # the following code is required to prevent some JS code causing cukes to fail\n  # i.e. our grid overlay javascript sets up 'keyup' event bindings\n  # for example if you press the 'a' key then the grid overlay visibility is toggled\n  # but when Capybara/Poltergeist fills in a form field it causes the grid to toggle on,\n  # and that then breaks further tests because Capybara/Poltergeist can't click on the page elements\n  page.driver.set_cookie('poltergeist', 'is running')\nend\n\nBefore \"@javascript\" do\n  setup_poltergeist\nend\n\nBefore \"@javascript_with_images\" do\n  setup_poltergeist 'images'\nend\n\nBefore \"@device_desktop\" do |scenario|\n  setup_poltergeist\n  set_device('desktop')\nend\n\nBefore \"@multi_device\" do |scenario|\n  setup_poltergeist\n  set_device(scenario.to_hash['device'])\nend\n\nBefore \"@multi_device_debug\" do |scenario|\n  Capybara.current_driver = :selenium\n  set_device(scenario.to_hash['device'])\nend\n\ndef set_device(device)\n  case device\n  #Height is set to 800 across the board, but should be changed\n  #to something more appropriate when our site reacts to it\n  when \"feature phone\"\n    Capybara.current_driver = nil\n  when \"smart phone portrait\"\n    resize_browser(320, 800)\n  when \"smart phone landscape\"\n    resize_browser(480, 800)\n  when \"tablet portrait\"\n    resize_browser(640, 800)\n  when \"tablet landscape\"\n    resize_browser(768, 800)\n  when \"desktop\"\n    resize_browser(1280, 1024)\n  when \"desktop no javascript\"\n    Capybara.current_driver = nil\n  end\nend\n\ndef resize_browser(w, h)\n  if Capybara.current_driver == :selenium\n    page.driver.browser.manage.window.resize_to(w, h)\n  else\n    page.driver.resize(w, h)\n  end\nend\n\nBefore \"@debug\" do\n  Capybara.current_driver = :selenium\nend\n\ndef destroy_poltergeist\n  begin\n    Capybara.drivers[:poltergeist].call().quit\n  rescue\n  end\n\n  Capybara.current_driver = nil\nend\n\nAfter \"@javascript\" do\n  destroy_poltergeist\nend\n\nAfter \"@javascript_with_images\" do\n  destroy_poltergeist\nend\n\nAfter \"@debug, @multi_device, @multi_device_debug\" do\n  Capybara.current_driver = nil\nend\n\nWorld(Capybara)\n\nmodule Capybara\n  class Session\n    alias :_visit :visit\n\n    def visit(url, opts = {})\n\n      opts[:query_params] ||= {}\n\n      if opts[:cache_busting] != false\n        opts[:query_params]['cb'] = Time.now.to_i\n        opts[:query_params]['i_hate_caching'] = rand(10000)\n      end\n\n      params = opts[:query_params].map{|k,v| [k, \"=\", v]}.map(\u0026:join).join(\"\u0026\")\n\n      uri = URI.parse(url)\n\n      query = \"#{uri.query}\u0026#{params}\".gsub(/^\u0026/, '')\n\n      url = URI::Generic.build(\n        :scheme =\u003e uri.scheme,\n        :host =\u003e uri.host,\n        :port =\u003e uri.port,\n        :path =\u003e uri.path,\n        :query =\u003e query,\n        :fragment =\u003e uri.fragment\n      ).to_s\n\n      _visit url\n      raise \"PHP #{$\u0026} in response!\" if /(?:Notice|Warning|Fatal error):/.match(body)\n    end\n  end\nend\n","tags":""},{"id":"8419151","title":"Private and Privileged methods using the Constructor pattern in JavaScript","content":"function Constructor(){\n  this.foo = 'foo';\n  \n  // Needed for Private methods\n  var self = this;\n  \n  // Private methods need to be placed inside the Constructor.\n  // Doesn't perform as well as prototype methods (as not shared across instances)\n  function private(){\n    console.log('I am private');\n    console.log(self.foo);\n  }\n\n  // Privileged methods need to be placed inside the Constructor.\n  // This is so they can get access to the Private methods.\n  this.privileged = function(){\n    private();\n  };\n}\n\nConstructor.prototype.public = function(){\n  console.log('I am public');\n};\n\nconstructor = new Constructor;\n\nconsole.log(constructor.foo);\n\n\nconstructor.public();     // will work\nconstructor.privileged(); // will work\nconstructor.private();    // won't work (can't be accessed directly)\n","tags":""},{"id":"8400550","title":"Better Mocking using RequireJS' `undef` method to unset redefined modules","content":"define(['require'], function(require) {\n    var stubbed = [];\n    return {\n        stub: function(name, implementation) {\n            stubbed.push(name);\n            requirejs.undef(name);\n            define(name, [], function() {\n                return implementation;\n            });\n        },\n        loadWithCurrentStubs: function(name, callback) {\n            requirejs.undef(name);\n            stubbed.push(name);\n            require([name], callback);\n        },\n        reset: function() {\n            stubbed.forEach(function(name) {\n                requirejs.undef(name);\n            });\n            stubbed = [];\n        }\n    };\n});\nbeforeEach(function () {\n    DependencyHelper.stub('name', implementation);\n\n    DependencyHelper.stub('deviceInspector', {\n        getGroup: function () {},\n        getType: function () {}\n    });\n\n    DependencyHelper.loadWithCurrentStubs('module/base', function (base) {\n        // code\n    });\n});\n\nafterEach(function () {\n    DependencyHelper.reset();\n});\n","tags":""},{"id":"8341704","title":"Rack Server Example","content":"run lambda { |env| [200, {\"Content-Type\"=\u003e\"text/html\"}, [\"Hello World\"]] }\n@root = File.expand_path(File.dirname(__FILE__))\n\nrun lambda { |env|\n  path = Rack::Utils.unescape(env['PATH_INFO'])\n  index_file = @root + \"#{path}index.html\"\n  [200, { 'Content-Type' =\u003e 'text/html' }, [File.exists?(index_file) ? File.read(index_file) : 'Hello World']]\n}\n\n# run with: rackup config.ru\n\n$: \u003c\u003c File.dirname(__FILE__)\n\nmodule TestComponent\n  class Application\n    def initialize\n      puts \"Application initialized\"\n    end\n\n    # Rack requires object being run to have a `call` method which returns\n    # an Array that includes the status code, http headers and a content response\n    def call(env)\n      [200, { 'Content-Type' =\u003e 'text/html' }, ['Hello World!']]\n    end\n  end\nend\n\n$: \u003c\u003c File.dirname(__FILE__)\n\nrequire 'app/app'\n\nrun TestComponent::Application.new\n\n","tags":""},{"id":"8114940","title":"Trying to run RSpec and Cucumber tests via Vim but found executing commands in different contexts means scope changes between what's available in the $PATH to the installed Ruby version and it's available gemsets.","content":"\" Run currently open test file\n\" Bastardised from https://github.com/r00k/dotfiles/blob/master/vimrc#L245\nfunction! SetTestFile()\n    let g:bjo_test_file=@%\nendfunction\n\nfunction! SetTestFileLineNumber()\n    let g:bjo_test_file_line=line(\".\")\nendfunction\n\nfunction! SetTestRunner(runner)\n    let g:bjo_test_runner=a:runner\nendfunction\n\nfunction! RunCurrentTestFile()\n    let in_a_test_file = match(expand(\"%\"), '\\(.feature\\|_spec.rb\\|_test.rb\\)$') != -1\n\n    if in_a_test_file\n        call SetTestFile()\n\n        if match(expand('%'), '\\.feature$') != -1\n            call SetTestRunner(\"!/Users/markmcdonnell/.gem/ruby/2.0.0/bin/cucumber\")\n            exec g:bjo_test_runner g:bjo_test_file\n        elseif match(expand('%'), '_spec\\.rb$') != -1\n            call SetTestRunner(\"!/Users/markmcdonnell/.gem/ruby/2.0.0/bin/rspec\")\n        endif\n    endif\nendfunction\n\nfunction! RunCurrentLineInTestFile()\n    let in_a_test_file = match(expand(\"%\"), '\\(.feature\\|_spec.rb\\|_test.rb\\)$') != -1\n\n    if in_a_test_file\n        call SetTestFileLineNumber()\n    endif\n\n    exec \"!/Users/markmcdonnell/.gem/ruby/2.0.0/bin/rspec\" g:bjo_test_file . \":\" . g:bjo_test_file_line\nendfunction\n\n","tags":""},{"id":"11207262","title":"Ruby Splat (single and double)","content":"# When calling a method with a splat then the parameters are passed as a comma separated list\n# When receiving arguments with a splat then they are converted into an Array\n# When using a double splat (2.0+) then the argument is converted into a Hash (i.e. named parameters)\n\ndef foo(*args)\n  p args\nend\n\nfoo 'a', 'b', 'c'\n# =\u003e [\"a\", \"b\", \"c\"]\n\nfoo *['a', 'b', 'c']\n# =\u003e [\"a\", \"b\", \"c\"]\n\n####################\n\ndef bar(a, *b, **c)\n  [a, b, c]\nend\n\nbar 10\n# =\u003e [10, [], {}]\n\nbar 10, 20, 30\n# =\u003e [10, [20, 30], {}]\n\nbar 10, 20, 30, d: 40, e: 50\n# =\u003e [10, [20, 30], {:d=\u003e40, :e=\u003e50}]\n\nbar 10, d: 40, e: 50\n# =\u003e [10, [], {:d=\u003e40, :e=\u003e50}]\n","tags":""},{"id":"8115457","title":"Shortcut Vim mappings for running RSpec and Cucumber tests","content":"\" Running Tests...\n\" See also \u003chttps://gist.github.com/8114940\u003e\n\n\" Run currently open RSpec test file\nmap \u003cLeader\u003erf :w\u003ccr\u003e:!rspec % --format nested\u003ccr\u003e\n\n\" Run current RSpec test\n\" RSpec is clever enough to work out test to run if cursor is on any line within the test\nmap \u003cLeader\u003erl :w\u003ccr\u003e:exe \"!rspec %\" . \":\" . line(\".\")\u003ccr\u003e\n\n\" Run all RSpec tests\nmap \u003cLeader\u003ert :w\u003ccr\u003e:!rspec --format nested\u003ccr\u003e\n\n\" Run currently open cucumber feature file\nmap \u003cLeader\u003ecf :w\u003ccr\u003e:!cucumber %\u003ccr\u003e\n\n\" Run current cucumber scenario\nmap \u003cLeader\u003ecl :w\u003ccr\u003e:exe \"!cucumber %\" . \":\" . line(\".\")\u003ccr\u003e\n\n\" Run all cucumber feature files\nmap \u003cLeader\u003ect :w\u003ccr\u003e:!cucumber\u003ccr\u003e\n\n","tags":""},{"id":"8098172","title":"Playing around with http://gulpjs.com/","content":"var gulp    = require('gulp');\nvar size    = require('gulp-filesize');\nvar stream  = require('stream');\nvar util    = require('util');\nvar styles  = 'Assets/Styles';\nvar scripts = 'Assets/Scripts';\n\nfunction aNewWritableStream() {\n    stream.Writable.call(this, { objectMode: true }); // make Stream behave like stream of objects instead of a Buffer with a set size\n\n    this.on('finish', function() {\n        console.log('Stream has finished, no more events can come through without causing an error');\n    });\n}\n\nutil.inherits(aNewWritableStream, stream.Writable);\n\naNewWritableStream.prototype._write = function(chunk, encoding, next) {\n    console.log(chunk.contents.toString(encoding)); // logs content of file\n    next();\n};\n\n// We need mulitiple Streams to be created for us to pipe the data through to\nvar writableStuff1 = new aNewWritableStream();\nvar writableStuff2 = new aNewWritableStream();\n\ngulp.task('filesizes', function() {\n    gulp.src(styles + '/**/*.css').pipe(size()).pipe(writableStuff1);\n    gulp.src(scripts + '/**/*.js').pipe(size()).pipe(writableStuff2);\n});\n\ngulp.task('default', function() {\n    gulp.watch([\n        styles + '/**/*.css',\n        scripts + '/**/*.js',\n        './gulpfile.js'\n    ], function() {\n        gulp.run('filesizes');\n    });\n});\nvar gulp    = require('gulp');\n\ngulp.task('test', function(cb) {\n    cb(null); // when the async task is done we execute our callback\n});\n\ngulp.task('default', function() {\n    gulp.watch([\n        './gulpfile.js'\n    ], function() {\n        gulp.run('test', doSomethingAsync);\n    });\n});\n\nfunction doSomethingAsync(err) {\n    if (err) console.log('Error: ' + err);\n\n    console.log('Our async task is complete and this is the callback to do something else after the async task');\n}\n","tags":""},{"id":"8035585","title":"Is there a more elegant way in Ruby to filter data from an object and store it in another object. We're searching for a key (which can appear multiple times) and I only want to store the key once, but to also increment that key's value every time the key is found.","content":"require 'httparty'\n\ndata = HTTParty.get('http://some_url/')\n\nbrowsers = {}\n\ndata.each do |item|\n  browser = item['browser']['family']\n\n  if browsers[browser]\n    browsers[browser] = browsers[browser] + 1\n  else\n    browsers[browser] = 1\n  end\n\n  # yes we *could* use a tertiary conditional but that can be a bit too terse sometimes\n  # browsers[browser] = browsers[browser] ? browsers[browser] + 1 : 1 \n  # i would argue that's actually harder to read than the expanded if/else\nend\n\nputs browsers # {\"Chrome Mobile\"=\u003e3, \"IE Mobile\"=\u003e2}\n\n# Update: the following refactor from Kenoir did the trick...\nbrowsers = data.reduce({}) do | obj, item |\n  browser = item['browser']['family']\n  obj[browser] = (obj[browser].nil?) ? 1 : obj[browser] + 1\n  obj\nend\n","tags":""},{"id":"8057721","title":"2013 review: looking back at what I achieved this year...","content":"- I joined BBC News (thanks [@tmaslen](https://twitter.com/tmaslen) for seeing it through my embarrassingly bad Skype interview test)\n- Learnt lots from the team at BBC (specifically [@danscotton](https://twitter.com/danscotton)) about object-oriented design\n- Helped introduce Node/Grunt as build tools\n- Shifted the team off of QUnit and onto Jasmine (as an intermediary step towards something better)\n- Attended the NET Magazine awards as [Mrs Cleveley](https://twitter.com/jcleveley)\n- Worked on a new pattern library\n- Joined the W3C Responsive Images group and also am now part of BBC GEL.\n- Did a lot of refactoring/simplifying of over-engineered code\n- Got the chance to write a lot more Ruby and experiment more with Node (and things like PhantomJS)\n- Co-Authored the BBC News new photo gallery\n- Was approached by twitter\n- Open Sourced a responsive image solution for the BBC (thanks [@oncletom](https://twitter.com/oncletom))\n- Gave a few dev talks at the BBC\n- Invited to speak at W3C Responsive Images meet-up in Paris alongside speakers and participants from Google, Apple, Microsoft, Adobe, Opera, W3C and Akamai (event hosted by Mozilla)\n- Created a grid system for future BBC News work to use as a foundation\n- Got to write a post on the BBC's responsive news website\n- Slowly over the year made my move to the command line almost 100% thanks to [@sthulb](https://twitter.com/sthulb) tireless support\n- Wrote an article for NET magazine (and will be doing another next year)\n- Led and released the new responsive BBC News navigation\n- Voted Developer of the Year by BBC News\n- NetTuts showed interest in me writing for them (watch this space)\n- Acquired over a 1000 followers! a few *web celebs* here and there ;-)\n\n","tags":""},{"id":"11206399","title":"Ruby Data Structures: Set","content":"Set, included in the stdlib, is an un-ordered collection of elements with no duplicates. However you’ll find that Set’s most useful feature is that its #include? method is much faster than Array’s. In fact Set#include? will always take the same amount of time, regardless of how many elements it contains, whereas Array#include? takes longer the more elements in the array.\n\nSets do take longer to build than Arrays, so work best when they can be created just once and assigned to a constant, or instance variable of a long lived object.\n\n```ruby\nrequire \"set\"\n\nTEMP_EMAIL_PROVIDERS = Set[\"temp-email.tld\", \"throwaway-mail.tld\", ...]\n\ndef temporary_email?(address)\n  TEMP_EMAIL_PROVIDERS.include?(address.split(\"@\").last.downcase)\nend\n```\n","tags":""},{"id":"11206349","title":"Ruby Data Structures: Queue","content":"Another useful data structure is Queue. This is a synchronised, i.e. thread safe, first-in first-out queue. This makes it easy to coordinate work between threads. \\\n\nBelow is a simple example of a program that lets you enter multiple URLs to download, then works through them one by one in the background:\n\n```ruby\nrequire \"thread\" # Queue is part of the thread library\nrequire \"net/http\"\n\nto_do = Queue.new\n\nThread.abort_on_exception = true # if one thread dies, everyone dies\n\ninterface = Thread.new do\n  loop do\n    url = STDIN.gets # waits here until a URL has been entered\n    if url \u0026\u0026 url != \"quit\\n\"\n      to_do.push(URI.parse(url))\n    else\n      to_do.push(false)\n      break\n    end\n  end\nend\n\nfetcher = Thread.new do\n  loop do\n    uri = to_do.pop # waits until there's a URI in the queue\n    break unless uri\n    result = Net::HTTP.get(uri)\n    File.open(\"#{uri.host}#{uri.path.tr(\"/\", \":\")}\", \"w+\") do |f|\n      f \u003c\u003c result\n    end\n    puts \"downloaded #{uri}\"\n  end\nend\n\n[interface, fetcher].each(\u0026:join) # don't exit until the threads are done\n```\n","tags":""},{"id":"11206577","title":"Ruby: Symbol class to_proc and custom class object to_proc (see also https://gist.github.com/Integralist/8079e79c5eb4e7b88183 to see how to use `\u0026` with `method()`)","content":"strs = ['foo', 'bar', 'baz']\n\n# standard long form way\ncaps = strs.map { |str| str.upcase }\n\n# short hand\ncaps = strs.map(\u0026:upcase)\n\n# The \u0026 takes any object and calls to_proc on it\n# In the above example we're using a Symbol and not an object\n# So the Symbol class's to_proc method returns a Proc, \n# that given some object will send itself (the Symbol) as a message to that given object\n\n# Using that explanation, the short hand is equivalent to:\ncaps = strs.map { |str| str.send(:upcase) }\nstrs = ['foo', 'bar', 'baz']\n\ndef dramatise(word)\n  word += '!!'\nend\n\nstrs.map(\u0026method(:dramatise)) # =\u003e [\"foo!!\", \"bar!!\", \"baz!!\"]\nclass Point\n  attr_accessor :x, :y\n\n  def initialize(x, y)\n    @x, @y = x, y\n  end\n\n  def self.to_proc\n    Proc.new do |args| \n      p args     # =\u003e [1, 5], [4, 2]\n      new(*args) # =\u003e create new instance of the `Point` class and splat incoming Array into the constructor\n    end\n  end\nend\n\n[[1, 5], [4, 2]].map(\u0026Point) # =\u003e [#\u003cPoint:0x007f87e983af40 @x=1, @y=5\u003e, #\u003cPoint:0x007f87e983ace8 @x=4, @y=2\u003e]\n","tags":""},{"id":"10357392","title":"Public-key infrastructure (PKI)","content":"http://www.linux.com/community/blogs/133-general-linux/742528-pki-implementation-for-the-linux-admin\n\nPublic-key infrastructure (PKI) is what makes internet encryption and digital signatures work. When you visit your bank website you are told it is encrypted and verified. \n\n## How PKI Works\n\nMost have heard the names of Verisign, Network Solutions, and GoDaddy. These companies along with many more are in the business of allowing the public to trust an organization's encryption keys and are referred to as Registration Authorities (RA)\n \n\nIf an organization, let’s say your bank, wants to encrypt their website that you use to manage your accounts they would first need to generate a private encryption key. The private key is something that should remain just that; private. With the private key one can extract a public key. While a public key can be created from a private key, the reverse should not be possible. \n \n \n\nNow the fun part, any messages encrypted using this private key can be decrypted via the public key and vice versa. The bank now decides that they want a third party to verify the authenticity of their private/public key pair because without it their users get a warning in their web browser stating that the site shouldn’t be trusted. I am sure most of you have seen this error before:\n\nThe bank sends their public key to an RA and pays for them to digitally sign it with their Root Certificate Authority (CA). This CA is nothing more than another public/private key pair. Remember how I said that anything encrypted with a private key can be decrypted with the public key? At the time it may not have sounded like a good idea to have any message encrypted that can be decrypted by anyone. In this case, the RA is the only one with access to their private key and everyone has their public key (You literally do have it, every modern operating system maintains a copy of these trusted Root Certificates). The RA adds a message to the bank’s public key using their private key with the goal that your web browser should now be able to decrypt and view the message. If this is all successful, you do not see the nasty page like the image above and you can be assured that this site is using a certificate that the third party has verified..\n\nSo you now have your bank’s public key. This means you can encrypt a message with it and only the bank can see that message using their private key. The bank does the same thing to send you messages. When you initiate a connection with a web browser to a site that uses HTTPS, you also send your own public key to your bank. They will use that to encrypt messages and send back to you for you to decrypt using your private key. Since you do not need to supply any authenticity of who you are to the website, there is no problem with your public/private keys being generated dynamically.\n\nLastly, public/private key encryption is wildly inefficient due to the existence of the public key. In order for the public key to be securely derived from the private, we have to use very large key sizes. At the time of this article I recommend 4096-bit key size. \n\nSo why do we use PKI if it is so inefficient?\n\nThis sort of encryption is also referred to as asymmetric encryption. Symmetric encryption is much more efficient, but has one flaw; both sides need to know what the private key is. The purpose of PKI is the means for two endpoints to securely decide on a symmetric key to use to continue communication; usually a 128-bit or 256-bit key.  \n\nTo summarize:\n\nYou type in your bank’s address in your web browser\nYour web browser provides your bank with its public key.\nYour bank responds with its public key\nYour web browser checks it’s list of Root Certificates to try to decrypt the digital signature\nIf successful, both sides run through a series of algorithms and exchanges to derive the same symmetric key to be used for the rest of communication within this session.\nAt this point, your bank’s website finally appears in your browser and any communication henceforth will be encrypted using the symmetric key.\n\n## Security Concerns\n\nSo what benefit does a company get when a root certificate authority is used to verify the public key a server presents to a client? The answer is more human than you would think. When a self-signed certificate is used, a user gets that nasty warning I discussed earlier. If this warning is disregarded and the user continues to the site, the communication between the server and client is still encrypted. \n\nHowever, If we train our users to ignore those security warnings about the inability to prove the authenticity of the server’s public key then our users will always ignore this error. In 99.999% of cases this is probably okay, but what can potentially happen is what is known as a Man-In-The-Middle(MITM) attack. \n\nUsing the brief description of PKI above, imagine if there was a malicious user somewhere on the internet, or more likely somewhere locally, placed directly between your computer and the server. When the initial key exchange takes place the attacker can intercept your public key, and send you theirs instead of the server’s of which you are trying to talk to. His public key will most likely not be digitally signed with the same domain name as the site you are visiting, although if this was a targeted attack on a particular server it could be possible. \n\nSince the attacker likely wants to steal data, he will then proxy a connection to the server your originally wanted to go to, but instead of your public key going to the server it would be the attacker’s. This places the attackers computer directly between you and the server and will be able to capture and view any data sent between both machines. Well, that is if the user has been trained to simply ignore the warning they got from their web browser.\n","tags":""},{"id":"10008871","title":"For up to date list of plugins please see my Fresh Install repository: https://github.com/Integralist/Fresh-Install/","content":"cd \"$HOME/.vim/bundle\"\n\nplugins=( airblade/vim-gitgutter \\\n          ap/vim-css-color \\\n          bling/vim-airline \\\n          edkolev/tmuxline.vim \\\n          ervandew/supertab \\\n          gcmt/wildfire.vim \\\n          godlygeek/tabular \\\n          kien/ctrlp.vim \\\n          kien/rainbow_parentheses.vim \\\n          MattesGroeger/vim-bookmarks \\\n          mattn/emmet-vim \\\n          mattn/webapi-vim \\\n          mileszs/ack.vim \\\n          othree/html5.vim \\\n          scrooloose/nerdtree \\\n          scrooloose/syntastic \\\n          sheerun/vim-polyglot \\\n          t9md/vim-choosewin \\\n          tpope/vim-commentary \\\n          tpope/vim-cucumber \\\n          tpope/vim-dispatch \\\n          tpope/vim-endwise \\\n          tpope/vim-fugitive \\\n          tpope/vim-haml \\\n          tpope/vim-markdown \\\n          tpope/vim-repeat \\\n          tpope/vim-surround \\\n          vim-scripts/camelcasemotion \\\n          vim-scripts/Gist.vim \\\n          vim-scripts/paredit.vim \\\n          vim-scripts/Tabmerge \\\n          vim-scripts/textutil.vim \\\n          vim-scripts/ZoomWin \\\n          wellle/targets.vim )\n\nfor item in \"${plugins[@]}\"\ndo\n  git clone \"https://github.com/$item.git\"\ndone\n","tags":""},{"id":"7978893","title":"RSpec Template","content":"describe Stack do\n  context \"Upon Creation\" do\n    let(:stack) { Stack.new } # `let` creates a lazy loaded (and memoized) helper method\n    \n    it \"will be empty\" do\n      stack.should be_empty # `stack` is still called when using the `should` assertion\n    end\n\n    it \"will raise underflow if popped\" do\n      lambda { stack.pop }.should raise_error(Underflow)\n    end\n  end\nend\n\n$count = 0\ndescribe \"let\" do\n  let(:count) { $count += 1 }\n\n  it \"memoizes the value\" do\n    count.should == 1\n    count.should == 1 # notice even though we call `count` again, the value is cached so it's still == one\n  end\n\n  it \"is not cached across examples\" do\n    count.should == 2 # but across tests the value can be updated\n  end\nend\n","tags":""},{"id":"8002000","title":"Mocking the `window` object in JavaScript unit tests","content":"define([\n    'module/bootstrap', // this is jQuery and PubSub libs\n], function (lib) {\n        var windowMock = {\n            resizeSet: false, // set within the fake `lib` object below\n\n            createFakeWindow: function(width, height) {\n                return {\n                    document: {\n                        documentElement: {\n                            clientWidth: width,\n                            clientHeight: height\n                        }\n                    },\n\n                    resizeTo: function(width, height) {\n                        this.document.documentElement = {\n                            clientWidth: width,\n                            clientHeight: height\n                        };\n                    }\n                };\n            },\n\n            fireResizeEvent: function() {\n                this.handler(); // set within the fake `lib` object below\n            },\n\n            lib: {\n                $: function(element) {\n                    return {\n                        on: function(event, handler) {\n                            if (event === 'resize') {\n                                windowMock.resizeSet = true;\n                                windowMock.handler = handler;\n                            }\n                        }\n                    };\n                },\n\n                pubsub: lib.pubsub\n            }\n        };\n\n        return windowMock;\n    }\n);\nfunction createFakeWindow (width, height) {\n    var fakeWindow = WindowMock.createFakeWindow(width, height);\n\n    someObject.init(fakeWindow, WindowMock.lib); // this can be removed or changed appropriately\n\n    return fakeWindow;\n}\n\nfunction resizeWindow (width, height, fakeWindow) {\n    document.body.style.width = width + 'px'; // remember to reset this in the test tear down\n    fakeWindow.resizeTo(width, height);\n    WindowMock.fireResizeEvent();\n}\ndefine(['module/bootstrap'], function (lib) {\n    var $, pubsub, someObject;\n\n    someObject = {\n        // Passing mocks to production code stinks!\n        // Would love others to suggest a better solution\n        init: function (windowMock, libMock) {\n            this.global = windowMock || window;\n            this.docEl = this.global.document.documentElement || document.documentElement;\n            this.lib = libMock || lib;\n\n            $ = this.lib.$;\n            pubsub = this.lib.pubsub;\n        }\n    };\n\n    return someObject;\n});\n\n","tags":""},{"id":"10135411","title":"Custom Ruby Error Handling","content":"class MyCustomError \u003c StandardError\n  attr_reader :object\n\n  def initialize(object)\n    @object = object\n  end\nend\n\nbegin\n  raise MyCustomError.new(\"an object\"), \"a message\"\nrescue Exception =\u003e e\n  puts e.message # =\u003e \"a message\"\n  puts e.object # =\u003e \"an object\"\nend\n","tags":""},{"id":"9910271","title":"Refactoring Ruby -\u003e not all conditionals can be removed, and those that can can't necessarily use the standard refactoring methods such as \"Replace Type Code with Module Extension\", \"Replace Type Code with Polymorphism\" or \"Replace Type Code with State/Strategy\". The below examples demonstrate this.","content":"class Foo\n  def initialize(a=[], b=[])\n    @a = a\n    @b = b\n  end\n  \n  def add(item)\n    if item.is_a? A\n      @a.push item\n    else\n      @b.push item\n    end\n  end\nend\n\nclass A\n  def initialize(name=\"Unknown\")\n    @name = \"A: #{name}\"\n    @time = Time.now\n  end\nend\n\nclass B\n  def initialize(name=\"Unknown\")\n    @name = \"B: #{name}\"\n    @time = Time.now\n  end\nend\n\nfoo = Foo.new\nfoo.add(A.new)\nfoo.add(B.new)\n# Thanks to @clauswitt for his guidance\n\nclass Foo\n  def initialize(storage={})\n    @storage = storage\n  end\n  \n  def add(item)\n    @storage[item.class] = [] unless @storage.has_key?(item.class)\n    @storage[item.class] \u003c\u003c item\n  end\nend\n\nclass A\n  def initialize(name=\"Unknown\")\n    @name = \"A: #{name}\"\n    @time = Time.now\n  end\nend\n\nclass B\n  def initialize(name=\"Unknown\")\n    @name = \"B: #{name}\"\n    @time = Time.now\n  end\nend\n\nfoo = Foo.new\nfoo.add(A.new)\nfoo.add(B.new)\n# - I've assumed you've separated the items into two arrays\n#   because you want to select those items at some point later.\n#   I've refactored to 'filter' the items on the way out, rather\n#   than filtering them on the way in.\n# - Also added a :type method rather than class checking.\n# - You could even use Set instead of [] here\n\nclass Foo\n  def initialize(initial_items = [])\n    @items = initial_items\n  end\n\n  def add(item)\n    @items \u003c\u003c item\n  end\n\n  def a\n    select(:a)\n  end\n\n  def b\n    select(:b)\n  end\n\n  private\n\n  def select(type)\n    @items.select { |item| item.type == type }\n  end\nend\n\n# If you wanted to create more types in the future, say :c, you\n# could dynamically generate the accessors?\n\nclass A\n  def initialize(name=\"Unknown\")\n    @name = \"A: #{name}\"\n    @time = Time.now\n  end\n  \n  def type\n    :a\n  end\nend\n\nclass B\n  def initialize(name=\"Unknown\")\n    @name = \"B: #{name}\"\n    @time = Time.now\n  end\n  \n  def type\n    :b\n  end\nend\n\nfoo = Foo.new\nfoo.add(A.new)\nfoo.add(B.new)\n","tags":""},{"id":"9887248","title":"AOP (Aspect-Oriented Programming)","content":"## What is AOP?\n\n\u003e Aspect Oriented Programming is a means to change the behaviour of – or add behaviour to – methods and functions (including constructors) non-invasively. The added behaviour is called “advice” and can be added before, after, or around the function it advises.\n\nThis description is similar to the [Extract Surrounding](http://www.integralist.co.uk/posts/refactoring-techniques/#extract-surrounding-method) refactoring method. The difference is in the direction of the change. It seems AOP is more focused at modifying existing behaviour non-invasively; where as the Extract Surrounding Method actually changes the source code to allow this type of behavioural modification.\n\n### Libraries\n\n- Ruby: https://github.com/deanwampler/Aquarium\n- JS: http://mulli.nu/2010/05/07/aop-js.html\n- JS: https://github.com/cujojs/meld\n// Variation 1 (AOP format -\u003e modifies behaviour without changing the `foo` method code)\n\nvar obj = {\n    foo: function(a, b, c) {\n        console.log('foo', a, b, c);\n    }\n};\n\nvar originalMethod = obj.foo;\n\noriginalMethod(1, 2, 3) // =\u003e foo, a, b, c\n\nobj.foo = function(a, b, c) {\n    console.log('before');\n    originalMethod.apply(this, arguments)\n    console.log('after');\n};\n\nobj.foo(1, 2, 3) // =\u003e before; foo, a, b, c; after\n\n// Variation 2 (Same as the first but abstracted into reusable helper functions)\n\nfunction before(f, advice) {\n    return function () {\n        advice.apply(this, arguments);\n        return f.apply(this, arguments);\n    };\n}\nfunction after(f, advice) {\n    return function () {\n        var result = f.apply(this, arguments);\n        advice.call(this, result);\n        return result;\n    };\n}\n\nvar obj = {\n    foo: function(a, b, c) {\n        console.log('foo', a, b, c);\n    }\n};\n\nobj.foo = before(obj.foo, function(){\n    console.log('Before!!');\n});\n\nobj.foo = after(obj.foo, function(){\n    console.log('After!!');\n});\n\nobj.foo(1, 2, 3) // =\u003e Before!!; foo, a, b, c; After!!\n\n// Variation 3 (\"Extract Surrounding\" format -\u003e not AOP as it modifies the source `foo` method)\n\nvar obj = {\n    foo: function(before, after) {\n        if (before) before();\n        console.log('foo');\n        if (after) after();\n    }\n};\n\nfunction before(){\n    console.log('before');\n}\n\nfunction after(){\n    console.log('after');\n}\n\nobject.foo(before, after);\n\n// Different example of the second variation\n\nfunction logsArguments (fn) {\n    return function () {\n      console.log.apply(this, arguments);\n      return fn.apply(this, arguments)\n    }\n}\n\nfunction sum (a, b) {\n    return a + b;\n}\n\nvar logsSum = logsArguments(sum);\n\nconsole.log(\n    logsSum(1, 3)\n);\nmodule AOP\n  def around(fn_name)\n    old_method = instance_method(fn_name)\n    define_method(fn_name) do |*args|\n      yield :before, args if block_given?\n      old_method.bind(self).call *args\n      yield :after, args if block_given?\n    end\n  end\nend\n \nclass Foo\n  extend AOP\n \n  def process(msg)\n    puts msg\n  end\nend\n \nFoo.around('process') do |state, args|\n  if state == :before\n    puts 'Blah 1'\n  elsif state == :after\n    puts 'Blah 2'\n  end\nend\n \nFoo.new.process('hai')\nmodule Around\n  def around(fn_name)\n    old_method = instance_method(fn_name)\n    define_method(fn_name) do |*args|\n      puts \"before\"\n      old_method.bind(self).call *args\n      puts \"after\"\n    end\n  end\nend\n \nclass Foo\n  extend Around\n \n  def bar\n    puts \"Bar!\"\n  end\n \n  bar = around(:bar)\nend\n \nFoo.new.bar # =\u003e before; Bar!; after\n","tags":""},{"id":"9791615","title":"Ruby: reducing context","content":"class Dependency\n  def initialize(foo, bar, baz)\n    @foo = foo\n    @bar = bar\n    @baz = baz\n  end\n\n  def data\n    { :foo =\u003e @foo, :bar =\u003e @bar, :baz =\u003e @baz }\n  end\nend\n\nclass Foo\n  def initialize(Dep)\n    @data = Dep.new(:a, :b, :c).data \n    # Foo knows too much about its dependency\n    # Foo not only relies on the public interface,\n    # but Foo also knows how to construct a new instance of the dependency;\n    # that's too much knowledge (context)\n    # So even though we're injecting our dependency, \n    # we're now tightly coupling Foo to the dependency \n  end\nend\n\nfoo = Foo.new(Dependency)\nclass Dependency\n  def initialize(foo, bar, baz)\n    @foo = foo\n    @bar = bar\n    @baz = baz\n  end\n\n  def data\n    { :foo =\u003e @foo, :bar =\u003e @bar, :baz =\u003e @baz }\n  end\nend\n\nclass Foo\n  def initialize(Dep)\n    @data = Dep.data # Foo now only relies on an interface \n    # e.g. relies on being able to safely send a `data` message to the dependency\n  end\nend\n\nfoo = Foo.new(Dependency.new(:a, :b, :c))\n","tags":""},{"id":"9893111","title":"Messing around with AWS and DynamoDB","content":"require 'aws-sdk'\n\nAWS.config(:region =\u003e 'eu-west-1')\n\ndynamo_db = AWS::DynamoDB.new\ndynamo_db.tables[\"mark_sequencer_test\"].exists?\n\ntable = dynamo_db.tables[\"mark_sequencer_test\"]\ntable.status #=\u003e :active\n\n# (column name, hash key, batch conditions)\nrows = table.batch_get([\"value\"], [\"foo/bar\"], { :consistent_read =\u003e true })\n# rows.count \u003e= 1 ? rows.first[\"value\"].to_i : nil\n\n# The following code doesn't appear to work because of the put conditional?\nmutex = Mutex.new\nmutex.synchronize do\n  value = 0 # would typically be provided by user\n  table.items.put(\n    { :key =\u003e \"bar/foo\", :value =\u003e 0 },\n    { :if =\u003e { :value =\u003e value.to_i } } # put condition\n  )\nend\n\n# But without a conditional it does...\ntable.items.put({ :key =\u003e \"a/b\", :value =\u003e 0 })\n\n# Generate some data to put into the table\nhash_keys = %w(foo/foo foo/bar foo/baz foo/qux foo/cor bar/foo bar/bar bar/baz bar/qux bar/cor baz/foo baz/bar baz/baz baz/qux baz/cor qux/foo qux/bar qux/baz qux/qux qux/cor cor/foo cor/bar cor/baz cor/qux cor/cor oof/foo oof/bar oof/baz oof/qux off/cor)\nhash_keys.each { |hash| table.items.put({ :key =\u003e hash, :value =\u003e 0 }) }\n\n# A better way to bulk generate some content\n(1..10).each { |count| table.items.put({ :key =\u003e \"foo/bulk#{count}\", :value =\u003e 0 }) }\n\n# Time our bulk writing (should really have researched how to do a batch put rather than individual puts)\nstart_time = Time.now\n(1..5000).each { |count| table.items.put({ :key =\u003e \"foo/bulk#{count}\", :value =\u003e 0 }) }\nendtime = Time.now\nendtime - start_time # =\u003e ~11.6 mins\n\n# Deleting items in batches\ntable.batch_delete(%w(foo/bar foo/baz))\n\ntable.items.each { |item| puts item.hash_value } # =\u003e displays all the hash values\n\n# So we can do something like:\ntable.batch_delete(table.items.collect { |item| item.hash_value })\n\n# The above line doesn't work because we're pushing more than 25 items in parallel. \n# So it causes the following error...\n# AWS::DynamoDB::Errors::ValidationException: Too many items requested for the BatchWriteItem call\n# from /Users/markmcdonnell/.gem/jruby/1.9.3/gems/aws-sdk-1.38.0/lib/aws/core/client.rb:374:in `return_or_raise'\n\n# To fix this we should chunk process the data\ntable.items.collect { |item| item.hash_value }.each_slice(25) { |arr| table.batch_delete(arr) }\n\n# Could refactor it into...\nprocess hash_list\n\ndef process(arr)\n  arr.each_slice(25) { |a| table.batch_delete(a) }\nend\n\ndef hash_list\n  table.items.collect { |item| item.hash_value }\nend\n\n# Alternative Deleting\nbatch = AWS::DynamoDB::BatchWrite.new\ntable.items.collect { |item| item.hash_value }.each_slice(25) { |arr| batch.delete(table, arr); batch.process! }\n\n# Alternative Writing\nbatch = AWS::DynamoDB::BatchWrite.new\nbatch.put(table, [\n  { :key =\u003e \"a/b\", :value =\u003e 0 },\n  { :key =\u003e \"c/d\", :value =\u003e 0 },\n  { :key =\u003e \"e/f\", :value =\u003e 0 }\n])\nbatch.process!\n\n# Example construction of our batching data and then using that to complete a batch write\nbatch_data = (1..5000).reduce([]) { |arr, n| arr.tap { |a| a \u003c\u003c { :key =\u003e \"bulk/#{n}\", :value =\u003e 0 } } }\nbatch.put(table, batch_data)\nbatch.process!\n\n# The above line doesn't work because we're pushing more than 25 items in parallel. \n# So it causes the following error...\n# AWS::DynamoDB::Errors::ValidationException: Too many items requested for the BatchWriteItem call\n\n# To fix this we should chunk process the data (NOTE: this doesn't fix the above error)\nbatch_data.each_slice(25) { |arr| batch.put(table, arr); batch.process! }\n\n# With rough timings...\nstart_time = Time.now\nbatch_data.each_slice(25) { |arr| batch.put(table, arr); batch.process! }\nend_time = Time.now\nend_time - start_time\n\n# Retrieving an item written to the table\ntable.items['bulk/4395'].attributes.values_at(:key)\ntable.items['bulk/4395'].attributes.values_at(:value)\na, b = table.items['bulk/4395'].attributes.values_at(:key, :value)\n\n# Deleting items without a range_value (hash_value only) in the SCHEMA e.g. [\"a/b\", \"c/d\"]\ntable.items.collect { |item| item.hash_value }.each_slice(25) { |arr| table.batch_delete(arr) }\n\n# Deleting items with both a range_value and hash_value in the SCHEMA e.g. [[\"a/b\", 0], [\"c/d\", 0]]\ntable.items.collect { |item| [item.hash_value, item.range_value.to_i] }.each_slice(25) { |arr| table.batch_delete(arr) }\n","tags":""},{"id":"9779256","title":"Concurrency vs Parallelism","content":"This is my understanding of the difference between \"Concurrency\" and \"Parallelism\". I believe it's *reasonably* accurate - although feel free to discuss in the comments if you feel the distinction is different to my definition.\n\nEffectively there is just \"concurrency\". Concurrency is the ability to handle multiple tasks/processes all running at the same time (rather than running tasks sequentially: one finishes, the next starts).\n\nIf there is only a single CPU available then concurrent processes won't perform as well as you might think because the CPU will be forced to do something called \"task switching\". Imagine you have two tasks (A and B) which are running concurrently; \"task switching\" breaks down to:\n\n- CPU works on task A for a short (predetermined) amount of time\n- If task A isn't complete by end of the set time frame then task B is started\n- CPU works on task B (again only for the predetermined amount of time)\n- If task B doesn't complete within the time frame then the CPU jumps back to work on task A\n- ...and back and forth the single CPU goes until both task A and B are complete...\n\nOne way to improve \"task switching\" is to run tasks in parallel; but this requires multiple CPUs. Running tasks in parallel mean that both tasks A and B can genuinely run at the same time rather than one at a time (remember the default format of \"task switching\" isn't as slow as just running the task sequentially).\n\nSo it's best to think of Concurrency as the **goal**; and \"task switching\" and \"parallelism\" as specific implementations; the latter yielding the fastest results.\n","tags":""},{"id":"9780188","title":"Object-Oriented Design Principles (Code Design)","content":"- [Messages and Duck Typing](#messages-and-duck-typing-ie-interfaces)\n- [Dependencies](#dependencies)\n- [Patterns](#patterns)\n  - [Template Method Pattern](#template-method-pattern)\n  - [Null Object Pattern](#null-object-pattern)\n  - [Replace Conditional with Polymorphism](#replace-conditional-with-polymorphism)\n  - [Transform complex data structures](#transform-complex-data-structures)\n- [Miscellaneous](#miscellaneous)\n\n## Messages and Duck Typing (i.e. interfaces)\n\n- Think about \"messages\" not \"objects\".\n- \"message\" == \"method call\" (e.g. \"I want to call Y's X method\" == \"I want to send the message X to object Y\").\n- New objects should be identified from the messages you know you want to send.\n- Knowing what messages to send is facilitated by the use of \"sequence diagrams\".\n- The result of this way of thinking is that you rely on an \"interface\" and not a concrete object.\n- The reason relying on an interface is better is that the object can later be swapped for another and it doesn't matter as long as it implements the same interface (i.e. Liskov Substitution Principle).\n- When creating a new instance of an object it should cause no side effects and shouldn't complicate testing with needing to mock many dependencies. To avoid this make sure the constructor only does the minimum and any additional bootstrapping is done via another method call (e.g. `Foo.new.bootup` rather than having all of the `bootstrap` code inside the constructor). If your code is just `Foo.new` and lots of things start to happen then that's a recognised code smell because your constructor isn't just doing some configuration; it's actually actioning and sending messages.\n\n## Dependencies\n\n- \"Tell, don't ask\". This will allow you to reduce the \"context\" of your objects (e.g. the amount an object knows about another object)\n- Injecting dependencies helps to decouple objects and thus makes your objects less tightly coupled to other objects.\n- The more loosely coupled your objects, the easier it is to swap objects without requiring lots of extra code changes.\n- Don't pass a class into an object and have that receiving object instantiate the class. This is because it increases the receiving object's context; as it now knows too much about the dependency being passed to it. The object should only know the dependencies public interface (remember: \"tell, don't ask\"). So pass a constructed object (i.e. instantiate the class as you pass it with the message)\n- When sending a message to a dependency, pass the current object (e.g. `self`) along with the message. This will further decouple your objects (i.e. the objects either side of a message can be easily swapped as neither relies on a concrete object).\n- In some instances loading lots of dependencies *outside* of a class isn't as helpful at reducing the number of dependencies in your class' constructor as you may think. The reason being: they're still dependencies; they're just \"implicit\" rather than \"explicit\". It can make testing (mocking/stubbing) easier if you're being explicit and pass a dependency into the constructor (Note: this depends on your language of choice. In Ruby, developers will argue DI isn't necessary as the language is designed to be very malleable -\u003e so see what works for you and your language; e.g. DI Containers work well in a language such as PHP (e.g. Pimple))\n- Simplify bloated constructors by teasing out functionality into a new object and also look at related dependencies and move one dependency into another (if possible) to reduce the number of dependencies passed into a single constructor.\n- Some bloated constructor parameters might not necessarily be violating SRP. They may well receive too many dependencies but it could be that they're related to configuration and so we're not setting enough default values which can then be overridden with a single config object parameter.\n\n## Patterns\n\n### Template Method Pattern\n\nUse the 'Template Method Pattern' with inheritance to abstract away common code into parent class. Some other things this pattern helps improve is:\n\n- Keeping defaults within the parent\n- Keep unique behaviour within the specific child objects\n- Avoids issue where developer unfamiliar with the code would otherwise need to (or not know to) call `super` (by implementing 'hook methods')\n- Avoids sub classes having too much context\n- Avoids minor changes in the parent class from affecting the sub class\n\n```ruby\nclass Parent\n  attr_reader :foo, :bar\n\n  def initialize(args = {})\n    @foo = args[:foo] || default_foo\n    @bar = args[:bar] || default_bar\n\n    post_initialize\n  end\n\n  def merge_obj(obj)\n    obj.merge(new_obj)\n  end\n\n  protected\n\n  def default_foo\n    \"foo\"\n  end\n\n  def default_bar\n    \"bar\"\n  end\n\n  def default_baz\n    raise NotImplementedError # this protects us from forgetting to implement an required method\n  end\n\n  def post_initialize\n    nil\n  end\n\n  def new_obj\n    {}\n  end\nend\n\nclass Child \u003c Parent\n  def post_initialize\n    # what would have been in a `super` call\n    # is now placed here and used as a 'hook method'\n    puts \"Child specific stuff (that normally would have been inside the constructor) goes here\"\n  end\n\n  private\n\n  def default_foo\n    \"FOO!\"\n  end\n\n  def default_bar\n    \"BAR!\"\n  end\n\n  def new_obj\n    # override the `new_obj` method within the parent class\n    { :foo =\u003e :bar }\n  end\nend\n\n# The following is example usage of the above code...\n\nparent = Parent.new\nputs parent.merge_obj(:a =\u003e 1, :b =\u003e 2, :c =\u003e 3)\nputs parent.foo\nputs parent.bar\n\nchild = Child.new\nputs child.merge_obj(:d =\u003e 4, :e =\u003e 5, :f =\u003e 6)\nputs child.foo\nputs child.bar\n```\n\n#### Hook methods\n\nHook methods don't work that well with deep hierarchy class structures. Best to avoid and use some form of composition (typically via module inclusion) to build up your functionality.\n\n#### Composition and Aggregation\n\nComposition and Aggregation both effectively mean the same thing: composing objects from other objects.\n\nBut there is a subtle difference between them, which is that Aggregation refers to composing objects which have a life (e.g. they continue to exist and have relevance) outside of the object they're being composited within.\n\nTypically you'll use the term composition nearly all the time unless you have a specific reason to provide a really granular explanation of the system you're designing.\n\n### Null Object Pattern\n\nRather than implementing multiple checks for available properties throughout your code; instead introduce the 'Null Object Pattern'.\n\n```ruby\nclass RealObject\n  def a\n    \"A!\"\n  end\n\n  def b\n    \"B!\"\n  end\nend\n\nclass NullObject\n  def a\n    \"Default value for A\"\n  end\n\n  def b\n    \"Default value for B\"\n  end\nend\n\nclass Bar\n  def initialize(obj)\n    @thing = obj || NullObject.new\n  end\n\n  def do_the_thing\n    puts @thing.a\n    puts @thing.b\n  end\nend\n\nbar1_passes_object      = Bar.new(RealObject.new)\nbar2_doesnt_pass_object = Bar.new\n\nbar1_passes_object.do_the_thing      # =\u003e A!, B!\nbar2_doesnt_pass_object.do_the_thing # =\u003e Default value for A, Default value for B\n```\n\n### Replace Conditional with Polymorphism\n\nInstead of using conditionals (e.g. `if/else` or `switch/case`) use Polymorphism. This really means: \"use a consistent interface between all your objects\".\n\n```ruby\n# Bad...\n\nclass Foo\n  def initialize(data)\n    @data = data\n  end\n\n  def do_something\n    if @data.class == Bar\n      puts \"Bar!\"\n    elsif @data.class == Baz\n      puts \"Baz!\"\n    elsif @data.class == Qux\n      puts \"Qux!\"\n    end\n  end\nend\n\nclass Bar; end\nclass Baz; end\nclass Qux; end\n\nfoo_bar = Foo.new(Bar.new)\nfoo_bar.do_something\n\nfoo_baz = Foo.new(Baz.new)\nfoo_baz.do_something\n\nfoo_qux = Foo.new(Qux.new)\nfoo_qux.do_something\n\n# Good (Polymorphism)...\n\nclass Foo\n  def initialize(data)\n    @data = data\n  end\n\n  def do_something\n    @data.identifier\n  end\nend\n\nclass Bar\n  def identifier\n    puts \"#{self.class}!\"\n  end\nend\n\nclass Baz\n  def identifier\n    puts \"#{self.class}!\"\n  end\nend\n\nclass Qux\n  def identifier\n    puts \"#{self.class}!\"\n  end\nend\n\nfoo_bar = Foo.new(Bar.new)\nfoo_bar.do_something\n\nfoo_baz = Foo.new(Baz.new)\nfoo_baz.do_something\n\nfoo_qux = Foo.new(Qux.new)\nfoo_qux.do_something\n```\n\nHere's a JavaScript implementation:\n\n```js\n// Bad...\n\nfunction test (condition) {\n    if (condition === \"A\") {\n        // lots of code related to \"A\" here\n    } else if (condition === \"B\") {\n        // lots of code related to \"B\" here\n    } else if (condition === \"C\") {\n        // lots of code related to \"C\" here\n    }\n}\n \ntest('A');\ntest('B');\ntest('C');\n \n// Good (Polymorphism)......\n \nvar A = {\n    doTheThing: function(){\n        lots of code related to \"A\" here\n    }\n}\n \nvar B = {\n    doTheThing: function(){\n        lots of code related to \"B\" here\n    }\n}\n \nvar C = {\n    doTheThing: function(){\n        lots of code related to \"C\" here\n    }\n}\n \nfunction test (condition) {\n    condition.doTheThing();    \n}\n \ntest(A);\ntest(B);\ntest(C);\n```\n\n### Transform complex data structures\n\nAvoid trying to access complex data structures. In the following example we convert a complex and indecipherable Array into an object with a clearly defined set of methods which helps clarify the code.\n\n```ruby\n# Bad...\n\nclass Foo \n  attr_reader :data \n\n  def initialize(data) \n    @data = data \n  end \n\n  def do_something \n    data.each do |item| \n      puts item[0] \n      puts item[1] \n      puts '---' \n    end \n  end \nend \n\nobj = Foo.new([[10, 25],[3, 9],[41, 7]]) \nobj.do_something\n\n# Good...\n\nclass Foo \n  attr_reader :new_data \n\n  def initialize(data) \n    @new_data = transform(data) \n  end \n\n  def do_something \n    new_data.each do |item| \n      # now we are able to reference easily understandable \n      # property names (rather than item[0], item[1]) \n      puts item.coord_x \n      puts item.coord_y \n      puts '---' \n    end \n  end \n\n  Transform = Struct.new(:coord_x, :coord_y) \n\n  def transform(data) \n    data.collect { |item| Transform.new(item[0], item[1]) } \n  end \nend \n\nobj = Foo.new([[10, 25],[3, 9],[41, 7]]) \nobj.do_something\n```\n\n## Miscellaneous\n\n- If you notice a Class starts to demonstrate more than one responsibility then extract that behaviour out into another Class.\n","tags":""},{"id":"9888759","title":"git reset --soft/--mixed/--hard","content":"## UPDATE\n\nEvery time I accidentally `git commit --amend` instead of a normal git commit I have to google `git reset --soft HEAD@{1}` to save the day.\n\n---\n\nImagine you have a file called `foo.txt` and your Git history looked like this: \n\n```\nA -\u003e B -\u003e C (HEAD)\n```\n\nLet's see each commit we made:\n\n```\nA == foo\nB == FOO\nC == Foo\n```\n\nThe following examples explain the different reset flags:\n\n```\ngit reset --soft B  == move HEAD to B but keep C's changes staged (i.e. added to the index)\n\ngit reset --mixed B == move HEAD to B but keep C's changes unstaged (--mixed is the DEFAULT)\n\ngit reset --hard B  == move HEAD to B but completely delete C (you've lost those changes forever)\n```\n\n\u003e **NOTE**: If you accidentally `git commit --amend` the `HEAD`, then you can undo that using `git reset --soft HEAD@{1}`. The `--soft` means the changes you made are kept staged (ready for an actual `git commit`) while the `HEAD@{1}` means set `HEAD` to what it was before the accidental `--amend`. This means `HEAD@{1}` is _NOT_ the same thing as `HEAD~1`, which gives you the commit that is the parent node of the commit that `HEAD` is currently pointing to. The reference `HEAD@{1}` is actually able to get back what we want because what it references is actually sourced from `git reflog`, which if you run `git reflog` you'll see the output shows an index for each recorded change.\n\nIf you want to clean up a PRs commits, then run:\n\n```\ngit reset origin/main \n```\n\nThen your changes will still exist, but will just be unstaged (as --mixed is the default behaviour). You can now `git add --patch` cleanly.\n","tags":""},{"id":"9482527","title":"S.O.L.I.D principles in Ruby","content":"## Single responsibility principle\n\nProbably the most well known principle, and one that should try to adhere to most of the time.\n\nLet's say you have this code:\n\n```ruby\nclass AuthenticatesUser\n  def authenticate(email, password)\n    if matches?(email, password)\n     do_some_authentication\n    else\n      raise NotAllowedError\n    end\n  end\n\n  private\n  def matches?(email, password)\n    user = find_from_db(:user, email)\n    user.encrypted_password == encrypt(password)\n  end\nend\n```\n\nThe `AuthenticatesUser` class is responsible for authenticating the user as well as knowing if the email and password match the ones in the database. It has two responsibilities, and according to the principle it should only have one, let's extract one.\n\n```ruby\nclass AuthenticatesUser\n  def authenticate(email, password)\n    if MatchesPasswords.new(email, password).matches?\n     do_some_authentication\n    else\n      raise NotAllowedError\n    end\n  end\nend\n\nclass MatchesPasswords\n  def initialize(email, password)\n     @email = email\n     @password = password\n  end\n\n  def matches?\n     user = find_from_db(:user, @email)\n    user.encrypted_password == encrypt(@password)\n  end\nend\n```\n\nI've used a refactoring technique called Extract Class and then use it on the class I already had, this is called sharing behaviour through composition.\n## Open/closed principle\n\n```ruby\nclass Report\n  def body\n     generate_reporty_stuff\n  end\n\n  def print\n     body.to_json\n  end\nend\n```\n\nThis code violates OCP, because if we want to change the format the report gets printed, you need to change the code of the class. Let's change it then.\n\n```ruby\nclass Report\n  def body\n     generate_reporty_stuff\n  end\n\n  def print(formatter: JSONFormatter.new)\n     formatter.format body\n  end\nend\n```\n\nThis way changing the formatter is as easy as:\n\n```ruby\nreport = Report.new\nreport.print(formatter: XMLFormatter.new)\n```\n\nThus I have extended the functionality without modifying the code. In this example, I have used a technique called Dependency Injection, but many other can apply.\n## Liskov substitution principle\n\nThis principle applies only to inheritance, so let's see an example of inheritance that breaks it:\n\n```ruby\nclass Animal\n  def walk\n     do_some_walkin\n  end\nend\n\nclass Cat \u003c Animal\n  def run\n    run_like_a_cat\n  end\nend\n```\n\nIn order to comply with the LSP, as Bob Martin puts it:\n\n\u003e Subtypes must be substitutable for their base types\n\nSo, they must have the same interface. Since ruby does not have abstract methods, we can do it like so:\n\n```ruby\nclass Animal\n  def walk\n     do_some_walkin\n  end\n\n  def run\n    raise NotImplementedError\n  end\nend\n\nclass Cat \u003c Animal\n  def run\n    run_like_a_cat\n  end\nend\n```\n## Interface segregation principle\n\nSimply put, this principle states that:\n\n\u003e when a client depends upon a class that contains interfaces that the client does not use, but that other clients do use, then that client will be affected by the changes that those other clients force upon the class\n\nThis one is simpler to demonstrate, if you have a class that has two clients (objects using it):\n\n```ruby\nclass Car\n  def open\n  end\n\n  def start_engine\n  end\n\n   def change_engine\n   end\nend\n\nclass Driver\n  def drive\n    @car.open\n    @car.start_engine\n  end\nend\n\nclass Mechanic\n  def do_stuff\n    @car.change_engine\n  end\nend\n```\n\nAs you can see, our Car class has an interface that's used partially by both the Driver and the Mechanic. We can improve our interface like so:\n\n```ruby\nclass Car\n  def open\n  end\n\n  def start_engine\n  end\nend\n\nclass CarInternals\n   def change_engine\n   end\nend\n\nclass Driver\n  def drive\n    @car.open\n    @car.start_engine\n  end\nend\n\nclass Mechanic\n  def do_stuff\n    @car_internals.change_engine\n  end\nend\n```\n\nBy splitting the interface into two, we can comply to the ISP.\n## Dependency inversion principle\n\nDirectly from the Wikipedia page:\n\n\u003e Abstractions should not depend upon details. Details should depend upon abstractions.\n\nLet's go back to the first example on the OCP and change it a bit:\n\n```ruby\nclass Report\n  def body\n     generate_reporty_stuff\n  end\n\n  def print\n     JSONFormatter.new.format(body)\n  end\nend\n\nclass JSONFormatter\n  def format(body)\n     ...\n  end\nend\n```\n\nNow there is a formatter class, but I've hardcoded it on the Report class, thus creating a dependency from the Report to the JSONFormatter. Since the Report is a more abstract (high-level) concept than the JSONFormatter, we're effectively breaking the DIP.\n\nWe can solve it the exact same way with solved it on the OCP problem, with dependency injection:\n\n```ruby\nclass Report\n  def body\n     generate_reporty_stuff\n  end\n\n  def print(formatter: JSONFormatter.new)\n     formatter.format body\n  end\nend\n```\n\nThis way the Report does not depend on the JSONFormatter and can use any type of formatter that has a method called format (this is known as duck typing).\n\nAnother thing of note is that we've used, once again, dependency injection to solve a problem. This technique is a very powerful one when our goal is decoupling objects, and even though it has the same initials as the dependency inversion principle (vs dependency injection pattern), they are completely different concepts.\n","tags":""},{"id":"cbbbb95b571bd08bb5aa","title":"Homebrew: switch to custom versions of software ","content":"If you wish to switch your `python` command to use a different Python interpreter (and it's a Python version you previously had installed using Homebrew):\n\n```bash\nbrew info python           # To see what you have previously installed\nbrew switch python 3.x.x_x # Ex. 3.6.5_1\n```\n\n\u003e NOTE: this might not be wise to do as you might have other software that relies on the Python interpreter you have currently (i.e. before the switch).\n\nOtherwise to install multiple Python versions using Homebrew (instead of something like `pyenv`)...\n\nTemplate:\n\n```bash\nbrew install https://address/to/the/formula/FORMULA_NAME.rb\n```\n\nExample Python 3 template:\n\n```bash\nbrew install https://raw.githubusercontent.com/Homebrew/homebrew-core/COMMIT_IDENTIFIER/Formula/python.rb\n```\n\nNow you can't view the commits via the GitHub UI because there are so many, so you'll have to clone the homebrew-core repository and do it via the command line:\n\n```bash\ngit clone git@github.com:Homebrew/homebrew-core.git\ngit log master -- Formula/python.rb\n```\n\nFrom there you can search for the commits which update the Python version by searching for the message `python: update \u003cversion\u003e bottle.`\n\nExample: we want to install Python version `3.7.5`\n\n```bash\ngit log --oneline --grep '^python: update .\\+ bottle'\n\nc14db427e7 python: update 3.7.7 bottle.\nf02346bd48 python: update 3.7.6_1 bottle.\n7ef074a882 python: update 3.7.6 bottle.\n2efdfe5519 python: update 3.7.5 bottle.    # \u003c\u003c HERE IT IS!\n6589f0f6f5 python: update 3.7.4_1 bottle.\ne9004bd764 python: update 3.7.4_1 bottle.\n1c2239bfdf python: update 3.7.4_1 bottle.\n48aba7218e python: update 3.7.4 bottle.\nc24d6bcd47 python: update 3.7.3 bottle.\n22c80fc362 python: update 3.7.3 bottle.\n\n...etc\n```\n\nNow we know the commit hash for the Python version `3.7.5` (i.e. `2efdfe5519`) we want we can install that version like so:\n\n```bash\nbrew unlink python # ONLY if you have installed (with brew) another version of python 3\nbrew install --ignore-dependencies https://raw.githubusercontent.com/Homebrew/homebrew-core/2efdfe5519/Formula/python.rb\n```\n- `brew versions {package}`\n- `brew switch {package} {version}`\n\nOR\n\n- `brew uninstall {package}`\n- `brew versions {package}`\n- `git checkout {commit} Library/Formula/{package}.rb`\n- `brew install {package}`\n","tags":"#homebrew #brew #install #versions #switch"},{"id":"f82dcb34a431e8fabf56","title":"Clojure Homework","content":"; Output required...\n; [[1] [2 3] [4 5]]\n\n(def coll [1 2 3 4 5])\n\n(defn is_even? [collection iteration]\n  (if (even? (get collection iteration))\n    true\n    false))\n\n(defn solution [collection starting_point]\n  (loop [acc [] iteration 0 prev_even starting_point]\n    (if (\u003e iteration (count collection))\n      acc\n      (recur\n        (if prev_even\n          (assoc-in acc [(dec iteration) (dec (count (dec iteration)))] (get collection iteration))\n          (assoc acc iteration [(get collection iteration)]))\n        (inc iteration)\n        (is_even? collection iteration)))))\n\n(solution coll (is_even? coll 0))\n","tags":""},{"id":"9544962","title":"Polymorphism using `if` condition in JavaScript","content":"function test (condition) {\n    if (condition === \"A\") {\n        // lots of code related to \"A\" here\n    } else if (condition === \"B\") {\n        // lots of code related to \"B\" here\n    } else if (condition === \"C\") {\n        // lots of code related to \"C\" here\n    }\n}\n \ntest('A');\ntest('B');\ntest('C');\n\n// CONVERT THAT TO...\n\nvar A = {\n    doTheThing: function(){\n        lots of code related to \"A\" here\n    }\n}\n\nvar B = {\n    doTheThing: function(){\n        lots of code related to \"B\" here\n    }\n}\n\nvar C = {\n    doTheThing: function(){\n        lots of code related to \"C\" here\n    }\n}\n\nfunction test (condition) {\n    condition.doTheThing();    \n}\n \ntest(A);\ntest(B);\ntest(C);\n","tags":""},{"id":"0bc61ef9827232605b55","title":"Testing a Ruby Gem","content":"## Version 1\n\n```sh\n# Long way of doing things (new files need to be added to staging area *before* building the gem)\ngit add . \u0026\u0026 gem build my_gem.gemspec \u0026\u0026 gem install my_gem-0.0.0.gem\n```\n\n## Version 2\n\n```sh\n# If using Bundler to generate the gem (rake task does the same as above)\ngit add . \u0026\u0026 rake install\n```\n\n## Version 3\n\n```ruby\n# This way you don't need to rebuild the gem after every change\ngem 'my_gem', :path =\u003e '/Users/me/path/to/my_gem'\ngem 'some_gem', :git =\u003e 'https://github.com/User/SomeGem.git', :branch =\u003e 'some-branch'\n```\n\n```sh\nbundle exec my_gem_command\n```\n\n\u003e Note: if you point to a local gem \"A\" and that gem internally references/requires another local gem \"B\" which you wish to run locally, then you need to open the Gemfile for the top-level application and modify it to use the same Bundler trick again `gem \"b\", :path =\u003e \"path/to/local/b/gem\"`\n","tags":""},{"id":"145efaf22f17d8a5cc73","title":"EC2 Roles applied by InstanceProfiles.md","content":"\u003e If an application runs on an Amazon EC2 instance and needs to make requests for AWS resources such as Amazon S3 buckets or an DynamoDB table, it must have security credentials. It isn't a good practice to embed or pass IAM user credentials to each instance; distributing long-term credentials to each instance is challenging to manage and a potential security risk. A better strategy is to create a role that is used when the Amazon EC2 instance is launched. An application can then get temporary security credentials from the Amazon EC2 instance\n\n## CloudFormation example\n\n```yaml\nResources:\n  Instance:\n    Type: \"AWS::EC2::Instance\"\n\n  Properties:\n    IamInstanceProfile:\n      Ref: \"Profile\"\n\n  Profile:\n    Type: \"AWS::IAM::InstanceProfile\"\n\n    Properties:\n      Path: \"/\"\n      Roles:\n        - Ref: \"Role\"\n\n  Role:\n    Type: \"AWS::IAM::Role\"\n\n    Properties:\n      AssumeRolePolicyDocument:\n        Statement:\n          - Action:\n              - \"sts:AssumeRole\"\n            Effect: \"Allow\"\n            Principal:\n              Service:\n                - \"ec2.amazonaws.com\"\n\n  Policy:\n    Type: \"AWS::IAM::Policy\"\n\n    Properties:\n      Roles:\n        - Ref: \"Role\"\n      PolicyName: \"Policy\"\n      PolicyDocument:\n        Statement:\n          - Action: \"sts:AssumeRole\"\n            Resource: \"*\"\n            Effect: \"Allow\"\n\n          - Action: \"ec2:Describe*\"\n            Resource: \"*\"\n            Effect: \"Allow\"\n```\n\n## AssumeRole\n\n\u003e A user in one account (the trusted account) can assume a role in another account (the trusting account). To assume a role, a user (or an application that the user is running) calls the AWS STS AssumeRole API. Before the user can assume a role, in the trusting account an administrator must configure the role to assume. In addition, in the trusted account, the user must be given permissions to call the AssumeRole API.\n\n## InstanceProfile\n\n\u003e An instance profile is a container for an IAM role. Instance profiles are used to pass role information to an Amazon EC2 instance when the instance starts. An instance profile can contain only one role. However, a role can be included in multiple instance profiles.\n","tags":""},{"id":"9503099","title":"Convert Ruby Hash keys into symbols ","content":"hash = { 'foo' =\u003e 'bar' }\n\n# Version 1\nhash = Hash[hash.map { |k, v| [k.to_sym, v] }]\n\n# Version 2\nhash = hash.reduce({}) do |memo, (k, v)| \n  memo.tap { |m| m[k.to_sym] = v }\nend\n\n# Version 3\nhash = hash.reduce({}) do |memo, (k, v)| \n  memo.merge({ k.to_sym =\u003e v})\nend\n\n# None of the above solutions work with a multi-level hash\n# They only work on the first level: {:foo=\u003e\"bar\", :level1=\u003e{\"level2\"=\u003e\"baz\"}}\n# The following two variations solve the problem in the same way\n\nmulti_hash = { 'foo' =\u003e 'bar', 'level1' =\u003e { 'level2' =\u003e 'baz' } }\n\n# Modify `Object`\nclass Object\n  def deep_symbolize_keys\n    return self.reduce({}) do |memo, (k, v)|\n      memo.tap { |m| m[k.to_sym] = v.deep_symbolize_keys }\n    end if self.is_a? Hash\n    \n    return self.reduce([]) do |memo, v| \n      memo \u003c\u003c v.deep_symbolize_keys; memo\n    end if self.is_a? Array\n    \n    self\n  end\nend\n\nmulti_hash = multi_hash.deep_symbolize_keys\n\n# Standalone method\ndef symbolize(obj)\n  return obj.reduce({}) do |memo, (k, v)|\n    memo.tap { |m| m[k.to_sym] = symbolize(v) }\n  end if obj.is_a? Hash\n    \n  return obj.reduce([]) do |memo, v| \n    memo \u003c\u003c symbolize(v); memo\n  end if obj.is_a? Array\n  \n  obj\nend\n\nmulti_hash = symbolize(multi_hash)\n","tags":""},{"id":"4708a79785466a800b90","title":"Sinatra Reloader","content":"require \"sinatra/reloader\"\n\nclass Foo\n  register Sinatra::Reloader\n  also_reload \"path/*/to/other/files/*.rb\"\nend\n","tags":""},{"id":"9a56468ba84d82c7ae6d","title":"Manually SSH into Vagrant","content":"Reference: http://thediscoblog.com/blog/2013/10/16/ssh-and-vagrant/\n\n```\nssh -i $(vagrant ssh-config | grep IdentityFile  | awk '{print $2}') -l vagrant -p 2222 -o UserKnownHostsFile=/dev/null -o StrictHostKeyChecking=no 127.0.0.1\n```\n\n\u003e Note: `vagrant` can be changed for any other user  \ne.g. you can add a user when logged in as `root` (see following section)\n\n```\nvagrant ssh\nsu # password: vagrant\nadduser foo\nadduser bar\naddgroup baz # create new group, which above users will be assigned to\nmkdir /var/baz # folder to hold tmux session data\nchgrp baz /var/baz # give group access to tmux session folder\nchmod g+ws /var/baz # ensure new files are accessible to the group\nusermod -aG baz foo # add foo user to the baz group\nusermod -aG baz bar # add bar user to the baz group\n```\n","tags":""},{"id":"4646ab0381d45402bfdd","title":"Create JSON from Yaml","content":"`ruby -rjson -ryaml -e \"puts JSON.generate(YAML.load_file('./stacks/s3.yml'))\" | json_pp | pbcopy`\n","tags":""},{"id":"ffe7f134a2ed1ecb62c7","title":"Auto Currying JavaScript Function","content":"// Copied from http://javascriptweblog.wordpress.com/2010/06/14/dipping-into-wu-js-autocurry/\nvar autoCurry = (function () {\n \n    var toArray = function toArray(arr, from) {\n        return Array.prototype.slice.call(arr, from || 0);\n    },\n \n    curry = function curry(fn /* variadic number of args */) {\n        var args = toArray(arguments, 1);\n        return function curried() {\n            return fn.apply(this, args.concat(toArray(arguments)));\n        };\n    };\n \n    return function autoCurry(fn, numArgs) {\n        numArgs = numArgs || fn.length;\n        return function autoCurried() {\n            if (arguments.length \u003c numArgs) {\n                return numArgs - arguments.length \u003e 0 ?\n                    autoCurry(curry.apply(this, [fn].concat(toArray(arguments))),\n                              numArgs - arguments.length) :\n                    curry.apply(this, [fn].concat(toArray(arguments)));\n            }\n            else {\n                return fn.apply(this, arguments);\n            }\n        };\n    };\n \n}());\n\nmarks = autoCurry(name)('Mark');\nbobs = marks('Bob Smith');\nbobs('McDonnell'); // =\u003e \"Mark Bob Smith McDonnell\"\n","tags":""},{"id":"151e15da5f74c9b4ea0e","title":"Bankers Dilemma","content":"If we imagine the below diagram is an example of a bankers dilemma (two users Foo and Bar have access to a single bank account: Baz). What is the expected behaviour when following one of the paths shown?\n\n\u003e Note: I'm assuming we're using a mutex (or some other form of synchronisation) on the Baz variable.\n\nExample 1: Baz initially holds the value 10. If Foo writes a new value (which is the result of removing 5 from the current value) before Bar; then Bar will end up taking 10 from the new value 5, leaving a minus balance (i.e. the final value will be -5). Meaning more money has been taken than available.\n\nExample 2: Baz initially holds the value 10. If Bar writes a new value (which is the result of removing 10 from the current value) before Foo; then Foo will end up taking 5 from the new value 0, leaving a minus balance (i.e. the final value will be -5). Meaning more money has been taken than available.\n\nBoth actions (`Foo (-5)` and `Bar (-10)`) are triggered at the same time. So how do we ensure that either Foo or Bar is alerted to the fact that their transaction cannot be completed (as there are not enough funds for it to succeed)?\n\nIt seems a potential solution is to ensure the caller executes a method that uses a mutex internally to lock the value first; then once the value is locked we can read the value; and then check if the action is valid. If the condition passes then we update the value and release the lock on the value. Meaning the next caller will be able to lock the value down and run through the same steps.\n\nBut how would this approach work with a distributed system? You could suggest using a global data store, but it would have to be one that guarantees consistency (e.g. a service such as AWS' Dynamo DB offers \"eventual consistency\" and so wouldn't work for a banking institution); but guaranteed consistency is generally considered to be very slow (depending on the number of distributed nodes I assume).\n\nSo how do we attempt to solve this design problem?\n\n![Bankers Dilemma](https://www.lucidchart.com/publicSegments/view/543a9d7b-eca4-4f78-ad1d-72050a005489/image.png)\n\n\n","tags":""},{"id":"7968aefac0f35f914484","title":"Ruby Namespace Concern","content":"module Foo\n  module Bar\n    def self.create(config)\n      Baz.new(config)\n    end\n\n    class Baz\n      def initialize(config)\n        # code\n      end\n    end\n  end\nend\n","tags":""},{"id":"f7fa2a2f3794787909f5","title":"Ruby: Command Design Pattern (can allow for \"undo\" history feature)","content":"# Invoker\nclass Invoker\n  def initialize\n    @history = []\n  end\n\n  def record_and_execute(command)\n    @history \u003c\u003c command  # Optional\n    command.execute\n  end\nend\n\n# Receiver\nclass Light\n  def turn_on\n    puts 'The light is on'\n  end\n\n  def turn_off\n    puts 'The light is off'\n  end\nend\n\n# A command\nclass TurnOnCommand\n  def initialize(light)\n    @light = light\n  end\n\n  def execute\n    @light.turn_on\n  end\nend\n\n# Another command\nclass TurnOffCommand\n  def initialize(light)\n    @light = light\n  end\n\n  def execute\n    @light.turn_off\n  end\nend\n\n# Client\nclass Client\n  def initialize\n    @invoker = Invoker.new\n    @light = Light.new\n  end\n\n  def party\n    50.times do\n      @invoker.record_and_execute(TurnOnCommand.new(@light))\n      @invoker.record_and_execute(TurnOffCommand.new(@light))\n    end\n  end\nend\n","tags":""},{"id":"58220f584782964aa2ca","title":"Ruby: use Struct for inheritance chain","content":"s = Struct.new(:foo, :bar, :baz).new(1, 2, 3)\ns.foo # =\u003e 1\ns.bar # =\u003e 2\ns.baz # =\u003e 3\ncache = Struct.new(nil) do\n  def set(key, value)\n    \"key: #{key}, value: #{value}\" \n  end\nend.new\n\ncache.set(\"k\", \"v\") # =\u003e \"key: k, value: v\"\n# Be warned: http://thepugautomatic.com/2013/08/struct-inheritance-is-overused/\n\nclass Foo \u003c Struct.new(:bar, :baz)\n  def initialize(bar, baz)\n    super\n  end\nend\n\nfoo = Foo.new('a', 'b') # =\u003e =\u003e #\u003cstruct Foo bar=\"a\", baz=\"b\"\u003e\nfoo.bar # =\u003e \"a\"\nfoo.baz # =\u003e \"b\"\n\n","tags":""},{"id":"39e4c5ee5a226d5dc0e2","title":"Designing Systems and Applications","content":"Images taken from http://www.slideshare.net/IanMassingham/aws-devops-event-aws-services-enabling-devops-automated-testing-monitoring-and-continuous-deployment\n\n## Bad Application Design\n\n![1](https://cloud.githubusercontent.com/assets/180050/4507524/4db2f3e6-4b0d-11e4-9f73-9d446e23a838.jpg)\n![2](https://cloud.githubusercontent.com/assets/180050/4507527/4db9cc52-4b0d-11e4-9e0d-6af792cd0b1c.jpg)\n\n## Good Application Design\n\n![3](https://cloud.githubusercontent.com/assets/180050/4507529/4dc06d50-4b0d-11e4-8b94-181b147d242c.jpg)\n![4](https://cloud.githubusercontent.com/assets/180050/4507528/4dbdf11a-4b0d-11e4-8f0a-a01f057cad3e.jpg)\n![5](https://cloud.githubusercontent.com/assets/180050/4507525/4db828de-4b0d-11e4-8844-c0dbc475495c.jpg)\n![6](https://cloud.githubusercontent.com/assets/180050/4507526/4db8b6e6-4b0d-11e4-85c6-1633e9e065ff.jpg)\n![7](https://cloud.githubusercontent.com/assets/180050/4507530/4dc33f6c-4b0d-11e4-89ed-3a2edf53bf41.jpg)\n![8](https://cloud.githubusercontent.com/assets/180050/4507531/4dca75ac-4b0d-11e4-8b45-3fb232fa909b.jpg)\n![9](https://cloud.githubusercontent.com/assets/180050/4507532/4dccd464-4b0d-11e4-9602-827647debd7a.jpg)\n# Designing Systems and Applications\n\nThis is a short document of tips and notes I've accumulated while learning more about designing distributed systems and building concurrent applications. It is by no means definitive and merely scratches the surface of what is needed to be considered when designing an architecture expected to handle large scale traffic.\n\n## Distributed Systems\n\n### Scale *out*, not *up*\n\nThere reaches a point in your application's design where by merely throwing more hardware at the problem (i.e. \"scaling up\") will fail to resolve the scalability issues you're encountering. \n\nYou should aim for an system designed to scale horizontally (i.e. \"scaling out\") as it allows for easier growth and improvement.\n\n### Build smaller applications\n\nIf you currently have a monolithic application, then you should consider drawing a top level diagram of your current architecture. Find logical areas of the application which can be split into separate services that communicate with each other. This allows each individual service to scale separately depending on its load.\n\n\u003e Note: mechanisms for communication could be pubsub (e.g. AWS SNS)  \nor via a push/pull design using queues (e.g. AWS SQS)  \nand use temporary storage to pass between services (e.g. AWS S3)\n\nThe discussion of designing modular systems and applications (which are connected via different mechanisms to potentially avoid single points of failure) will always cause some contention between the arguments of \"pure scalability\" \u0026 \"economical financial stability\"; e.g. smaller set of servers sharing multiple services is cheaper than a individual servers for each service. The outcome will depend on the size of the organisation and whether it's financially viable to support an extremely granular architecture.\n\n### Measure, Monitor, Log\n\nImplement solutions to application logging and server monitoring as soon as possible. Aim to *prevent* disasters rather than just automating recovery from them. Identify unhealthy services before they become an unrecoverable problem.\n\nAlso, by measuring and monitoring appropriately, we can ascertain whether our instances are too small/large and can be scaled up/down accordingly.\n\n### Utilization\n\nDon't just think about automatically scaling; you should definitely scale where appropriate, but also think about optimizing utilization. For example, look at your application/service design and look at ways to modify them so they can handle more traffic, more efficiently. Doing this will help to reduce costs by not needing to scale as much as we'll be better utilizing the resources.\n\n### Single Points of Failure (SPOF)\n\nYou should look to identify weak spots (e.g. \"single points of failure\") in your architecture. These are places where by if any part of your application or service goes down, then the whole application becomes useless (see next section on failing gracefully). See the [architecture diagrams at the bottom of this page](https://gist.github.com/Integralist/39e4c5ee5a226d5dc0e2#file-designing-systems-md) which demonstrate a simple application which had a SPOF but re-architectured the applications and services so they could better handle potential failures and keep users unaware there was a problem with the system.\n\n### Fail Gracefully\n\nCertain components can't scale easily (such as databases \u0026 nosql document stores). In an ideal world we would build the application to fail gracefully. For example, we could monitor/watch for \"warning\" thresholds; and when critical mass is reached and the relevant alarm is fired (let's say an AWS SNS notification is sent) our applications (if subscribed to the SNS topic) would be able to take action to store off important data in an external service (in case of imminent failure) or worst case temporarily disabling certain features so the user doesn't lose important data.\n\nHow we fail should be determined by us and our application and will be dependent on the application being built (i.e. you couldn't fail in the exact same way for every application type as the requirements would be vastly different).\n\n### Caching\n\nAnalyse your architecture not only for SPOF but also to see where we can implement caching layers to reduce traffic load.\n\n## Concurrency\n\nConcurrency introduces many different types of problems. As an example, think of the classic \"Banker's Dilemma\" where by you have two customers: John and Bob who both have access to a joint account, which currently holds £10. If both John and Bob trigger an action at the same time (let's say John takes out £10 and Bob takes out £5) then what should be the outcome? If John's action was handled first then the account balance should be 0, but if Bob's action was triggered at the same time but didn't finish as quickly then we have an issue where he'll be attempting to take £5 from a 0 balance account.\n\n### Thread Safety\n\nAlthough a much larger discussion by itself, the principle of data being \"thread safe\" is that it is accessible via multiple threads at the same time and will not cause conflict. Usually have globally shared state can help, or better yet, writing applications that work with the idea of immutable data (where by a copy of the modified data is used and the original is left untouched - see languages such as Haskell and Clojure).\n\n\u003e Note: for more information on thread safety, have a read of  \nhttp://en.wikipedia.org/wiki/Thread_safety\n\n### Eventual Consistency\n\nThe principle of \"eventual consistency\" is implemented in distributed systems as a way to ensure that a data change will \"eventually\" be applied to all available nodes (i.e. it wont be immediate; as that is the tradeoff with the principle of \"high availability\").\n\nIf you want a change to be made immediately across multiple nodes then those nodes would need to be locked down long enough for the change to be replicated throughout. This could be a lengthy process and so the eventual consistency model was designed to keep availability high and allow for systems to keep running until the change had been safely applied throughout all available nodes.\n\n### CPU vs I/O\n\nA CPU/Processor can contain one or more cores. For example, a quad core processor that runs at speed of 3GHz will have 4 cores running at that speed.\n\nI/O, whether a file system action or Network - e.g. HTTP - action, can block and so if the application is designed to work concurrently (e.g. there are other threads the CPU can jump to in the mean time) then the current thread will be left to finish and another thread will be picked up instead (this is how concurrency works - the CPU interleaves between threads - this should also clarify how concurrency *is not* the same thing as paralleism).\n\nFor computational intensive operations you'll want the number of threads to be equal to the number of cores available.\n\nFor I/O intensive operations you'll want more threads than available cores. This is because (as explained above) the CPU/Processor will \"context switch\" to another thread when the current thread is blocked (hence it is better to have more threads than cores for I/O).\n\n### Calculating The Number of Threads\n\nTo calculate how many more threads than cores you'll need for an intensive set of I/O operations, use the following algorithm: \n\nNumber of Threads = Number of Available Cores / (1 - Blocking Coefficient)\n\n\u003e Note: the blocking coefficient (coefficient being a fancy word that means: a value used as a multiplier) is different depending on the operation. For a computational operation it is 0, where as a fully blocking operation it is 1.\n\nAn example of a blocking coefficient would be: `0.9` - which means a task blocks 90% (`0.9`) of the time \u0026 works only 10% (`0.1`) of the time. Meaning, if you has 2 cores then you'd want 20 threads.\n\n`2 / (1 - 0.9) = 20`\n\n### Thread Pools\n\nA thread pool is a collection of pre-determined threads that automatically handles the management of tasks from a queue. Thread pools can sometimes be more efficient (and practical) than manually maintaining individual threads via your own application. Languages such as Java (and indirectly JRuby) has built-in support for thread pools.\n\n![thread pool](https://cloud.githubusercontent.com/assets/180050/4523399/f7b9065c-4d36-11e4-98ed-65eb7b80313e.png)\n\n### Even Workload Distribution\n\nIf you have two cores and a very large queue of messages to process, then your initial thought would maybe be to split the queue (i.e. the tasks) into two. This would mean you could have two threads running (i.e. utilising both cores); the first thread processing the first queue data and the second thread handling the other half of the queue data.\n\nThe problem with this solution is that is doesn't necessarily guarantee even distribution of the tasks across your available cores. If our queue data consisted of a computational task such as calculating prime numbers then the first half of the queue would take a lot less time to process because the smaller prime numbers would take less time to calculate than the other queue (which if evenly split in two would mean the other queue would have the much larger prime numbers to calculate).\n\nThis means one core will be sitting idle while the other core is still processing data.\n\nWhat would be better is to have more *parts* than threads/cores. So if one \"part\" finishes more quickly than expected, then another part can be picked up. Simply diving our tasks into two parts means one core will likely be sitting idle for longer than the other core. But if we divide our tasks into more granular parts, then we can aim to utilise as much of each core as possible. \n\n## AWS\n\n### Understanding AutoScaling\n\nASG contains instances and so requires a Launch Configuration\n\nLaunch Configurations determine which instance is launched (AMI \u0026 Instance Type)\n\nAlarms are from CloudWatch and they determine when a scaling action (i.e. policy) should take place\n\nPolicies specify that instances should be launched or terminated\n\nScale up/down amount should be a multiple of the number availability zones (so ELB can evenly distribute)\n\nSteps: create launch config (specify AMI \u0026 instance type); create ASG (pass in launch config, availability zones, main/max instances, load balancers); create policies (to represent scaling actions); create alarms to trigger policies\n\n### Calculating Costs\n\nUse the official [AWS Simple Monthly Calculator](http://calculator.s3.amazonaws.com/index.html) to estimate costs of all services used. This is to help communicate to the business that we're aware of cost concerns and are designing our applications to be as cost effective as possible.\n\n### Prevention *AND* Reaction\n\nAs mentioned earlier, we don't want to just react to issues, but be prepared by proactively monitoring our services and utilizing resources such as CloudWatch alarms as a way to indicate preventative thresholds be crossed.  \n\nWe should be looking for sustained high usage and not solely worrying about specific spikes/peaks in traffic. High usage could be an indicator of a potential optimisation hot spot.\n\nWe should also be considerate of high profile events in our industry. With this knowledge we could indicate a potential to pre-warm our servers rather than just reacting to sudden high traffic loads. \n\n### Analyse Groups\n\nWe should try to utilise CloudWatch within the AWS console to analyse multiple servers at once. In doing this we can then monitor AutoScaling groups to ensure the group, as a whole, is healthy - rather than simply analysing smaller instances and not getting a view of the bigger picture.\n\nDepending on the system design and workflow of your application, the throughput on a queue should give us a correlating throughput in subsequent queues. For example, you might have a queue that takes in messages for orders to be processed, then once processed the successful order details are sent to a subsequent queue which are processed and emailed to the relevant customers. The \"processing\" queue \u0026 \"successful orders\" queue should have similar throughput - giving us a useful indication of a healthy overall system (i.e. we're not just processing orders and failing to process the emails to customers). \n","tags":""},{"id":"427746222345cfe81a24","title":"Using git bisect to find where a bug was introduced","content":"http://git-scm.com/docs/git-bisect\n\n```sh\ngit bisect start\ngit bisect bad # to indicate current commit is broken\ngit bisect good {commit} # to indicate the last good commit\n\n# at this point git will set HEAD to a specific commit within\n# the specified range of good-\u003ebad commits.\n#\n# you'll now run your code and if the code is working, you'll\n# mark it as a 'good', otherwise if the code is still broken\n# you'll mark it as 'bad'.\n#\n# once you're done going through all the necessary commits\n# git will tell you which commit introduced the bug.\n\ngit bisect bad|good # you'll run this command over and over while Git changes commits to find which commit introduced the bug\ngit bisect reset # to bail out of everything and move back to original HEAD (i.e. the latest broken commit)\n```\n\nYou can also filter what commits are included in a bisect like so:\n\n```sh\ngit bisect start -- ./sub_directory\n```\n\nThis will mean only commits that affected files inside of `./sub_directory` are considered.\n\n\u003e Note: you can also specify a range of commits to skip: `git bisect skip 0dae5f ff049ab ...`\n","tags":""},{"id":"1ac9e20330fd14db2390","title":"AWS Instance types","content":"- General Purpose\n  - \tM1, M3 (balanced CPU, Memory, Network resources)\n    - Small to mid size databases or data processing tasks\n\n- Compute Optmized\n  - C1, CC2 (higher computer power with increased CPUs compared to Memory)\n    - High traffic websites, on demand services, web servers, video encoding\n\n- Memory Optimized\n  - M2, CR1 (memory intensive applications)\n    - High perf databases, distributed cache\n\n- Storage Optimized\n  - HI1, HS1 (direct-attached storage, disk I/O \u0026 storage capacity requirements)\n    - HI1 for NoSQL databases like MongoDB\n    - HS1 for data warehouses like Hadoop clusters\n\n- Micro Instances\n  - Micro, T1 (small CPU)\n    - low throughput applications, low-traffic websites\n\n- GPU Instances\n  - CG1 (parallel performance, and high CPU)\n    - Very high computational algorithms and graphics rendering\n","tags":""},{"id":"9994331","title":"Ruby lambdas","content":"## Lambda: standard\n\n```ruby\n# Creating a lambda\nl = lambda { |name| \"Hi #{name}!\" }\n\n# Executing the lambda\nl.call(\"foo\") # =\u003e Hi foo!\n```\n\n## Lambda: shorthand\n\n```ruby\n# Creating a lambda using shorthand notation\nl = -\u003e name { puts \"Hi #{name}!\" }\n\n# Excuting the lambda using shorthand notation\nl.(\"foo\") # =\u003e Hi foo!\n\n# Multiple arguments\nl = -\u003e name, age { puts \"Hi #{name}! You're #{age} years young\" }\nl.(\"foo\", 32) # =\u003e Hi foo! You're 32 years young\n\n# No arguments\nl = -\u003e { puts \"foo!\" }\nl.() # =\u003e \"foo!\"\n```\n\n## Closures\n\nLambda's also enforce a closure and so are able to keep their context across objects, as demonstrated below:\n\n```rb\nrequire \"json\"\n\nclass Bar\n  attr_reader :l\n\n  def initialize(h = {})\n    @l = h[:l] || -\u003e _ { p \"no-op\"; false }\n  end\n\n  def dothing\n    result = l.(\"Mark\")\n    p \"result = #{result}\"\n  end\nend\n\nclass Foo\n  def initialize\n    @h = {\n      :l =\u003e -\u003e name { p \"hello #{name}\"; foo_test }\n    }\n    @bar = Bar.new(@h) # remove @h to test for defensive behaviour\n  end\n\n  def start\n    @bar.dothing\n  end\n\n  private\n\n  def foo_test\n    p \"I'm internal to Foo class\"\n    raise ::JSON::ParserError\n    true # never reached due to above line triggering an error\n  rescue ::JSON::ParserError\n    p \"caught an error\"\n    false\n  end\nend\n\nfoo = Foo.new\nfoo.start\n```\n\nThe default output of the above program is:\n\n```bash\n\"hello Mark\"\n\"I'm internal to Foo class\"\n\"caught an error\"\n\"result = false\"\n```\n\n## Lambda: partial application vs currying\n\n\u003e Partial function aplication is calling a function with some number of arguments, in order to get a function back that will take that many less arguments.  \n\u003e Currying is taking a function that takes `n` arguments, and splitting it into `n` functions that take one argument.  \n\u003e In order to give you a clearer idea of what each of these two things will do a function, let’s take an example Proc:  \n\u003e `proc { |x, y, z| x + y + z }`  \n\u003e Partial application of this function would return, if we passed in the first two arguments, the following nested Procs:  \n\u003e `proc { |x, y| proc { |z| x + y + z} }`  \n\u003e On the other hand, currying this function would return the following nested Procs:  \n\u003e `proc { |x| proc { |y| proc { |z| x + y + z} } }`  \n\u003e Note that you can only pass in one argument at a time to the result of a curried function, but pass as many as you like at a time when using partial application. This is the core principal that defines these two applications. The `Proc#curry` method in Ruby allows you to execute both of these applications.\n\n## Lambda: curry\n\n\u003e Currying: continuously partially apply a handler function until it receives all its expected requirements before invoking. Any remaining arguments will be passed on at invocation.\n\n\u003e `.curry` returns a curried proc. If the optional arity argument is given, it determines the number of arguments. A curried proc receives some arguments. If a sufficient number of arguments are supplied, it passes the supplied arguments to the original proc and returns the result. Otherwise, returns another curried proc that takes the rest of arguments.\n\n```ruby\n# Example 1\nl = lambda { |x, y, z| x + y + z }\nl.curry[1][2][3] # =\u003e 6\n\n# Example 2\na = l.curry[1] # =\u003e \u003cProc:0x007fc759a22920 (lambda)\u003e\nb = a[2]       # =\u003e \u003cProc:0x007fc759a68b00 (lambda)\u003e \nb[3]           # =\u003e 6\n\n# Better real world example\napply_math = -\u003e fn, a, b { a.send fn, b }\nadd = apply_math.curry.(:+)\nadd.(1, 2) # =\u003e 3\nincrement = add.curry.(1)\nincrement.(1) # =\u003e 2\nincrement.(5) # =\u003e 6\n```\n\n## Arity\n\n\u003e the arity of a function or operation is the number of arguments or operands the function or operation accepts\n\nArity is only useful when using an actual Proc and not a lambda. It's best to think of a lambda like it's an anonymous function; where as a Proc is more like code being 'included' into another chunk of code. \n\nFor example if you pass in a Proc to another function then the reason things like the number of arguments you pass to the Proc, and how the Proc's return values work (i.e. returning from a Proc also returns out of the containing function) is because effectively the Proc's code is injected into that other function. But as the lambda acts like a real anonymous function it will error if called with the wrong number of arguments and when executing a `return` it'll return out of only that specific block of code and doesn't effect the surrounding function code it was called within.\n\nNow the reason you need to know all this is that being able to use partial application via the arity argument will only work with a Proc. If you use a lambda then by its very nature will throw an error about incorrect number of arguments.\n\nThe following is an example of using arity:\n\n```ruby\np = proc { |x, y, z| x + y + z }\nadd_to_the_value_three = p.curry(2)\nadd_to_the_value_three[1][2] # =\u003e we're setting up the Proc to have first two args pre-filled (x, y == 1, 2)\n# Note: we more likely would've done p.curry(2)[1][2]\nadd_to_the_value_three[6] # =\u003e 9\n```\n","tags":""},{"id":"438898d6164daebec0c9","title":"AWS EC2 SSH Access and creating new AMI","content":"Access instance via SSH\n\nWe need to create a key pair via AWS Console (or CLI tool). AWS will load the public half of the key into your EC2 instances and when you try to SSH into the instance then AWS will require you to provide the private half of the key pair (you do this using the `-i path/to/private.pem` flag).\n\n```sh\n# We specify our private key (my.pem)\nssh -i ~/.ssh/path/to/my.pem root@ec2-xx-xx-xx-xx.some-name.amazonaws.com\n```\n\nDefault location of web page on base AWS AMI (open it and make a change):\n\n```sh\nvi /var/www/html/index.html\n```\n\nTo create a new AMI based off any modifications we make to the currently running instance:\n\n```sh\n# We're copying over our X.509 certificate and key (we use a glob as the names are quite long)\n# We copy them to the /mnt directory because we don't want the certs to be part of the new AMI generated\n# The bundling process excludes some folders, and /mnt is one of them\nscp -i ~/.ssh/path/to/my.pem ~/Temp/cert*.pem root@ec2-xx-xx-xx-xx.some-name.amazonaws.com:/mnt\nscp -i ~/.ssh/path/to/my.pem ~/Temp/pk*.pem root@ec2-xx-xx-xx-xx.some-name.amazonaws.com:/mnt\n\n# Verify X.509 files have been updated\nls -l /mnt\n```\n\nTo generate a new AMI based on the state of the currently running instance, ssh into the instance and run:\n\n```sh\nec2-bundle-vol \\\n  -d /mnt \\            # bundle to be stored\n  -k /mnt/pk-*.pem \\   # our key\n  -c /mnt/cert-*.pem \\ # our certificate\n  -u 926130534554 \\    # our user id\n  -r i386 \\            # image architecture\n  -p myNewBundleName   # file name prefix\n```\n\nFor full details see: http://docs.aws.amazon.com/AWSEC2/latest/CommandLineReference/CLTRG-ami-bundle-vol.html\n\nWe now need to upload the new AMI to S3, so still within the running instance execute the following command:\n\n```sh\nec2-upload-bundle \\\n  -b myS3BuckName \\                           # S3 Bucket name\n  -m /mnt/myNewBundleName.manifest.xml \\      # Manifest file for the new AMI bundle\n  -a 123 \\                                    # AWS Access Key ID\n  -s 456                                      # AWS Secret Access Key\n```\n\nFor full details see: http://docs.aws.amazon.com/AWSEC2/latest/CommandLineReference/CLTRG-ami-upload-bundle.html\n\nNow we need to register our new AMI (done via the AWS Console): \"Register New AMI\" under EC2 \u003e AMIs \nThen specify the locatation in S3: `{S3_buckname}/{path_to_manifest_xml}`\nNow from here we can launch an instance from this new AMI.\n","tags":""},{"id":"06004b0fccc2bed05460","title":"Docker tagging and ONBUILD","content":"When an author builds the image https://github.com/cpuguy83/docker-jruby/blob/10eae9359611104c013e82206104b40f20fac377/1.7/Dockerfile:\n\n```\nFROM java:8\nENV JRUBY_VERSION 1.7.16\nRUN mkdir /opt/jruby \\\n  \u0026\u0026 curl http://jruby.org.s3.amazonaws.com/downloads/${JRUBY_VERSION}/jruby-bin-${JRUBY_VERSION}.tar.gz \\\n  | tar -zxC /opt/jruby --strip-components=1 \\\n  \u0026\u0026 update-alternatives --install /usr/local/bin/ruby ruby /opt/jruby/bin/jruby 1\nENV PATH /opt/jruby/bin:$PATH\n\nRUN echo 'gem: --no-rdoc --no-ri' \u003e\u003e /.gemrc\n\nRUN gem install bundler\n\nCMD [ \"irb\" ]\n```\n\n...they tag it with (for example) `1.7.16` so that the other docker image https://github.com/cpuguy83/docker-jruby/blob/10eae9359611104c013e82206104b40f20fac377/1.7/onbuild/Dockerfile:\n\n```\nFROM jruby:1.7.16\n\nRUN mkdir -p /usr/src/app\nWORKDIR /usr/src/app\n\nONBUILD ADD Gemfile /usr/src/app/\nONBUILD ADD Gemfile.lock /usr/src/app/\nONBUILD RUN bundle install --system\n\nONBUILD ADD . /usr/src/app\n```\n\n...can then build from that (e.g. `FROM jruby:1.7.16`). \n\nThen when that image is pushed up they tag it `1.7-onbuild` (as they utilise the `ONBUILD` feature). \n\nWe then base our own Docker image off of `FROM jruby:1.7-onbuild`. Using `jruby:1.7-onbuild` means when we build our own image the gems are already installed, and it avoids the issue of installing the Gems every time you execute `docker run` an image to start up a container.\n\n","tags":""},{"id":"a2c2fcdf565047910126","title":"Monads in JavaScript and the power of composability","content":"// The Monad design pattern functions\n// i.e. compose, bind, unit, lift\n\n// These are functions that are part of the design pattern's \"interface\"\n// Their implementation can change (well, maybe not `compose`) \n// but these function identifiers should be implemented \n// as other devs will use those identifiers as a common language \n// when discussing the Monad pattern\n\n// compose = returns a function that takes a data structure (accepted data structure argument is passed to `g` and then result of that is passed to `f`)\n// bind = returns a function that takes a data structure (function return value is same expected data structure type; function extracts values from original data structure and manipulates them before returning new data structure)\n// unit = wraps the value provided in a data structure that is expected by other functions we'll be using\n// lift = returns a function that accepts a value. The value is passed to the lifted function and that return value is passed to `unit`. It uses partial application to call `compose` with first argument pre-filled (in this case `unit`) and then function provided as argument to `lift` is passed as second argument to `compose` (returning a function that accepts a single value; accepted argument to that function is passed to `g` and then result of that is passed to `f`)\n\nvar compose = function(f, g) {\n  return function(x) {\n    return f(g(x));\n  };\n};\n\nvar bind = function(f) {\n  return function(tuple) {\n    var x  = tuple[0],\n        s  = tuple[1],\n        fx = f(x),\n        y  = fx[0],\n        t  = fx[1];\n\n    return [y, s + t];\n  };\n};\n\nvar unit = function(x) { return [x, ''] };\nvar lift = function(f) { return compose(unit, f) };\n\n// User functions\n\nvar sine       = function(x) { return [Math.sin(x), 'sine was called.'] };\nvar round      = function(x) { return Math.round(x) };\nvar roundDebug = lift(round);\n\n// See our example executed...\n\n/*\n  compose(bind(roundDebug), bind(sine))\n\n    function (x) {\n      return f(g(x));\n    }\n*/\nvar f = compose(bind(roundDebug), bind(sine));\n\nconsole.log(\n  f(unit(27))\n); // -\u003e [1, 'sine was called.']\n\n// ----------------------------------------------------------------------------\n// ----------------------------------------------------------------------------\n// ----------------------------------------------------------------------------\n\n// Breakdown of each function's composability...\n\n// [27, \"\"]\nconsole.log(unit(27));\n\n// f = function (x) { return f(g(x)) }\nconsole.log(compose(bind(roundDebug), bind(sine)));\n\n// [0.8414709848078963, \"sine was called.\"]\nconsole.log(sine(1));\n\n// 1\nconsole.log(round(1));\n\n// function (x) { return f(g(x)) }\n// i.e. function (x) { return unit(round(x)) }\nconsole.log(lift(round));\n\n// [1, \"\"]\n// roundDebug was `lift`ed\nconsole.log(roundDebug(1));\n\n/*\n  Both functions below return (where `f` is the function binded)...\n\n  function (tuple) {\n    var x  = tuple[0],\n        s  = tuple[1],\n        fx = f(x),\n        y  = fx[0],\n        t  = fx[1];\n\n    return [y, s + t];\n  }\n*/ \nconsole.log(bind(roundDebug));\nconsole.log(bind(sine));\n\n/*\n  function (x) { return f(g(x)) }\n  \n  i.e.\n  function (x) {\n    return function (tuple) {\n      var x  = tuple[0],\n          s  = tuple[1],\n          fx = roundDebug(x),\n          y  = fx[0],\n          t  = fx[1];\n\n      return [y, s + t];\n    }(\n      function (tuple) {\n        var x  = tuple[0],\n            s  = tuple[1],\n            fx = sine(x),\n            y  = fx[0],\n            t  = fx[1];\n\n        return [y, s + t];\n      }(x)\n    )\n  }\n*/\nconsole.log(compose(bind(roundDebug), bind(sine)));\n\n// f(unit(27)) == function ([27, \"\"]) { return f(g([27, \"\"])) }\nAll code sourced directly from:\nhttps://blog.jcoglan.com/2011/03/05/translation-from-haskell-to-javascript-of-selected-portions-of-the-best-introduction-to-monads-ive-ever-read/\n\n- `compose`, which converts two functions into a composed/nested set of functions\n- `bind`, which converts a debuggable function into a composable form\n- `unit`, which converts a simple value into the format required for debugging, by placing it in a container\n- `lift`, which converts a ‘simple’ function into a debuggable function\n\n## some functions\n\n```js\n// These functions want to be composable but aren't because\n// they return different data types to what was passed in.\n// The functions are no longer \"pure\"\nvar sine = function(x) {\n  return [Math.sin(x), 'sine was called.'];\n};\n\nvar cube = function(x) {\n  return [x * x * x, 'cube was called.'];\n};\n```\n\n## compose\n\n```js\n// Takes two functions f and g and \n// returns another function that computes f(g(x))\nvar compose = function(f, g) {\n  return function(x) {\n    return f(g(x));\n  };\n};\n```\n\n## bind\n\n```js\n// Take a Number -\u003e (Number,String) function and \n// return a (Number,String) -\u003e (Number,String) function\nvar bind = function(f) {\n  return function(tuple) {\n    var x  = tuple[0],\n        s  = tuple[1],\n        fx = f(x),\n        y  = fx[0],\n        t  = fx[1];\n    \n    return [y, s + t];\n  };\n};\n```\n\n## unit\n\n```js\n// The role of unit is to take a value and wrap it in a basic container \n// that the functions we’re working with can consume. \n// For our debuggable functions, this just means \n// pairing the number with a blank string:\n// unit :: Number -\u003e (Number,String)\nvar unit = function(x) { return [x, ''] };\n\n// This unit function also lets us convert any function into a debuggable one, \n// by converting its return value into an acceptable input for debuggable functions:\n\n// round :: Number -\u003e Number\nvar round = function(x) { return Math.round(x) };\n\n// roundDebug :: Number -\u003e (Number,String)\nvar roundDebug = function(x) { return unit(round(x)) };\n\n// This type of conversion, from a 'plain' function to a debuggable one, \n// can be abstracted into a function we’ll call lift (see below)\n```\n\n## lift\n\n```js\n// lift :: (Number -\u003e Number) -\u003e (Number -\u003e (Number,String))\nvar lift = function(f) {\n  return function(x) {\n    return unit(f(x));\n  };\n};\n\n// or, more simply:\nvar lift = function(f) { return compose(unit, f) };\n```\n\n## Example (using the above functions)\n\n```js\nvar sine = function(x) {\n  return [Math.sin(x), 'sine was called.'];\n};\n\nvar compose = function(f, g) {\n  return function(x) {\n    return f(g(x));\n  };\n};\n\nvar bind = function(f) {\n  return function(tuple) {\n    var x  = tuple[0],\n        s  = tuple[1],\n        fx = f(x),\n        y  = fx[0],\n        t  = fx[1];\n\n    return [y, s + t];\n  };\n};\n\nvar unit = function(x) { return [x, ''] };\n\nvar lift = function(f) { return compose(unit, f) };\n\n// Usage...\nvar round = function(x) { return Math.round(x) };\nvar roundDebug = lift(round);\nvar f = compose(bind(roundDebug), bind(sine));\nf(unit(27)) // -\u003e [1, 'sine was called.']\n```\n\n## Monads?\n\nThe functions `bind` and `unit` describe a Monad.\n\nSo what is a monad? Well, it’s a design pattern. It says that whenever you have a class of functions that accept one type of thing and return another type of thing, there are two functions that can be applied across this class to make them composable:\n\n- There is a `bind` function that transforms any function so that accepts the same type as it returns, making it composable\n- There is a `unit` function that wraps a value in the type accepted by the composable functions.\n\nIt's a very useful design pattern to be aware of because it helps you spot accidental complexity: code that isn't dealing directly with the problem at hand, but which is dealing with glueing data types together. Being able to spot and extract such boilerplate can radically improve the clarity of your code.\n\n## DOM example\n\nSuppose you have a function whose job is to take one DOM node and return all its children as an array; \nits function signature says that it takes a single HTMLElement and returns an array of HTMLElements.\n\n```js\n// children :: HTMLElement -\u003e [HTMLElement]\nvar children = function(node) {\n  var children = node.childNodes, ary = [];\n  for (var i = 0, n = children.length; i \u003c n; i++) {\n    ary[i] = children[i];\n  }\n  return ary;\n};\n\nvar heading = document.getElementsByTagName('h3')[0];\nchildren(heading)\n```\n\nTo get the grandchildren we might manually write it like:\n\n```js\n// grandchildren :: HTMLElement -\u003e [HTMLElement]\nvar grandchildren = function(node) {\n  var output = [], childs = children(node);\n  for (var i = 0, n = childs.length; i \u003c n; i++) {\n    output = output.concat(children(childs[i]));\n  }\n  return output;\n};\n```\n\nBut that's not very functional. We need to take two steps to fix this: provide a `bind` function to turn children into composable form, and write a `unit` function to turn the initial input – the heading – into an acceptable type.\n\n```js\n// unit :: a -\u003e [a]\nvar unit = function(x) { return [x] };\n\n// bind :: (a -\u003e [a]) -\u003e ([a] -\u003e [a])\nvar bind = function(f) {\n  return function(list) {\n    var output = [];\n    for (var i = 0, n = list.length; i \u003c n; i++) {\n      output = output.concat(f(list[i]));\n    }\n    return output;\n  };\n};\n```\n\nWe can now compose children as desired:\n\n```js\nvar div = document.getElementsByTagName('div')[0];\nvar grandchildren = compose(bind(children), bind(children));\n\ngrandchildren(unit(div))\n// -\u003e [\u003ch1\u003e…\u003c/h1\u003e, \u003cp\u003e…\u003c/p\u003e, ...]\n```\n","tags":""},{"id":"4691a91dae0d7e1bb3d4","title":"Node Dockerfile with PhantomJS","content":"FROM node:0.10\n\nRUN apt-get update\nRUN apt-get install curl build-essential chrpath git-core libssl-dev libfontconfig1-dev libxft-dev\n\nRUN apt-get update \\\n\u0026\u0026 curl -o phantomjs.tar.gz -L https://bitbucket.org/ariya/phantomjs/downloads/phantomjs-1.9.7-linux-x86_64.tar.bz2 \\\n\u0026\u0026 tar -xvf phantomjs.tar.gz \\\n\u0026\u0026 mv phantomjs-1.9.7-linux-x86_64/bin/phantomjs /usr/bin\n\nRUN apt-get autoremove -y\nRUN apt-get clean all\n","tags":""},{"id":"13d9f5e8ec197e5e53c6","title":"Get a git diff and apply git diff using gist ruby gem -\u003e https://github.com/defunkt/gist (also see this alternative using `git format-patch`: https://gist.github.com/Integralist/87852ced09d7918322c0)","content":"git show HEAD HEAD~1 # (or use a hash instead: `git show {commit} {commit} {commit}`)\n\ngit diff --cached | gist -p -f test.diff\n\ncurl https://gist.githubusercontent.com/anonymous/x/raw/x/test.diff | git apply\n\ncurl https://gist.githubusercontent.com/anonymous/x/raw/x/test.diff | git apply --reverse\n","tags":""},{"id":"3e9c2ab8c1733c71a00c","title":"Recursion and Trampolines in JavaScript (code copied from JS Drip Newsletter ","content":"function trampoline (func, arg) {\n    var value = func(arg);\n\n    while(typeof value === \"function\") {\n        value = value();\n    }\n\n    return value;\n}\n\ntrampoline(isEvenInner, 99999);\n// =\u003e false\n\ntrampoline(isEvenInner, 99998);\n// =\u003e true\n\nvar isEven = trampoline.bind(null, isEvenInner);\n\nisEven(99999);\n// =\u003e false\nfunction isEvenNaive (num) {\n    if (num === 0) {\n        return true;\n    }\n\n    if (num === 1) {\n        return false;\n    }\n\n    return isEvenNaive(Math.abs(num) - 2);\n}\n\nisEvenNaive(10);\n// =\u003e true\n\nisEvenNaive(9);\n// =\u003e false\n\nisEvenNaive(99999);\n// =\u003e InternalError: too much recursion\nfunction isEvenInner (num) {\n    if (num === 0) {\n        return true;\n    }\n\n    if (num === 1) {\n        return false;\n    }\n\n    return function() {\n        return isEvenInner(Math.abs(num) - 2);\n    };\n}\n\nisEvenInner(8);\n// =\u003e function() {\n//        return isEvenInner(Math.abs(num) - 2);\n//    };\n\nisEvenInner(8)()()()();\n// =\u003e true\n\n/*\nThe first thing to notice about our isEvenInner function is that instead of directly calling itself again, it returns an anonymous function. That means each call to isEvenInner gets resolved immediately, and doesn't increase the size of the stack. It also means that we need a way to automatically invoke all of those anonymous functions that will get returned along the way. That's where trampoline comes in.\n\nThe trampoline function effectively turns this recursive algorithm into something that is executed by a while loop. As long as isEvenInner keeps returning functions, trampoline will keep executing them. When we finally reach a non-function value, trampoline will return the result.\n */\n","tags":"#65)"},{"id":"8015efed6bfb59ee93af","title":"Ruby: Check Balanced Params","content":"def check_balanced(str)\n  str.chars.reduce(0) { |open, char|\n    if char == ')' \u0026\u0026 open == 0\n      return false\n    elsif char == '('\n      open + 1\n    elsif char == ')'\n      open - 1\n    else\n      open\n    end\n  } == 0\nend\n\ncheck_balanced \"(()())\"\n","tags":""},{"id":"9d02e37ee65746cdafdb","title":"Ruby Threads","content":"- MRI 1.8 (Green Threads)\n- MRI 1.9 (Native Threads; concurrent interleaving but no parallelism due to non-thread safe Ruby code)\n- JRuby (Native Threads + Parallelism)\n","tags":""},{"id":"99577f14fb01101123bb","title":"Mori.js Calendar Application (NodeJS) -\u003e copied from the talk http://vimeo.com/96425437","content":"var mori = require(\"mori\");\n\nfunction Calendar(appointments, previousCalendar) {\n\tappointments = appointments;\n\n  var cal = {};\n  \n  cal.add = function(appointment) {\n  \tvar withAppointments = mori.conj(appointments, appointment);\n    return Calendar(withAppointments, cal);\n  };\n  \n  cal.upcoming = function(start, n) {\n    var futureAppointments = mori.filter(function(a) {\n    \treturn a.date \u003e= start;\n    }, appointments);\n    \n    return mori.take(n, futureAppointments);\n  };\n  \n  cal.undo = function() {\n  \treturn previousCalendar || Calendar();\n  };\n  \n  return cal;\n}\n\nvar myCalendar = Calendar().add({\n  title: 'X',\n  date: Date.parse('2014-07-11T18:00') // update this\n}).add({\n  title: 'Y',\n  date: Date.parse('2014-07-11T19:00') // update this\n}).add({\n  title: 'Z',\n  date: Date.parse('2014-07-11T20:00') // update this\n});\n\nvar nextAppointments = myCalendar.upcoming(Date.now(), 2);\n\nconsole.log(\n  mori.map(function(a) {\n  \treturn a.title;\n  }, nextAppointments).toString() // we need to convert the Mori object some how (.toString for ease)\n); // =\u003e (\"Z\" \"Y\")\n\nvar previousCalendar = myCalendar.undo().undo();\nvar appointments = previousCalendar.upcoming(Date.now(), 2);\n\nconsole.log(\n  mori.map(function(a) {\n  \treturn a.title;\n  }, appointments).toString()\n); // =\u003e (\"X\")\n","tags":""},{"id":"43b6da80a91827671e55","title":"Process for rebasing Pull Request","content":"1. On the PR branch\n2. `git rebase -i master` (i.e. `git rebase -i {parent_commit_of_first_commit_in_PR}`)\n3. Change top commit (the oldest) to `reword`\n4. Change all other commits to `fixup`\n5. In commit message (line 1) change title to reflect entire PR\n6. In commit message (line 2) add `Closes #n` and/or `Fixes #n`\n7. In commit message (line 3) add `Authors: @integralist`\n8. `git checkout master`\n9. `git merge {PR_branch}` or `git cherry-pick {new_rebased_commit}`\n10. `git branch -D {PR_branch}`\n11. `git push origin master`\n","tags":""},{"id":"e8b0adc5bb96a4162aea","title":"Mori.js ClojureScript Data Structures in plain vanilla JavaScript -\u003e http://swannodette.github.io/mori/ and https://github.com/swannodette/mori","content":"var mori = require(\"mori\");\n\nvar inc = function(n) {\n  return n+1;\n};\n\nvar v1 = mori.vector(1,2,3,4,5);\nvar v2 = mori.map(inc, v1);\n\nconsole.log(v2.toString()); // =\u003e (2 3 4 5 6) \nconsole.log(mori.into_array(v1)); // =\u003e [1, 2, 3, 4, 5] \nconsole.log(mori.into_array(v2)); // =\u003e [2, 3, 4, 5, 6] \n\nconsole.log(\n  mori.into_array(\n    mori.map(inc, mori.vector(1,2,3,4,5))\n  )\n); // =\u003e [2, 3, 4, 5, 6] \n","tags":""},{"id":"a9b12a7a3db9f9ca11ba","title":"Ruby string formatting functionality (like PHP's sprintf)","content":"\"foo-%s-baz\" % \"bar\" # =\u003e \"foo-bar-baz\"\n\"foo-%s-baz\" % 123   # =\u003e \"foo-123-baz\"\n","tags":""},{"id":"c7277cbacd53487b3bb0","title":"Software Simplicity","content":"- Simplicity !== Easy\n- Easy is short term and can sometimes even introduce complexity\n- Simplicity allows for easy while avoiding complexity\n- Complect == tangling/braiding together\n- Complexity is the *result* of something that has been complected\n- Untangle complected code (e.g. decoupling of components)\n- Do not chain calls (i.e. Law of Demeter)\n- Consider Channels as form of asynchronous flow control\n- Ask yourself all the time: \"can this *thing* be moved? does it have well defined boundaries?\"\n","tags":""},{"id":"30a2c7351c028a0dda32","title":"Polling example with back pressure handling","content":"define(['module/bootstrap', 'module/dispatch', 'config'], function(news, dispatch, config) {\n    var URL = config.dynamic.broker;\n    var cb;\n\n    function seconds(secs) {\n        return secs * 1000;\n    }\n\n    function minutes(mins) {\n        return mins * seconds(60);\n    }\n\n    function incrementDelay() {\n        if (delay \u003c THRESHOLD) {\n            delay *= 2;\n        }\n\n        return delay; // we return a value for the sake of our `dispatch` method called by `statusChecks`\n    }\n\n    var statusChecks = dispatch(\n        function(status) { return status === 304       ? incrementDelay()   : null; },\n        function(status) { return status === 200       ? delay = seconds(5) : null; },\n        function(status) { return status === 420       ? true               : null; },\n        function(status) { return status === 'timeout' ? true               : null; }\n    );\n\n    function isSafeToCallback(status, rest) {\n        return status ? executeCallback(rest[0]) : null;\n    }\n\n    function trackTimeout() {\n        failCount++;\n\n        return disablePolling(failCount \u003e FAIL_THRESHOLD);\n    }\n\n    function tooManyRequests(timeout, resultFromStatusCheck) {\n        return timeout ? trackTimeout() : resultFromStatusCheck;\n    }\n\n    function disablePolling(status) {\n        return status ? true : false;\n    }\n\n    function delayPolling(disabled) {\n        if (!disabled) {\n            incrementDelay();\n            poll(endpoint(URL));\n        }\n    }\n\n    function executeCallback(data) {\n        cb(data);\n        poll(endpoint(URL));\n    }\n\n    function success(data, status, xhr) {\n        isSafeToCallback(\n            statusChecks(xhr.status), data\n        );\n    }\n\n    // This alias helps make a call to statusChecks inside failure fn clearer\n    // Otherwise it would look like we're calling the same function twice\n    var checkForTimeout = statusChecks;\n\n    function failure(xhr, status, error) {\n        delayPolling(\n            disablePolling(\n                tooManyRequests(\n                    checkForTimeout(status), statusChecks(xhr.status)\n                )\n            )\n        );\n    }\n\n    function postDataAssetTemplate(data) {\n        return {\n            \"type\": \"asset\",\n            \"payload\": {\n                \"component_id\": data.id,\n                \"options\": data.opts\n            }\n        };\n    }\n\n    function generateJsonData() {\n        var obj  = config.dynamic.components;\n        var data = { requests: [] };\n\n        for (var prop in obj) {\n            data.requests.push(\n                postDataAssetTemplate(obj[prop])\n            );\n        }\n\n        return JSON.stringify(data);\n    }\n\n    function endpoint(url) {\n        return (function(url) {\n            return function() {\n                news.$.ajax(url, {\n                    processData : false,\n                    type        : 'post',\n                    contentType : 'application/json',\n                    data        : generateJsonData(),\n                    timeout     : seconds(5)\n                }).then(success, failure);\n            };\n        }(url));\n    }\n\n    function poll(endpoint) {\n        return window.setTimeout(endpoint, delay);\n    }\n\n    // Constants\n    var THRESHOLD      = seconds(20);\n    var FAIL_THRESHOLD = 5;\n\n    // Mutables\n    var delay     = seconds(5);\n    var failCount = 0;\n\n    return function(callback) {\n        cb = callback;\n        poll(endpoint(URL));\n    };\n});\n\n// Fuzzying the delay was a bit confusing so left it for now\n","tags":""},{"id":"b79b7a7706cc150b457c","title":"Ruby: pass a block to a function that has zero arity (i.e. don't define \u0026block inside of our initialize method). The point of this demonstration is that you are able to pass a block through to another method whilst not initially defining an argument for the block to be passed by. This way we gain better performance (calling a proc is very slow compared to yielding), and regardless we're not able to pass a yield through to another method.","content":"I saw this in some code written by BBC principle developer @kenoir and later located the following useful post: http://mudge.name/2011/01/26/passing-blocks-in-ruby-without-block.html\n\n```ruby\nclass Foo\n  def initialize\n    bar \u0026Proc.new # voodoo\n  end\n  def bar(\u0026block)\n    block.call\n  end\nend\n\nFoo.new { puts \"hai\" }\n```\n\nIn short, the reason it works is this: \n\n\u003e If `Proc.new` is called from inside a method without any arguments of its own, it will return a new Proc containing the block given to its surrounding method.\n\nVery nice!\n","tags":""},{"id":"d67f0f913d795f703b89","title":"Design Patterns: Adapter vs Facade vs Bridge","content":"The three design patterns (Adapter, Facade and Bridge) all produce the result of a clean public API. The difference between the patterns are usually due to a subtle context shift (and in some cases, a behavioural requirement).\n\n## Adapter\n\nThe primary function of an Adapter is to produce a *unified* interface for a number of underlying and unrelated objects.\n\nYou will notice this pattern being utilised in many applications. For example, ActiveRecord (the popular Ruby ORM; object-relational mapping) creates a unified interface as part of its API but the code underneath the interface is able to communicate with many different types of databases. Allowing the consumer of the API to not have to worry about specific database implementation details.\n\nThe principle structure of this pattern is:\n\n```\nCurrent | Future\n----------------\nB(C)    | B(A)\n```\n\nThe `B` function cannot be changed and it is dependant on the interface that was originally provided by `C`, but now we are passing in `A` which has an incompatible interface.\n\nAn adapter can solve this by creating a new function `A2C` which contains the relevant logic for handling the interaction between `B` and `A`.\n\n```\nCurrent | Future\n----------------\nB(C)    | B(A2C(A))\n```\n\n## Facade\n\nThe primary function of a Facade is to simplify the interaction between a consumer and an interface.\n\nMost DSL's are a facade of some form. The popular jQuery library consists of multiple facades (one for each type of feature). For example, the jQuery `ajax` method makes it very easy to make an XHR (`XMLHttpRequest`).\n\n\u003e The difference between a Facade and an Adapter is that the Facade makes a simple abstraction, where as an Adapter will handle complex interactions by taking incoming data and constructing it to work with the underlying objects.\n\n## Bridge\n\nThe primary function of a Bridge is to decouple an abstraction from its implementation.\n\n\u003e Adapter makes things work _after_ they're designed  \n\u003e Bridge makes them work _before_ they are\n\nImagine you have a function that abstracts the implementation detail of making an HTTP request to an external API endpoint. In a language like JavaScript you might tightly couple the abstraction with the consumer code.\n\nFor example:\n\n```js\nfunction get(e) {\n  return asyncRequest('foo?bar=' + this.id, function(response) {\n    console.log(response)\n  })\n}\n\nmyTrigger.addEventListener('click', get, false)\n```\n\nThe above abstraction (i.e. the `get` function) will only ever work within the context of a web browser. The abstraction has been tightly coupled to the consumer.\n\nUtilising a bridge will allow us to decouple this code:\n\n```js\nfunction get(id, callback) {\n  return asyncRequest('foo?bar=' + id, function(response) {\n    callback(response)\n  })\n}\n\nfunction getBridge(e) {\n  get(this.id, function(response) {\n    console.log(response)\n  })\n}\n\nmyTrigger.addEventListener('click', getBridge, false)\n```\n","tags":""},{"id":"3b6b69e1bafb30b81890","title":"Data Structures","content":"## Update\n\nThis gist has been superseded by https://github.com/Integralist/Data-Structures and also https://www.integralist.co.uk/data-types-and-data-structures/\n\n---\n\n\u003e Note:  \n\u003e sequential == collection keeps order of population  \n\u003e ordered == collection is re-ordered (implements a Sequence interface)\n\n**Tuple**\n\n- ordered\n- duplicates allowed\n\n**Set**\n\n- sequential\n- no duplicates\n\n\u003e Note: Clojure's Set data structure appears to be ordered `#{3 1 2}`, `(first #{3 1 2})` returns 1\n\n**Linked list**\n\n- list contains nodes\n- each node holds: \n  - data\n  - pointer to the next node\n- the last node's pointer points to `null` \n  - this is a singly linked list\n  - a doubly linked list will also have a pointer to the previous node\n- no direct access to individual elements\n  - you must access the head and navigate until element is found\n\n**Array/Vector**\n\n- index access\n- duplicates allowed\n- Vectors are synchronised (i.e. thread-safe)\n- Arrays allow operations across multiple threads (i.e. not thread-safe)\n- Array size is determined up front\n  - you cannot remove an element from an Array\n    - but you can put a null pointer or no value to it\n- Vector is dynamic (i.e. it can resize dynamically based on new elements added)\n- Arrays can't add elements to a specific index, only to the end. \n- Vectors are like super Arrays.\n\n**List/Sequence**\n\n- ordered\n- duplicates allowed (but finite size)\n\n**Stack**\n\n- ordered\n- LIFO (last in, first out)\n- only actions available are `push` and `pop` (`push` directs \"in\", `pop` directs \"out\")\n\n**Queue**\n\n- ordered\n- FIFO (first in, first out)\n- only actions available are `enqueue` and `dequeue` (`enqueue` directs \"in\", `dequeue` directs \"out\")\n","tags":""},{"id":"d84d65c909eeafe4dfca","title":"Functional Programming: Polling XHR","content":"define(['module/bootstrap'], function(news) {\n    var $ = news.$;\n\n    function seconds(secs) {\n        return secs * 1000;\n    }\n\n    function incrementDelay() {\n        // don't want the delay to become ridiculous so I set a threshold I don't want it to go beyond\n        if (delay \u003c threshold) {\n            delay *= 2;\n        }\n\n        return delay; // we return a value for the sake of our `dispatch` method called by `checkStatus`\n    }\n\n    function exists(value) {\n        return value !== undefined \u0026\u0026 value !== null;\n    }\n\n    function dispatch() {\n        var fns  = Array.prototype.slice.call(arguments, 0);\n        var size = fns.length;\n\n        return function(target) {\n            var ret;\n\n            for (var i = 0; i \u003c size; i++) {\n                var fn = fns[i];\n\n                ret = fn.call(fn, target);\n\n                if (exists(ret)) {\n                    return ret; // break out of the loop as we've executed a function that doesn't return null\n                }\n            }\n\n            return ret;\n        };\n    }\n\n    var checkStatus = dispatch(\n        function(status) { return status === 304 ? incrementDelay()   : null; },\n        function(status) { return status === 200 ? delay = seconds(5) : null; }\n    );\n\n    function success(data, status, xhr) {\n        checkStatus(xhr.status);\n        poll(endpoint);\n    }\n\n    function failure(xhr, status, error) {\n        incrementDelay();\n        poll(endpoint);\n    }\n\n    function endpoint() {\n        $.ajax('http://localhost:3000/foobar', { timeout: limit }).then(success, failure);\n    }\n\n    function poll(endpoint) {\n        window.setTimeout(endpoint, delay);\n    }\n\n    var limit     = seconds(5);  // XHR timeout limit\n    var delay     = seconds(5);  // timer delay\n    var threshold = seconds(20); // timer delay threshold\n\n    poll(endpoint);\n});\n","tags":""},{"id":"a96cf6d6f01d5d0cce0a","title":"Ruby OOP vs FP (examples are from ThoughtBot's Weekly Iteration -\u003e you should subscribe!)","content":"# Examples taken from ThoughtBot's Weekly Iteration\n# We need to implement a solution that allows us to cleanly use two separate APIs\n\n# Our fake APIs\nPayPal.charge!(auth_code, 25)\nStripe::CreditCard.new(credit_card_token).charge(25)\n# Both of the below classes are utilising the principle of polymorphism\n\n# Strategy pattern (passing in object that determines the strategy to be used)\nclass Payment \u003c Struct.new(:price, :client)\n  def charge\n    client.charge(price)\n  end\nend\n\n# Adapter pattern (creates a consistent internal API when using an external API)\nclass PayPalAdapter \u003c Struct.new(:auth_code)\n  def charge(amount)\n    PayPal.charge!(auth_code, amount)\n  end\nend\n\n# Consistent API thanks to Adapter pattern\nPayment.new(25, Stripe::CreditCard.new(credit_card_token)).charge\nPayment.new(25, PayPalAdapter.new(auth_code)).charge\n# The .call() method allows us to execute the provided method\n# and pass through an argument to that method.\n# In the following code examples we call Payment.new and pass in a method which can be called\nclass Payment \u003c Struct.new(:price, :client)\n  def charge\n    client.call(price)\n  end\nend\n\n# Use .method() to return a Proc which the above charge method can trigger a .call() on\n# http://www.ruby-doc.org/core-2.1.1/Method.html\nPayment.new(\n  25, \n  Stripe::CreditCard.new(credit_card_token).method(:charge)\n).charge\n\n# Again use .method() to return a Proc\n# This means we can then use Currying to return another Proc \n# That returned Proc has its first argument pre-filled with :auth_code\n# The above charge method can then trigger .call() on the curried Proc (passing in the remaining argument)\nPayment.new(\n  25, \n  PayPal.method(:charge!).curry(:auth_code)\n).charge\n","tags":""},{"id":"e239380bb4e4c5b50280","title":"RoboHydra","content":"/*\n    In project directory:\n\n    - npm install robohydra\n    - create file ./my_config.conf (content of file below)\n\n    {\n        \"plugins\": [\n            {\n                \"name\": \"some_name\",\n                \"config\": {}\n            }\n        ]\n    }\n\n    - create directory structure for a custom plugin: ./robohydra/plugins/some_name/index.js (content of file below)\n    - notice \"some_name\" in plugin directory path matches content inside \"my_config.conf\"\n    - run `robohydra -p 3000 my_config.conf` to start RoboHydra server (port 3000 is the default so can be left out)\n */\n\n// Content of ./robohydra/plugins/some_name/index.js\n\nvar robohydra    = require('robohydra');\nvar Server       = robohydra.heads.RoboHydraHead;\nvar StaticServer = robohydra.heads.RoboHydraHeadStatic;\nvar Response     = robohydra.Response // used specifically by RoboHydraHead\n\nexports.getBodyParts = function(config) {\n    return {\n        // Each \"head\" represents an endpoint\n        heads: [\n            new Server({\n                path: '/foobar',\n                // We need to manually write JSON\n                // compared to the StaticServer version (see below example)\n                handler: function(req, res) {\n                    // Allow AJAX requests across domains\n                    res.headers['Access-Control-Allow-Origin'] = '*';\n                    res.headers['Access-Control-Allow-Headers'] = 'X-Requested-With';\n\n                    res.statusCode = 200;\n                    res.send('{ \"foo\": 1, \"bar\": 2 }');\n                }\n            })\n        ],\n        // \"scenarios\" are like categories\n        // you need to enable scenarios manually via admin area\n        // http://localhost:3000/robohydra-admin/scenarios/\n        scenarios: {\n            // a category I called \"example\" (it could be called anything you like)\n            // that has same endpoint as the above \"default\"\n            // but serves slightly different content\n            example: {\n                heads: [\n                    new StaticServer({\n                        path: '/foobar',\n                        // Specifying an object for the content means\n                        // RoboHydra will automatically send back JSON\n                        content: {\n                            foo: 3,\n                            bar: 4\n                        }\n                    })\n                ]\n            },\n            // a category I called \"failure\" (it could be called anything you like)\n            failure: {\n                heads: [\n                    new StaticServer({\n                        path: '/.*',\n                        content: 'Unhandled exception of some kind (fake)',\n                        statusCode: 500\n                    })\n                ]\n            },\n            // a category I called \"timeout\" (it could be called anything you like)\n            timeout: {\n                heads: [\n                    new Server({\n                        path: '/slow',\n                        handler: function(req, res) {\n                            // Allow AJAX requests across domains\n                            res.headers['Access-Control-Allow-Origin'] = '*';\n                            res.headers['Access-Control-Allow-Headers'] = 'X-Requested-With';\n\n                            // Mimic a slow connection\n                            setTimeout(function() {\n                                res.statusCode = 504;\n                                res.send('The server did not receive a timely response (fake)');\n                            }, 5000);\n                        }\n                    }),\n                    new Server({\n                        path: '/slower/:milliseconds',\n                        handler: function(req, res) {\n                            // Allow AJAX requests across domains\n                            res.headers['Access-Control-Allow-Origin'] = '*';\n                            res.headers['Access-Control-Allow-Headers'] = 'X-Requested-With';\n\n                            // User determines how slow the connection is\n                            // http://localhost:3000/slower/10000\n                            setTimeout(function() {\n                                res.statusCode = 504;\n                                res.send('The server did not receive a timely response (fake)');\n                            }, req.params.milliseconds);\n                        }\n                    })\n                ]\n            }\n        }\n    };\n};\n","tags":""},{"id":"fe4221f6207471b614ce","title":"[Example of using cat to pass HEREDOC content into a file] ","content":"cat \u003e foo.txt \u003c\u003cEOF\n  content\nEOF\n\n# Alternative version\ncat \u003c\u003c EOF \u003e ./sass/test.scss\nbody {\n  p {\n    \u0026:hover {\n      color: red;\n    }\n  }\n}\nEOF\n","tags":"#bash #heredoc #file"},{"id":"054e34983e8680c506c3","title":"Currying vs Partial Application","content":"When we use Partial Application we always execute our function twice (regardless of the number of arguments). \n\nWhen we use Currying we execute our function once for each argument.\n\n## Examples of Partial Application\n\n```js\n// `partial` is a made up function\nfn  = function (a, b, c) { return a + b + c }\nfoo = partial(fn, 'x', 'y')\nfoo('z') // =\u003e 'xyz'\n```\n\nIn the next example we can see that it's possible to change the arguments we partially apply:\n\n```js\n// `partial` is a made up function\nfn  = function (a, b, c) { return a + b + c }\nfoo = partial(fn, 'x')\nfoo('y', 'z') // =\u003e 'xyz'\n```\n\n\u003e Note how with Partial Application we make a function call twice (once when partially applying the arguments; and again when we fulfil the rest of the arguments). But remember: we can choose how many arguments we partially apply on the first call.\n\n## Examples of Currying\n\n```js\n// `curry` is a made up function\nfn  = function (a, b, c) { return a + b + c }\nfoo = curry(fn)\nfoo('x')('y')('z') // =\u003e 'xyz'\n```\n\n```js\n// `curry` is a made up function\nfn  = function (a, b, c) { return a + b + c }\nfoo = curry(fn)\nbar = foo('x')\nbar('y')('z') // =\u003e 'xyz'\n```\n\n\u003e Note that a function that has been curried wont return the value of the function until each argument has been provided (i.e. satisfied). The arguments are manually partially applied one by one.\n\n## Functional Libraries\n\n- [fn.js](http://eliperelman.com/fn.js/)\n- [functional js](https://github.com/osteele/functional-javascript)\n","tags":""},{"id":"57ebb1ddc040ea813b64","title":"Run Sass within Ruby","content":"require \"sass\"\noptions = {\n  cache: true,\n  syntax: :sass,\n  style: :compressed,\n  filename: original_file_name,\n  ...\n}\nrender = Sass::Engine.new(File.read(original_file_name), options).render\nFile.write(output_file_name, render)\n","tags":""},{"id":"a0faa55488af1b4b358e","title":"Pro Vim `.zshrc` configuration file","content":"# Some of the Zsh awesomeness seen below was originally found here...\n# http://zanshin.net/2013/02/02/zsh-configuration-from-the-ground-up/\n\n# Exports {{{\nexport GITHUB_USER=\"your-username\"\nexport PATH=/usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin # Reorder PATH so local bin is first\nexport GREP_OPTIONS='--color=auto'\nexport GREP_COLOR='1;32'\nexport MANPAGER=\"less -X\" # Don’t clear the screen after quitting a manual page\nexport EDITOR=\"vim\"\nexport TERM=\"screen-256color\"\nexport CLICOLOR=1\nexport LSCOLORS=Gxfxcxdxbxegedabagacad\nexport LS_COLORS=Gxfxcxdxbxegedabagacad\n# }}}\n\n# Tmux {{{\n# Makes creating a new tmux session (with a specific name) easier\nfunction tmuxopen() {\n  tmux attach -t $1\n}\n\n# Makes creating a new tmux session (with a specific name) easier\nfunction tmuxnew() {\n  tmux new -s $1\n}\n\n# Makes deleting a tmux session easier\nfunction tmuxkill() {\n  tmux kill-session -t $1\n}\n# }}}\n\n# Alias' {{{\nalias vi=\"vim\"\nalias r=\"source ~/.zshrc\"\nalias tmuxsrc=\"tmux source-file ~/.tmux.conf\"\nalias tmuxkillall=\"tmux ls | cut -d : -f 1 | xargs -I {} tmux kill-session -t {}\" # tmux kill all sessions\nalias ct=\"ctags -R --exclude=.git --exclude=node_modules\"\nalias dotfiles=\"ls -a | grep '^\\.' | grep --invert-match '\\.DS_Store\\|\\.$'\"\n# }}}\n\n# Auto Completion {{{\nautoload -U compinit \u0026\u0026 compinit\nzmodload -i zsh/complist\n\n# man zshcontrib\nzstyle ':vcs_info:*' actionformats '%F{5}(%f%s%F{5})%F{3}-%F{5}[%F{2}%b%F{3}|%F{1}%a%F{5}]%f '\nzstyle ':vcs_info:*' formats '%F{5}(%f%s%F{5})%F{3}-%F{5}[%F{2}%b%F{5}]%f '\nzstyle ':vcs_info:*' enable git #svn cvs\n\n# Enable completion caching, use rehash to clear\nzstyle ':completion::complete:*' use-cache on\nzstyle ':completion::complete:*' cache-path ~/.zsh/cache/$HOST\n\n# Fallback to built in ls colors\nzstyle ':completion:*' list-colors ''\n\n# Make the list prompt friendly\nzstyle ':completion:*' list-prompt '%SAt %p: Hit TAB for more, or the character to insert%s'\n\n# Make the selection prompt friendly when there are a lot of choices\nzstyle ':completion:*' select-prompt '%SScrolling active: current selection at %p%s'\n\n# Add simple colors to kill\nzstyle ':completion:*:*:kill:*:processes' list-colors '=(#b) #([0-9]#) ([0-9a-z-]#)*=01;34=0=01'\n\n# list of completers to use\nzstyle ':completion:*::::' completer _expand _complete _ignored _approximate\nzstyle ':completion:*' menu select=1 _complete _ignored _approximate\n\n# match uppercase from lowercase\nzstyle ':completion:*' matcher-list 'm:{a-z}={A-Z}'\n\n# offer indexes before parameters in subscripts\nzstyle ':completion:*:*:-subscript-:*' tag-order indexes parameters\n\n# formatting and messages\nzstyle ':completion:*' verbose yes\nzstyle ':completion:*:descriptions' format '%B%d%b'\nzstyle ':completion:*:messages' format '%d'\nzstyle ':completion:*:warnings' format 'No matches for: %d'\nzstyle ':completion:*:corrections' format '%B%d (errors: %e)%b'\nzstyle ':completion:*' group-name ''\n\n# ignore completion functions (until the _ignored completer)\nzstyle ':completion:*:functions' ignored-patterns '_*'\nzstyle ':completion:*:scp:*' tag-order files users 'hosts:-host hosts:-domain:domain hosts:-ipaddr\"IP\\ Address *'\nzstyle ':completion:*:scp:*' group-order files all-files users hosts-domain hosts-host hosts-ipaddr\nzstyle ':completion:*:ssh:*' tag-order users 'hosts:-host hosts:-domain:domain hosts:-ipaddr\"IP\\ Address *'\nzstyle ':completion:*:ssh:*' group-order hosts-domain hosts-host users hosts-ipaddr\nzstyle '*' single-ignored show\n# }}}\n\n# Key Bindings {{{\n# Make the delete key (or Fn + Delete on the Mac) work instead of outputting a ~\nbindkey '^?' backward-delete-char\nbindkey \"^[[3~\" delete-char\nbindkey \"^[3;5~\" delete-char\nbindkey \"\\e[3~\" delete-char\n\n# Make the `beginning/end` of line and `bck-i-search` commands work within tmux\nbindkey '^R' history-incremental-search-backward\nbindkey '^A' beginning-of-line\nbindkey '^E' end-of-line\n# }}}\n\n# Colours {{{\nautoload colors; colors\n\n# The variables are wrapped in \\%\\{\\%\\}. This should be the case for every\n# variable that does not contain space.\nfor COLOR in RED GREEN YELLOW BLUE MAGENTA CYAN BLACK WHITE; do\n  eval PR_$COLOR='%{$fg_no_bold[${(L)COLOR}]%}'\n  eval PR_BOLD_$COLOR='%{$fg_bold[${(L)COLOR}]%}'\ndone\n\neval RESET='$reset_color'\nexport PR_RED PR_GREEN PR_YELLOW PR_BLUE PR_WHITE PR_BLACK\nexport PR_BOLD_RED PR_BOLD_GREEN PR_BOLD_YELLOW PR_BOLD_BLUE\nexport PR_BOLD_WHITE PR_BOLD_BLACK\n\n# Clear LSCOLORS\nunset LSCOLORS\n# }}}\n\n# Set Options {{{\n# ===== Basics\nsetopt no_beep # don't beep on error\nsetopt interactive_comments # Allow comments even in interactive shells (especially for Muness)\n\n# ===== Changing Directories\nsetopt auto_cd # If you type foo, and it isn't a command, and it is a directory in your cdpath, go there\nsetopt cdablevarS # if argument to cd is the name of a parameter whose value is a valid directory, it will become the current directory\nsetopt pushd_ignore_dups # don't push multiple copies of the same directory onto the directory stack\n\n# ===== Expansion and Globbing\nsetopt extended_glob # treat #, ~, and ^ as part of patterns for filename generation\n\n# ===== History\nsetopt append_history # Allow multiple terminal sessions to all append to one zsh command history\nsetopt extended_history # save timestamp of command and duration\nsetopt inc_append_history # Add comamnds as they are typed, don't wait until shell exit\nsetopt hist_expire_dups_first # when trimming history, lose oldest duplicates first\nsetopt hist_ignore_dups # Do not write events to history that are duplicates of previous events\nsetopt hist_ignore_space # remove command line from history list when first character on the line is a space\nsetopt hist_find_no_dups # When searching history don't display results already cycled through twice\nsetopt hist_reduce_blanks # Remove extra blanks from each command line being added to history\nsetopt hist_verify # don't execute, just expand history\nsetopt share_history # imports new commands and appends typed commands to history\n\n# ===== Completion\nsetopt always_to_end # When completing from the middle of a word, move the cursor to the end of the word\nsetopt auto_menu # show completion menu on successive tab press. needs unsetop menu_complete to work\nsetopt auto_name_dirs # any parameter that is set to the absolute name of a directory immediately becomes a name for that directory\nsetopt complete_in_word # Allow completion from within a word/phrase\n\nunsetopt menu_complete # do not autoselect the first completion entry\n\n# ===== Correction\nsetopt correct # spelling correction for commands\nsetopt correctall # spelling correction for arguments\n\n# ===== Prompt\nsetopt prompt_subst # Enable parameter expansion, command substitution, and arithmetic expansion in the prompt\nsetopt transient_rprompt # only show the rprompt on the current prompt\n\n# ===== Scripts and Functions\nsetopt multios # perform implicit tees or cats when multiple redirections are attempted\n# }}}\n\n# Prompt {{{\nfunction virtualenv_info {\n  [ $VIRTUAL_ENV ] \u0026\u0026 echo '('`basename $VIRTUAL_ENV`') '\n}\n\nfunction prompt_char {\n  git branch \u003e/dev/null 2\u003e/dev/null \u0026\u0026 echo '±' \u0026\u0026 return\n  hg root \u003e/dev/null 2\u003e/dev/null \u0026\u0026 echo '☿' \u0026\u0026 return\n  echo '○'\n}\n\nfunction box_name {\n  [ -f ~/.box-name ] \u0026\u0026 cat ~/.box-name || hostname -s\n}\n\n# http://blog.joshdick.net/2012/12/30/my_git_prompt_for_zsh.html\n# copied from https://gist.github.com/4415470\n# Adapted from code found at \u003chttps://gist.github.com/1712320\u003e.\n\n#setopt promptsubst\nautoload -U colors \u0026\u0026 colors # Enable colors in prompt\n\n# Modify the colors and symbols in these variables as desired.\nGIT_PROMPT_SYMBOL=\"%{$fg[blue]%}±\"\nGIT_PROMPT_PREFIX=\"%{$fg[green]%} [%{$reset_color%}\"\nGIT_PROMPT_SUFFIX=\"%{$fg[green]%}]%{$reset_color%}\"\nGIT_PROMPT_AHEAD=\"%{$fg[red]%}ANUM%{$reset_color%}\"\nGIT_PROMPT_BEHIND=\"%{$fg[cyan]%}BNUM%{$reset_color%}\"\nGIT_PROMPT_MERGING=\"%{$fg_bold[magenta]%}⚡︎%{$reset_color%}\"\nGIT_PROMPT_UNTRACKED=\"%{$fg_bold[red]%}u%{$reset_color%}\"\nGIT_PROMPT_MODIFIED=\"%{$fg_bold[yellow]%}m%{$reset_color%}\"\nGIT_PROMPT_STAGED=\"%{$fg_bold[green]%}s%{$reset_color%}\"\n\n# Show Git branch/tag, or name-rev if on detached head\nfunction parse_git_branch() {\n  (git symbolic-ref -q HEAD || git name-rev --name-only --no-undefined --always HEAD) 2\u003e /dev/null\n}\n\n# Show different symbols as appropriate for various Git repository states\nfunction parse_git_state() {\n  # Compose this value via multiple conditional appends.\n  local GIT_STATE=\"\"\n\n  local NUM_AHEAD=\"$(git log --oneline @{u}.. 2\u003e /dev/null | wc -l | tr -d ' ')\"\n  if [ \"$NUM_AHEAD\" -gt 0 ]; then\n    GIT_STATE=$GIT_STATE${GIT_PROMPT_AHEAD//NUM/$NUM_AHEAD}\n  fi\n\n  local NUM_BEHIND=\"$(git log --oneline ..@{u} 2\u003e /dev/null | wc -l | tr -d ' ')\"\n  if [ \"$NUM_BEHIND\" -gt 0 ]; then\n    GIT_STATE=$GIT_STATE${GIT_PROMPT_BEHIND//NUM/$NUM_BEHIND}\n  fi\n\n  local GIT_DIR=\"$(git rev-parse --git-dir 2\u003e /dev/null)\"\n  if [ -n $GIT_DIR ] \u0026\u0026 test -r $GIT_DIR/MERGE_HEAD; then\n    GIT_STATE=$GIT_STATE$GIT_PROMPT_MERGING\n  fi\n\n  if [[ -n $(git ls-files --other --exclude-standard 2\u003e /dev/null) ]]; then\n    GIT_STATE=$GIT_STATE$GIT_PROMPT_UNTRACKED\n  fi\n\n  if ! git diff --quiet 2\u003e /dev/null; then\n    GIT_STATE=$GIT_STATE$GIT_PROMPT_MODIFIED\n  fi\n\n  if ! git diff --cached --quiet 2\u003e /dev/null; then\n    GIT_STATE=$GIT_STATE$GIT_PROMPT_STAGED\n  fi\n\n  if [[ -n $GIT_STATE ]]; then\n    echo \"$GIT_PROMPT_PREFIX$GIT_STATE$GIT_PROMPT_SUFFIX\"\n  fi\n}\n\n# If inside a Git repository, print its branch and state\nfunction git_prompt_string() {\n  local git_where=\"$(parse_git_branch)\"\n  [ -n \"$git_where\" ] \u0026\u0026 echo \"on %{$fg[blue]%}${git_where#(refs/heads/|tags/)}$(parse_git_state)\"\n}\n\nfunction current_pwd {\n  echo $(pwd | sed -e \"s,^$HOME,~,\")\n}\n\n# Original prompt with User name and Computer name included...\n# PROMPT='\n# ${PR_GREEN}%n%{$reset_color%} %{$FG[239]%}at%{$reset_color%} ${PR_BOLD_BLUE}$(box_name)%{$reset_color%} %{$FG[239]%}in%{$reset_color%} ${PR_BOLD_YELLOW}$(current_pwd)%{$reset_color%} $(git_prompt_string)\n# $(prompt_char) '\n\nPROMPT='\n${PR_GREEN}M.%{$reset_color%} ${PR_BOLD_YELLOW}$(current_pwd)%{$reset_color%} $(git_prompt_string)\n$(prompt_char) '\n\nexport SPROMPT=\"Correct $fg[red]%R$reset_color to $fg[green]%r$reset_color [(y)es (n)o (a)bort (e)dit]? \"\n\nRPROMPT='${PR_GREEN}$(virtualenv_info)%{$reset_color%} ${PR_RED}$(get_ruby_version)%{$reset_color%}'\n# }}}\n\n# History {{{\nHISTSIZE=10000\nSAVEHIST=9000\nHISTFILE=~/.zsh_history\n# }}}\n\n# Zsh Hooks {{{\nfunction precmd {\n  # vcs_info\n  # Put the string \"hostname::/full/directory/path\" in the title bar:\n  echo -ne \"\\e]2;$PWD\\a\"\n\n  # Put the parentdir/currentdir in the tab\n  echo -ne \"\\e]1;$PWD:h:t/$PWD:t\\a\"\n}\n\nfunction set_running_app {\n  printf \"\\e]1; $PWD:t:$(history $HISTCMD | cut -b7- ) \\a\"\n}\n\nfunction preexec {\n  set_running_app\n}\n\nfunction postexec {\n  set_running_app\n}\n# }}}\n","tags":""},{"id":"67360cd42b64329e7448","title":"Ruby's \"Around Alias\" pattern","content":"class String\n  alias :orig_length :length\n\n  def length\n    \"Length of string '#{self}' is: #{orig_length}\"\n  end  \nend\n\n\"abc\".length\n#=\u003e \"Length of string 'abc' is: 3\"\n","tags":""},{"id":"2cf1079f564a430d1313","title":"Best way to modular Grunt tasks","content":"module.exports = function(grunt) {\n    grunt.config('requirejs', {\n        compile: {\n            options: {\n                baseUrl: './app',\n                name: 'main',\n                out: './app/release/main.js'\n            }\n        }\n    });\n\n    grunt.loadNpmTasks('grunt-contrib-requirejs');\n};\nmodule.exports = function (grunt) {\n    grunt.registerTask('images', [], function() {\n        grunt.config('responsive_images', {\n            main: { ... }\n        });\n\n        grunt.loadNpmTasks('grunt-responsive-images');\n        grunt.task.run('responsive_images');\n    });\n};\n|— Gruntfile\n|— package.json\n|— grunt\n| – contrib-requirejs.js\nmodule.exports = function(grunt) {\n    grunt.loadTasks('grunt');\n};\n","tags":""},{"id":"9bdbb99b83bd1613f062","title":"Why does this fail in MRI 2.0 but pass in JRuby (which is API compat with MRI 1.9.3)?","content":"my_proc = proc { |x, y, z| x + y + z }\nadd_to_the_value_three = my_proc.curry(2)[1][2]\nputs add_to_the_value_three[6] # =\u003e 9\n\n=begin\ntest.rb:1:in `+': nil can't be coerced into Fixnum (TypeError)\n\tfrom test.rb:1:in `block in \u003cmain\u003e'\n\tfrom test.rb:2:in `[]'\n\tfrom test.rb:2:in `\u003cmain\u003e'\n=end\n","tags":""},{"id":"b7ed2e337a0b5cbbecce","title":"JavaScript Function Programming (scratch pad) -\u003e Most of the code here is modified from the excellent O'Reilly book \"Functional JavaScript\".","content":"var csv = 'name,age,hair\\nmark,32,brown\\ncat,27,red';\n\nfunction parseCSV(csv) {\n    var data = csv.split('\\n');\n        data.unshift([]); // accumulator\n\n    // ES5's `reduce` method isn't as nice to use as found in Underscore/Lo-Dash\n    // This is because it uses the first item in the collection as the accumulator \n    // So really the `current` argument starts at index 1 and `previous` is index 0\n    // Underscore/Lo-Dash works the same but also allows you to pass in an accumulator\n    // So to make things easier/clearer I decided to inject my own accumulator into the collection\n    return data.reduce(\n        function(previous, current, index, collection) {\n            previous.push(current.split(',').map(function(item) {\n                return item.trim();\n            })); // `push` returns the new length of the array rather than the array itself...\n\n            return previous; // ...hence we need to explicitly return the array\n        }\n    );\n}\n\nparseCSV(csv) // =\u003e [ [ 'name', 'age', 'hair' ],\n              //    [ 'mark', '32', 'brown' ],\n              //    [ 'cat', '27', 'red' ] ]\n// Code copied from http://eliperelman.com/fn.js/\n\nvar fn = {};\n\nfn.toArray = function (collection) {\n\treturn [].slice.call(collection);\n};\n\nfn.cloneArray = fn.toArray;\n\nfn.apply = function (handler, args) {\n\treturn handler.apply(null, args);\n};\n\nfn.concat = function () {\n\tvar args = fn.toArray(arguments);\n\tvar first = args[ 0 ];\n\n\tif (!fn.is('array', first) \u0026\u0026 !fn.is('string', first)) {\n\t\tfirst = args.length ? [ first ] : [ ];\n\t}\n\n\treturn first.concat.apply(first, args.slice(1));\n};\n\nfn.type = function (value) {\n\t// If the value is null or undefined, return the stringified name,\n\t// otherwise get the [[Class]] and compare to the relevant part of the value\n\treturn value == null ?\n\t\t'' + value :\n\t\t{ }.toString.call(value).slice(8, -1).toLowerCase();\n};\n\nfn.is = function (type, value) {\n\treturn type === fn.type(value);\n};\n\nfn.partial = function () {\n\tvar args = fn.toArray(arguments);\n\tvar handler = args[0];\n\tvar partialArgs = args.slice(1);\n\n\treturn function () {\n\t\treturn fn.apply(handler, fn.concat(partialArgs, fn.toArray(arguments)) );\n\t};\n};\n\nfn.identity = function (arg) {\n\treturn arg;\n};\n\nfn.reverse = function (collection) {\n\treturn fn.cloneArray(collection).reverse();\n};\n\nvar currier = function makeCurry(rightward) {\n\treturn function (handler, arity) {\n\t\tif (handler.curried) {\n\t\t\treturn handler;\n\t\t}\n\n\t\tarity = arity || handler.length;\n\n\t\tvar curry = function curry() {\n\t\t\tvar args = fn.toArray(arguments);\n\n\t\t\tif (args.length \u003e= arity) {\n\t\t\t\tvar transform = rightward ? 'reverse' : 'identity';\n\t\t\t\treturn fn.apply(handler, fn[ transform ](args));\n\t\t\t}\n\n\t\t\tvar inner = function () {\n\t\t\t\treturn fn.apply(curry, args.concat(fn.toArray(arguments)));\n\t\t\t};\n\n\t\t\tinner.curried = true;\n\n\t\t\treturn inner;\n\t\t};\n\n\t\tcurry.curried = true;\n\n\t\treturn curry;\n\t};\n};\n\nfn.curry = currier(false);\n\nfn.curryRight = currier(true);\n\n// Partial Application\n\nvar fullName = function (firstName, lastName) {\n\treturn firstName + ' ' + lastName;\n};\n\nvar billName = fn.partial(fullName, 'Bill');\n\nbillName('Smith'); // \"Bill Smith\"\nbillName('Clinton'); // \"Bill Clinton\"\n\n// Curry\n\nvar fullName2 = fn.curry(function (firstName, middleName, lastName) {\n\treturn firstName + ' ' + middleName + ' ' + lastName;\n});\n\nvar billName2 = fullName2('Bill');\n\nbillName2('Damon')('Smith'); // \"Bill Damon Smith\"\nbillName2('Jefferson', 'Clinton'); // \"Bill Jefferson Clinton\"\nfullName2('Jenn', 'Anne', 'Cochran'); // \"Jenn Anne Cochran\"\nfullName2('Jenn', 'Anne')('Cochran'); // \"Jenn Anne Cochran\"\n\n// Curry right\n\nvar fullName3 = fn.curryRight(function (firstName, middleName, lastName) {\n\treturn firstName + ' ' + middleName + ' ' + lastName;\n});\n\nvar smithName = fullName3('Smith');\n\nsmithName('Damon')('Bill'); // \"Bill Damon Smith\"\nsmithName('Jefferson', 'Bill'); // \"Bill Jefferson Clinton\"\nfullName3('Cochran', 'Anne', 'Jenn'); // \"Jenn Anne Cochran\"\nfullName3('Cochran', 'Anne')('Jenn'); // \"Jenn Anne Cochran\"\nvar _ = require('lodash');\n\nfunction rev(arr) {\n    return _.chain(arr)\n            .reverse()\n            .value();\n}\n\nfunction pipeline(seed) {\n    return _.reduce(_.rest(arguments), function(l, r) {\n        return r(l);\n    }, seed);\n}\n\nvar data = [2, 3, null, 1, 42, false];\n\nconsole.log(\n    pipeline(data,\n            _.compact,\n            _.initial,\n            _.rest,\n            rev)\n); // =\u003e [1, 3]\n\n// Evaluates to...\n\n/*\nrev(\n    _.rest(\n        _.initial(\n            _.compact(data))))\n*/\n// Note: using Lo-Dash/Underscore's `_.reduce` is a lot cleaner and easier code to use\n// By that I mean we don't need to manipulate our data structure to allow for an accumulator to be injected\n\nvar _ = {\n    reduce: require('lodash.reduce'), // npm install lodash.reduce\n    map:    require('lodash.map')     // npm install lodash.map\n};\n\nfunction _parseCSV(csv) {\n    return _.reduce(csv.split('\\n'), function(accumulator, item) {\n            accumulator.push(_.map(item.split(','), function(item) {\n                return item.trim();\n            }));\n\n            return accumulator;\n        }, []);\n}\n\n_parseCSV(csv) // =\u003e [ [ 'name', 'age', 'hair' ],\n               //    [ 'mark', '32', 'brown' ],\n               //    [ 'cat', '27', 'red' ] ]\n\nvar _ = require('lodash'); // lodash.tap wasn't available on npm as separate modules (update: there is a Lo-Dash npm module that allows for pulling in specific functions)\n\nfunction exists(value) {\n    return value !== undefined \u0026\u0026 value !== null\n}\n\nfunction truthy(value) {\n    return value !== false \u0026\u0026 exists(value)\n}\n\n// The following code abstracts away the ugliness of using conditionals to say:\n// \"do this thing, only if this other thing exists\"\n// The use of `if (!!condition)` would be more concise than having two separate functions\n// like we use above (`exists` and `truthy`) but we're abiding by FP principle of:\n// \"replace values with functions\"\n\nfunction doWhen(condition, action) {\n    if (truthy(condition))\n        return action()\n    else\n        return\n}\n\nfunction executeIfFieldExists(target, field) {\n    return doWhen(target[field], function() {\n        return _(target).tap(function(target) {\n            console.log('The result is', _.result(target, field))\n        })\n    })\n}\n\nexecuteIfFieldExists({ foo: 'bar' }, 'foo');   // =\u003e 'bar'\nexecuteIfFieldExists([1, 2, 3, 4], 'reverse'); // =\u003e [4, 3, 2, 1]\nvar _ = require('lodash');\n\nfunction exists(value) {\n    return value !== undefined \u0026\u0026 value !== null;\n}\n\nfunction dispatch() {\n    var fns  = _.toArray(arguments);\n    var size = fns.length;\n\n    return function(target) {\n        var ret;\n\n        for (var i = 0; i \u003c size; i++) {\n            var fn = fns[i];\n\n            ret = fn.call(fn, target);\n\n            if (exists(ret)) return ret;\n        }\n\n        return ret;\n    };\n}\n\n// The `dispatch` function executes each provided function\n// until a non-undefined value is returned.\n// Effectively action like a batch of if statements\nvar convertToString = dispatch(\n    function(s) { return _.isString(s) ? s : undefined; },\n    function(s) { return _.isObject(s) ? JSON.stringify(s) : undefined; },\n    function(s) { return s.toString(); }\n);\n\nconsole.log(\n    convertToString({ foo: 'bar' })\n);\n\nconsole.log(\n    convertToString(123)\n);\n\nconsole.log(\n    convertToString('abc')\n);\nA pure function adheres to the following properties:\n\n- Its result is calculated only from the values of its arguments\n- It cannot rely on data that changes external to its control\n- It cannot change the state of something external to its body\nThis code is modified from the excellent O'Reilly book \"Functional JavaScript\". You should buy it, I highly recommend it! Don't kid yourself into thinking this gist even remotely covers the great content from a 200+ page technical book on the subject; it doesn't. Buy the book and get the in-depth knowledge for yourself. It's worth it.\n\n- [Composability through higher order functions](https://gist.github.com/Integralist/b7ed2e337a0b5cbbecce#file-01-composability-js)\n- [Parsing CSV (ES5 version)](https://gist.github.com/Integralist/b7ed2e337a0b5cbbecce/#file-02-es5-js)\n- [Parsing CSV (LoDash version)](https://gist.github.com/Integralist/b7ed2e337a0b5cbbecce/#file-03-lodash-js)\n- [Abstract away conditionals](https://gist.github.com/Integralist/b7ed2e337a0b5cbbecce/#file-04-conditionals-js)\n- [Data construction](https://gist.github.com/Integralist/b7ed2e337a0b5cbbecce/#file-05-construction-js)\n- [Currying and Partial Application](https://gist.github.com/Integralist/b7ed2e337a0b5cbbecce/#file-06-currying-and-partial-application-js)\n- [Null Object pattern](https://gist.github.com/Integralist/b7ed2e337a0b5cbbecce/#file-07-null-object-pattern-js)\n- [Checking and Validating data](https://gist.github.com/Integralist/b7ed2e337a0b5cbbecce#file-08-checking-and-validating-data-js)\n- [Rules of Recursion](https://gist.github.com/Integralist/b7ed2e337a0b5cbbecce#file-09-rules-of-recursion-md)\n- [Recursive Checking and Validating](https://gist.github.com/Integralist/b7ed2e337a0b5cbbecce#file-10-recursive-checking-and-validating-js)\n- [Definition of Purity](https://gist.github.com/Integralist/b7ed2e337a0b5cbbecce#file-11-definition-of-purity-md)\n- [Composition can help avoid mutation](https://gist.github.com/Integralist/b7ed2e337a0b5cbbecce#file-12-composition-can-help-avoid-mutation-js)\n- [If statements in Functional form](https://gist.github.com/Integralist/b7ed2e337a0b5cbbecce#file-13-if-statements-in-functional-form-js)\n- [Pipeline](https://gist.github.com/Integralist/b7ed2e337a0b5cbbecce#file-14-pipeline-js)\n// Higher order function (takes in a function and returns a function)\nfunction comparator(predicate) {\n    return function(x, y) {\n        if (predicate(x, y)) {\n            return -1;\n        } else if (predicate(y, x)) {\n            return 1;\n        } else {\n            return 0;\n        }\n    };\n}\n\nfunction lessOrEqual(x, y) {\n    return x \u003c= y;\n}\n\n// Composability\n[2, 3, -1, -6, 0, -108, 42, 10].sort(comparator(lessOrEqual)) // =\u003e [-108, -6, -1, 0, 2, 3, 10, 42]\nvar _ = require('lodash'); // lodash.tap and lodash.chain weren't available on npm as separate modules (update: there is a Lo-Dash npm module that allows for pulling in specific functions)\n\nfunction lyricSegment(number) {\n    return _.chain([])\n            .push(number + ' bottles of beer on the wall')\n            .push(number + ' bottles of beer')\n            .push('Take one down, pass it around')\n            .tap(function(lyrics) {\n                if (number \u003e 1)\n                    lyrics.push((number - 1) + ' bottles of beer on the wall.')\n                else\n                    lyrics.push('No more bottles of beer on the wall!')\n            })\n            .value()\n}\n\nfunction song(start, end, generator) {\n    return _.reduce(_.range(start, end, -1), function(accumulator, number) {\n        return accumulator.concat(generator(number))\n    }, [])\n}\n\nsong(99, 0, lyricSegment)\nvar _ = require('lodash'); // lodash.tap and lodash.chain weren't available on npm as separate modules (update: there is a Lo-Dash npm module that allows for pulling in specific functions)\n\n// Variation of a no-op that\n// always returns the value specified\nfunction always(value) {\n    return function() {\n        return value;\n    };\n}\n\n// This function requires that all provided \"validators\"\n// return an object that has a \"message\" property.\n// This is so the \"errs\" accumulator Array will hold relevant error messages\nfunction checker() {\n    var validators = _.toArray(arguments);\n\n    return function(obj) {\n        return _.reduce(validators, function(errs, check) {\n            if (check(obj)) {\n                return errs;\n            } else {\n                // We use the \"chain\" method much like \"tap\" in Ruby.\n                // The \"chain\" method needs \"value\" to be called\n                // otherwise it'll always return a chain obj until\n                // the final value is requested\n                return _.chain(errs).push(check.message).value();\n            }\n        }, []);\n    };\n}\n\nvar alwaysPasses = checker(always(true), always(true)); // we can have as many \"validators\" as we want\n\nconsole.log(\n    alwaysPasses({})\n); // =\u003e [] no errors\n\n// We'll make sure our next example fails,\n// so we need a \"message\" property on the \"validator\" we provide\nvar fails = always(false);\n    fails.message = \"This thing failed\";\n\nvar alwaysFails = checker(fails);\n\nconsole.log(\n    alwaysFails({})\n); // =\u003e [\"This thing failed\"]\n\n// We want to be careful adding a \"message\" property to objects we don't own\n// The following function automates this for us\nfunction validator(message, fn) {\n    var f = function() {\n        // Call the original function\n        // such as _.isObject and pass itself as the \"this\" value\n        // and pass through the original argument(s) to that function\n        // e.g. var test = validator(\"Error!\", _.isObject) will mean when we call\n        // test([]) then test.message == \"Error!\"\n        return fn.apply(fn, arguments);\n    };\n\n    f.message = message;\n\n    return f;\n}\n\nvar objectCheck = checker(validator(\"object validation fail\", _.isObject));\nvar arrayCheck = checker(validator(\"array validation fail\", _.isArray));\n\nconsole.log(\n    objectCheck(123)\n); // =\u003e [\"object validation fail\"]\n\nconsole.log(\n    arrayCheck(123)\n); // =\u003e [\"array validation fail\"]\n\nconsole.log(\n    arrayCheck([])\n); // =\u003e []\n- Know when to stop\n- Decide how to take one step\n- Break the problem down into a smaller problem\n\n```js\nfunction myLength(arr) {\n    if (_.isEmpty(arr)) {\n        return 0;\n    } else {\n        return 1 + myLength(_.rest(arr));\n    }\n}\n\nmyLength(_.range(10));     // 10\nmyLength(_.range(1000));   // 1000\nmyLength(_.range(10000));  // 10000\nmyLength(_.range(100000)); // FATAL ERROR: JS Allocation failed - process out of memory\n\n// See http://www.integralist.co.uk/posts/understanding-recursion-in-functional-javascript-programming/\n// to understand tail-call optimisation\n```\n\n- Know when to stop (`if (_.isEmpty(arr)) {`)\n- Decide how to take one step (`1 + myLength(...)`)\n- Break the problem down into a smaller problem (`myLength(_.rest(arr)`)\nvar _ = require('lodash'); // lodash.toArray and lodash.isEmpty weren't available on npm as separate modules (update: there is a Lo-Dash npm module that allows for pulling in specific functions)\n\nfunction isEven(item) {\n    return item % 2 === 0 ? true : false;\n}\n\nfunction isOdd(item) {\n    return item % 2 === 1 ? true : false;\n}\n\nfunction isZero(item) {\n    return item === 0 ? true : false;\n}\n\nfunction valid() {\n    var predicates = _.toArray(arguments);\n\n    return function() {\n        var args = _.toArray(arguments);\n\n        // \"truth\" is whatever we want to return,\n        // if all the arguments provided to the above return function\n        // pass each predicate's requirements\n        var everything = function(preds, truth) {\n            // If there are no preds\n            // (or no more since the recursive calls to this function)\n            // then we've safely validated our \"args\" so we can return our \"truth\"\n            if (_.isEmpty(preds)) {\n                return truth;\n            } else {\n                // recursiveness happens here...\n                // if all the args pass the first pred's requirements\n                // then call \"everything\" again, but now reduce the problem\n                // down to the remaining preds the args have yet to be tested against.\n                return _.every(args, _.first(preds)) \u0026\u0026 everything(_.rest(preds), truth);\n\n                // Note: we have short-circuited the recursiveness\n                // by first making sure the arguments pass the first set of requirements\n                // e.g. whatever the first predicate function that was provided\n            }\n        };\n\n        return everything(predicates, true);\n    };\n}\n\nvar evenNumbers = valid(_.isNumber, isEven);\n\nconsole.log(\n    evenNumbers(1, 2)\n); // =\u003e false\n\nconsole.log(\n    evenNumbers(2, 4, 6)\n); // =\u003e true\n\n// We can change the functionality to allow some items to pass by\n// setting our truth to be \"false\" while using _.some instead of _.every\n// and also chaning our condition from \u0026\u0026 to ||\n// See below example...\n\nfunction possiblyValid() {\n    var predicates = _.toArray(arguments);\n\n    return function() {\n        var args = _.toArray(arguments);\n\n        var something = function(preds, truth) {\n            if (_.isEmpty(preds)) {\n                return truth;\n            } else {\n                return _.some(args, _.first(preds)) || something(_.rest(preds), truth);\n            }\n        };\n\n        return something(predicates, false);\n    };\n}\n\nvar zeroOrOdd = possiblyValid(isOdd, isZero);\n\nconsole.log(\n    zeroOrOdd()\n); // =\u003e false\n\nconsole.log(\n    zeroOrOdd(0, 2, 4, 6)\n); // =\u003e true\n\nconsole.log(\n    zeroOrOdd(2, 4, 6)\n); // =\u003e false\n\nconsole.log(\n    zeroOrOdd(2, 4, 6, 7)\n); // =\u003e true\nvar _ = {\n    reduce: require('lodash.reduce'), // npm install lodash.reduce\n    rest:   require('lodash.rest'),   // npm install lodash.rest\n    map:    require('lodash.map')     // npm install lodash.map\n};\n\nfunction exists(value) {\n    return value !== undefined \u0026\u0026 value !== null\n}\n\nfunction fnull(fn) {\n    var defaults = _.rest(arguments); // default values to use in case a null value is passed in\n\n    return function() {\n        /*\n            Modify arguments so null values are replaced with default values\n            e.g. args passed in our example below:\n                 1, 2 (1 * 2 == 2)\n                 2, 3 (2 * 3 == 6)\n                 6, null (null replaced with 1 and so this becomes 6 * 1 == 6)\n                 6, 5 (6 * 5 == 30)\n        */\n        var args = _.map(arguments, function(item, index) {\n            return exists(item) ? item : defaults[index];\n        });\n\n        return fn.apply(null, args);\n    };\n}\n\nvar data = [1, 2, 3, null, 5];\nvar multiplier   = function(total, n) { return total * n }; \nvar safeMultiply = fnull(multiplier, 1, 1);\n\n_.reduce(data, multiplier);   // =\u003e 0\n_.reduce(data, safeMultiply); // =\u003e 30\nvar _ = require('lodash');\n\n// Make an Array out of the provided arguments\nfunction construct() {\n    return _.reduce(_.toArray(arguments), function(accumulator, value) {\n        return _.chain(accumulator)\n                .push(value)\n                .value();\n    }, []);\n}\n\nfunction merge() {\n    return _.extend.apply(null,\n                          construct.apply(\n                              construct, _.flatten([{}, arguments])\n                          )\n                         );\n}\n\nvar person = { name: \"Mark\" };\n\n// We return an object that is a combination of the provided objects\nconsole.log(\n    merge(person, { age: 32 }, { location: \"London\" })\n); // =\u003e { name: \"Mark\", age: 32, location: \"London\" }\n\n// But we don't mutate the original object\nconsole.log(\n    person\n); // =\u003e { name: \"Mark\" }\n","tags":""},{"id":"11471364","title":"Expanding scratch pad of Clojure code","content":"; reduce two vectors into a single map\n; =\u003e {:c 3, :b 2, :a 1}\n(reduce\n  (fn\n    [m [k v]]\n    (assoc m k v))\n  {}\n  (map vector [:a :b :c] [1 2 3]))\n\n; break down the above reduce...\n\n; `vector` constructs a new vector containing each argument\n; =\u003e [[:a :b :c] [1 2 3]]\n(vector [:a :b :c] [1 2 3])\n\n; `map` executes the `vector` fn each loop iteration\n; each loop iteration gains the first item from each vector (passed in as arguments)\n; and ultimately returns a sequence constructed of vectors\n; =\u003e ([:a 1] [:b 2] [:c 3])\n(map vector [:a :b :c] [1 2 3])\n\n; the result of a sequence ([:a 1] [:b 2] [:c 3]) needs to be passed without being evaluated\n; so we quote the sequence (otherwise we'd need to change the sequence into an explicit vector)\n; that is then passed (along with {} which acts as an accumulator)\n; to an anonymous function which `reduce` then calls recursively\n; {:c 3, :b 2, :a 1}\n(reduce\n  (fn\n    [m [k v]]\n    (assoc m k v))\n  {}\n  '([:a 1] [:b 2] [:c 3]))\n\n; prints x and y so you can see how map passes in the first item from each vector\n; note that the function doesn't return anything and so we see `nil` appear as well\n; (:a 1:b 2nil :c 3nil nil)\n(map (fn [x y] (pr x y)) [:a :b :c] [1 2 3])\n; the `delay` function returns an object that works much like\n; an anonymous function in that the inner expression isn't evaluated until called\n; the body of the `delay` object will only yield when forced using `force` or `defer/@`\n(def later (fn [] (prn \"a\") (+ 1 1)))\n(later) ; =\u003e \"a\" and 2 (always! it never caches the evaluation)\n(def later (delay (prn \"a\") (+ 1 1)))\n(deref later) ; =\u003e \"a\" and 2 on the first evaluation, but 2 for all calls after that\n@later ; =\u003e interpreted as `(deref later)` also known as a 'wormhole' operator\n\n; a `future` is a `delay` that evaluates its body in parallel\n; this will evaluate all but the last expression `(+ 1 2)` in parallel\n; so when testing from the REPL you'll see `#'user/x` returned as expected and\n; \"hi\", \"!\", 2 will be displayed somewhere around `#'user/x` \n; (either before or after as the evaluation is happening concurrently)\n(def x (future (prn \"hi\") (prn \"!\") (prn (+ 1 1)) (+ 1 2)))\n@x ; =\u003e 3 (this is the last expression that was lazily evaluated and is now always returned)\n\n; futures can cause odd side effects because of their concurrent nature\n; for example if you run the following code:\n(dotimes [i 5] (prn i)) ; =\u003e 0 1 2 3 4 nil (each on a separate line)\n; but if you use a future then because the code executes in parallel you could see something like:\n; nil02\n; 4\n; 1\n; \n; \n; 3\n(dotimes [i 5] (future (prn i)))\n\n; notice how the return value of `nil` and the numbers `0` and `2` all executed at once\n; and the line breaks were triggered in odd places.\n; `agents` and `locks` apparently resolve these side effects\n\n; delays defer evaluation, and futures parallelize them\n; promises let us defer something that might not even exist yet\n; we can set-up a promise and then assign something to it using `deliver`\n; if we try to `deref` a promise that doesn't have any content yet then we'll wait around indefinitely!\n; so make sure to `deliver` your promise before trying to deref it.\n; promises also can't be changed once they've been delivered\n(def box (promise))\nbox ; =\u003e #\u003ccore$promise$reify__6310@746f6266: :pending\u003e\n(deliver box :live-scorpions!) ; =\u003e #\u003ccore$promise$reify__6310@746f6266: :live-scorpions!\u003e\n@box ; =\u003e :live-scorpions!\n(deliver box :puppy) ; =\u003e nil\n@box ; =\u003e :live-scorpions!\n; define our multimethod `greeting` \n; and specify that :language will be the variant\n(defmulti greeting :language)\n\n; create some methods that are built from the multimethod\n; the underscore in the argument list is a convention that indicates we do nothing with the argument\n(defmethod greeting \"English\" [_] \"Hi\")\n(defmethod greeting \"French\" [_] \"Salut\")\n\n; test it\n(greeting {:language \"English\"}) ; =\u003e \"Hi\"\n(greeting {:language \"French\"}) ; =\u003e \"Salut\"\nLists: `(1 2 3)` are implemented as a Linked List and so they are more efficient for walking/iterating a long collection and adding/removing items from the beginning of the list.\n\nVectors: `[1 2 3]` have index access and are a more performant sequence collection for adding/removing items from the end of the collection. It's best to use `(peek [1 2 3])` to find the last item of the collection than `(last [1 2 3])` as `peek` determines the best algorithm for the data structure where as `last` walks the collection looking for the last item.\n; vectors are added to the rear\n; lists are added to the front\n\n; vector example:\n; [1 2 3 99 :bottles]\n(into [1 2 3] [99 :bottles])\n\n; list example:\n; [:bottles 99 1 2 3]\n; you should notice the arguments (`99` and `:bottles`) are reversed.\n; this is because `99` is added to the front and then \n; `:bottles` is added to the front (pushing `99` out of first position)\n(into '(1 2 3) [99 :bottles])\n; example of closure via an anonymous function `fn [] ()`\n; and use `str` for concatenation\n(defn greeting\n  [x]\n  (fn [y] (str x y)))\n\n(def exclaim (greeting \"hello\"))\n(exclaim \"!\") ; =\u003e \"hello!\"\n; lein new async-test\n; inside our project.clj\n(defproject async-test \"0.1.0-SNAPSHOT\"\n  :description \"FIXME: write description\"\n  :url \"http://example.com/FIXME\"\n  :license {:name \"Eclipse Public License\"\n            :url \"http://www.eclipse.org/legal/epl-v10.html\"}\n  :dependencies [\n                 [org.clojure/clojure \"1.5.1\"]\n                 [org.clojure/core.async \"0.1.303.0-886421-alpha\"]])\n\n\n(ns async.example\n  (:require [clojure.core.async :as async :refer :all]))\n\n; or (require '[clojure.core.async :as async :refer :all])\n\n(def hand-off (chan)) ; create a symbol whose value is a new Channel\n\n; (\u003e! channel value) == put\n; (\u003c! channel) == take\n\n(go\n  (dotimes [x 10]\n    (Thread/sleep 1000)\n    (\u003e! hand-off x)))\n\n(go\n  (while true\n    (println (\u003c! hand-off))))\n(defn foo [x, y, z] (prn x y z))\n(foo \"a\" \"b\" \"c\") ; \"a\" \"b\" \"c\"\n\n(def foo-a (partial foo \"a\"))\n(foo-a \"b\" \"c\") ; \"a\" \"b\" \"c\"\nWhat we cover:\n\n- defining functions\n- anonymous functions\n- short hand anonymous functions\n- complex reducing\n- alternatives to the reduce example\n- demonstrate how vectors and lists are different\n- custom method that separates the specified predicate from a sequence\n- destructuring with let bindings\n- utilising `do` to create side effects\n- closures\n- delays, futures, promises\n- atoms for thread safety\n- macros\n- macro syntax quote\n- refactoring (and unquote slicing)\n- multimethods\n- lazy evaluation\n- data structures\n- channels\n- refs\n- composition\n- partial application\n; an alternative (expanded for easier reading) version\n; where we use `do` to execute side effects\n; and the function acts like it should by returning a value\n; (a redundant value, but a value nonetheless)\n; (:a 1:b 2\"foo\" :c 3\"foo\" \"foo\")\n(map \n  (fn [x y] \n    (do (pr x y)) \n    \"foo\") \n  [:a :b :c] \n  [1 2 3])\n\n; here is the original reduce code we had:\n; (reduce (fn [m [k v]] (assoc m k v)) {} (map vector [:a :b :c] [1 2 3]))\n; there are alternatives, each one becoming more focused than the other\n; until we realise that Clojure has provided a function that handles exactly our use case\n(apply hash-map (interleave [:a :b :c] [1 2 3]))\n(into {} (map vector [:a :b :c] [1 2 3]))\n(zipmap [:a :b :c] [1 2 3])\n\n; Increment values of a map (remember we don't mutate the original data)\n; {:a 2, :c 3, :b 5}\n(merge-with + {:a 1, :c 3, :b 2} {:a 1 :b 3})\n; (1 3 5)\n(let [[o e] (separate odd? [1 2 3 4 5])] o)\n\n; (2 4)\n(let [[o e] (separate odd? [1 2 3 4 5])] e)\n\n; rest using \u0026\n; x: 1 more: (2 3)\n(let [[x \u0026 more] [1 2 3]]\n  (println \"x:\" x \"more:\" more))\n\n; hold the complete list using :as\n; x: 1 more: (2 3) full list: [1 2 3]\n(let [[x \u0026 more :as full-list] [1 2 3]]\n  (println \"x:\" x \"more:\" more \"full list:\" full-list))\n\n; x: 5 y: 7\n(let [{the-x :x the-y :y} {:x 5 :y 7}]\n  (println \"x:\" the-x \"y:\" the-y))\n\n; The :keys directive allows you to specify keys that you would like as locals with the same name\n; x: 5 y: 7\n(let [{:keys [x y]} {:x 5 :y 7}]\n  (println \"x:\" x \"y:\" y))\n\n; default values\n; x: 0 y: 7\n(let [{:keys [x y] :or {x 0 y 0}} {:y 7}]\n  (println \"x:\" x \"y:\" y))\n; use `do` to allow side effects...\n; (1 3 5)\n; (2 4)\n; nil\n(let [[o e] (separate odd? [1 2 3 4 5])] (do (prn o) (prn e)))\n; All of this is taken from http://www.braveclojure.com/writing-macros/\n\n; you can define a macro that is quote complex \n\n(defmacro code-critic\n  \"phrases are courtesy Hermes Conrad from Futurama\"\n  [{:keys [good bad]}]\n  (list 'do\n        (list 'println\n              \"Great squid of Madrid, this is bad code:\"\n              (list 'quote bad))\n        (list 'println\n              \"Sweet gorilla of Manila, this is good code:\"\n              (list 'quote good))))\n\n; slight refactor with macro syntax quoting\n\n(defmacro code-critic\n  \"phrases are courtesy Hermes Conrad from Futurama\"\n  [{:keys [good bad]}]\n  ;; Notice the backtick - that's the syntax quote\n  `(do (println \"Great squid of Madrid, this is bad code:\"\n                (quote ~bad))\n       (println \"Sweet gorilla of Manila, this is good code:\"\n                (quote ~good))))\n\n; usage\n; =\u003e Cursed bacteria of Liberia, this is bad code: (1 + 1)\n; =\u003e Sweet sacred boa of Western and Eastern Samoa, this is good code: (+ 1 1)\n(code-critic {:good (+ 1 1) :bad (1 + 1)})\n\n; and then refactor it so some of the complexity\n; is placed inside another function\n; that function is then only really useful when \n; used from inside the macro\n\n(defn criticize-code\n  [criticism code]\n  `(println ~criticism (quote ~code)))\n\n(defmacro code-critic\n  [{:keys [good bad]}]\n  `(do ~(criticize-code \"Cursed bacteria of Liberia, this is bad code:\" bad)\n       ~(criticize-code \"Sweet sacred boa of Western and Eastern Samoa, this is good code:\" good)))\n\n; more refactoring\n(defmacro code-critic\n  [{:keys [good bad]}]\n  `(do ~(map #(apply criticize-code %)\n             [[\"Great squid of Madrid, this is bad code:\" bad]\n              [\"Sweet gorilla of Manila, this is good code:\" good]])))\n\n; uh-oh that caused an error\n; use macroexpand to decipher what's happening\n; for those short on time, the fix is unquote splicing ~@\n; Unquote splicing is like unwrapping a seq'able data structure (examples below)\n\n; Without unquote splicing\n; =\u003e (clojure.core/+ (1 2 3))\n; which would cause an error\n`(+ ~(list 1 2 3))\n\n; With unquote splicing\n; =\u003e (clojure.core/+ 1 2 3)\n`(+ ~@(list 1 2 3))\n\n(defmacro code-critic\n  [{:keys [good bad]}]\n  `(do ~@(map #(apply criticize-code %)\n              [[\"Sweet lion of Zion, this is bad code:\" bad]\n               [\"Great cow of Moscow, this is good code:\" good]])))\n(code-critic {:good (+ 1 1) :bad (1 + 1)})\n\n; final refactoring\n\n(def criticisms {:good \"Sweet manatee of Galilee, this is good code:\"\n                 :bad \"Sweet giant anteater of Santa Anita, this is bad code:\"})\n\n(defn criticize-code\n  [[criticism-key code]]\n  `(println (~criticism-key criticisms) (quote ~code)))\n\n(defmacro code-critic\n  [code-evaluations]\n  `(do ~@(map criticize-code code-evaluations)))\n; we'll see that the sequence is lazily evaluated\n; meaning the entire range isn't created initially\n; that only happens when the user requests the relevant data\n(def squares\n  (map \n    (fn [x] (println x) (* x x)) \n    (range 1 100)))\n\n(first squares) ; prints 1 to 31 (as a side effect) and returns first value: 1\n; short-hand anonymous function\n; here is an example of a long-form anonymous function\n; =\u003e {:baz 3, :foo 1}\n((fn [data] (select-keys data [:foo :baz])) {:foo 1 :bar 2 :baz 3})\n\n; here is the short-hand variation using `#()` and passing in `%` as the placeholder value\n; use `%` if one arg, `%n` (e.g. `%1`, `%2` etc) when multiple args and `%\u0026` acts like rest\n(#(select-keys % [:foo :baz]) {:foo 1 :bar 2 :baz 3})\n; custom method that separates the predicate from a sequence\n; a predicate is a fancy word for a function that returns a boolean (true/false) value\n; e.g. from `[1 2 3 4 5]`, if the predicate is `odd?` then we'll get back `[(1 3 5) (2 4)]`\n(def separate\n  (fn [predicate sequence]\n    [(filter predicate sequence) (remove predicate sequence)]))\n\n; [(1 3 5) (2 4)]\n(separate odd? [1 2 3 4 5])\n(defmacro postfix-notation\n  \"I'm too indie for prefix notation\"\n  [expression]\n  (conj (butlast expression) (last expression)))\n\n; The expression/form (1 1 +) would normally cause an error\n; But as we're calling a macro it is passed unevaluated\n; =\u003e 2\n(postfix-notation (1 1 +))\n\n; We can see the evaluated result of a macro\n; by using the macroexpand function along with a single quote\n; to prevent evaluation (as normal functions fully evaluate their arguments)\n; =\u003e ; =\u003e (+ 1 1)\n(macroexpand '(postfix-notation (1 1 +)))\n\n; Building macros is usually about constructing a list\n; that when called will be evaluated\n; Because of this quoting, either '(+ 1 1) or (quote (+ 1 1)), is used a lot\n; This is so you can construct an unevaluated list within the macro\n; See the following macro uses quotes to prevent `if` and `do` being evaluated\n\n;; This is when's actual source\n(defmacro when\n  \"Evaluates test. If logical true, evaluates body in an implicit do.\"\n  {:added \"1.0\"}\n  [test \u0026 body]\n  (list 'if test (cons 'do body)))\n\n(macroexpand '(when (the-cows-come :home)\n                (call me :pappy)\n                (slap me :silly)))\n; =\u003e\n(if (the-cows-come :home)\n  (do (call me :pappy)\n      (slap me :silly)))\n\n; Here is another macro example\n\n(defmacro unless\n  \"Inverted 'if'\"\n  [test \u0026 branches]\n  (conj (reverse branches) test 'if))\n\n(macroexpand '(unless (done-been slapped? me)\n                      (slap me :silly)\n                      (say \"I reckon that'll learn me\")))\n; =\u003e\n(if (done-been slapped? me)\n  (say \"I reckon that'll learn me\")\n  (slap me :silly))\n; Instead of having to generate lots of lists inside your macro\n; all of which need to their function symbols to be quoted\n; you could instead use the macro syntax quote ` and ~\n; ` will return the fully qualified symbols so that the symbol includes its namespace\n; so `+ will return clojure.core/+\n; and `(+ 1 2) will return (clojure.core/+ 1 2)\n; ~ allows you to temporarily unquote a form expression\n; so `(+ 1 ~(inc 1)) returns (clojure.core/+ 1 2)\n\n(defmacro triple [x]\n  `(+ ~x ~x ~x))\n\n; =\u003e 12\n(triple 4)\n\n; Building a list with the list function\n; =\u003e (+ 1 2)\n(list '+ 1 (inc 1))\n\n; Building a list from a quoted list - super awkward\n; =\u003e (+ 1 2)\n(concat '(+ 1) (list (inc 1)))\n\n; Building a list with unquoting\n; =\u003e (clojure.core/+ 1 2)\n`(+ 1 ~(inc 1))\n(def bank (ref 0))\n(def bank-props (ref #{\"Baltic\" \"Park Place\" \"Boardwalk\"}))\n(def player (ref [{:money 1500\n                   :props #{}}]))\n@bank\n;=\u003e 0\n@bank-props\n;=\u003e #{\"Baltic\" \"Boardwalk\" \"Park Place\"}\n@player\n;=\u003e [{:money 1500, :props #{}}]\n \n(defn buy-property\n  [prop-name cost player-num]\n  (dosync \n    (alter bank + cost)\n    (alter player update-in [player-num :money] - cost)\n    (alter bank-props disj prop-name)\n    (alter player update-in [player-num :props] conj prop-name)))\n\n(buy-property \"Baltic\" 200 0)\n\n@bank\n;=\u003e 200\n@bank-props\n;=\u003e #{\"Boardwalk\" \"Park Place\"}\n@player\n;=\u003e [{:money 1300, :props #{\"Baltic\"}}]\n(select-keys {:a 1 :b 2 :c 3} [:a :c]) ; {:c 3, :a 1}\n(vals {:c 3, :a 1}) ; (3 1)\n\n; the above can be composed manually to:\n(vals (select-keys {:a 1 :b 2 :c 3} [:a :c])) ; (3 1)\n\n; but we can use the comp function instead of that:\n(def c (comp vals select-keys))\n(c {:a 1 :b 2 :c 3} [:a :c]) ; (3 1)\n; the following code first demonstrates non-thread safe code\n; then we use an `atom` and its associated function `swap!` to change the value of the atom\n; ultimately the code becomes thread safe\n(def xs #{})\n(dotimes [i 10] (future (def xs (conj xs i))))\nxs ; =\u003e #{2 5 6 8 9}\n\n; notice the set doesn't hold values zero to nine like we expect\n; this is because running conj on the *current* value over multiple threads means\n; we can't guarantee the value of xs (unless it's locked/synchronised/mutexed)\n\n; here is the thread safe version\n(def xs (atom #{}))\n(dotimes [i 10] (future (swap! xs conj i)))\n@xs ; =\u003e #{0 1 2 3 4 5 6 7 8 9}\n; defining a simple function\n(defn foobar \"blah\" [x]\n  (+ x 1))\n\n; use the above function\n; =\u003e 11\n(foobar 10)\n; anonymous function\n; =\u003e 6\n((fn [a [b c]] (+ a b c)) 1 [2 3])\n","tags":""},{"id":"ac3eb133663d20a9fce1","title":"Ruby Array Guarding","content":"Below is an example of trying to protect against a request for data failing to return the expected data structure (in this case an Array)...\n\n```ruby\nexpect_an_array_back = SomeClass.make_a_request_for_data\n\nif expect_an_array_back.any?\n  expect_an_array_back.each do |user|\n    # ...\n  end\nend\n```\n\nInstead we should guard against failing in a cleaner way. \n\nIf the collection is empty then we can just loop over the Array without a guard, like so...\n\n```ruby\nSomeClass.make_a_request_for_data.each do |user|\n  # ...\nend\n```\n\nOr in situations where we're not sure if we'll get an empty Array or `nil` then we can wrap the returned value in an Array and if it is `nil` then `Array(expect_an_array_back)` will be converted into an empty collection (which will be safe to enumerate), like so...\n\n```ruby\nexpect_an_array_back = SomeClass.make_a_request_for_data\n\nArray(expect_an_array_back).each do |user|\n  # ...\nend\n```\n","tags":""},{"id":"a29212a8eb10bc8154b7","title":"Ruby Meta Programming","content":"# Context Probe\n# Execute a code block in the context of another object using `instance_eval`\nclass Foo\n  def initialize\n    @z = 1\n  end\nend\nfoo = Foo.new\nfoo.instance_eval do\n  puts self # =\u003e #\u003cFoo:0x7d15e891\u003e\n  puts @z # =\u003e 1\nend\nnew_value = 2\nfoo.instance_eval { @z = new_value }\nfoo.instance_eval { puts @z } # =\u003e 2\n\n# There is also `instance_exec` which works the same way but allows passing arguments to the block\nclass Foo\n  def initialize\n    @x, @y = 1, 2\n  end\nend\nFoo.new.instance_exec(3) { |arg| (@x + @y) * arg } # =\u003e 9\n# Evaluate a block in the context of a class\n# Similar to re-opening a class but more flexible in that it\n# works on any variable that references a class, where as re-opening\n# a class requires defining a constant.\n\n# Classic class re-opening style\nclass String\n  def m; puts \"hello!\" end\nend\n\n# Class eval style \n# The extra code is used to make the example a bit more re-usable/abstracted\ndef add_method_to_class(the_class)\n  the_class.class_eval do\n    def m; puts \"hello!\" end\n  end\nend\n\nadd_method_to_class String\n\"abc\".m # =\u003e hello!\n- Dynamic Dispatch\n- Dynamic Method\n- Ghost Methods\n- Dynamic Proxies\n- Blank Slate\n- Kernel Method\n- Flattening the Scope (aka Nested Lexical Scopes)\n- Context Probe\n- Class Eval *(not really a 'spell' more just a demonstration of its usage)*\n- Class Macros\n- Around Alias\n- Hook Methods\n- Class Extension Mixin\n- Module Namespace Interpolation\n# Dynamic Proxies\n# Catching \"Ghost Methods\" and forwarding them onto another method\n# Whilst possibly adding logic around the call.\n#\n# For example,\n# You can provide imaginary methods by utilising `method_missing` to parse\n# the incoming message (e.g. `get_name`, `get_age`) and to delegate off to \n# another method such as `get(:data_type)` where `:data_type` is `:name` or `:age`.\ndef method_missing(message, *args, \u0026block)\n  return get($1.to_sym, *args, \u0026block) if message.to_s =~ /^get_(.*)/\n  super # if we don't find a match then we'll call the top level `BasicObject#method_missing`\nend\n\n# If (after analysis) you discover a performance issue with using `method_missing`\n# you can utilise the \"Dynamic Method\" technique to create a real method after \n# the message has been received by `method_missing` the first time.\n# Flattening the Scope (aka Nested Lexical Scopes)\n# Where you change the code in such a way that it's easier for you to pass variables through \"Scope Gates\".\n# A scope gate is any block, where normally when you enter its scope the variables outside of it become unreachable.\n# This happens in: Class definitions, Module definitions, Method definitions\n# I'm not sure what the real life examples are of this, but if you ever wonder why some code does the following,\n# then maybe it was that they wanted to flatten the scope so they could more easily pass around variables.\n# I guess it's better to do it this way than to define a global variable?\n#\n# In the following code we want to access `my_var` from inside the method (inner scope gate) that's\n# inside the class (outer scope gate).\nmy_var = \"abc\"\nclass OuterScopeGate\n  puts my_var\n\n  def inner_scope_gate\n    puts my_var\n  end\nend\n\n# We fix this by flattening the code into method calls (method *calls* aren't scope gates)\n# So we turn the class keyword into a method call using `Class.new`\n# We also turn the method inside the class from a keyword into a method call using `define_method`\nmy_var = \"abc\"\nMyClass = Class.new do\n  puts \"Here is 'my_var' inside my class definition: #{my_var}\"\n  \n  define_method :my_method do\n    puts \"Here is 'my_var' inside my class instance method: #{my_var}\"\n  end\nend # =\u003e Here is 'my_var' inside my class definition: abc\nMyClass.new.my_method # =\u003e Here is 'my_var' inside my class instance method: abc\n# Class Macros are just regular class methods that are only used in a class definition \n# e.g. not used from a new instance of the class (only at the time the class is defined)\n#\n# Below is an example of a Class Macro that alerts users of a publically available class\n# that the methods they've been using are now deprecated and they should use the renamed version.\n#\n# It uses \"Dynamic Method\" to help performance by creating the old methods again and delegating off\n# to the new methods (rather than using `method_missing` which can be quite slow as it has to spend\n# time looking up the inheritance chain)\nclass Foo\n  def get_a; puts \"I'm an A\" end\n  def get_b; puts \"I'm an B\" end\n  def get_c; puts \"I'm an C\" end\n\n  # Defining our Class Macro\n  def self.deprecate(old_method, new_method)\n    define_method(old_method) do |*args, \u0026block|\n      puts \"Warning: #{old_method} is deprecated! Use #{new_method} instead\"\n      send(new_method, *args, \u0026block) # `self` is assumed when calling `send`\n    end\n  end\n\n  # Using our Class Macro\n  deprecate :a, :get_a\n  deprecate :b, :get_b\n  deprecate :c, :get_c\nend\n# Around Alias uses the `alias` keyword to store a copy of the original method under a new name,\n# allowing you to redefine the original method name and to delegate off to the previous method implementation\n\nclass String\n  alias :orig_length :length\n \n  def length\n    \"Length of string '#{self}' is: #{orig_length}\"\n  end  \nend\n \n\"abc\".length\n#=\u003e \"Length of string 'abc' is: 3\"\n```rb\n# Hook Methods are provided by the Ruby language and let you know about certain events\n# such as when a class inherits from another class or when a method has been added to an object.\nclass String\n  def self.inherited(subclass)\n    puts \"#{self} was inherited by #{subclass}\"\n  end\nend\nclass MyString \u003c String; end # =\u003e String was inherited by MyString\n```\n\nThere are quite a few hooks which I've listed below.\n\n**Method-related hooks**\n\n```\nmethod_missing\nmethod_added\nsingleton_method_added\nmethod_removed\nsingleton_method_removed\nmethod_undefined\nsingleton_method_undefined\n```\n\n**Class \u0026 Module Hooks**\n\n```\ninherited\nappend_features\nincluded\nextend_object\nextended\ninitialize_copy\nconst_missing\n```\n\n**Marshalling Hooks**\n\n```\nmarshal_dump\nmarshal_load\n```\n\n**Coercion Hooks**\n\n```\ncoerce\ninduced_from\nto_xxx\n```\ntype = \"baz\"\nFoo::Bar.const_get(type.capitalize).new # =\u003e new instance of Foo::Bar::Baz\n# Dynamic Dispatch\n# Allows us to send messages to even private methods\n# object.send(message, *arguments)\n1.send(:+, 2) # =\u003e 3\n# Dynamic Method\n# Allows us to dynamically create methods\n# define_method :method_name { block that becomes method body }\nclass Foo\n  define_method :bar do\n    puts \"This is a dynamic method\"\n  end\nend\nFoo.new.bar # =\u003e \"This is a dynamic method\"\n\n# Dynamic Method\n# Alternative example\nclass Bar\n  # we have to define this method on `self` (see below comment)\n  def self.create_method(method)\n    define_method \"my_#{method}\" do\n      puts \"Dynamic method called 'my_#{method}'\"\n    end\n  end\n\n  # these methods are executed within the definition of the Bar class\n  create_method :foo\n  create_method :bar\n  create_method :baz\nend\nBar.new.my_foo # =\u003e \"Dynamic method called 'my_foo'\"\nBar.new.my_bar # =\u003e \"Dynamic method called 'my_bar'\"\nBar.new.my_baz # =\u003e \"Dynamic method called 'my_baz'\"\n\n# Dynamic Method\n# Parse another class for data\nclass AnotherClass\n  def get_foo_stuff; end\n  def get_bar_stuff; end\n  def get_baz_stuff; end\nend\nclass Baz\n  def initialize(a_class)\n    a_class.methods.grep(/^get_(.*)_stuff$/) { Baz.create_method $1 }\n  end\n  def self.create_method(method)\n    define_method \"my_#{method}\" do\n      puts \"Dynamic method called 'my_#{method}'\"\n    end\n  end\nend\nanother_class = AnotherClass.new\nBaz.new(another_class).my_foo # =\u003e \"Dynamic method called 'my_foo'\"\nBaz.new(another_class).my_bar # =\u003e \"Dynamic method called 'my_bar'\"\nBaz.new(another_class).my_baz # =\u003e \"Dynamic method called 'my_baz'\"\n\nclass Foo\n  def initialize(bar)\n    self.class.send(:define_method, bar) { p \"hello #{bar}!\" }\n  end  \nend\nfoo = Foo.new(\"world\")\nfoo.world # =\u003e \"hello world!\"\n# Blank Slate\n# Prevents issues when using \"Dynamic Proxies\"\n#\n# e.g. user calls a method that exists higher up the inheritance chain\n# so your `method_missing` doesn't fire because the method does exist.\n# \n# To work around this issue, make sure your class starts with a \"Blank Slate\"\n# So you remove any methods you don't want to appear at all in the inheritance chain\n# by using `undef_method` (there is also `remove_method` which doesn't remove the named\n# method from the inheritance chain but just the current class, but that doesn't help us\n# fix the \"Dynamic Proxy\" scenario so we use `undef_method` instead).\n#\n# For \"Dynamic Proxy\" we use the parent `method_missing` so we keep that,\n# we also might use `respond_to?` so we keep that (although you can remove it if you don't).\n# Also the `__` in the below regex pattern is to prevent Ruby from displaying a warning \n# about removing 'reserved' methods such as `__id__` and `__send__`\nclass ImBlank\n  instance_methods.each do |m|\n    undef_method m unless m.to_s =~ /^__|method_missing|respond_to?/\n  end\n\n  # rest of your code (such as your \"Dynamic Proxy\" implementation)\nend\n# Kernel Method\n# Add a method that gives the illusion it's a language keyword\n# But really it's just added to the `Kernel` module which all other objects inherit from.\n# At the top level of a Ruby program `self` is == `main`.\n# `self.class` == `Object` and the `Kernel` sits above it in the hierarchy.\n# You can see this by running the following code:\nclass Foo; end\nFoo.ancestors # =\u003e [Foo, Object, Kernel, BasicObject]\n\n# So we can see we can add what looks to be a language provided feature like so:\nmodule Kernel\n  def foobar\n    puts \"I'm not a language keyword, I'm just a fake\"\n  end\nend\n\n# Now from any where in our program we can call\nfoobar # =\u003e I'm not a language keyword, I'm just a fake\n# Class Extension Mixin allows you to both `include` and `extend` a class\nmodule MyMixin\n  def self.included(base) # Hook Method\n    base.extend(ClassMethods)\n  end\n\n  def a\n    puts \"I'm A (an instance method)\"\n  end\n\n  module ClassMethods # \"ClassMethods\" is a recognised naming pattern\n    def x\n      puts \"I'm X (a class method)\"\n    end\n  end\nend\n\nclass Foo\n  include MyMixin\nend\n\nFoo.x # =\u003e I'm X (a class method)\nFoo.new.a # =\u003e I'm A (an instance method)\n# Ghost Methods\n# Utilises `method_missing`\nclass Hai\n  def method_missing(method, *args)\n    puts \"You called: #{method}(#{args.join(', ')})\"\n    puts \"You also passed a block\" if block_given?\n  end\nend\nHai.new.yolo # =\u003e You called: yolo()\nHai.new.yolo \"a\", 123, :c # =\u003e You called: yolo(a, 123, c)\nHai.new.yolo(:a, :b, :c) { puts \"a block\" } # =\u003e You called: yolo(a, b, c)\n                                            # =\u003e You also passed a block\n","tags":""},{"id":"7560051","title":"Complex Sass example found in the wild...","content":"$metaHeight: 20px;\n\n.container--news {\n    .container__toggle { display: none; }\n}\n\n// $collection: (width: 12, height: 5, flow-offset-x: 8, flow-offset-y: 3);\n//  @include nc-collection($collection);\n//\n//  height\n//  |------------ width\n//  |          y\n//  |   x    |---\n//  |        |     \u003c-- Flow\n//  |        |\n\n@mixin nc-collection($collection) {\n    $width:         map-get($collection, width);\n    $height:        map-get($collection, height);\n    $flow-offset-x: map-get($collection, flow-offset-x);\n    $flow-offset-y: map-get($collection, flow-offset-y);\n\n    $flow-container-width: gs-span($width - $flow-offset-x) + $gs-gutter;\n    $flow-container-height: gs-height($height - $flow-offset-y) + $gs-baseline;\n\n    $dimensions: (\n        width: $flow-container-width,\n        min-height: $flow-container-height\n    );\n\n    @if($flow-offset-x \u003e 0) {\n        $dimensions: map-merge($dimensions, (padding-left: gs-span($flow-offset-x)));\n    }\n    @if($flow-offset-y \u003e 0) {\n        $dimensions: map-merge($dimensions, (padding-top: gs-height($flow-offset-y) + $gs-baseline));\n    }\n    @include rem($dimensions);\n}\n\n@mixin nc-position($x, $y) {\n    @include rem((\n        left: if($x \u003e 0, gs-span($x) + $gs-gutter,     0),\n        top:  if($y \u003e 0, gs-height($y) + $gs-baseline, 0)\n    ));\n}\n\n@mixin nc-item($width, $height, $x, $y, $collection) {\n    @include rem((\n        width: gs-span($width),\n        height: gs-height($height)\n    ));\n    @include nc-position($x, $y);\n}\n\n@mixin align-separator-with-tone-border {\n    \u0026:before {\n        @include rem((\n            top: $gs-baseline / 2\n        ));\n    }\n}\n\n\n.item__image-container {\n    @include rem((\n        margin-top: $gs-baseline / 3\n    ));\n}\n.container--news {\n    @include mq(tablet) {\n        .collection {\n            position: relative;\n            margin-left: 0;\n            margin-right: 0;\n            border-bottom: 1px solid $c-neutral5;\n\n            .item {\n                min-height: 0; // override existing facia styles\n            }\n        }\n        .item__title {\n            @include fs-headline(3);\n            @include rem((\n                margin-bottom: $gs-baseline\n            ));\n        }\n        .item__standfirst {\n            @include fs-headline(1);\n            color: $c-neutral2;\n            text-decoration: none;\n            margin-top: 0;\n            @include rem((\n                margin-bottom: $gs-baseline,\n                padding-right: gs-span(1)\n            ));\n        }\n        .item__meta {\n            @include rem((\n                height: $metaHeight\n            ));\n        }\n        .item__byline {\n            display: none !important; // Todo: support for cif pieces\n        }\n        .item {\n            @include box-sizing(content-box);\n            position: absolute;\n            margin-top: 0;\n            margin-bottom: 0;\n            @include rem((\n                padding: $gs-baseline / 2 0\n            ));\n\n            \u0026:first-child {\n                .item__link {\n                    border-top-style: solid;\n                }\n                \u0026:before {\n                    display: none;\n                }\n            }\n            .item__image-container {\n                display: none;\n            }\n            @include when-no-image(':first-child') {\n                .item__title {\n                    @include fs-headline(9, true);\n                }\n                .item__standfirst {\n                    @include fs-headline(3, true);\n                    display: block;\n                }\n            }\n        }\n    }\n    @include mq(tablet, desktop) {\n        $collection: (width: 9, height: 12, flow-offset-x: 6, flow-offset-y: 6);\n\n        .collection {\n            @include nc-collection($collection);\n        }\n        .item {\n            \u0026 {\n                @include nc-item(6, 8, 0, 0, $collection);\n\n                .item__title {\n                    @include fs-headline(4, true);\n                }\n                .item__standfirst {\n                    display: none;\n                }\n            }\n            @include when-image(':first-child') {\n                .item__image-container {\n                    display: block;\n                }\n            }\n            \u0026:nth-child(n+2) {\n                \u0026:before {\n                    @include rem((\n                        left: -10px\n                    ));\n                }\n                .item__title {\n                    @include rem((\n                        margin-bottom: $baseline*2\n                    ));\n                }\n            }\n            \u0026:nth-child(2) {\n                @include nc-item(3, 6, 6, 0, $collection);\n                @include align-separator-with-tone-border;\n\n                .item__title {\n                    @include fs-headline(2, true);\n                }\n            }\n            @include when-image(':nth-child(2)') {\n                .item__image-container {\n                    display: block;\n                }\n            }\n            @include when-no-image(':nth-child(2)') {\n                .item__standfirst {\n                    display: block;\n                    padding-right: 0;\n                }\n            }\n            \u0026:nth-child(3),\n            \u0026:nth-child(4) {\n                @include nc-item(3, 4, 0, 8, $collection);\n                @include align-separator-with-tone-border;\n\n                .item__image-container {\n                    display: none;\n                }\n                .item__title {\n                    @include fs-headline(3, true);\n                }\n            }\n            @include when-no-image(':nth-child(3)') {\n                .item__standfirst {\n                    display: none;\n                }\n            }\n            @include when-no-image(':nth-child(4)') {\n                .item__standfirst {\n                    display: none;\n                }\n            }\n            \u0026:nth-child(4) {\n                @include nc-position(3, 8);\n            }\n            \u0026:nth-child(n+5) {\n                position: relative;\n                float: left;\n                @include rem((\n                    width: gs-span(3),\n                    height: gs-height(2),\n                    margin-left: $gs-gutter\n                ));\n\n                .item__image-container {\n                    display: none;\n                }\n                .item__title {\n                    @include fs-headline(1, true);\n                    padding-right: 0;\n                    margin-bottom: 0;\n                }\n            }\n            \u0026:nth-child(n+8) {\n                @include rem((\n                    width: gs-span(3),\n                    height: gs-height(2)\n                ));\n            }\n            \u0026:nth-child(3n+8) {\n                clear: both;\n                @include rem((\n                    margin-left: gs-span(6) * -1\n                ));\n            }\n            \u0026:nth-child(3n+9) {\n                clear: none;\n                @include rem((\n                    margin-left: gs-span(3) * -1\n                ));\n            }\n            \u0026:nth-child(3n+10) {\n                clear: none;\n                @include rem((\n                    margin-left: $gs-gutter\n                ));\n            }\n        }\n    }\n    @include mq(desktop, wide) {\n        $collection: (width: 12, height: 10, flow-offset-x: 8, flow-offset-y: 0);\n\n        .collection {\n            @include nc-collection($collection);\n        }\n        .item {\n            .item__title {\n                @include fs-headline(4, true);\n            }\n            \u0026:nth-child(1) {\n                @include nc-item(5, 10, 0, 0, $collection);\n\n                .item__standfirst {\n                    display: block;\n                }\n            }\n            @include when-image(':first-child') {\n                .item__image-container {\n                    display: block;\n                }\n            }\n            \u0026:nth-child(n+2) {\n                \u0026:before {\n                    @include rem((\n                        left: -10px\n                    ));\n                }\n            }\n            \u0026:nth-child(2),\n            \u0026:nth-child(3) {\n                @include align-separator-with-tone-border;\n\n                .item__title {\n                    @include fs-headline(2, true);\n                    @include rem((\n                        margin-bottom: $baseline*2\n                    ));\n                }\n            }\n            \u0026:nth-child(2) {\n                @include nc-item(3, 6, 5, 0, $collection);\n            }\n            @include when-image(':nth-child(2)') {\n                .item__image-container {\n                    display: block;\n                }\n            }\n            @include when-no-image(':nth-child(2)') {\n                .item__standfirst {\n                    display: block;\n                    padding-right: 0;\n                }\n            }\n            \n            \u0026:nth-child(3) {\n                @include nc-item(3, 4, 5, 6, $collection);\n\n                .item__title {\n                    @include fs-headline(3, true);\n                }\n            }\n            \u0026:nth-child(n+3) {\n                .item__standfirst {\n                    display: none;\n                }\n            }\n            \u0026:nth-child(n+4) {\n                position: relative;\n                float: left;\n                @include rem((\n                    width: gs-span(4),\n                    height: gs-height(2),\n                    margin-left: $gs-gutter\n                ));\n                @include align-separator-with-tone-border;\n\n                .item__title {\n                    @include fs-headline(10, true);\n                    padding-right: 0;\n                }\n            }\n            \u0026:nth-child(3),\n            \u0026:nth-child(8) {\n                \u0026:before {\n                    height: auto;\n                }\n            }\n            \u0026:nth-child(n+9) {\n                clear: none;\n                @include rem((\n                    width: gs-span(3),\n                    height: gs-height(3)\n                ));\n            }\n            \u0026:nth-child(4n+9) {\n                clear: both;\n                @include rem((\n                    margin-left: gs-span(8) * -1\n                ));\n            }\n            \u0026:nth-child(4n+10) {\n                @include rem((\n                    margin-left: gs-span(5) * -1\n                ));\n            }\n            \u0026:nth-child(4n+11) {\n                @include rem((\n                    margin-left: gs-span(2) * -1\n                ));\n            }\n            \u0026:nth-child(4n+12) {\n                @include rem((\n                    margin-left: $gs-gutter\n                ));\n            }\n        }\n    }\n    @include mq(wide) {\n        $collection: (width: 16, height: 10, flow-offset-x: 12, flow-offset-y: 0);\n\n        .collection {\n            @include nc-collection($collection);\n        }\n        .item {\n            @include nc-item(6, 10, 0, 0, $collection);\n\n            .item__title {\n                @include fs-headline(4);\n            }\n            .item__standfirst {\n                display: block;\n            }\n            \u0026:first-child {\n                .item__title {\n                    @include rem((margin-top: $baseline));\n                }\n            }\n            @include when-image(':first-child') {\n                .item__image-container {\n                    display: block;\n                }\n            }\n            @include when-no-image(':first-child') {\n                .item__standfirst {\n                    display: block;\n                    @include rem((\n                        padding-right: gs-span(1)\n                    ));\n                }\n            }\n            \u0026:nth-child(n+2) {\n                \u0026:before {\n                    @include rem((\n                        left: -10px\n                    ));\n                }\n            }\n            \u0026:nth-child(2),\n            \u0026:nth-child(3),\n            \u0026:nth-child(5) {\n                @include align-separator-with-tone-border;\n            }\n            \u0026:nth-child(2),\n            \u0026:nth-child(3) {\n                @include nc-item(3, 6, 6, 0, $collection);\n\n                .item__title {\n                    @include fs-headline(2, true);\n                    @include rem((\n                        margin-bottom: $baseline*2\n                    ));\n                }\n                .item__standfirst {\n                    display: none;\n                }\n            }\n            @include when-image(':nth-child(2)') {\n                .item__image-container {\n                    display: block;\n                }\n            }\n            @include when-image(':nth-child(3)') {\n                .item__image-container {\n                    display: block;\n                }\n            }\n            @include when-no-image(':nth-child(2)') {\n                .item__standfirst {\n                    display: block;\n                    padding-right: 0;\n                }\n            }\n            @include when-no-image(':nth-child(3)') {\n                .item__standfirst {\n                    display: block;\n                    padding-right: 0;\n                }\n            }\n\n            @include when-no-image(':nth-child(4)') {\n                .item__standfirst {\n                    display: block;\n                    padding-right: 0;\n                }\n            }\n            \u0026:nth-child(3) {\n                @include nc-position(9, 0);\n            }\n\n            \u0026:nth-child(4) {\n                @include nc-item(6, 4, 6, 6, $collection);\n\n                .item__title {\n                    @include fs-headline(3, true);\n                    @include rem((\n                        margin-top: 3px,\n                        padding-right: gs-span(1)\n                    ));\n                }\n                .item__standfirst {\n                    display: block;\n                    @include rem((\n                        padding-right: gs-span(1)\n                    ));\n                }\n            }\n            \u0026:nth-child(n+5) {\n                position: relative;\n                float: left;\n                margin-top: 0;\n                @include rem((\n                    width: gs-span(4),\n                    height: gs-height(2),\n                    margin-left: $gs-gutter\n                ));\n\n                .item__title {\n                    @include fs-headline(10, true);\n                    padding-right: 0;\n                    margin-bottom: 0;\n                }\n                .item__standfirst {\n                    display: none;\n                }\n            }\n            @include when-no-image(':nth-child(n+5)') {\n                .item__standfirst {\n                    display: none;\n                }\n            }\n            \u0026:nth-child(n+10) {\n                clear: none;\n\n                \u0026:before { @include rem((top: 6px)); }\n            }\n            \u0026:nth-child(4n+10) {\n                clear: both;\n\n                @include rem((\n                    margin-left: gs-span(12) * -1\n                ));\n            }\n            \u0026:nth-child(4n+11) {\n                @include rem((\n                    margin-left: gs-span(8) * -1\n                ));\n            }\n            \u0026:nth-child(4n+12) {\n                @include rem((\n                    margin-left: gs-span(4) * -1\n                ));\n            }\n            \u0026:nth-child(4n+13) {\n                @include rem((\n                    margin-left: $gs-gutter\n                ));\n            }\n        }\n    }\n}\n","tags":""},{"id":"7910295","title":"Node debugger API","content":"```sh\nRun your application using: `node debug xxx.js` then use the following commands to step-through the code (note: Ctrl+D to exit the debugger)...\n \n    `cont`                      -\u003e continue running\n    `next`                      -\u003e step over next statement\n    `step`                      -\u003e step into next statement (if possible, otherwise it just steps over)\n    `out`                       -\u003e step out of the currently executing function\n    `backtrace`                 -\u003e show the current call execution frame or call stack\n    `repl`                      -\u003e start the node repl to allow you to view variable values and execute code\n    `watch(expr)`               -\u003e add given expression to the watch list (which is shown whenever you step through anything in the debugger)\n    `list(n)`                   -\u003e list the 'n' lines of source code before and after the currently stopped line in the debugger\n    `setBreakpoint(lineNumber)` -\u003e set break-point for specified line number\n \n    The way to use this is to have two terminal screens open.\n    In the first have your `node debug xxx.js`\n    In the second have your `curl –i http://localhost:8080` (don't run this command yet)\n \n    In the first, look through your code using `list(n)`.\n    Once you find a line you think might be the cause of the error use `setBreakpoint(lineNumber)`.\n    Then type `cont` and go to the other terminal window and run the curl command.\n    You'll see that the curl command never completes as the node debugger has taken over.\n    Go back to the first terminal window and use `repl` to inspect the data at that break-point.\n    You can just type the variables into the console (no need to console.log(variableName)).\n    You'll need to press Ctrl+C to exit the REPL so you can continue using the debugger.\n    Or you can Ctrl+D to exit debugging completely.\n```\n","tags":""},{"id":"7694814","title":"[The distinction between \"arguments\" and \"parameters\"] ","content":"/*\n  Arguments are used when a function is being called. \n  We pass arguments to functions. \n  Parameters are set up when the function is defined. \n  So it is said that parameters are used to define a function and arguments are used to invoke a function. \n  These words are typically interchangeable but knowing the distinction can be handy.\n*/\n\nvar myFunction = function(x,y,z){ // x,y,z are parameters\n    return x+y+z\n};\n\nmyFunction(1,2,3); // 1,2,3 are arguments\n","tags":"#args #params #vs"},{"id":"7605146","title":"Sass REM","content":"// Transform a value into rem\n// Assuming baseline is set to 10px on :root/html\n@function rem($value, $baseline: 10px) {\n    @if type-of($value) == list {\n        $result: ();\n        @each $e in $value {\n            $result: append($result, rem($e));\n        }\n        @return $result;\n    } @else {\n        @if $value == 0 { @return 0; } // 0px =\u003e 0\n        @return if(unit($value) == px, $value / $baseline * 1rem, $value);\n    }\n}\n\n// Output rem units with px fallback\n// Expects $properties to be a Sass map\n// Usage: see font-size mixin below\n// or http://sassmeister.com/gist/7451284\n@mixin rem($properties) {\n    @each $property, $value in $properties {\n        @if (type-of($value) == number and $value != 0) {\n            // Turn any value into pixels\n            $value: if(unitless($value), $value * 1px, $value);\n        }\n\n        #{$property}: $value;\n        #{$property}: rem($value);\n    }\n}\n\n@mixin font-size($size, $line-height: $size) {\n    @include rem((\n        font-size: $size,\n        line-height: $line-height\n    ));\n}\n\n@mixin font($family, $weight, $size, $line-height: $size) {\n    font-family: $family;\n    font-weight: $weight;\n    @include font-size($size, $line-height);\n}\n// ----\n// Sass (v3.3.0.rc.1)\n// Compass (v0.13.alpha.10)\n// ----\n\n// Transform a value into rem\n// Assuming baseline is set to 10px on :root/html\n@function rem($value, $baseline: 10px) {\n    @if $value == 0 { @return 0; } // 0rem -\u003e 0\n    @if type-of($value) == list {\n        $result: ();\n        @each $e in $value {\n            $result: append($result, rem($e));\n        }\n        @return $result;\n    } @else {\n        @return if(type-of($value) == number and unit($value) == px, $value / $baseline * 1rem, $value);\n    }\n}\n\n// Output rem units with px fallback\n// Expects $properties to be a Sass map\n@mixin rem($properties) {\n    @each $property, $value in $properties {\n        @if (type-of($value) == number and $value != 0) {\n            // Turn any value into pixels\n            $value: if(unitless($value), $value * 1px, $value);\n        }\n\n        #{$property}: $value;\n        #{$property}: rem($value);\n    }\n}\n\n.test {\n    @include rem((\n        padding: 20px 0 0px 3vh,\n        margin: 0 auto 20px,\n        width: 300px,\n        height: 350px,\n        line-height: 20px\n    ));\n}\n","tags":""},{"id":"7604932","title":"Clamps a block of text to a certain number of lines followed by an ellipsis in Webkit and Blink based browsers","content":"// Reference: http://dropshado.ws/post/1015351370/webkit-line-clamp\n@mixin text-clamp($lines: 2, $line-height: false) {\n    overflow: hidden;\n    display: -webkit-box;\n    -webkit-box-orient: vertical;\n    -webkit-line-clamp: $lines;\n \n    // Fallback for non-Webkit browsers\n    // (won't show `…` at the end of the block)\n    @if $line-height {\n        max-height: $line-height * $lines * 1px;\n    }\n}\n","tags":""},{"id":"3186740","title":"JavaScript pass by value/reference example","content":"var my_num = 123;\nvar my_str = 'abc';\nvar my_obj = { name: 'mark' };\nvar my_arr = ['a', 'b', 'c'];\nvar my_bool = true;\n\nvar new_num = my_num;\nvar new_str = my_str;\nvar new_obj = my_obj;\nvar new_arr = my_arr;\nvar new_bool = my_bool;\n\n++new_num; // increase value by 1\nnew_str += 'def'; // add def to the end of the String\nnew_obj.age = 100; // add new property to the Object\nnew_arr.push('d'); // add new item to the end of the Array\nnew_bool = false; // reverse boolean value\n\nconsole.group('Original');\n    console.log(my_num);\n    console.log(my_str);\n    console.log(my_obj);\n    console.log(my_arr);\n    console.log(my_bool);\nconsole.groupEnd();\n\nconsole.group('New');\n    console.log(new_num);\n    console.log(new_str);\n    console.log(new_obj);\n    console.log(new_arr);\n    console.log(new_bool);\nconsole.groupEnd();\n\n/*\n * JavaScript types are split into two groups: primitive types and reference types. \n * Numbers, Booleans, Strings, Null and Undefined types are primitive. \n * Objects, Arrays, and Functions are reference types. \n * \n * So you'll notice that JavaScript passes Objects/Arrays/Functions by reference  \n * and passes primitives such as Booleans/Strings/Numbers by value\n */\n","tags":""},{"id":"7927745","title":"JavaScript: mocking the Window and Document objects","content":"In `tabloid/webapp/php/sharedmodules/tabloid-shared/views/layout/base.spv` we run...\n\n```js\nrequire(['module/base', 'domReady'], function (base, domReady) {\n    domReady(function () {\n        base.init();\n        \u003c?php $this-\u003enewsPageJavaScript(); ?\u003e\n    });\n});\n```\n\n...this loads our base module which sets up stats and other baseline requirement stuff (such as setting classes on HTML elements).\n\nThis module loads `module/bootstrap` which sets up jQuery and our pubsub library. This module is typically imported EVERYWHERE, like so...\n\n```js\ndefine(['module/bootstrap'], function (news) {\n    var $      = news.$,\n        pubsub = news.pubsub;\n        \n    // code\n});\n```\n\nI'm thinking within `module/bootstrap` we could load up the WindowMock module like so...\n\n```js\ndefine(['jquery', 'config', 'module/windowMock' 'vendor/events/pubsub'], function(jquery, config, windowMock) {\n    // note: pubsub module doesn't return anything and so we put it last in the dependency list\n    var news = {\n        pubsub: jquery,\n        $: jquery,\n        config: config,\n        window: (isTestEnvironment) ? windowMock : window,\n        document: (isTestEnvironment) ? windowMock.document : window.document\n    };\n\n    return news;\n});\n```\n\n...note: we'd need to move the windowMock helper file into the 'module' directory.\n\nThe windowMock file looks like this...\n\n```js\ndefine([\n    'module/bootstrap',\n], function (news) {\n        var windowMock = {\n            resizeSet: false, // set within the fake News object below\n\n            createFakeWindow: function(width, height) {\n                return {\n                    document: {\n                        documentElement: {\n                            clientWidth: width,\n                            clientHeight: height\n                        }\n                    },\n\n                    resizeTo: function(width, height) {\n                        this.document.documentElement = {\n                            clientWidth: width,\n                            clientHeight: height\n                        };\n                    }\n                };\n            },\n\n            fireResizeEvent: function() {\n                this.handler(); // set within the fake News object below\n            },\n\n            news: {\n                $: function(element) {\n                    return {\n                        on: function(event, handler) {\n                            if (event === 'resize') {\n                                windowMock.resizeSet = true;\n                                windowMock.handler = handler;\n                            }\n                        }\n                    };\n                },\n\n                pubsub: news.pubsub\n            }\n        };\n\n        return windowMock;\n    }\n);\n```\n\nYou can also use it like so...\n\n```js\nfunction createFakeWindow (width, height) {\n    var fakeWindow = WindowMock.createFakeWindow(width, height);\n\n    someObject.init(fakeWindow, WindowMock.news); // this can be removed or changed appropriately\n\n    return fakeWindow;\n}\n\nfunction resizeWindow (width, height, fakeWindow) {\n    document.body.style.width = width + 'px'; // remember to reset this in the test tear down\n    fakeWindow.resizeTo(width, height);\n    WindowMock.fireResizeEvent();\n}\n```\n\nSee we use `isTestEnvironment` to check what to return. I'm guessing we'll set `isTestEnvironment = true` within our jasmine test runner set-up (before we load `modules/bootstrap`).\n\nSo within our code we can just do...\n\n```js\ndefine([\n    'module/bootstrap',\n    'module/navigation/nav',\n    'module/navigation/narrow'\n], function(\n    news,\n    nav,\n    narrow\n) {\n    var $ = news.$,\n        pubsub = news.pubsub,\n        window = news.window,\n        document = news.document;\n\n    // we can now use `window` and `document` and they'll either be our mock or the real thing\n});\n```\n","tags":""},{"id":"7464000","title":"Example of how to structure your Grunt files","content":"module.exports = function (grunt) {\n    \"use strict\";\n\n    var tasks = require('./scripts/grunt')(grunt); // this points to a directory and not a file (there should be an index.js inside the directory for this to work)\n\n    grunt.registerTask('noop', 'A no-operation task -\u003e useful in testing situations', tasks.noop.runTask);\n};\n\"use strict\";\n\nmodule.exports = function (grunt) {\n    return {\n        noop: require('./noop.js')(grunt) // result of scripts/grunt/noop.js is stored on the 'noop' property\n    };\n};\n\"use strict\";\n\nmodule.exports = function (grunt) {\n    return {\n        runTask: function runNoopTask () {\n            grunt.log.writeln(\"noop run\");\n        }\n    };\n};\nmodule.exports = function (grunt) {\n\n    // Project configuration.\n    grunt.initConfig({\n\n        // Store your Package file so you can reference its specific data whenever necessary\n        pkg: grunt.file.readJSON('package.json')\n        \n        // ...tasks...\n        \n    });\n\n    // Default task\n    grunt.registerTask('default', ['...']);\n\n    // Load custom tasks...\n    require('./grunt-customtasks.js')(grunt);\n\n};\n","tags":""},{"id":"7750250","title":"[Cucumber Gherkin Template Feature File] ","content":"Feature: \u003ctitle\u003e\n  \n  In order to \u003cdo something\u003e\n  As a \u003cuser\u003e\n  I want to \u003cachieve some goal\u003e\n\n  Scenario: \u003ctitle\u003e\n  \n    \u003cadditional description\u003e\n  \n    Given \u003csome state\u003e\n    When \u003csome action\u003e\n    Then \u003csome expectation\u003e with \u003csome_name\u003e # where \u003csome_name\u003e is actual Gherkin syntax for a table lookup!\n\n    Examples:\n      | some_name |\n      | A         |\n      | B         |\n      | C         |\n      | ...etc    |\n\n  Tasks: # non-standard syntax, but useful for most 'project planning' purposes\n\n    - What: ...\n      Why: ...\n      Impact: ...\nFeature: Resilience\n\n  In order to provide content to our users\n  As an organisation\n  We want our websites/apps and their dependencies to be available\n\n  Scenario: Fastly Unavailable\n\n    Fastly is our CDN provider, and is effectively the 'front door' to the\n    majority of our publicly consumed content.\n\n    Given Fastly is unavailable\n    When a user requests a public buzzfeed resource (e.g. www.buzzfeed.com)\n    Then we expect the resource to be provided\n\n  Tasks:\n\n    - What: Investigation of 'stale rendering' vs 'multi-region infrastructure'\n      Why: Understand the risk/cost implications of each approach.\n      Impact: We'll be able to proceed with the approach which provides the most value.\n\n    - What: Migration of CDN logic to Perimeter.\n      Why: We want to reduce the amount of unfamilar code.\n      Impact: Will make migrating to an alternative CDN provider easier as there is less logic coupling.\n\nFeature: Restaurant\n\n  Scenario Outline: eating\n\n    Given there are \u003cstart\u003e cucumbers\n    When I eat \u003ceat\u003e cucumbers\n    Then I should have \u003cleft\u003e cucumbers\n\n    Examples:\n      | start | eat | left |\n      |    12 |   5 |    7 |\n      |    20 |   5 |   15 |\n","tags":"#gherkin #cucumber #userstory #story #feature #scenario"},{"id":"2964977","title":"Mega Validation Form","content":"define([\"../Templating/hogan\", \"../XHR/ajax\", \"../Array/map\", \"../DOM/getEl\"], function (hogan, ajax, map, getElement) {\n\t\n\tfunction validate (formname) {\n\t\tvar template,\n\t\t\tdoc = document,\n\t\t\tmodule = getElement(\"js-alreadymember\"),\n\t\t\tinsert_errors = getElement(\"js-formerrors\"),\n\t\t\tpin_error = getElement(\"js-incorrectpin\"),\n\t\t\terrors = [],\n\t\t\tform = document.forms[formname],\n\t\t\tfields = form.elements,\n\t\t\tformats = {\n\t\t\t\tnumber: function (field) {\n\t\t\t\t\tif (/^\\D+/.test(field.value) || !field.value.length) {\n\t\t\t\t\t\terrors.push(field);\n\t\t\t\t\t} else if (field.name === \"pin\") {\n\t\t\t\t\t\t// We call script which tells us whether the data added by the user is correct or not\n\t\t\t\t\t\tajax({\n\t\t\t\t\t\t\turl: \"Assets/PHP/pin.php\",\n\t\t\t\t\t\t\tasync: false, // first time ever I've needed to use a 'synchronous' AJAX call\n\t\t\t\t\t\t\tmethod: \"POST\",\n\t\t\t\t\t\t\tdata: \"pin=\" + field.value + \"\", // we're posting the user's entered pin to the server\n\t\t\t\t\t\t\tonSuccess: function (data) {\n\t\t\t\t\t\t\t\t// 'data' is returned as a String which causes issues with coercion (as a string of any length, even if it contains zero, is still a truthy value)\n\t\t\t\t\t\t\t\t// So we use the + operator to convert the string into a number\n\t\t\t\t\t\t\t\tif (+data) {\n\t\t\t\t\t\t\t\t\tpin_error.className = \"hide\";\n\t\t\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\t\t\terrors.push(field);\n\t\t\t\t\t\t\t\t\tpin_error.className = \"\";\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t});\n\t\t\t\t\t}\n\t\t\t\t},\n\t\t\t\tdate: function (field) {\n\t\t\t\t\t/*\n\t\t\t\t\t\tThe regex allows the following formats:\n\t\t\t\t\t\t\t00/00/0000\n\t\t\t\t\t\t\t00/00/00\n\t\t\t\t\t\t\t0/0/00\n\t\t\t\t\t */\n\t\t\t\t\tif (!/^\\d{1,2}\\/\\d{1,2}\\/\\d{2,4}$/.test(field.value) || !field.value.length) {\n    \t\t\t\t    errors.push(field);\n\t\t\t\t\t}\n\t\t\t\t},\n\t\t\t\temail: function (field) {\n\t\t\t\t\tif (field.value.indexOf(\"@\") === -1 || !field.value.length) {\n\t\t\t\t\t\terrors.push(field);\n\t\t\t\t\t}\n\t\t\t\t},\n\t\t\t\tmobile: function (field) {\n\t\t\t\t\t/*\n\t\t\t\t\t\tThe regex allows the following formats:\n\t\t\t\t\t\t\t+44 07000000000\n\t\t\t\t\t\t\t07000000000\n\t\t\t\t\t\t\t+4407000000000\n\t\t\t\t\t\t\n\t\t\t\t\t\tSo there is an optional +000 country code at the start (wrapped in a non-capturing group)\n\t\t\t\t\t\tWe then allow for an optional space after the optional country code\n\t\t\t\t\t\tFinally we allow for 11 digits (no spaces)\n\t\t\t\t\t */\n\t\t\t\t\tif (!/^(?:\\+\\d{1,3})?\\s?\\d{11}$/.test(field.value) || !field.value.length) {\n\t\t\t\t\t\terrors.push(field);\n\t\t\t\t\t}\n\t\t\t\t},\n\t\t\t\tpassword: function (field) {\n\t\t\t\t\t/*\n\t\t\t\t\t\tThe regex makes sure there is at least 8 alpha-numerical characters\n\t\t\t\t\t\tAnd that at least one of those values is a number\n\t\t\t\t\t\tAnd that at least one of those values is a text character\n\t\t\t\t\t\tWe use a positive lookahead (which checks to see if a sub pattern matches a specific position)\n\t\t\t\t\t\tThe lookahead checks for any character (zero or more times) is followed by a digit (e.g. making sure there is at least one digit)\n\t\t\t\t\t\tThe lookahead then checks for any character (zero or more times) is followed by a text character (e.g. making sure there is at least one text character)\n\t\t\t\t\t\tFinally after the two lookaheads we have the standard regex which makes sure there is at least 8 alpha-numerical characters\n\t\t\t\t\t */\n\t\t\t\t\tif (!/^(?=.*\\d)(?=.*[a-z])\\w{8,}/i.test(field.value)) {\n\t\t\t\t\t\terrors.push(field);\n\t\t\t\t\t}\n\t\t\t\t},\n\t\t\t\tincome: function (field) { \n\t\t\t\t\tif (!/^[\\d,.]+/.test(field.value) || !field.value.length) {\n\t\t\t\t\t\terrors.push(field);\n\t\t\t\t\t}\n\t\t\t\t},\n\t\t\t\taccountnumber: function (field) {\n\t\t\t\t\tif (!/^\\d{8}$/.test(field.value)) {\n\t\t\t\t\t\terrors.push(field);\n\t\t\t\t\t}\n\t\t\t\t},\n\t\t\t\tcardnumber: function (field) {\n\t\t\t\t\tfunction luhn (cardnumber) {\n                        // Build an array with the digits in the card number\n                        var getdigits = /\\d/g;\n                        var digits = [];\n                        \n                        while (match = getdigits.exec(cardnumber)) {\n                            digits.push(parseInt(match[0], 10));\n                        }\n                        \n                        // Run the Luhn algorithm on the array\n                        var sum = 0;\n                        var alt = false;\n                        \n                        for (var i = digits.length - 1; i \u003e= 0; i--) {\n                            // On every other number in the card sequence...\n                            if (alt) {\n                                digits[i] *= 2; // multiple the number by itself\n                                \n                                // If the number is now over 9 then we'll minus 9 from the number\n                                if (digits[i] \u003e 9) {\n                                    digits[i] -= 9;\n                                }\n                            }\n                            \n                            // Add this digit onto the current total sum\n                            sum += digits[i];\n                            \n                            // Alternate\n                            alt = !alt;\n                        }\n                        \n                        // The individual card numbers (after the above algorithm is applied and then when added together) \n                        // should be possible to divide by 10 with zero left over\n                        if (sum % 10 == 0) {\n                            return true;\n                        } else {\n                            return false;\n                        }\n                    }\n\t\t\t\t\t\n\t\t\t\t\t/*\n\t\t\t\t\t\tThe following regex was actually borrowed from The Regular Expression Cookbook (co-written by the regex legend @stevenlevithan)\n\t\t\t\t\t */\n\t\t\t\t\tif (!/^(?:4[0-9]{12}(?:[0-9]{3})?|5[1-5][0-9]{14}|6(?:011|5[0-9][0-9])[0-9]{12}|3[47][0-9]{13}|3(?:0[0-5]|[68][0-9])[0-9]{11}|(?:2131|1800|35\\d{3})\\d{11})$/g.test(field.value)) {\n\t\t\t\t\t\terrors.push(field);\n\t\t\t\t\t} else {\n    \t\t\t\t\t// If the card number appears to be valid we then run the Luhn test\n    \t\t\t\t\tif (!luhn(field.value)) {\n        \t\t\t\t\terrors.push(field);\n    \t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t},\n\t\t\t\tshortdate: function (field) {\n\t\t\t\t\t/*\n\t\t\t\t\t\tThe regex allows the following formats:\n\t\t\t\t\t\t\t00/0000\n\t\t\t\t\t\t\t0/0000\n\t\t\t\t\t\t\t00/00\n\t\t\t\t\t\t\t0/00\n\t\t\t\t\t */\n\t\t\t\t\tif (!/^\\d{1,2}\\/\\d{2,4}$/.test(field.value) || !field.value.length) {\n    \t\t\t\t    errors.push(field);\n\t\t\t\t\t}\n\t\t\t\t},\n\t\t\t\tyear: function (field) {\n\t\t\t\t\t// The regex forces the year to be a 4 digit number\n\t\t\t\t\tif (!/^\\d{4}$/.test(field.value) || !field.value.length) {\n    \t\t\t\t    errors.push(field);\n\t\t\t\t\t}\n\t\t\t\t},\n\t\t\t\tcheckbox: function (field) {\n\t\t\t\t\tif (!field.checked) {\n\t\t\t\t\t\terrors.push(field);\n\t\t\t\t\t}\n\t\t\t\t},\n\t\t\t\tconfirm: function (field, index) {\n\t\t\t\t\tif (field.value.length \u0026\u0026 field.value !== fields[index].value) {\n\t\t\t\t\t\terrors.push(field);\n\t\t\t\t\t}\n\t\t\t\t},\n\t\t\t\tis_expiry_invalid: function (field) {\n\t\t\t\t\tvar split = field.value.split(\"/\"),\n\t\t\t\t\t\tmonth = split[0],\n\t\t\t\t\t\tyear = split[1],\n\t\t\t\t\t\tpaydate = new Date(window.mp_paymentdate[1], window.mp_paymentdate[0]-1, window.mp_paymentdate[2]),\n\t\t\t\t\t\texpirydate = new Date(\"20\"+year,month-1, window.mp_paymentdate[2]); // month is zero indexed\n\n\t\t\t\t\t// We construct a date object based on the user's final pay date and their card's expiry date\n\t\t\t\t\t// We then convert both dates into a number so we can compare the values\n\t\t\t\t\tif (+expirydate \u003c= +paydate) {\n\t\t\t\t\t\terrors.push(field);\t\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t};\n\t\t\t\n\t\tfunction display_errors(){\n\t\t\t// First we'll remove any messages that are already on the page\n\t\t\tvar original_list = getElement(\"js-errorlist\");\n\t\t\tif (original_list) {\n\t\t\t\toriginal_list.parentNode.removeChild(original_list);\n\t\t\t}\n\t\t\t\n\t\t\tvar content,\n\t\t\t\t// We need to make sure that all mandatory fields have a custom attribute \"data-errormsg\"\n\t\t\t\t// Which will display the relevant message necessary if there is a problem\n\t\t\t\terr = map(errors.reverse(), function (item, index, array) {\n\t\t\t\t\treturn {\n\t\t\t\t\t\t// I don't like the idea of having to touch the DOM every time I need to get an error message but\n\t\t\t\t\t\t// this seemed like the best way to temporarily access that data without using expando properties\n\t\t\t\t\t\t// which can cause memory leaks in Internet Explorer\n\t\t\t\t\t\terror: item.getAttribute(\"data-errormsg\")\n\t\t\t\t\t}\n\t\t\t\t});\n\t\t\t\t\n\t\t\tfunction generate_html(){\n\t\t\t\tvar frag = doc.createDocumentFragment(),\n\t\t\t\t\tdiv = doc.createElement(\"div\");\n\t\t\t\t\tdiv.id = \"js-errorlist\";\n\t\t\t\t\n\t\t\t\t// Insert 'confirmation' header into page above the Flash file\n\t\t\t\tdiv.innerHTML = content;\n\t\t\t\tfrag.appendChild(div);\n\t\t\t\tinsert_errors.parentNode.insertBefore(frag, insert_errors);\n\t\t\t\twindow.location.hash = \"js-errorlist\";\n\t\t\t}\n\t\t\t\n\t\t\t// The following code prevents calling the server every time the form is submitted.\n\t\t\t// Instead we retrieve the template and compile it once\n\t\t\tif (template) {\n\t\t\t\tcontent = template.render({ \n\t\t\t\t\terrors: err\n\t\t\t\t});\n\t\t\t\tgenerate_html();\n\t\t\t} else {\n\t\t\t\tajax({\n\t\t\t\t\turl: \"Assets/Templates/FormErrors.tpl\",\n\t\t\t\t\tdata: \"html\",\n\t\t\t\t\tonSuccess: function (data) {\n\t\t\t\t\t\ttemplate = hogan.compile(data);\n\t\t\t\t\t\t\n\t\t\t\t\t\tcontent = template.render({ \n\t\t\t\t\t\t\terrors: err \n\t\t\t\t\t\t});\n\t\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\tgenerate_html();\n\t\t\t\t\t}\n\t\t\t\t});\n\t\t\t}\n\t\t}\n\t\t\n\t\tform.onsubmit = function(){\n\t\t\tvar len = fields.length,\n\t\t\t\tfield,\n\t\t\t\tclassname,\n\t\t\t\ti;\n\t\t\t\n\t\t\terrors = [];\n\t\t\t\n\t\t\t// If the \"Are you already a member\" module still visible then hide it.\n\t\t\t// No point in still showing it when we know they are trying to register\n\t\t\t// Also it makes it less confusing for the user if we need to display an error message box,\n\t\t\t// otherwise there would be two red boxes next to each other and the errors could be lost\n\t\t\t// This element only appears on the Stage 1 page so we need to check that it exists and if it does then we check it's class attribute value\n\t\t\tif (module \u0026\u0026 module.className.indexOf(\" hide\") === -1) {\n\t\t\t\tmodule.className += \" hide\";\n\t\t\t}\n\t\t\t\n\t\t\twhile(len--) {\n\t\t\t\tfield = fields[len];\n\t\t\t\tclassname = field.className;\n\t\t\t\ti = classname.indexOf(\"mandatory\");\n\t\t\t\t\n\t\t\t\tif (i \u003e= 0) {\n\t\t\t\t\t// For the validation script to work we need to ensure a specific format is used in the HTML.\n\t\t\t\t\t// The main principle is to make sure the last class on an input is either 'mandatory' or 'mandatory-xxxx' \n\t\t\t\t\t// e.g. 'mandatory-number', 'mandatory-dob', 'mandatory-email', 'mandatory-mobile', 'mandatory-password'\n\t\t\t\t\t\n\t\t\t\t\tif (classname.split(\"mandatory-\")[1]) {\n\t\t\t\t\t\t// If there is a second item then we know there is a specific type to validate against\n\t\t\t\t\t\tformats[classname.split(\"mandatory-\")[1]](field);\n\t\t\t\t\t} else {\n\t\t\t\t\t\t// Otherwise we validate by standard method\n\t\t\t\t\t\t// e.g. if the length is zero (meaning the field is empty) then zero will coerce to false\n\t\t\t\t\t\t// \t\tso we return the opposite of that using the ! operator (so the first part of the following condition is met)\n\t\t\t\t\t\t// \t\tand if the length is greater than zero then the regex checks to see if the content isn't just empty spaces\n\t\t\t\t\t\tif (/^\\s+$/.test(field.value) || !field.value.length) {\n\t\t\t\t\t\t\terrors.push(field);\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\t\n\t\t\t\tif (formname === \"createaccount-stage1\" \u0026\u0026 field.name === \"confirmemail\") {\n\t\t\t\t\t// If the email and confirm email values aren't the same then store as error\n\t\t\t\t\tformats.confirm(field, len-1);\n\t\t\t\t}\n\t\t\t\t\n\t\t\t\tif (formname === \"createaccount-stage2\" \u0026\u0026 field.name === \"password2\") {\n\t\t\t\t\t// If the password and confirm password values aren't the same then store as error\n\t\t\t\t\tformats.confirm(field, len-1);\n\t\t\t\t}\n\t\t\t\t\n\t\t\t\tif (formname === \"createaccount-stage2\" \u0026\u0026 field.name === \"question2\") {\n\t\t\t\t\t// If the 2nd question selected is the same as the 1st question field then store as error (we don't want user selecting same question twice)\n\t\t\t\t\tif (field.value.length \u0026\u0026 field.value === fields[len-2].value) {\n\t\t\t\t\t\terrors.push(field);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\t\n\t\t\t\tif (formname === \"createaccount-stage4\" \u0026\u0026 field.name === \"expirydate\") {\n\t\t\t\t\tif (field.value.length) {\n\t\t\t\t\t\tformats.is_expiry_invalid(field)\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\t\n\t\t\t// Make sure there are no errors stored\n\t\t\t// If errors.length is zero then that means there are no errors\n\t\t\t// Zero will coerce to false and so we return the opposite of false using the ! operator\n\t\t\tif (!errors.length) {\n\t\t\t\treturn true;\n\t\t\t} \n\t\t\t\n\t\t\t// We return false to prevent the form from submitting\n\t\t\t// And we display the errors we found\n\t\t\telse {\n\t\t\t\tdisplay_errors();\n\t\t\t\treturn false;\n\t\t\t}\n\t\t}\n\t}\n\t\n\treturn validate;\n\t\n});\n","tags":""},{"id":"7352055","title":"JavaScript: function to determine object's type","content":"var type = function (o) {\n\n    // handle null in old IE\n    if (o === null) {\n        return 'null';\n    }\n\n    // handle DOM elements\n    if (o \u0026\u0026 (o.nodeType === 1 || o.nodeType === 9)) {\n        return 'element';\n    }\n\n    var s = Object.prototype.toString.call(o);\n    var type = s.match(/\\[object (.*?)\\]/)[1].toLowerCase();\n\n    // handle NaN and Infinity\n    if (type === 'number') {\n        if (isNaN(o)) {\n            return 'nan';\n        }\n        if (!isFinite(o)) {\n            return 'infinity';\n        }\n    }\n\n    return type;\n}\n\n['Null',\n 'Undefined',\n 'Object',\n 'Array',\n 'String',\n 'Number',\n 'Boolean',\n 'Function',\n 'RegExp',\n 'Element',\n 'NaN',\n 'Infinite'\n].forEach(function (t) {\n    type['is' + t] = function (o) {\n        return type(o) === t.toLowerCase();\n    };\n});\n\n// examples:\ntype.isObject({}); // true\ntype.isNumber(NaN); // false\ntype.isElement(document.createElement('div')); // true\ntype.isRegExp(/abc/); // true\n","tags":""},{"id":"7378674","title":"JavaScript grid overlay","content":"(function(){\n    var boundaryInserted, grid12, grid24, boundary, firstTimeVisible, magicNumber = 126;\n\n    function getDocHeight(){\n        var body = document.body,\n            elem = document.documentElement;\n\n        return Math.max(\n            Math.max(body.scrollHeight, elem.scrollHeight),\n            Math.max(body.offsetHeight, elem.offsetHeight),\n            Math.max(body.clientHeight, elem.clientHeight)\n        );\n    }\n\n    function insertBoundary(){\n        if (!boundaryInserted) {\n            boundaryInserted = true;\n\n            var styles = '\u003cstyle\u003e\\\n                        .boundary { background-color: #CCC; color: black; margin: auto; max-width: 1028px; padding-bottom: .5em; padding-top: .5em; position: relative; text-align: center; z-index: 9999; }\\\n                        .boundary__border { background-color: #CCC; position: absolute; top: 0; width: 1px; }\\\n                        .boundary__border--left { left: 0; }\\\n                        .boundary__border--right { right: 0; }\\\n                        \u003c/style\u003e';\n\n            var overlay = document.createElement('div');\n                overlay.id = 'js-overlay';\n\n            var overlay24 = document.createElement('div');\n                overlay24.id = 'js-overlay-24';\n\n            var boundary = document.createElement('div');\n                boundary.className = 'boundary';\n                boundary.innerHTML = 'This element indicates the outer margins (which *used* to be incorporated into the Grid, but not any more)\u003cbr\u003e\u003cbr\u003e\u003cb\u003e\\\n                                        Press:\u003cbr\u003e\\\n                                        \"a\" to toggle everything\u003cbr\u003e\\\n                                        \"b\" to toggle boundary box\u003cbr\u003e\\\n                                        \"g\" key to toggle 12 column grid visibility\u003cbr\u003e\\\n                                        \"f\" key to toggle 24 column grid visibility\u003c/b\u003e';\n\n            var wrapper = document.querySelector('.wrapper');\n                wrapper.parentNode.insertBefore(boundary, wrapper);\n\n            var borderLeft = document.createElement('div');\n                borderLeft.className = 'boundary__border boundary__border--left';\n\n            var borderRight = document.createElement('div');\n                borderRight.className = 'boundary__border boundary__border--right';\n\n            boundary.appendChild(borderLeft);\n            boundary.appendChild(borderRight);\n            document.body.appendChild(overlay);\n            document.body.appendChild(overlay24);\n\n            $(boundary).before($(styles));\n        }\n    }\n\n    function setUpKeyBindings(){\n        var visible = false;\n\n        $(document).on('keyup', function (e) {\n            // Toggle 12 column grid (g)\n            if (e.keyCode === 71) {\n                grid12.toggle();\n            }\n\n            // Toggle 24 column grid (f)\n            if (e.keyCode === 70) {\n                grid24.toggle();\n            }\n\n            // Toggle outer boundary (b)\n            if (e.keyCode === 66) {\n                boundary.toggle();\n            }\n\n            // Toggle everything (a)\n            if (e.keyCode === 65) {\n                if (visible) {\n                    boundary.hide();\n                    grid12.hide();\n                    grid24.hide();\n                    visible = false;\n                } else {\n                    // If it's the first time we're displaying the boundary and grids then ensure their height is set\n                    if (!firstTimeVisible) {\n                        $('.boundary__border, #gridpak, #gridpak24').each($.proxy(function (index, item) {\n                            item.style.height = getDocHeight() + magicNumber + 'px';\n                        }, this));\n\n                        firstTimeVisible = true;\n                    }\n\n                    boundary.show();\n                    grid12.show();\n                    grid24.show();\n                    visible = true;\n                }\n            }\n        });\n    }\n\n    function Gridpak (numberOfColumns, userProvidedGrids) {\n        this.$container = {};\n        this.append = (numberOfColumns === 24) ? '#js-overlay-24' : '#js-overlay'; // DOM element to append the Gridpak too\n        this.columnNumber = numberOfColumns;\n        this.injectCSSName = (numberOfColumns === 24) ? 'gridpak24' : 'gridpak';\n        this.hideOnSmallerScreens = (numberOfColumns === 24) ? true : false;\n        this.css = '';\n        this.userProvidedGrids = userProvidedGrids;\n        this.gridpakWrapper = '';\n        this.numberOfColumns = numberOfColumns;\n        this.init();\n    }\n\n    Gridpak.prototype.init = function(){\n        insertBoundary();\n\n        var grids = this.userProvidedGrids,\n            numGrids = grids.length - 1,\n            i = 0;\n\n        this.css += '\u003cstyle type=\"text/css\"\u003e ' +\n            '#' + this.injectCSSName + ' { ' +\n                'width:100%; ' +\n                'height:100%; ' +\n                'display:block; ' +\n                'position:absolute; ' +\n                'top:0; ' +\n                'left:0; ' +\n                'z-index:9998; ' +\n            '} ' +\n            '#' + this.injectCSSName + ' .' + this.injectCSSName + '_wrapper { ' +\n                'max-width:996px; ' +\n                'height:100%; ' +\n                'margin:auto; ' +\n                'padding-left:16px; ' +\n                'padding-right:16px; ' +\n            '} ' +\n            '#' + this.injectCSSName + ' .' + this.injectCSSName + '_wrapper.' + this.injectCSSName + '_wrapper--smallerOuterMargins { ' +\n                'padding-left:8px; ' +\n                'padding-right:8px; ' +\n            '} ' +\n            '#' + this.injectCSSName + ' .' + this.injectCSSName + '_grid { ' +\n                'height:100%; ' +\n                'display:none; ' +\n            '} ' +\n            '#' + this.injectCSSName + ' .' + this.injectCSSName + '_col { ' +\n                'border-left:0 solid rgba(255,255,255,0); ' +\n                'border-right:0 solid rgba(255,255,255,0); ' +\n                '-moz-background-clip: padding; -webkit-background-clip: padding-box; background-clip: padding-box;' +\n                'padding:0; ' +\n                '-webkit-box-sizing:border-box; -moz-box-sizing:border-box; box-sizing:border-box; ' +\n                'display:block; ' +\n                'float:left; ' +\n                'height:100%; ' +\n                'background-color:rgba(153,0,0,0.2); ' +\n\n            '} ' +\n            '#' + this.injectCSSName + ' .' + this.injectCSSName + '_visible { ' +\n                'width:100%; ' +\n                'height:100%; ' +\n                'display:block; ' +\n                'background:rgba(255,255,255,0.3); ' +\n            '} ';\n\n        this.markup = '\u003cdiv id=\"' + this.injectCSSName + '\"\u003e\u003cdiv class=\"' + this.injectCSSName + '_wrapper\"\u003e';\n\n        // Put the grids on the screen\n        for (i; i\u003c=numGrids; i++) {\n            this.drawGrid(grids[i], i);\n        }\n\n        this.markup += '\u003c/div\u003e\u003c/div\u003e';\n\n        this.css += '\u003c/style\u003e';\n\n        if (this.columnNumber === 24) {\n            grid24 = this.$container = $(this.markup);\n        } else {\n            grid12 = this.$container = $(this.markup);\n        }\n\n        this.topLevelContainerElement = $(this.append);\n\n        this.topLevelContainerElement.prepend(this.css);\n\n        this.topLevelContainerElement.append(this.$container);\n\n        boundary = this.boundary = $('.boundary');\n\n        this.gridpakWrapper = $('.' + this.injectCSSName + '_wrapper');\n\n        this.checkOuterMargins();\n\n        // Hide the boundary and the grids on load\n        this.boundary.hide();\n        this.$container.hide();\n\n        $(window).on('resize', $.proxy(this.checkOuterMargins, this));\n    };\n\n    Gridpak.prototype.checkOuterMargins = function(){\n        if (this.columnNumber === 24) {\n            this.hideOnSmallerScreens = true;\n        }\n\n        if (document.documentElement.clientWidth \u003c 600) {\n            if (this.hideOnSmallerScreens) {\n                this.topLevelContainerElement.hide();\n            }\n        } else {\n            if (this.hideOnSmallerScreens) {\n                this.topLevelContainerElement.show();\n            }\n        }\n\n        if (document.documentElement.clientWidth \u003c 400) {\n            this.gridpakWrapper.addClass(this.injectCSSName + '_wrapper--smallerOuterMargins');\n        } else {\n            this.gridpakWrapper.removeClass(this.injectCSSName + '_wrapper--smallerOuterMargins');\n        }\n\n    };\n\n    Gridpak.prototype.drawGrid = function (grid, num) {\n        var new_markup = '',\n            i = 1,\n            gutter_pc = (grid.gutter_type === '%') ? grid.gutter_width : 0,\n            gutter_px = (grid.gutter_type === 'px') ? grid.gutter_width : 0,\n            width = 0;\n\n        if (grid.gutter_type === 'px') {\n            width = 100 / grid.col_num;\n        } else {\n            width = (100 - (gutter_pc * (grid.col_num - 1))) / grid.col_num;\n        }\n\n        new_markup = '\u003cdiv class=\"' + this.injectCSSName + '_grid ' + this.injectCSSName + '_grid_' + num + '\"\u003e';\n\n        this.css += '#' + this.injectCSSName + ' .' + this.injectCSSName + '_grid_' + num + ' { ' +\n            'margin-left:-' + gutter_px + 'px; ' +\n        '} ' +\n        '#' + this.injectCSSName + ' .' + this.injectCSSName + '_grid_' + num + ' .' + this.injectCSSName + '_col { ' +\n            'width:' + width + '%; ' +\n            'margin-left:' + gutter_pc + '%; ' +\n            'border-left-width:' + gutter_px + 'px; ' +\n            'padding-left:' + grid.padding_width + grid.padding_type +'; ' +\n            'padding-right:' + grid.padding_width + grid.padding_type + '; ' +\n        '} ';\n        if (grid.gutter_type === '%') {\n            this.css += '#' + this.injectCSSName + ' .' + this.injectCSSName + '_grid_' + num + ' .' + this.injectCSSName + '_col:first-child { ' +\n                'margin-left:0;' +\n            '} ';\n        }\n\n        this.css += '@media screen and (min-width: ' + grid.min_width + 'px) ';\n        if (grid.upper !== false) {this.css += 'and (max-width: ' + grid.upper + 'px) ';}\n        this.css += ' { ' +\n            '#' + this.injectCSSName + ' .' + this.injectCSSName + '_grid_' + num + ' { ' +\n                'display: block; ' +\n            '} ' +\n        '} ';\n\n        for(i; i\u003c=grid.col_num; i++) {\n\n            new_markup += '\u003cdiv class=\"' + this.injectCSSName + '_col\"\u003e\u003cdiv class=\"' + this.injectCSSName + '_visible\"\u003e\u003c/div\u003e\u003c/div\u003e';\n        }\n\n        new_markup += '\u003c/div\u003e';\n\n        this.markup += new_markup;\n    };\n\n    setUpKeyBindings();\n\n    // 12 Column Grid\n    var grid = new Gridpak(12, [\n        {\n            min_width: 0,\n            col_num: 12,\n            gutter_type: 'px',\n            gutter_width: 8,\n            padding_type: 'px',\n            padding_width: 0,\n            upper: 419\n        },\n        {\n            min_width: 400,\n            col_num: 12,\n            gutter_type: 'px',\n            gutter_width: 16,\n            padding_type: 'px',\n            padding_width: 0,\n            upper: 599\n        },\n        {\n            min_width: 600,\n            col_num: 12,\n            gutter_type: 'px',\n            gutter_width: 16,\n            padding_type: 'px',\n            padding_width: 0,\n            upper: 1000\n        },\n        {\n            min_width: 1001,\n            col_num: 12,\n            gutter_type: 'px',\n            gutter_width: 16,\n            padding_type: 'px',\n            padding_width: 0,\n            upper: false\n        }\n    ]);\n\n    // 24 Column Grid\n    var grid_24 = new Gridpak(24, [\n        {\n            min_width: 600,\n            col_num: 24,\n            gutter_type: 'px',\n            gutter_width: 16,\n            padding_type: 'px',\n            padding_width: 0,\n            upper: 1000\n        },\n        {\n            min_width: 1001,\n            col_num: 24,\n            gutter_type: 'px',\n            gutter_width: 16,\n            padding_type: 'px',\n            padding_width: 0,\n            upper: false\n        }\n    ]);\n\n}());\n","tags":""},{"id":"7463783","title":"How to extract JSHint details into its own config file","content":"jshint: {\n    files: ['**/*.js'],\n    options: {\n        jshintrc: '.jshintrc'\n    }\n}\n{\n    \"curly\":      true,\n    \"eqeqeq\":     true,\n    \"immed\":      true,\n    \"latedef\":    true,\n    \"noarg\":      true,\n    \"sub\":        true,\n    \"undef\":      true,\n    \"boss\":       true,\n    \"eqnull\":     true,\n    \"browser\":    true,\n    \"multistr\":   true,\n    \"newcap\":     false,\n    \"globals\": {\n\n\"\": \"AMD\",\n\n            \"module\":       true,\n            \"require\":      true,\n            \"requirejs\":    true,\n            \"define\":       true,\n\n\"\": \"Environments\",\n\n            \"console\":      true,\n\n\"\": \"General Purpose Libraries\",\n\n            \"$\":            true,\n            \"jQuery\":       true,\n            \"EventEmitter\": true,\n\n\"\": \"Testing\",\n\n            \"sinon\":        true,\n            \"describe\":     true,\n            \"it\":           true,\n            \"expect\":       true,\n            \"beforeEach\":   true,\n            \"waitsFor\":     true,\n            \"runs\":         true,\n            \"afterEach\":    true\n\n    }\n}\n","tags":""},{"id":"3004787","title":"Chunky script","content":"define(['../Utils/Events/events', '../Utils/XHR/ajax', '../Utils/Templating/hogan', '../Utils/Patterns/when', '../Utils/DOM/getEl', '../Utils/CSS/getAppliedStyle', '../Utils/CSS/addClass', '../Utils/CSS/removeClass', '../Utils/CSS/hasClass', '../Utils/DOM/getOffset', '../Utils/Datepicker/kalendae'], function (event, ajax, hogan, when, getElement, getAppliedStyle, addClass, removeClass, hasClass, getOffset, Kalendae) {\n    \n    /*\n     * Code Structure:\n     * - Variables\n     * - Functions\n     *   - check_amount\n     *   - check_popup_close\n     *   - load_calendar\n     *   - get_costs\n     *   - generate_html\n     *   - calculate\n     *   - process_application\n     *   - update_amount\n     *   - show_popup\n     * - Initialisation\n     */\n     \n    var amount = getElement('js-amount');\n    var amount_updated = getElement('js-amount-update');\n    var max = +amount.getAttribute('data-max');\n    var specify_amount = getElement('js-specifyamount');\n    var paydate = getElement('js-choosepaydate');\n    var popup = getElement('js-calendarpopup');\n    var button_continue = getElement('js-appcontinue');\n    var details_container = getElement('js-details');\n    var details_summary = getElement('js-details-summary');\n    var borrowing = getElement('js-initialamount');\n    var limit_reached = false;\n    var calendar_container = document.createElement('div');\n    var days_to_pay = 1;\n    var calendar, template, template_content;\n    \n    function check_amount (isPopup) {\n        var input = (isPopup) ? amount_updated : amount;\n        \n        // because the content of the summary box is pulled in from a template file we have\n        // to store a reference to the element in the current execution context\n        // e.g. we can't store in a variable prior to this function executing because\n        // the template is re-loaded every time a new calculation is made\n        var apply_now = getElement('js-applynow');\n        \n        /*\n         * if statement checks following aspects:\n         *      make sure value entered isn't the same as the placeholder value\n         *      make sure user has entered a number\n         *      make sure a value of some form has been entered\n         */\n        if (input.value === input.getAttribute('placeholder') || \n            !/^\\d+$/.test(input.value) || \n            input.value.length === 0) { \n            \n            input.value = 0;\n            input.focus();\n            \n            // only handle messages if the popup isn't showing\n            if (!isPopup) {\n                if (limit_reached) {\n                    specify_amount.innerHTML = specify_amount.getAttribute('data-noamount');\n                    limit_reached = false;\n                }\n            \n                removeClass(specify_amount, 'hide');\n            }\n            \n            // if we can access the #js-applynow element then hide it now there is an error\n            if (apply_now) {\n                addClass(apply_now, 'hide');\n            }\n        } \n        \n        /*\n         * because DOM values are of type String we use unary operator to convert to integer\n         * we then check to see if the user has requested a value lower than 1\n         * if they have then we reset it to to zero and update the message to let them know\n         */\n        else if (+input.value \u003c 1) {\n            input.value = 0;\n            \n            // only handle messages if the popup isn't showing\n            if (!isPopup) {\n                if (limit_reached) {\n                    specify_amount.innerHTML = specify_amount.getAttribute('data-noamount');\n                    limit_reached = false;\n                }\n                \n                removeClass(specify_amount, 'hide');\n            }\n        } \n        \n        /*\n         * because DOM values are of type String we use unary operator to convert to integer\n         * we then check to see if the user has requested a value greater than the max\n         * if they have then we reset it to the maximum allowed and update the message to let them know\n         */\n        else if (+input.value \u003e max) {\n            input.value = max;\n            \n            // only handle messages if the popup isn't showing\n            if (!isPopup) {\n                specify_amount.innerHTML = 'Requested amount limit reached';\n                limit_reached = true;\n                removeClass(specify_amount, 'hide');\n            }\n            \n            // in the popup we aren't displaying a message to the user when they go over the max allowed value\n            // so in this instance we'll return true so our calling environment (#js-amount-update 'keyup' listener) can start calculating costs\n            else {\n                return true;\n            }\n        } \n        \n        /*\n         * if all other conditions aren't met then we're OK to display the calendar to the user\n         * and to hide any error message previously shown to the user\n         */\n        else {\n            addClass(specify_amount, 'hide');\n            return true; // amount has validated successfully\n        }\n        \n        return false;\n    }\n    \n    function check_popup_close (e) {\n        /*\n         * we want to close the popup when the user clicks on the area where the close button appears.\n         * the close button is added via CSS' :after pseudo-element and so isn't actually accessible to JavaScript\n         * so we need to detect the area of the popup where it appears.\n         * to do this we need to first locate the popup within the page and then calculate where the close button sits relative to the popup\n         * \n         * the CSS looks like this:\n         *      height: 30px;\n         *      width: 30px;\n         *      right: -13px;\n         *      top: -10px;\n         *\n         * this means the close button has 17px over the popup on the x axis and 20px over the popup on the y axis\n         *\n         * we first have to get references to the pseudo-element's styles which is easy enough for browsers that support getComputedStyle \n         * but for Internet Explorer 8 this becomes a bit of a chore as we have to loop through all rules of specific stylesheet.\n         * but we make sure we cache this processing work because there is no point in doing it every time the 'checkPopupClose' function is called.\n         */\n        \n        var cache_styles = (function(){\n            var cache, len, found;\n            \n            return function(){\n                if (!cache) {\n                    cache = {};\n                    // IE9+ and all versions of Firefox/Chrome/Safari\n                    if (window.getComputedStyle) {\n                        cache.style = window.getComputedStyle(popup, ':after');\n                        cache.right = parseInt(cache.style.right);   // -13\n                        cache.top = parseInt(cache.style.top);       // -10\n                        cache.height = parseInt(cache.style.height); // 30\n                        cache.width = parseInt(cache.style.width);   // 30\n                    }\n                    // IE8 - needs to loop through stylesheet looking for the relevant Rule to pick up the :after styles from\n                    else {\n                        len = document.styleSheets[1].rules.length;\n                        while (len--) {\n                            if (document.styleSheets[1].rules[len].selectorText === '.application-popup:after') {\n                                found = document.styleSheets[1].rules[len];\n                                break;\n                            }\n                        }\n                        cache.styles = found.style.cssText.toLowerCase();\n                        cache.right = parseInt(cache.styles.match(/right: ?([^;]+)/)[1]);     // -13\n                        cache.top = parseInt(cache.styles.match(/top: ?([^;]+)/)[1]);         // -10\n                        cache.height = parseInt(cache.styles.match(/height: ?([^;]+)/)[1]);   // 30\n                        cache.width = parseInt(cache.styles.match(/width: ?([^;]+)/)[1]);     // 30\n                    }\n                    \n                    // currently the values are negative integers so we need to check for that and return positive integer if need be\n                    cache.right = (cache.right \u003c 0) ? Math.abs(cache.right) : cache.right;  // 13\n                    cache.top = (cache.top \u003c 0) ? Math.abs(cache.top) : cache.top;          // 10\n                }\n                \n                return cache;\n            };\n        }());\n        \n        var pseudo = cache_styles();\n        \n        /*\n         * pageX/Y is position relative to Window\n         * clientX/Y is for Internet Explorer which doesn't recognise pageX/Y\n         *\n         * BUT although clientX/Y is similar it has one small caveat!\n         * the value changes depending on whether the user has scrolled the window\n         * which means we need to add on top of clientY any scroll amount (if any)\n         */\n        var x = e.pageX || e.originalEvent.clientX;\n        var y = e.pageY || (document.documentElement.scrollTop + e.originalEvent.clientY);\n        \n        var popup_width = popup.clientWidth;\n        var popup_height = popup.clientHeight;\n        var popup_offset = getOffset(popup);\n        var popup_x = popup_offset.left;\n        var popup_y = popup_offset.top;\n        var popup_xrange = (popup_x + popup_width) + (pseudo.width - pseudo.right); // 30 - 13 = 17\n        var popup_yrange = popup_y - pseudo.top;\n        var popup_xclose = (popup_x + popup_width) - pseudo.right;\n        var popup_yclose = popup_y + (pseudo.height - pseudo.top); // 30 - 10 = 20\n        var within_xrange = x \u003c= popup_xrange \u0026\u0026 x \u003e= popup_xclose;\n        var within_yrange = y \u003c= popup_yclose \u0026\u0026 y \u003e= popup_yrange;\n        \n        if (within_xrange \u0026\u0026 within_yrange) {\n            addClass(popup, 'hide');\n        }\n    }\n    \n    function load_calendar(){\n        // the following variables are used for calculating the difference between \n        // today's date and the selected date to pay back the loan\n        var curent_date = new Date();\n        var current_day = curent_date.getDate();\n        var current_month = curent_date.getMonth();\n        var current_year = curent_date.getFullYear();\n        var today;\n        \n        // we correct current_month to include a zero prefix if the number is less than 10\n        current_month = (current_month \u003c 10) ? ('0' + current_month) : current_month;\n        \n        // construct a date for today which is used for calculating diff\n        today = new Date(current_year, current_month, current_day);\n        \n        calendar = new Kalendae({\n            // element to attach the calendar to\n            attachTo: calendar_container,\n            \n            // blackout days after 45 days from current date\n            blackout: function (date) {\n                return Kalendae.moment().yearDay() + 45 \u003c date.yearDay(); // yearDay() is an extension Kalendae adds to moment.js to calculate the total number of days since epoch.\n            },\n            \n            // how many characters from the week day name to display (e.g. we've gone with 3 = Mon, Tue, Wed, Thu, Fri, Sat, Sun)\n            columnHeaderLength: 3,\n            \n            // restricts date selectability to past or future ('future' blacks out all days previous to current date)\n            direction: 'future',\n            \n            // only allows selection of one day\n            mode: 'single',\n            \n            // determines the number of months to display\n            months: 2,\n            \n            // determines when the week should start (Sunday = 0 [default] or Monday = 1 etc)\n            weekStart: 1,\n            \n            // causes the \u003cinput\u003e to update to the selected date\n            subscribe: {\n                'change': function(){\n                    var selected_date = this.getSelected();\n                    var temp_integer_month;\n                    var one_day;\n                    var payback_date;\n                    \n                    days_to_pay = selected_date.split('-');\n                    \n                    // the date is returned as non-zero index format, so put it back to be zero-indexed\n                    temp_integer_month = parseInt(days_to_pay[1], 10);\n                    days_to_pay[1] = '0' + --temp_integer_month;\n                    \n                    one_day = 24*60*60*1000; // hours * minutes * seconds * milliseconds\n                    payback_date = new Date(days_to_pay[0], days_to_pay[1], days_to_pay[2]);\n                    days_to_pay = Math.abs((today.getTime() - payback_date.getTime()) / (one_day));\n                    \n                    // update the \u003cinput\u003e #js-choosepaydate (currently sitting behind the popup) to display the date selected by the user\n                    paydate.value = selected_date;\n                    \n                    // call function which will pull in the relevant template and populate with relevant costs\n                    calculate();\n                }\n            }\n\t\t});\n    }\n    \n    function get_costs (amount) {\n\t\tvar dfd = when.defer();\n\t\t\n\t\tajax({\n\t\t\turl: 'Assets/PHP/calculator.php',\n\t\t\tmethod: 'POST',\n\t\t\tdata: 'amount=' + amount + '\u0026days=' + days_to_pay,\n\t\t\tonSuccess: function (data) {\n\t\t\t\tdfd.resolve(data);\n\t\t\t}\n\t\t});\n\t\t\n\t\treturn dfd.promise;\n\t}\n\t\n\tfunction generate_html(){\n    \tdetails_container.innerHTML = template_content;\n    \tdetails_summary.innerHTML = template_content;\n    \t\n    \t// this is the 'apply now' button outside of the popup\n    \tdisplay_applynow();\n\t}\n    \n    function calculate(){\n        /*\n         * wait for async functions to finish before inserting HTML\n         */\n        function process(){\n            when(get_costs(amount_updated.value), function (data) {\n\t\t\t\ttemplate_content = template.render(JSON.parse(data));\n\t\t\t\tgenerate_html();\n\t\t\t\t\n\t\t\t\t// once the HTML is generated then we're safe to set-up an event listener for the 'continue' button (within the popup)\n\t\t\t\tevent.add(button_continue, 'click', process_application);\n\t\t\t});\n        }\n        \n        // the following code prevents calling the server to load/compile the same template code every time the button is pressed.\n\t\t// instead we retrieve the template and compile it once\n\t\tif (template) {\n\t\t\tprocess();\n\t\t} else {\n\t\t\tajax({\n\t\t\t\turl: 'Assets/Templates/Application-Calculator.tpl',\n\t\t\t\tdata: 'html',\n\t\t\t\tonSuccess: function (tmp) {\n\t\t\t\t\ttemplate = hogan.compile(tmp);\n\t\t\t\t\tprocess();\n\t\t\t\t}\n\t\t\t});\n\t\t}\n    }\n    \n    function display_applynow(){\n        // because the content of the summary box is pulled in from a template file we have\n        // to store a reference to the element in the current execution context\n        // e.g. we can't store in a variable prior to this function executing because\n        // the template is re-loaded every time a new calculation is made\n        var apply_now = getElement('js-applynow');\n        removeClass(apply_now, 'hide');\n    }\n    \n    function process_application(){\n        // hide the popup and show the summary of costs\n        addClass(popup, 'hide');\n        removeClass(details_summary, 'hide');\n        \n        // once the popup is closed we want to show the 'apply now' button within the details summary box\n        display_applynow();\n    }\n    \n    function update_amount (e) {\n        // we pass through 'true' to the 'check_amount' function so it knows to apply\n        // specific code branches based on the \u003cinput\u003e #js-amount-update within the popup\n        if (check_amount(true)) {\n            amount.value = amount_updated.value; // ensure the \u003cinput\u003e outside the popup is updated to reflect the new value inside the popup\n            calculate();\n        } else {\n            // Prevent the user from closing the popup if the amount is invalid\n            event.remove(button_continue, 'click', process_application);\n        }\n    }\n    \n    function show_popup(){\n        removeClass(popup, 'hide');\n        \n        event.add(popup, 'click', check_popup_close);\n        event.add(amount_updated, 'keyup', update_amount);\n        \n        // pull in amount entered into the main \u003cinput\u003e #js-amount\n        amount_updated.value = amount.value;\n        \n        // if no template available then we know this is the first time opening the popup\n        // and we do a quick and dirty 'innerHTML' of the amount to be borrowed\n        if (!template) {\n            borrowing.innerHTML = '\u0026pound;' + amount.value;\n        }\n        \n        // no point in loading a new instance of the calendar every time the popup is displayed\n        if (!calendar) {\n            load_calendar();\n        }\n    }\n    \n    paydate.onfocus = function(){\n        // validate the amount entered by the user\n        if (check_amount()) {\n            show_popup();\n        }\n    };\n    \n    amount.onblur = function(){\n        // if the user has already opened the popup and selected some values and clicked to continue\n        // then we know the #js-details-summary element will be visible and so we need to call\n        // the function which gets costs/interest fees etc and update the values\n        if (!hasClass(details_summary, 'hide')) {\n            // validate the amount entered by the user\n            if (check_amount()) {\n                amount_updated.value = amount.value; // ensure the \u003cinput\u003e inside the popup is updated to reflect the new value outside the popup\n                calculate();\n            }\n        }\n    };\n    \n    popup.insertBefore(calendar_container, details_container.parentNode); // insert Kalendae (calendar) widget into the popup dialog\n    \n});\n","tags":""},{"id":"3169769","title":"I'm glad ES4 never happened. Couldn't imagine writing bullshit JavaScript like this ActionScript code...","content":"// All this code is used for is to add a hyperlink to a button...\n\nimport flash.net.URLRequest;\n\nfunction open_url(e:MouseEvent):void {\n\tvar url:URLRequest = new URLRequest('http://www.google.com/')\n\tnavigateToURL(url);\n}\n\nlink.addEventListener(MouseEvent.CLICK, open_url);\n","tags":""},{"id":"7702823","title":"The importance of refactoring...","content":"var cutsTheMustard = 'querySelector' in document \u0026\u0026 'localStorage' in window \u0026\u0026 'addEventListener' in window,\n    isNotProxyBased = !/S40[\\w]{3,5}Browser|Opera\\sMini\\//i.test(navigator.userAgent),\n    modernDevice = cutsTheMustard \u0026\u0026 isNotProxyBased,\n    holepunched = isIE \u003e 6 \u0026\u0026 document.getElementById('js-holepunched');\n \nif (modernDevice || holepunched) {\n    // do stuff\n}\nI refactored this code by making just a couple of very basic tweaks...\n\n1. move all logic out of the conditional and into variables\n2. removed unnecessary syntax cruft from `isProxyBrowser`\n3. give the variables descriptive names\n4. further break down the logic (e.g. group the checks for 'cutting the mustard' and 'being a proxy based browser')\n5. reversed the `isProxyBased` logic so it becomes `isNotProxyBased` (this meant we didn't clutter `modernDevice` with extra syntax and made it as readable as possible)\n6. use selected variables within the conditional\nIs there any thing more we could do with this code to make it as simple as possible to understand?\n\nWell, one small tweak we *could* make would be to simplify the conditional even further. We could do this by creating another variable (again with a helpfully descriptive identifier) to hold the check of `modernDevice || holepunched`, like so...\n\n```js\nvar cutsTheMustard = 'querySelector' in document \u0026\u0026 'localStorage' in window \u0026\u0026 'addEventListener' in window,\n    isNotProxyBased = !/S40[\\w]{3,5}Browser|Opera\\sMini\\//i.test(navigator.userAgent),\n    modernDevice = cutsTheMustard \u0026\u0026 isNotProxyBased,\n    holepunched = isIE \u003e 6 \u0026\u0026 document.getElementById('js-holepunched'),\n    enhancedExperience = modernDevice || holepunched;\n \nif (enhancedExperience) {\n    // do stuff\n}\n```\n\nOne thing to be aware of is: refactoring can actually be a bad thing if you don't know why you're doing it. If you're just blindly following predefined rules of refactoring then the above small tweak could end up making the code harder to read. \n\nImagine if we were in a situation where there wasn't a logical association between `modernDevice` and `holepunched`. We could end up creating a variable like `passesOurChecks` (this is a poor example I know). Which would mean this new variable would actually make the code slightly harder to read because it wouldn't be descriptive enough and would likely mean the reader would need to check what the value of that variable was to better understand the code.\n\nJust something to keep in mind.\nvar isProxyBased = (/S40[\\w]{3,5}Browser|Opera\\sMini\\//i).test(navigator.userAgent);\n\nif (('querySelector' in document \u0026\u0026 'localStorage' in window \u0026\u0026 'addEventListener' in window \u0026\u0026 !isProxyBased) || (isIE \u003e 6 \u0026\u0026 document.getElementById('js-holepunched'))) {\n    // do stuff\n}\n","tags":""},{"id":"3046619","title":"WinXP IE8 doesn't work, but Win7 IE8 Browser/Document Mode does work?","content":".icon:before {\n\tcontent: \"\\25b6\"; /* right arrow uni-code character (http://www.fileformat.info/info/unicode/char/25b6/index.htm) */\n\tfont-size: 85%;\n}\n","tags":""},{"id":"7944948","title":"Sandi Metz advice for writing tests","content":"# Rules for good testing\n\nLook at the following image...\n\n![](https://speakerd.s3.amazonaws.com/presentations/ac751bc0918e01300e0b6698bdce82b7/slide_29.jpg?1367359730)\n\n...it shows an object being tested. \n\nYou can't see inside the object. All you can do is send it messages. This is an important point to make because we should be \"testing the interface, and NOT the implementation\" - doing so will allow us to change the implementation without causing our tests to break.\n\nMessages can go 'into' an object and can be sent 'out' from an object (as you can see from the image above, there are messages going in as well as messages going out). That's fine, that's how objects communicate.\n\nNow there are two types of messages: 'query' and 'command'...\n\n## Queries\n\nQueries are messages that \"return something\" and \"change nothing\". \n\nIn programming terms they are \"getters\" and not \"setters\".\n\n## Commands\n\nCommands are messages that \"return nothing\" and \"change something\".\n\nIn programming terms they are \"setters\" and not \"getters\".\n\n## What to test?\n\n- Test incoming query messages by making assertions about what they send back\n- Test incoming command messages by making assertions about direct public side effects\n\n## What NOT to test?\n\n- Messages that are sent from within the object itself (e.g. private methods).\n- Outgoing query messages (as they have no public side effects)\n- Outgoing command messages (use mocks and set expectations on behaviour to ensure rest of your code pass without error)\n- Incoming messages that have no dependants (just remove those tests)\n\nNote: there is no point in testing outgoing messages because they should be tested as incoming messages on another object\n\n## What to Mock/Stub\n\nCommand messages should be mocked, while query messages should be stubbed\n\n## Contract Tests\n\nContract tests exist to ensure a specific 'role' (or 'interface' by another - stricter - name) actually presents an API that we expect.\n\nThese types of tests can be useful to ensure third party APIs do (or don't) cause our code to break when we update the version of the software.\n\n\u003e Note: if the libraries we use follow [Semantic Versioning](http://semver.org/) then this should only happen when we do a major version upgrade. But it's still good to have contract/role/interface tests in place to catch any problems.\n\nThe following is a modified example (written in Ruby) borrowed from the book \"Practical Object-Oriented Design in Ruby\":\n\n```ruby\n# Following test asserts that SomeObject (@some_object) \n# implements the method `some_x_interface_method`\nmodule SomeObjectInterfaceTest\n  def test_object_implements_the_x_interface\n    assert_respond_to(@some_object, :some_x_interface_method)\n  end\nend\n\n# Following test proves that Foobar implements the SomeObject role correctly\n# i.e. Foobar implements the SomeObject interface\nclass FoobarTest \u003c MiniTest::Unit::TestCase\n  include SomeObjectInterfaceTest\n\n  def setup\n    @foobar = @some_object = Foobar.new\n  end\n\n  # ...other tests...\nend\n```\n\n","tags":""},{"id":"2996941","title":"How to access a specific :after pseudo-element's styles via JavaScript","content":"var cache_styles = (function(){\n    var cache, len, found;\n    \n    return function(){\n        if (!cache) {\n            cache = {};\n\n            // IE9+ and all versions of Firefox/Chrome/Safari\n            if (window.getComputedStyle) {\n                cache.style = window.getComputedStyle(popup, ':after');\n                cache.right = parseInt(cache.style.right);\n                cache.top = parseInt(cache.style.top);\n                cache.height = parseInt(cache.style.height);\n                cache.width = parseInt(cache.style.width);\n            }\n            // IE8 - needs to loop through stylesheet looking for the relevant Rule to pick up the :after styles from\n            else {\n                len = document.styleSheets[1].rules.length;\n\n                while (len--) {\n                    if (document.styleSheets[1].rules[len].selectorText === '.application-popup:after') {\n                        found = document.styleSheets[1].rules[len];\n                        break;\n                    }\n                }\n\n                cache.styles = found.style.cssText.toLowerCase();\n                cache.right = parseInt(cache.styles.match(/right: ?([^;]+)/)[1]);\n                cache.top = parseInt(cache.styles.match(/top: ?([^;]+)/)[1]);\n                cache.height = parseInt(cache.styles.match(/height: ?([^;]+)/)[1]);\n                cache.width = parseInt(cache.styles.match(/width: ?([^;]+)/)[1]);\n            }\n            \n            // The following code is *VERY* specific to my use case and so would need to be revisited for others thinking of using this code\n            // Currently the values are negative integers so we need to check for that and return positive integer (if need be)\n            cache.right = (cache.right \u003c 0) ? Math.abs(cache.right) : cache.right;  // 13\n            cache.top = (cache.top \u003c 0) ? Math.abs(cache.top) : cache.top;          // 10\n        }\n        \n        return cache;\n    };\n}());\n","tags":""},{"id":"5244199","title":"Basic Closure example in PHP","content":"\u003c?php\n    function doSomething($multiplier)\n    {\n        return array_map(function ($item) {\n            return $item * $multiplier;\n        }, array(1, 2, 3));\n    }\n\n    function doSomethingWithClosure($multiplier)\n    {\n        // We tell the Closure to `use` (i.e. pass through) `$multiplier` from the parent scope. \n        // If we didn't then `$multiplier` would be equal to zero (as scope within the anonymous function is lost).\n        // The previous `doSomething` function demonstrates what would happen if we didn't pass through $multiplier. \n        return array_map(function ($item) use ($multiplier) {\n            return $item * $multiplier;\n        }, array(1, 2, 3));\n    }\n\n    print_r(doSomething(2)); // [0, 0, 0]\n    print_r(doSomethingWithClosure(2));  // [2, 4, 6]\n","tags":""},{"id":"2994844","title":"How to target close button","content":"#How to target CSS generated content via JavaScript?\n##The content was generated using `:after` pseudo-element\n\nHere is the design... \n\n!['Popup Design'](http://f.cl.ly/items/2E2M3T2h2Y060M2d3d3e/Screen%20Shot%202012-06-26%20at%2011.13.06.png)\n\nBelow is the JavaScript I'm using to access the 'X' close button which was generated by the CSS.\n\nNote: I don't want an extra HTML element in the page, I'd rather CSS handle the generation. \n\nAlso, I will be replacing the hard coded values with values pulled from `getComputedStyle`, but this is my initial attempt...\n\n```js\n/*\n * pageX/Y is position relative to Window\n * clientX/Y is for Internet Explorer which doesn't recognise pageX/Y\n *\n * BUT although clientX/Y is similar it has one small caveat!\n * The value changes depending on whether the user has scrolled the window\n * Which means we need to add on top of clientY any scroll amount (if any)\n */\nvar x = e.pageX || e.originalEvent.clientX;\nvar y = e.pageY || (document.documentElement.scrollTop + e.originalEvent.clientY);\nvar popup_width = popup.clientWidth;\nvar popup_height = popup.clientHeight;\nvar popup_offset = getOffset(popup);\nvar popup_x = popup_offset.left;\nvar popup_y = popup_offset.top;\nvar popup_xrange = (popup_x + popup_width) + 17;\nvar popup_yrange = popup_y - 10;\nvar popup_xclose = (popup_x + popup_width) - 13;\nvar popup_yclose = popup_y + 20;\nvar within_xrange = x \u003c= popup_xrange \u0026\u0026 x \u003e= popup_xclose;\nvar within_yrange = y \u003c= popup_yclose \u0026\u0026 y \u003e= popup_yrange;\n\nif (within_xrange \u0026\u0026 within_yrange) {\n    // DO SOMETHING NOW WE'VE FOUND THE CLOSE BUTTON\n}\n```\n\n...note that the `getOffset` function used above looks like this...\n\n```js\n/**\n * Following method determines the left/top position of the target element.\n *\n * @param elem { Node } the target element\n * @param end { String } id value for the top most element we want to check against\n * @return { Object } object containing x and y position for specified element\n */\nvar getOffset = function(elem, end) {\n\tvar _x = 0,\n\t\t _y = 0;\n\t\n\twhile (elem \u0026\u0026 !isNaN(elem.offsetLeft) \u0026\u0026 !isNaN(elem.offsetTop)) {\n\t\t// Store the x and y co-ordinates of the current element\n\t\t_x += elem.offsetLeft - elem.scrollLeft;\n\t\t_y += elem.offsetTop - elem.scrollTop;\n\t\t\n\t\t// Then move onto the next element up (and we keep going all the way to the top of the document unless stopped)\n\t\t// We use offsetParent instead of parentNode because the offsetLeft/Top adds on extra un-needed dimensions!\n\t\telem = elem.offsetParent;\n\t\t\n\t\t/*\n\t\t\tIn the following conditional statement…\n\t\t\t\n\t\t\t- We need to avoid a situation where the \u003cbody\u003e tag isn't considered an offsetParent and so the browser continues up until null is returned\n\t\t\t- We can specify an element's id as the top level element to top checking for\n\t\t\t- We can pass through '_now_' as the end value which means the check stops immediately\n\t\t\t- Failing the id or _now_ we can try and stop at the document.body element (which will only work if the body is considered an offsetParent)\n\t\t */\n\t\tif (elem == null || elem.id === end || end === '_now_' || elem.tagName.toLowerCase() === 'body') {\n\t\t\tbreak;\n\t\t}\n\t}\n\t\n\treturn { top: _y, left: _x };\n};\n```\n","tags":""},{"id":"6711354","title":"PhantomJS network tests","content":"var page = require('webpage').create();\n\npage.onResourceRequested = function (request) {\n    if (/(?:png|jpeg|jpg|gif)$/i.test(request.url)) {\n        console.log('Image requested: ', request.url);\n    }\n};\n\npage.onResourceReceived = function (request) {\n    if (/(?:png|jpeg|jpg|gif)$/i.test(request.url)) {\n        console.log('Image received: ', request.url);\n    }\n};\n\npage.onError = function (msg, trace) {\n    console.log(msg);\n\n    trace.forEach(function (item) {\n        console.log('  ', item.file, ':', item.line);\n    });\n}\n\npage.viewportSize = { width: 1920, height: 800 };\n\npage.open('http://stormcreative.co.uk/', function (status) {\n    console.log('Status:' + status);\n    phantom.exit();\n});\n","tags":""},{"id":"7264753","title":"How should we handle sub elements within an existing element? Should it be converted into a block?","content":"\u003c!-- we could keep `block__element-3` as a sub element... --\u003e\n\u003cdiv class=\"block\"\u003e\n    \u003cdiv class=\"block__element-1\"\u003e\n        \u003cdiv class=\"block__element-3\"\u003e\u003c/div\u003e\n    \u003c/div\u003e\n    \u003cdiv class=\"block__element-2\"\u003e\u003c/div\u003e\n\u003c/div\u003e\n\n\u003c!-- or we could convert `block__element-3` into a new block... --\u003e\n\u003cdiv class=\"block\"\u003e\n    \u003cdiv class=\"block__element-1\"\u003e\n        \u003cdiv class=\"new-block\"\u003e\u003c/div\u003e\n    \u003c/div\u003e\n    \u003cdiv class=\"block__element-2\"\u003e\u003c/div\u003e\n\u003c/div\u003e\n","tags":""},{"id":"7100367","title":"CabinJS static generator example","content":"Using CabinJS to create my blog, but it only works with GitHub pages (so as I have a user account set-up for my domain repo CabinJS' deployment process doesn't work for me, which means I need to copy the `dist` folder over to my website repo manually).\n\nSo rather than write a Rake task (or a Node/Grunt task) and have to spend time looking up the different File system APIs (which I always forget), I've decided to use standard unix commands to achieve the same thing.\n\nYes I'm sure it *looks* a lot more long winded but it works and took me a lot less time to write...\n\n```sh\nalias site=\"cd ~/Code/CabinJS \u0026\u0026 \n            touch log.txt \u0026\u0026 \n            git log --oneline -n 1 | \n            cut -d ' ' -f 2- | \n            xargs -I {} echo {} \u003e log.txt \u0026\u0026 \n            cd ../Website \u0026\u0026 \n            cp -r ../CabinJS/dist/* ./ \u0026\u0026 \n            git add . \u0026\u0026 \n            git add -A \u0026\u0026 \n            cat ../CabinJS/log.txt | \n            xargs -I {} git commit -m {} \u0026\u0026 \n            git push origin master\"\n```\n\n...to explain what it's doing...\n\n- we move into our CabinJS directory\n- we create a log.txt file\n- we send to stdout the latest commit message (originally I used `git log --pretty=oneline | sed -n 1p` - where `-n` meant 'no print' and `1p` meant 'print line 1' - before I realised I could avoid `sed` altogether and just use the `-n 1` flag for the git log instead)\n- we cut out just the message (ignoring the commit hash)\n- we pipe the stdout to xargs where we then write it into the log.txt\n- we move into our CabinJS release folder (e.g. where it generates the static site content)\n- we copy the content of the release folder (`dist`) into our main Website folder\n- we `git add` and `git add -A`\n- we send to stdout the content of our log.txt (which is the commit message)\n- we then pipe that commit message over to xargs which runs `git commit` using it\n- finally we `git push origin master`\n","tags":""},{"id":"7269907","title":"BBC News' RTL (right to left) solution","content":"# Right-to-Left (RTL)\n\n## Implementation\n\nThere are two methods to use in order to flip CSS styles: interpolated properties and the flip() function.\n\n- Interpolation should be used for any property which has a direction (e.g. `padding-left`, `margin-right`, `border-right`, `left`, etc.)\n- `flip()` should be used for all other properties\n\n### Which properties need to be flipped?\n\n- background\n- background-position\n- border\n- border-radius\n- clear\n- cursor\n- direction\n- float\n- left/right\n- margin\n- padding\n- text-align\n- text-indent\n\n### How does it work?\n\n    // guts/mixins/_rtl.scss\n    @function flip($value_ltr, $value_rtl) {\n      @if $rtl { @return $value_rtl; }\n      @else { @return $value_ltr; }\n    }\n\n    $padding-left:    padding-left;\n    $padding-right:   padding-right;\n    $margin-left:     margin-left;\n    $margin-right:    margin-right;\n    $border-right:    border-right;\n    $left:            left;\n    $right:           right;\n\n    @if $rtl {\n      $padding-left:  padding-right;\n      $padding-right: padding-left;\n      $margin-left:   margin-right;\n      $margin-right:  margin-left;\n      $border-right:  border-left;\n      $left:          right;\n      $right:         left;\n    }\n\n#### Flip\n\nTo implement, let's take the following style as an example:\n\n    // Original Sass\n    .class {\n      float: left;\n    }\n\nFor a RTL layout, `float: left;` should be flipped to `float: right'`.\n\nWe can use the `flip()` function to accomplish this.\n\n    // Flipped Sass\n    .class {\n      float: flip(left, right);\n    }\n\nWhen Sass comes across the `flip()` function when compiling the code, it will check what the `$rtl` variable is set to. This variable is set at the top level, for example in `sass/intl-arabic-core.scss`.\n\nIf `$rtl` is `false`, the `flip()` function will take the first parameter.\nIf `$rtl` is `true`, the `flip()` function will take the second parameter.\n\nThe Sass will compile out as follows:\n\n    // Compiled LTR style\n    .class {\n      float: left;\n    }\n\n    // Compiled RTL style\n    .class {\n      float: right;\n    }\n\n#### Interpolation\n\nThis method interpolates the property names from variables which are flipped higher up.\n\nIn `_rtl.scss`, the `$padding-left` variable is declared as `padding-left`. Then if `$rtl` is `true`, it is overridden with `padding-right`.\n\nTo implement, take the following style as an example:\n\n    // Original Sass\n    .class {\n      padding-left: 8px;\n    }\n\nFor a RTL layout, `padding-left: 8px;` should be flipped to `padding-right: 8px;`.\n\nIn order to flip this, we have to interpolate the style property:\n\n    // Flipped Sass\n    .class {\n      #{$padding-left}: 8px;\n    }\n\nThis will compile out to:\n\n    // Compiled LTR style\n    .class {\n      padding-left: 8px;\n    }\n\n    // Compiled RTL style\n    .class {\n      padding-right: 8px;\n    }\n\n#### Markup\n\nPlacing the `dir=rtl` attribute on the `\u003chtml\u003e` tag can cause the scrollbar in certain browsers to be flipped to the left-hand side. This is generally found to be a bad experience for RTL users.\n\nAdding `dir=rtl` to the `\u003chead\u003e` tag and to a `\u003cdiv\u003e` wrapping the whole page, as recommended by [W3C](http://www.w3.org/TR/i18n-html-tech-bidi/#tech-scrollbar), ensures that the scrollbar isn't flipped.\n\n    \u003c!DOCTYPE HTML\u003e\n    \u003chtml\u003e\n    \u003chead dir=\"rtl\"\u003e\n        ...\n    \u003c/head\u003e\n    \u003cbody\u003e\n        \u003cdiv dir=\"rtl\"\u003e\n            ...\n        \u003c/div\u003e\n    \u003c/body\u003e\n    \u003c/html\u003e\n\n### More examples\n\n    // Flipped Sass\n    .class {\n      #{$padding-left}: 8px;\n      #{$padding-right}: 8px;\n      #{$margin-left}: 8px;\n      #{$margin-right}: 8px;\n      #{$left}: 8px;\n      #{$right}: 8px;\n      margin: flip(1px 2px 3px 4px, 1px 4px 3px 2px);\n      float: flip(left, right);\n    }\n\n    // Compiled LTR style\n    .class {\n      padding-left: 8px;\n      padding-right: 8px;\n      margin-left: 8px;\n      margin-right: 8px;\n      left: 8px;\n      right: 8px;\n      margin: 1px 2px 3px 4px;\n      float: left;\n    }\n\n    // Compiled RTL style\n    .class {\n      padding-right: 8px;\n      padding-left: 8px;\n      margin-right: 8px;\n      margin-left: 8px;\n      right: 8px;\n      left: 8px;\n      margin: 1px 4px 3px 2px;\n      float: right;\n    }\n\n# Best practices\n\n- Don't flip everything! Only flip what needs to be flipped. This will help keep the CSS as clean as possible.\n- Styles which are hiding elements by pushing them off the screen (e.g. `text-align: -320px;` or `right: 5000%;`) don't need to be flipped unless they are being transitioned or overridden.\n- If left and right properties have the same values in the same selector, they dont need to be flipped (e.g. `margin-left: 0; margin-right: 0;`)\n- Write long values on separate lines:\n\n```\n// Good\n.class {\n  padding: flip($gutter/2 $gutter*2.5 $gutter/4 $gutter/2,\n                $gutter/2 $gutter/2 $gutter/4 $gutter*2.5);\n}\n\n// Bad\n.class {\n  padding: flip($gutter/2 $gutter*2.5 $gutter/4 $gutter/2, $gutter/2 $gutter/2 $gutter/4 $gutter*2.5);\n}\n```\n\n- Separate `background-position` from `background` shorthand\n\n```\n// Good\n.class {\n  background: $pale-grey image-url('icons-sprite.png') no-repeat;\n  background-position: flip(right -792px, left -792px);\n}\n\n// Bad\n.class {\n  background: flip($pale-grey image-url('icons-sprite.png') no-repeat right -792px,\n                   $pale-grey image-url('icons-sprite.png') no-repeat left -792px);\n}\n```\n\n- How to fix bi-directional brackets issue: http://blog.jalproductions.co.uk/2013/04/19/how-to-fix-rtl-bracketsparenthesis-problem/\n\n","tags":""},{"id":"6571371","title":"Thoughts re: UnCSS (a way to parse CSS files to see if all of the rules/selectors apply to a HTML page)","content":"There are a couple of steps (and issues) that need to be considered for a solution to present itself...\n\n- Load CSS\n- Check each rule's list of selectors\n- If the selector is a `class` or an `id` then we can just see if it appears in the HTML markup\n- If it's neither a `class` or an `id` then we'll need to somehow parse the HTML and see if the CSS applies\n    - But how do we work around HTML that is post loaded via JavaScript?\n    - This is where using a headless browser would be required, and if that's the case we may as well go headless completely\n- We need to check each media query found and see if selectors within match at some point\n    - The same process as above needs to happen (if `class` or `id` then we can just check HTML markup)\n    - Otherwise we'll need to parse HTML to see if the CSS applies\n","tags":""},{"id":"6573026","title":"MongoDB: when using the `find()` method on a Collection you'll need to `toArray()` on results as it doesn't run your query but instead returns new Cursor instance","content":"// Using \u003chttps://github.com/Colingo/continuable-mongo\u003e api\n\nvar collection = client.collection('someCollection');\n\ncollection.insert([{\n    some: 'key',\n    value: 'pair'\n}], function (err, inserted) {\n    collection.find({\n        some: 'key'\n    }).toArray(function (err, results) {\n        // results = found documents\n    });\n});\n","tags":""},{"id":"6222299","title":"Sass mixin that handles span'ing content based off of a 12 column grid (could be updated to accept dynamic content)","content":"/* =============================================================================\n   Creates vendor-prefixed CSS declaration blocks in one go\n\n   Example usage:\n   @include vendor(box-sizing, border-box);\n\n   Notes:\n   Majority of the usage will be a basic property (that needs to be prefixed)\n   followed by a corresponding value. \n\n   But when the user specifies the `@viewport` declaration as a property then \n   we need to branch off into a different scenario - Sass was bombing out with\n   compile errors when trying to make the mixin 100% dynamic so we have to \n   hardcode `@viewport` (and prefixes).\n   ========================================================================== */\n\n@mixin vendor ($property, $value) {\n  @if $property == viewport {\n    @-webkit-viewport { width: $value; }\n       @-moz-viewport { width: $value; }\n        @-ms-viewport { width: $value; }\n         @-o-viewport { width: $value; }\n            @viewport { width: $value; }\n  } @else {\n    -webkit-#{$property}: $value;\n       -moz-#{$property}: $value;\n        -ms-#{$property}: $value;\n         -o-#{$property}: $value;\n            #{$property}: $value;\n  }\n}\n\n@mixin span($numberOfColumnsToSpan, $includeLeftPadding: true) {\n    @include vendor(box-sizing, border-box);\n\n    $width: 100% / 12 * $numberOfColumnsToSpan; // 12 (number of columns in total) could be configurable via mixin argument\n  \n    $fix-blackberry-os5-rounding-issue: 0.00100066;\n\n    @if $width == 50% {\n      $width: $width - $fix-blackberry-os5-rounding-issue;\n    }\n\n    @if $includeLeftPadding {\n        padding-left: 8px; // this could be a variable which is updated dynamically within media queries\n    }\n\n    width: $width;\n}\n\n// EXAMPLE USAGE...\n\n.column1 {\n    @include span(9, false); // we know this is the first column so don't include the left column\n}\n\n.column2 {\n    @include span(2);\n}\n","tags":""},{"id":"6229170","title":"Imager.js (as of 14th August 2013)","content":"(function (window, document) {\n\n    'use strict';\n\n    var $, Imager;\n\n    window.requestAnimationFrame = \n    window.requestAnimationFrame || \n    window.mozRequestAnimationFrame || \n    window.webkitRequestAnimationFrame || \n    function (callback) {\n        window.setTimeout(callback, 1000 / 60);\n    };\n\n\n    $ = (function (dollar) {\n        if (dollar) {\n            return dollar;\n        }\n\n        return function (selector) {\n            return Array.prototype.slice.call(document.querySelectorAll(selector));\n        };\n    }(window.$));\n\n\n    /*\n        Construct a new Imager instance, passing an optional configuration object.\n\n        Example usage:\n\n            {\n                // Available widths for your images\n                availableWidths: [Number]\n\n                // Selector to be used to locate your div placeholders\n                selector: '',\n\n                // Class name to give your resizable images.\n                className: '',\n\n                // Regular expression to match against your image endpoint's naming conventions \n                // e.g. http://yourserver.com/image/horse/400\n                regex: RegExp\n            }\n\n        @param {object} configuration settings\n        @return {object} instance of Imager\n     */\n    window.Imager = Imager = function (opts) {\n        var self = this;\n            opts = opts || {};\n\n        this.availableWidths = opts.availableWidths || [96, 130, 165, 200, 235, 270, 304, 340, 375, 410, 445, 485, 520, 555, 590, 625, 660, 695, 736];\n        this.selector        = opts.selector || '.delayed-image-load';\n        this.className       = '.' + (opts.className || 'image-replace').replace(/^\\.+/, '.');\n        this.regex           = opts.regex || /^(.+\\/)\\d+$/i;\n        this.gif             = document.createElement('img');\n        this.gif.src         = 'data:image/gif;base64,R0lGODlhEAAJAIAAAP///wAAACH5BAEAAAAALAAAAAAQAAkAAAIKhI+py+0Po5yUFQA7';\n        this.gif.className   = this.className.replace(/^[#.]/, '');\n        this.divs            = $(this.selector);\n        this.cache           = {};\n        this.changeDivsToEmptyImages();\n\n        window.requestAnimationFrame(function(){\n            self.init();\n        });\n    };\n\n\n    Imager.prototype.init = function () {\n        var self = this;\n\n        this.initialized = true;\n        this.checkImagesNeedReplacing();\n\n        window.addEventListener('resize', function(){\n            self.checkImagesNeedReplacing();\n        }, false);\n    };\n\n\n    Imager.prototype.changeDivsToEmptyImages = function () {\n        var divs = this.divs,\n            i = divs.length,\n            gif;\n\n        while (i--) {\n            gif = this.gif.cloneNode(false);\n            gif.width = divs[i].getAttribute('data-width');\n            gif.setAttribute('data-src', divs[i].getAttribute('data-src'));\n            divs[i].parentNode.replaceChild(gif, divs[i]);\n        }\n\n        if (this.initialized) {\n            this.checkImagesNeedReplacing();\n        }\n    };\n\n\n    Imager.prototype.checkImagesNeedReplacing = function () {\n        var self = this,\n            images = $(this.className),\n            i = images.length;\n\n        if (!this.isResizing) {\n            this.isResizing = true;\n\n            while (i--) {\n                this.replaceImagesBasedOnScreenDimensions(images[i]);\n            }\n\n            this.isResizing = false;\n        }\n    };\n\n    Imager.prototype.replaceImagesBasedOnScreenDimensions = function (image) {\n        var src = this.determineAppropriateResolution(image),\n            parent = image.parentNode,\n            replacedImage;\n\n        if (this.cache[src]) {\n            replacedImage = this.cache[src].cloneNode(false);\n            replacedImage.width = image.getAttribute('width');\n        } else {\n            replacedImage = image.cloneNode(false);\n            replacedImage.src = src;\n            this.cache[src] = replacedImage;\n        }\n\n        parent.replaceChild(replacedImage, image);\n    };\n\n    Imager.prototype.determineAppropriateResolution = function (image) {\n        var src           = image.getAttribute('data-src'),\n            imagewidth    = image.clientWidth,\n            selectedWidth = this.availableWidths[0],\n            i             = this.availableWidths.length;\n\n        while (i--) {\n            if (imagewidth \u003c= this.availableWidths[i]) {\n                selectedWidth = this.availableWidths[i];\n            }\n        }\n\n        return this.changeImageSrcToUseNewImageDimensions(src, selectedWidth);\n    };\n\n    Imager.prototype.changeImageSrcToUseNewImageDimensions = function (src, selectedWidth) {\n        return src.replace(this.regex, function (match, captured) {\n            return captured + selectedWidth;\n        });\n    };\n\n}(window, document));\n","tags":""},{"id":"5985455","title":"Strategy pattern to remove the need for conditionals. If you find yourself writing conditionals then that's really just an object waiting to be made. Yes there are more lines of code, but this enforces the 'open/closed principle' which means the code is open for extension but closed for modification and means our code can scale a lot more easily than the conditional style.","content":"function test(condition){\n    if (condition === 'a') {\n        console.log('test a here');\n    } else if (condition === 'b') {\n        console.log('test b here');\n    } else if (condition === 'c') {\n        console.log('test c here');\n    }\n}\n\ntest('a');\ntest('b');\ntest('c');\nfunction betterExample(obj) {\n    obj.log();\n}\n\nvar a = {\n    log: function(){\n        console.log('better a here');\n    }\n};\n\nvar b = {\n    log: function(){\n        console.log('better b here');\n    }\n};\n\nvar c = {\n    log: function(){\n        console.log('better c here');\n    }\n};\n\nbetterExample(a);\nbetterExample(b);\nbetterExample(c);\n","tags":""},{"id":"6105162","title":"Firefox chokes on this code without the `setTimeout`...","content":"/*\n    This is ugly.\n    Firefox doesn't trigger a transitionend event unless the ui is unblocked.\n    So I use a timeout to cause the ui thread to become unblocked allowing the event code to work.\n */\nwindow.setTimeout(function(){\n    element.on('transitionend webkitTransitionEnd oTransitionEnd MSTransitionEnd', function(){\n        element.remove();\n    });\n\n    if (!featureDetector.can('CssTransition')) {\n        element.remove();\n    }\n\n    element.addClass('setOpacityToZero');\n}, 0);\n","tags":""},{"id":"6088405","title":"Is this good flow control? Or would Promises (or Generators) make this much simpler and easier to read? I write my code in such a way that I try to be as 'functional' as possible, and that the code reads in a linear fashion (as if telling a story, there is a start, middle and an end).","content":"var http = require('http'),\n    fs   = require('fs');\n\nvar server = http.createServer(processRequest);\n    server.listen(8080);\n    \nfunction processRequest (request, response) {\n    console.log('INCOMING REQUEST: ' + request.method + ', ' + request.url);\n\n    loadAlbumList(handleAlbumList);\n    \n    /*\n        I'd really like to move these inner functions outside of the `processRequest` but that would mean\n        I would need to pass around the `request` and `response` parameters as well which would start \n        feeling a little messy to me? Is this just the way it is or do you think there is a better way \n        to handle this type of situation?\n     */\n\n    function handleAlbumList (err, albums) {\n        if (err) {\n            displayError(err);\n            return;\n        }\n\n        displaySuccess(albums);\n    }\n\n    function displayError (err) {\n        response.writeHead(503, { 'Content-Type': 'application/json' });\n        response.end(JSON.stringify(err) + '\\n');\n    }\n\n    function displaySuccess (albums) {\n        var output = {\n            error: null,\n            data: { albums: albums }\n        };\n\n        response.writeHead(200, { 'Content-Type': 'application/json' });\n        response.end(JSON.stringify(output) + '\\n');\n    }\n}\n\nfunction loadAlbumList (callback) {\n    fs.readdir('albums/', function (err, files) {\n        if (err) {\n            callback(err);\n            return;\n        }\n\n        files = files.filter(function (value) {\n            if (/^\\./i.test(value)) {\n                return false;\n            }\n            \n            return true;\n        });\n\n        callback(null, files);\n    });\n}\n","tags":""},{"id":"5896921","title":"The power of r.js is incredible. `insertRequire` and `onBuildRead` are insanely useful in the right situation (not to mention other useful features such as `fileExclusionRegExp`, `removeCombined` and literally a ton more)...","content":"var config = {\n    paths: { jquery: 'libs/jquery' },\n    fileExclusionRegExp: /^\\.|node_modules|Gruntfile|grunt-|libs|\\.md|package.json/,\n    baseUrl: './',\n    modules: [\n        { \n            name: 'bootstrap-about', \n            exclude: ['app'], \n            include: ['components/world/component'], \n            insertRequire: ['components/world/component'] \n        },\n        { \n            name: 'bootstrap-index', \n            exclude: ['app'], \n            include: ['components/hello/component', 'components/world/component'], \n            insertRequire: ['components/hello/component', 'components/world/component'] \n        }\n    ],\n    dir: './release/',\n    optimize: 'none',\n    removeCombined: true,\n    onBuildRead: function (moduleName, path, contents) {\n        if (path.indexOf('bootstrap-') !== -1 || path.indexOf('/app.js') !== -1) {\n            return '';\n        } else {\n            return contents;\n        }\n    }\n};\n","tags":""},{"id":"5798071","title":"Example of how Sass mixins when used excessively and without thought can actually be more of a code smell than a helper.","content":"\nWe had multiple mixins for prefixing properties such as:\n\n- `border-box`\n- `border-radius`\n- `box-shadow`\n- ...on and on...\n\nWhen realistically we just needed...\n\n```sass\n@mixin vendor ($property, $value) {\n    -webkit-#{$property}: $value;\n       -moz-#{$property}: $value;\n        -ms-#{$property}: $value;\n         -o-#{$property}: $value;\n            #{$property}: $value;\n}\n```\n\n...which you would use as for example: `@include vendor(box-sizing, border-box);`\n\nYes this adds prefixes that might not be needed (e.g. border-radius is reasonably well supported in older versions of Firefox and WebKit) but this repeatable content will get chewed up when it comes to GZIP'ing.\n","tags":""},{"id":"5763792","title":"S.O.L.I.D - (L)iskov Substitution. ","content":"```php\nclass Parrot extends Bird \n{\n    public function Talk() \n    {\n        echo 'Talk';\n    }\n}\n```\n\nA Bird can't necessarily \"talk\" so you'd assume that a Parrot can't be substituted with a Bird. But this isn't the Liskov principle.\n\nThe point is a Parrot should act like a Bird in all ways, so that someone who has a plan for dealing with birds in general won't be surprised by a Parrot they run across. \n\nIf the Parrot happens to be able to talk as well, it doesn't matter, because their plan doesn't involve asking birds to talk.\n\nFor example, perhaps they just call $bird-\u003efly() on every Bird they get - the ability of a Parrot to talk won't disrupt that activity, so their algorithm still works. But if you invent a sort of bird that can't fly (an Ostrich, say), then you've violated the principle, and their general bird-handling algorithm no longer works on all sorts of birds.\n","tags":""},{"id":"6157139","title":"This is how BBC News currently implements it's Image Enhancer for responsive images. Note: this is a completely rebuilt version of the code so the BBC's original source code doesn't actually look anything like the below example.","content":"The BBC has a server-side image service which provides developers with multiple sized versions of any image they request. It works in a similar fashion to [http://placehold.it/](http://placehold.it/) but it also handles the image ratios returned (where as placehold.it doesn't).\n\nThe original BBC News process (and my re-working of the script) follows roughly these steps...\n\n- Create new instance of ImageEnhancer\n- Change any `div`s within the page (which have a class of `delayed-image-load`) into a transparent GIF using a Base64 encoded string.\n  - We set the `width` \u0026 `height` HTML attributes of the image to the required size\n  - We know what size the image needs to be because each `div` has custom `data-attr` set server-side to the size of the image\n  - We then set a class of `image-replace` onto each newly created transparent image\n- We use a 250ms `setTimeout` to unblock the UI thread and which calls a function `resizeImages` which enhances the `image-replace` images so their source is now set to a URL where the returned image matches the requested dimensions in the URL path (in my example below I use `requestAnimationFrame` instead)\n    - We also create an event listener for the resize event which fires a pubsub event of `imageEnhancer:resize` \n- We call `resizeImages` initially and then every time the pubsub event fires. \n  - This function loops each `image-replace` image and changes the `src` attribute to the new URL with the best possible match dimensions specified within the URL path (based on the dimensions required for the image). \n  - If the resize event fires then we check the dimensions of the page and determine if we need a new URL to be used.\n\nThe example code that follows is not production ready, you can't just drop it into your code base and expect it to work. It is a rough prototype I built in about 30 minutes to help demonstrate in a roundabout way how the BBC News responsive team were handling the enhancement of images. The code uses features only available to more modern browsers (e.g. I've tested it in Chrome 28 and nothing else so your mile may vary if you're using a different browser to look at the example).\n\nI've also used the [http://placehold.it/](http://placehold.it/) service in place of the actual BBC News image provider. They don't work in quite the same way, but if you open the following HTML code in a modern browser (e.g. Chrome) and resize the browser window downwards you'll see the images change based on the current window dimensions. So rather than load a large image for smaller screens we swap out our images with images that are optimised for that screen size.\n\nNotes about the rewritten example:\n\n- ~~I should use live `nodeList` otherwise we'll miss any images added to the DOM after ImageEnhancer is initialised.~~\n- I might be able to work-around the use of the base64 image\n- Look at caching of image loads\n\u003c!doctype html\u003e\n\u003chtml dir=\"ltr\" lang=\"en\"\u003e\n    \u003chead\u003e\n        \u003cmeta charset=\"utf-8\"\u003e\n        \u003cmeta name=\"viewport\" content=\"width=device-width, initial-scale=1\"\u003e\n        \u003ctitle\u003eImageEnhancer\u003c/title\u003e\n        \u003cstyle\u003e\n            img {\n                max-width: 100%;\n            }\n\n            a {\n                display: block;\n                margin-top: 1em;\n            }\n        \u003c/style\u003e\n    \u003c/head\u003e\n    \u003cbody\u003e\n        \u003cp\u003eHere is our main image, we load this regardless of JavaScript support.\u003c/p\u003e\n        \u003cimg src=\"http://placehold.it/340\"\u003e\n\n        \u003cp\u003eBelow are three \u003ccode\u003ediv\u003c/code\u003e elements that will lazy-load more images (as long as JavaScript is enabled).\u003c/p\u003e\n        \u003cdiv class=\"delayed-image-load\" data-src=\"http://placehold.it/340\" data-width=\"340\"\u003e\u003c/div\u003e\n        \u003cdiv class=\"delayed-image-load\" data-src=\"http://placehold.it/340\" data-width=\"340\"\u003e\u003c/div\u003e\n        \u003cdiv class=\"delayed-image-load\" data-src=\"http://placehold.it/340\" data-width=\"340\"\u003e\u003c/div\u003e\n\n        \u003cscript\u003e\n            var pubsub = (function(){\n                var doc = document;\n                var topics = {};\n                var id = -1;\n                var pubsub = {};\n\n                pubsub.subscribe =  function (topic, fn) {\n                    if (!topics[topic]) {\n                        topics[topic] = [];\n                    }\n\n                    var token = (++id).toString();\n\n                    topics[topic].push({\n                        token: token,\n                        fn: fn\n                    });\n\n                    return token;\n                };\n\n                pubsub.unsubscribe =  function (token) {\n                    for (var m in topics) {\n                        if (topics[m]) {\n                            for (var i = 0, j = topics[m].length; i \u003c j; i++) {\n                                if (topics[m][i].token === token) {\n                                    topics[m].splice(i, 1);\n                                    return token;\n                                }\n                            }\n                        }\n                    }\n\n                    return false;\n                };\n\n                pubsub.publish =  function (topic, data) {\n                    if (!topics[topic]) {\n                        return false;\n                    }\n\n                    setTimeout(function(){\n                        var subscribers = topics[topic],\n\n                        len = topics[topic].length;\n\n                        while (len--) {\n                            subscribers[len].fn(topic, data);\n                        }\n                    }, 0);\n\n                    return true;\n                };\n\n                return pubsub;\n            }());\n\n            function ImageEnhancer(){\n                pubsub.subscribe('imageEnhancer:resize', this.resizeImages.bind(this));\n                pubsub.subscribe('div:added', this.changeDivsToEmptyImages.bind(this));\n                pubsub.subscribe('div:changed', this.resizeImages.bind(this));\n                this.availableWidthsFromOurImageProviderService = [96, 130, 165, 200, 235, 270, 304, 340, 375, 410, 445, 485, 520, 555, 590, 625, 660, 695, 736];\n                this.divs = document.getElementsByClassName('delayed-image-load'); // we use `getElementsByClassName` so we get a live NodeList\n                this.changeDivsToEmptyImages();\n                window.requestAnimationFrame(this.init.bind(this));\n            }\n\n            ImageEnhancer.prototype = {\n                changeDivsToEmptyImages: function(){\n                    var i = this.divs.length;\n\n                    while (i--) {\n                        var div           = this.divs[i],\n                            img           = document.createElement('img');\n                            img.src       = 'data:image/gif;base64,R0lGODlhEAAJAIAAAP///wAAACH5BAEAAAAALAAAAAAQAAkAAAIKhI+py+0Po5yUFQA7';\n                            img.className = 'image-replace';\n                            img.width     = div.getAttribute('data-width');\n                            img.setAttribute('data-src', div.getAttribute('data-src'));\n                        \n                        div.parentNode.replaceChild(img, div);\n                    }\n\n                    if (this.initialised) {\n                        pubsub.publish('div:changed');\n                    }\n                },\n\n                init: function(){\n                    this.initialised = true;\n                    this.resizeImages();\n                    \n                    window.addEventListener('resize', function() {\n                        pubsub.publish('imageEnhancer:resize');\n                    }, false);\n                },\n\n                resizeImages: function(){\n                    var imageList = Array.prototype.slice.call(document.querySelectorAll('.image-replace'));\n\n                    if (!this.isResizing) {\n                        this.isResizing = true;\n\n                        imageList.forEach(function (img) {\n                            img.src = this.calculateNewImageSrc(img);\n                        }.bind(this));\n\n                        this.isResizing = false;\n                    }\n                },\n\n                calculateNewImageSrc: function (img) {\n                    var imageSrc      = img.getAttribute('data-src'),\n                        imageWidth    = img.clientWidth,\n                        selectedWidth = this.availableWidthsFromOurImageProviderService[0];\n\n                    this.availableWidthsFromOurImageProviderService.forEach(function (currentlyAvailableWidth, index) {\n                        if (imageWidth \u003e currentlyAvailableWidth) {\n                            selectedWidth = this.availableWidthsFromOurImageProviderService[index + 1];\n                        }\n                    }.bind(this));\n\n                    return imageSrc.replace(/^(.+\\/)\\d+$/i, function (match, captured) {\n                        return captured + selectedWidth;\n                    });\n                }\n            };\n\n            function createAnchor(){\n                var anchor = document.createElement('a');\n                    anchor.href = '#my_new_element';\n                    anchor.innerHTML = 'Click me to add a new image to the DOM after ImageEnhancer has already been instantiated'\n\n                document.body.appendChild(anchor);\n\n                anchor.onclick = createNewImage;\n            }\n\n            function createNewImage(){\n                var div = document.createElement('div');\n                    div.className = 'delayed-image-load';\n                    div.setAttribute('name', 'my_new_element');\n                    div.setAttribute('data-src', 'http://placehold.it/340');\n                    div.setAttribute('data-width', '340');\n\n                document.body.appendChild(div);\n\n                pubsub.publish('div:added');\n            }\n\n            createAnchor();\n\n            new ImageEnhancer();\n\n        \u003c/script\u003e\n    \u003c/body\u003e\n\u003c/html\u003e\n","tags":""},{"id":"5772010","title":"Mocking a Window object for unit-testing purposes","content":"var mocks = {\n    resizeCalled: false,\n\n    createFakeWindow: function(width, height) {\n        var module = this;\n\n        return {\n            document: {\n                documentElement: {\n                    clientWidth: width,\n                    clientHeight: height\n                }\n            },\n\n            history: {\n                back: function(){}\n            },\n\n            location: {\n                replace: function(){}\n            },\n\n            resizeTo: function(width, height) {\n                this.document.documentElement = {\n                    clientWidth: width,\n                    clientHeight: height\n                };\n            }\n        };\n    },\n\n    fireResizeEvent: function() {\n        this.handler();\n    },\n\n    news: {\n        $: function(element) {\n            return {\n                on: function(event, handler) {\n                    if (event === 'resize') {\n                        mocks.resizeCalled = true;\n                    }\n                    \n                    mocks.handler = handler;\n                }\n            };\n        }\n    }\n};\n\nit('should bind to `resize` event on `init`', function(){\n    var fakeWindow = mocks.createFakeWindow(320, 480);\n\n    deviceInspector.init(fakeWindow, mocks.news);\n\n    expect(mocks.resizeCalled).toBeTruthy();\n});\n\nit('should only publish `device` event when device type changes', function(){\n    var fakeWindow = mocks.createFakeWindow(1008, 1024),\n        device     = deviceInspector.init(fakeWindow, mocks.news);\n\n    fakeWindow.resizeTo(960, 1024);\n    mocks.fireResizeEvent();\n\n    fakeWindow.resizeTo(320, 480);\n    mocks.fireResizeEvent();\n});\n\nit('should take the user back to the previous page in their history', function(){\n    var fakeWindow = mocks.createFakeWindow(),\n        fakeWindowHistoryBackSpy = sinon.spy(fakeWindow.history, 'back'),\n        fakeWindowLocationReplaceSpy = sinon.spy(fakeWindow.location, 'replace');\n\n    pictureViewer.init(fakeWindow);\n\n    $('.picture-viewer__button--back').trigger('click');\n\n    expect(fakeWindowHistoryBackSpy).toHaveBeenCalledOnce();\n    expect(fakeWindowLocationReplaceSpy).toHaveBeenCalledOnce();\n});\nfunction bindEvents() {\n    news.$(global).on('resize', handleResize);\n}\n\nfunction init(windowMock, newsMock) {\n    global   = windowMock || window;\n    news     = newsMock || newsModule;\n}\n","tags":""},{"id":"5774273","title":"Over engineered Sass...","content":"Below is a piece of Sass code which is ~50 lines of code.\n\nWhat it does...\n\n- Uses a Sass loop\n- Which uses Sass interpolation\n- Which also uses a Sass extend\n    - Which itself uses another Sass extends\n    - Which itself includes a Sass mixin\n- And also a native Sass function\n- And a custom Sass function (to do some calculations)\n \n...all this code (not to mention the mental stress it causes trying to decipher it) for effectively creating 7 unique classes.\n\nThat is just mental!\n\n```sass\n// Live icons\n// Usage: `.icon-email`, `.icon-tweet`… in HTML\n// Sprite: live-sprite.png\n\n// Space between the icons in the sprite\n$icon-spacing-in-sprite: 100px;\n\n// Space before the first icon\n$first-icon-vertical-offset: 8px;\n\n// Name of the class (usually the entry type)\n// followed by its position in the sprite\n// Usage: `(tweet, 0)` = First pictogram is a tweet icon\n$live-icons: (tweet,    0),\n             (email,    1),\n             (quote,    2),\n             (blog,     2),\n             (sms,      3),\n             (comment,  4),\n             (facebook, 5);\n\n\n// Abstraction for image replacement\n// Based on @necolas work and made\n// more robust for older browsers\n%image-replace {\n  display: block;\n  height: 0;\n  overflow: hidden;\n  text-indent: 150%;\n  font: normal 0/0 a;\n  color: transparent;\n}\n\n// Common rules for all live icons\n%live-icon {\n  @extend %image-replace;\n  width: 32px;\n  padding-top: 32px;\n  background: url('../../../img/live-sprite.png') no-repeat;\n  @include hidpi {\n    background-image: url('../../../img/live-sprite_x2.png');\n    background-size: 32px;\n  }\n}\n\n@function live-icon-background-position($i) {\n  @return $i * $icon-spacing-in-sprite * -1 - $first-icon-vertical-offset;\n}\n\n// Outputs all icon classes based on the $live-icons list\n// `.icon-tweet`, `.icon-email`\n@each $icon in $live-icons {\n  .icon-#{nth($icon, 1)} {\n    @extend %live-icon;\n    background-position: 0 live-icon-background-position(nth($icon, 2));\n  }\n}\n```\n","tags":""},{"id":"5763515","title":"S.O.L.I.D - (D)ependency Inversion. In the bad example, yes we're injecting our dependency but the Button class is now no longer reusable as it is too tightly coupled to the Lamp class. In the better example, we're still injecting our dependency but we now inverse the control via the use of an Interface. So now any `SwitchableDevice` can be used with the Button class.","content":"\u003c?php\nclass Lamp\n{\n    public function turnOn()\n    {\n        // code\n    }\n    \n    public function turnOff()\n    {\n        // code\n    }\n}\n\nclass Button\n{\n    private $lamp;\n    \n    public function __construct(Lamp $lamp)\n    {\n        $this-\u003elamp = $lamp;\n    }\n    \n    public function doSomething()\n    {\n        if (x) {\n            $this-\u003elamp-\u003eturnOn();\n        }\n    }\n}\n\u003c?php\ninterface SwitchableDevice\n{\n    public function turnOn();\n    public function turnOff();\n}\n\nclass Lamp implements SwitchableDevice\n{\n    public function turnOn()\n    {\n        // code\n    }\n    \n    public function turnOff()\n    {\n        // code\n    }\n}\n\nclass Button\n{\n    private $switchableDevice;\n    \n    public function __construct(SwitchableDevice $switchableDevice)\n    {\n        $this-\u003eswitchableDevice = $switchableDevice;\n    }\n    \n    public function doSomething()\n    {\n        if (x) {\n            $this-\u003eswitchableDevice-\u003eturnOn();\n        }\n    }\n}\n","tags":""},{"id":"5759057","title":"Avoid direct access to complex data structures, transform them to avoid problems when the structure changes","content":"class MyClass\n    attr_reader :data\n    \n    def initialize(data)\n        @data = data\n    end\n\n    def do_something\n        data.each do |item| \n            puts item[0]\n            puts item[1]\n            puts '---'\n        end\n    end\nend\n\nobj = MyClass.new([[10, 25],[3, 9],[41, 7]])\nobj.do_something\nclass MyClass\n    attr_reader :new_data\n    \n    def initialize(data)\n        @new_data = transform(data)\n    end\n\n    def do_something\n        new_data.each do |item| \n            # now we are able to reference easily understandable \n            # property names (rather than item[0], item[1])\n            puts item.coord_x\n            puts item.coord_y\n            puts '---'\n        end\n    end\n\n    Transform = Struct.new(:coord_x, :coord_y)\n    \n    def transform(data)\n        data.map { |item| Transform.new(item[0], item[1]) }\n    end\nend\n\nobj = MyClass.new([[10, 25],[3, 9],[41, 7]])\nobj.do_something\n","tags":""},{"id":"5755078","title":"S.O.L.I.D - (O)pen/Closed Principle","content":"\u003c?php\nnamespace Library\\View;\n\nclass HtmlDiv\n{\n    private $text;\n    private $id;\n    private $class;\n\n    public function __construct($text, $id = null, $class = null) {\n        $this-\u003esetText($text);\n        if ($id !== null) {\n            $this-\u003esetId($id);\n        }\n        if ($class !== null) {\n            $this-\u003esetClass($class);\n        }\n    }\n\n    public function setText($text) {\n        if (!is_string($text) || empty($text)) {\n            throw new \\InvalidArgumentException(\n                \"The text of the element is invalid.\");\n        }\n        $this-\u003etext = $text;\n        return $this;\n    }\n\n    public function setId($id) {\n        if (!preg_match('/^[a-z0-9_-]+$/', $id)) {\n            throw new \\InvalidArgumentException(\n                 \"The attribute value is invalid.\");\n        }\n        $this-\u003eid = $id;\n        return $this;     \n    }\n\n    public function setClass($class) {\n        if (!preg_match('/^[a-z0-9_-]+$/', $id)) {\n            throw new \\InvalidArgumentException(\n                 \"The attribute value is invalid.\");\n        }\n        $this-\u003eclass = $class;\n        return $this;     \n    }\n\n    public function renderDiv() {\n        return '\u003cdiv' .\n            ($this-\u003eid ? ' id=\"' . $this-\u003eid . '\"' : '') .\n            ($this-\u003eclass ? ' class=\"' . $this-\u003eclass . '\"' : '') .\n            '\u003e' . $this-\u003etext . '\u003c/div\u003e';\n    }\n}\n\n/////////////////////////////////////////////////////////////////////\n\n\u003c?php\nnamespace Library\\View;\n\nclass HtmlParagraph\n{\n    private $text;\n    private $id;\n    private $class;\n\n    public function __construct($text, $id = null, $class = null) {\n        $this-\u003esetText($text);\n        if ($id !== null) {\n            $this-\u003esetId($id);\n        }\n        if ($class !== null) {\n            $this-\u003esetClass($class);\n        }\n    }\n\n    public function setText($text) {\n        if (!is_string($text) || empty($text)) {\n            throw new \\InvalidArgumentException(\n                \"The text of the element is invalid.\");\n        }\n        $this-\u003etext = $text;\n        return $this;\n    }\n\n    public function setId($id) {\n        if (!preg_match('/^[a-z0-9_-]+$/', $id)) {\n            throw new \\InvalidArgumentException(\n                 \"The attribute value is invalid.\");\n        }\n        $this-\u003eid = $id;\n        return $this;     \n    }\n\n    public function setClass($class) {\n        if (!preg_match('/^[a-z0-9_-]+$/', $id)) {\n            throw new \\InvalidArgumentException(\n                 \"The attribute value is invalid.\");\n        }\n        $this-\u003eclass = $class;\n        return $this;     \n    }\n\n    public function renderParagraph() {\n        return '\u003cp' .\n            ($this-\u003eid ? ' id=\"' . $this-\u003eid . '\"' : '') .\n            ($this-\u003eclass ? ' class=\"' . $this-\u003eclass . '\"' : '') .\n            '\u003e' . $this-\u003etext . '\u003c/p\u003e';\n    }\n}\n\n/////////////////////////////////////////////////////////////////////\n\n\u003c?php\nnamespace Library\\View;\n\nclass HtmlRenderer\n{\n    private $elements = array();\n\n    public function __construct(array $elements = array()) {\n        if (!empty($elements)) {\n            $this-\u003eaddElements($elements);\n        }\n    }\n\n    public function addElement($element) {\n        $this-\u003eelements[] = $element;\n        return $this;\n    }\n\n    public function addElements(array $elements) {\n        foreach ($elements as $element) {\n            $this-\u003eaddElement($element);\n        }\n        return $this;\n    }\n\n    public function render() {\n        $html = \"\";\n        \n        // IF WE FORCE OURSELVES TO NOT TOUCH THIS FILE AGAIN (CLOSED FOR MODIFICATION)\n        // THEN HOW DO WE MAKE IT \"OPEN FOR EXTENSION\" (SO WE DON'T HAVE TO ADD MORE 'if' CONDITIONALS)?\n        foreach ($this-\u003eelements as $element) {\n            if ($element instanceof HtmlDiv) {\n                $html .= $element-\u003erenderDiv();\n            }\n            else if ($element instanceof HtmlParagraph) {\n                $html .= $element-\u003erenderParagraph();\n            }\n        }\n        \n        return $html;\n    }\n}\n\u003c?php\n\n// THE SOLUTION IS TO USE POLYMORPHISM AND INTERFACES TO BUILD A CONTRACT\n// FOR OUR CLASSES TO ABIDE TO AND THEN THE 'HtmlRender' CLASS CAN TRUST LOOPING\n// THROUGH ALL ADDED ELEMENTS AS THEY HAVE TO ABIDE BY THE INTERFACE CONTRACT\n\nnamespace Library\\View;\n\ninterface HtmlElementInterface\n{\n    public function render();\n}\n\n/////////////////////////////////////////////////////////////////////\n\n\u003c?php\nnamespace Library\\View;\n\nabstract class AbstractHtmlElement implements HtmlElementInterface\n{\n    protected $text;\n    protected $id;\n    protected $class;\n\n    public function __construct($text, $id = null, $class = null) {\n        $this-\u003esetText($text);\n        if ($id !== null) {\n            $this-\u003esetId($id);\n        }\n        if ($class !== null) {\n            $this-\u003esetClass($class);\n        }\n    }\n\n    public function setText($text) {\n        if (!is_string($text) || empty($text)) {\n            throw new \\InvalidArgumentException(\n                \"The text of the element is invalid.\");\n        }\n        $this-\u003etext = $text;\n        return $this;\n    }\n\n    public function setId($id) {\n        $this-\u003echeckAttribute($id);\n        $this-\u003eid = $id;\n        return $this;     \n    }\n\n    public function setClass($class) {\n        $this-\u003echeckAttribute($class);\n        $this-\u003eclass = $class;\n        return $this;     \n    }\n\n    protected function checkAttribute($value) {\n        if (!preg_match('/^[a-z0-9_-]+$/', $value)) {\n            throw new \\InvalidArgumentException(\n                \"The attribute value is invalid.\");\n        }\n    }\n}\n\n/////////////////////////////////////////////////////////////////////\n\n\u003c?php\nnamespace Library\\View;\n\nclass HtmlDiv extends AbstractHtmlElement\n{    \n    public function render() {\n        return '\u003cdiv' .\n            ($this-\u003eid ? ' id=\"' . $this-\u003eid . '\"' : '') .\n            ($this-\u003eclass ? ' class=\"' . $this-\u003eclass . '\"' : '') .\n            '\u003e' . $this-\u003etext . '\u003c/div\u003e';\n    }\n}\n\n/////////////////////////////////////////////////////////////////////\n\n\u003c?php\nnamespace Library\\View;\n\nclass HtmlParagraph extends AbstractHtmlElement\n{    \n    public function render() {\n        return '\u003cp' .\n            ($this-\u003eid ? ' id=\"' . $this-\u003eid . '\"' : '') .\n            ($this-\u003eclass ? ' class=\"' . $this-\u003eclass . '\"' : '') .\n            '\u003e' . $this-\u003etext . '\u003c/p\u003e';\n    }\n}\n\n/////////////////////////////////////////////////////////////////////\n\n\u003c?php\nnamespace Library\\View;\n\nclass HtmlRenderer\n{\n    private $elements = array();\n\n    public function __construct(array $elements = array()) {\n        if (!empty($elements)) {\n            $this-\u003eaddElements($elements);\n        }\n    }\n\n    public function addElement(HtmlElementInterface $element) {\n        $this-\u003eelements[] = $element;\n        return $this;\n    }\n\n    public function addElements(array $elements) {\n        foreach ($elements as $element) {\n            $this-\u003eaddElement($element);\n        }\n        return $this;\n    }\n\n    public function render() {\n        $html = \"\";\n        \n        // NOW THIS IS CLOSED FOR MODIFICATION\n        // BUT DEFINITELY OPEN FOR EXTENSION BY ANY CLASS THAT IMPLEMENTS THE 'render' METHOD\n        foreach ($this-\u003eelements as $element) {\n            $html .= $element-\u003erender();\n        }\n        \n        return $html;\n    }\n}\n\n/////////////////////////////////////////////////////////////////////\n\n\u003c?php\nuse Library\\Loader\\Autoloader,\n    Library\\View\\HtmlDiv,\n    Library\\View\\HtmlParagraph,\n    Library\\View\\HtmlRenderer;\n\nrequire_once __DIR__ . \"/Library/Loader/Autoloader.php\";\n$autoloader = new Autoloader();\n$autoloader-\u003eregister();\n\n$div = new HtmlDiv(\"This is the text of the div.\", \"dID\", \"dClass\");\n\n$p = new HtmlParagraph(\"This is the text of the paragraph.\", \"pID\", \"pClass\");\n\n$renderer = new HtmlRenderer(array($div, $p));\necho $renderer-\u003erender();\n","tags":""},{"id":"5755677","title":"Need help watching/compiling multiple Sass files in a project with a awkward folder structure...","content":"## Directory structure\n\n- Sass\n  - x\n      - module.scss\n      - module.scss\n  - y\n      - module.scss\n      - module.scss\n  - z\n      - module.scss\n      - module.scss\n  - services\n      - language a\n          - module.scss\n          - module.scss\n      - language b\n          - module.scss\n          - module.scss\n      - language c \n          - module.scss\n          - module.scss\n\n## The problem\n\nThere is a team for each language service. They don't want to do a standard \"watch/compile all the sass files\" because there are so many, it takes about a minute to compile them all (that's for every little change they make).\n\nSo we want to allow them to watch for changes to just their specific language files and watch any files that are imported into those language files.\n\nThe first part is easy enough, we can set-up a watch for each language service, but the Sass watch only picks up changes to those language files, not any of the changes made to other Sass files that are imported into the language files.\n\n## The solution I have currently...\n\nBased on the above issue, I have set-up some Grunt watch sub tasks that say \"watch all directories, but ignore these other specifically named directories\" (you can see this in my Gruntfile example below). So when any Sass files are changed, we then call the appropriate sass sub task. \n\nSo for example if we run `grunt watch:arabic` then any changes to any Sass files (excluding any Sass files from inside a language directory which isn't arabic) will cause the `sass:arabic` sub task to run.\n\nThe problem with this solution is it isn't scalable. Every new language requires a developer to remember to edit/update the Gruntfile and then to re-update each of the Watch sub tasks so they include the new language directory be ignored (for the other languages already present).\n\n## Summary of things we want to achieve\n\nI want to find a solution to my problem (one that is scalable and automated)\n\nPersonally I was thinking something along the lines of finding a way to dynamically generate Grunt sub tasks based on the folders within our /services/ directory -\u003e but this means that the Gruntfile.js would need to have a task that is run on a regular basis to refresh that I'm guessing? But this just sounds like the totally wrong way of solving the problem.\n\n## My current Grunt file (that I would like to refactor)\n\n```js\nmodule.exports = function (grunt) {\n\n    grunt.initConfig({\n\n        pkg: grunt.file.readJSON('package.json'),\n\n        dir: {\n            static: './tabloid/webapp/static/',\n            static_sass: '\u003c%= dir.static %\u003e' + 'sass/',\n            static_css: '\u003c%= dir.static %\u003e' + 'stylesheets/'\n        },\n\n        sass: {\n            news: {\n                options: {\n                    style: 'expanded',\n                    debugInfo: true,\n                    lineNumbers: true,\n                    require: ['\u003c%= dir.static_sass %\u003ehelpers/url64.rb']\n                },\n                expand: true,\n                cwd: '\u003c%= dir.static_sass %\u003e/services/news',\n                src: ['*.scss'],\n                dest: '\u003c%= dir.static_css %\u003e/services/news',\n                ext: '.css'\n            },\n            afrique: { /* effectively repeat the above 'news' property (but change directory to compile) */ },\n            arabic: { /* effectively repeat the above 'news' property (but change directory to compile) */ },\n            hausa: { /* effectively repeat the above 'news' property (but change directory to compile) */ },\n            hindi: { /* effectively repeat the above 'news' property (but change directory to compile) */ },\n            indonesia: { /* effectively repeat the above 'news' property (but change directory to compile) */ },\n            mundo: { /* effectively repeat the above 'news' property (but change directory to compile) */ },\n            newyddion: { /* effectively repeat the above 'news' property (but change directory to compile) */ },\n            russian: { /* effectively repeat the above 'news' property (but change directory to compile) */ }\n        },\n\n        watch: {\n            afrique: {\n                files: ['\u003c%= dir.static_sass %\u003e**/*.scss', \n                        '!\u003c%= dir.static_sass %\u003eservices/arabic/*.scss',\n                        '!\u003c%= dir.static_sass %\u003eservices/hausa/*.scss',\n                        '!\u003c%= dir.static_sass %\u003eservices/hindi/*.scss',\n                        '!\u003c%= dir.static_sass %\u003eservices/indonesia/*.scss',\n                        '!\u003c%= dir.static_sass %\u003eservices/mundo/*.scss',\n                        '!\u003c%= dir.static_sass %\u003eservices/news/*.scss',\n                        '!\u003c%= dir.static_sass %\u003eservices/newyddion/*.scss',\n                        '!\u003c%= dir.static_sass %\u003eservices/russian/*.scss'],\n                tasks: ['news']\n            },\n            arabic: {\n                files: ['\u003c%= dir.static_sass %\u003e**/*.scss', \n                        '!\u003c%= dir.static_sass %\u003eservices/afrique/*.scss',\n                        '!\u003c%= dir.static_sass %\u003eservices/hausa/*.scss',\n                        '!\u003c%= dir.static_sass %\u003eservices/hindi/*.scss',\n                        '!\u003c%= dir.static_sass %\u003eservices/indonesia/*.scss',\n                        '!\u003c%= dir.static_sass %\u003eservices/mundo/*.scss',\n                        '!\u003c%= dir.static_sass %\u003eservices/news/*.scss',\n                        '!\u003c%= dir.static_sass %\u003eservices/newyddion/*.scss',\n                        '!\u003c%= dir.static_sass %\u003eservices/russian/*.scss'],\n                tasks: ['news']\n            },\n            hausa: {\n                files: ['\u003c%= dir.static_sass %\u003e**/*.scss', \n                        '!\u003c%= dir.static_sass %\u003eservices/afrique/*.scss',\n                        '!\u003c%= dir.static_sass %\u003eservices/arabic/*.scss',\n                        '!\u003c%= dir.static_sass %\u003eservices/hindi/*.scss',\n                        '!\u003c%= dir.static_sass %\u003eservices/indonesia/*.scss',\n                        '!\u003c%= dir.static_sass %\u003eservices/mundo/*.scss',\n                        '!\u003c%= dir.static_sass %\u003eservices/news/*.scss',\n                        '!\u003c%= dir.static_sass %\u003eservices/newyddion/*.scss',\n                        '!\u003c%= dir.static_sass %\u003eservices/russian/*.scss'],\n                tasks: ['news']\n            },\n            hindi: {\n                files: ['\u003c%= dir.static_sass %\u003e**/*.scss', \n                        '!\u003c%= dir.static_sass %\u003eservices/afrique/*.scss',\n                        '!\u003c%= dir.static_sass %\u003eservices/arabic/*.scss',\n                        '!\u003c%= dir.static_sass %\u003eservices/hausa/*.scss',\n                        '!\u003c%= dir.static_sass %\u003eservices/indonesia/*.scss',\n                        '!\u003c%= dir.static_sass %\u003eservices/mundo/*.scss',\n                        '!\u003c%= dir.static_sass %\u003eservices/news/*.scss',\n                        '!\u003c%= dir.static_sass %\u003eservices/newyddion/*.scss',\n                        '!\u003c%= dir.static_sass %\u003eservices/russian/*.scss'],\n                tasks: ['news']\n            },\n            indonesia: {\n                files: ['\u003c%= dir.static_sass %\u003e**/*.scss', \n                        '!\u003c%= dir.static_sass %\u003eservices/afrique/*.scss',\n                        '!\u003c%= dir.static_sass %\u003eservices/arabic/*.scss',\n                        '!\u003c%= dir.static_sass %\u003eservices/hausa/*.scss',\n                        '!\u003c%= dir.static_sass %\u003eservices/hindi/*.scss',\n                        '!\u003c%= dir.static_sass %\u003eservices/mundo/*.scss',\n                        '!\u003c%= dir.static_sass %\u003eservices/news/*.scss',\n                        '!\u003c%= dir.static_sass %\u003eservices/newyddion/*.scss',\n                        '!\u003c%= dir.static_sass %\u003eservices/russian/*.scss'],\n                tasks: ['news']\n            },\n            mundo: {\n                files: ['\u003c%= dir.static_sass %\u003e**/*.scss', \n                        '!\u003c%= dir.static_sass %\u003eservices/afrique/*.scss',\n                        '!\u003c%= dir.static_sass %\u003eservices/arabic/*.scss',\n                        '!\u003c%= dir.static_sass %\u003eservices/hausa/*.scss',\n                        '!\u003c%= dir.static_sass %\u003eservices/hindi/*.scss',\n                        '!\u003c%= dir.static_sass %\u003eservices/indonesia/*.scss',\n                        '!\u003c%= dir.static_sass %\u003eservices/news/*.scss',\n                        '!\u003c%= dir.static_sass %\u003eservices/newyddion/*.scss',\n                        '!\u003c%= dir.static_sass %\u003eservices/russian/*.scss'],\n                tasks: ['news']\n            },\n            news: {\n                files: ['\u003c%= dir.static_sass %\u003e**/*.scss', \n                        '!\u003c%= dir.static_sass %\u003eservices/afrique/*.scss',\n                        '!\u003c%= dir.static_sass %\u003eservices/arabic/*.scss',\n                        '!\u003c%= dir.static_sass %\u003eservices/hausa/*.scss',\n                        '!\u003c%= dir.static_sass %\u003eservices/hindi/*.scss',\n                        '!\u003c%= dir.static_sass %\u003eservices/indonesia/*.scss',\n                        '!\u003c%= dir.static_sass %\u003eservices/mundo/*.scss',\n                        '!\u003c%= dir.static_sass %\u003eservices/newyddion/*.scss',\n                        '!\u003c%= dir.static_sass %\u003eservices/russian/*.scss'],\n                tasks: ['news']\n            },\n            newyddion: {\n                files: ['\u003c%= dir.static_sass %\u003e**/*.scss', \n                        '!\u003c%= dir.static_sass %\u003eservices/afrique/*.scss',\n                        '!\u003c%= dir.static_sass %\u003eservices/arabic/*.scss',\n                        '!\u003c%= dir.static_sass %\u003eservices/hausa/*.scss',\n                        '!\u003c%= dir.static_sass %\u003eservices/hindi/*.scss',\n                        '!\u003c%= dir.static_sass %\u003eservices/indonesia/*.scss',\n                        '!\u003c%= dir.static_sass %\u003eservices/mundo/*.scss',\n                        '!\u003c%= dir.static_sass %\u003eservices/news/*.scss',\n                        '!\u003c%= dir.static_sass %\u003eservices/russian/*.scss'],\n                tasks: ['news']\n            },\n            russian: {\n                files: ['\u003c%= dir.static_sass %\u003e**/*.scss', \n                        '!\u003c%= dir.static_sass %\u003eservices/afrique/*.scss',\n                        '!\u003c%= dir.static_sass %\u003eservices/arabic/*.scss',\n                        '!\u003c%= dir.static_sass %\u003eservices/hausa/*.scss',\n                        '!\u003c%= dir.static_sass %\u003eservices/hindi/*.scss',\n                        '!\u003c%= dir.static_sass %\u003eservices/indonesia/*.scss',\n                        '!\u003c%= dir.static_sass %\u003eservices/mundo/*.scss',\n                        '!\u003c%= dir.static_sass %\u003eservices/news/*.scss',\n                        '!\u003c%= dir.static_sass %\u003eservices/newyddion/*.scss'],\n                tasks: ['news']\n            }\n        }\n\n    });\n\n    // Load NPM Tasks\n    grunt.loadNpmTasks('grunt-contrib-watch');\n    grunt.loadNpmTasks('grunt-contrib-sass');\n\n        // Afrique Task\n        grunt.registerTask('afrique', ['sass:afrique']);\n\n        // Arabic Task\n        grunt.registerTask('arabic', ['sass:arabic']);\n\n        // Hausa Task\n        grunt.registerTask('hausa', ['sass:hausa']);\n\n        // Hindi Task\n        grunt.registerTask('hindi', ['sass:hindi']);\n\n        // Indonesia Task\n        grunt.registerTask('indonesia', ['sass:indonesia']);\n\n        // Mundo Task\n        grunt.registerTask('mundo', ['sass:mundo']);\n\n        // News Task\n        grunt.registerTask('news', ['sass:news']);\n\n        // Newyddion Task\n        grunt.registerTask('newyddion', ['sass:newyddion']);\n\n        // Russian Task\n        grunt.registerTask('russian', ['sass:russian']);\n\n};\n```\n","tags":""},{"id":"5755008","title":"S.O.L.I.D - (S)ingle Responsibility Principle","content":"\u003c?php\nnamespace Model;\n\ninterface UserInterface\n{\n    public function setId($id);\n    public function getId();\n\n    public function setName($name);\n    public function getName();\n\n    public function setEmail($email);\n    public function getEmail();\n    public function getGravatar();\n\n    public function findById($id);\n    public function insert();\n    public function update();\n    public function delete();\n}\n\n////////////////////////////////////////////////////////////////////////////////////\n\n\u003c?php\nnamespace Model;\n\nuse Library\\Database\\DatabaseAdapterInterface;\n\nclass User implements UserInterface\n{\n    private $id;\n    private $name;\n    private $email;\n    private $db;\n    private $table = \"users\";\n\n    public function __construct(DatabaseAdapterInterface $db) {\n        $this-\u003edb = $db;\n    }\n\n    public function setId($id) {\n        if ($this-\u003eid !== null) {\n            throw new \\BadMethodCallException(\"The user ID has been set already.\");\n        }\n        \n        if (!is_int($id) || $id \u003c 1) {\n            throw new \\InvalidArgumentException(\"The user ID is invalid.\");\n        }\n        \n        $this-\u003eid = $id;\n        \n        return $this;\n    }\n    \n    public function getId() {\n        return $this-\u003eid;\n    }\n    \n    public function setName($name) {\n        if (strlen($name) \u003c 2 || strlen($name) \u003e 30) {\n            throw new \\InvalidArgumentException(\"The user name is invalid.\");\n        }\n        \n        $this-\u003ename = $name;\n        \n        return $this;\n    }\n    \n    public function getName() {\n        if ($this-\u003ename === null) {\n            throw new \\UnexpectedValueException(\"The user name has not been set.\");\n        }\n        \n        return $this-\u003ename;\n    }\n\n    public function setEmail($email) {\n        if (!filter_var($email, FILTER_VALIDATE_EMAIL)) {\n            throw new \\InvalidArgumentException(\"The user email is invalid.\");\n        }\n        \n        $this-\u003eemail = $email;\n        \n        return $this;\n    }\n    \n    public function getEmail() {\n        if ($this-\u003eemail === null) {\n            throw new \\UnexpectedValueException(\"The user email has not been set.\");\n        }\n        return $this-\u003eemail;\n    }\n    \n    public function getGravatar($size = 70, $default = \"monsterid\") {\n        return \"http://www.gravatar.com/avatar/\" .\n            md5(strtolower($this-\u003egetEmail())) .\n            \"?s=\" . (integer) $size .\n            \"\u0026d=\" . urlencode($default) .\n            \"\u0026r=G\";\n    }\n    \n    public function findById($id) {\n        $this-\u003edb-\u003eselect($this-\u003etable, [\"id\" =\u003e $id]);\n        \n        if (!$row = $this-\u003edb-\u003efetch()) {\n            return null;\n        }\n        \n        $user = new User($this-\u003edb);\n        $user-\u003esetId($row[\"id\"])\n             -\u003esetName($row[\"name\"])\n             -\u003esetEmail($row[\"email\"]);\n        \n        return $user;\n    }\n    \n    public function insert() {\n        $this-\u003edb-\u003einsert($this-\u003etable, [\n            \"name\"  =\u003e $this-\u003egetName(), \n            \"email\" =\u003e $this-\u003egetEmail()\n        ]);\n    }\n    \n    public function update() {\n        $this-\u003edb-\u003eupdate($this-\u003etable, [\n                \"name\"  =\u003e $this-\u003egetName(), \n                \"email\" =\u003e $this-\u003egetEmail()], \n            \"id = {$this-\u003eid}\");\n    }\n\n    public function delete() {\n        $this-\u003edb-\u003edelete($this-\u003etable, \"id = {$this-\u003eid}\");\n    }\n}\n\u003c?php\nnamespace Mapper;\nuse Model\\UserInterface;\n\ninterface UserMapperInterface\n{\n    public function findById($id);\n    public function insert(UserInterface $user);\n    public function update(UserInterface $user);\n    public function delete($id);\n}\n\n////////////////////////////////////////////////////////////////////////////////////\n\n\u003c?php\nnamespace Mapper;\nuse Library\\Database\\DatabaseAdapterInterface,\n    Model\\UserInterface,\n    Model\\User;\n\nclass UserMapper implements UserMapperInterface\n{\n    private $db;\n    private $table = \"users\";\n    \n    public function __construct(DatabaseAdapterInterface $db) {\n        $this-\u003edb = $db;\n    }\n    \n    public function findById($id) {\n        $this-\u003edb-\u003eselect($this-\u003etable, [\"id\" =\u003e $id]);\n        \n        if (!$row = $this-\u003edb-\u003efetch()) {\n            return null;\n        }\n        \n        return $this-\u003eloadUser($row);\n    }\n    \n    public function insert(UserInterface $user) {\n        return $this-\u003edb-\u003einsert($this-\u003etable, [\n            \"name\"  =\u003e $user-\u003egetName(), \n            \"email\" =\u003e $user-\u003egetEmail()\n        ]);\n    }\n    \n    public function update(UserInterface $user) {\n        return $this-\u003edb-\u003eupdate($this-\u003etable, [\n            \"name\"  =\u003e $user-\u003egetName(), \n            \"email\" =\u003e $user-\u003egetEmail()\n        ], \n        \"id = {$user-\u003egetId()}\");\n    }\n    \n    public function delete($id) {\n        if ($id instanceof UserInterface) {\n            $id = $id-\u003egetId();\n        }\n        \n        return $this-\u003edb-\u003edelete($this-\u003etable, \"id = $id\");\n    }\n    \n    private function loadUser(array $row) {\n        $user = new User($row[\"name\"], $row[\"email\"]);\n        $user-\u003esetId($row[\"id\"]);\n        return $user;\n    }\n}\n\n////////////////////////////////////////////////////////////////////////////////////\n\n\u003c?php\nnamespace Model;\n\ninterface UserInterface\n{\n    public function setId($id);\n    public function getId();\n\n    public function setName($name);\n    public function getName();\n\n    public function setEmail($email);\n    public function getEmail();\n    public function getGravatar();\n}\n\n////////////////////////////////////////////////////////////////////////////////////\n\n\u003c?php\nnamespace Model;\n\nclass User implements UserInterface\n{\n    private $id;\n    private $name;\n    private $email;\n\n    public function __construct($name, $email) {\n        $this-\u003esetName($name);\n        $this-\u003esetEmail($email);\n    }\n    \n    public function setId($id) {\n        if ($this-\u003eid !== null) {\n            throw new \\BadMethodCallException(\"The user ID has been set already.\");\n        }\n        \n        if (!is_int($id) || $id \u003c 1) {\n            throw new \\InvalidArgumentException(\"The user ID is invalid.\");\n        }\n        \n        $this-\u003eid = $id;\n        \n        return $this;\n    }\n    \n    public function getId() {\n        return $this-\u003eid;\n    }\n    \n    public function setName($name) {\n        if (strlen($name) \u003c 2 || strlen($name) \u003e 30) {\n            throw new \\InvalidArgumentException(\"The user name is invalid.\");\n        }\n        \n        $this-\u003ename = $name;\n        \n        return $this;\n    }\n    \n    public function getName() {\n        return $this-\u003ename;\n    }\n\n    public function setEmail($email) {\n        if (!filter_var($email, FILTER_VALIDATE_EMAIL)) {\n            throw new \\InvalidArgumentException(\"The user email is invalid.\");\n        }\n        \n        $this-\u003eemail = $email;\n        \n        return $this;\n    }\n    \n    public function getEmail() {\n        return $this-\u003eemail;\n    }\n     \n    public function getGravatar($size = 70, $default = \"monsterid\") {\n        return \"http://www.gravatar.com/avatar/\" .\n            md5(strtolower($this-\u003eemail)) .\n            \"?s=\" . (integer) $size .\n            \"\u0026d=\" . urlencode($default) .\n            \"\u0026r=G\";\n    }\n}\n\n////////////////////////////////////////////////////////////////////////////////////\n\n\u003c?php\n$db = new PdoAdapter(\"mysql:dbname=test\", \"myusername\",\n    \"mypassword\");\n$userMapper = new UserMapper($db);\n\n// Display user data\n$user = $userMapper-\u003efindById(1);\necho $user-\u003egetName() . ' ' . $user-\u003egetEmail() .\n    '\u003cimg src=\"' . $user-\u003egetGravatar() . '\"\u003e';\n\n// Insert a new user\n$user = new User(\"John Doe\", \"john@example.com\");\n$userMapper-\u003einsert($user);\n\n// Update a user\n$user = $userMapper-\u003efindById(2);\n$user-\u003esetName(\"Jack\");\n$userMapper-\u003eupdate($user);\n\n// Delete a user    \n$userMapper-\u003edelete(3); \n","tags":""},{"id":"5541500","title":"There are a couple of different ways to `require` a module using RequireJS","content":"```js\nrequire(['module-cjs-sugared-form', 'standard', 'async-callback'], function(a, b, c) {\n    console.log('main page (a):', a);\n    console.log('main page (b):', b, b.a, b.b);\n    console.log('main page (c):', c);\n});\n```\n\nCJS Sugared Version...\n\n```js\ndefine(function(require) {\n    var a = require('a');\n    console.log('cjs:', a);\n    return a;\n});\n```\n\nThe above converts internally to the standard AMD format...\n\n```js\ndefine(['require', 'a'], function(require) {\n    var a = require('a'); // sync call, but module already loaded\n    console.log(a);\n});\n```\n\n...this conversion happens whenever no dependency list is specified.\n\nRequireJS will see no dependencies specified and then start scanning for `require('some-string')` instead and do the conversion using any it finds as dependencies.\n\nSo `require('a')` will returned the already loaded dependency 'a' as a cached module.\n\nThe following would cause an error because the module hasn't been loaded...\n\n```js\ndefine(['a'], function(a) {\n    var b = require('b'); // would cause an error -\u003e not loaded yet for context\n    return {\n        a: a,\n        b: b\n    };\n});\n```\n\nThe following is an asynchronous loading mechanism...\n\n```js\ndefine(['require', 'a'], function(require, a) {\n    var b = require(['b'], function(b) {\n        console.log('b callback', b);\n    });\n\n    return {\n        a: a,\n        b: b\n    };\n});\n```\n","tags":""},{"id":"5575743","title":"Example of a r.js build script for AMD formatted modules loaded using RequireJS","content":"/*\n  https://github.com/jrburke/r.js/blob/master/build/example.build.js\n  \n  node r.js -o app.build.js\n*/\n({  \n    // \n    appDir: './',\n    \n    // \n    baseUrl: './js',\n    \n    // output directory\n    dir: './dist',\n    \n    // modules to optimise\n    modules: [\n        {\n            name: 'main'\n            /*\n            include: ['module'],\n            exclude: ['module']\n            */\n        }\n    ],\n    \n    // files/directories matched aren't copied to output directory\n    fileExclusionRegExp: /^(r|build)\\.js$/,\n    \n    // “uglify” (default), “uglify2”, “closure”, “closure.keepLines”, “none”\n    optimize: 'none',\n    \n    // “none”, “standard”, “standard.keepLines”, “standard.keepComments”, “standard.keepComments.keepLines”\n    optimizeCss: 'none',\n    \n    // removes concatenated files from the output directory\n    removeCombined: true,\n    \n    // relative paths of modules (relative to baseUrl)\n    paths: {\n        jquery: 'lib/jquery',\n        underscore: 'lib/underscore',\n        backbone: 'lib/backbone/backbone',\n        backboneLocalstorage: 'lib/backbone/backbone.localStorage',\n        text: 'lib/require/text'\n    },\n    \n    // dependencies and exports for “browser globals” scripts, that do not use define() to declare the dependencies and set a module value\n    shim: {\n        underscore: {\n            exports: '_'\n        },\n        backbone: {\n            deps: [\n                'underscore',\n                'jquery'\n            ],\n            exports: 'Backbone'\n        },\n        backboneLocalstorage: {\n            deps: ['backbone'],\n            exports: 'Store'\n        }\n    }\n})\n","tags":""},{"id":"5458681","title":"Using RequireJS, switch from jQuery 2.0 down to 1.9.1","content":"```js\nrequire.config({\n    baseUrl: './',\n    paths: {\n      'jquery': 'libs/jquery-2.0.js',\n      'jquery-1.9.1': 'libs/jquery-1.9.1.js'\n    }\n});\n\nif (isIE) { // https://github.com/Integralist/Robur/blob/master/Assets/Scripts/Utils/Checks/isIE.js\n  require.config({\n    map: {\n        // Any module in our application that sets `jquery` as a dependency, map the request to `jquery-1.9.1` instead\n        '*': {\n            'jquery': 'jquery-1.9.1'\n        }\n    }\n  });\n}\n```\n","tags":""},{"id":"5442770","title":"Ruby 1.8.7 doesn't support regular expression lookbehind assertions -\u003e so this example mimicks it using lookaheads and some trickery. Basically the solution is to reverse your content and lookahead for the items you want to avoid or include.","content":"tag = 'article'\n\ntext_class = '.article {'\ntext_element = 'article {'\n\nputs text_element.reverse.gsub(%r/#{tag.reverse}(?![.#])/oi, \"div.HTML5#{tag}\".reverse).reverse\nputs text_class.reverse.gsub(%r/#{tag.reverse}(?![.#])/oi, \"div.HTML5#{tag}\".reverse).reverse\nputs '.some_text article .something_else {'.reverse.gsub(%r/#{tag.reverse}(?![.#])/oi, \"div.HTML5#{tag}\".reverse).reverse\n\n# changes (as expected)\n# div.HTML5article {\n\n# leaves alone (perfect)\n# .article {\n\n# changes (as expected) \n# .some_text div.HTML5article .something_else {\n","tags":""},{"id":"5433330","title":"PHP Reflection Example","content":"# http://net.tutsplus.com/tutorials/php/reflection-in-php/\n\nclass Some_TestCase extends PHPUnit_Framework_TestCase\n{\n    public function reflectValueIntoObject($object, $name, $value)\n    {\n        $refObject = new ReflectionObject($object);\n        $refProperty = $refObject-\u003egetProperty($name);\n        $refProperty-\u003esetAccessible(true);\n        $refProperty-\u003esetValue(\n            $object,\n            $value\n        ); # I find it so odd that we can call `setValue` on a property but the method needs the property's object to be specified?\n    }\n}\n\n","tags":""},{"id":"5736427","title":"Strategy Design Pattern in JavaScript","content":"// Greeter is a class of object that can greet people.\n// It can learn different ways of greeting people through\n// 'Strategies.'\n//\n// This is the Greeter constructor.\nvar Greeter = function(strategy) {\n  this.strategy = strategy;  \n};\n \n// Greeter provides a greet function that is going to\n// greet people using the Strategy passed to the constructor.\nGreeter.prototype.greet = function() {\n  return this.strategy();\n};\n \n// Since a function encapsulates an algorithm, it makes a perfect\n// candidate for a Strategy.\n//\n// Here are a couple of Strategies to use with our Greeter.\nvar politeGreetingStrategy = function() {\n console.log(\"Hello.\"); \n};\n \nvar friendlyGreetingStrategy = function() {\n  console.log(\"Hey!\");\n};\n \nvar boredGreetingStrategy = function() {\n  console.log(\"sup.\");\n};\n \n// Let's use these strategies!\nvar politeGreeter   = new Greeter(politeGreetingStrategy);\nvar friendlyGreeter = new Greeter(friendlyGreetingStrategy);\nvar boredGreeter    = new Greeter(boredGreetingStrategy);\n \npoliteGreeter.greet();   //=\u003e Hello.\nfriendlyGreeter.greet(); //=\u003e Hey!\nboredGreeter.greet();    //=\u003e sup.\n","tags":""},{"id":"5396881","title":"PubSub in JavaScript","content":"define(function(){\n\n    var doc = document;\n    var topics = {};\n    var id = -1;\n    var pubsub = {};\n\n    pubsub.subscribe =  function (topic, fn) {\n        if (!topics[topic]) {\n            topics[topic] = [];\n        }\n\n        var token = (++id).toString();\n\n        topics[topic].push({\n            token: token,\n            fn: fn\n        });\n\n        return token;\n    };\n\n    pubsub.unsubscribe =  function (token) {\n        for (var m in topics) {\n            if (topics[m]) {\n                for (var i = 0, j = topics[m].length; i \u003c j; i++) {\n                    if (topics[m][i].token === token) {\n                        topics[m].splice(i, 1);\n\n                        return token;\n                    }\n                }\n            }\n        }\n\n        return false;\n    };\n\n    pubsub.publish =  function (topic, data) {\n        if (!topics[topic]) {\n            return false;\n        }\n\n        setTimeout(function(){\n            var subscribers = topics[topic],\n\n            len = topics[topic].length;\n\n            while (len--) {\n                subscribers[len].fn(topic, data);\n            }\n        }, 0);\n\n        return true;\n    };\n\n    return pubsub;\n\n});\n/*\n    A basic implementation of the Publisher/Subscriber design pattern.\n    Developed by Addy Osmani (http://addyosmani.com/)\n\n    Example Usage:\n\n                    // Create subscriber function to be called when topic publishes an event\n                    var testSubscriber = function (topics, data) {\n                        console.log(topics + ': ' + data);\n                    };\n\n                    // Subscribe 'testSubscriber' to the event 'example1'\n                    var testSubscription = pubsub.subscribe('example1', testSubscriber);\n\n                    // Trigger the 'example1' event multiple times with different data each time\n                    pubsub.publish('example1', 'hello world!');\n                    pubsub.publish('example1', ['test','a', 'b', 'c']);\n                    pubsub.publish('example1', [{ 'color':'blue' }, { 'text' : 'hello' }]);\n\n                    // Unsubscribe 'testSubscription' from being notified of published events\n                    setTimeout(function(){\n                        pubsub.unsubscribe(testSubscription);\n                    }, 0);\n\n                    // This event will be published but 'testSubscription' will no longer receive a notification of it\n                    pubsub.publish('example1', 'hello again!');\n */\ndefine(function(){\n\n    var doc = document;\n    var topics = {};\n    var id = -1;\n    var pubsub = {};\n\n    /*\n        Subscribe to a specific topic and specify a callback function \n        to be executed when the topic triggers an event\n\n        @param  topics  {String}    the name of the topic to add the subscriber to\n        @param  fn      {Function}  the function to be called when an event for this topic is triggered\n        @return token   {String}    the unique id to be associated with the subscriber\n     */\n    pubsub.subscribe =  function (topic, fn) {\n        /*\n           If the specified topic doesn't exist on the object \n           then add it as a new property and set it to an empty Array\n         */\n        if (!topics[topic]) {\n            topics[topic] = [];\n        }\n\n        // Create a unique id to be associated with the subscriber\n        var token = (++id).toString();\n\n        // Store the token and the subscriber (function) in this topic\n        topics[topic].push({\n            token: token,\n            fn: fn\n        });\n\n        // Return the unique id for this subscriber\n        return token;\n    };\n\n    /*\n        Unsubscribe the specified subscriber (specified by the unique token associated to a subscriber)\n\n        @param  token {String}  the unique id for the subscriber\n        @Return false {Boolean} nothing else to happen so just return false\n     */\n    pubsub.unsubscribe =  function (token) {\n        // Loop through all topics...\n        for (var m in topics) {\n            // For each topic...\n            if (topics[m]) {\n                // Loop through each subscriber...\n                for (var i = 0, j = topics[m].length; i \u003c j; i++) {\n                    // If the current subscriber's token matches the token passed to the function...\n                    if (topics[m][i].token === token) {\n                        // Then remove it...\n                        topics[m].splice(i, 1);\n\n                        // And return the subscriber's unique id as a reference\n                        return token;\n                    }\n                }\n            }\n        }\n\n        return false;\n    };\n\n    /*\n        Publish an event for the specified topic, which will trigger all associated subscriber functions to execute\n\n        @param  topic   {String}    the topic name\n        @param  data    {Multiple}  data is passed through to the subscriber function to process (data type can be anything, String/Array/Object whatever!)\n        @Return true    {Boolean}   return true so we know the function was executed successfully\n     */\n    pubsub.publish =  function (topic, data) {\n        // If the topic specified cannot be found then return the function early (no point continuing)\n        if (!topics[topic]) {\n            return false;\n        }\n\n        // Asynchronously execute each subscriber function\n        setTimeout(function(){\n            // Cache the topic\n            var subscribers = topics[topic],\n\n            // Cache the length of subscribers for the topic \n            // Note: If the topic has no subscribers then the length will be equal to zero and the following loop will not run\n            len = topics[topic].length;\n\n            // Loop through each subscriber...\n            while (len--) {\n                // And execute the subscriber's associated function\n                subscribers[len].fn(topic, data);\n            }\n        }, 0);\n\n        return true;\n    };\n\n    return pubsub;\n\n});\n","tags":""},{"id":"5433171","title":"CSS touch delay","content":"Although it's possible to extend the above optimisation approach to `checknavigator.maxTouchPoints` and to then hook up our listener to `pointerup` rather than `click`, there is a much simpler way: setting the [`touch-action` CSS property](http://www.w3.org/Submission/pointer-events/#the-touch-action-css-property) of our element to `none` eliminates the delay.\n\n```css\n/* suppress default touch action like double-tap zoom */\na, button {\n    -ms-touch-action: none;\n        touch-action: none;\n}\n```\n","tags":""},{"id":"5361793","title":"[Sass: avoiding @if conditionals] ","content":"#Ugly Conditionals\n\nInstead of this...\n\n```sass\n$core: true;\n$gutter: 8px;\n\n.block {\n    @if $core or $compact {\n        margin: $gutter;\n    }\n\n    @if $tablet {\n        margin: $gutter * 2;\n    }\n\n    @if $wide {\n        margin: $gutter * 4;\n    }\n}\n```\n\n...I propose...\n\n```sass\n$core: true;\n$gutter: 8px;\n\n.block {\n    margin: _($core_value:    $gutter, \n               $compact_value: $gutter,\n               $tablet_value:  $gutter * 2,\n               $wide_value:    $gutter * 4);\n}\n```\n\nThis requires the use of the following function...\n\n```sass\n@function __($core_value:    inherit, \n             $compact_value: inherit, \n             $tablet_value:  inherit, \n             $wide_value:    inherit) {\n\n    @if $core {\n        @return $core_value;\n    }\n\n    @if $compact {\n        @return $compact_value;\n    }\n\n    @if $tablet {\n        @return $tablet_value;\n    }\n\n    @if $wide {\n        @return $wide_value;\n    }\n\n    @return inherit; // fallback in case none of the conditionals pass\n}\n```\n\n...and because we use 'named' arguments it means we can miss out arguments that don't need a value set, so for example below I'm not passing through the `$compact_value`...\n\n```sass\n.block {\n    border: __($core_value:    1px solid red,\n               $tablet_value:  1px solid green,\n               $wide_value:    1px solid blue);\n}\n```\n\n##Issues?\n\nWell there is potentially one issue and one... concern.\n\nThe 'issue' would be when you miss an argument (as per the `border` example above) then having us set `inherit` on a property might break your CSS if you've already set a value on that property somewhere else in your code base.\n\nThe 'concern' is setting a value of `inherit` is an extra line of CSS code. But that's the trade-off between slightly larger compiled code compared to the easier maintenance.\n","tags":"#sass #if #conditions"},{"id":"4117173","title":"Ensure two columns match heights (rather than tweaking CSS for multiple browser's rendering differences)","content":"When I get a chance I'm going to rewrite the following module to return a function that can accept multiple columns and change the height a bit more efficiently (as well as specify the device dimensions it should be applied for). But for now, this proof of concept works perfectly...\n\n```js\ndefine(function(){\n\n    var doc = document;\n\n    if (doc.documentElement.clientWidth \u003e= 650) {\n        var compare = doc.querySelector('.island.compare');\n        var lending = doc.querySelector('.island.lending');\n        var highest = Math.max(compare.clientHeight, lending.clientHeight);\n\n        compare.style.height = highest + 'px';\n        lending.style.height = highest + 'px';\n    }\n\n});\n```\n","tags":""},{"id":"5235882","title":"The responsive GEL grid system","content":"javascript:(function(w, d){\n    var columns = 12,\n        css     = '.bbcnews-debug-grid{position:fixed;left:0;top:0;right:0;bottom:0;z-index:9999;display:block;pointer-events:none;}.bbcnews-debug-grid__inner{margin:0 auto;padding:0 4px;height:100%}.bbcnews-debug-column{float:left;width:8.333333333%;height:100%}.bbcnews-debug-column__inner{margin-left:4px;margin-right:4px;height:100%;background-color:rgba(0,171,236,0.2)}@media(min-width:400px){.bbcnews-debug-grid__inner{padding:0 12px}}@media(min-width:600px){.bbcnews-debug-grid__inner{padding:0 24px}.bbcnews-debug-column__inner{margin-left:8px;margin-right:8px}}@media(min-width:1008px){.bbcnews-debug-grid__inner{padding:0;width:992px;max-width:992px}}';\n\n    function createColumn(i) {\n        var column = d.createElement('div'),\n            inner  = d.createElement('div');\n\n        column.className = 'bbcnews-debug-column bbcnews-debug-column--'+i;\n        inner.className  = 'bbcnews-debug-column__inner';\n\n        column.appendChild(inner);\n        return column;\n    }\n\n    function createGrid() {\n        var grid  = d.createElement('div'),\n            inner = d.createElement('div');\n\n        grid.className  = 'bbcnews-debug-grid';\n        inner.className = 'bbcnews-debug-grid__inner';\n\n        for(var i = 1; i \u003c= columns; i++) {\n            inner.appendChild(createColumn(i));\n        }\n\n        grid.appendChild(inner);\n        d.body.appendChild(grid);\n    }\n\n    function insertCSS() {\n        var style = d.createElement('style');\n        style.setAttribute('type', 'text/css');\n        style.innerHTML = css;\n        d.body.appendChild(style);\n    }\n\n    createGrid();\n    insertCSS();\n}(window, window.document));\n\n// minified version\n/* \njavascript:(function(w,d){var columns=12,css=\".bbcnews-debug-grid{position:fixed;left:0;top:0;right:0;bottom:0;z-index:9999;display:block;pointer-events:none;}.bbcnews-debug-grid__inner{margin:0 auto;padding:0 4px;height:100%}.bbcnews-debug-column{float:left;width:8.333333333%;height:100%}.bbcnews-debug-column__inner{margin-left:4px;margin-right:4px;height:100%;background-color:rgba(0,171,236,0.2)}@media(min-width:400px){.bbcnews-debug-grid__inner{padding:0 12px}}@media(min-width:600px){.bbcnews-debug-grid__inner{padding:0 24px}.bbcnews-debug-column__inner{margin-left:8px;margin-right:8px}}@media(min-width:1008px){.bbcnews-debug-grid__inner{padding:0;width:992px;max-width:992px}}\";function createColumn(i){var column=d.createElement(\"div\"),inner=d.createElement(\"div\");column.className=\"bbcnews-debug-column bbcnews-debug-column--\"+i;inner.className=\"bbcnews-debug-column__inner\";column.appendChild(inner);return column}function createGrid(){var grid=d.createElement(\"div\"),inner=d.createElement(\"div\");grid.className=\"bbcnews-debug-grid\";inner.className=\"bbcnews-debug-grid__inner\";for(var i=1;i\u003c=columns;i++){inner.appendChild(createColumn(i))}grid.appendChild(inner);d.body.appendChild(grid)}function insertCSS(){var style=d.createElement(\"style\");style.setAttribute(\"type\",\"text/css\");style.innerHTML=css;d.body.appendChild(style)}createGrid();insertCSS()})(window,window.document);\n*/\n","tags":""},{"id":"5194807","title":"A few (of the many) different ways to create a Singleton in JavaScript. Be warned some of these examples require a lot more code to make them true Singletons. As is the case with most problems: simplicity is the key.","content":"function Universe() {\n    // do we have an existing instance?\n    if (typeof Universe.instance === \"object\") {\n        return Universe.instance; \n    }\n    \n    // proceed as normal \n    this.start_time = 0; \n    this.bang = \"Big\";\n    \n    // public methods\n    this.setTime = function(time){\n        this.start_time = time;\n    }\n    \n    // cache (warning this property is public and so can be modified!)\n    Universe.instance = this;\n}\n\n// testing\nvar uni = new Universe(); \nvar uni2 = new Universe(); \nconsole.log(uni === uni2); // true\n\n// view each instance to see their value\nconsole.log(uni.start_time);\nconsole.log(uni2.start_time);\n\n// update the value for the first instance\nuni.setTime(123);\n\n// see both instances have updated (which means although different instances were created, the object is still a Singleton\nconsole.log(uni.start_time);\nconsole.log(uni2.start_time);\nfunction Universe() {\n    // the cached instance \n    var instance = this;\n    \n    // proceed as normal \n    this.start_time = 0; \n    this.bang = \"Big\";\n    \n    // public methods\n    this.setTime = function(time){\n        this.start_time = time;\n    }\n    \n    // rewrite the constructor\n    Universe = function () {\n        return instance;\n    };\n}\n\n// testing\nvar uni = new Universe(); \nvar uni2 = new Universe(); \nconsole.log(uni === uni2); // true\n\n// view each instance to see their value\nconsole.log(uni.start_time);\nconsole.log(uni2.start_time);\n\n// update the value for the first instance\nuni.setTime(123);\n\n// see both instances have updated (which means although different instances were created, the object is still a Singleton\nconsole.log(uni.start_time);\nconsole.log(uni2.start_time);\nvar Singleton = (function(){ // We use a 'immediately invoked function expression' to create a Closure.\n    // Private attribute that holds the single instance\n    var uniqueInstance;\n    \n    // Private method which holds all of the normal Singleton code\n    function Constructor(){\n\t\t// Private members (can't be accessed directly)\n\t\tvar privateAttribute1 = false;\n\t\tvar privateAttribute2 = [1, 2, 3];\n\t\t\n\t\t// Private method (can't be accessed directly)\n\t\tfunction privateMethod(){\n\t\t\treturn 'my private method';\n\t\t}\n\t\t\n\t\treturn {\n\t\t\tpublicAttribute1: true,\n\t\t\tpublicAttribute2: 10,\n\t\t\t\n            // This method can be referred to as a 'Privileged' method as it has access to Private areas\n\t\t\tpublicMethod: function(){\n    \t\t\tconsole.log('privateMethod() = ' + privateMethod()); // privileged access\n\t\t\t\tconsole.log('privateAttribute1 = ' + privateAttribute1); // privileged access \n\t\t\t\tconsole.log('privateAttribute2 = ' + privateAttribute2); // privileged access\n\t\t\t\tconsole.log('this.publicAttribute1 = ' + this.publicAttribute1);\n\t\t\t\tconsole.log('this.publicAttribute2 = ' + this.publicAttribute2);\n\t\t\t}\n\t\t}\n\t}\n\t\n\treturn {\n\t\tgetInstance: function(){\n\t\t\t// Instantiate only if the instance doesn't exist.\n\t\t\tif (!uniqueInstance) {\n\t\t\t\tuniqueInstance = Constructor();\n\t\t\t}\n\t\t\t\n\t\t\treturn uniqueInstance;\n\t\t}\n\t}\n})();\n\t\n/**\n * Now this singleton uses 'lazy loading' we must make sure we use the correct function calls\n *\n * e.g. \n * Singleton.getInstance().publicMethod1();\n *\n * Notice we can 'chain' the methods because 'getInstance' returns the function object itself rather than a value.\n */\n \nSingleton.getInstance().publicMethod();\n","tags":""},{"id":"5145242","title":"Boilerplate for AMD, Node and browser global","content":"(function(define) {\n    'use strict';\n\n    define(function() {\n        return LIBRARY_NAME;\n    });\n}(typeof define == 'function' \u0026\u0026 define.amd\n    ? define\n    : function (factory) { typeof exports === 'object'\n        ? (module.exports = factory())\n        : (this.LIBRARY_NAME = factory());\n    }\n    // Boilerplate for AMD, Node, and browser global\n));\n","tags":""},{"id":"5355802","title":"[Sass: right-to-left CSS] ","content":"/*\nMy proposed solution to the right-to-left CSS issue for BBC Responsive World Service (UPDATED with @danscotton) -\u003e version_2 is what we're proposing...\n*/\n\n$rtol: true;\n\n@mixin context ($property, $value_left, $value_right) {\n    @if $rtol {\n        #{$property}: $value_right;\n    } @else {\n        #{$property}: $value_left;\n    }\n}\n\n@function _($ltr: '', $rtl: '') {\n    @if $rtol {\n        @return $rtl;\n    } @else {\n        @return $ltr;\n    }\n}\n\n.image_v1 {\n    margin: 0 16px 0 0;\n}\n\n.image_v1 {\n    float: _($ltr: left, $rtl: right);\n\n    margin-left: _($rtl: 16px);\n    margin-right: _($ltr: 16px); // downside: duplicated in compiled code\n\n    padding-left: _($ltr: 16px);\n    padding-right: _($rtl: 16px);\n}\n\n.image_v2 {\n    margin-left: 8px;\n    margin-right: 10px;\n}\n\n.image_v2 {\n    @include context(float, left, right);\n    @include context(margin-left, null, 16px);\n    @include context(margin-right, 16px, null);\n}\n","tags":"#sass #css #rtl"},{"id":"5206872","title":"Basic script loader example that works for all browsers","content":"function loadScript(url, callback) {\n    var d = document, \n\ts = d.getElementsByTagName('script')[0], \n\tdone = false, \n\tscript = d.createElement('script');\t\t \n\tscript.type = \"text/javascript\";\n\tscript.src = url;\n\t\t \n    script.onload = script.onreadystatechange = function() {\n        if (!done \u0026\u0026 (!this.readyState || this.readyState == 'loaded' || this.readyState == 'complete')) {\n            done = true;\n            script.onload = script.onreadystatechange = null;\n            if (callback) {\n                callback();\n            }\n        }\n    };\n\t\n    s.parentNode.insertBefore(script, s); // Find the \u003cscript\u003e tag and insert new script above it\n}\n","tags":""},{"id":"5098437","title":"Comments on Analytics code...","content":"The original source code is shown at the bottom of this page.\n\nMy comments were as follows...\n\n- The `sendEvents` method stores `this.events`, then resets `this.events` to an empty Array but would it not be less confusing to just wait until after sending the data to the server (via XHR) before clearing the Array. For example...   \n  ```js\n    var xmlhttp = null;\n\n    if(typeof XDomainRequest != \"undefined\")\n    {\n        xmlhttp = new XDomainRequest();\n        xmlhttp.open(\"POST\",this.s);\n    }\n    else\n    {\n        xmlhttp = new XMLHttpRequest();     \n        xmlhttp.open(\"POST\",this.s, true);\n        xmlhttp.setRequestHeader(\"Content-type\", 'application/json');\n    }\n\n    xmlhttp.onreadystatechange = function()\n    {\n        if(xmlhttp.readyState == 4)\n        {\n            if(callback)\n            {\n                callback(xmlhttp.status);\n            }\n        }\n    }\n        \n    try\n    {\n        xmlhttp.send(JSON.stringify({events:this.events}));\n        this.events = [];\n    }catch(e)\n    {\n        console.log(\"caught:\"+e);\n    }\n  ```\n- Make the properties on the event object clearer:  \n  `this.s = config.server` should be `this.server = config.server`\n- The date creation isn't wrapped properly:  \n  `(new Date().getTime())` should be `(new Date()).getTime()`  \n  we're not sure if the current way will cause an error in certain browsers or not, hence we just felt it would be safer to wrap the new date in parenthesis first before chaining the get time method.\n- Not sure if the code should be written in the Constructor pattern as there is only ever going to be one instance of the Analytic object so it would be better if it was written as an object literal instead.\n- Coding style currently matches our PHP guidelines but that could introduce issues with minifiers so it needs to follow our [JavaScript style guide](https://github.com/BBC-News/guts/wiki/JavaScript-Style-Guide)\n- The module returns an object which maps to the Constructor `{AC:AC}` but it seems redundant to do that. If we do keep with the Constructor pattern then the module should just return the Constructor and not an object literal (unless of course the object that is returned will have additional public API's added to it which will be consumable).\n- Again, if we keep with the module returning an object then the `AC` property should be renamed to something clearer like `init`:  \n  `return {AC:AC};` should be `return { init: AC };`\n- Remove the distracting and quite hideous redundant comments: `//-----------------------------------------------------------------------------` as they make the code much harder to read.\n- The `load` method creates a `self` variable and assigns `this` to it, but that seems redundant? The only exception is the `setTimeout` which changes the scope to be `window`. But for that instance we should be able to get rid of the `self` variable and instead use the `.bind` method...  \n  ```js\n  setTimeout(function(){\n      var data = window.performance.timing;\n      data.url = window.location.pathname;\n      \n      this.addSendEvent(\"PT\", data);\n  }.bind(this), 0);\n  ```\n  ...or alternatively you could create a helper method to wrap the callback function so it binds `this` correctly (see: [MDN Polyfill](https://developer.mozilla.org/en-US/docs/JavaScript/Reference/Global_Objects/Function/bind#Compatibility))\n- I'd cache the `window` reference so the code isn't constantly doing scope lookups.\n- Currently all the methods attached to the `AC` prototype look to be public api methods and really (from a design point of view) I assume these methods should be internalised so they are private and not public.\n\n##Original JavaScript code:\n\n```js\n//-----------------------------------------------------------------------------\nif (typeof define !== 'function') { var define = require('amdefine')(module)}//node.js magic\n//-----------------------------------------------------------------------------\ndefine(function(require){ //BEGIN AMD\n//-----------------------------------------------------------------------------\n/**\n @classdesc The Analytic Client provides an API for applications to submit\n   events for collation and later analysis.\n  \n  \tThis version makes some assumptions based on its intended usage.\n  \t\u003e=IE9 support only, requires native JSON and XMLHttpRequest or XDomainRequest.\n\n\t@param {object} config This contains the followin attributes:\n\t\tserver : string : the address of the events server\n\t\tproduct : string : uniquely identifies product\n\t\tprobability : number : 0 == never, 1.0 == always trigger non critical events\n @class\n*/\n//-----------------------------------------------------------------------------\nfunction AC(config)\n{\n\tthis.events = []; //this is where we store events until we send them\n\tthis.s = config.server;\n\tthis.p = config.product;\n\tthis.tprob = config.probability\n};\n//-----------------------------------------------------------------------------\n//-----------------------------------------------------------------------------\nAC.EN_IP \t= 1; //adds user IP address to event server side\nAC.EN_GEOIP = 2; //adds user Location based on IP to event server side\n//-----------------------------------------------------------------------------\n//-----------------------------------------------------------------------------\n/**\n\tAdd an event to the internal queue.\n\n\t@param {number} eventId The id of the event\n\t@param {Object} eventData The payload data of the event\n\t@param {array}\tenrich (optional) An array of possible enrichments\n*/\n//-----------------------------------------------------------------------------\nAC.prototype.addEvent = function(eventId,eventData,enrich)\n{\n\tthis.events.push(\n\t{\n\t\tp : this.p,\n\t\tid : eventId,\n\t\tts : (new Date().getTime()),\n\t\tdata : eventData,\n\t\tenrich : enrich\n\t});\n};\n//-----------------------------------------------------------------------------\n//-----------------------------------------------------------------------------\n/**\n\tAdd an event to the internal queue.\n\n\t@param {number} eventId The id of the event\n\t@param {Object} eventData The payload data of the event\n\t@param {array}\tenrich (optional) An array of possible enrichments\n\t@param {function} callback This will be fired after event has\n\t been added to queue if present\n*/\n//-----------------------------------------------------------------------------\nAC.prototype.addSendEvent = function(eventId,eventData,enrich,callback)\n{\n\tthis.addEvent(eventId,eventData,enrich);\n\tthis.sendEvents(callback);\n};\n//-----------------------------------------------------------------------------\n/**\n\tCreate the payload required for the special Page Load event.\n\tThis event is automatically triggered whenever the user loads a new\n\tpage, it contains detail about their navigation along with performance\n\ttimings.\n\n\t@return {Object} The created Page Load payload.\n*/\n//-----------------------------------------------------------------------------\nAC.prototype.createPLData = function()\n{\n\treturn {\t\t\n\t\turl : window.location.pathname,\n\t\treferrer : document.referrer\n\t};\n};\n//-----------------------------------------------------------------------------\n/**\n\tThis will send all events currently stored in the client to the \n\tserver endpoint.\n\n\t@param {function} callback Fired upon completion of sending messages.\n*/\n//-----------------------------------------------------------------------------\nAC.prototype.sendEvents = function(callback)\n{\n\tvar events = this.events;\n\tthis.events = [];\n\tvar xmlhttp = null;\n\n\tif(typeof XDomainRequest != \"undefined\")\n\t{\n\t\txmlhttp = new XDomainRequest();\n\t\txmlhttp.open(\"POST\",this.s);\n\t}\n\telse\n\t{\n\t\txmlhttp = new XMLHttpRequest();\t\t\n\t\txmlhttp.open(\"POST\",this.s, true);\n\t\txmlhttp.setRequestHeader(\"Content-type\", 'application/json');\n\t}\n\n\txmlhttp.onreadystatechange = function()\n\t{\n\t\tif(xmlhttp.readyState == 4)\n\t\t{\n\t\t\tif(callback)\n\t    \t{\n\t    \t\tcallback(xmlhttp.status);\n\t    \t}\n\t\t}\n\t}\n\t\t\n\ttry\n\t{\n\t\txmlhttp.send(JSON.stringify({events:events}));\n\t}catch(e)\n\t{\n\t\tconsole.log(\"caught:\"+e);\n\t}\n};\n//-----------------------------------------------------------------------------\n/**\n\tWhen the page has completed loading we create an instance \n\tof the client and submit the special page load event.\n */\n//-----------------------------------------------------------------------------\nAC.prototype.load = function()\n{\n\tvar self = this;\n\n\tif(Math.random() \u003c self.tprob)\n\t{\n\t\tif(typeof window.performance === 'object')\n\t\t{\n\t\t\tself.addEvent(\"PL\",self.createPLData());\n\t\t\t\n\t\t\t//If called on pageload this will not populate performance data properly\n\t\t\t// as the first tick is taken into consideration, thus need to get it on second tick.\n\t\t\tsetTimeout(function()\n\t\t\t{\n\t\t\t\tvar data = window.performance.timing;\n\t\t\t\tdata.url = window.location.pathname;\n\t\t\t\t\n\t\t\t\tself.addSendEvent(\"PT\", data);\n\t\t\t},0);\n\t\t}\n\t\telse\n\t\t{\n\t\t\tself.addSendEvent(\"PL\",self.createPLData());\n\t\t}\n\t}\n};\n//-----------------------------------------------------------------------------\n//-----------------------------------------------------------------------------\nreturn {AC:AC};}); //END AMD\n```\n","tags":""},{"id":"5094034","title":"Example of prototypal inheritance but done in a 'classical inheritance' style...","content":"/*\n    The following style of inheritance is called 'classical inheritance'\n    The fundamentals of it are using functions as a 'Constructor' (class) to create new objects.\n */\nfunction Article(title, date, description) {\n    this.title = title || 'No title provided';\n    this.date = date || 'No date provided';\n    this.description = description || 'No description provided';\n}\n\n/*\n    Notice we didn't do...\n\n    function Article(title, date, description) {\n        ...\n        this.displayArticle = function(){};\n    }\n\n    ...instead we set the `displayArticle` method directly onto the `prototype` of the `Article` constructor.\n    The reason we do this is because it results in better performance.\n\n    The reason why this is better performing is because if we put `displayArticle` inside the constructor function \n    then every new instance/object we created would have a copy of `displayArticle` within it. But by setting it on \n    the prototype chain it means there is only ever one instance of the `displayArticle` method and all instances/objects \n    created refer to that one function.\n */\nArticle.prototype.displayArticle = function() {\n    console.group(this.title);\n        console.log('Article date: %s | Article description: %s', this.date, this.description);\n    console.groupEnd();\n};\n\n/*\n    If you want to create sub classes that inherit functionality from the base class (in this case `Article`) \n    then there are at least 10 different ways to do it.\n\n    The most typical pattern is this...\n\n    function inherit(Child, Parent) {\n        var F = function(){};\n        F.prototype = Parent.prototype;\n        \n        // Only this (i.e. creating new instance of intermediate constructor F) maintains the prototype chain.\n        // But also allows us to add to Child.prototype without affecting the parent.\n        Child.prototype = new F();\n        Child.uber = Parent.prototype;\n        Child.prototype.constructor = Child;\n    }\n    inherit(SubArticle, Article);\n\n    ...but an even simpler way to do inheritance is like so...\n */\nfunction SubArticle(title, date, description, links) {\n    // We're executing the parent constructor (Article) and passing through the details to it but\n    // using SubArticle as the context\n    Article.call(this, title, date, description);\n\n    // New data that has nothing to do with Article and is specific to SubArticle\n    this.links = links || 'No links provided';\n}\n\n// The following line lets the 'SubArticle' Class inherit all 'Article' methods/properties set on the Article prototype chain\n// Because we're only using `Article` to generate the prototype chain for us to assign to `SubArticle` we don't bother passing \n// any arguments to the `new Article` and so we don't need the parenthesis at the end (e.g. we don't need to do this `new Article()`)\n// That goes for any constructor in JavaScript: e.g. `new Date()` can be written as `new Date` without parenthesis.\nSubArticle.prototype = new Article;\n\nSubArticle.prototype.displayLinks = function() {\n    console.log(this.links);\n}\n\nvar main = new Article('My main Title', '2013-03-05', 'My main description');\n\nmain.displayArticle();\n\ntry {\n    main.displayLinks();\n} catch(e) {\n    alert(\"The previous line of code just failed because I'm trying to access a method that isn't available on the prototype chain for `Article` -\u003e but it does exist for `SubArticle`\");\n}\n\n// Now we can see that if we create a new `SubArticle` that we have access to the `displayArticle` method as well as any new \n// methods we've created specifically for `SubArticle`...\nvar sub = new SubArticle('My Sub Title', '2013-03-05', 'My sub description', ['http://www.google.com/', 'http://www.yahoo.com/']);\n\nsub.displayArticle();\nsub.displayLinks();\n","tags":""},{"id":"5078336","title":"Example code using RubyInline which lets you run foreign code (such as C or C++) within Ruby which has much greater performance over Ruby itself.","content":"#!/usr/bin/env ruby\n\n# gem install RubyInline\n\nrequire 'inline'\nrequire 'benchmark'\n\nclass Fixnum\n    def factorial\n        (1..self).inject { |a, b| a * b }\n    end\nend\n\nclass CFactorial\n    inline do |builder|\n        builder.c_singleton %q{\n            long factorial(int value) {\n                long result = 1, i = 1;\n                for (i = 1; i \u003c= value; i++) {\n                    result *= i;\n                }\n                return result;\n            }\n        }\n    end\nend\n\nBenchmark.bm do |bm|\n    bm.report('ruby:') do\n        100000.times { 8.factorial }\n    end\n\n    bm.report('c:') do\n        100000.times { CFactorial.factorial(8) }\n    end\nend\n","tags":""},{"id":"3898612","title":"Updated truncation script/module","content":"define(function(){\n\n    var truncate = function(str, length, suffix) {\n        var length = length || 30;\n        var suffix = (typeof suffix == \"undefined\") ? '...' : suffix;\n        \n        // strip off HTML entities such as \u0026nbsp; but use a negative lookahead to prevent \u0026hellip; from being stripped\n        var strip_entities = str.replace(/\u0026(?!hellip)[a-z]+;/gim, '');\n\n        // strip off dodgy line breaks and carriage returns and extra potential spaces/tabs\n        var strip_breaks = strip_entities.replace(/\\r+\\s+\\t+\\r+/gim, '');\n\n        // if the string isn't longer than the specified cut-off length then just return the original string\n        var add_suffix = (strip_breaks.length \u003e length) \n            ? /* next we borrow the String object's \"slice()\" method using the \"call()\" method */ String.prototype.slice.call(strip_breaks, 0, length - suffix.length) + suffix \n            : strip_breaks;\n\n        var strip_endspace = add_suffix.replace(/\\s(\\.\\.\\.)$/gim, function (match, cg1) {\n            return cg1;\n        });\n\n        return strip_endspace;\n    }\n    \n    return truncate;\n\n});\n","tags":""},{"id":"5073030","title":"The difference between `prototype` and `__proto__`","content":"function Point(x, y) {\n  this.x = x;\n  this.y = y;\n}\n\nPoint.prototype.display = function() {\n  console.log(this.x + ' | ' + this.y);\n}\n\nvar point = new Point(1, 2);\n\nconsole.group('Point');\n    console.log(typeof Point); // =\u003e \"function\"\nconsole.groupEnd();\n\nconsole.group('point');\n    console.log(typeof point); // =\u003e \"object\"\n    console.log(point); // =\u003e `Point {x: 1, y: 2, display: function}`\nconsole.groupEnd();\n\nconsole.group('point.__proto__');\n    console.log(point.__proto__); // =\u003e `Point {display: function}`\n    console.log('`__proto__` is the actual object that is used in the lookup chain to resolve methods');\n    console.log('in most browsers `__proto__` is an internal property and not accessible via JavaScript (soon to change with ES6)');\nconsole.groupEnd();\n\nconsole.group('point.prototype');\n    console.log(point.prototype); // =\u003e `undefined`\n    console.log('only Functions have the `prototype` property');\n    console.log('`prototype` is the object that is used to build `__proto__` when you create an object with `new`');\nconsole.groupEnd();\n\nconsole.group('({}).__proto__');\n    console.log(({}).__proto__); // =\u003e Object {}\nconsole.groupEnd();\n\nconsole.group('point.__proto__ == point.prototype');\n    console.log(point.__proto__ == point.prototype); // =\u003e `false`\nconsole.groupEnd();\n","tags":""},{"id":"5109219","title":"Add properties to PHP object dynamically","content":"// Check it out online: http://phpepl.cloudcontrolled.com/\n \n$obj = new stdClass();\n$abc = 'something';\n \n$obj-\u003e{$abc} = 'test'; // dynamically generated object key = MIND BLOWN\n \nvar_dump($obj); // =\u003e object(stdClass)#1 (1) { [\"something\"]=\u003e string(4) \"test\" }\n","tags":""},{"id":"4116778","title":"The Checkbox CSS Hack (doesn't work in IE \u003c= 8, but all other browsers fine)","content":"\u003clabel for=\"toggle-1\"\u003eI'm a toggle\u003c/label\u003e\n\u003cinput type=\"checkbox\" id=\"toggle-1\"\u003e\n\u003cdiv\u003eI'm controlled by toggle. No JavaScript!\u003c/div\u003e\n/* Checkbox Hack */\n\ninput[type=checkbox] {\n   position: absolute;\n   top: -9999px;\n   left: -9999px;\n}\nlabel { \n  -webkit-appearance: push-button;\n  -moz-appearance: button; \n  display: inline-block;\n  margin: 60px 0 10px 0;\n  cursor: pointer;\n}\n\n/* Default State */\ndiv {\n   background: green;\n   width: 400px;\n   height: 100px;\n   line-height: 100px;\n   color: white;\n   text-align: center;\n}\n\n/* Toggled State */\ninput[type=checkbox]:checked ~ div {\n   background: red;\n}\n\n","tags":""},{"id":"5134943","title":"The difference between JavaScript's `exec` and `match` methods is subtle but important, and I always forget...","content":"var str = \"The quick brown fox jumped over the box like an ox with a sox in its mouth\";\n\nstr.match(/\\w(ox)/g); // [\"fox\", \"box\", \"sox\"]\n\n// match (when used with a 'g' flag) returns an Array with all matches found\n// if you don't use the 'g' flag then it acts the same as the 'exec' method.\n\nstr.match(/\\w(ox)/); // [\"fox\", \"ox\"]\n/\\w(ox)/.exec(str);  // [\"fox\", \"ox\"]\n\n// the exec method returns an Array where the first index is the match and all other indexes are capturing groups\n// note: adding a 'g' flag has no effect on the returned Array\n\n/\\w(ox)/g.exec(str);  // [\"fox\", \"ox\"]\n\n// although you can use a while loop with the exec method to find successive matches\n\nvar myRe = /ab*/g;\nvar str = \"abbcdefabh\";\nvar myArray;\nwhile ((myArray = myRe.exec(str)) !== null) {\n  var msg = \"Found \" + myArray[0] + \".  \";\n  msg += \"Next match starts at \" + myRe.lastIndex;\n  console.log(msg);\n}\n\n/*\nFound abb.  Next match starts at 3\nFound ab.  Next match starts at 9\n */\n","tags":""},{"id":"4966463","title":"Was reading http://jspro.com/raw-javascript/intelligent-string-abbreviation/ and decided to try and clean up the example.\r\n\r\nI then made another version which separated specific functionality into individual functions.\r\n\r\nFinally I made a third variation which made dependencies external.","content":"/**\n * Shorten a string by a specified number of characters and end the string \n * using either a user specified suffix or a default suffix.\n * Ensures string is not abbreviated prematurely (e.g. half way through a word)\n * \n * @param {string} user specified string\n * @param {number} the maximum allowed characters before abbreviating\n * @param {string} the characters used to end the string\n * @return {string} the abbreviated string\n */\nfunction abbreviate (user_str, user_max, user_suffix) {\n    var startend_spaces = /^\\s+|\\s+$/g;\n    var linebreak_spaces = /[\\r\\n]*\\s*[\\r\\n]+/g;\n    var tab_spaces = /[ \\t]+/g;\n    var ending_space = /[ ]$/g;\n    var abbr = '';\n    var suffix = (typeof user_suffix !== 'undefined' ? user_suffix : '...');\n    var max = user_max - suffix.length;\n    var counter = 0;\n    var string = user_str;\n    var len;\n\n    // if after cleaning up all extraneous white space, if the length of the \n    // string is less than the `max` value then just return the string\n    if ((string = string.replace(startend_spaces, '').replace(linebreak_spaces, ' ').replace(tab_spaces, ' ')).length \u003c= max) {\n        return string;\n    }\n\n    string = string.split(' ');\n    len = string.length;\n\n    while (counter \u003c len) {\n        // individual characters of a string can be accessed via bracket notation\n        if ((abbr + string[counter]).length \u003c max) {\n            abbr += string[counter] + ' ';\n        } else {\n            break;\n        }\n\n        counter++;\n    }\n\n    return abbr.replace(ending_space, '') + suffix;\n}\n\n// Example usage:\nconsole.log(abbreviate('this is my very long string that probably should be cropped at some point soon', 11, '!!!'));\nconsole.log(abbreviate('this is my very long string that probably should be cropped at some point soon', 20));\n/**\n * Shorten a string by a specified number of characters and end the string \n * using either a user specified suffix or a default suffix.\n * Ensures string is not abbreviated prematurely (e.g. half way through a word)\n * \n * @param {string} user specified string\n * @param {number} the maximum allowed characters before abbreviating\n * @param {string} the characters used to end the string\n * @return {string} the abbreviated string\n */\nfunction abbreviate (user_str, user_max, user_suffix) {\n    /**\n     * Code Structure:\n     * - Variables\n     * - Functions\n     *   - clean_string\n     *   - is_too_short\n     *   - crop\n     * - Initialisation\n     */\n    var suffix = (typeof user_suffix !== 'undefined' ? user_suffix : '...');\n    var max = user_max - suffix.length;\n    var string = user_str;\n\n    function clean_string(){\n        var startend_spaces = /^\\s+|\\s+$/g;\n        var linebreak_spaces = /[\\r\\n]*\\s*[\\r\\n]+/g;\n        var tab_spaces = /[ \\t]+/g;\n\n        string = string.replace(startend_spaces, '').replace(linebreak_spaces, ' ').replace(tab_spaces, ' ');\n    }\n\n    function is_too_short(){\n        return string.length \u003c= max;\n    }\n\n    function crop(){\n        var abbr = '';\n        var counter = 0;\n        var len;\n        var ending_space = /[ ]$/g;\n\n        string = string.split(' ');\n        len = string.length;\n\n        while (counter \u003c len) {\n            // individual characters of a string can be accessed via bracket notation\n            if ((abbr + string[counter]).length \u003c max) {\n                abbr += string[counter] + ' ';\n            } else {\n                break;\n            }\n\n            counter++;\n        }\n\n        return abbr.replace(ending_space, '') + suffix;\n    }\n\n    clean_string(); // remove all extraneous white space\n\n    if (is_too_short()) {\n        return string;\n    }\n\n    return crop();\n}\n\n// Example usage:\nconsole.log(abbreviate('this is my very long string that probably should be cropped at some point soon', 11, '!!!'));\nconsole.log(abbreviate('this is my very long string that probably should be cropped at some point soon', 20));\n/**\n * Shorten a string by a specified number of characters and end the string \n * using either a user specified suffix or a default suffix.\n * Ensures string is not abbreviated prematurely (e.g. half way through a word)\n * \n * Dependencies:\n *     - clean_string\n *     - is_too_short\n *     - crop\n * \n * @param user_str {string} user specified string\n * @param user_max {number} the maximum allowed characters before abbreviating\n * @param user_suffix {string} the characters used to end the string\n * @return {string} the abbreviated string\n */\nfunction abbreviate (user_str, user_max, user_suffix) {\n    var suffix = (typeof user_suffix !== 'undefined' ? user_suffix : '...');\n    var max = user_max - suffix.length;\n    var string = clean_string(user_str); // remove all extraneous white space\n\n    if (shorter_than(string, max)) {\n        return string;\n    }\n\n    return crop(string, max, suffix);\n}\n\n/**\n * Removes any unnecessary spaces from the specified string\n * \n * @param string {string} user specified string\n * @return {string} the string cleared of unnecessary spaces\n */\nfunction clean_string (string) {\n    var startend_spaces = /^\\s+|\\s+$/g;\n    var linebreak_spaces = /[\\r\\n]*\\s*[\\r\\n]+/g;\n    var tab_spaces = /[ \\t]+/g;\n\n    return string.replace(startend_spaces, '').replace(linebreak_spaces, ' ').replace(tab_spaces, ' ');\n}\n\n/**\n * Checks if the string length is less or equal to the maximum allowed\n * \n * @param string {string} user specified string\n * @param max {number} the maximum allowed characters before abbreviating\n * @return {boolean} whether the length of the string exceeds the maximum\n */\nfunction shorter_than (string, max) {\n    return string.length \u003c= max;\n}\n\n/**\n * Crops the string so its length is under the max allowed, and also\n * adds the specified suffix to the end of the string\n * Ensures string is not abbreviated prematurely (e.g. half way through a word)\n * \n * @param string {string} user specified string\n * @param max {number} the maximum allowed characters before abbreviating\n * @param suffix {string} the characters used to end the string\n * @return {string} the abbreviated string\n */\nfunction crop (string, max, suffix) {\n    var abbr = '';\n    var counter = 0;\n    var len;\n    var ending_space = /[ ]$/g;\n\n    string = string.split(' ');\n    len = string.length;\n\n    while (counter \u003c len) {\n        // individual characters of a string can be accessed via bracket notation\n        if ((abbr + string[counter]).length \u003c max) {\n            abbr += string[counter] + ' ';\n        } else {\n            break;\n        }\n\n        counter++;\n    }\n\n    return abbr.replace(ending_space, '') + suffix;\n}\n\n// Example usage:\nconsole.log(abbreviate('this is my very long string that probably should be cropped at some point soon', 11, '!!!'));\nconsole.log(abbreviate('this is my very long string that probably should be cropped at some point soon', 20));\n","tags":""},{"id":"4960210","title":"In CSS/BEM: how do we name a sub-block that is related to its parent block?","content":"\u003c!-- Simplest solution is to just label the element as a element within an element --\u003e\n\u003cdiv class=\"block\"\u003e\n  Content\n  \u003cdiv class=\"block__element\"\u003e\n    Content\n    \u003cdiv class=\"block__element__element\"\u003e\n      Content related to `block__element`\n    \u003c/div\u003e\n  \u003c/div\u003e\n\u003c/div\u003e\n\n\u003c!-- You could have a separate block element inside of the parent block but how does the naming convention work? --\u003e\n\u003cdiv class=\"block\"\u003e\n  Content\n  \u003cdiv class=\"block__element\"\u003e\n    Content\n    \u003cdiv class=\"newblock\"\u003e\n      Content related to `block__element` but is now namespaced under `newblock` which is wrong\n    \u003c/div\u003e\n  \u003c/div\u003e\n\u003c/div\u003e\n\n\u003c!-- Harry Roberts suggestion --\u003e\n\u003cdiv class=\"block\"\u003e\n  Content\n  \u003cdiv class=\"block__element newblock\"\u003e\n    Content\n    \u003cdiv class=\"newblock__element\"\u003e\n      Content related to `block__element` but is now namespaced under `newblock` which is wrong\n    \u003c/div\u003e\n  \u003c/div\u003e\n\u003c/div\u003e\n","tags":""},{"id":"3938408","title":"Detect CSS Animation support and provide object of normalised properties","content":"    function CSSAnimation(){\n        /*\n            webkitAnimationName =\u003e Safari/Chrome\n            MozAnimationName =\u003e Mozilla Firefox\n            OAnimationName =\u003e Opera\n            animationName =\u003e compliant browsers (inc. IE10)\n         */\n        var supported = false;\n        var prefixes = ['webkit', 'Moz', 'O', ''];\n        var limit = prefixes.length;\n        var doc = document.documentElement.style;\n        var prefix, start, end;\n\n        while (limit--) {\n            // If the compliant browser check (in this case an empty string value) then we need to check against different string (animationName and not prefix + AnimationName)\n            if (!prefixes[limit]) {\n                // If not undefined then we've found a successful match\n                if (doc['animationName'] !== undefined) {\n                    prefix = prefixes[limit];\n                    start = 'animationstart';\n                    end = 'animationend';\n                    supported = true;\n                    break;\n                }\n            } \n            // Other brower prefixes to be checked\n            else {\n                // If not undefined then we've found a successful match\n                if (doc[prefixes[limit] + 'AnimationName'] !== undefined) {\n                    prefix = prefixes[limit];\n\n                    switch (limit) {\n                        case 0:\n                            //  webkitAnimationStart \u0026\u0026 webkitAnimationEnd\n                            start = prefix.toLowerCase() + 'AnimationStart';\n                            end = prefix.toLowerCase() + 'AnimationEnd';\n                            supported = true;\n                            break;\n\n                        case 1:                        \n                            // animationstart \u0026\u0026 animationend\n                            start = 'animationstart';\n                            end = 'animationend';\n                            supported = true;\n                            break;\n\n                        case 2:\n                            // oanimationstart \u0026\u0026 oanimationend\n                            start = prefix.toLowerCase() + 'animationstart';\n                            end = prefix.toLowerCase() + 'animationend';\n                            supported = true;\n                            break;\n                    }\n                    \n                    break;\n                }\n            }\n        }\n\n        return {\n            supported: supported,\n            prefix: prefix,\n            start: start,\n            end: end\n        };\n    }\n\n    var animation = CSSAnimation();\n    var element = document.getElementById('js-animation');\n\n    if (animation.supported) {\n        element.addEventListener(animation.start, AnimationListener, false);\n        element.addEventListener(animation.end, AnimationListener, false);\n    }\n\n    function AnimationListener (e) {\n        console.log(e, e.type);\n    }\n","tags":""},{"id":"3947056","title":"Doesn't work: preload images so we can check when background images are loaded via CSS","content":"    function preload (srcArray) {\n        var len = srcArray.length;\n        var imgs = new Array(len);\n        var count = 0;\n\n        for (var i=0; i\u003clen; i++) {\n            imgs[i] = new Image();\n            imgs[i].src = srcArray[i];\n            imgs[i].onload = function(){\n                count++;\n                if (count === 6) {\n                    complete();\n                }\n            };\n        }\n\n        function complete(){\n            console.log('images preloaded');\n            var lis = document.querySelector('.experiences').getElementsByTagName('li');\n            var list = ['a', 'b', 'c', 'd', 'e', 'f', 'g'];\n\n            for (var i = 1; i \u003c lis.length; i++) {\n                // Replace the class value with the relevant Array index value\n                // e.g. 'b invisible' should be just 'b'\n                // there are more eloquent ways to achieve this but required a fair bit of extra code and I was going for speed over beautiful code\n                lis[i].className = list[i];\n            }\n\n            console.log(lis);\n        }\n\n        console.log(imgs);\n    }\n    \n    preload([\n        \"http://192.168.0.40/~stormcreative/Assets/Images/experience-1.jpg\",\n        \"http://192.168.0.40/~stormcreative/Assets/Images/experience-2.jpg\",\n        \"http://192.168.0.40/~stormcreative/Assets/Images/experience-3.jpg\",\n        \"http://192.168.0.40/~stormcreative/Assets/Images/experience-4.jpg\",\n        \"http://192.168.0.40/~stormcreative/Assets/Images/experience-5.jpg\",\n        \"http://192.168.0.40/~stormcreative/Assets/Images/experience-6.jpg\"\n    ]);\n","tags":""},{"id":"4713288","title":"Made a super quick bookmarklet for displaying the current screen dimensions for Chrome","content":"javascript:(function(w, d){\n    var el = d.createElement('div');\n        el.setAttribute('style', 'position: fixed; right: 1em; top: 0; background-color: red; color: white; padding: 5px; z-index: 1000;');\n    el.innerHTML = d.documentElement.clientWidth;\n    d.body.appendChild(el);\n    w.addEventListener('resize', function(){\n        el.innerHTML = d.documentElement.clientWidth;\n    }, false);\n}(window, window.document));\n\n// minified version\n/* \njavascript:(function(w,d){var el=d.createElement(\"div\");el.setAttribute(\"style\",\"position: fixed; right: 1em; top: 0; background-color: red; color: white; padding: 5px; z-index: 1000;\");el.innerHTML=d.documentElement.clientWidth;d.body.appendChild(el);w.addEventListener(\"resize\",function(){el.innerHTML=d.documentElement.clientWidth},false)})(window,window.document);\n*/\n","tags":""},{"id":"4642970","title":"I'm trying to get the cleanest, most basic export from r.js","content":"Directory structure...\n\n- app\n  - images\n  - release\n  - styles\n      - main.css\n- lib\n  - jquery.js\n  - require.js\n- modules\n  - a.js\n  - b.js\n  - c.js\n\nSpecific RequireJS settings within my Gruntfile...\n\n```js\nrequirejs: {\n  compile: {\n    options: {\n      baseUrl: './app',\n      mainConfigFile: './app/main.js',\n      dir: './app/release/',\n      fileExclusionRegExp: /^\\.|node_modules|Gruntfile|\\.md|package.json/,\n      modules: [\n        {\n          name: 'main'\n        }\n      ]\n    }\n  }\n}\n```\n\nExecuting `grunt release` feeds back the following information...\n\n```sh\n$ grunt release\nRunning \"requirejs:compile\" (requirejs) task\n\u003e\u003e Optimizing (standard.keepLines) CSS file:\n\u003e\u003e /Library/WebServer/Documents/GruntTest/2/app/release/styles/main.css\n\u003e\u003e Tracing dependencies for: main\n\u003e\u003e Uglifying file: /Library/WebServer/Documents/GruntTest/2/app/release/a.js\n\u003e\u003e Uglifying file: /Library/WebServer/Documents/GruntTest/2/app/release/b.js\n\u003e\u003e Uglifying file: /Library/WebServer/Documents/GruntTest/2/app/release/c.js\n\u003e\u003e Uglifying file:\n\u003e\u003e /Library/WebServer/Documents/GruntTest/2/app/release/jquery.js\n\u003e\u003e Uglifying file: /Library/WebServer/Documents/GruntTest/2/app/release/main.js\n\u003e\u003e styles/main.css\n\u003e\u003e ----------------\n\u003e\u003e styles/main.css\n\u003e\u003e \n\u003e\u003e main.js\n\u003e\u003e ----------------\n\u003e\u003e a.js\n\u003e\u003e b.js\n\u003e\u003e c.js\n\u003e\u003e jquery.js\n\u003e\u003e main.js\n\nRunning \"sass:dist\" (sass) task\n\nDone, without errors.\n```\n\n...after the above command is run my directory structure looks like this...\n\n- app\n  - images\n  - release\n      - images\n      - styles\n          - main.css (optimised)\n      - a.js\n      - b.js\n      - build.txt\n      - c.js\n      - jquery.js (optimised)\n      - main.js (optimised)\n  - styles\n      - main.css\n- lib\n  - jquery.js\n  - require.js\n- modules\n  - a.js\n  - b.js\n  - c.js\n\n...but really I want to end up with the following directory structure instead...\n\n- app\n  - images\n  - release\n      - build.txt\n      - main.js (optimised)\n  - styles\n      - main.css\n- lib\n  - jquery.js\n  - require.js\n- modules\n  - a.js\n  - b.js\n  - c.js\n","tags":""},{"id":"4319778","title":"The last time I wrote any real PHP (of any production worth) was back in 2006 (it's now December 2012). I thought I would share some potentially terrible PHP code I wrote today whilst trying to refresh my memory. Definitely feel free to have a good laugh, but what would be even better would be some constructive criticism. This isn't supposed to be anything remotely near finished code. The purpose was to get me back into the feel for writing PHP. If there are suggestions about what I've written (things I should avoid for example) then I'd love to hear them. Thanks!","content":"\u003c?php\n    class Database {\n        private $_dbconnection;\n\n        /*\n            @description \n            Constructor that creates a new instance of a PDO connection.\n            \n            @param username     {String} username access\n            @param password     {String} password access\n            @param host         {String} host information (either localhost or ip address, defaults to localhost)\n            @param dbname       {String} database name to access (defaults to stormtest)\n            @param errortype    {Object} sets the error mode (defaults to ERRMODE_SILENT)\n            @return             {Object} new class instance object is returned\n         */\n        public function __construct ($username, $password, $host = 'localhost', $dbname = 'mydemodb', $errortype = PDO::ERRMODE_SILENT) {\n            try {\n                $this-\u003e_dbconnection = new PDO('mysql:host=' . $host . ';dbname=' . $dbname, $username, $password);\n                $this-\u003e_dbconnection-\u003esetAttribute(PDO::ATTR_ERRMODE, $errortype);\n\n                /*\n                    // Different error settings that can be used...\n\n                    $_dbconnection-\u003esetAttribute( PDO::ATTR_ERRMODE, PDO::ERRMODE_SILENT );    // Standard\n                    $_dbconnection-\u003esetAttribute( PDO::ATTR_ERRMODE, PDO::ERRMODE_WARNING );   // Useful for debuggin\n                    $_dbconnection-\u003esetAttribute( PDO::ATTR_ERRMODE, PDO::ERRMODE_EXCEPTION ); // Shows an exception and hides all other important data\n                 */\n            } catch (PDOException $error) {\n                die($error-\u003egetMessage()); // Ideally we'd do something better here than just die!\n            }\n        }\n\n        /*\n            @description \n            Fetch data from table using specified SQL command and returns data as either an Array or an Object (depending on what the user specifies).\n            \n            @param sql              {String}        The SQL command to execute\n            @param response_type    {Object}        Optional response type (defaults to Array)\n            @return results         {Object|Array}  Returns either an Array or an Object (depending on what the user specified)\n         */\n        public function fetch ($sql, $response_type = PDO::FETCH_ASSOC) {\n            $query = $this-\u003e_dbconnection-\u003equery($sql);\n            $query-\u003esetFetchMode($response_type);\n            $results = $query-\u003efetchAll(); // was originally using `fetch` but realised that only returns first result\n            return $results;\n        }\n\n        // Close the database connection\n        public function close () {\n            $this-\u003e_dbconnection = null;\n        }\n    }\n?\u003e\n\u003c?php\n\n// CONFIGURE ERROR MESSAGES\n    ini_set('display_errors',1);\n    error_reporting(E_ALL);\n\n// PULL IN OUR DATABASE CLASS\n    require 'Database.php';\n\n// GENERIC CONNECTION (REUSED A FEW TIMES BELOW)\n    $db_connection = new Database('root', 'mydemopass');\n    \n// EXAMPLE OF BASIC QUERY\n    $results_array = $db_connection-\u003efetch('SELECT * FROM testing');\n    $results_object = $db_connection-\u003efetch('SELECT * FROM testing', PDO::FETCH_OBJ);\n\n    print_r($results_array);\n        echo '\u003cbr\u003e\u003chr\u003e';\n    print_r($results_object);\n        echo '\u003cbr\u003e\u003chr\u003e';\n\n// EXAMPLE OF JOINING DATA VIA FOREIGN KEY\n    $sql = 'SELECT * FROM testing INNER JOIN roles ON testing.user_role = roles.role_id'; // In MySQL we set-up `user_role` to be an index/foreign key which points to the `roles` table\n    $results_full_object = $db_connection-\u003efetch($sql, PDO::FETCH_OBJ);\n\n    print_r($results_full_object);\n        echo '\u003chr\u003e';\n\n    /*\n        An Array wraps multiple Objects in the results.\n        So we have to loop through the Array first before we can access the Objects within.\n     */\n    foreach ($results_full_object as $index) {\n        \n        foreach ($index as $key =\u003e $value) {\n            echo $key . ': ' . $value . '\u003cbr\u003e';\n\n            /*\n                // This loop will display something like this...\n\n                user_id: 1\n                user_name: Joe\n                user_surname: Bloggs\n                user_age: 30\n                user_role: 1\n                role_id: 1\n                role_name: Manager\n                user_id: 1\n                user_name: Bob\n                user_surname: Smith\n                user_age: 99\n                user_role: 2\n                role_id: 2\n                role_name: Developer\n             */\n        }\n    }\n\n// WE'RE DONE, LETS GO!\n    $db_connection-\u003eclose();\n\n?\u003e\n","tags":""},{"id":"3912086","title":"Example of passing a code block to a Mixin to make it more flexible (especially for displaying retina content)","content":"@mixin retina {\n    /* Target any and all high-density screens on any browser currently known (October 2012) */\n    @media (min--moz-device-pixel-ratio: 1.5), \n           (-o-min-device-pixel-ratio: 3/2), \n           (-webkit-min-device-pixel-ratio: 1.5), \n           (min-resolution: 1.5dppx) {\n        @content;\n    }\n}\n\n@include retina {\n    background: url(../Images/Retina/logo_2x.png) 0 0 no-repeat;\n    background-size: 286px;\n}\n","tags":""},{"id":"3918798","title":"Backbone example","content":"define(['../Utils/Templating/hogan', '../Utils/Datepicker/kalendae', '../Models/LoanApplication', '../Utils/DOM/getEl', 'Backbone'], function (hogan, Kalendae, LoanApplication, getElement) {\n\n    return Backbone.View.extend({\n        model: new LoanApplication(),\n\n        initialize: function(){\n            // Store other elements that will be interacted with.\n            // Any element that will potentially utilise jQuery we pre-wrap in a single jQuery instance.\n            this.promocode = getElement('js-promocode');\n            this.amount = getElement('js-amount');\n            this.error_amount = $('#js-amounterror');\n            this.error_amount_popup = $('#js-amounterror-popup');\n            this.popup = $('#js-loanpopup');\n            this.popup_amount = getElement('js-popupamount');\n            this.loan_details = getElement('js-loandetails');\n            this.apply_now = $('#js-applynow');\n            this.trigger_popup = getElement('js-pickdate'); // this is the form input that triggers the popup to be shown\n\n            // We use this to tell whether the calendar widget has already been rendered,\n            // as there is no point re-rendering it every time the popup is closed then opened again.\n            this.is_calendar_rendered = false;\n\n            // Details that will be passed around in different methods\n            this.days_to_pay = null;\n            this.amount_to_borrow = null;\n            this.selected_date = null;\n\n            // This holds the template file we'll compile with data pulled from server\n            this.template = null;\n            this.template_content = null;\n\n            // The Model triggers custom events when certain actions happen which the View should ideally handle\n            this.model.on('item:invalid', this.process_errors, this);\n            this.model.on('amount:changed', this.validation_success, this);\n\n            // There is one instance where we need the Model to have access to the View (so we can set a shared property)\n            this.model.view = this;\n\n            // Used within 'remove_error' method\n            this.allow_app_process = false;\n\n            // Used to determine if the application can proceed\n            this.valid_date = false;\n\n            // Used to determine if the validation passed\n            this.validation_pass = false;\n        },\n\n        // The containing element\n        el: getElement('js-loanapplication'),\n\n        // Selectors are scoped to the parent element\n        events: {\n            'focus #js-pickdate': 'validate_amount',\n            'click #js-calendarclose': 'close_popup',\n            'click #js-applynow': 'validate_amount',\n            'keyup #js-popupamount': 'validate_amount'\n        },\n\n        validate_amount: function (e) {\n            /*\n                First thing we need to do is to lose focus on the #js-pickdate input element\n                Otherwise, if the user has the popup open and then decides to view a different screen and comes back.\n                Returning back causes the input to gain focus again.\n             */\n            this.trigger_popup.blur();\n\n            /*\n                We validate a different field depending on whether the popup is open (the popup has its own copy of the application fields)\n                Note: Model's \"set\" method calls Backbone validation by default (see Model for validation rules)\n             */\n\n            // If popup is hidden\n            if (this.popup.hasClass('hide')) {\n                this.model.set({\n                    amount: this.amount.value,\n                    event_type: e.type\n                });\n            } \n            // If popup is visible\n            else {\n                if (e.type === 'keyup') {\n                    /*\n                        We don't want to validate the amount if the user is just pressing the shift key or the left/right/up/down arrow keys:\n                        Shift = 16 | Left = 37 | Up = 38 | Right = 39 | Down = 40\n                     */\n                    if (!_.contains([16, 37, 38, 39, 40], e.keyCode)) {\n                        this.model.set({\n                            amount: this.popup_amount.value,\n                            event_type: e.type // passing through the event type means we can prevent the 'remove_error' method from processing the application\n                        });\n                    }\n                }\n                else {\n                    this.model.set({\n                        amount: this.popup_amount.value,\n                        event_type: e.type\n                    });\n                }\n            }\n        },\n\n        process_errors: function (item) {\n            // Hide the 'apply' button if it's already viewable\n            this.apply_now.addClass('hide');\n\n            // Check what field was invalid and display corresponding error message\n            switch (item.field) {\n                case 'amount':\n                    // We display the error message in a different place depending on whether the popup is open\n                    \n                    // If the popup is NOT visible\n                    if (this.popup.hasClass('hide')) {\n                        this.error_amount.removeClass('invisible');\n                    } else {\n                        this.error_amount_popup.removeClass('invisible');\n                    }\n                    \n                    break;\n            }\n        },\n\n        validation_success: function(){\n            this.validation_pass = true;\n            this.check_apply_display();\n        },\n\n        check_apply_display: function(){\n            // If there is a valid date then we can show the 'apply' button\n            if (this.valid_date) {\n                this.apply_now.removeClass('hide');\n            }\n\n            // Now we hide any errors\n            this.remove_error();\n        },\n\n        // TODO: refactor this function - surely the inner if statement logic can be abstracted into a separate function?\n        remove_error: function(){\n            // We remove the error message from different places depending on whether the popup is open\n\n            // If the popup is NOT visible\n            if (this.popup.hasClass('hide')) {\n                this.error_amount.addClass('invisible');\n                this.display_calendar();\n            } else {\n                this.error_amount_popup.addClass('invisible');\n\n                // Only process the application if the user has explictly clicked on the 'apply' button and their data has been validate\n                if (this.allow_app_process \u0026\u0026 this.valid_date) {\n                    window.location = 'create-account.php?amount=' + this.popup_amount.value + '\u0026paymentdate=' + this.selected_date;\n                } else {\n                    // Noticed issue with keyup event constantly firing, so safer just to force the input to lose focus\n                    this.popup_amount.blur();\n                }\n            }\n        },\n\n        display_calendar: function(){\n            /*\n                We only load the calendar on screens large enough to display it\n                And we make sure to only render it once by check \"is_calendar_rendered\" is false\n\n                UPDATE: Since moving this script into an 'advanced' file and having a seperate 'basic' version - the clientWidth check is redundant here.\n                Although it probably isn't much of a performance hit to have that extra check in place still.\n             */\n            if (document.documentElement.clientWidth \u003e= 585 \u0026\u0026 !this.is_calendar_rendered) {\n                this.render_calendar();\n            }\n\n            // Pass through the value into this new popup view\n            this.popup_amount.value = this.amount.value;\n\n            // Make the popup visible\n            this.popup.removeClass('hide');\n        },\n\n        render_calendar: function(){\n            this.is_calendar_rendered = true;\n\n            // Context of \"this\" gets lost within the Kalendae script\n            var self = this;\n\n            // the following variables are used for calculating the difference between \n            // today's date and the selected date to pay back the loan\n            var calendar_container = getElement('js-calendar');\n            var calendar;\n            \n            calendar = new Kalendae({\n                // element to attach the calendar to\n                attachTo: calendar_container,\n                \n                // blackout days after 45 days from current date\n                blackout: function (date) {\n                    return Kalendae.moment().yearDay() + 45 \u003c date.yearDay(); // yearDay() is an extension Kalendae adds to moment.js to calculate the total number of days since epoch.\n                },\n                \n                // how many characters from the week day name to display (e.g. we've gone with 3 = Mon, Tue, Wed, Thu, Fri, Sat, Sun)\n                columnHeaderLength: 3,\n                \n                // restricts date selectability to past or future ('future' blacks out all days previous to current date)\n                direction: 'future',\n                \n                // only allows selection of one day\n                mode: 'single',\n                \n                // determines the number of months to display\n                months: 2,\n                \n                // determines when the week should start (Sunday = 0 [default] or Monday = 1 etc)\n                weekStart: 1,\n                \n                // causes the \u003cinput\u003e to update to the selected date\n                subscribe: {\n                    'date-clicked': function(){\n                        // This event is fire before the selection is changed\n                        if (!self.validation_pass) {\n                            return false;\n                        }\n                    },\n                    'change': function(){\n                        // We don't want to let the user select a date if the amount is invalid\n                        // allow_app_process is being used to determine if the app can move to stage 1 of application\n                        // but it's set every time validation is carried out so we can use it here\n                        if (self.validation_pass) {\n                            // We know a date was selected so we store that information\n                            self.valid_date = true;\n\n                            /*\n                                There could be an instance where the user enters a valid amount *before* the popup is shown, \n                                and then selects a date from the date picker, but that wont trigger a change event on the amount \n                                and so the model doesn't validate the amount and doesn't then cause the 'apply' button to appear.\n\n                                This means we need to check here (once a date is picked) if the user should see the 'apply' button.\n                                We do this by setting the attribute value again (thus causing the validation to be triggered)\n                             */\n                            self.model.set({\n                                amount: self.popup_amount.value\n                            });\n\n                            // The following code works out the number of days selected to pay back the loan\n\n                            var selected_date = this.getSelected();\n                            var temp_integer_month;\n                            var one_day;\n                            var payback_date;\n                            var days_to_pay;\n\n                            days_to_pay = selected_date.split('-');\n\n                            // Make sure the date is in the correct order\n                            self.selected_date = days_to_pay[2] + '-' + days_to_pay[1] + '-' + days_to_pay[0];\n                            \n                            // the date is returned as non-zero index format, so put it back to be zero-indexed\n                            temp_integer_month = parseInt(days_to_pay[1], 10);\n                            days_to_pay[1] = '0' + --temp_integer_month;\n\n                            one_day = 24*60*60*1000; // hours * minutes * seconds * milliseconds\n                            payback_date = new Date(days_to_pay[0], days_to_pay[1], days_to_pay[2]);\n                            days_to_pay = Math.ceil(Math.abs(((new Date()).getTime() - payback_date.getTime()) / (one_day)));\n                            \n                            // Keep reference to number of days to pay\n                            self.days_to_pay = days_to_pay;\n\n                            // call function which will pull in the relevant template and populate with relevant costs\n                            self.calculate();\n                        }\n                    }\n                }\n            });\n        },\n\n        close_popup: function(){\n            this.amount.value = ''; // We reset the value so the Model's \"change\" event can be fired (which is what we rely upon to trigger the popup)\n            this.trigger_popup.value = ''; // was finding Firefox would randomly put the 'amount' value into this input, can't see why though?\n            this.loan_details.innerHTML = '\u003cdt\u003e\u003c/dt\u003e\u003cdd\u003e\u003c/dd\u003e'; // if the user re-opens the popup then we don't want the old details to be there still\n            this.allow_app_process = false;\n            this.valid_date = false;\n            this.validation_pass = false;\n            this.apply_now.addClass('hide');\n            this.popup.addClass('hide');\n        },\n\n        calculate: function(){\n            // Noticed issue with keyup event constantly firing, so safer just to force the input to lose focus\n            this.popup_amount.blur();\n\n            // Context of \"this\" gets lost within the jQuery methods\n            var self = this;\n\n            // Wait for async functions to finish before inserting HTML\n            function process(){\n                $.when(self.get_costs(self.popup_amount.value)).then(function (data) {\n                    // Take the JSON data and compile it into the template file\n                    self.template_content = self.template.render(JSON.parse(data));\n\n                    // Generate the HTML code\n                    self.generate_html();\n                });\n            }\n            \n            // The following code prevents calling the server to load/compile the same template code every time the button is pressed.\n            // Instead we retrieve the template and compile it once\n            if (self.template) {\n                process();\n            } else {\n                $.ajax({\n                    url: 'Assets/Templates/Application-Calculator.txt',\n                    dataType: 'html',\n                    success: function (tmp) {\n                        self.template = hogan.compile(tmp);\n                        process();\n                    }\n                });\n            }\n        },\n\n        get_costs: function (amount) {\n            var dfd = $.Deferred();\n            \n            $.ajax({\n                url: 'Assets/PHP/calculator.php',\n                type: 'POST',\n                data: 'amount=' + amount + '\u0026days=' + this.days_to_pay,\n                success: function (data) {\n                    dfd.resolve(data);\n                }\n            });\n            \n            return dfd.promise();\n        },\n\n        generate_html: function(){\n            // Insert the template content into the DOM\n            this.loan_details.innerHTML = this.template_content;\n        }\n\n    });\n\n});\n","tags":""},{"id":"4327823","title":"Refreshing my memory on PHP inheritance and general OOP","content":"\u003c?php\n\n    // Configure error messages\n    ini_set('display_errors',1);\n    error_reporting(E_ALL);\n\n    class Adult {\n        /*\n            We set the visibility of these properties to 'protected' so they are accessible within the Child class.\n            We prefix private and protected properties/methods with an underscore, so (at a glance) while scanning a long file we can instantly recognise the visibility.\n         */\n        protected $_name;\n        protected $_age;\n\n        /*\n            Note: static properties/methods belong to the whole class (inc. sub classes)\n            To access it from within a class or subclass use `self::`\n            e.g. self::$_teststatic\n\n            Static properties/methods can also be accessed from outside the class using `ClassName::STATIC`\n            e.g. Adult::$_teststatic\n            \n            Attempts to access a normal public property from outside a class will cause an error, so the `static` keyword is required.\n            You can still set the visibility of a static property/method (e.g. if set to `protected` then running Adult::$_teststatic outside a class would cause an error)\n         */\n        public static $_teststatic = 'This is a test static property';\n\n        // Indicates how many class instances have been created\n        protected static $_counter = 0;\n\n        /*\n            Note: this constant can also be accessed from outside the class (like a static property) using `ClassName::CONSTANT`\n            e.g. Adult::LOCATION\n         */\n        const LOCATION = 'England';\n\n        public function __construct ($name, $age) {\n            $this-\u003e_name = $name;\n            $this-\u003e_age = $age;\n            $this-\u003eintroduction();\n\n            // Update the static property so we know another new instance has been created\n            self::$_counter++;\n        }\n\n        public function how_many_instances(){\n            echo 'There have been: ' . self::$_counter . ' number of class instances created.\u003chr\u003e';\n        }\n\n        public function reset_instances(){\n            self::$_counter = 0;\n        }\n\n        public function introduction(){\n            echo 'Hi, my name is ' . $this-\u003e_name . ' and I am ' . $this-\u003e_age . ' years old.\u003chr\u003e';\n        }\n\n        // Set visibility to `final` so it can never be modified by a sub class\n        final public function birthday(){\n            $this-\u003e_age++;\n            echo $this-\u003e_name . ' has had a birthday and is now ' . $this-\u003e_age . ' years old!\u003chr\u003e';\n        }\n    }\n\n    class Child extends Adult {\n        protected $_favtoy;\n\n        // We've inherited the Constructor from Adult but we'll overwrite it here\n        public function __construct ($name, $age, $favtoy) {\n            // We've not defined these properties (_name \u0026 _age) in this class - they're inherited from the Adult class.\n            $this-\u003e_name = $name;\n            $this-\u003e_age = $age;\n            $this-\u003e_favtoy = $favtoy;\n            $this-\u003eintroduction();\n\n            /*\n                Another way to do this with slightly less code is to call the parent class' constructor.\n                One problem I noticed was that if we ran this code we'd need to call the parent constructor AFTER setting properties on this instance (otherwise the property is never set?)\n                I'm not sure why the property would have not set when calling the parent constructor, but for whatever reason it wouldn't work until I moved the call after the properties?\n             */\n            //parent::__construct($name, $age);\n\n            // Update the static property so we know another new instance has been created\n            self::$_counter++;\n        }\n\n        // We're again, over writing this method so it's different from the Parent class\n        public function introduction(){\n            echo 'Hi, my name is ' . $this-\u003e_name . ' and I am ' . $this-\u003e_age . ' years old AND my favourite toy is ' . $this-\u003e_favtoy . '.\u003chr\u003e';\n        }\n\n        public function display_location(){\n            echo self::LOCATION . '\u003chr\u003e'; // constants defined inside a class need to be references by `SELF::`\n        }\n    }\n\n    class Baby extends Child {\n        const LOCATION = 'Bedroom'; // Note: constants can't be modified within their own class but sub classes can modify the value\n\n        /*\n            Note: even though the constant value has been updated if we relied on the inheritance chain then the value displayed would be the one defined in Child class\n            For it to work how we want it to we need to overwrite the `display_location` method completely.\n            We can't use parent::display_location(); inside of the redefined method because the scope/context still changes to the Child class.\n            So we literally need to have a duplicate of the `display_location` method.\n\n            Really the best thing to do here would be to not use a constant (as it's not actually a constant value if it changes between classes!) \n            Instead we should have used a protected property.\n         */\n        public function display_location(){\n            echo self::LOCATION . '\u003chr\u003e'; // constants defined inside a class need to be references by `SELF::`\n        }\n    }\n\n    $dad = new Adult('Bob', 40);\n    $mom = new Adult('Alice', 35);\n    $son = new Child('Jim', 10, 'Rubik Cube');\n    $baby = new Baby('Katie', 1, 'Thumb');\n\n    $dad-\u003ebirthday();\n    $son-\u003ebirthday();\n\n    $son-\u003edisplay_location();\n    $baby-\u003edisplay_location();\n\n    echo 'We\\'re accessing a public static method: \"' . Adult::$_teststatic . '\"\u003chr\u003e';\n\n    /*\n        Notice how each class instance references the same static property and returns the same value. \n        This was done on purpose to demonstrate static classes but this example is a bit pointless in real world terms.\n     */\n    Adult::how_many_instances();\n    Child::how_many_instances();\n    Baby::how_many_instances();\n\n    Adult::reset_instances(); // We have effectively set-up a priviledged method (it is public but it can access protected/private data)\n    Adult::how_many_instances(); // So although we can't access the static property directly (as the below line demonstrates) we can still change its value if we really need to.\n    echo Adult::$_counter; // Fatal error: Cannot access protected property Adult::$_counter in /Users/stormcreative/Sites/pdo/Class-inheritance.php on line 137 \n\n?\u003e\n","tags":""},{"id":"3926924","title":"Data warehouse module","content":"/*\n    A data warehouse mechanism (based on a basic implementation from @stoyanstefanov)\n\n    Example usage:\n\n                    var div = document.getElementById('test');\n\n                    Data.set(div, { yo: 'yo', ma: 'ma', la: 'la' });\n\n                    var testing = Data.get(div);\n                    var a = testing.yo;\n                    var b = testing.ma;\n                    var c = testing.la;\n\n                    console.log(testing, a, b, c);\n                    console.log(Data.show());\n\n                    Data.reset();\n\n                    console.log(Data.show());\n */\ndefine(function(){\n\n    var warehouse = {};\n    var count = 1;\n\n    window.onbeforeunload = function(){\n        Data.reset();\n    };\n\n    return {\n        /*\n            Set some data onto the specified Element via DOM property rather than via DOM attributes.\n\n            @param dom {Element/Node} the element to set data on\n            @param data {Multiple} the data to be set (could be an Array, String, Object anything)\n            @return undefined {undefined} no explicit return value\n         */\n        set: function (dom, data) {\n            // Set a DOM property '__data' and give it a unique ID value\n            if (!dom.__data) {\n                dom.__data = 'uid_' + count++;\n            }\n\n            // Store the data in our Warehouse object and assign it to a key whose value is the unique DOM property value\n            warehouse[dom.__data] = {\n                element: dom,\n                data: data\n            };\n        },\n\n        /*\n            Returns the data associated with the specified Element.\n\n            @param dom {Element/Node} the element to retrieve stored data for\n            @return warehouse[dom.__data] {Multiple} the data stored for the element with a DOM property of '__data'\n         */\n        get: function (dom) {\n            return warehouse[dom.__data].data;\n        },\n\n        /*\n            Resets the 'warehouse' object so there are no stored pieces of data\n\n            @return undefined {undefined} no explicit return value\n         */\n        reset: function(){\n            /*\n                We have created a circular reference by having a JavaScript object reference a DOM object, \n                and then having that same DOM object reference a JavaScript object.\n                So we clean-up after ourselves by null'ing the references when we reset the warehouse object.\n             */\n\n            // Loop through the properties of the 'warehouse' object\n            for (prop in warehouse) {\n                // Delete the DOM property\n                delete warehouse[prop].element.__data;\n            }\n\n            count = 1;\n            warehouse = {};\n        },\n\n        /*\n            Returns the 'warehouse' object itself so we can see at a glance its contents\n\n            @return warehouse {Object} the main 'warehouse' object\n         */\n        show: function(){\n            return warehouse;\n        }\n    };\n\n});\n","tags":""},{"id":"3743933","title":"Backbone.js example script (?)","content":"requirejs.config({\n    paths: {\n        Backbone: '../Utils/Libraries/backbone'\n    },\n    shim: {\n        'Backbone': {\n            deps: ['../Utils/Libraries/lodash', '../Utils/Libraries/jquery'], // load dependencies\n            exports: 'Backbone' // use the global 'Backbone' as the module value\n        }\n    }\n});\n\nrequire(['../Views/CustomerLogin'], function (CustomerLoginView) {\n\n    var customer_login = new CustomerLoginView();\n\n});\ndefine(['../Models/CustomerLogin', 'Backbone'], function (CustomerLogin) {\n\n    return Backbone.View.extend({\n        initialize: function(){\n            // Store the form element and hide it\n            this.form = this.$el.find('form');\n            this.form.hide();\n\n            // Store the Model object for easy reference\n            this.model = new CustomerLogin();\n        },\n\n        // The containing element\n        el: $('.customer-login'),\n\n        // Selectors are scoped to the parent element\n        events: {\n            'click .login-btn': 'toggle_display',\n            'submit form': 'store_user_details'\n        },\n\n        toggle_display: function(){\n            this.form.slideToggle();\n        },\n\n        store_user_details: function (e) {\n            // Calling 'set' triggers the Model's built-in 'validate' method (see: Models/CustomerLogin)\n            this.model.set({\n                account: this.form[0].elements[0].value,\n                password: this.form[0].elements[1].value\n            });\n\n            e.preventDefault();\n        }\n    });\n\n});\ndefine(['Backbone'], function(){\n\n    return Backbone.Model.extend({\n        initialize: function(){\n            this.on('error', this.handle_errors);\n        },  \n                      \n        validate: function (attributes) {\n            var errors = [];\n\n            if (attributes.account.indexOf('@') === -1) {\n                errors.push({\n                    field: 'account',\n                    value: attributes.account\n                });\n            }\n\n            if (attributes.password === '') {\n                errors.push({\n                    field: 'password',\n                    value: attributes.password\n                });\n            }\n\n            if (errors.length) {\n                return errors\n            }\n        },\n\n        handle_errors: function (model, error) {\n            _.each(error, function (list, iterator) {\n                console.log(list, iterator);\n            });\n        }\n    });\n\n});\n","tags":""},{"id":"3807247","title":"Basic Sass Grid","content":"$grid-columns: 12;\n$grid-width: 960px;\n$grid-gutter: 10px;\n@function column-width($cols) {\n  @return ($grid-width\n           - $grid-gutter * ($grid-columns - 1))\n          / $grid-columns * $cols\n          + $grid-gutter * ($cols - 1);\n}\n\n// Create the columns...\n.col-1 { width: column-width(1); }\n…\n.col-12 { width: column-width(12); }\n","tags":""},{"id":"3788967","title":"My mammoth View file (this needs refactoring for sure - maybe into sub views?)","content":"define(['Backbone'], function(){\n\n    var min = 50;\n    var max = 400;\n\n    return Backbone.Model.extend({\n        defaults: {\n            amount: 0,\n            code: null,\n            date: (new Date())\n        },\n\n        initialize: function(){\n            this.on('error', this.handle_errors);\n        },  \n                      \n        validate: function (attributes) {\n            var errors = [];\n            var amount = parseInt(attributes.amount, 10);\n\n            /*\n                We first parse the amount (as it comes through as a String)\n                Once it's converted to a number we check that the value is NaN.\n                We also check if the amount entered fits within the allowed range.\n             */\n            if (_.isNaN(amount) || amount \u003c min || amount \u003e max) {\n                errors.push({\n                    field: 'amount',\n                    error: 'The amount was invalid'\n                });\n            } \n            // If there were no errors validating this particular attribute...\n            else {\n                /*\n                   We use the following attribute 'event_type' to decide whether the user means to process the application or not.\n\n                   What happens is: regardless of whether the user changes the loan amount, or if they click on the 'apply' button, \n                   the amount is validated before proceeding.\n\n                   So if the user is changing the amount within the popup then the keyup event will fire, \n                   and so although the amount may be valid we don't want to suddenly automatically start processing the application!\n                   We only want that to happen if a click on the 'apply' button was made.\n\n                   So to work-around this we need to set a View property so the receiving method knows what's happening.\n                 */\n                \n                if (attributes.event_type === 'keyup') {\n                    this.view.allow_app_process = false; // don't allow application to be processed (because they've changed the amount, NOT pressed 'apply')\n                } \n                /*\n                    Noticed an issue with setting this value to true when it shouldn't have been\n                    It was getting set to true by the focus event of the amount input (outside the popup)\n                    So we worked around that by ignoring the focus event (could have set 'click' but not sure if that would be valid on mobile device?)\n                 */\n                else if (attributes.event_type !== 'focusin') {\n                    this.view.allow_app_process = true; // allow application to be processed\n                }\n\n                /*\n                    OK I can imagine this manual trigger of the custom event 'amount:changed' might seem strange at first \n                    (as Model's accept event listeners on their initialize method), but there apparently was no other work-around.\n\n                    Talking to the Backbone.js maintainers they suggested that I manually trigger the custom event like this.\n                    Which was instead of having: this.on('change:amount', this.amount_change); =\u003e which itself then ran: this.trigger('amount:changed');\n\n                    The problem was/is as follows:\n                    \n                    If a user enters a valid amount `123` and then enters an invalid amount like zero then the attribute value isn't changed.\n                    But if the user then enters the correct amount `123` again the change event can't be fired because nothing has actually changed.\n                    So we relying on the change event firing, to tell if the application should go through, but this logic was flawed here.\n                    \n                    This meant we needed to manually trigger the 'amount:changed' event after successfully validating the data, \n                    rather than relying on the Model to trigger a change event.\n                 */\n                this.trigger('amount:changed');\n            }\n\n            if (errors.length) {\n                // We pass some info through to the View so it knows that the validation failed\n                this.view.validation_pass = false;\n                this.view.allow_app_process = false;\n                \n                return errors\n            }\n        },\n\n        handle_errors: function (model, error) {\n            // Context of \"this\" gets lost within _.each()\n            var self = this;\n            \n            _.each(error, function (item, iterator) {\n                self.trigger('item:invalid', item);\n            });\n        }\n    });\n\n});\ndefine(['../Utils/Templating/hogan', '../Utils/Datepicker/kalendae', '../Models/LoanApplication', '../Utils/DOM/getEl', 'Backbone'], function (hogan, Kalendae, LoanApplication, getElement) {\n\n    return Backbone.View.extend({\n        model: new LoanApplication(),\n\n        initialize: function(){\n            // Store other elements that will be interacted with.\n            // Any element that will potentially utilise jQuery we pre-wrap in a single jQuery instance.\n            this.promocode = getElement('js-promocode');\n            this.amount = getElement('js-amount');\n            this.error_amount = $('#js-amounterror');\n            this.error_amount_popup = $('#js-amounterror-popup');\n            this.popup = $('#js-loanpopup');\n            this.popup_amount = getElement('js-popupamount');\n            this.loan_details = getElement('js-loandetails');\n            this.apply_now = $('#js-applynow');\n\n            // We use this to tell whether the calendar widget has already been rendered,\n            // as there is no point re-rendering it every time the popup is closed then opened again.\n            this.is_calendar_rendered = false;\n\n            // Details that will be passed around in different methods\n            this.days_to_pay = null;\n            this.amount_to_borrow = null;\n\n            // This holds the template file we'll compile with data pulled from server\n            this.template = null;\n            this.template_content = null;\n\n            // The Model triggers custom events when certain actions happen which the View should ideally handle\n            this.model.on('item:invalid', this.process_errors, this);\n            this.model.on('amount:changed', this.validation_success, this);\n\n            // There is one instance where we need the Model to have access to the View (so we can set a shared property)\n            this.model.view = this;\n\n            // Used within 'validate_amount' method\n            this.allow_app_process = false;\n\n            // Used to determine if the application can proceed\n            this.valid_date = false;\n\n            // Used to determine if the validation passed\n            this.validation_pass = false;\n        },\n\n        // The containing element\n        el: getElement('js-loanapplication'),\n\n        // Selectors are scoped to the parent element\n        events: {\n            'focus #js-pickdate': 'validate_amount',\n            'click #js-calendarclose': 'close_popup',\n            'click #js-applynow': 'validate_amount',\n            'keyup #js-popupamount': 'validate_amount'\n        },\n\n        validate_amount: function (e) {\n            /*\n                First thing we need to do is to lose focus on the #js-pickdate input element\n                Otherwise, if the user has the popup open and then decides to view a different screen and comes back.\n                Returning back causes the input to gain focus again.\n             */\n            getElement('js-pickdate').blur();\n\n            /*\n                We validate a different field depending on whether the popup is open (the popup has its own copy of the application fields)\n                Note: Model's \"set\" method calls Backbone validation by default (see Model for validation rules)\n             */\n\n            // If popup is hidden\n            if (this.popup.hasClass('hide')) {\n                this.model.set({\n                    amount: this.amount.value,\n                    event_type: e.type\n                });\n            } \n            // If popup is visible\n            else {\n                if (e.type === 'keyup') {\n                    /*\n                        We don't want to validate the amount if the user is just pressing the shift key or the left/right/up/down arrow keys:\n                        Shift = 16 | Left = 37 | Up = 38 | Right = 39 | Down = 40\n                     */\n                    if (!_.contains([16, 37, 38, 39, 40], e.keyCode)) {\n                        this.model.set({\n                            amount: this.popup_amount.value,\n                            event_type: e.type // passing through the event type means we can prevent the 'remove_error' method from processing the application\n                        });\n                    }\n                }\n                else {\n                    this.model.set({\n                        amount: this.popup_amount.value,\n                        event_type: e.type\n                    });\n                }\n            }\n        },\n\n        process_errors: function (item) {\n            // Hide the 'apply' button if it's already viewable\n            this.apply_now.addClass('hide');\n\n            // Check what field was invalid and display corresponding error message\n            switch (item.field) {\n                case 'amount':\n                    // We display the error message in a different place depending on whether the popup is open\n                    \n                    // If the popup is NOT visible\n                    if (this.popup.hasClass('hide')) {\n                        this.error_amount.removeClass('invisible');\n                    } else {\n                        this.error_amount_popup.removeClass('invisible');\n                    }\n                    \n                    break;\n            }\n        },\n\n        validation_success: function(){\n            this.validation_pass = true;\n            this.check_apply_display();\n        },\n\n        check_apply_display: function(){\n            // If there is a valid date then we can show the 'apply' button\n            if (this.valid_date) {\n                this.apply_now.removeClass('hide');\n            }\n\n            // Now we hide any errors\n            this.remove_error();\n        },\n\n        // TODO: refactor this function - surely the inner if statement logic can be abstracted into a separate function?\n        remove_error: function(){\n            // We remove the error message from different places depending on whether the popup is open\n\n            // If the popup is NOT visible\n            if (this.popup.hasClass('hide')) {\n                this.error_amount.addClass('invisible');\n                this.display_calendar();\n            } else {\n                this.error_amount_popup.addClass('invisible');\n\n                // Only process the application if the user has explictly clicked on the 'apply' button and their data has been validate\n                if (this.allow_app_process \u0026\u0026 this.valid_date) {\n                    alert('NOW PROCESS THE APPLICATION!');\n                } else {\n                    // Only trigger a calculation to be made if a date has been selected\n                    if (this.valid_date) {\n                        this.calculate();\n                    } else {\n                        // Noticed issue with keyup event constantly firing, so safer just to force the input to lose focus\n                        this.popup_amount.blur();\n                    }\n                }\n            }\n        },\n\n        display_calendar: function(){\n            // We only load the calendar on screens large enough to display it\n            // And we make sure to only render it once by check \"is_calendar_rendered\" is false\n            if (document.documentElement.clientWidth \u003e= 585 \u0026\u0026 !this.is_calendar_rendered) {\n                this.render_calendar();\n            }\n\n            // Pass through the value into this new popup view\n            this.popup_amount.value = this.amount.value;\n\n            // Make the popup visible\n            this.popup.removeClass('hide');\n        },\n\n        render_calendar: function(){\n            this.is_calendar_rendered = true;\n\n            // Context of \"this\" gets lost within the Kalendae script\n            var self = this;\n\n            // the following variables are used for calculating the difference between \n            // today's date and the selected date to pay back the loan\n            var calendar_container = getElement('js-calendar');\n            var curent_date = new Date();\n            var current_day = curent_date.getDate();\n            var current_month = curent_date.getMonth();\n            var current_year = curent_date.getFullYear();\n            var today, calendar;\n            \n            // we correct current_month to include a zero prefix if the number is less than 10\n            current_month = (current_month \u003c 10) ? ('0' + current_month) : current_month;\n            \n            // construct a date for today which is used for calculating diff\n            today = new Date(current_year, current_month, current_day);\n            \n            calendar = new Kalendae({\n                // element to attach the calendar to\n                attachTo: calendar_container,\n                \n                // blackout days after 45 days from current date\n                blackout: function (date) {\n                    return Kalendae.moment().yearDay() + 45 \u003c date.yearDay(); // yearDay() is an extension Kalendae adds to moment.js to calculate the total number of days since epoch.\n                },\n                \n                // how many characters from the week day name to display (e.g. we've gone with 3 = Mon, Tue, Wed, Thu, Fri, Sat, Sun)\n                columnHeaderLength: 3,\n                \n                // restricts date selectability to past or future ('future' blacks out all days previous to current date)\n                direction: 'future',\n                \n                // only allows selection of one day\n                mode: 'single',\n                \n                // determines the number of months to display\n                months: 2,\n                \n                // determines when the week should start (Sunday = 0 [default] or Monday = 1 etc)\n                weekStart: 1,\n                \n                // causes the \u003cinput\u003e to update to the selected date\n                subscribe: {\n                    'date-clicked': function(){\n                        // This event is fire before the selection is changed\n                        if (!self.validation_pass) {\n                            return false;\n                        }\n                    },\n                    'change': function(){\n                        // We don't want to let the user select a date if the amount is invalid\n                        // allow_app_process is being used to determine if the app can move to stage 1 of application\n                        // but it's set every time validation is carried out so we can use it here\n                        if (self.validation_pass) {\n                            // We know a date was selected so we store that information\n                            self.valid_date = true;\n\n                            /*\n                                There could be an instance where the user enters a valid amount *before* the popup is shown, \n                                and then selects a date from the date picker, but that wont trigger a change event on the amount \n                                and so the model doesn't validate the amount and doesn't then cause the 'apply' button to appear.\n\n                                This means we need to check here (once a date is picked) if the user should see the 'apply' button.\n                                We do this by setting the attribute value again (thus causing the validation to be triggered)\n                             */\n                            self.model.set({\n                                amount: self.popup_amount.value\n                            });\n\n                            // The following code works out the number of days selected to pay back the loan\n                            \n                            var selected_date = this.getSelected();\n                            var temp_integer_month;\n                            var one_day;\n                            var payback_date;\n                            var days_to_pay;\n\n                            days_to_pay = selected_date.split('-');\n                            \n                            // the date is returned as non-zero index format, so put it back to be zero-indexed\n                            temp_integer_month = parseInt(days_to_pay[1], 10);\n                            days_to_pay[1] = '0' + --temp_integer_month;\n                            \n                            one_day = 24*60*60*1000; // hours * minutes * seconds * milliseconds\n                            payback_date = new Date(days_to_pay[0], days_to_pay[1], days_to_pay[2]);\n                            days_to_pay = Math.round(Math.abs((today.getTime() - payback_date.getTime()) / (one_day)));\n                            \n                            // Keep reference to number of days to pay\n                            self.days_to_pay = days_to_pay;\n\n                            // call function which will pull in the relevant template and populate with relevant costs\n                            self.calculate();\n                        }\n                    }\n                }\n            });\n        },\n\n        close_popup: function(){\n            this.amount.value = ''; // We reset the value so the Model's \"change\" event can be fired (which is what we rely upon to trigger the popup)\n            this.popup.addClass('hide');\n            this.loan_details.innerHTML = '\u003cdt\u003e\u003c/dt\u003e\u003cdd\u003e\u003c/dd\u003e'; // if the user re-opens the popup then we don't want the old details to be there still\n        },\n\n        calculate: function(){\n            // Noticed issue with keyup event constantly firing, so safer just to force the input to lose focus\n            this.popup_amount.blur();\n\n            // Context of \"this\" gets lost within the Kalendae script\n            var self = this;\n\n            // Wait for async functions to finish before inserting HTML\n            function process(){\n                $.when(self.get_costs(self.popup_amount.value)).then(function (data) {\n                    // Take the JSON data and compile it into the template file\n                    self.template_content = self.template.render(JSON.parse(data));\n\n                    // Generate the HTML code\n                    self.generate_html();\n                });\n            }\n            \n            // The following code prevents calling the server to load/compile the same template code every time the button is pressed.\n            // Instead we retrieve the template and compile it once\n            if (self.template) {\n                process();\n            } else {\n                $.ajax({\n                    url: 'Assets/Templates/Application-Calculator.txt',\n                    dataType: 'html',\n                    success: function (tmp) {\n                        self.template = hogan.compile(tmp);\n                        process();\n                    }\n                });\n            }\n        },\n\n        get_costs: function (amount) {\n            var dfd = $.Deferred();\n            \n            $.ajax({\n                url: 'Assets/PHP/calculator.php',\n                type: 'POST',\n                data: 'amount=' + amount + '\u0026days=' + this.days_to_pay,\n                success: function (data) {\n                    dfd.resolve(data);\n                }\n            });\n            \n            return dfd.promise();\n        },\n\n        generate_html: function(){\n            // Insert the template content into the DOM\n            this.loan_details.innerHTML = this.template_content;\n        }\n\n    });\n\n});\n","tags":""},{"id":"3675078","title":"Toast Grid Code","content":"/*\nToast Framework - grid.css\n*/\n.wrap {\n  max-width: 940px;\n  padding: 10px;\n  margin: 0 auto;\n}\n\n/*\nColumn container\n*/\n.grids {\n  width: auto;\n  max-width: 960px;\n  margin: 0 0 0 -1.7%;\n  list-style: none;\n  /* So we can make grids out of lists. */\n\n  overflow: hidden;\n  /* Clear the floats */\n\n  letter-spacing: -.25em; /* Fix inline-block weirdness */\n}\n\n.grids [class*=\"grid-\"] {\n  display: inline-block;\n  margin: 0 0 0 1.7%;\n  -webkit-box-sizing: border-box; /* Allow padding \u0026 borders on grids without breaking. IE8+ */\n  -moz-box-sizing: border-box;\n  box-sizing: border-box;\n  vertical-align: top;\n  letter-spacing: 0; /* And restore our letter spacing. */\n}\n\n.grid-1 {\n  width: 6.15%;\n}\n\n.grid-2 {\n  width: 14.583%;\n}\n\n.grid-3 {\n  width: 22.917%;\n}\n\n.grid-4, .grid-one-third {\n  width: 31.25%;\n}\n\n.grid-5 {\n  width: 39.583%;\n}\n\n.grid-6, .grid-half {\n  width: 47.917%;\n}\n\n.grid-7 {\n  width: 56.25%;\n}\n\n.grid-8, .grid-two-thirds {\n  width: 64.583%;\n}\n\n.grid-9 {\n  width: 72.917%;\n}\n\n.grid-10 {\n  width: 81.25%;\n}\n\n.grid-11 {\n  width: 89.583%;\n}\n\n.grid-12 {\n  width: 97.917%;\n  margin: 0;\n}\n\n@media screen and (max-width: 700px) {\n  .grids {\n    margin: 0;\n    width: auto;\n  }\n\n  .grids [class*=\"grid-\"] {\n    display: block;\n    width: auto;\n    margin: 0;\n  }\n}\n","tags":""},{"id":"3226822","title":"Sass: referencing parent selector","content":"[http://thesassway.com/intermediate/referencing-parent-selectors-using-ampersand](http://thesassway.com/intermediate/referencing-parent-selectors-using-ampersand)\n\n```scss\nh3 {\n    font-size: 20px\n    margin-bottom: 10px\n    \n    .ie8 \u0026 {\n        font-size: 24px\n        margin-bottom: 20px\n    }\n}\n```\n\n...produces...\n\n```css\nh3 {\n    font-size: 20px\n    margin-bottom: 10px\n}\n\n.ie8 h3 {\n    font-size: 24px\n    margin-bottom: 20px\n}\n```\n\n...perfect for keeping IE related style fixes together (rather than bunching them up at the bottom of your main rule)\n","tags":""},{"id":"3761608","title":"The model only triggers the change event when the value being set is unique (i.e. not set before)","content":"define(['../Utils/Templating/hogan', '../Utils/Datepicker/kalendae', '../Models/LoanApplication', '../Utils/DOM/getEl', 'Backbone'], function (hogan, Kalendae, LoanApplication, getElement) {\n\n    // ES3, ES5 non strict\n    var global = (function(){return this})();\n\n    return Backbone.View.extend({\n        initialize: function(){\n            // Store other elements that will be interacted with.\n            // Any element that will potentially utilise jQuery we pre-wrap in a single jQuery instance.\n            this.promocode = getElement('js-promocode');\n            this.amount = getElement('js-amount');\n            this.error_amount = $('#js-amounterror');\n            this.error_amount_popup = $('#js-amounterror-popup');\n            this.popup = $('#js-loanpopup');\n            this.popup_amount = getElement('js-popupamount');\n\n            // We use this to tell whether the calendar widget has already been rendered,\n            // as there is no point re-rendering it every time the popup is closed then opened again.\n            this.is_calendar_rendered = false;\n\n            // Store the Model object for easy reference\n            this.model = new LoanApplication();\n\n            // The Model triggers custom events when certain actions happen which the View should ideally handle\n            this.model.on('item:invalid', this.process_errors, this);\n            this.model.on('amount:changed', this.remove_error, this);\n        },\n\n        // The containing element\n        el: getElement('js-loanapplication'),\n\n        // Selectors are scoped to the parent element\n        events: {\n            'focus #js-pickdate': 'validate_amount',\n            'click #js-calendarclose': 'close_popup',\n            'click #js-applynow': 'validate_amount'\n        },\n\n        validate_amount: function(){\n            // We validate a different field depending on whether the popup is open (the popup has its own copy of the application fields)\n            // Note: Model's \"set\" method calls Backbone validation by default (see Model for validation rules)\n                    \n            // If the popup is NOT visible\n            if (this.popup.hasClass('hide')) {\n                this.model.set({\n                    amount: this.amount.value\n                });\n            } else {\n                this.model.set({\n                    amount: this.popup_amount.value\n                });\n            }\n        },\n\n        process_errors: function (item) {\n            // Check what field was invalid and display corresponding error message\n            switch (item.field) {\n                case 'amount':\n                    // We display the error message in a different place depending on whether the popup is open\n                    \n                    // If the popup is NOT visible\n                    if (this.popup.hasClass('hide')) {\n                        this.error_amount.removeClass('invisible');\n                    } else {\n                        this.error_amount_popup.removeClass('invisible');\n                    }\n                    \n                    break;\n            }\n        },\n\n        remove_error: function(){\n            // We remove the error message from different places depending on whether the popup is open\n\n            // If the popup is NOT visible\n            if (this.popup.hasClass('hide')) {\n                this.error_amount.addClass('invisible');\n                this.display_calendar();\n            } else {\n                this.error_amount_popup.addClass('invisible');\n\n                // NOW PROCESS THE APPLICATION!\n            }\n        },\n\n        display_calendar: function(){\n            // We only load the calendar on screens large enough to display it\n            // And we make sure to only render it once by check \"is_calendar_rendered\" is false\n            if (document.documentElement.clientWidth \u003e= 585 \u0026\u0026 !this.is_calendar_rendered) {\n                this.render_calendar();\n            }\n\n            this.popup_amount.value = this.amount.value; // pass through the value into this new popup view\n            this.popup.removeClass('hide');\n        },\n\n        render_calendar: function(){\n            this.is_calendar_rendered = true;\n\n            // the following variables are used for calculating the difference between \n            // today's date and the selected date to pay back the loan\n            var calendar_container = getElement('js-calendar');\n            var curent_date = new Date();\n            var current_day = curent_date.getDate();\n            var current_month = curent_date.getMonth();\n            var current_year = curent_date.getFullYear();\n            var today, calendar;\n            \n            // we correct current_month to include a zero prefix if the number is less than 10\n            current_month = (current_month \u003c 10) ? ('0' + current_month) : current_month;\n            \n            // construct a date for today which is used for calculating diff\n            today = new Date(current_year, current_month, current_day);\n            \n            calendar = new Kalendae({\n                // element to attach the calendar to\n                attachTo: calendar_container,\n                \n                // blackout days after 45 days from current date\n                blackout: function (date) {\n                    return Kalendae.moment().yearDay() + 45 \u003c date.yearDay(); // yearDay() is an extension Kalendae adds to moment.js to calculate the total number of days since epoch.\n                },\n                \n                // how many characters from the week day name to display (e.g. we've gone with 3 = Mon, Tue, Wed, Thu, Fri, Sat, Sun)\n                columnHeaderLength: 3,\n                \n                // restricts date selectability to past or future ('future' blacks out all days previous to current date)\n                direction: 'future',\n                \n                // only allows selection of one day\n                mode: 'single',\n                \n                // determines the number of months to display\n                months: 2,\n                \n                // determines when the week should start (Sunday = 0 [default] or Monday = 1 etc)\n                weekStart: 1,\n                \n                // causes the \u003cinput\u003e to update to the selected date\n                subscribe: {\n                    'change': function(){\n                        var selected_date = this.getSelected();\n                        var temp_integer_month;\n                        var one_day;\n                        var payback_date;\n                        \n                        days_to_pay = selected_date.split('-');\n                        \n                        // the date is returned as non-zero index format, so put it back to be zero-indexed\n                        temp_integer_month = parseInt(days_to_pay[1], 10);\n                        days_to_pay[1] = '0' + --temp_integer_month;\n                        \n                        one_day = 24*60*60*1000; // hours * minutes * seconds * milliseconds\n                        payback_date = new Date(days_to_pay[0], days_to_pay[1], days_to_pay[2]);\n                        days_to_pay = Math.abs((today.getTime() - payback_date.getTime()) / (one_day));\n                        \n                        // update the \u003cinput\u003e #js-choosepaydate (currently sitting behind the popup) to display the date selected by the user\n                        //paydate.value = selected_date;\n                        \n                        // call function which will pull in the relevant template and populate with relevant costs\n                        //calculate();\n                        console.log(selected_date);\n                    }\n                }\n            });\n        },\n\n        close_popup: function(){\n            this.popup.addClass('hide');\n            this.amount.value = ''; // we reset the value so the Model's \"change\" event can be fired (which is what we rely upon to trigger the popup)\n        }\n\n    });\n\n});\ndefine(['Backbone'], function(){\n\n    var min = 50;\n    var max = 400;\n\n    return Backbone.Model.extend({\n        defaults: {\n            amount: 0,\n            code: null,\n            date: (new Date())\n        },\n\n        initialize: function(){\n            this.on('error', this.handle_errors);\n            this.on('change:amount', this.amount_change);\n        },  \n                      \n        validate: function (attributes) {\n            var errors = [];\n            var amount = parseInt(attributes.amount, 10);\n\n            /*\n                We first parse the amount (as it comes through as a String)\n                Once it's converted to a number we check that the value is NaN.\n                We also check if the amount entered fits within the allowed range.\n             */\n            if (_.isNaN(amount) || amount \u003c min || amount \u003e max) {\n                errors.push({\n                    field: 'amount',\n                    error: 'The amount was invalid'\n                });\n            }\n\n            if (errors.length) {\n                return errors\n            }\n        },\n\n        handle_errors: function (model, error) {\n            // Context of 'this' gets lost within _.each()\n            var self = this;\n            \n            _.each(error, function (item, iterator) {\n                self.trigger('item:invalid', item);\n            });\n        },\n\n        amount_change: function(){\n            this.trigger('amount:changed');\n        }\n    });\n\n});\n","tags":""},{"id":"3414140","title":"Example font-face code","content":"@font-face {\n    font-family: 'TTMegaThin';\n    src: url('../Fonts/titilliumtext22l001-webfont.eot');\n    src: url('../Fonts/titilliumtext22l001-webfont.eot?#iefix') format('embedded-opentype'),\n         url('../Fonts/titilliumtext22l001-webfont.woff') format('woff'),\n         url('../Fonts/titilliumtext22l001-webfont.ttf') format('truetype'),\n         url('../Fonts/titilliumtext22l001-webfont.svg#TitilliumText22LThThin') format('svg');\n    font-weight: normal;\n    font-style: normal;\n}\n\n@font-face {\n    font-family: 'TTThin';\n    src: url('../Fonts/titilliumtext22l002-webfont.eot');\n    src: url('../Fonts/titilliumtext22l002-webfont.eot?#iefix') format('embedded-opentype'),\n         url('../Fonts/titilliumtext22l002-webfont.woff') format('woff'),\n         url('../Fonts/titilliumtext22l002-webfont.ttf') format('truetype'),\n         url('../Fonts/titilliumtext22l002-webfont.svg#TitilliumText22LLtThin') format('svg');\n    font-weight: normal;\n    font-style: normal;\n}\n\n@font-face {\n    font-family: 'TTRegular';\n    src: url('../Fonts/titilliumtext22l003-webfont.eot');\n    src: url('../Fonts/titilliumtext22l003-webfont.eot?#iefix') format('embedded-opentype'),\n         url('../Fonts/titilliumtext22l003-webfont.woff') format('woff'),\n         url('../Fonts/titilliumtext22l003-webfont.ttf') format('truetype'),\n         url('../Fonts/titilliumtext22l003-webfont.svg#TitilliumText22LRgRegular') format('svg');\n    font-weight: normal;\n    font-style: normal;\n}\n\n@font-face {\n    font-family: 'TTMedium';\n    src: url('../Fonts/titilliumtext22l004-webfont.eot');\n    src: url('../Fonts/titilliumtext22l004-webfont.eot?#iefix') format('embedded-opentype'),\n         url('../Fonts/titilliumtext22l004-webfont.woff') format('woff'),\n         url('../Fonts/titilliumtext22l004-webfont.ttf') format('truetype'),\n         url('../Fonts/titilliumtext22l004-webfont.svg#TitilliumText22LLtMedium') format('svg');\n    font-weight: normal;\n    font-style: normal;\n}\n\n@font-face {\n    font-family: 'TTBold';\n    src: url('../Fonts/titilliumtext22l005-webfont.eot');\n    src: url('../Fonts/titilliumtext22l005-webfont.eot?#iefix') format('embedded-opentype'),\n         url('../Fonts/titilliumtext22l005-webfont.woff') format('woff'),\n         url('../Fonts/titilliumtext22l005-webfont.ttf') format('truetype'),\n         url('../Fonts/titilliumtext22l005-webfont.svg#TitilliumText22LRgBold') format('svg');\n    font-weight: normal;\n    font-style: normal;\n}\n\n@font-face {\n    font-family: 'TTMegaBold';\n    src: url('../Fonts/titilliumtext22l006-webfont.eot');\n    src: url('../Fonts/titilliumtext22l006-webfont.eot?#iefix') format('embedded-opentype'),\n         url('../Fonts/titilliumtext22l006-webfont.woff') format('woff'),\n         url('../Fonts/titilliumtext22l006-webfont.ttf') format('truetype'),\n         url('../Fonts/titilliumtext22l006-webfont.svg#TitilliumText22LXbBold') format('svg');\n    font-weight: normal;\n    font-style: normal;\n}\n\nh1 {\n    font-family: 'TTRegular';\n}\n","tags":""},{"id":"3447189","title":"Basic Page Layout ","content":"\u003c!doctype html\u003e\n\u003chtml lang=\"en\"\u003e\n  \u003chead\u003e\n    \u003cmeta charset=\"utf-8\"\u003e\n    \u003ctitle\u003e...\u003c/title\u003e\n  \u003c/head\u003e\n  \u003cbody\u003e\n    \u003ch1\u003e...\u003c/h1\u003e\n    \u003cscript src=\"...\"\u003e\u003c/script\u003e\n  \u003c/body\u003e\n\u003c/html\u003e\n\u003c!doctype html\u003e\n\u003c!--[if IE 8]\u003e\u003chtml class=\"ie8\" dir=\"ltr\" lang=\"en\"\u003e\u003c![endif]--\u003e\n\u003c!--[if IE 9]\u003e\u003chtml class=\"ie9\" dir=\"ltr\" lang=\"en\"\u003e\u003c![endif]--\u003e\n\u003c!--[if gt IE 9]\u003e\u003c!--\u003e \u003chtml dir=\"ltr\" lang=\"en\"\u003e \u003c!--\u003c![endif]--\u003e\n    \u003chead\u003e\n        \u003cmeta charset=\"utf-8\"\u003e\n        \u003cmeta name=\"viewport\" content=\"width=device-width, initial-scale=1\"\u003e\n        \u003cmeta name=\"author\" content=\"\" /\u003e\n        \u003ctitle\u003e\u003c/title\u003e\n        \u003cscript\u003e\n            // Google Analytics is loaded asynchronously so it's OK to insert it at the top of the page\n            // All other JavaScript should be loaded at the bottom of the page though.\n            var _gaq = _gaq || [];\n            _gaq.push(['_setAccount', 'UA-XXXXX-X']);\n            _gaq.push(['_trackPageview']);\n            _gaq.push(['_trackPageLoadTime']);\n            \n            (function(){\n                var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;\n                ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';\n                var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);\n            }());\n        \u003c/script\u003e\n        \u003c!--[if lt IE 9]\u003e\n            \u003cscript src=\"/Assets/Scripts/Utils/Elements/html5.js\"\u003e\u003c/script\u003e\n        \u003c![endif]--\u003e\n        \u003clink rel=\"author\" href=\"/humans.txt\" type=\"text/plain\"\u003e\n        \u003clink rel=\"stylesheet\" href=\"Assets/Styles/320px-480px_home.css\"  media=\"only screen and (min-width: 20em) and (max-width: 30em)\"\u003e\n        \u003clink rel=\"stylesheet\" href=\"Assets/Styles/600px-959px_home.css\"  media=\"only screen and (min-width: 37.5em) and (max-width: 59.9375em)\"\u003e\n        \u003clink rel=\"stylesheet\" href=\"Assets/Styles/960px_home.css\" media=\"only screen and (min-width: 60em)\"\u003e\n        \u003c!--[if (lt IE 9) \u0026 (!IEMobile)]\u003e\n        \u003clink rel=\"stylesheet\" href=\"/Assets/Styles/960px_home.css\"\u003e\n        \u003c![endif]--\u003e\n    \u003c/head\u003e\n    \u003cbody\u003e\n        \u003c!--[if lte IE 7]\u003e\n            \u003clink rel=\"stylesheet\" media=\"screen\" href=\"/Assets/Styles/IE_notification.css\" /\u003e\n            \u003cdiv id=\"ie-container\"\u003e\u003c/div\u003e\n            \u003cdiv id=\"ie-message\"\u003e\n                \u003ca href=\"/internet-explorer\"\u003e\n                    \u003cspan\u003eInternet Explorer 6/7\u003c/span\u003e\n                    \u003cimg src=\"/Assets/Images/Browser-Warning-Message.png\"\u003e\n                \u003c/a\u003e\n            \u003c/div\u003e\n        \u003c![endif]--\u003e\n        Content.\n    \u003c/body\u003e\n\u003c/html\u003e\n","tags":"#basic #html"},{"id":"3931680","title":"Sass Mixin for CSS3 Animations","content":"@include keyframe(fadeout) {\n    0% {\n        opacity: 1;\n    }\n\n    100% {\n        opacity: 0;\n    }\n}\n\n@include keyframe(changecolour) {\n    0% {\n        color: #000;\n    }\n\n    100% {\n        color: #FFF;\n    }\n}\n@mixin keyframe ($animation_name) {\n    @-webkit-keyframes $animation_name {\n        @content;\n    }\n\n    @-moz-keyframes $animation_name {\n        @content;\n    }\n\n    @-o-keyframes $animation_name {\n        @content;\n    }\n\n    @keyframes $animation_name {\n        @content;\n    }\n}\n/*\n    Example usage: \n    @include animation(10s, 5s, changecolour)\n */\n@mixin animation ($delay, $duration, $animation) {\n    -webkit-animation-delay: $delay;\n    -webkit-animation-duration: $duration;\n    -webkit-animation-name: $animation;\n    -webkit-animation-fill-mode: forwards; /* this prevents the animation from restarting! */\n\n    -moz-animation-delay: $delay;\n    -moz-animation-duration: $duration;\n    -moz-animation-name: $animation;\n    -moz-animation-fill-mode: forwards; /* this prevents the animation from restarting! */\n\n    -o-animation-delay: $delay;\n    -o-animation-duration: $duration;\n    -o-animation-name: $animation;\n    -o-animation-fill-mode: forwards; /* this prevents the animation from restarting! */\n\n    animation-delay: $delay;\n    animation-duration: $duration;\n    animation-name: $animation;\n    animation-fill-mode: forwards; /* this prevents the animation from restarting! */\n}\n","tags":""},{"id":"2030311","title":"Unit Testing with BusterJS","content":"Folder structure:  \n\n* example.js\n* index.html\n* /test/\n  * buster.js\n  * example-test.js\n\nWhen in the terminal application I move to the `/test/` folder and after running `buster server` and opening port 1111 in my browsers of choice (or in this case just one browser FF 10.0.2) I then open a new terminal tab and execute `buster test --reporter specification` but the terminal just hangs there doing nothing (where originally it would run the `example-test.js` test case and show what failed/succeeded).\n\nCan you advise if I've missed something really obvious? I'm using the latest busterjs version (uninstalled and re-installed via NPM)\n\n// Create a new assertion\nbuster.assertions.add('myIsArray', {\n\tassert: function (obj) {\n\t\treturn Object.prototype.toString.call(obj).slice(8, -1) === 'Array';\n\t}\n});\n\n// Typically, you have one test case per file\nbuster.testCase('My test module', {\n    \n    // Can't have empty setUp/tearDown methods, but I leave them here to remember the syntax\n    \n    setUp: function(){\n    \tthis.clock = this.useFakeTimers(); // needed for async tests - modifies setTimeout/Interval to be synchronous (see: http://sinonjs.org/docs/#clock)\n    },\n    \n    tearDown: function(){\n        this.clock.restore(); // put back the original asynchronous versions of setTimeout/Interval\n    },\n    \n    // Two forward slashes at the start of a test case's name indicates that it should be ignored but shown in the results as 'deferred'    \n    '//A test that I want to comment out for a while but not hide from the test results': function(){\n    \tvar num = 123;\n    \tassert.match(num, 123);\n    },\n    \n    'an async test': function(){\n    \tvar num;\n    \t\n        window.setTimeout(function(){\n    \t\tnum = 123;\n    \t}, 10000);\n    \t\n    \tthis.clock.tick(10000);\n    \t\n    \tassert.match(num, 123);\n    },\n    \n    // Test case\n    'A bad test (as it tests random stuff when it should test specific functionality)': function(){\n    \t// See all assertions: http://busterjs.org/docs/assertions/\n\t\t\n\t\t/* Assertion: assert\n\t\t *******************/\n\t\t\n\t\tvar user = canDrink(18);\n\t\tassert(user);\n\t\t\n\t\t/*\n\t\tvar mytest = false;\n\t\tassert(mytest, 'my failure message taken from the assert that failed!');\n\t\t*/\n\t\t\n\t\t/* Assertion: match (regex)\n\t\t **************************/\n\t\t\n\t\tvar test = 'This is my string with some {{data}} inside of {{template}} brackets';\n\t\tassert.match(test, /{{[a-z]+}}/i);\n\t\t\n\t\t/* Assertion: match (element)\n\t\t ****************************/\n\t\t\n\t\tvar elem = document.createElement('h1'),\n\t\t\ttxt = document.createTextNode('some text');\n\t\t\n\t\telem.className = 'myClass';\n\t\telem.appendChild(txt);\n\t\t\n\t\tassert.match(elem, {\n\t\t\ttagName: 'h1',\n\t\t\tclassName: 'myClass',\n\t\t\tinnerHTML: 'some text'\n\t\t});\n\t\t\n\t\t/* Assertion: same (===)\n\t\t ***********************/\n\t\t \n\t\tvar str1 = 'a',\n\t\t\tstr2 = 'a',\n\t\t\tstr3 = 'c',\n\t\t\tstr4 = 'd';\n\t\t\t\n\t\tassert.same(str1, str2);\n\t\trefute.same(str3, str4);\n\t\t\n\t\t/* Assertion: equals (checks properties)\n\t\t ***************************************/\n\n\t\tvar obj1 = { name:'bob', age:123 },\n\t\t\tobj2 = { name:'bob', age:123 },\n\t\t\tobj3 = { name:'sam', age:123 },\n\t\t\tobj4 = { name:'jon', age:456 };\n\t\t\t\n\t\tassert.equals(obj1, obj2);\n\t\trefute.equals(obj3, obj4);\n\t\t\n\t\t/* Assertion: typeOf\n\t\t *******************/\n\n\t\tassert.typeOf({}, 'object', 'This will pass');\n\t\tassert.typeOf({}, 'object');\n\t\tassert.typeOf('bobby', 'string');\n\t\trefute.typeOf(null, 'function');\n\t\trefute.typeOf([], 'array'); // doesn't use Object.prototype.toString.call() to see inner [[Class]] property so [] equals 'object'\n\t\tassert.myIsArray([]); // so we build our own\n\t\t\n\t\t/* Assertion: defined (if the value is anything other than undefined)\n\t\t ********************************************************************/\n\n\t\tassert.defined.message = 'my specified item seems to be undefined?'; // changed default message\n\t\tvar a;\n\t\tassert.defined({});\n\t\trefute.defined(a);\n\t\t\n\t\t/* Assertion: isNull (fails if the object is not null)\n\t\t *****************************************************/\n\n\t\tassert.isNull(null, 'This will pass');\n\t\trefute.isNull({});\n\t\t\n\t\t/* Assertion: isObject (fails if object is null or not an object)\n\t\t ****************************************************************/\n\n\t\tassert.isObject({});\n\t\tassert.isObject([1, 2, 3]);\n\t\trefute.isObject(42);\n\t\trefute.isObject(function(){});\n\t\t\n\t\t/* Assertion: isFunction (fails if object is not a function)\n\t\t ***********************************************************/\n\n\t\trefute.isFunction({});\n\t\trefute.isFunction(42);\n\t\tassert.isFunction(function(){});\n\t\t\n\t\t/* Assertion: tagName (Fails if the element either does not specify a tagName property, or if its value is not a case-insensitive match with the expected tagName)\n\t\t *****************************************************************************************************************************************************************/\n\n\t\tassert.tagName(document.createElement('p'), 'p');\n\t\tassert.tagName(document.createElement('h2'), 'H2');\n\t\trefute.tagName(document.createElement('p'), 'li');\n\t\t\n\t\t/* Assertion: className (Fails if the element either does not specify a className property, or if its value is not a space-separated list of all class names in classNames)\n\t\t **************************************************************************************************************************************************************************/\n\t\t \n\t\tvar el = document.createElement('p');\n\t\tel.className = 'feed item blog-post';\n\t\t\n\t\tassert.className(el, 'item');\n\t\tassert.className(el, 'blog-post feed');\n\t\tassert.className(el, ['item', 'feed']);\n\t\trefute.className(el, 'feed items');\n\t\trefute.className(el, 'news');\n    }\n    \n});\nfunction canDrink(age) {\n\tif (typeof age != 'number') {\n\t\tage = parseInt(age);\n\t}\n\treturn (age \u003e= 18) ? true : false;\n}\n\u003c!doctype html\u003e\n\u003chtml\u003e\n\t\u003chead\u003e\n\t\t\u003cmeta charset=\"utf-8\"\u003e\n\t\t\u003ctitle\u003eBuster.js Unit-Testing\u003c/title\u003e\n\t\u003c/head\u003e\n\t\u003cbody\u003e\n\t\tBuster is run via Terminal (see \u003ccode\u003etest/buster.js\u003c/code\u003e for details)\n\t\u003c/body\u003e\n\u003c/html\u003e\nvar config = module.exports;\n\nconfig['My tests'] = {\n    rootPath: '../',\t\t\t\t// Set root path which is relative to where the config file is found\n    environment: 'browser',\t\t\t// or \"node\"\n    sources: [\n        'example.js' \t\t\t\t// Paths are relative to config file or rootPath\n        //'../**/*.js'\t\t\t\t// Glob patterns supported\n    ],\n    tests: [\n        'test/*-test.js'\t\t\t// All files named [whatever]-test.js will be run\n    ]\n}\n","tags":""},{"id":"2665277","title":"CSS alignment test","content":".logo {\n\t display: block;\n\t  margin: -73px 0 0 -64px;\n\t    left: 50%;\n\tposition: absolute;\n\t\t top: 50%;\n\t\t\t\t\n\t/*  CSS3 Transforms */\n\t\t\t\t\n\t-webkit-transform: scale(2) rotate(90deg);\n\t   -moz-transform: scale(2) rotate(90deg);\n\t\t-ms-transform: scale(2) rotate(90deg);\n\t\t -o-transform: scale(2) rotate(90deg);\n\t\t\ttransform: scale(2) rotate(90deg);\n}\n\n\u003cimg class=\"logo\" src=\"https://developer.mozilla.org/media/img/mdn-logo.png\"\u003e\n\n{\"view\":\"split-vertical\",\"fontsize\":\"100\",\"seethrough\":\"1\",\"prefixfree\":\"\",\"page\":\"css\"}\n","tags":""},{"id":"2937109","title":"Animating image slides in ActionScript","content":"stop();\n\nconst SPEED = 5;\n\nvar counter = 0;\nvar list = [{ mc: one, delay: 10 }, \n\t\t\t{ mc: two, delay: 10 }, \n\t\t\t{ mc: three, delay: 10 }, \n\t\t\t{ mc: four, delay: 10 }, \n\t\t\t{ mc: five, delay: 10 }, \n\t\t\t{ mc: six, delay: 10 }, \n\t\t\t{ mc: seven, delay: 10 }, \n\t\t\t{ mc: eight, delay: 10 }, \n\t\t\t{ mc: nine, delay: 10 }, \n\t\t\t{ mc: ten, delay: 10 }, \n\t\t\t{ mc: eleven, delay: 10 }]; // list of MovieClip instance names and their associated delays\n\nfunction animate(){\n\tTweener.addTween(list[counter].mc, {\n\t\talpha: 0,\n\t\tdelay: list[counter].delay,\n\t\ttime: SPEED,\n\t\tonComplete: function(){\t\t\t\n\t\t\tif (counter == list.length - 1) {\n\t\t\t\tcounter = 0;\n\t\t\t\tlist.forEach(function (item) {\n\t\t\t\t\titem.mc.alpha = 1;\n\t\t\t\t});\n\t\t\t\tgotoAndPlay(1);\n\t\t\t} else {\n\t\t\t\tcounter++;\n\t\t\t\tanimate();\n\t\t\t}\n\t\t}\n\t});\n}\n\n// Just before we start the animation lets set all screens to be blank so we can fade the first one into view\nlist.forEach(function (item) {\n\titem.mc.alpha = 0;\n});\n\nTweener.addTween(list[0].mc, {\n\talpha: 1,\n\ttime: SPEED,\n\tonComplete: function(){\n\t\t// Now the first screen is faded in, we'll reset all movie clips back to having full alpha\n\t\tlist.forEach(function (item) {\n\t\t\titem.mc.alpha = 1;\n\t\t});\n\t\tanimate();\n\t}\n});\n","tags":""},{"id":"1973283","title":"Canvas example","content":"\u003c!doctype html\u003e\n\u003chtml dir=\"ltr\" lang=\"en\"\u003e\n    \u003chead\u003e\n    \t\u003cmeta charset=\"utf-8\"\u003e\n    \t\u003ctitle\u003eHTML5 Canvas\u003c/title\u003e\n    \t\u003cstyle type=\"text/css\"\u003e\n    \t   body {\n    \t       font: normal large Helvetica, sans-serif;\n    \t   }\n    \t   \n    \t   #card {\n    \t       border: 1px solid red;\n    \t   }\n    \t   \n    \t   #downloadform {\n    \t       border: 1px solid green;\n    \t       float: right;\n    \t       margin-left: 10px;\n    \t       padding: 10px;\n    \t   }\n    \t   \n    \t   #generatedImage {\n    \t       border: 1px solid blue;\n    \t       width: 300px;\n    \t   }\n    \t   \n    \t   input {\n    \t       display: block;\n    \t   }\n    \t\u003c/style\u003e\n    \u003c/head\u003e\n    \u003cbody\u003e\n        \u003cform action=\"saveimage.php\" method=\"post\" id=\"downloadform\"\u003e\n            \u003cinput type=\"hidden\" name=\"imgdata\" id=\"imgdata\"\u003e\n            \u003cinput type=\"submit\" value=\"Save Image\"\u003e\n        \u003c/form\u003e\n        \u003ccanvas id=\"card\" width=\"960\" height=\"739\"\u003e\u003c/canvas\u003e\n    \t\u003cscript type=\"text/javascript\"\u003e\n            var canvas = document.getElementById(\"card\"),\n                ctx = canvas.getContext(\"2d\"),\n                img = new Image();\n                img.src = \"card.png\";\n                img.onload = loadImageIntoCanvas;\n                \n            function loadImageIntoCanvas() {\n                // Load the specified image into the canvas (image, x, y, width[optional], height[optional])\n                ctx.drawImage(img, 0, 0, 700, 400); // I've purposedly squashed the image\n                \n                // Now image is loaded we'll draw some text into the canvas\n                writeText();\n            }\n            \n            function writeText() {\n                // Place text into the canvas\n                ctx.fillStyle = \"#CC0000\"; // red\n                ctx.font = \"italic bold 25px Helvetica\";\n                ctx.fillText(\"Some text I've inserted into the image\", 125, 180);\n                \n                // Now lets save this image\n                saveImage();\n            }\n            \n            function saveImage() {\n                var form = document.forms[0],\n                    input = form.elements[0],\n                    dataURL = canvas.toDataURL(),\n                    img = new Image();\n                    img.src = dataURL;\n                    img.id = \"generatedImage\";\n                \n                input.value = dataURL;\n                form.insertBefore(img, form.firstChild);\n            }\n    \t\u003c/script\u003e\n    \u003c/body\u003e\n\u003c/html\u003e\n\u003c?php\n    // Get data\n    $data = $_POST['imgdata'];\n\n    // Remove the \"data:image/png;base64,\" part\n    $uri =  substr($data, strpos($data, \",\") + 1);\n    \n    // Save the file to the machine\n    file_put_contents(\"generated.png\", base64_decode($uri));\n    \n    // Force user to download the saved image\n    if (file_exists(\"generated.png\")) {\n        // We'll be outputting a PNG\n        header(\"Content-type: image/png\");\n        \n        // It will be called generated.png\n        header(\"Content-Disposition: attachment; filename=generated.png\");\n\n        // Reads the file and writes it to the output buffer\n        readfile(\"generated.png\");\n    }\n?\u003e\n","tags":""},{"id":"763762","title":"Observer Design Pattern ","content":"/*\nExample from @stoyanstefanov's JavaScript Pattern book\n\nLet’s say you have a publisher paper, which publishes a daily newspaper and a monthly magazine. A subscriber joe will be notified whenever that happens.\n\nThe paper object needs to have a property subscribers that is an array storing all sub- scribers. \nThe act of subscription is merely adding to this array. \nWhen an event occurs, paper loops through the list of subscribers and notifies them. \nThe notification means calling a method of the subscriber object.\nTherefore, when subscribing, the subscriber provides one of its methods to paper’s subscribe() method.\n\nThe paper can also provide unsubscribe(), which means removing from the array of subscribers. \nThe last important method of paper is publish(), which will call the sub- scribers’ methods. \nTo summarize, a publisher object needs to have these members:\n\nsubscribers\n\tAn array\nsubscribe()\n\tAdd to the array of subscribers\nunsubscribe()\n\tRemove from the subscribers array\npublish()\n\tLoop though subscribers and call the methods they provided when they signed up\n\t\nAll the three methods need a type parameter, because a publisher may fire several events (publish both a magazine and a newspaper) \nand subscribers may chose to subscribe to one, but not to the other.\n\nBecause these members are generic for any publisher object, it makes sense to implement them as part of a separate object. \nThen we can copy them over (mix-in pattern) to any object and turn any given object into a publisher.\n*/\n\n// Here’s an example implementation of the generic publisher functionality\nvar publisher = {\n\t// The subscriber list is empty initially\n\tsubscribers: {\n\t\tany: [] // event type: subscribers\n\t},\n\t\n\tsubscribe: function(fn, type){\n\t\t// If no type supplied then assume 'any'.\n\t\t// By default we want the user to subscribe to all our publications ('any')\n\t\ttype = type || 'any';\n\t\t\n\t\t// If type provided is unknown then create a new type in the 'subscribers' object.\n\t\tif (typeof this.subscribers[type] === 'undefined') {\n\t\t\tthis.subscribers[type] = [];\n\t\t}\n\t\t\n\t\t// Update the 'subscriber' list (this will either be 'any' list or a new list) so it contains the callback function specified by the subscriber.\n\t\t// This subscriber callback function will be called when an event is triggered for their subscription type.\n\t\tthis.subscribers[type].push(fn);\n\t},\n\t\n\tunsubscribe: function(fn, type){\n\t\tthis.action('unsubscribe', fn, type);\n\t},\n\t\n\tpublish: function(article, type){\n\t\tthis.action('publish', article, type);\n\t},\n\t\n\taction: function(action, item, type){\n\t\t// item will either be the 'callback' function (if the action is to unsubscribe)\n\t\t// or item will be the article text (if the action is to publish)\n\t\t\n\t\tvar pubtype = type || 'any', // If no type supplied then assume 'any'\n\t\t\t subscribers = this.subscribers[pubtype], // store the relevant subscriber list\n\t\t\t i,\n\t\t\t max = subscribers.length;\n\t\t\n\t\t// Loop through each user in the relevant subscriber list\n\t\tfor (i = 0; i \u003c max; i += 1) {\n\t\t\tif (action === 'publish') {\n\t\t\t\t// Call the subscribers callback function.\n\t\t\t\t// We also pass in the article text for the callback to utilise however it needs to.\n\t\t\t\tsubscribers[i](item);\n\t\t\t} else {\n\t\t\t\t// We know if the action isn't to publish then it can only be to unsubscribe\n\t\t\t\t// So we check if the current Array item (the specified callback function) matches the callback function set in the unsubscribe request,\n\t\t\t\t// And if there is a match then the users callback is removed and thus they are unsubscribed from the list.\n\t\t\t\tif (subscribers[i] === item) {\n\t\t\t\t\tsubscribers.splice(i, 1);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n};\n\n// Here’s a function that takes an object and turns it into a publisher by simply copying over the generic publisher’s methods\nfunction makePublisher(o){\n\tvar i;\n\t\n\t// Loop through the publisher object and copy its methods into the object passed to this function\n\tfor (i in publisher) {\n\t\t// Make sure we only copy 'methods' that are directly set on the publisher object (ignore prototype)\n\t\tif (publisher.hasOwnProperty(i) \u0026\u0026 typeof publisher[i] === 'function') {\n\t\t\t// Copy method(s) from publisher\n\t\t\to[i] = publisher[i];\n\t\t}\n\t}\n\t\n\t// Now the specified object has all the methods found in the publisher object,\n\t// we can give it a fresh/clean subscribers list\n\to.subscribers = { any: [] };\n}\n\n// Now let’s implement the paper object. All it can do is publish daily and monthly:\nvar paper = {\n\tdaily: function(update){\n\t\tthis.publish(update);\n\t},\n\tmonthly: function(update){\n\t\tthis.publish(update, 'monthly');\n\t}\n};\n\n// Now we need to make 'paper' a publisher\n// This means paper has all the methods of publisher as well as it's own 'daily' and 'monthly' methods\nmakePublisher(paper);\n\n// Now that we have a publisher, let’s see the subscriber object joe, which has two methods:\nvar joe = {\n\tdrinkCoffee: function(article){\n\t\tconsole.log('(Joe) Just read: ' + article);\n\t},\n\tsundayPreNap: function(article){\n\t\tconsole.log('(Joe) About to fall asleep reading this: ' + article);\n\t}\n};\n\n// Lets reuse joe for a new subscriber called bob:\nvar bob = {\n\tdrinkCoffee: function(article){\n\t\tconsole.log('(Bob) Just read: ' + article);\n\t},\n\tsundayPreNap: function(article){\n\t\tconsole.log('(Bob) About to fall asleep reading this: ' + article);\n\t}\n};\n\n// Now the paper subscribes both joe \u0026 bob (in other words both joe \u0026 bob subscribes to the paper):\npaper.subscribe(joe.drinkCoffee);\npaper.subscribe(joe.sundayPreNap, 'monthly');\npaper.subscribe(bob.drinkCoffee);\npaper.subscribe(bob.sundayPreNap, 'monthly');\n\n// As you see, joe \u0026 bob provide a method to be called for the default “any” event \n// and another method to be called when the “monthly” type of event occurs. \n// Now let’s fire some events:\npaper.daily('big news today (daily 1)');\npaper.daily('big news today (daily 2)');\npaper.daily('big news today (daily 3)');\npaper.monthly('interesting analysis (monthly 1)');\npaper.monthly('interesting analysis (monthly 2)');\n\n// The good part here is that the paper object doesn’t hardcode joe and joe doesn’t hard- code paper. \n// There’s also no mediator object that knows everything. \n// The participating objects are loosely coupled, and without modifying them at all, we can add many more subscribers to paper; \n\n// Also joe can unsubscribe at any time:\n// But needs to specify the callback function he signed up with \n// (like when you unsubscribe from a mailing list you must enter the email address you signed up with)\npaper.unsubscribe(joe.sundayPreNap, 'monthly');\n\n// Both joe \u0026 bob still receive daily updates\npaper.daily('big news today (daily 4)');\n\n// But now joe has given up on the monthly updates, he wont receive any notifications, althoug bob will still get them:\npaper.monthly('interesting analysis (monthly 3)');\n\n// Now bob unsubscribes from everything\npaper.unsubscribe(bob.drinkCoffee);\n\n// joe still receives daily updates but bob receives nothing\npaper.daily('big news today (daily 5)');\n\n// Let’s take this example a step further and also make joe a publisher. \n// (After all, with blogs and microblogs anyone can be a publisher.) \n// So joe becomes a publisher and can post status updates on Twitter:\nmakePublisher(joe);\n\njoe.tweet = function(msg) {\n\tthis.publish(msg);\n};\n\n// Now imagine that the paper’s public relations department decides to read what its readers tweet \n// and subscribes to joe, providing the method readTweets():\npaper.readTweets = function(tweet){\n\tconsole.log('The paper received this alert from Joe\\'s twitter feed: \"' + tweet + '\"');\n};\n\n// Now joe subscribes the paper (in other words the paper subscribes to joes tweets):\njoe.subscribe(paper.readTweets);\n\n// As soon as joe tweets, the paper is alerted\njoe.tweet('hated the paper today');\njoe.tweet('loves playing with his dog');\n","tags":"#patterns"},{"id":"2947867","title":"More ActionScript, how I hate dealing with Flash","content":"import flash.events.MouseEvent;\n\nstop();\n\nvar counter = 0;\nvar list = [one, two, three, four, five, six, seven, eight, nine, ten, eleven]; // list of MovieClip instance names\n\nfunction goBack (e:MouseEvent):void {\n\t// Prevent user from clicking the navigation buttons too quickly (e.g. clicking when animation is still running)\n\tbtn_prev.removeEventListener(MouseEvent.CLICK, goBack);\n\tbtn_next.removeEventListener(MouseEvent.CLICK, goForward);\n\t\n\tif (counter == 0) {\n\t\tlist.forEach(function (item, index) {\n\t\t\t// We don't want to hide the first slide yet, but all others do\n\t\t\tif (index != 0) {\n\t\t\t\titem.alpha = 0;\n\t\t\t}\n\t\t});\n\t\t\n\t\t// Start fading out the first screen\n\t\tTweener.addTween(list[0], {\n\t\t\talpha: 0,\n\t\t\ttime: 1,\n\t\t\ttransition: \"linear\",\n\t\t\tonComplete: function(){\n\t\t\t\t// Now the first screen is faded out we need to fade in the last screen\n\t\t\t\tTweener.addTween(list[counter], {\n\t\t\t\t\talpha: 1,\n\t\t\t\t\ttime: 1,\n\t\t\t\t\ttransition: \"linear\",\n\t\t\t\t\tonComplete: function(){\n\t\t\t\t\t\t// Now the last screen is now faded back into view we can allow the user to start using the navigation again\n\t\t\t\t\t\tbtn_prev.addEventListener(MouseEvent.CLICK, goBack);\n\t\t\t\t\t\tbtn_next.addEventListener(MouseEvent.CLICK, goForward);\n\t\t\t\t\t}\n\t\t\t\t});\n\t\t\t}\n\t\t});\n\t} else {\n\t\tTweener.addTween(list[counter-1], {\n\t\t\talpha: 1,\n\t\t\ttime: 1,\n\t\t\ttransition: \"linear\",\n\t\t\tonComplete: function(){\n\t\t\t\t// Now the previous screen is now faded back into view we can allow the user to start using the navigation again\n\t\t\t\tbtn_prev.addEventListener(MouseEvent.CLICK, goBack);\n\t\t\t\tbtn_next.addEventListener(MouseEvent.CLICK, goForward);\n\t\t\t}\n\t\t});\n\t}\n\t\n\tif (counter \u003c= 0) {\n\t\tcounter = list.length - 1;\n\t} else {\n\t\tcounter--;\n\t}\n}\n\nfunction goForward (e:MouseEvent):void {\n\t// Prevent user from clicking the navigation buttons too quickly (e.g. clicking when animation is still running)\n\tbtn_prev.removeEventListener(MouseEvent.CLICK, goBack);\n\tbtn_next.removeEventListener(MouseEvent.CLICK, goForward);\n\t\n\tTweener.addTween(list[counter], {\n\t\talpha: 0,\n\t\ttime: 1,\n\t\ttransition: \"linear\",\n\t\tonComplete: function(){\n\t\t\tif (counter == 0) {\n\t\t\t\tTweener.addTween(list[counter], {\n\t\t\t\t\talpha: 1,\n\t\t\t\t\ttime: 1,\n\t\t\t\t\tonComplete: function(){\n\t\t\t\t\t\t// Now the first screen is faded in, we'll reset all movie clips back to having full alpha\n\t\t\t\t\t\tlist.forEach(function (item) {\n\t\t\t\t\t\t\titem.alpha = 1;\n\t\t\t\t\t\t});\n\t\t\t\t\t\t\n\t\t\t\t\t\t// Now the current screen is faded out, we'll allow user to start using the navigation again\n\t\t\t\t\t\tbtn_prev.addEventListener(MouseEvent.CLICK, goBack);\n\t\t\t\t\t\tbtn_next.addEventListener(MouseEvent.CLICK, goForward);\n\t\t\t\t\t}\n\t\t\t\t})\n\t\t\t} else {\n\t\t\t\t// Now the current screen is faded out, we'll allow user to start using the navigation again\n\t\t\t\tbtn_prev.addEventListener(MouseEvent.CLICK, goBack);\n\t\t\t\tbtn_next.addEventListener(MouseEvent.CLICK, goForward);\n\t\t\t}\n\t\t}\n\t});\n\t\n\tif (counter \u003e= (list.length - 1)) {\n\t\tcounter = 0;\n\t} else {\n\t\tcounter++;\n\t}\n}\n\n// Just before we start the animation lets set all screens to be blank so we can fade the first one into view\nlist.forEach(function (item) {\n\titem.alpha = 0;\n});\n\n// Start the animation by initially fadding into view the first slide\nTweener.addTween(list[0], {\n\talpha: 1,\n\ttime: 1,\n\ttransition: \"linear\",\n\tonComplete: function(){\n\t\t// Now the first screen is faded in, we'll reset all movie clips back to having full alpha\n\t\tlist.forEach(function (item) {\n\t\t\titem.alpha = 1;\n\t\t});\n\t\t\n\t\tbtn_prev.addEventListener(MouseEvent.CLICK, goBack);\n\t\tbtn_next.addEventListener(MouseEvent.CLICK, goForward);\n\t}\n});\n","tags":""},{"id":"2651826","title":"Custom Scrollbars (WebKit only because no other browser has similar feature)","content":"// See also: http://css-tricks.com/custom-scrollbars-in-webkit/\n\n::-webkit-scrollbar {\n\tbackground-color: #333;\n\theight:13px;\n\twidth:13px;\n}\n\n::-webkit-scrollbar-button {\n\tdisplay: none;\n}\n\n::-webkit-scrollbar-thumb {\n\tbackground: url(scrollbar-track.png) left top repeat-y #EC008C;\n\t-webkit-border-radius: 5px;\n\tborder-radius: 7px;\n}\n","tags":""},{"id":"1973726","title":"Automatically generated images via JavaScript Canvas API","content":"This is a quick prototype I knocked together (in under an hour) for a family member who had a business idea that he wasn't sure how to implement. \n\nI had never used the HTML5 Canvas API before but it sounded like it could be a good fit for what he was trying to achieve.\n\nIt was a fun little thing to work on as it gave me a chance to play around with using Canvas and I discovered that text written in Canvas cannot (currently) wrap to the width of the Canvas element. Although I believe there may now be some new additions to the API which works around this wrapping issue.\n\u003c!doctype html\u003e\n\u003chtml dir=\"ltr\" lang=\"en\"\u003e\n    \u003chead\u003e\n    \t\u003cmeta charset=\"utf-8\"\u003e\n    \t\u003ctitle\u003eHTML5 Canvas\u003c/title\u003e\n    \t\u003cstyle type=\"text/css\"\u003e\n    \t   body {\n    \t       font: normal large Helvetica, sans-serif;\n    \t   }\n    \t   \n    \t   #card {\n    \t       border: 1px solid red;\n    \t   }\n    \t\u003c/style\u003e\n    \u003c/head\u003e\n    \u003cbody\u003e\n        \u003cp\u003eStatus:\u003c/p\u003e\n        \u003cul id=\"status\"\u003e\u003c/ul\u003e\n        \u003cscript type=\"text/javascript\"\u003e\n            var doc = document,\n                status = doc.getElementById(\"status\"),\n                canvas = doc.createElement(\"canvas\"),\n                counter = 0;\n                cards = [\n                            { img: \"card1\", txt: \"card 1 text\" },\n                            { img: \"card2\", txt: \"card 2 text\" },\n                            { img: \"card3\", txt: \"card 3 text\" }\n                        ];\n                        \n            canvas.width = 960;\n            canvas.height = 739;\n                \n            cards.forEach(function (card) {\n                var img = new Image();\n                    img.id = \"Card\" + ++counter;\n                    img.src = card.img + \".png\";\n                    img.onload = function(){\n                        // First argument of drawImage (see further down) should be an image and not a string\n                        // So we must replace string in object to be the image just created\n                        card.img = img;\n                        \n                        // Now create a new canvas for this image\n                        createCanvas(card);\n                    };\n            });\n            \n            function createCanvas(card) {\n                var newCanvas = canvas.cloneNode(false), // shallow clone\n                    ctx = newCanvas.getContext(\"2d\");\n                \n                // Now load relevant image into this canvas\n                loadImageIntoCanvas(card, newCanvas, ctx);\n            }\n                \n            function loadImageIntoCanvas (card, newCanvas, ctx) {\n                // Load the specified image into the canvas (image, x, y, width[optional], height[optional])\n                ctx.drawImage(card.img, 0, 0, 700, 400); // I've purposedly squashed the image\n                \n                // Now image is loaded we'll draw some text into the canvas\n                writeText(card, newCanvas, ctx);\n            }\n            \n            function writeText (card, newCanvas, ctx) {\n                // Place text into the canvas (beware the text can't wrap so you might need multiple 'fillText' calls)\n                ctx.fillStyle = \"#CC0000\";\n                ctx.font = \"italic bold 25px Helvetica\";\n                ctx.fillText(card.txt, 125, 180);\n                \n                // Now lets save this image\n                saveImage(card, newCanvas, ctx);\n            }\n            \n            function checkHTTPSuccess (xhr) {\n            \ttry {\n\t\t\t\t\t// If no server status is provided, and we're actually\n\t\t\t\t\t// requesting a local file, then it was successful\n\t\t\t\t\treturn !xhr.status \u0026\u0026 location.protocol == 'file:' ||\n\t\t\t\t\t\n\t\t\t\t\t// Any status in the 200 range is good\n\t\t\t\t\t( xhr.status \u003e= 200 \u0026\u0026 xhr.status \u003c 300 ) ||\n\t\t\t\t\t\n\t\t\t\t\t// Successful if the document has not been modified\n\t\t\t\t\txhr.status == 304 ||\n\t\t\t\t\t\n\t\t\t\t\t// Safari returns an empty status if the file has not been modified\n\t\t\t\t\tnavigator.userAgent.indexOf('Safari') \u003e= 0 \u0026\u0026 typeof xhr.status == 'undefined';\n\t\t\t\t} catch(e){\n\t\t\t\t\t// Throw a corresponding error\n\t\t\t\t\tthrow new Error(\"httpSuccess Error = \" + e);\n\t\t\t\t}\n\t\t\t\t\n\t\t\t\t// If checking the status failed, then assume that the request failed too\n\t\t\t\treturn false;\n            }\n            \n            function getHTTPData (xhr, type) {\n            \tif (type === 'json') {\n\t\t\t\t\treturn JSON.parse(xhr.responseText);\n\t\t\t\t}\n\t\t\t\t\n\t\t\t\telse if (type === 'html') {\n\t\t\t\t\treturn xhr.responseText;\n\t\t\t\t}\n\t\t\t\t\n\t\t\t\telse if (type === 'xml') {\n\t\t\t\t\treturn xhr.responseXML;\n\t\t\t\t}\n\t\t\t\t\n\t\t\t\t// Attempt to work out the content type\n\t\t\t\telse {\n\t\t\t\t\t// Get the content-type header\n\t\t\t\t\tvar contentType = xhr.getResponseHeader(\"content-type\"), \n\t\t\t\t\t\tdata = !type \u0026\u0026 contentType \u0026\u0026 contentType.indexOf(\"xml\") \u003e= 0; // If no default type was provided, determine if some form of XML was returned from the server\n\t\t\t\t\t\n\t\t\t\t\t// Get the XML Document object if XML was returned from the server,\n\t\t\t\t\t// otherwise return the text contents returned by the server\n\t\t\t\t\tdata = (type == \"xml\" || data) ? xhr.responseXML : xhr.responseText;\t\n\t\t\t\t\t\n\t\t\t\t\t// Return the response data (either an XML Document or a text string)\n\t\t\t\t\treturn data;\n\t\t\t\t}\n            }\n            \n            function onSuccessfulImageProcessing (card, newCanvas, ctx, response) {\n            \t// Clean-up after ourselves to save application memory\n                newCanvas = null;\n                ctx = null;\n                \n                // Update status list\n                var txt = doc.createTextNode(card.img.id + \" has now been generated.\"),\n                    li = doc.createElement(\"li\");\n                    li.appendChild(txt);\n                    status.appendChild(li);\n            }\n            \n            function saveImage(card, newCanvas, ctx) {\n                // Can't use standard library AJAX methods (such as…)\n                // data: \"imgdata=\" + newCanvas.toDataURL()\n                // Not sure why it doesn't work as we're only abstracting an API over the top of the native XHR object?\n                // To make this work we need to use a proper FormData object (no data on browser support)\n                var formData = new FormData();  \n  \t\t\t\tformData.append(\"imgdata\", newCanvas.toDataURL());\n  \t\t\t\t\n                var xhr = new XMLHttpRequest();\n                xhr.open(\"POST\", \"saveimage.php\");\n                xhr.send(formData);\n                \n                // Watch for when the state of the document gets updated\n\t\t\t\txhr.onreadystatechange = function(){\t\t\t\t\t\n\t\t\t\t\t// Wait until the data is fully loaded, and make sure that the request hasn't already timed out\n\t\t\t\t\tif (xhr.readyState == 4) {\t\t\t\t\t\t\n\t\t\t\t\t\t// Check to see if the request was successful\n\t\t\t\t\t\tif (checkHTTPSuccess(xhr)) {\n\t\t\t\t\t\t\t// Execute the success callback\n\t\t\t\t\t\t\tonSuccessfulImageProcessing(card, newCanvas, ctx, getHTTPData(xhr));\n\t\t\t\t\t\t}\n\t\t\t\t\t\telse {\n\t\t\t\t\t\t\tthrow new Error(\"checkHTTPSuccess failed = \" + e);\n\t\t\t\t\t\t}\n\t\t\t\t\t\t\n\t\t\t\t\t\txhr.onreadystatechange = null;\n\t\t\t\t\t\txhr = null;\t\t\t\t\t\t\n\t\t\t\t\t}\t\t\t\t\t\n\t\t\t\t};\n            }\n    \t\u003c/script\u003e\n    \u003c/body\u003e\n\u003c/html\u003e\n\u003c?php\n    // Get data\n    $data = $_POST['imgdata'];\n\n    // Remove the \"data:image/png;base64,\" part\n    $uri =  substr($data, strpos($data, \",\") + 1);\n    \n    // Save the file to the machine (try to make it unique)\n    file_put_contents(\"./Generated/card-\" . mt_rand() . \".png\", base64_decode($uri));\n?\u003e\n","tags":""},{"id":"1899675","title":"IE Box Model in other browsers ","content":"```css\n/* force IE Box Model */\n* {\n    -moz-box-sizing: border-box;\n    -webkit-box-sizing: border-box;\n    box-sizing: border-box;\n}\n\n.left{\n    background-color: pink;\n    border: 10px solid red;\n    float: left;\n    height: 150px;\n    width: 30%;\n}\n\n.right{\n    background-color: lightgreen;\n    border: 10px solid blue;\n    float: left;\n    height: 150px;\n    width: 70%;\n}\n```\n\n```html\n\u003cdiv class=\"left\"\u003econtent-box\u003c/div\u003e\n\u003cdiv class=\"right\"\u003ebox-sizing\u003c/div\u003e\n```\n/**\n * IE Box Model in other browsers\n * All browsers have supported CSS3 box-sizing for a long time \n * Except Firefox which only added support from version 7.0 so still a bit of time before we can use this.\n * Obviously IE still uses this box model so for once we don't need to worry about it :-)\n */\n\n* { \n    -moz-box-sizing: border-box;\n    -webkit-box-sizing: border-box;\n    box-sizing: border-box; \n}\n    \ndiv {\n    background: #ccc;\n    border: 10px solid red;\n    width: 400px;\n}\n\n\u003c!--\nThe W3C specified the width of a box to be it's content (not including padding or borders).\nWhich means if you have a box with a width of 400px and add a 10px border the box will resize to 420px width.\n\nThe \"IE Box Model\" dictates the width of the box would stay at 400px and it incorporates a 10px border.\nThis works great for percentage based floats for example when you need to add padding to the floated elements.\n--\u003e\n\u003cdiv\u003e\n\tSome content\n\u003c/div\u003e\n\n","tags":"#js"},{"id":"1663422","title":"Beware of setting 'require' as a dependancy ","content":"Imagine this is your module…\n\n```js\ndefine(['Utils/css'], function(css){\n\n\tconsole.log(css);\n\t\n});\n```\n\nIf your `Utils/css` dependancy was like the following…\n\n```js\ndefine(['require'], function(require){\n\n\treturn {\n\t\tstyle: require('Utils/CSS/getAppliedStyle'),\n\t\tclasses: require('Utils/CSS/getArrayOfClassNames'),\n\t\tadd: require('Utils/CSS/addClass'),\n\t\tremove: require('Utils/CSS/removeClass'),\n\t\thas: require('Utils/CSS/hasClass')\n\t}\n\n});\n```\n\n…then you would have this error displayed: `Uncaught Error: Module name 'Utils/CSS/getAppliedStyle' has not been loaded yet for context: _` because you created a race condition issue.\n\nOne work around would be to do…\n\n```js\ndefine(['Utils/CSS/getAppliedStyle', 'Utils/CSS/getArrayOfClassNames', 'Utils/CSS/addClass', 'Utils/CSS/removeClass', 'Utils/CSS/hasClass'], function(getAppliedStyle, getArrayOfClassNames, addClass, removeClass, hasClass){\n\n\treturn {\n\t\tstyle: getAppliedStyle,\n\t\tclasses: getArrayOfClassNames,\n\t\tadd: addClass,\n\t\tremove: removeClass,\n\t\thas: hasClass\n\t}\n\n});\n```\n\nBut that's FUGLY, so instead, go back to what we had before but just don't specify `require` as a dependancy… \n\n```js\ndefine(function(require){\n\n\treturn {\n\t\tstyle: require('Utils/CSS/getAppliedStyle'),\n\t\tclasses: require('Utils/CSS/getArrayOfClassNames'),\n\t\tadd: require('Utils/CSS/addClass'),\n\t\tremove: require('Utils/CSS/removeClass'),\n\t\thas: require('Utils/CSS/hasClass')\n\t}\n\n});\n```\n\nI have an idea of why this works but maybe [@jrburke](https://github.com/jrburke/) can clarify.\n","tags":"#js"},{"id":"1625810","title":"Sinon.js Fake XHR ","content":"define(['Utils/isIE', 'Utils/json'], function(isIE, JSON){\n\n\t// Note: wasn't able to require() in the json.js script for browsers that don't support it\n\t// As it would load asynchronusly and the below callback function would have executed before the json.js was loaded\n\t// I could have used when.js to handle this situation but seems a bit OTT.\n\t// I could also of have had one if statement at the top of this module which checked for support and forked there but I didn't like the idea of having all my code in an else statement\n\t// So decided to just load the script for all users (once it's minified and gzip'ed it shouldn't be much of a performance issue).\n\n\t// Used by ajax method to store errors\n\tvar errors = [];\n\t\n\t/**\n\t * XMLHttpRequest abstraction.\n\t * \n\t * @return xhr { XMLHttpRequest|ActiveXObject } a new instance of either the native XMLHttpRequest object or the corresponding ActiveXObject\n\t */\n \tvar __xhr = (function() {\n\n\t\t// Create local variable which will cache the results of this function\n\t\tvar xhr;\n\t\t\n\t\treturn function() {\n\t\t\t// Check if function has already cached the value\n\t\t\tif (xhr) {\n\t\t\t\t// Create a new XMLHttpRequest instance\n\t\t\t\treturn new xhr();\n\t\t\t} else {\n\t\t\t\t// Check what XMLHttpRequest object is available and cache it\n\t\t\t\txhr = (!window.XMLHttpRequest) ? function() {\n\t\t\t\t\treturn new ActiveXObject(\n\t\t\t\t\t\t// Internet Explorer 5 uses a different XMLHTTP object from Internet Explorer 6\n\t\t\t\t\t\t(isIE \u003c 6) ? \"Microsoft.XMLHTTP\" : \"MSXML2.XMLHTTP\"\n\t\t\t\t\t);\n\t\t\t\t} : window.XMLHttpRequest;\n\t\t\t\t\n\t\t\t\t// Return a new XMLHttpRequest instance\n\t\t\t\treturn new xhr();\n\t\t\t}\n\t\t};\n\t\t\n\t}());\n\t\n\t/**\n\t * A basic AJAX method.\n\t * \n\t * @param settings { Object } user configuration\n\t * @return undefined {  } no explicitly returned value\n\t */\n \tvar ajax = function(settings) {\n \t\n \t\t// JavaScript engine will 'hoist' variables so we'll be specific and declare them here\n \t\tvar xhr, url, requestDone, xhrTimeout,  \n \t\t\n \t\t// Load the config object with defaults, if no values were provided by the user\n\t\tconfig = {\n\t\t\t// The type of HTTP Request\n\t\t\tmethod: settings.method || 'GET',\n\t\t\t\n\t\t\t// The data to POST to the server\n\t\t\tdata: settings.data || '',\n\t\t\n\t\t\t// The URL the request will be made to\n\t\t\turl: settings.url || '',\n\t\t\n\t\t\t// How long to wait before considering the request to be a timeout\n\t\t\ttimeout: settings.timeout || 5000,\n\t\t\n\t\t\t// Functions to call when the request fails, succeeds, or completes (either fail or succeed)\n\t\t\tonComplete: settings.onComplete || function(){},\n\t\t\tonError: settings.onError || function(){},\n\t\t\tonSuccess: settings.onSuccess || function(){},\n\t\t\n\t\t\t// The data type that'll be returned from the server\n\t\t\t// the default is simply to determine what data was returned from the server and act accordingly.\n\t\t\tdataType: settings.dataType || ''\n\t\t};\n\t\t\n\t\t// Create new cross-browser XMLHttpRequest instance\n\t\txhr = __xhr();\n\t\t\n\t\t// Open the asynchronous request\n\t\txhr.open(config.method, config.url, true);\n\t\t\n\t\t// Determine the success of the HTTP response\n\t\tfunction httpSuccess(r) {\n\t\t\ttry {\n\t\t\t\t// If no server status is provided, and we're actually\n\t\t\t\t// requesting a local file, then it was successful\n\t\t\t\treturn !r.status \u0026\u0026 location.protocol == 'file:' ||\n\t\t\t\t\n\t\t\t\t// Any status in the 200 range is good\n\t\t\t\t( r.status \u003e= 200 \u0026\u0026 r.status \u003c 300 ) ||\n\t\t\t\t\n\t\t\t\t// Successful if the document has not been modified\n\t\t\t\tr.status == 304 ||\n\t\t\t\t\n\t\t\t\t// Safari returns an empty status if the file has not been modified\n\t\t\t\tnavigator.userAgent.indexOf('Safari') \u003e= 0 \u0026\u0026 typeof r.status == 'undefined';\n\t\t\t} catch(e){\n\t\t\t\t// Throw a corresponding error\n\t\t\t\tthrow new Error(\"httpSuccess Error = \" + e);\n\t\t\t}\n\t\t\t\n\t\t\t// If checking the status failed, then assume that the request failed too\n\t\t\treturn false;\n\t\t}\n\t\t\n\t\t// Extract the correct data from the HTTP response\n\t\tfunction httpData(xhr, type) {\n\t\t\t\n\t\t\tif (type === 'json') {\n\t\t\t\treturn JSON.parse(xhr.responseText);\n\t\t\t\t//return eval('(' + xhr.responseText + ')');\n\t\t\t}\n\t\t\t\n\t\t\t//\n\t\t\telse if (type === 'html') {\n\t\t\t\treturn xhr.responseText;\n\t\t\t}\n\t\t\t\n\t\t\t//\n\t\t\telse if (type === 'xml') {\n\t\t\t\treturn xhr.responseXML;\n\t\t\t}\n\t\t\t\n\t\t\t// Attempt to work out the content type\n\t\t\telse {\n\t\t\t\t// Get the content-type header\n\t\t\t\tvar contentType = xhr.getResponseHeader(\"content-type\"), \n\t\t\t\t\t data = !type \u0026\u0026 contentType \u0026\u0026 contentType.indexOf(\"xml\") \u003e= 0; // If no default type was provided, determine if some form of XML was returned from the server\n\t\t\t\t\n\t\t\t\t// Get the XML Document object if XML was returned from the server,\n\t\t\t\t// otherwise return the text contents returned by the server\n\t\t\t\tdata = (type == \"xml\" || data) ? xhr.responseXML : xhr.responseText;\t\n\t\t\t\t\n\t\t\t\t// Return the response data (either an XML Document or a text string)\n\t\t\t\treturn data;\n\t\t\t}\n\t\t\t\n\t\t}\n\t\t\n\t\t// Initalize a callback which will fire within the timeout range, also cancelling the request (if it has not already occurred)\n\t\txhrTimeout = window.setTimeout(function() {\n\t\t\trequestDone = true;\n\t\t\tconfig.onComplete();\n\t\t}, config.timeout);\n\t\t\n\t\t// Watch for when the state of the document gets updated\n\t\txhr.onreadystatechange = function() {\n\t\t\t\n\t\t\t// Wait until the data is fully loaded, and make sure that the request hasn't already timed out\n\t\t\tif (xhr.readyState == 4 \u0026\u0026 !requestDone) {\n\t\t\t\t\n\t\t\t\t// Check to see if the request was successful\n\t\t\t\tif (httpSuccess(xhr)) {\n\t\t\t\t\t// Execute the success callback\n\t\t\t\t\tconfig.onSuccess(httpData(xhr, config.dataType));\n\t\t\t\t}\n\t\t\t\t\n\t\t\t\t/**\n\t\t\t\t * For some reason, in an example PHP script that returns JSON data,\n\t\t\t\t * even though the request 'timed out' it still generated a readyState of 4.\n\t\t\t\t * I believe this was because although the script used sleep() to delay the data returned, the fact it returned data after the timeout caused an error.\n\t\t\t\t * So when the httpSuccess expression used in the above condition returns false we need to execute the onError handler.\n\t\t\t\t */\n\t\t\t\telse {\n\t\t\t\t\tconfig.onError(xhr);\n\t\t\t\t}\n\t\n\t\t\t\t// Call the completion callback\n\t\t\t\tconfig.onComplete();\n\t\t\t\t\n\t\t\t\t// Clean up after ourselves (+ help to avoid memory leaks)\n\t\t\t\tclearTimeout(xhrTimeout);\n\t\t\t\txhr.onreadystatechange = null;\n\t\t\t\txhr = null;\n\t\t\t\t\n\t\t\t} else if (requestDone \u0026\u0026 xhr.readyState != 4) {\n\t\t\t\t// If the script timed out then keep a log of it so the developer can query this and handle any exceptions\n\t\t\t\terrors.push(url + \" { timed out } \");\n\t\t\t\t\n\t\t\t\t// Bail out of the request immediately\n\t\t\t\txhr.onreadystatechange = null;\n\t\t\t\txhr = null;\n\t\t\t}\n\t\t\t\n\t\t};\n\t\t\n\t\t// Get if we should POST or GET...\n\t\tif (config.data \u0026\u0026 config.method === 'POST') {\n\t\t\t// Settings\n\t\t\txhr.setRequestHeader(\"Content-Type\",\"application/x-www-form-urlencoded\");\n\t\t\t\n\t\t\t// Establish the connection to the server\n\t\t\txhr.send(config.data);\n\t\t} else {\n\t\t\t// Establish the connection to the server\n\t\t\txhr.send(null);\n\t\t}\n\n\t}\n\n\treturn ajax;\n\n});\ndefine(function(){\n\t\n\t/**\n\t * Following property indicates whether the current rendering engine is Trident (i.e. Internet Explorer)\n\t * \n\t * @return v { Integer|undefined } if IE then returns the version, otherwise returns 'undefined' to indicate NOT a IE browser\n\t */\n\tvar isIE = (function() {\n\t\tvar undef,\n\t\t\tv = 3,\n\t\t\tdiv = document.createElement('div'),\n\t\t\tall = div.getElementsByTagName('i');\n\t\n\t\twhile (\n\t\t\tdiv.innerHTML = '\u003c!--[if gt IE ' + (++v) + ']\u003e\u003ci\u003e\u003c/i\u003e\u003c![endif]--\u003e',\n\t\t\tall[0]\n\t\t);\n\t\n\t\treturn v \u003e 4 ? v : undef;\t\n\t}());\n\t\n\treturn isIE;\n\t\n});\ndefine(function(){\n\t\n\t// Taken directly from Douglas Crockfords JSON2.js implementation (https://raw.github.com/douglascrockford/JSON-js/master/json2.js)\n\t\n\t// Create a JSON object only if one does not already exist. We create the\n\t// methods in a closure to avoid creating global variables.\n\tvar JSON;\n\tif (!JSON) {\n\t    JSON = {};\n\t}\n\t\n\tfunction f(n) {\n        // Format integers to have at least two digits.\n        return n \u003c 10 ? '0' + n : n;\n    }\n\n    if (typeof Date.prototype.toJSON !== 'function') {\n\n        Date.prototype.toJSON = function (key) {\n\n            return isFinite(this.valueOf())\n                ? this.getUTCFullYear()     + '-' +\n                    f(this.getUTCMonth() + 1) + '-' +\n                    f(this.getUTCDate())      + 'T' +\n                    f(this.getUTCHours())     + ':' +\n                    f(this.getUTCMinutes())   + ':' +\n                    f(this.getUTCSeconds())   + 'Z'\n                : null;\n        };\n\n        String.prototype.toJSON      =\n            Number.prototype.toJSON  =\n            Boolean.prototype.toJSON = function (key) {\n                return this.valueOf();\n            };\n    }\n\n    var cx = /[\\u0000\\u00ad\\u0600-\\u0604\\u070f\\u17b4\\u17b5\\u200c-\\u200f\\u2028-\\u202f\\u2060-\\u206f\\ufeff\\ufff0-\\uffff]/g,\n        escapable = /[\\\\\\\"\\x00-\\x1f\\x7f-\\x9f\\u00ad\\u0600-\\u0604\\u070f\\u17b4\\u17b5\\u200c-\\u200f\\u2028-\\u202f\\u2060-\\u206f\\ufeff\\ufff0-\\uffff]/g,\n        gap,\n        indent,\n        meta = {    // table of character substitutions\n            '\\b': '\\\\b',\n            '\\t': '\\\\t',\n            '\\n': '\\\\n',\n            '\\f': '\\\\f',\n            '\\r': '\\\\r',\n            '\"' : '\\\\\"',\n            '\\\\': '\\\\\\\\'\n        },\n        rep;\n\n\n    function quote(string) {\n\n// If the string contains no control characters, no quote characters, and no\n// backslash characters, then we can safely slap some quotes around it.\n// Otherwise we must also replace the offending characters with safe escape\n// sequences.\n\n        escapable.lastIndex = 0;\n        return escapable.test(string) ? '\"' + string.replace(escapable, function (a) {\n            var c = meta[a];\n            return typeof c === 'string'\n                ? c\n                : '\\\\u' + ('0000' + a.charCodeAt(0).toString(16)).slice(-4);\n        }) + '\"' : '\"' + string + '\"';\n    }\n\n\n    function str(key, holder) {\n\n// Produce a string from holder[key].\n\n        var i,          // The loop counter.\n            k,          // The member key.\n            v,          // The member value.\n            length,\n            mind = gap,\n            partial,\n            value = holder[key];\n\n// If the value has a toJSON method, call it to obtain a replacement value.\n\n        if (value \u0026\u0026 typeof value === 'object' \u0026\u0026\n                typeof value.toJSON === 'function') {\n            value = value.toJSON(key);\n        }\n\n// If we were called with a replacer function, then call the replacer to\n// obtain a replacement value.\n\n        if (typeof rep === 'function') {\n            value = rep.call(holder, key, value);\n        }\n\n// What happens next depends on the value's type.\n\n        switch (typeof value) {\n        case 'string':\n            return quote(value);\n\n        case 'number':\n\n// JSON numbers must be finite. Encode non-finite numbers as null.\n\n            return isFinite(value) ? String(value) : 'null';\n\n        case 'boolean':\n        case 'null':\n\n// If the value is a boolean or null, convert it to a string. Note:\n// typeof null does not produce 'null'. The case is included here in\n// the remote chance that this gets fixed someday.\n\n            return String(value);\n\n// If the type is 'object', we might be dealing with an object or an array or\n// null.\n\n        case 'object':\n\n// Due to a specification blunder in ECMAScript, typeof null is 'object',\n// so watch out for that case.\n\n            if (!value) {\n                return 'null';\n            }\n\n// Make an array to hold the partial results of stringifying this object value.\n\n            gap += indent;\n            partial = [];\n\n// Is the value an array?\n\n            if (Object.prototype.toString.apply(value) === '[object Array]') {\n\n// The value is an array. Stringify every element. Use null as a placeholder\n// for non-JSON values.\n\n                length = value.length;\n                for (i = 0; i \u003c length; i += 1) {\n                    partial[i] = str(i, value) || 'null';\n                }\n\n// Join all of the elements together, separated with commas, and wrap them in\n// brackets.\n\n                v = partial.length === 0\n                    ? '[]'\n                    : gap\n                    ? '[\\n' + gap + partial.join(',\\n' + gap) + '\\n' + mind + ']'\n                    : '[' + partial.join(',') + ']';\n                gap = mind;\n                return v;\n            }\n\n// If the replacer is an array, use it to select the members to be stringified.\n\n            if (rep \u0026\u0026 typeof rep === 'object') {\n                length = rep.length;\n                for (i = 0; i \u003c length; i += 1) {\n                    if (typeof rep[i] === 'string') {\n                        k = rep[i];\n                        v = str(k, value);\n                        if (v) {\n                            partial.push(quote(k) + (gap ? ': ' : ':') + v);\n                        }\n                    }\n                }\n            } else {\n\n// Otherwise, iterate through all of the keys in the object.\n\n                for (k in value) {\n                    if (Object.prototype.hasOwnProperty.call(value, k)) {\n                        v = str(k, value);\n                        if (v) {\n                            partial.push(quote(k) + (gap ? ': ' : ':') + v);\n                        }\n                    }\n                }\n            }\n\n// Join all of the member texts together, separated with commas,\n// and wrap them in braces.\n\n            v = partial.length === 0\n                ? '{}'\n                : gap\n                ? '{\\n' + gap + partial.join(',\\n' + gap) + '\\n' + mind + '}'\n                : '{' + partial.join(',') + '}';\n            gap = mind;\n            return v;\n        }\n    }\n\n// If the JSON object does not yet have a stringify method, give it one.\n\n    if (typeof JSON.stringify !== 'function') {\n        JSON.stringify = function (value, replacer, space) {\n\n// The stringify method takes a value and an optional replacer, and an optional\n// space parameter, and returns a JSON text. The replacer can be a function\n// that can replace values, or an array of strings that will select the keys.\n// A default replacer method can be provided. Use of the space parameter can\n// produce text that is more easily readable.\n\n            var i;\n            gap = '';\n            indent = '';\n\n// If the space parameter is a number, make an indent string containing that\n// many spaces.\n\n            if (typeof space === 'number') {\n                for (i = 0; i \u003c space; i += 1) {\n                    indent += ' ';\n                }\n\n// If the space parameter is a string, it will be used as the indent string.\n\n            } else if (typeof space === 'string') {\n                indent = space;\n            }\n\n// If there is a replacer, it must be a function or an array.\n// Otherwise, throw an error.\n\n            rep = replacer;\n            if (replacer \u0026\u0026 typeof replacer !== 'function' \u0026\u0026\n                    (typeof replacer !== 'object' ||\n                    typeof replacer.length !== 'number')) {\n                throw new Error('JSON.stringify');\n            }\n\n// Make a fake root object containing our value under the key of ''.\n// Return the result of stringifying the value.\n\n            return str('', {'': value});\n        };\n    }\n\n\n// If the JSON object does not yet have a parse method, give it one.\n\n    if (typeof JSON.parse !== 'function') {\n        JSON.parse = function (text, reviver) {\n\n// The parse method takes a text and an optional reviver function, and returns\n// a JavaScript value if the text is a valid JSON text.\n\n            var j;\n\n            function walk(holder, key) {\n\n// The walk method is used to recursively walk the resulting structure so\n// that modifications can be made.\n\n                var k, v, value = holder[key];\n                if (value \u0026\u0026 typeof value === 'object') {\n                    for (k in value) {\n                        if (Object.prototype.hasOwnProperty.call(value, k)) {\n                            v = walk(value, k);\n                            if (v !== undefined) {\n                                value[k] = v;\n                            } else {\n                                delete value[k];\n                            }\n                        }\n                    }\n                }\n                return reviver.call(holder, key, value);\n            }\n\n\n// Parsing happens in four stages. In the first stage, we replace certain\n// Unicode characters with escape sequences. JavaScript handles many characters\n// incorrectly, either silently deleting them, or treating them as line endings.\n\n            text = String(text);\n            cx.lastIndex = 0;\n            if (cx.test(text)) {\n                text = text.replace(cx, function (a) {\n                    return '\\\\u' +\n                        ('0000' + a.charCodeAt(0).toString(16)).slice(-4);\n                });\n            }\n\n// In the second stage, we run the text against regular expressions that look\n// for non-JSON patterns. We are especially concerned with '()' and 'new'\n// because they can cause invocation, and '=' because it can cause mutation.\n// But just to be safe, we want to reject all unexpected forms.\n\n// We split the second stage into 4 regexp operations in order to work around\n// crippling inefficiencies in IE's and Safari's regexp engines. First we\n// replace the JSON backslash pairs with '@' (a non-JSON character). Second, we\n// replace all simple value tokens with ']' characters. Third, we delete all\n// open brackets that follow a colon or comma or that begin the text. Finally,\n// we look to see that the remaining characters are only whitespace or ']' or\n// ',' or ':' or '{' or '}'. If that is so, then the text is safe for eval.\n\n            if (/^[\\],:{}\\s]*$/\n                    .test(text.replace(/\\\\(?:[\"\\\\\\/bfnrt]|u[0-9a-fA-F]{4})/g, '@')\n                        .replace(/\"[^\"\\\\\\n\\r]*\"|true|false|null|-?\\d+(?:\\.\\d*)?(?:[eE][+\\-]?\\d+)?/g, ']')\n                        .replace(/(?:^|:|,)(?:\\s*\\[)+/g, ''))) {\n\n// In the third stage we use the eval function to compile the text into a\n// JavaScript structure. The '{' operator is subject to a syntactic ambiguity\n// in JavaScript: it can begin a block or an object literal. We wrap the text\n// in parens to eliminate the ambiguity.\n\n                j = eval('(' + text + ')');\n\n// In the optional fourth stage, we recursively walk the new structure, passing\n// each name/value pair to a reviver function for possible transformation.\n\n                return typeof reviver === 'function'\n                    ? walk({'': j}, '')\n                    : j;\n            }\n\n// If the text is not JSON parseable, then a SyntaxError is thrown.\n\n            throw new SyntaxError('JSON.parse');\n        };\n    }\n\t\t\t\n\treturn JSON;\n\n});\ndefine(['Utils/ajax'], function(ajax){\n\n\t// Test Suite\n\tdescribe('AJAX test', function() {\n\t\t\n\t\tbeforeEach(function() {\n\t\t\tthis.addMatchers({\n\t\t\t\ttoBeNumber: function(expected) {\n\t\t\t\t\treturn /\\d+/.test(this.actual);\n\t\t\t\t}\n\t\t\t});\n\t\t\t\n\t\t\t// Sinon.js code follows…\t\t\t\n\t\t\tthis.myAjax = sinon.useFakeXMLHttpRequest();\t\t\t\n\t        \tvar requests = this.requests = [];\t\n\t\t\tthis.myAjax.onCreate = function (xhr) {\n\t            \t\trequests.push(xhr);\n\t        \t};\n  \t\t});\n  \t\t\n  \t\tafterEach(function() {\n    \t\t\t// Sinon.js code follows…\n    \t\t\tthis.myAjax.restore();\n  \t\t});\n  \t\t\n\t\tit('Grabs data and returns a json object', function(){\n\t\t\t\n\t\t\tvar callback = sinon.spy();\n\t\t\t\n\t\t\tajax({\n\t\t\t\turl: 'JSON.php',\n\t\t\t\tdataType: 'json',\t\t\t\n\t\t\t\tonSuccess: callback\n\t\t\t});\n\t\t\t\n\t\t\tthis.requests[0].respond(200, { \"Content-Type\": \"application/json\" }, \n\t\t\t\t\t\t\t'[{ \"id\": 12, \"comment\": \"Hey there\" }]');\n\t\t\t\n\t\t\texpect(this.requests.length).toBeNumber();\n\t\t\texpect(this.requests.length).toBe(1);\n\t\t\texpect(callback.calledWith([{ \"id\": 12, \"comment\": \"Hey there\" }])).toBeTruthy();\n\t\t\t\n\t\t});\n\t\t\n\t});\n\n});\n","tags":"#js"},{"id":"1834760","title":"Star ratings ","content":"/**\n * Star ratings with CSS\n */\n\n.rating {\n\t  unicode-bidi: bidi-override;\n\t  direction: rtl;\n}\n\n.rating \u003e span {\n\t  cursor: pointer;\n\t  display: inline-block;\n\t  position: relative;\n\t  width: 1.1em;\n}\n\n.rating \u003e span:hover:before,\n.rating \u003e span:hover ~ span:before {\n\t   content: \"\\2605\";\n\t   position: absolute;\n}\n\n\u003c!-- content to be placed inside \u003cbody\u003e…\u003c/body\u003e --\u003e\n\u003cdiv class=\"rating\"\u003e\n\t\u003cspan\u003e☆\u003c/span\u003e\n\t\u003cspan\u003e☆\u003c/span\u003e\n\t\u003cspan\u003e☆\u003c/span\u003e\n\t\u003cspan\u003e☆\u003c/span\u003e\n\t\u003cspan\u003e☆\u003c/span\u003e\n\u003c/div\u003e\n\n{\"view\":\"split\",\"prefixfree\":\"1\",\"page\":\"css\"}\n","tags":"#css"},{"id":"1599740","title":"Detect `onhashchange` support ","content":"var docmode = document.documentMode;\n\n// Does the browser support window.onhashchange?\n// Note that IE8 running in IE7 compatibility mode reports true for 'onhashchange' in window, \n// even though the event isn't supported, so also test document.documentMode.\nif ('onhashchange' in window \u0026\u0026 (docmode === undefined || docmode \u003e 7 )) {\n\twindow.onhashchange = checkHash;\n} \n// IE7 doesn't support the hashchange event so we fall back to standard polling technique\nelse {\n\tpoll = window.setInterval(checkHash, 500);\n\t\n\t// Clean-up objects as IE7 has hideous performance\n\twindow.onunload = function() {\n\t\twindow.clearInterval(poll);\n\t}\n}\n","tags":"#js"},{"id":"1530417","title":"Element dimensions ","content":"https://developer.mozilla.org/en/Determining_the_dimensions_of_elements\n\nGet dimensions that include everything except margin space (so borders + padding):\n`offsetWidth` and `offsetHeight`\n\nGet dimensions for just content:\n`clientWidth` and `clientHeight`\n\nGet dimensions of total height (regardless if any part is clipped/hidden):\n`scrollWidth` and `scrollHeight`\n","tags":"#js"},{"id":"1599546","title":"Error Handling with RequireJs ","content":"\u003c!doctype html\u003e\n\u003chtml dir=\"ltr\" lang=\"en\"\u003e\n\u003chead\u003e\n   \u003cmeta charset=\"utf-8\"\u003e\n\t\u003ctitle\u003eRequire Js\u003c/title\u003e\n\u003c/head\u003e\n\u003cbody\u003e\n\t\u003ch1\u003eError Handling\u003c/h1\u003e\n\t\u003cscript data-main=\"Assets/Scripts/example-error-handling\" src=\"Assets/Scripts/Require.min.js\"\u003e\u003c/script\u003e\n\u003c/body\u003e\n\u003c/html\u003e\ndefine(['this-doesnt-exist'], function(){\n\n\treturn 'my module';\n\t\n});\ndefine(function(){\n\t\n\treturn function(errObject) {\n\t\trequireType = errObject.requireType; \n                requireModules = errObject.requireModules.trim().split(' ');\n                console.log(requireType, requireModules);\n\t};\n\t\n});\nrequire.config({\n\tcatchError: {\n\t\tdefine: true\n\t}\n});\n  \nrequire(['errorhandler'], function(handler) {\n\tconsole.log('error handler loaded');\n\trequire.onError = handler;\n});\n\nrequire(['module-with-dependancy-issue'], function(mod) {\n\tconsole.log(mod);\n});\n","tags":"#js"},{"id":"1593770","title":"Host Objects ","content":"The easiest way to check what 'host' objects are available is to execute the following code:\n\n```js\nvar global = (function(){return this}()); // http://perfectionkills.com/unnecessarily-comprehensive-look-into-a-rather-insignificant-issue-of-global-objects-creation/\n\nfor (props in global) {\n    console.log(props); \n}\n```\n\nThe following is taken from Cody Lindley's \"JavaScript Enlightenment\"... \n\n\"*As it pertains to web browsers, the most famous of all hosted objects is the interface for working with HTML documents, also known as the DOM. Below, is a method to list all of the objects contained inside the `window.document` object provided by the browser environment.*\"\n\n```js\nfor (props in window.document) {\n    console.log(props); \n}\n```\n\n\"*There is a dividing line between what JavaScript provides (e.g. JavaScript 1.5, ECMA-262, Edition 3 v.s. [Mozilla's JavaScript](https://developer.mozilla.org/en/JavaScript/New_in_JavaScript)) and what the host environment provides, and these two should not be confused.*\n\n*The host environment (e.g. a web browser) that runs JavaScript code typically provides the head object (e.g. `window` object in web browser) where the native portions of the language are stored along with host objects (e.g. `window.location` in web browser) and user-defined objects (e.g. the code your write to run in the web browser).*\n\n*It's not uncommon for a web browser manufacturer as the host of the JavaScript interrupter to push forward the version of JavaScript or add future specifications to JavaScript before they have been approved (e.g. Mozilla's [Firefox](https://developer.mozilla.org/en/JavaScript/New_in_JavaScript) JavaScript 1.6, 1.7, 1.8, 1.8.1, 1.8.5).*\"\n","tags":"#js"},{"id":"1710256","title":"Google Maps with native HTML5 geolocation + audio ","content":"We had a meeting with a new client to discuss a mobile app (client had asked for an app that worked on the \"iPhone\"). This app needed to play back audio depending on the users location (specifically if they were within 5 miles of the relevant location).\n\nWe decided that we would try and guide the client to build a mobile web app and so I knocked together a quick prototype of a Google Map that used a JavaScript version of it's Places API to load McDonald restaurants within 1 mile of the users current location. I used native browser geolocation to determine the users location. I started to include the `watchPosition` method which would have been used to demonstrate the app tracking our location but wasn't added in the end because we realised we wouldn't be able to properly demo that :-)\n\nI dropped in custom markers onto the map and also decided to exclude IE9 from the demo because we had noticed issues with its geolocation algorithm (I checked online for any feedback I could find and apparently Microsofts database of Wifi locations just wasn't as good as other browsers and so the results were hideously off base).\n\u003c!doctype html\u003e\n\u003chtml lang=\"en\" dir=\"ltr\"\u003e\n\t\u003chead\u003e\n\t\t\u003cmeta charset=\"utf-8\"\u003e\n\t\t\u003ctitle\u003eGoogle Map Prototype\u003c/title\u003e\n\t\t\u003cstyle type=\"text/css\"\u003e\n\t\t\tbody {\n\t\t\t\tmargin: 0;\n\t\t\t\tpadding: 0;\n\t\t\t}\n\t\t\t\n\t\t\t/* We use set width/height dimensions because using percentages causes iOS resources to be exhausted!? */\n\t\t\t#map {\n\t\t\t\theight: 500px;\n\t\t\t\tleft: 50%;\n\t\t\t\tmargin: -225px 0 0 -350px;\n\t\t\t\tposition: absolute;\n\t\t\t\ttop: 50%;\n\t\t\t\twidth: 700px;\n\t\t\t}\n\t\t\t\n\t\t\t#audiofile {\n\t\t\t\tdisplay: none;\n\t\t\t\t\n\t\t\t\t/* iOS devices aren't hiding the element so we use a CSS3 trick to get the element out of view! */\n\t\t\t\t-webkit-transform: translate(-999em, 0);\n\t\t\t\t-moz-transform: translate(-999em, 0);\n\t\t\t\t-o-transform: translate(-999em, 0);\n\t\t\t\ttransform: translate(-999em, 0);\n\t\t\t}\n\t\t\u003c/style\u003e\n\t\u003c/head\u003e\n\t\u003cbody\u003e\n\t\t\u003caudio id=\"audiofile\" controls preload=\"auto\" autobuffer\u003e \n\t\t\t\u003csource src=\"sample.mp3\" /\u003e\n\t\t\t\u003csource src=\"sample.ogg\" /\u003e\n\t\t\u003c/audio\u003e\n\t\t\u003cdiv id=\"map\"\u003e\u003c/div\u003e\n\t\t\u003c!--\n\t\t\tNot using just standard Google Maps\n\t\t\t\u003cscript src=\"http://maps.google.com/maps/api/js?sensor=true\"\u003e\u003c/script\u003e\n\t\t--\u003e\n\t\t\u003c!--\n\t\t\tNow using Places library which also loads the Maps api\n\t\t\tReference: https://code.google.com/apis/maps/documentation/javascript/places.html\n\t\t--\u003e\n\t\t\u003cscript src=\"http://maps.googleapis.com/maps/api/js?libraries=places\u0026sensor=true\"\u003e\u003c/script\u003e\n\t\t\u003cscript type=\"text/javascript\"\u003e\n\t\t\t// Set-up new map instance (no location details specified yet)\n\t\t\tvar map = new google.maps.Map(document.getElementById('map'), {\n\t\t\t\t\tmapTypeControl: true,\n\t\t\t\t\tmapTypeControlOptions: { \n\t\t\t\t\t\tstyle: google.maps.MapTypeControlStyle.DROPDOWN_MENU \n\t\t\t\t\t},\n\t\t\t\t\tmapTypeId: google.maps.MapTypeId.ROADMAP,\n\t\t\t\t\tstreetViewControl: true\n\t\t\t\t}),\n\t\t\t\tinfowindow = new google.maps.InfoWindow(),\n\t\t\t\tmarker,\n\t\t\t\tlatlng,\n\t\t\t\twatchID,\n\t\t\t\taudioelement = document.getElementById('audiofile');\t\t\t\t\n\t\t\t\t\n\t\t\t/**\n\t\t\t * Following property indicates whether the current rendering engine is Trident (i.e. Internet Explorer)\n\t\t\t * \n\t\t\t * @return v { Integer|undefined } if IE then returns the version, otherwise returns 'undefined' to indicate NOT a IE browser\n\t\t\t */\n\t\t\tvar isIE = (function() {\n\t\t\t\tvar undef,\n\t\t\t\t\tv = 3,\n\t\t\t\t\tdiv = document.createElement('div'),\n\t\t\t\t\tall = div.getElementsByTagName('i');\n\t\t\t\n\t\t\t\twhile (\n\t\t\t\t\tdiv.innerHTML = '\u003c!--[if gt IE ' + (++v) + ']\u003e\u003ci\u003e\u003c/i\u003e\u003c![endif]--\u003e',\n\t\t\t\t\tall[0]\n\t\t\t\t);\n\t\t\t\n\t\t\t\treturn v \u003e 4 ? v : undef;\t\n\t\t\t}());\n\t\t\t\n\t\t\tvar whichPrefix = (function(){\n\t\t\t\t// check if the browser supports CSS animation\n\t\t\t\tvar temp = document.createElement('div'),\n\t\t\t\t\tprefixes = 'Webkit Moz O ms Khtml'.split(' '),\n\t\t\t\t\tprefix = false;\n\t\t\t\t\n\t\t\t\tfor(var i = 0, len = prefixes.length; i \u003c len; i++) {\n\t\t\t\t\tif(temp.style[prefixes[i] + 'Transform'] !== undefined) {\n\t\t\t\t\t\tprefix = prefixes[i];\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\t\n\t\t\t\treturn prefix;\n\t\t\t}());\n\t\t\t\n\t\t\tfunction isHostMethod(object, property) {\n\t\t\t\tvar type = typeof object[property];\n\t\n\t\t\t\treturn type == 'function' || // For Safari 3 typeof result being 'function' instead of 'object'\n\t\t\t\t\t   (type == 'object' \u0026\u0026 !!object[property]) || // Protect against ES3 'null' typeof result being 'object'\n\t\t\t\t\t   type == 'unknown' || // For IE \u003c 9 when Microsoft used ActiveX objects for Native Functions\n\t\t\t\t\t   type == 'string'; // typeof for 'document.body[outerHTML]' results in 'string'\n\t\t\t}\n\t\t\t\n\t\t\tfunction isHostObject(object, property) {\n\t\t\t\t// object[property] protects against ES3 specification which allows null to be typeof 'object'\n\t\t\t\t// so we check if 'object' is returned and that object[property] coerces to true\n\t\t\t\t// then we group both checks (\u0026\u0026 operator returns 2nd expression if 1st expression evaluates to true) and convert result into boolean\n\t\t\t\treturn !!(typeof(object[property]) == 'object' \u0026\u0026 object[property]);\n\t\t\t}\n\t\t\t\n\t\t\tfunction createMarker(place) {\n\t\t\t\tvar placeLoc = place.geometry.location,\n\t\t\t\t\tlogo = new google.maps.MarkerImage('marker-mcdonalds.png', new google.maps.Size(73,75), new google.maps.Point(0,0)),\n\t\t\t\t\tmarker = new google.maps.Marker({\n\t\t\t\t\t\tmap: map,\n\t\t\t\t\t\tposition: place.geometry.location,\n\t\t\t\t\t\ticon: logo\n\t\t\t\t\t}),\n\t\t\t\t\tcontent = '\u003cstrong\u003e' + place.name + '\u003c/strong\u003e\u003cbr\u003e' + place.vicinity + '\u003cbr\u003e\u003ca href=\"#\" id=\"audiolink\"\u003eShow audio player\u003c/a\u003e\u003cbr\u003e\u003cbr\u003e';\n\t\t\t\t\n\t\t\t\tgoogle.maps.event.addListener(marker, 'click', function() {\n\t\t\t\t\tinfowindow.setContent(content);\n\t\t\t\t\tinfowindow.open(map, this);\n\t\t\t\t});\n\t\t\t}\n\t\t\t\n\t\t\tfunction processLocation(position) {\n\t\t\t\t// Get position\n\t\t\t\tvar lat = position.coords.latitude,\n\t\t\t\t\tlng = position.coords.longitude,\n\t\t\t\t\tlatlng = new google.maps.LatLng(lat, lng);\n\t\t\t\t\n\t\t\t\t// Set map location\n\t\t\t\tmap.setOptions({\n\t\t        \tcenter: latlng,\n\t\t        \tscrollwheel: false,\n\t\t        \tzoom: 12\n\t\t        });\n\t\t        \n\t\t        // Add marker to map\n\t\t        marker = new google.maps.Marker({\n\t\t\t\t\tposition: latlng,\n\t\t\t\t\tmap: map,\n\t\t\t\t\ttitle: 'Test Title'\n\t\t\t\t});\n\t\t\t\t\n\t\t\t\t// Event listener for users current location marker\n\t\t\t\tgoogle.maps.event.addListener(marker, 'click', function() {\n\t\t\t\t\tinfowindow.setContent('This is your current location!\u003cbr\u003eWe\\'re now showing you all the McDonald\\'s in a 5 mile radius');\n\t\t\t\t\tinfowindow.open(map, this);\n\t\t\t\t});\n\t\t\t\t\n\t\t\t\t// Open the window when the app has loaded\n\t\t\t\tgoogle.maps.event.trigger(marker, 'click', function() {\n\t\t\t\t\tinfowindow.setContent('This is your current location!\u003cbr\u003eWe\\'re now showing you all the McDonald\\'s in a 5 mile radius');\n\t\t\t\t\tinfowindow.open(map, this);\n\t\t\t\t});\n\t\t\t\t\n\t\t\t\t// Request any McDonald's within 1 mile (in meters) from the current location\n\t\t\t\tvar request = {\n\t\t\t\t\tlocation: latlng,\n\t\t\t\t\tradius: 8046.72, // 5 miles =\u003e http://www.unitconversion.org/length/meters-to-miles-conversion.html\n\t\t\t\t\ttypes: ['food'],\n\t\t\t\t\tname: 'McDonald'\n\t\t\t\t};\n\t\t\t\t\n\t\t\t\t// Create the Places request\n\t\t\t\tvar service = new google.maps.places.PlacesService(map);\n\t\t\t\t\tservice.search(request, function(results, status){\n\t\t\t\t\t\tif (status == google.maps.places.PlacesServiceStatus.OK) {\n\t\t\t\t\t\t\tfor (var i = 0; i \u003c results.length; i++) {\n\t\t\t\t\t\t\t\tvar place = results[i];\n\t\t\t\t\t\t\t\tcreateMarker(results[i]); \n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t});\n\t\t\t}\n\t\t\t\n\t\t\t// Doesn't appear to be executed??\n\t\t\tfunction handleLocationErrors(err) {\n\t\t\t\tswitch(err.code) {\n\t\t\t\t\tcase err.PERMISSION_DENIED:\n\t\t\t\t\t\talert('You have decided not to share your location information');\n\t\t\t\t\t\tbreak;\n\t\t\t\t\tcase err.POSITION_UNAVAILABLE:\n\t\t\t\t\t\talert('I\\'m sorry but we could not detect your location');\n\t\t\t\t\t\tbreak;\n\t\t\t\t\tcase err.TIMEOUT:\n\t\t\t\t\t\talert('I\\'m sorry but the system timed out while waiting to retrieve your location information');\n\t\t\t\t\t\tbreak;\n\t\t\t\t\tdefault:\n\t\t\t\t\t\talert('I\\'m sorry but an unknown error occurred');\n\t\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t\t\n\t\t\t// Handle audio playback\n\t\t\tfunction handleAudio(e) {\n\t\t\t\tvar targ = e.target,\n\t\t\t\t\taudio;\n\t\t\t\t\n\t\t\t\tif (targ.id === 'audiolink') {\n\t\t\t\t\t// Make a copy of the \u003caudio\u003e element hidden in the page\n\t\t\t\t\taudio = audioelement.cloneNode(true);\n\t\t\t\t\t\n\t\t\t\t\t// Remove the link and replace with an audio tag\n\t\t\t\t\ttarg.parentNode.replaceChild(audio, targ);\n\t\t\t\t\taudio.style.display = 'block';\n\t\t\t\t\t\n\t\t\t\t\tif (whichPrefix !== false) {\n\t\t\t\t\t\taudio.style[whichPrefix + 'Transform'] = 'translate(0, 0)';\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\t\n\t\t\t// Bind Event Delegation to links\n\t\t\tdocument.body.addEventListener('click', handleAudio, false);\n\t\t\t\n\t\t\t// Because of IE9's rubbish implementation of geolocation makes it as useful as the basic ip address lookup polyfills (so not very useful)\n\t\t\tif(isHostObject(navigator, 'geolocation') || isIE \u003e 9) {\n\t\t\t\t// This will ask the user to authorise the request for their location (only if geolocation is natively supported)\n\t\t\t\tnavigator.geolocation.getCurrentPosition(processLocation, handleLocationErrors);\n\t\t\t\t\n\t\t\t\t// If the user starts moving around then watch their position\n\t\t\t\twatchID = navigator.geolocation.watchPosition(function(){\n\t\t\t\t\t// DO SOMETHING\n\t\t\t\t});\n\t\t\t} else {\n\t\t\t\talert('I\\'m sorry, your device isn\\'t capable of supporting the geolocation api which is required for this application to work correctly');\n\t\t\t}\n\t\t\u003c/script\u003e\n\t\u003c/body\u003e\n\u003c/html\u003e\n","tags":"#js"},{"id":"1525419","title":"Execution context (Variable/Activation Object) from @kangax's ","content":"Reference: \nhttp://perfectionkills.com/understanding-delete/\n\nThere are 3 types of executable code in ECMAScript: \n\n* Global code\n* Function code\n* Eval code\n\nWhen ECMAScript code executes, it always happens within a certain execution context.\n\nExecution contexts can logically form a stack. First there might be Global code with its own execution context; that code might call a function, with its own execution context; that function could call another function, and so on and so forth. Even if function is calling itself recursively, a new execution context is being entered with every invocation.\n\nGlobal code (and the Variable Object)\n=====================================\n\nEvery execution context has a so-called Variable Object associated with it.\n\nWhen control enters execution context for Global code, a Global object is used as a Variable object. This is precisely why variables or functions declared globally become properties of a Global object.\n\nFunction code\n=============\n\nOk, so global variables become properties of Global object, but what happens with local variables — those declared in Function code? The behavior is actually very similar: they become properties of a Variable object. The only difference is that when in Function code, a Variable object is not a Global object, but a so-called Activation object. An Activation object is created every time execution context for Function code is entered.\n\nNot only do variables and functions declared within Function code become properties of Activation object; this also happens with each of function arguments (under names corresponding to formal parameters) and a special Arguments object (under arguments name). Note that Activation object is an internal mechanism and is never really accessible by program code.\n\nEval code\n=========\n\nVariables declared within Eval code are created as properties of calling context’s Variable object. Eval code simply uses Variable object of the execution context that it’s being called within.\n\nProperty Attributes\n===================\n\nEvery property can have zero or more attributes from the following set — ReadOnly, DontEnum, DontDelete and Internal. You can think of them as flags — an attribute can either exist on a property or not. For the purposes of today’s discussion, we are only interested in DontDelete.\n\nWhen declared variables and functions become properties of a Variable object — either Activation object (for Function code), or Global object (for Global code), these properties are created with DontDelete attribute. However, any explicit (or implicit) property assignment creates property without DontDelete attribute. And this is essentialy why we can delete some properties, but not others.\n\nSummary\n=======\n\nHere’s a short summary of how deletion works in Javascript:\n\n* Variables and function declarations are properties of either Activation or Global objects.\n* Properties have attributes, one of which — DontDelete — is responsible for whether a property can be deleted.\n* Variable and function declarations in Global and Function code always create properties with DontDelete.\n* Function arguments are also properties of Activation object and are created with DontDelete.\n* Variable and function declarations in Eval code always create properties without DontDelete.\n* New properties are always created with empty attributes (and so without DontDelete).\n* Host objects are allowed to react to deletion however they want.\n","tags":"#js"},{"id":"1525378","title":"Feature Testing a Host Method ","content":"        /*\n\t * Feature Testing a Host Method\n\t * Because a callable host object can legitimately have any typeof result then it can't be relied upon.\n\t *\n\t * @notes:\n\t * The reason for the \u0026\u0026 !!object[property] is because in ECMAScript version 3, \n\t * a null object has typeof result 'object' (which is considered a bug).\n\t * In future versions (ECMAScript 5+) the typeof result will be 'null' (as it should be).\n\t * \n\t * @reference: http://michaux.ca/articles/feature-detection-state-of-the-art-browser-scripting\n\t */\n\n\tfunction isHostMethod(object, property) {\n\t\tvar type = typeof object[property];\n\n\t\treturn type == 'function' || // For Safari 3 typeof result being 'function' instead of 'object'\n\t\t\t   (type == 'object' \u0026\u0026 !!object[property]) || // Protect against ES3 'null' typeof result being 'object'\n\t\t\t   type == 'unknown' || // For IE \u003c 9 when Microsoft used ActiveX objects for Native Functions\n\t\t\t   type == 'string'; // typeof for 'document.body[outerHTML]' results in 'string'\n\t}\n","tags":"#js"},{"id":"1430271","title":"JSON-P ","content":"\u003c?php\n\theader('Content-Type: text/javascript; charset=utf8');\n\theader('Access-Control-Allow-Origin: http://www.domain.com/');\n\theader('Access-Control-Max-Age: 3628800');\n\theader('Access-Control-Allow-Methods: GET, POST, PUT, DELETE');\n\t\n\t// Callback function\n\t$callback = $_GET['callback'];\n\t\n\t// JSON data\n\t$data = '{\"name\":\"mark mcdonnell\"}';\n\t\n\techo $callback.'('.$data.');';\n?\u003e\n","tags":"#php"},{"id":"1513947","title":"Calculate distance between two co-ordinates on a Map (Lat/Lng) ","content":"$custlat1 = xxxxx;\n$custlong1 = xxxxx;\n$custlat2 = xxxxx;\n$custlong2 = xxxxx;\n\n$pi80 = M_PI / 180;\n$custlat1 *= $pi80;\n$custlong1 *= $pi80;\n$custlat2 *= $pi80;\n$custlong2 *= $pi80;\n$r = 6372.797; \n$dlat = $custlat2 - $custlat1;\n$dlng = $custlong2 - $custlong1;\n$a = sin( $dlat / 2 ) * sin( $dlat / 2 ) + cos( $custlat1 ) * cos( $custlat2 ) * sin( $dlng / 2 ) * sin( $dlng / 2 );\n$c = 2 * atan2( sqrt( $a ), sqrt( 1 - $a ) );\n  \n// Distance in KM so we can work out how the milage\n$km = round( $r * $c, 2 );\n  \n// Now we have the distance in miles\n$miles = round( $km * 0.621371192, 2 );\norigin = new google.maps.LatLng(userLatLng[0], userLatLng[1]);\ndestination = new google.maps.LatLng(results[0].geometry.location.Qa, results[0].geometry.location.Ra);\n\nvar pi, \n    custlat1 = userLatLng[0],\n    custlong1 = userLatLng[1],\n    custlat2 = results[0].geometry.location.Qa,\n    custlong2 = results[0].geometry.location.Ra,\n    r,\n    dlat,\n    dlng,\n    a,\n    c,\n    km,\n    miles;\n\t\t\t\t\t\t\n// Calculate the distance between two Lat/Lng values\npi = Math.PI / 180;\ncustlat1 *= pi;\ncustlong1 *= pi;\ncustlat2 *= pi;\ncustlong2 *= pi;\nr = 6372.797;\ndlat = custlat2 - custlat1;\ndlng = custlong2 - custlong1;\na = Math.sin(dlat / 2) * Math.sin(dlat / 2) + Math.cos(custlat1) * Math.cos(custlat2) * Math.sin(dlng / 2) * Math.sin(dlng / 2);\nc = 2 * Math.atan2(Math.sqrt(a), Math.sqrt(1 - a));\nkm = roundNumber(r * c, 2); // Distance in KM so we can work out how the milage\nmiles = roundNumber(km * 0.621371192, 2); // Now we have the distance in miles\n\t\t\t\t\t\nconsole.log('miles:', miles, 'address:', address);\n","tags":"#js"},{"id":"1446641","title":"How to use @testling ","content":"// Create account with http://browserling.com/\n// Run tests via http://testling.com/\n//\n// Documentation: http://testling.com/docs/\n//\n// Execute test via Terminal: \n// \t\tcurl -u me@example.com:password -sSNT mytest.js testling.com/?browsers=iexplore/6.0,iexplore/7.0,safari/5.0\n// \t\tcurl -u me@example.com:password -sSNT mytest.js testling.com/?browsers=iexplore/6.0,firefox,safari\n//\n// With a free account you get 200 minutes per month.\n// To check your usage:\n// \t\tcurl -u me@example.com -s testling.com/usage\n\nvar test = require('testling');\n\ntest('the test name', function (t) {\n    // See all test assertions here: \n    // http://testling.com/docs/#test-assertions\n    \n    t.equal(2 + 2, 4);\n    \n    t.ok(window.JSON, 'JSON is natively supported');\n    \n    t.log(window.navigator.appName);\n\n    t.end();\n});\n","tags":"#js"},{"id":"1442875","title":"browser cache prevents image onload event ","content":"/*\n * Had issue with browsers caching images and so they were not triggering an onload event.\n * This jQuery snippet helped fixed the issue.\n * \n * UPDATE: \n * Discovered that IE9 was having issues (IE7/8 were fine?)\n * So we used a 'cache-buster' technique which is to append a QueryString onto the end of the image URL\n */\n\nvar originalSource,\n    imageList = $('img');\n\n/*\n * Following function expression indicates whether the current rendering engine is Trident (i.e. Internet Explorer)\n * \n * @return v { Integer|undefined } if IE then returns the version, otherwise returns 'undefined' to indicate NOT a IE browser\n */\nvar isIE = (function() {\n    var undef,\n        v = 3,\n        div = document.createElement('div'),\n        all = div.getElementsByTagName('i');\n\n    while (\n        div.innerHTML = '\u003c!--[if gt IE ' + (++v) + ']\u003e\u003ci\u003e\u003c/i\u003e\u003c![endif]--\u003e',\n        all[0]\n    );\n\n    return v \u003e 4 ? v : undef;\t\n}());\n\n// If we're not using IE then we can use the img.complete property to determine if image is loaded\nif (!isIE) {\n  \n    // Execute the 'load' event only once\n    $(imageList).one('load', function() {\n        // Do stuff on image load\n    })\n    // Loop through each image found\n    .each(function() {\n        // Check if the image 'complete' property has been set to true\n        // See: https://developer.mozilla.org/en/DOM/HTMLImageElement#DOM_properties\n        if(this.complete) {\n            // Trigger the load event for each image\n            $(this).load();\n        }\n    });\n  \n} else {\n   \n    // Loop through each image found\n    $(imageList).each(function(){\n        \n        // Keep a reference to the original src\n        originalSource = this.src;\n\n        // Reset the src attribute so it includes a QueryString (this is the 'cache-buster' technique)\n        this.src = originalSource + '?' + new Date().getTime();\n\n    }).on('load', function(){\n        // Do stuff on image load \n    });\n    \n}\n","tags":"#js"},{"id":"1393248","title":"News Ticker ","content":"function handler() {\n\t/*\n\t * I try to structure my code as follows:\n\t *  - Variables (they're hoisted anyway so best to define at top)\n\t *  - Functions (I find it neater to have functions next before the code that uses them)\n\t *  - Code (this is the code that the above variables/functions were set-up for)\n\t *\n\t * Help:\n\t *  I want to try and clean this code example up but not sure where to start, ideas?\n\t */\n\t \n\t// Define variables in use throughout script\n\tvar doc = document,\n            element = doc.createElement('div'),\n            delay = 1000,\n            timer = 100,\n            pos = 0,\n            x = 0,\n            list,\n            max,\n            len;\n\t\n\t// Define function for handling the ticker text\n\tfunction ticker() {\n\t\t\t\n\t\t// Get the next section of characters (starting from 0 to current character position)\n\t\telement.innerHTML = list[x].substring(0, pos) + '_';\n\t\t\n\t\tif(pos++ === len) { \n\t\t\t\n\t\t\tpos = 0;\n\t\t\t\n\t\t\t// Wait for specified time frame before executing again\n\t\t\t// This gives the user a chance to read the text in full\n\t\t\tsetTimeout(function(){\n\t\t\t\tticker();\n\t\t\t}, delay);\n\t\t\t\n\t\t\tx++;\n\t\t\t\n\t\t\t// If we've reached the end of the list of available strings then reset\n\t\t\tif(x === max) {\n\t\t\t\tx = 0;\n\t\t\t}\n\t\t\t\n\t\t\tlen = list[x].length;\n\t\t\t\n\t\t} else {\n\t\t\t// If we're not at the end of the current String item then re-execute\n\t\t\tsetTimeout(function(){\n\t\t\t\tticker();\n\t\t\t}, timer);\n\t\t}\n\t\t\n\t}\n\t\n\t// Set-up the element that will hold the ticker text\n\telement.id = 'ticker';\n\tdoc.body.appendChild(element);\n\t\n\t// Create the ticker text data\t\n\tlist = [\n\t\t'This is a message',\n\t\t'Another one',\n\t\t'And this will be the third',\n\t\t'And the fourth is the last!'\n\t];\n\n\t// Set restrictions\n\tmax = list.length;\n\tlen = list[0].length;\n\t\n\t// Start the ticker\n\tticker();\n}\n\ndocument.addEventListener('DOMContentLoaded', handler, false);\n","tags":"#js"},{"id":"2510274","title":"HTML5 Placeholder Polyfill","content":"var doc = document,\n    body = doc.body,\n    inputs = doc.getElementsByTagName(\"input\"),\n    txtarea = doc.getElementsByTagName(\"textarea\"),\n    combined = [],\n    len,\n    placeholder, \n    lastInputSelected;\n\n/**\n * Following function determines whether the previously selected input should have its original placeholder value re-inserted.\n * And then based on the currently selected input works out if it should have it's placeholder text removed so user can enter their own value.\n *\n * @param e { Object } standardised event object\n * @return undefined {  } no explicitly returned value\n */\t\nfunction inputHandler(e) {\n\tvar targ = e.target || e.srcElement,\n        type = e.type;\n\t\t \n\tplaceholder = targ.getAttribute(\"placeholder\");\n\t\n\t// If there was an input previously selected...\n\tif (lastInputSelected !== undefined) {\n\t\t// ...then check to make sure that if it was left blank...\n\t\tif (lastInputSelected.value === '') {\n\t\t\t// ...that its value is set back to it's placeholder value\n\t\t\tlastInputSelected.value = lastInputSelected.getAttribute(\"placeholder\");\n\t\t}\n\t}\n\t\n\t// If the target element has a placeholder...\n\tif (placeholder !== null) {\n\t\t\n\t\t// ...then store it as the last input selected...\n\t\tlastInputSelected = targ;\n\t\t\n\t\tif (type === \"blur\") {\n\t\t\tif (targ.value === \"\") {\n\t\t\t\ttarg.value = placeholder;\n\t\t\t}\n\t\t} else {\n\t\t\t// ...then check if its value is the same as its placeholder and clear the value if so...\n\t\t\tif (targ.value === placeholder) {\n\t\t\t\ttarg.value = \"\";\n\t\t\t}\n\t\t}\n\t\t\n\t}\n}\n\n/*\n * To combine the two Arrays it would have been nice to just do:\n *     var combined = [].concat(Array.prototype.slice.call(inputs), Array.prototype.slice.call(txtarea));\n * But Internet Explorer fails with this, so we have merge the objects the long way!\n */\n\nfor (var i = 0; i \u003c inputs.length; i++) {\n    combined.push(inputs[i]);\n}\n\nfor (var j = 0; j \u003c txtarea.length; j++) {\n    combined.push(txtarea[j]);\n}\n\t\nlen = combined.length;\n\n\twhile (len--) {\n\t// Make sure the input has a placeholder attribute AND isn't a password field (for the time being I'm ignoring password fields)\n\tif (combined[len].getAttribute('placeholder') !== null \u0026\u0026 combined[len].type !== 'password') {\n\t\t// Set the value of the input to the placeholder value\n\t\tcombined[len].value = combined[len].getAttribute('placeholder');\n\t}\n}\n\n// To get Event Delegation to work we need to listen for 'focus' \u0026 'blur' events.\n// Firefox \u0026 WebKit have useCapture set to true which initiates capturing (rather than bubbling)\n// Internet Explorer uses attachEvent to listen to 'focusin' event (as it can only handling bubbling phase)\nif (\"addEventListener\" in window) {\n    body.addEventListener(\"focus\", inputHandler, true);\n    body.addEventListener(\"blur\", inputHandler, true);\n} else {\n\tbody.attachEvent(\"onfocusin\", inputHandler);\n\tbody.attachEvent(\"onfocusout\", inputHandler);\n}\n","tags":""},{"id":"1393418","title":"Detect previousElementSibling/nextElementSibling ","content":"Description\n-----------\n\nMy team likes to use the `previousElementSibling` and `nextElementSibling` methods as it saves them having to filter out TEXT_NODES (which the majority of the time - when sifting through the DOM - they don't have to worry about).\n\nInternet Explorer \u003c= 8 doesn't support either method, but it's current DOM implementation ignores TEXT_NODES (when using `previousSibling` and `nextSibling`) so they already act like `previousElementSibling` and `nextElementSibling`.\n\nBut when checking over my teams code I noticed that they would use a conditional code branching in every instance where they wanted to use `previousElementSibling` and `nextElementSibling`, so to try and help keep their code DRY I just used a very basic feature detection script to abstract these methods into two separate functions for them to use instead.\n\nCaveat\n------\n\nThis feature detection assumes the `head` and a `body` tags are available at the time of the script executing.\nvar prevElementSibling = (function(){\n\tvar supported = !!document.body.previousElementSibling,\n\t\tprev = (supported) ? 'previousElementSibling' : 'previousSibling';\n\t\n\treturn function(currentElement) {\n\t\treturn currentElement[prev];\n\t};\n}());\n\nvar nextElementSibling = (function(){\n\tvar supported = !!document.getElementsByTagName('head')[0].nextElementSibling,\n\t\tnext = (supported) ? 'nextElementSibling' : 'nextSibling';\n\t\n\treturn function(currentElement) {\n\t\treturn currentElement[next];\n\t};\n}());\n\nvar head = prevElementSibling(document.body);\nconsole.log(head);\n\nvar body = nextElementSibling(document.getElementsByTagName('head')[0]);\nconsole.log(body);\n","tags":"#js"},{"id":"2391459","title":"Relative Sizing","content":"If you set the `\u003cbody\u003e` element to have `font-size: 100%` then you are effectively setting the pixel size base line to be `16px`.\n\nSo now `1em` equals `16px`.\n\nTo size either our text or our layouts to match what the designer has specified in pixels we use the following calculation:\n\n`target / context = result`\n\nThis means if your target font size for a `\u003ch1\u003e` is 24px and your 'context' (the container) is 16px then you calculate this as:\n\n`24 / 16 = 1.5`\n\nSo you set your font size to `1.5em`.\n\nSame for a layout. If the designer has made the website `960px` wide and has an element within it that is `900px` wide. \n\nFirst thing to do is to set the `960px` width to be a percentage. Well we have to just take a guess on this I'm afraid so we'll choose 90%.\n\nBut thankfully to turn `900px` into a percentage we can use the previous calculation of `target / context = result` again:\n\n`900 / 960 = .9375`\n\nBut now (as you're using percentages for your layout) you move the decimal over two places: `93.75%`\n","tags":""},{"id":"1370735","title":"JSONP Async Loading via RequireJs ","content":"\u003c?php\n\theader('Content-Type: text/javascript; charset=utf8');\n\theader('Access-Control-Allow-Origin: *');\n\theader('Access-Control-Max-Age: 3628800');\n\theader('Access-Control-Allow-Methods: GET, POST, PUT, DELETE');\n\t\n\t// Callback function\n\t$callback = $_GET['callback'];\n\t\n\t// JSON data\n\t$data = '{\"name\":\"mark mcdonnell\"}';\n\t\n\t// Delay sending the data back (this is to mimic latency)\n\tsleep(5);\n\t\n\techo $callback.'('.$data.');';\n?\u003e\nrequire.config({ \n\tpaths: { \n\t\tjsonp: 'Plugins/jsonp'\n\t} \n});\n\nrequire(['jsonp!http://twitter.com/statuses/user_timeline/Integralist.json?callback=rjs_global', \n\t\t 'jsonp!http://twitter.com/statuses/user_timeline/Barracat.json?callback=rjs_global', \n\t\t 'jsonp!http://api.twitter.com/1/trends/available.json?callback=rjs_global'], function(feed1, feed2, feed3) {\n\tconsole.log('feed1: ', feed1);\n\tconsole.log('feed2: ', feed2);\n\tconsole.log('feed3: ', feed3);\n});\n\nrequire(['jsonp!JSON-P.php?callback=rjs_global'], function(feed4) {\n\tconsole.log('feed4: ', feed4);\n});\ndefine(function(){\n\t\n\tfunction loadScript(url, callback) {\n\t\tvar d = document,\n\t\t\tb = d.body,\n\t\t\tcallback = (typeof callback !== \"undefined\") ? callback : function(){},\n\t\t\tscript = d.createElement(\"script\");\n\t\t\tscript.type = \"text/javascript\";\n\t\n\t\tif (script.readyState) { // Internet Explorer\n\t\t\tscript.onreadystatechange = function() {\n\t\t\t\tif (script.readyState == \"loaded\" || script.readyState == \"complete\") {\n\t\t\t\t\t/*\n\t\t\t\t\t * Oddly the final readyState isn’t always \"complete\". \n\t\t\t\t\t * Sometimes, readyState stops at \"loaded\" without going on to \"complete\" \n\t\t\t\t\t * and sometimes it skips over \"loaded\" altogether. \n\t\t\t\t\t * \n\t\t\t\t\t * The best approach is to check for both readyState values \n\t\t\t\t\t * and remove the event handler in both cases to ensure you don’t handle the loading twice:\n\t\t\t\t\t */\n\t\t\t\t\tscript.onreadystatechange = null;\n\t\t\t\t\tcallback(true);\n\t\t\t\t}\n\t\t\t};\n\t\t} else {\n\t\t\tscript.onload = function() {\n\t\t\t\tcallback(true);\n\t\t\t};\n\t\t}\n\t\n\t\tscript.src = url;\n\t\tb.insertBefore(script, b.firstChild); // can be a problem if the BODY doesn't exist\n\t}\n\t\n\t// Create global variable for jsonp service to execute\n\twindow['rjs_global'] = function(data) {\n\t\t// Create global variable to store returned data\n\t\twindow['rjs_jsonp'] = data;\n\t};\n\t\n\treturn {\n\t\t/**\n\t\t * @param resource { String } the resource to be loaded\n\t\t * @param req { Function } a local require() for loading other modules\n\t\t * @param load { Function } a function to call with the value for name (this tells the loader that the plugin is done loading the resource)\n\t\t * @param config { Object } the main configuration object RequireJs is using\n\t\t */\n\t\tload: function(resource, req, load, config) {\n\t\t\tloadScript(resource, function(loaded){\n\t\t\t\tif (loaded \u0026\u0026 ('rjs_jsonp' in window)) {\n\t\t\t\t\tload(window['rjs_jsonp']);\n\t\t\t\t}\n\t\t\t});\n\t\t}\n\t};\n\t\n});\n","tags":"#js #php"},{"id":"1391785","title":"mixins \u003e inheritance ","content":"var people,\n\tperson = {\n\t\tnames: ['James', 'Neil', 'Russ', 'Stuart']\n\t};\n\nfunction extend(destination, source, overwrite) {\n\tvar overwrite = overwrite || false;\n\tfor (var i in source) {\n\t\tif (source.hasOwnProperty(i)) {\n\t\t\t// If we're not allowed to overwrite an existing property… \n\t\t\tif (!overwrite) {\n\t\t\t\t// …then we check to see if the property is undefined… \n\t\t\t\tif (destination[i] === undefined) {\n\t\t\t\t\t// …if it is then we know we can copy the property to the destination object\n\t\t\t\t\tdestination[i] = source[i];\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tdestination[i] = source[i];\n\t\t\t}\n\t\t}\n\t}\n\treturn destination; \n}\n\npeople = {\n\tnames: ['Ash', 'Brad', 'Mark', 'Mike'],\n\tspeak: function(which) {\n\t\tconsole.log('Hi, my name is ' + this.names[which]);\n\t}\n};\n\n// Composition not Inheritance\npeople.speak.call(person, 1); // Neil\n\n// Composition via Mixin\nextend(person, people, true); // leaving off the 3rd argument means we can can't overwrite the 'names' Array as it already exists\nperson.speak(1); // Brad\nconsole.log('person has been extended', person);\n","tags":"#js"},{"id":"2509586","title":"Recruitment Questions for front-end developer (modified from https://github.com/darcyclarke/Front-end-Developer-Interview-Questions)","content":"##JavaScript specific Questions\n\n* Which JavaScript libraries have you used?\n* How is JavaScript different from Java?\n* What are undefined and undeclared variables?\n* What is an expression?\n* What is a statement?\n* Give an example of a function declaration\n* Give an example of a function expression\n* Explain what the DOM is and some best practices for interacting with it.\n* What is a closure, and how/why would you use one?\n* What's a typical use case for anonymous functions?\n* Explain the \"JavaScript module pattern\" and when you'd use it.\n* How do you organize your code? (AMD, module pattern, classical inheritance)\n* What's the difference between host objects and native objects?\n* Explain Function.prototype.bind?\n* When do you optimize your code?\n* Can you explain how inheritance works in JavaScript?\n* When would you use document.write()?\n* What's the difference between feature detection, feature inference, and using the UA string?\n* Explain AJAX in as much detail as possible\n* Explain how JSONP works?\n* Have you ever used JavaScript templating, and if so, what/how?\n* Explain \"hoisting\".\n* What is FOUC? How do you avoid FOUC?\n* Describe event bubbling.\n* What's the difference between an \"attribute\" and a \"property\"?\n* Why is extending host objects not a good idea?\n* Difference between document load event and document ready event?\n* What is the difference between == and ===?\n* Explain how you would get a query string parameter from the browser window's URL.\n* Explain event delegation.\n* Describe inheritance patterns in JavaScript.\n* Describe a strategy for memoization (avoiding calculation repetition) in JavaScript.\n* What's the best way to handle lots of arguments passed to a function?\n* Have you used the Canvas element and if so what did you use it for?\n* How do you debug errors in your code?\n* Do you validate your code and if so what tools do you use?\n* Show us how you would get the internal class of a native object, specifically an Array (e.g. `typeof [1, 2, 3]` results in 'object' which is incorrect, we want to get the actual class value which should be 'Array').\n* Write a quick events library that abstracts the basic 'add' and 'remove' event listeners so they work across multiple browsers (specifically needs to work with Internet Explorer)\n* Write a quick function which lets an object inherit the methods and properties from another object (you can use either an inheritance pattern or a composite pattern).\n* Write a quick function which demonstrates the 'module pattern' (this pattern keeps variables and methods private and can also provide an API to allow another user to access the internal methods via 'privileged' methods).\n* Write a quick function which allows the user to specify an element and to add a class to that element (being careful not to overwrite the existing classes or adding the same class twice).\n* Write a quick function that truncates a String of text which is over 30 characters long (e.g. if the String of text is over 30 characters then the text is shortened to 30 characters and a '...' placed at the end to show the text has been shortened)\n* What are some best practices when using a framework such as jQuery?\n* What's wrong with the following jQuery code? (extra points for pointing out other issues with the HTML - inc. best practices and performance):\n\n![](http://f.cl.ly/items/0x3r132T322e2f3D0S2N/whats-wrong-with-this-code.png)\n\n##General Questions\n\n* Are you on twitter? If so who do you follow? and is there any one of interest following you!\n* Are you on GitHub? If so can you show us some of your repositories and tell us a bit about why you've mentioned them specifically?\n* What (if any) Version Control systems have you used? Also, which one do you prefer and why?\n* What development tools do you use (e.g. IDE's such as Eclipse, or more CLI like vim)?\n* What is your development environment? (e.g. do you work with Mac or Windows? do you use an IDE or basic text editor?)\n* Can you describe your workflow when you create a web page?\n* What is a design pattern?\n* Briefly explain creatively what Object Oriented programming is.\n* You need to make your site as quick as possible to load, what are some of the things you can do to help page performance?\n* You need to build an online auction system that works like eBay. How would you plan and structure your code? What important aspects would you need to consider?\n* You need to build the next big social networking web application. It's going to be used by millions of users. How would you plan and structure your code? What important aspects would you need to consider?\n* How would you work with a group of developers on the same code base?\n* Working on a website with a high volume of users, how would you push new features to the live site without disrupting the website or current users?\n* What is progressive enhancement and graceful degradation?\n* Explain what \"Semantic HTML\" means.\n* What does \"minification\" do?\n* Why is it better to serve site assets from multiple domains?\n* If you have 8 different stylesheets for a given design, how would you integrate them into the site?\n* What tools do you use to test your code's performance?\n* If you could master one technology this year, what would it be?\n* Name 3 ways to decrease page load?\n* What tools do you use to analyse website performance?\n* What does a doctype do?\n* What's the difference between standards mode and quirks mode?\n* What are the limitations when serving XHTML pages? Are there any problems with serving pages as application/xhtml+xml?\n* What are data- attributes good for?\n* What are the content models in HTML4 and are they different in HTML5?\n* What is HTML5?\n* Describe the difference between cookies, sessionStorage and localStorage.\n\n##CSS Specific Questions\n\n* Describe what a \"reset\" CSS file does and whether you think they are useful or not.\n* How do you structure your CSS?\n* Explain CSS sprites.\n* What are the differences between the IE box model and the W3C box model?\n* What are your favourite image replacement techniques and which do you use and when?\n* CSS property hacks, conditionally included .css files, or... something else?\n* How do you serve certain CSS features to older browsers who do not support them?\n* What technique do you use to hide content?\n* Have you ever used a grid system, and if so, which one and what are your thoughts on grid systems in general?\n* Have you used media queries or implemented a mobile specific layout/CSS?\n* How do you optimize your webpages for print?\n* What are some rules for writing efficient CSS?\n* Do you use CSS preprocessors? If so, describe what you like and dislike about the CSS preprocessors you have used.\n* How would you implement a web design comp that uses non-standard fonts?\n* What's the coolest thing you've ever coded, what are you most proud of?\n* Do you have any side projects? What kind?\n","tags":""},{"id":"1875544","title":"set-up remote git repository ","content":"Set-up remote git repository on a standard server\n===\n\nThe first thing to do is to install Git on the remote server.\n\nOnce you do that the rest of the process is split into three sections:\n\n1. Server set-up\n2. Local set-up (push commits)\n3. Server (pull commits)\n\nServer set-up\n---\n* `ssh -pxxxx username@xxx.xxx.xxx.xxx` (this is you connecting to your remote server)\n* `cd ../` (this gets you to the 'absolute root' of the server)\n* `cd www/..../` (navigate to the directory one level above your website directory - e.g. your website directory being where you would upload your `HTML` files etc)\n\n*Note*: if (for example) your web directory is `httpdocs` then move up one level from there.\n\nThe following example assumes `httpdocs` is your web directory...\n\n* `rm -rf httpdocs` (remove the web directory - you'll recreate it again in a minute)\n* `mkdir httpdocs \u0026\u0026 cd httpdocs` (create new web directory folder and move inside it)\n* `git init` (initiate new git repo)\n* `cd ../` (jump back up a directory level)\n\nThe following three commands are the *black magic* for getting a remote git repo setup:\n\n* `git clone --bare httpdocs httpdocs.git`\n* `mv httpdocs httpdocs.backup`\n* `git clone httpdocs.git`\n\nLocal set-up (push commits)\n---\n* `cd ~/Desktop/Sites/myWebsite`\n* `git init`\n* `git add *`\n* `git commit -m 'Start of new project'`\n* `git remote add origin ssh://username@xxx.xxx.xxx.xxx:xxxx/www/.../httpdocs.git`\n* `git push origin master`\n\nServer (pull commits)\n---\n* `cd ../`\n* `cd www/..../httpdocs/`\n* `git fetch`\n* `git diff origin/master`\n* `git merge origin/master`\n","tags":"#git"},{"id":"2214136","title":"Git Workflow using an organisation account with Private repositories","content":"#Overview - setting up our git workflow\nThis set-up works for our team as we don't mind pushing directly to a `development` branch, but this wouldn't work for other companies as the development branch could potentially get broken fairly quickly and with multiple developers working on this singular branch would be awkward to locate issues and fix - but for a small team this seems to work fine.\n\n##Initial User Set-Up\nThe first developer to work on the new project will go through this process:\n\n* `\u003cgithub\u003e`  \n\tCreate repository on GitHub company account\n\t\n* `\u003clocal\u003e`  \n\tCreate folder and initialise repo: `git init`\n\t\n* `\u003clocal\u003e`  \n\tAdd remote: `git remote add origin \u003cpath/to/repo\u003e`\n\t\n* `\u003clocal\u003e`  \n\tStage, Commit \u0026 Push a README file to `origin`\n\t\n* `\u003clocal\u003e`  \n\tCreate a `development` branch: `git checkout -b development`\n\t\n* `\u003clocal\u003e`  \n\tStage updated README, Commit \u0026 Push the `development` branch to GitHub: `git push origin development`\n\n##New User\nIf another member of the team wants to work on this repository then they'll follow this process:\n\n* `\u003cgithub\u003e`  \n\tFind the SSH url to the repo\n\n* `\u003clocal\u003e`  \n\tClone the remote repo using the SSH url (notice only `master` branch is visible)\n\t\n* `\u003clocal\u003e`  \t\n\tWe need to track the remote branch `development`: `git checkout -b development origin/development`\n\t\n* `\u003clocal\u003e`  \t\n\tNow we're on the `development` branch we can make our updates.\n\t\n* `\u003clocal\u003e`  \t\n\tStage, Commit and Push to `development` branch: `git push origin development`\n","tags":""},{"id":"2035643","title":"Aspect Ratio Calculator","content":"If you have a photo that is 1600 x 1200 pixels, but your website only has space for a photo 400 pixels wide. To find the new height of your photo — while preserving the aspect ratio — you would need to do the following calculation:\n\n`original height / original width x new width = new height`\n\n`1200 / 1600 x 400 = 300`\n","tags":""},{"id":"2385187","title":"[JS before AMD] ","content":"Example of how I used to write my code (before I discovered AMD)\n\nFor example in my HTML page would be… \n\n```html\n\u003cscript src=\"Assets/Scripts/LAB.min.js\"\u003e\u003c/script\u003e\n\u003cscript\u003e\n\t$LAB\n\t.setOptions({ AlwaysPreserveOrder:true, BasePath:\"Assets/Scripts/\" })\n\t\t.script(\"bootstrap.js\").wait(function(){\n\t\t\tmm.init({ cool_feature:true, another_cool_feature:true });\n\t\t});\n\u003c/script\u003e\n```\n…and within `bootstrap.js`… \n\n```js\nvar mm = {\n\tinit: function (settings) {\n\t\tif (settings === undefined) {\n\t\t\treturn \"this method should be passed an object literal\";\n\t\t}\n\t\t\n\t\tif (settings.cool_feature) {\n\t\t\t$LAB.script(\"/Assets/Scripts/cool_feature.js\");\n\t\t}\n\t}\n};\n```\n…and within the lazy-loaded script… \n\n```js\nmm.cool_feature = function(){\n\t// code\n};\n\nmm.cool_feature();\n```\n","tags":"#amd #lab #js #html"},{"id":"1370134","title":"Examples of jsonp loading via RequireJs ","content":"// Taken from: \n// http://requirejs.org/docs/api.html#jsonp\n// http://api.twitter.com/1/trends/available.json (seems to return data but is an Array not Object)\nrequire([\"http://search.twitter.com/trends/current.json?callback=define\"], function (trends) {\n\tconsole.log('trends: ', trends);\n});\n\n// Separate attempt\nrequire(['http://twitter.com/statuses/user_timeline/Integralist.json?callback=define'], function(feed) {\n\tconsole.log('feed: ', feed);\n});\n\n\n","tags":"#js"},{"id":"1363933","title":"Curl Google Plugin Example ","content":"\u003c!doctype html\u003e\n\u003chtml dir=\"ltr\" lang=\"en\"\u003e\n\u003chead\u003e\n   \u003cmeta charset=\"utf-8\"\u003e\n\t\u003ctitle\u003eCurl (Cujo Resource Loader)\u003c/title\u003e\n\u003c/head\u003e\n\u003cbody\u003e\n\n\t\u003cscript type=\"text/javascript\"\u003e\n\t\tcurl = {\n\t\t    baseUrl: 'Assets/Scripts',\n\t\t    paths: {\n\t\t        curl: 'Curl',\n\t\t        google: 'Plugins/google'\n\t\t    }\n\t\t};\n\t\u003c/script\u003e\n\t\u003cscript src=\"Assets/Scripts/Curl.js\"\u003e\u003c/script\u003e\n\t\u003cscript type=\"text/javascript\"\u003e\n\t\tcurl(['google!maps/3', 'google!visualization/1'], function(maps, viz) {\t\t\n\t\t\tconsole.log(maps, viz);\n\t\t});\n\t\u003c/script\u003e\n\t\n\u003c/body\u003e\n\u003c/html\u003e\n// google! plugin:\nvar google; // will become defined by googleMain below\ndefine({\n    load: function (resourceId, req, loaded, config) {\n        var googleMain = 'http://www.google.com/jsapi?key=' + config.apikey + 'callback=define',\n            args = resourceId.split('/');\n        // args = ['module-name', 'version', callbackFunc];\n        args.push(function () { loaded(google[args[0]]); });\n        // once main google library is available, get module\n        req([googleMain], function () {\n            google.load.apply(google, args);\n        });\n    }\n});\nUncaught Error: define() not found or duplicates found: http://www.google.com/jsapi?key=undefinedcallback=define\n\n/*\nOriginally I didn't specify the path for the Google plugin and so the error I was getting (then) was:\nGET http://curl:8888/Assets/Scripts/Curl/plugin/google.js 404 (Not Found)\nCurl.js:4Uncaught Error: Syntax error or http error: Assets/Scripts/Curl/plugin/google.js\n*/\n","tags":"#js"},{"id":"1336327","title":"jQuery Mobile application event list ","content":"* `pagebeforechange`\nThis event is triggered prior to any page loading or transition\n\n* `pagebeforeload`\nTriggered before any load request is made\n\n* `pagebeforecreate`\nTriggered on the page being initialized, before most plugin auto-initialization occurs\n\n* `pageload`\nTriggered after the page is successfully loaded and inserted into the DOM\n\n* `pagebeforechange`\nThis event is triggered prior to any page loading or transition\n\n* `pagebeforehide`\nTriggered on the \"fromPage\" we are transitioning away from, before the actual transition animation is kicked off\n\n* `pagebeforeshow`\nTriggered on the \"toPage\" we are transitioning to, before the actual transition animation is kicked off\n\n* `pagehide`\nTriggered on the \"fromPage\" after the transition animation has completed\n\n* `pageshow`\nTriggered on the \"toPage\" after the transition animation has completed\n\n* `pagechange`\nThis event is triggered after the `changePage()` request has finished loading the page into the DOM and all page transition animations have completed\n","tags":"#js"},{"id":"1363964","title":"Attempt at polyfilling addEventListener in IE7 via .htc hack ","content":"Element = function(){};\n\u003cPUBLIC:COMPONENT\u003e\n    \u003cPUBLIC:METHOD NAME=\"addEventListener\" INTERNALNAME=\"_addEventListener\" /\u003e\n\t\u003cscript type=\"text/javascript\"\u003e\n        var element = new Element;\n        _addEventListener = element.addEventListener;\n    \u003c/script\u003e\n\u003c/PUBLIC:COMPONENT\u003e\n\u003c!doctype html\u003e\n\u003chtml dir=\"ltr\" lang=\"en\"\u003e\n\t\u003chead\u003e\n\t\t\u003cmeta charset=\"utf-8\"\u003e\n\t\t\u003ctitle\u003eaddEventListener Shim\u003c/title\u003e\n\t\t\u003c!--[if lte IE 7]\u003e\n\t\t\t\u003cscript src=\"IE7.js\"\u003e\u003c/script\u003e\n\t\t\t\u003cstyle type=\"text/css\"\u003e\n\t\t\t\t* { behavior: url(ie_fix.htc); }\n\t\t\t\u003c/style\u003e\n\t\t\u003c![endif]--\u003e\n\t\u003c/head\u003e\n\t\u003cbody\u003e\n\t\n\t\t\u003cdiv id=\"testelement\" class=\"testclass\"\u003e\n\t\t\tThis is my test element\n\t\t\u003c/div\u003e\n\t\t\n\t\t\u003cscript type=\"text/javascript\"\u003e\n\t\t\t// IE8 (provides access to its 'Element' Interface)\n\t\t\tif (window.Element \u0026\u0026 !window.addEventListener) {\n\t\t\t\twindow.Element.prototype.addEventListener = function(type, listener, useCapture) {\n\t\t\t\t\tthis.attachEvent('on' + type, listener);\n\t\t\t\t}\n\t\t\t\t\n\t\t\t\twindow.Element.prototype.removeEventListener = function(type, listener, useCapture) {\n\t\t\t\t\tthis.detachEvent('on' + type, listener);\n\t\t\t\t}\n\t\t\t}\n\t\t\t\n\t\t\tfunction test() {\n\t\t\t\talert('I\\'m the listener for the addEventListener');\n\t\t\t\t\n\t\t\t\ttestelem.removeEventListener('click', test, false);\n\t\t\t}\n\t\t\t\n\t\t\tvar testelem = document.getElementById('testelement');\n\t\t\t\n\t\t\ttestelem.addEventListener('click', test, false);\n\t\t\u003c/script\u003e\n\t\u003c/body\u003e\n\u003c/html\u003e\n","tags":"#js"},{"id":"1303396","title":"jQuery Ajax Test (using Deferred/Promises) ","content":"\u003c!doctype html\u003e\n\u003chtml\u003e\n\t\u003chead\u003e\n\t\t\u003ctitle\u003ejQuery Ajax Test\u003c/title\u003e\n\t\t\u003cstyle type=\"text/css\"\u003e\n\t\t\t#test {\n\t\t\t\tbackground-color:pink;\n\t\t\t\tdisplay:none;\n\t\t\t\tpadding:10px;\n\t\t\t\ttext-align:center;\n\t\t\t\twidth:200px;\n\t\t\t}\n\t\t\u003c/style\u003e\n\t\u003c/head\u003e\n\t\u003cbody\u003e\n\t\n\t\t\u003cdiv id=\"test\"\u003e\n\t\t\tSome content\n\t\t\u003c/div\u003e\n\t\n\t\t\u003cscript src=\"https://ajax.googleapis.com/ajax/libs/jquery/1.6.4/jquery.min.js\"\u003e\u003c/script\u003e\n\t\t\u003cscript type=\"text/javascript\"\u003e\n\t\t\t$.ajax({\n\t\t\t\turl: 'test.js',\n\t\t\t\tsuccess: function(response) {\n\t\t\t\t\tconsole.log('I\\'m the most basic AJAX request (test.js): ', response);\n\t\t\t\t}\n\t\t\t});\n\t\t\t\n\t\t\tfunction aSuccessfullAJAXCall() {\n\t\t\t\tvar myData = $.ajax({\n\t\t\t\t\ttype: \"GET\",\n\t\t\t\t\turl: \"test.js\",\n\t\t\t\t\tdataType: \"json\"\n\t\t\t\t});\n\t\t\t\t\n\t\t\t\treturn myData;\n\t\t\t}\n\t\t\t\n\t\t\tfunction aFailingAJAXCall() {\n\t\t\t\tvar myData = window.setTimeout(function(){\n\t\t\t\t\t$.ajax({\n\t\t\t\t\t\ttype: \"GET\",\n\t\t\t\t\t\turl: \"i-dont-exist.js\",\n\t\t\t\t\t\tdataType: \"json\"\n\t\t\t\t\t})\n\t\t\t\t}, 5000);\n\t\t\t\t\n\t\t\t\treturn myData;\n\t\t\t}\n\t\t\t\n\t\t\tfunction doSomethingAsynchronously() {\n\t\t\t\t// Create new instance of a Deferred object\n\t\t\t\tvar dfd = $.Deferred();\n\t\t\t\t\n\t\t\t\t// In 5 seconds time fade in the hidden div so it becomes visible\n\t\t\t\t// This is considered an 'asynchronous' task as the function doSomethingAsynchronously() will technically finish executing ages before the 5 second timeout is triggered\n\t\t\t\t// When the animation finishes we let jQuery's Deferred object know but calling the 'resolve' property (dfd.resolve)\n\t\t\t\t$('#test').delay('5000').fadeIn(2000, dfd.resolve);\n\t\t\t\t\n\t\t\t\t// Whenever you use a Deferred object you must return a 'promise'\n\t\t\t\t// This is because the asynchronous task we're carrying out could take a long time to process\n\t\t\t\t// So dfd.promise() is saying: \"Go on and do other stuff, I'm going wait here, and I'll let you know when something happens\"\n\t\t\t\treturn dfd.promise();\n\t\t\t}\n\t\t\t\n\t\t\t// Global 'when' method which listens out for any 'promises' to both be returned.\n\t\t\t// The 'then()' method only executes when both specified functions are successful\n\t\t\t$.when(aSuccessfullAJAXCall(), doSomethingAsynchronously()).then(function(result) {\n\t\t\t\tconsole.group();\n\t\t\t\t\tconsole.log('The animation AND the ajax request are both complete.');\n\t\t\t\t\tconsole.log('The ajax call would have completed in only a few milliseconds, but this callback couldn\\'t be executed until both specified functions completed.');\n\t\t\t\t\tconsole.log('Now that jQuery has implemented the \"deferred\" design pattern we are able to lose the old style of JavaScript programming, i.e. long messy anonymous callback functions');\n\t\t\t\t\tconsole.log('This is the complete server response (data, status, jqXHR): ', result);\n\t\t\t\tconsole.groupEnd();\n\t\t\t\tconsole.group();\n\t\t\t\t\tconsole.log('Display our json data (from test.js): ', result[0]); // the specific json data from our test.js file\n\t\t\t\t\tconsole.log('Display specifically the \\'Brad\\' object: ', result[0][0]);\n\t\t\t\t\tconsole.log('Display Brad\\'s age: ', result[0][0].age);\n\t\t\t\tconsole.groupEnd();\n\t\t\t});\n\t\t\u003c/script\u003e\n\t\n\t\u003c/body\u003e\n\u003c/html\u003e\n[\n\t{\n\t\t\"name\": \"Brad\",\n\t\t\"age\": 102\n\t},\n\t{\n\t\t\"name\": \"Mark\",\n\t\t\"age\": 29\n\t}\n]\n","tags":"#js"},{"id":"1357584","title":"Curl Example ","content":"define(function() {\n\t\n\tfunction method (x) {\n\t\treturn x + x;\n\t}\n \n\treturn {\n\t\tsomeValue: 'foobar',\n\t\tmyMethod: method\n\t}\n\t\n});\ndefine(function() {\n\t\n\treturn function Person(fullname) {\n\t\tthis.name = fullname;\n\t}\n\t\n});\n\u003c!doctype html\u003e\n\u003chtml dir=\"ltr\" lang=\"en\"\u003e\n\u003chead\u003e\n\t\u003cmeta charset=\"utf-8\"\u003e\n\t\u003ctitle\u003eCurl (Cujo Resource Loader)\u003c/title\u003e\n\u003c/head\u003e\n\u003cbody\u003e\n\t\u003cscript type=\"text/javascript\"\u003e\n\t\tcurl = {\n\t\t    baseUrl: 'Assets/Scripts',\n\t\t    paths: {\n\t\t        curl: 'Curl',\n\t\t        jquery: 'Utils/jquery'\n\t\t    }\n\t\t};\n\t\u003c/script\u003e\n\t\u003cscript src=\"Assets/Scripts/Curl.js\"\u003e\u003c/script\u003e\n\t\u003cscript type=\"text/javascript\"\u003e\n\t\tcurl(['App/people'], function(o) {\n\t\t\tconsole.log(o.list, o.scripts);\n\t\t});\n\t\u003c/script\u003e\n\u003c/body\u003e\n\u003c/html\u003e\n\ndefine(['Models/Person', 'Utils/random', 'jquery'], function (Person, randomUtility, $) {\n\t\n\tvar people = [],\n\t    scriptsOnPage = $('script');\n\t\n\tpeople.push(new Person('Jim'));\n\tpeople.push(new Person(randomUtility.someValue));\n  \n\treturn { list: people, scripts: scriptsOnPage };\n\t\n});\n","tags":"#js"},{"id":"1336279","title":"cancel all jQuery AJAX requests ","content":"$.xhrPool = [];\n\n$.xhrPool.abortAll = function() {\n  /* Original example used _underscore api\n    _.each(this, function(jqXHR) {\n        jqXHR.abort();\n    });\n  */\n    $.each(this, function(jqXHR) { \n        jqXHR.abort(); \n    });\n};\n\n$.ajaxSetup({\n    beforeSend: function(jqXHR) {\n        $.xhrPool.push(jqXHR);\n    }\n});\n","tags":"#js"},{"id":"1303355","title":"Analyze the viewport size ","content":"It’s possible to analyze the viewport size in JavaScript but it’s a little messy:\n\n  - Most browsers support `window.innerWidth` and `window.innerHeight`.\n\n  - But IE6, 7, 8 and 9 in quirks mode require `document.body.clientWidth` and `document.body.clientHeight`.\n\n  - All the main browsers support `document.documentElement.clientWidth` and `document.documentElement.clientHeight` but it’s inconsistent. \n    Either the window or document dimensions will be returned depending on the browser and mode.\n","tags":"#js"},{"id":"1258903","title":"RequireJs Build Script ","content":"/*\n * http://requirejs.org/docs/optimization.html\n *\n * Use NodeJs to execute the r.js optimization script on this build script\n * node r.js -o app.build.js\n *\n * See: https://github.com/jrburke/r.js/blob/master/build/example.build.js for an example build script\n *\n * If you specify just the name (with no includes/excludes) then all modules are combined into the \"main\" file.\n * You can include/exclude specific modules though if needed\n *\n * You can also set optimize: \"none\" (or more specific uglifyjs settings) if you need to.\n */\n({\n    appDir: \"../../\",\n    baseUrl: \"Assets/Scripts\",\n    dir: \"../../project-build\",\n    modules: [\n        {\n            name: \"main\"\n            /*\n            include: [\"App/people\"],\n            exclude: [\"Utils/random\"]\n            */\n        }\n    ]\n})\n","tags":"#js "},{"id":"1247263","title":"Create Elements using memoization technique (modified to @GarrettS' points) ","content":"/**\n * The following method creates a new element or returns a copy of an element already created by this script.\n *\n * @param tagname { String } element to be created/copied\n * @return { Element/Node } the newly created element\n */\ncreateElement: (function(){\n\t// Memorize previous elements created\n\tvar cache = {};\n\t\n\treturn function(tagname) {\n\t\tif (!(tagname in cache)) {\n\t\t\t// Create new instance of specified element and store it\n\t\t\tcache[tagname] = document.createElement(tagname);\n\t\t}\n\t\t\n\t\t// If we've already created an element of the specified kind then duplicate it\n\t\treturn cache[tagname].cloneNode(false);\n\t}\n}())\n","tags":"#js"},{"id":"1225181","title":"@madrobby's 140 bytes template engine ","content":"function template(string, data, prop) {\n    for (prop in data) {\n        string = string.replace(new RegExp('{' + prop + '}', 'g'), data[prop]);\n    }\n    return string;\n}\n\n/*\nString templating engine:\n\nt(\"Hello {name}!, It is {date}!\", { name: \"Thomas\", date: function(){ return new Date }});\n// = \"Hello Thomas!, It is Sun May 08 2011 15:15:33 GMT-0400 (EDT)!\"\n*/\n","tags":"#js"},{"id":"1186328","title":"Access original value of property that has been over-written /via @jdalton and modified by @dperini ","content":"(function() {\n  var hasKey = {}.hasOwnProperty;\n\n  Object.prototype.hasOwnProperty = 1;\n  delete Object.prototype.hasOwnProperty;\n\n  var iframe = document.createElement('iframe');\n  document.documentElement.appendChild(iframe);\n  Object.prototype.hasOwnProperty = window.frames[0].Object.prototype.hasOwnProperty;\n  document.documentElement.removeChild(iframe);\n\n  alert('value after deleting Object.prototype.hasOwnProperty is: ' + {}.hasOwnProperty);\n\n}());\n","tags":"#js"},{"id":"1186292","title":"displays CSS properties that support URL as value via @LeaVerou ","content":"var s = document.body.style; \nfor (var i in s) {\n    s[i] = \"url('foo')\"; \n    \n    if(s[i]) {\n        console.log(i); \n        s[i] = ''\n    }\n}\n","tags":"#js"},{"id":"1148650","title":"better CSS pseudo-element selector detector ","content":"body {\n    font: normal small Helvetica, Arial, Verdana, sans-serif;\n}\n\nh1 {\n    border-bottom: 1px solid #C00;\n    color: #666;\n    font-weight: bold;\n    margin-bottom: 10px;\n}\n\ndiv {\n    border: 1px dashed #333;\n    padding: 10px;\n}\n\ndiv,\ndiv p {\n    margin-bottom: 10px;    \n}\n\ncode {\n    color: blue;\n}\n\nul {\n    list-style: disc;\n    margin-left: 10px;\n    padding-left: 10px;\n}\n\n.before #apply:before {\n    color: red;\n    content: \"before\";\n    display: inline-block;\n    margin: 0 5px 5px 0;\n}\n\n.after #apply:after {\n    color: green;\n    content: \"after\";\n    display: inline-block;\n    margin: 0 0 0 55px;\n}\n\u003ch1\u003eDetection script for CSS :before and :after support\u003c/h1\u003e\n\u003cdiv\u003e\n    \u003cp\u003eThis script detects support of the CSS selectors \u003ccode\u003e:before\u003c/code\u003e and \u003ccode\u003e:after\u003c/code\u003e by:\u003c/p\u003e\n    \u003cul\u003e\n        \u003cli\u003eAdding two empty paragraph elements to the page (effectively their height each is zero).\u003c/li\u003e\n        \u003cli\u003eAdding a style element to the page (+inserting the relevant \u003ccode\u003e:before\u003c/code\u003e/\u003ccode\u003e:after\u003c/code\u003e code).\u003c/li\u003e\n        \u003cli\u003eChecking the height of the element using offsetHeight.\u003c/li\u003e\n        \u003cli\u003eIf the height is greater or equal to 1 then we know the content was added so support is detected.\u003c/li\u003e\n        \u003cli\u003eMuch like \u003ca href=\"http://www.modernizr.com/\"\u003eModernizr\u003c/a\u003e we add relevant class names to the main \u003ccode\u003ehtml\u003c/code\u003e element\u003c/li\u003e\n    \u003c/ul\u003e\n\u003c/div\u003e\n\u003cp id=\"apply\"\u003eParagraph 1\u003c/p\u003e\n\u003cp\u003eParagraph 2\u003c/p\u003e\nwindow.onload = function() {\n    var doc = document,\n        html = doc.documentElement,\n        body = doc.body,\n        paraBefore = doc.createElement('p'),\n        paraAfter = doc.createElement('p'),\n        styleBefore = doc.createElement('style'),\n        styleAfter = doc.createElement('style'),\n        heightBefore, \n        heightAfter, \n        selectorsBefore = '#testbefore:before { content: \"before\"; }',\n        selectorsAfter = '#testafter:after { content: \"after\"; }';\n\n    // Internet Explorer seems to need a type attribute to recognise a stylesheet?\n    styleBefore.type = 'text\\/css';\n    styleAfter.type = 'text\\/css';\n\n    paraBefore.id = 'testbefore';\n    paraAfter.id = 'testafter';\n\n    // For Internet Explorer...\n    if (styleBefore.styleSheet) {\n        styleBefore.styleSheet.cssText = selectorsBefore;\n        styleAfter.styleSheet.cssText = selectorsAfter;\n    } else {\n        styleBefore.appendChild(doc.createTextNode(selectorsBefore));\n        styleAfter.appendChild(doc.createTextNode(selectorsAfter));\n    }\n\n    body.appendChild(styleBefore);\n    body.appendChild(styleAfter);\n    body.appendChild(paraBefore);\n    body.appendChild(paraAfter);\n\n    heightBefore = doc.getElementById('testbefore').offsetHeight;\n    heightAfter = doc.getElementById('testafter').offsetHeight;\n    \n    console.log(heightBefore, heightAfter);\n\n    if (heightBefore \u003e= 1) {\n        html.className += ' before';\n        body.removeChild(styleBefore);\n        body.removeChild(paraBefore);\n    }\n\n    if (heightAfter \u003e= 1) {\n        html.className += ' after';\n        body.removeChild(styleAfter);\n        body.removeChild(paraAfter);\n    }\n};\n","tags":"#js"},{"id":"1213445","title":"Better CSS Grid System ","content":"/*\n * Algorithm taken from: \n * http://csswizardry.com/2011/08/building-better-grid-systems/\n */\n\n.row {\n\twidth: (number of columns * width of one column) + (number of columns * width of one gutter) px;\n\tmargin-left: -width of one gutter px;\n\toverflow: hidden;\n\tclear: both;\n}\n\n.grid {\n\tfloat: left;\n\tmargin-left: width of one gutter px;\n}\n","tags":"#css"},{"id":"1186135","title":"server-sent events ","content":"\u003c?php\nheader(\"Content-Type: text/event-stream\");\nwhile(true) {\n    echo \"Event: server-time\\n\";\n    $time = time();\n    echo \"data: $time\\n\";\n    echo \"\\n\";\n    flush();\n    sleep(3);\n}\n?\u003e\n","tags":"#php"},{"id":"1148624","title":"detect CSS pseudo-element selector support ","content":"// Get a style property (name) of a specific element (elem)\nfunction getStyle(elem, name) {\n    // If the property exists in style[], then it's been set recently (and is current)\n    if (elem.style[name]) {\n        return elem.style[name];\n    }\n    // Otherwise, try to use IE's method\n    else if (elem.currentStyle) {\n        return elem.currentStyle[name];\n    }\n    // Or the W3C's method, if it exists\n    else if (document.defaultView \u0026\u0026 document.defaultView.getComputedStyle) {\n        // It uses the traditional 'text-align' style of rule writing, instead of textAlign\n        name = name.replace(/([A-Z])/g, '-$1');\n        name = name.toLowerCase();\n\n        // Get the style object and get the value of the property (if it exists)\n        var s = document.defaultView.getComputedStyle(elem, '');\n\n        return s \u0026\u0026 s.getPropertyValue(name);\n    }\n    // Otherwise, we're using some other browser\n    else {\n        return null;\n    }\n}\n\nwindow.onload = function() {\n    var doc = document,\n        html = doc.documentElement,\n        body = doc.body,\n        paraBefore = doc.createElement('p'),\n        paraAfter = doc.createElement('p'),\n        styleBefore = doc.createElement('style'),\n        styleAfter = doc.createElement('style'),\n        widthBefore, widthAfter, selectorsBefore = '#testbefore { display:inline-block; } #testbefore:before { content: \"before\"; }',\n        selectorsAfter = '#testafter { display:inline-block; } #testafter:after { content: \"after\"; }';\n\n    // Internet Explorer seems to need a type attribute to recognise a stylesheet?\n    styleBefore.type = 'text\\/css';\n    styleAfter.type = 'text\\/css';\n\n    paraBefore.id = 'testbefore';\n    paraAfter.id = 'testafter';\n\n    // For Internet Explorer...\n    if (styleBefore.styleSheet) {\n        styleBefore.styleSheet.cssText = selectorsBefore;\n        styleAfter.styleSheet.cssText = selectorsAfter;\n    } else {\n        styleBefore.appendChild(doc.createTextNode(selectorsBefore));\n        styleAfter.appendChild(doc.createTextNode(selectorsAfter));\n    }\n\n    body.appendChild(styleBefore);\n    body.appendChild(styleAfter);\n    body.appendChild(paraBefore);\n    body.appendChild(paraAfter);\n\n    // Internet Explorer doesn't always play ball…\n    widthBefore = (getStyle(document.getElementById('testbefore'), 'width') === 'auto') ? document.getElementById('testbefore').offsetWidth : parseInt(getStyle(document.getElementById('testbefore'), 'width'));\n    widthAfter = (getStyle(document.getElementById('testafter'), 'width') === 'auto') ? document.getElementById('testafter').offsetWidth : parseInt(getStyle(document.getElementById('testafter'), 'width'));\n\n    if (widthBefore \u003e 0) {\n        html.className += ' before';\n        body.removeChild(styleBefore);\n        body.removeChild(paraBefore);\n    } else {\n        console.log('before failed');\n    }\n\n    if (widthAfter \u003e 0) {\n        html.className += ' after';\n        body.removeChild(styleAfter);\n        body.removeChild(paraAfter);\n    } else {\n        console.log('after failed');\n    }\n};\nbody {\n    font: normal small Helvetica, Arial, Verdana, sans-serif;\n}\n\nh1 {\n    border-bottom: 1px solid #C00;\n    color: #666;\n    font-weight: bold;\n    margin-bottom: 10px;\n}\n\ndiv {\n    border: 1px dashed #333;\n    padding: 10px;\n}\n\ndiv,\ndiv p {\n    margin-bottom: 10px;    \n}\n\ncode {\n    color: blue;\n}\n\nul {\n    list-style: disc;\n    margin-left: 10px;\n    padding-left: 10px;\n}\n\n.before #apply:before {\n    color: red;\n    content: \"before\";\n    display: inline-block;\n    margin: 0 5px 5px 0;\n}\n\n.after #apply:after {\n    color: green;\n    content: \"after\";\n    display: inline-block;\n    margin: 0 0 0 55px;\n}\n\u003ch1\u003eDetection script for CSS :before and :after support\u003c/h1\u003e\n\u003cdiv\u003e\n    \u003cp\u003eThis script detects support of the CSS selectors \u003ccode\u003e:before\u003c/code\u003e and \u003ccode\u003e:after\u003c/code\u003e by:\u003c/p\u003e\n    \u003cul\u003e\n        \u003cli\u003eAdding two empty paragraph elements to the page (effectively their width each is zero).\u003c/li\u003e\n        \u003cli\u003eAdding a style element to the page (+inserting the relevant \u003ccode\u003e:before\u003c/code\u003e/\u003ccode\u003e:after\u003c/code\u003e code).\u003c/li\u003e\n        \u003cli\u003eChecking the width of the element (we need to set them to \u003ccode\u003edisplay:inline-block\u003c/code\u003e).\u003c/li\u003e\n        \u003cli\u003eIf the width is greater than zero then we know the content was added so support is detected.\u003c/li\u003e\n        \u003cli\u003eMuch like \u003ca href=\"http://www.modernizr.com/\"\u003eModernizr\u003c/a\u003e we add relevant class names to the main \u003ccode\u003ehtml\u003c/code\u003e element\u003c/li\u003e\n        \u003cli\u003eHad to go back and make changes for Internet Explorer (see code comments)\u003c/li\u003e\n    \u003c/ul\u003e\n\u003c/div\u003e\n\u003cp id=\"apply\"\u003eParagraph 1\u003c/p\u003e\n\u003cp\u003eParagraph 2\u003c/p\u003e\n","tags":"#js"},{"id":"1391440","title":"List of Twitter Bootstrap CSS classes ","content":"/*\n * Scaffolding\n * Basic and global styles for generating a grid system, structural layout, and page templates\n * ------------------------------------------------------------------------------------------- */\n\n.container\nSets a width of 940px which also centres the content (clears floated elements before/after)\n\n.container-fluid\nSets a minimum width of 940px (clears floated elements before/after)\n\n.pull-right\nFloats element to the right\n\n.pull-left\nFloats element to the left\n\n.hide\nsets element to display:none\n\n.show\nsets element to display:block\n\n.row\nSets a -20px margin (clears floated elements before/after)\n\n.span1 up to .span24\nSets specific pixel width values\n\n.row \u003e .offset1 (up to .offset12)\nSets specific margin-left values\n\n.span-one-third\nSets width of 300px\n\n.span-two-thirds\nSets width of 620px\n\n.span-one-third\nSets margin-left of 340px (so clears .span-one-third by 40px)\n\n.span-two-thirds\nSets margin-left of 660px (so clears .span-two-thirds by 40px)\n\n/* Forms.less\n * Base styles for various input types, form layouts, and states\n * ------------------------------------------------------------- */\n\n.uneditable-input\nSets element to block and gives border-radius + sets height/line-height to 18px + sets a box-shadow + background colour white + cursor: not-allowed\n\n.input-mini\n.mini\nSets width to 60px\n\n.input-small\n.small\nSets width to 90px\n\n.input-medium\n.medium\nSets width to 150px\n\n.input-large\n.large\nSets width to 210px\n\n.input-xlarge\n.xlarge\nSets width to 270px\n\n.input-xxlarge\n.xxlarge\nSets width to 530px\n\n.span1 up to .span16 (when applied to inputs and textareas)\nSets specific pixel width values + no float + no left margin + inline-block\n\n.actions\nSets top/bottom margin of 18px + padding + top border + border-radius\n\n.actions .secondary-action\nfloats element right and \u003ca\u003e get a line-height of 30px\n\n.help-inline\n.help-block\nline-height 18px + font-size: 13px\n\n.form-stacked\npadding-left: 20px;\n\n/*\n * Tables.less\n * Tables for, you guessed it, tabular data\n * ---------------------------------------- */\n\n.condensed-table\nApplies smaller padding than default\n\n.bordered-table\nApplies borders to the table\n\n.zebra-striped\nUses CSS3 to apply stripes (e.g. tr:nth-child(odd) td)\n\ntable .header\ncursor:pointer\n\n/* Patterns.less\n * Repeatable UI elements outside the base styles provided from the scaffolding\n * ---------------------------------------------------------------------------- */\n\n.topbar\nSets height to 40px + position:fixed + to top/left of screen with a very large z-index (10,000)\nAlso sets styles on sub elements like a form, p, input, div \u003e ul\n\n.topbar-inner, .topbar .fill\nSets dark background gradient\n\n.menu-dropdown\n.dropdown-menu\nSets white background, floats to left, absolute positioning, box shadow, border-radius, large z-index (900) + min/max widths + display none!?\n(I believe this is the drop down menu itself which is hidden until hovered over)\n\n.breadcrumb\n.pagination\nApplies relevant styles to a \u003cul\u003e element\n\n.hero-unit \nSets elements as a large promotional section\n\n.page-header\nApplies box-shadow and bottom-border\n\n.btn.error\n.btn.success\n.btn.info\n.btn\n.btn.primary\n.btn.active\n.btn.disabled\n.btn.large\n.btn.small\n.close\nDifferent button styles\n\n.well\nApplies padding/background colours/border-radius/box-shadow\n","tags":"#css"},{"id":"1123058","title":"lookbehind implementations ","content":"\u003e taken from http://www.regular-expressions.info/lookaround.html\n\n\"The bad news is that most regex flavors do not allow you to use just any regex inside a lookbehind, because they cannot apply a regular expression backwards. Therefore, the regular expression engine needs to be able to figure out how many steps to step back before checking the lookbehind.\n\nTherefore, many regex flavors, including those used by Perl and Python, only allow fixed-length strings. You can use any regex of which the length of the match can be predetermined. This means you can use literal text and character classes. You cannot use repetition or optional items. You can use alternation, but only if all options in the alternation have the same length.\n\nPCRE is not fully Perl-compatible when it comes to lookbehind. While Perl requires alternatives inside lookbehind to have the same length, PCRE allows alternatives of variable length. Each alternative still has to be fixed-length.\n\nJava takes things a step further by allowing finite repetition. You still cannot use the star or plus, but you can use the question mark and the curly braces with the max parameter specified. Java recognizes the fact that finite repetition can be rewritten as an alternation of strings with different, but fixed lengths. Unfortunately, the JDK 1.4 and 1.5 have some bugs when you use alternation inside lookbehind. These were fixed in JDK 1.6.\n\nThe only regex engines that allow you to use a full regular expression inside lookbehind, including infinite repetition, are the JGsoft engine and the .NET framework RegEx classes\"\n","tags":"#regex"},{"id":"1106383","title":"CSS Syntax Terminology ","content":"/* Rule (the entire chunk of code below can just be referred to as a single 'rule') */\n\n/* Selectors */\n#myID, .myClass \n\n/* Declaration Block */\n{\n\t/* Declaration */\n\t/* Property */border: /* Value */1px solid #DCDDDE;\n\t\n\t/* Declaration */\n\t/* Property */width: /* Value */335px;\n}\n","tags":"#css"},{"id":"1080410","title":"input placeholder polyfill ","content":"/*\n * The following script should be run on window.onload\n */\n\n/*******************************************************\n * VARIABLE SET-UP/CACHING\n *******************************************************/\n\n\tvar doc = document,\n\t\t body = doc.body,\n\t\t inputs = doc.getElementsByTagName('input'),\n\t\t txtarea = doc.getElementsByTagName('textarea'),\n\t\t combined = [],\n\t\t len,\n\t\t eventHandler,\n\t\t mainSiteContainer = doc.getElementById('main'),\n\t\t placeholder, \n\t\t lastInputSelected;\n\t\n\t/*\n\t * Would have been nice to just do:\n\t * \tvar combined = [].concat(Array.prototype.slice.call(inputs), Array.prototype.slice.call(txtarea));\n\t * But Internet Explorer fails with this, so we have merge the objects the long way!\n\t */\n\t\n\tfor (var i = 0; i \u003c inputs.length; i++) {\n\t    combined.push(inputs[i]);\n\t}\n\t\n\tfor (var j = 0; j \u003c txtarea.length; j++) {\n\t    combined.push(txtarea[j]);\n\t}\n\t\n\tlen = combined.length;\n\t\n/*******************************************************\n * FUNCTIONS\n *******************************************************/\n\t\n\t/**\n\t * Following function determines whether the previously selected input should have its original placeholder value re-inserted.\n\t * And then based on the currently selected input works out if it should have it's placeholder text removed so user can enter their own value.\n\t */\t\n\tfunction inputHandler(e) {\n\t\tvar e = e || window.event,\n\t\t\t targ = e.target || e.srcElement,\n\t\t\t type = e.type;\n\t\t\t \n\t\tplaceholder = targ.getAttribute('placeholder');\n\t\t\n\t\t// If there was an input previously selected...\n\t\tif (lastInputSelected !== undefined) {\n\t\t\t// ...then check to make sure that if it was left blank...\n\t\t\tif (lastInputSelected.value === '') {\n\t\t\t\t// ...that its value is set back to it's placeholder value\n\t\t\t\tlastInputSelected.value = lastInputSelected.getAttribute('placeholder');\n\t\t\t}\n\t\t}\n\t\t\n\t\t// If the target element has a placeholder...\n\t\tif (placeholder !== null) {\n\t\t\t\n\t\t\t// ...then store it as the last input selected...\n\t\t\tlastInputSelected = targ;\n\t\t\t\n\t\t\tif (type === 'blur') {\n\t\t\t\tif (targ.value === '') {\n\t\t\t\t\ttarg.value = placeholder;\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\t// ...then check if its value is the same as its placeholder and clear the value if so...\n\t\t\t\tif (targ.value === placeholder) {\n\t\t\t\t\ttarg.value = '';\n\t\t\t\t}\n\t\t\t}\n\t\t\t\n\t\t}\n\t}\n\t\n/*******************************************************\n * INITIAL SET-UP\n *******************************************************/\n \n \twhile (len--) {\n\t\t// Make sure the input has a placeholder attribute AND isn't a password field (for the time being I'm ignoring password fields)\n\t\tif (combined[len].getAttribute('placeholder') !== null \u0026\u0026 combined[len].type !== 'password') {\n\t\t\t// Set the value of the input to the placeholder value\n\t\t\tcombined[len].value = combined[len].getAttribute('placeholder');\n\t\t}\n\t}\n\t\n/*******************************************************\n * EVENT LISTENERS\n *******************************************************/\n\t\n\t// To get Event Delegation to work listening for 'focus' \u0026 'blur' events we need to fork the code depending on the browser.\n\t// Firefox \u0026 WebKit have useCapture set to true which initiates capturing (rather than bubbling)\n\t// Internet Explorer uses attachEvent to listen to 'focusin' event (as it can only handling bubbling phase)\n\tif (\"addEventListener\" in this.win) {\n\t   body.addEventListener('focus', inputHandler, true);\n\t   body.addEventListener('blur', inputHandler, true);\n\t} else {\n\t\tbody.attachEvent('onfocusin', inputHandler);\n\t\tbody.attachEvent('onfocusout', inputHandler);\n\t}\n","tags":"#js"},{"id":"884830","title":"Mobile Selector Engine ","content":"// A extremely basic selector engine for mobiles that support querySelectorAll /via @WebReflection (Andrea Giammarchi)\nvar $ = (function (s) {\n    return function $(q) {\n        return s.call(document.querySelectorAll(q))\n    }\n}([].slice));\n","tags":"#js"},{"id":"890700","title":"Generic JavaScript library ","content":"(function(window, document, undef) {\n\t\n\t// Generic library\n\tvar mylib = (function(){\n\t\n\t\t// Private implementation\n\t\tvar __mylib = {\n\t\t\t\n\t\t\t/**\n\t\t\t * Following property indicates whether the current rendering engine is Trident (i.e. Internet Explorer)\n\t\t\t * \n\t\t\t * @return v { Integer|undefined } if IE then returns the version, otherwise returns 'undefined' to indicate NOT a IE browser\n\t\t\t */\n\t\t\tisIE: (function() {\n\t\t\t\tvar undef,\n\t\t\t\t\t v = 3,\n\t\t\t\t\t div = document.createElement('div'),\n\t\t\t\t\t all = div.getElementsByTagName('i');\n\t\t\t\n\t\t\t\twhile (\n\t\t\t\t\tdiv.innerHTML = '\u003c!--[if gt IE ' + (++v) + ']\u003e\u003ci\u003e\u003c/i\u003e\u003c![endif]--\u003e',\n\t\t\t\t\tall[0]\n\t\t\t\t);\n\t\t\t\n\t\t\t\treturn v \u003e 4 ? v : undef;\n\t\t\t}()),\n\t\t\t\n\t\t\t// Errors\n\t\t\terrors: [],\n\t\t\t\n\t\t\t/**\n\t\t\t * Listens for when the DOM is ready to be interacted with.\n\t\t\t * Then processes queued functions.\n\t\t\t * \n\t\t\t * @param fn { Function } a function to be executed when the DOM is ready.\n\t\t\t * @return anonymous { Function } immediately-invoked function expression which returns a Function to be executed.\n\t\t\t */\n\t\t\tdomready: (function(){\n\n\t\t\t\t// Variables used throughout this script\n\t\t\t\tvar queue = [],\n\t\t\t\t\t exec,\n\t\t\t\t\t loaded,\n\t\t\t\t\t original_onload;\n\t\t\t\t\n\t\t\t\t// Private inner function which is called once DOM is loaded.\n\t\t\t\tfunction process() {\n\t\t\t\t\t// Let the script know the DOM is loaded\n\t\t\t\t\tloaded = true;\n\t\t\t\t\t\n\t\t\t\t\t// Cleanup\n\t\t\t\t\tif (document.addEventListener) {\n\t\t\t\t\t\tdocument.removeEventListener(\"DOMContentLoaded\", process, false);\n\t\t\t\t\t}\n\t\t\t\t\n\t\t\t\t\t// Move the zero index item from the queue and set 'exec' equal to it\n\t\t\t\t\twhile ((exec = queue.shift())) {\n\t\t\t\t\t\t// Now execute the current function\n\t\t\t\t\t\texec();\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\n\t\t\t\treturn function(fn) {\n\t\t\t\t\t// if DOM is already loaded then just execute the specified function\n\t\t\t\t\tif (loaded) { \n\t\t\t\t\t\treturn fn();\n\t\t\t\t\t}\n\t\t\t\t\t\n\t\t\t\t\tif (document.addEventListener) {\n\t\t\t\t\t\t// Any number of listeners can be set for when this event fires,\n\t\t\t\t\t\t// but just know that this event only ever fires once\n\t\t\t\t\t\tdocument.addEventListener(\"DOMContentLoaded\", process, false);\n\t\t\t\t\t} else {\n\t\t\t\t\t\t// All browsers support document.readyState (except Firefox 3.5 and lower, but they support DOMContentLoaded event)\n\t\t\t\t\t\t/loaded|complete/.test(document.readyState) ? process() : setTimeout(\"__mylib.domready(\" + fn + \")\", 10);\n\t\t\t\t\t}\n\t\t\t\t\t\n\t\t\t\t\t// Fall back to standard window.onload event\n\t\t\t\t\t// But make sure to store the original window.onload in case it was already set by another script\n\t\t\t\t\toriginal_onload = window.onload;\n\t\t\t\t\t\n\t\t\t\t\twindow.onload = function() {\n\t\t\t\t\t\n\t\t\t\t\t\t// Note: calling process() now wont cause any problem for modern browsers.\n\t\t\t\t\t\t// Because the function would have already been called when the DOM was loaded.\n\t\t\t\t\t\t// Meaning the queue of functions have already been executed\n\t\t\t\t\t\tprocess();\n\t\t\t\t\t\t\n\t\t\t\t\t\t// Check for original window.onload and execute it\n\t\t\t\t\t\tif (original_onload) {\n\t\t\t\t\t\t\toriginal_onload();\n\t\t\t\t\t\t}\n\t\t\t\t\t\t\n\t\t\t\t\t};\n\t\t\t\t\t\n\t\t\t\t\t// As the DOM hasn't loaded yet we'll store this function and execute it later\n\t\t\t\t\tqueue.push(fn);\n\t\t\t\t};\n\t\t\t\t\n\t\t\t}()),\n\t\t\t\n\t\t\t/**\n\t\t\t * XMLHttpRequest abstraction.\n\t\t\t * \n\t\t\t * @return xhr { XMLHttpRequest|ActiveXObject } a new instance of either the native XMLHttpRequest object or the corresponding ActiveXObject\n\t\t\t */\n\t\t \txhr: (function() {\n\t\n\t\t\t\t// Create local variable which will cache the results of this function\n\t\t\t\tvar xhr;\n\t\t\t\t\n\t\t\t\treturn function() {\n\t\t\t\t\t// Check if function has already cached the value\n\t\t\t\t\tif (xhr) {\n\t\t\t\t\t\t// Create a new XMLHttpRequest instance\n\t\t\t\t\t\treturn new xhr();\n\t\t\t\t\t} else {\n\t\t\t\t\t\t// Check what XMLHttpRequest object is available and cache it\n\t\t\t\t\t\txhr = (!window.XMLHttpRequest) ? function() {\n\t\t\t\t\t\t\treturn new ActiveXObject(\n\t\t\t\t\t\t\t\t// Internet Explorer 5 uses a different XMLHTTP object from Internet Explorer 6\n\t\t\t\t\t\t\t\t(__mylib.isIE \u003c 6) ? \"Microsoft.XMLHTTP\" : \"MSXML2.XMLHTTP\"\n\t\t\t\t\t\t\t);\n\t\t\t\t\t\t} : window.XMLHttpRequest;\n\t\t\t\t\t\t\n\t\t\t\t\t\t// Return a new XMLHttpRequest instance\n\t\t\t\t\t\treturn new xhr();\n\t\t\t\t\t}\n\t\t\t\t};\n\t\t\t\t\n\t\t\t}()),\n\t\t\t\n\t\t\t/**\n\t\t\t * A basic AJAX method.\n\t\t\t * \n\t\t\t * @param settings { Object } user configuration\n\t\t\t * @return undefined {  } no explicitly returned value\n\t\t\t */\n\t\t \tajax: function(settings) {\n\t\t \t\n\t\t \t\t// JavaScript engine will 'hoist' variables so we'll be specific and declare them here\n\t\t \t\tvar xhr, url, requestDone;\n\t\t \t\t\n\t\t \t\t// Load the config object with defaults, if no values were provided by the user\n\t\t\t\tconfig = {\n\t\t\t\t\t// The type of HTTP Request\n\t\t\t\t\tmethod: settings.method || 'POST',\n\t\t\t\t\t\n\t\t\t\t\t// The data to POST to the server\n\t\t\t\t\tdata: settings.data || '',\n\t\t\t\t\n\t\t\t\t\t// The URL the request will be made to\n\t\t\t\t\turl: settings.url || '',\n\t\t\t\t\n\t\t\t\t\t// How long to wait before considering the request to be a timeout\n\t\t\t\t\ttimeout: settings.timeout || 5000,\n\t\t\t\t\n\t\t\t\t\t// Functions to call when the request fails, succeeds, or completes (either fail or succeed)\n\t\t\t\t\tonComplete: settings.onComplete || function(){},\n\t\t\t\t\tonError: settings.onError || function(){},\n\t\t\t\t\tonSuccess: settings.onSuccess || function(){},\n\t\t\t\t\n\t\t\t\t\t// The data type that'll be returned from the server\n\t\t\t\t\t// the default is simply to determine what data was returned from the and act accordingly.\n\t\t\t\t\tdataType: settings.dataType || ''\n\t\t\t\t};\n\t\t\t\t\n\t\t\t\t// Create new cross-browser XMLHttpRequest instance\n\t\t\t\txhr = __mylib.xhr();\n\t\t\t\t\n\t\t\t\t// Open the asynchronous request\n\t\t\t\txhr.open(config.method, config.url, true);\n\t\t\t\t\n\t\t\t\t// Determine the success of the HTTP response\n\t\t\t\tfunction httpSuccess(r) {\n\t\t\t\t\ttry {\n\t\t\t\t\t\t// If no server status is provided, and we're actually\n\t\t\t\t\t\t// requesting a local file, then it was successful\n\t\t\t\t\t\treturn !r.status \u0026\u0026 location.protocol == 'file:' ||\n\t\t\t\t\t\t\n\t\t\t\t\t\t// Any status in the 200 range is good\n\t\t\t\t\t\t( r.status \u003e= 200 \u0026\u0026 r.status \u003c 300 ) ||\n\t\t\t\t\t\t\n\t\t\t\t\t\t// Successful if the document has not been modified\n\t\t\t\t\t\tr.status == 304 ||\n\t\t\t\t\t\t\n\t\t\t\t\t\t// Safari returns an empty status if the file has not been modified\n\t\t\t\t\t\tnavigator.userAgent.indexOf('Safari') \u003e= 0 \u0026\u0026 typeof r.status == 'undefined';\n\t\t\t\t\t} catch(e){\n\t\t\t\t\t\t// Throw a corresponding error\n\t\t\t\t\t\tthrow new Error(\"httpSuccess = \" + e);\n\t\t\t\t\t}\n\t\t\t\t\t\n\t\t\t\t\t// If checking the status failed, then assume that the request failed too\n\t\t\t\t\treturn false;\n\t\t\t\t}\n\t\t\t\t\n\t\t\t\t// Extract the correct data from the HTTP response\n\t\t\t\tfunction httpData(r, type) {\n\t\t\t\t\n\t\t\t\t\t// Get the content-type header\n\t\t\t\t\tvar ct = r.getResponseHeader(\"content-type\"),\n\t\t\t\t\t\t data = !type \u0026\u0026 ct \u0026\u0026 ct.indexOf(\"xml\") \u003e= 0; // If no default type was provided, determine if some form of XML was returned from the server\n\t\t\t\t\t\n\t\t\t\t\t// Get the XML Document object if XML was returned from the server,\n\t\t\t\t\t// otherwise return the text contents returned by the server\n\t\t\t\t\tdata = (type == \"xml\" || data) ? r.responseXML : r.responseText;\n\t\t\t\t\t\n\t\t\t\t\t// If the specified type is \"script\", execute the returned text response as if it was JavaScript\n\t\t\t\t\tif (type == \"script\") {\n\t\t\t\t\t\teval.call(window, data);\n\t\t\t\t\t}\n\t\t\t\t\t\n\t\t\t\t\t// Return the response data (either an XML Document or a text string)\n\t\t\t\t\treturn data;\n\t\t\t\t\t\n\t\t\t\t}\n\t\t\t\t\n\t\t\t\t// Initalize a callback which will fire within the timeout range, cancelling the request (if it has not already occurred)\n\t\t\t\twindow.setTimeout(function() {\n\t\t\t\t\trequestDone = true;\n\t\t\t\t}, config.timeout);\n\t\t\t\t\n\t\t\t\t// Watch for when the state of the document gets updated\n\t\t\t\txhr.onreadystatechange = function() {\n\t\t\t\t\n\t\t\t\t\t// Wait until the data is fully loaded, and make sure that the request hasn't already timed out\n\t\t\t\t\tif (xhr.readyState == 4 \u0026\u0026 !requestDone) {\n\t\t\t\t\t\t\n\t\t\t\t\t\t// Check to see if the request was successful\n\t\t\t\t\t\tif (httpSuccess(xhr)) {\n\t\t\t\t\t\t\t// Execute the success callback\n\t\t\t\t\t\t\tconfig.onSuccess(httpData(xhr, config.type));\n\t\t\t\t\t\t}\n\t\t\t\t\t\t// Otherwise, an error occurred, so execute the error callback\n\t\t\t\t\t\telse {\n\t\t\t\t\t\t\tconfig.onError(httpData(xhr, config.type));\n\t\t\t\t\t\t}\n\t\t\t\n\t\t\t\t\t\t// Call the completion callback\n\t\t\t\t\t\tconfig.onComplete();\n\t\t\t\t\t\t\n\t\t\t\t\t\t// Clean up after ourselves, to avoid memory leaks\n\t\t\t\t\t\txhr = null;\n\t\t\t\t\t\t\n\t\t\t\t\t} else if (requestDone \u0026\u0026 xhr.readyState != 4) {\n\t\t\t\t\t\t// If the script timed out then keep a log of it so the developer can query this and handle any exceptions\n\t\t\t\t\t\t__mylib.errors.push(url + \" { timed out } \");\n\t\t\t\t\t\t\n\t\t\t\t\t\t// Bail out of the request immediately\n\t\t\t\t\t\txhr.onreadystatechange = null;\n\t\t\t\t\t}\n\t\t\t\t\t\n\t\t\t\t};\n\t\t\t\t\n\t\t\t\t// Get if we should POST or GET...\n\t\t\t\tif (config.data) {\n\t\t\t\t\t// Settings\n\t\t\t\t\txhr.setRequestHeader(\"Content-Type\",\"application/x-www-form-urlencoded\");\n\t\t\t\t\t\n\t\t\t\t\t// Establish the connection to the server\n\t\t\t\t\txhr.send(config.data);\n\t\t\t\t} else {\t\t\t\t\t\n\t\t\t\t\t// Establish the connection to the server\n\t\t\t\t\txhr.send(null);\n\t\t\t\t}\n\t\n\t\t\t},\n\t\t\t\n\t\t\t// Event management\n\t\t\tevents: {\n\t\t\t\t\n\t\t\t\t/**\n\t\t\t\t * \n\t\t\t\t */\n\t\t\t\tprepareHandler: function(fn, model) {\n\t\t\t\t\tvar e = (model) ? e : window.event;\n\t\t\t\t\treturn function(e) {\n\t\t\t\t\t\t// Execute handler function, passing it a normalised version of the event object\n\t\t\t\t\t\tfn(__mylib.events.standardize(e));\n\t\t\t\t\t};\n\t\t\t\t},\n\t\t\t\t\n\t\t\t\t/**\n\t\t\t\t * \n\t\t\t\t */\n\t\t\t\tcheckHandler: function(fn, operation, model) {\n\t\t\t\t\t\n\t\t\t\t\tvar ch = this.checkHandler, list, map, handler, i, index = -1;\n\t\t\t\t\t\n\t\t\t\t\t// Maintain a static function list\n\t\t\t\t\t// If no list property exists then we'll create one\n\t\t\t\t\tif (!ch.list) {\n\t\t\t\t\t\tch.list = [];\n\t\t\t\t\t}\n\t\t\t\t\tlist = ch.list;\n\t\t\t\t\t\n\t\t\t\t\t// Loop through our list looking for the item\n\t\t\t\t\t// We cache the handler so we don't have to keep checking the 'standardise' method every time the handler is called\n\t\t\t\t\tfor (i = list.length - 1; i \u003e= 0; i -= 1) {\n\t\t\t\t\t\tmap = list[i];\n\t\t\t\t\t\tif (map \u0026\u0026 map.original === fn) {\n\t\t\t\t\t\t\tindex = i;\n\t\t\t\t\t\t\thandler = map.generated;\n\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\t\n\t\t\t\t\tif (operation == 'remove') {\n\t\t\t\t\t\t\n\t\t\t\t\t\tif (index !== -1) {\n\t\t\t\t\t\t\tlist[index].counter -= 1;\n\t\t\t\t\t\t\tif (list[index].counter \u003c= 0) {\n\t\t\t\t\t\t\t\tdelete list[index];\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t\t\n\t\t\t\t\t} else if(operation == 'add') {\n\t\t\t\t\t\t\n\t\t\t\t\t\tif (index !== -1) {\n\t\t\t\t\t\t\tlist[index].counter += 1;\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\thandler = __mylib.events.prepareHandler(fn, model);\n\t\t\t\t\t\t\tlist[list.length] = {\n\t\t\t\t\t\t\t\toriginal: fn,\n\t\t\t\t\t\t\t\tgenerated: handler,\n\t\t\t\t\t\t\t\tcounter: 1\n\t\t\t\t\t\t\t};\n\t\t\t\t\t\t}\n\t\t\t\t\t\t\n\t\t\t\t\t}\n\t\t\t\t\t\n\t\t\t\t\tconsole.log(list);\n\t\t\t\t\treturn handler;\n\t\t\t\t\t\n\t\t\t\t},\n\t\t\t\n\t\t\t\t/**\n\t\t\t\t * The add method allows us to assign a function to execute when an event of a specified type occurs on a specific element\n\t\t\t\t * \n\t\t\t\t * @param element { Element/Node } the element that will have the event listener attached\n\t\t\t\t * @param eventType { String } the event type, e.g. 'click' that will trigger the event handler\n\t\t\t\t * @param handler { Function } the function that will execute as the event handler\n\t\t\t\t * @return __add { Function } this immediately invoked function expression returns a bridge function which calls the private implementation\n\t\t\t\t */\n\t\t\t\tadd: (function() {\n\t\t\t\t\t\n\t\t\t\t\tvar __add, eventType, fn;\n\t\t\t\t\t\n\t\t\t\t\tif (document.addEventListener) {\n\t\t\t\t\t\t\n\t\t\t\t\t\t// Rewrite add method to use W3C event listener\n\t\t\t\t\t\t__add = function(element, eventType, handler) {\n\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t// Because we're using an anonymous function below (within the addEventListener method - this is so we can standardise the event object),\n\t\t\t\t\t\t\t// removing the event listener wont work because you must use a Function Declaration/Expression (not an anonymous function).\n\t\t\t\t\t\t\t// A way to explain this would be: var x = {}, y = {}; (x !== y) they may *look* the same but there is no way to tell.\n\t\t\t\t\t\t\t// So to work around this we need to prepare(store) the handler before specifying it as the handler.\n\t\t\t\t\t\t\t\n\t\t\t\t\t\t\tfn = __mylib.events.checkHandler(handler, 'add', 1);\n\t\t\t\t\t\t\t\n\t\t\t\t\t\t\teventType = eventType.toLowerCase();\n\t\t\t\t\t\t\telement.addEventListener(eventType, fn, false);\n\t\t\t\t\t\t\t\n\t\t\t\t\t\t};\n\t\t\t\t\t\t\n\t\t\t\t\t} \n\t\t\t\t\t\n\t\t\t\t\telse if (document.attachEvent) {\n\t\t\t\t\t\n\t\t\t\t\t\t// Rewrite add method to use Internet Explorer event listener\n\t\t\t\t\t\t__add = function(element, eventType, handler) {\n\t\t\t\t\t\t\n\t\t\t\t\t\t\t// Keep reference to the handler\n\t\t\t\t\t\t\tfn = __mylib.events.checkHandler(handler, 'add', 0);\n\t\t\t\t\t\t\t\n\t\t\t\t\t\t\teventType = eventType.toLowerCase();\n\t\t\t\t\t\t\telement.attachEvent(\"on\" + eventType, fn);\n\t\t\t\t\t\t\t\n\t\t\t\t\t\t};\n\t\t\t\t\t\t\n\t\t\t\t\t}\n\t\t\t\t\t\n\t\t\t\t\treturn function(element, eventType, handler) {\n\t\t\t\t\t\t__add(element, eventType, handler);\n\t\t\t\t\t};\n\t\t\t\t\t\n\t\t\t\t}()),\n\t\t\t\t\n\t\t\t\t/**\n\t\t\t\t * The remove method allows us to remove previously assigned code from an event\n\t\t\t\t * \n\t\t\t\t * @param element { Element/Node } the element that will have the event listener detached\n\t\t\t\t * @param eventType { String } the event type, e.g. 'click' that triggered the event handler\n\t\t\t\t * @param callback { Function } the function that was to be executed as the event handler\n\t\t\t\t * @return __remove { Function } this immediately invoked function expression returns a bridge function which calls the private implementation\n\t\t\t\t */\n\t\t\t\tremove: (function() {\n\t\t\t\t\t\n\t\t\t\t\tvar __remove, eventType, fn;\n\t\t\t\t\t\n\t\t\t\t\tif (document.removeEventListener) {\n\t\t\t\t\t\t\n\t\t\t\t\t\t// Rewrite remove method to use W3C event listener\n\t\t\t\t\t\t__remove = function(element, eventType, handler) {\n\t\t\t\t\t\t\t\n\t\t\t\t\t\t\tfn = __mylib.events.checkHandler(handler, 'remove', 1);\n\t\t\t\t\t\t\teventType = eventType.toLowerCase();\n\t\t\t\t\t\t\telement.removeEventListener(element, eventType, handler);\n\t\t\t\t\t\t\t\n\t\t\t\t\t\t};\n\t\t\t\t\t\t\n\t\t\t\t\t} \n\t\t\t\t\t\n\t\t\t\t\telse if (document.detachEvent) {\n\t\t\t\t\t\n\t\t\t\t\t\t// Rewrite remove method to use Internet Explorer event listener\n\t\t\t\t\t\t__remove = function(element, eventType, handler) {\n\t\t\t\t\t\t\t\n\t\t\t\t\t\t\tfn = __mylib.events.checkHandler(handler, 'remove', 0);\n\t\t\t\t\t\t\teventType = eventType.toLowerCase();\n\t\t\t\t\t\t\telement.detachEvent(\"on\" + eventType, handler);\n\t\t\t\t\t\t\t\n\t\t\t\t\t\t};\n\t\t\t\t\t\t\n\t\t\t\t\t}\n\t\t\t\t\t\n\t\t\t\t\treturn function(element, eventType, handler) {\n\t\t\t\t\t\t__remove(element, eventType, handler);\n\t\t\t\t\t};\n\t\t\t\t\t\n\t\t\t\t}()),\n\t\t\t\t\t\t\t\t\n\t\t\t\t/**\n\t\t\t\t * The standardize method produces a unified set of event properties, regardless of the browser\n\t\t\t\t * \n\t\t\t\t * @param event { Object } the event object associated with the event that was triggered\n\t\t\t\t * @return anonymous { Object } an un-named object literal with the relevant event properties normalised\n\t\t\t\t */\n\t\t\t \tstandardize: function(event) { \n\t\t\t\t\n\t\t\t\t\t// These two methods, defined later, return the current position of the \n\t\t\t\t\t// mouse pointer, relative to the document as a whole, and relative to the \n\t\t\t\t\t// element the event occurred within \n\t\t\t\t\tvar page = this.getMousePositionRelativeToDocument(event),\n\t\t\t\t\t\t offset = this.getMousePositionOffset(event);\n\t\t\t\t\t\n\t\t\t\t\t// Let's stop events from firing on element nodes above the current...\n\t\t\t\t\t\n\t\t\t\t\t// W3C method \n\t\t\t\t\tif (event.stopPropagation) { \n\t\t\t\t\t\tevent.stopPropagation(); \n\t\t\t\t\t} \n\t\t\t\t\t\n\t\t\t\t\t// Internet Explorer method \n\t\t\t\t\telse { \n\t\t\t\t\t\tevent.cancelBubble = true; \n\t\t\t\t\t} \n\t\t\t\t\t\n\t\t\t\t\t// We return an object literal containing seven properties and one method \n\t\t\t\t\treturn { \n\t\t\t\t\t\n\t\t\t\t\t\t// The target is the element the event occurred on \n\t\t\t\t\t\ttarget: this.getTarget(event), \n\t\t\t\t\t\t\n\t\t\t\t\t\t// The relatedTarget is the element the event was listening for, \n\t\t\t\t\t\t// which can be different from the target if the event occurred on an \n\t\t\t\t\t\t// element located within the relatedTarget element in the DOM \n\t\t\t\t\t\trelatedTarget: this.getRelatedTarget(event), \n\t\t\t\t\t\t\n\t\t\t\t\t\t// If the event was a  keyboard- related one, key returns the character \n\t\t\t\t\t\tkey: this.getCharacterFromKey(event), \n\t\t\t\t\t\t\n\t\t\t\t\t\t// Return the x and y coordinates of the mouse pointer, \n\t\t\t\t\t\t// relative to the document \n\t\t\t\t\t\tpageX: page.x, \n\t\t\t\t\t\tpageY: page.y, \n\t\t\t\t\t\t\n\t\t\t\t\t\t// Return the x and y coordinates of the mouse pointer, \n\t\t\t\t\t\t// relative to the element the current event occurred on \n\t\t\t\t\t\toffsetX: offset.x, \n\t\t\t\t\t\toffsetY: offset.y, \n\t\t\t\t\t\t\n\t\t\t\t\t\t// The preventDefault method stops the default event of the element \n\t\t\t\t\t\t// we're acting upon from occurring. If we were listening for click \n\t\t\t\t\t\t// events on a hyperlink, for example, this method would stop the \n\t\t\t\t\t\t// link from being followed \n\t\t\t\t\t\tpreventDefault: function() {\n\t\t\t\t\t\t \n\t\t\t\t\t\t \t// W3C method\n\t\t\t\t\t\t\tif (event.preventDefault) {\n\t\t\t\t\t\t\t\tevent.preventDefault();\n\t\t\t\t\t\t\t} \n\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t// Internet Explorer method\n\t\t\t\t\t\t\telse { \n\t\t\t\t\t\t\t\tevent.returnValue = false; \n\t\t\t\t\t\t\t} \n\t\t\t\t\t\t\t\n\t\t\t\t\t\t}\n\t\t\t\t\t\t\n\t\t\t\t\t};\n\t\t\t\t\t\n\t\t\t\t},\n\t\t\t\t\n\t\t\t\t/**\n\t\t\t\t * The getTarget method locates the element the event occurred on\n\t\t\t\t * \n\t\t\t\t * @param event { Object } the event object associated with the event that was triggered\n\t\t\t\t * @return target { Element/Node } the element that was the target of the triggered event\n\t\t\t\t */\n\t\t\t \tgetTarget: function(event) { \n\t\t\t\t\n\t\t\t\t\t// Internet Explorer value is srcElement, W3C value is target \n\t\t\t\t\tvar target = event.srcElement || event.target; \n\t\t\t\t\t\n\t\t\t\t\t// Fix legacy Safari bug which reports events occurring on a text node instead of an element node \n\t\t\t\t\tif (target.nodeType == 3) { // 3 denotes a text node \n\t\t\t\t\t\ttarget = target.parentNode; // Get parent node of text node \n\t\t\t\t\t} \n\t\t\t\t\t\n\t\t\t\t\t// Return the element node the event occurred on \n\t\t\t\t\treturn target;\n\t\t\t\t\t \n\t\t\t\t},\n\t\t\t\t\n\t\t\t\t/**\n\t\t\t\t * The getCharacterFromKey method returns the character pressed when keyboard events occur. \n\t\t\t\t * You should use the keypress event as others vary in reliability\n\t\t\t\t * \n\t\t\t\t * @param event { Object } the event object associated with the event that was triggered\n\t\t\t\t * @return character { String } the character pressed when keyboard events occurred\n\t\t\t\t */\n\t\t\t \tgetCharacterFromKey: function(event) {\n\t\t\t\t \n\t\t\t\t\tvar character = \"\"; \n\t\t\t\t\t\n\t\t\t\t\t// Internet Explorer \n\t\t\t\t\tif (event.keyCode) {\n\t\t\t\t\t\tcharacter = String.fromCharCode(event.keyCode); \n\t\t\t\t\t} \n\t\t\t\t\t\n\t\t\t\t\t// W3C \n\t\t\t\t\telse if (event.which) {\n\t\t\t\t\t\tcharacter = String.fromCharCode(event.which); \n\t\t\t\t\t} \n\t\t\t\t\t\n\t\t\t\t\treturn character;\n\t\t\t\t\t\n\t\t\t\t},\n\t\t\t\t\n\t\t\t\t/**\n\t\t\t\t * The getMousePositionRelativeToDocument method returns the current mouse pointer position relative to the top left edge of the current page.\n\t\t\t\t * \n\t\t\t\t * @param event { Object } the event object associated with the event that was triggered\n\t\t\t\t * @return anonymous { Object } the x and y coordinates\n\t\t\t\t */\n\t\t\t \tgetMousePositionRelativeToDocument: function(event) { \n\t\t\t\t\t\n\t\t\t\t\tvar x = 0, y = 0; \n\t\t\t\t\t\n\t\t\t\t\t// pageX gets coordinates of pointer from left of entire document \n\t\t\t\t\tif (event.pageX) { \n\t\t\t\t\t\tx = event.pageX; \n\t\t\t\t\t\ty = event.pageY; \n\t\t\t\t\t} \n\t\t\t\t\t\n\t\t\t\t\t// clientX gets coordinates from left of current viewable area \n\t\t\t\t\t// so we have to add the distance the page has scrolled onto this value \n\t\t\t\t\telse if (event.clientX) { \n\t\t\t\t\t\tx = event.clientX + document.body.scrollLeft + document.documentElement.scrollLeft; \n\t\t\t\t\t\ty = event.clientY + document.body.scrollTop + document.documentElement.scrollTop; \n\t\t\t\t\t}\n\t\t\t\t\t\n\t\t\t\t\t// Return an object literal containing the x and y mouse coordinates \n\t\t\t\t\treturn { \n\t\t\t\t\t\tx: x, \n\t\t\t\t\t\ty: y \n\t\t\t\t\t};\n\t\t\t\t\t\n\t\t\t\t},\n\t\t\t\t\n\t\t\t\t/**\n\t\t\t\t * The getMousePositionOffset method returns the distance of the mouse pointer from the top left of the element the event occurred on\n\t\t\t\t * \n\t\t\t\t * @param event { Object } the event object associated with the event that was triggered\n\t\t\t\t * @return anonymous { Object } the x and y coordinates of the mouse relative to the element\n\t\t\t\t */\n\t\t\t \tgetMousePositionOffset: function(event) {\n\t\t\t\t \n\t\t\t\t\tvar x = 0, y = 0; \n\t\t\t\t\n\t\t\t\t\tif (event.layerX) { \n\t\t\t\t\t\tx = event.layerX; \n\t\t\t\t\t\ty = event.layerY; \n\t\t\t\t\t}\n\t\t\t\t\t\n\t\t\t\t\t// Internet Explorer proprietary\n\t\t\t\t\telse if (event.offsetX) { \n\t\t\t\t\t\tx = event.offsetX; \n\t\t\t\t\t\ty = event.offsetY; \n\t\t\t\t\t} \n\t\t\t\t\t\n\t\t\t\t\t// Returns an object literal containing the x and y coordinates of the mouse relative to the element the event fired on \n\t\t\t\t\treturn { \n\t\t\t\t\t\tx: x, \n\t\t\t\t\t\ty: y \n\t\t\t\t\t};\n\t\t\t\t\t\n\t\t\t\t},\n\t\t\t\t\n\t\t\t\t/**\n\t\t\t\t * The getRelatedTarget method returns the element node the event was set up to fire on, \n\t\t\t\t * which can be different from the element the event actually fired on\n\t\t\t\t * \n\t\t\t\t * @param event { Object } the event object associated with the event that was triggered\n\t\t\t\t * @return relatedTarget { Element/Node } the element the event was set up to fire on\n\t\t\t\t */\n\t\t\t \tgetRelatedTarget: function(event) { \n\t\t\t\t\n\t\t\t\t\tvar relatedTarget = event.relatedTarget; \n\t\t\t\t\t\n\t\t\t\t\t// With mouseover events, relatedTarget is not set by default \n\t\t\t\t\tif (event.type == \"mouseover\") { \n\t\t\t\t\t\trelatedTarget = event.fromElement; \n\t\t\t\t\t} \n\t\t\t\t\t\n\t\t\t\t\t// With mouseout events, relatedTarget is not set by default\n\t\t\t\t\telse if (event.type == \"mouseout\") { \n\t\t\t\t\t\trelatedTarget = event.toElement; \n\t\t\t\t\t}\n\t\t\t\t\t\n\t\t\t\t\treturn relatedTarget; \n\t\t\t\t\t\n\t\t\t\t}\n\t\t\t\t\n\t\t\t},\n\t\t\t\n\t\t\tutilities: {\n\t\t\t\n\t\t\t\t/**\n\t\t\t\t * The toCamelCase method takes a hyphenated value and converts it into a camel case equivalent.\n\t\t\t\t * e.g. margin-left becomes marginLeft. \n\t\t\t\t * Hyphens are removed, and each word after the first begins with a capital letter.\n\t\t\t\t * \n\t\t\t\t * @param hyphenatedValue { String } hyphenated string to be converted\n\t\t\t\t * @return result { String } the camel case version of the string argument\n\t\t\t\t */\n\t\t\t \ttoCamelCase: function(hyphenatedValue) { \n\t\t\t\t\t\n\t\t\t\t\tvar result = hyphenatedValue.replace(/-\\D/g, function(character) { \n\t\t\t\t\t\treturn character.charAt(1).toUpperCase(); \n\t\t\t\t\t}); \n\t\t\t\t\t\n\t\t\t\t\treturn result;\n\t\t\t\t\t \n\t\t\t\t}, \n\t\t\t\t\n\t\t\t\t/**\n\t\t\t\t * The toHyphens method performs the opposite conversion, taking a camel case string and converting it into a hyphenated one.\n\t\t\t\t * e.g. marginLeft becomes margin-left\n\t\t\t\t * \n\t\t\t\t * @param camelCaseValue { String } camel cased string to be converted\n\t\t\t\t * @return result { String } the hyphenated version of the string argument\n\t\t\t\t */\n\t\t\t \ttoHyphens: function(camelCaseValue) { \n\t\t\t\t\t\n\t\t\t\t\tvar result = camelCaseValue.replace(/[A-Z]/g, function(character) { \n\t\t\t\t\t\treturn ('-' + character.charAt(0).toLowerCase()); \n\t\t\t\t\t});\n\t\t\t\t\n\t\t\t\t\treturn result; \n\n\t\t\t\t}\n\t\t\t\t\n\t\t\t},\n\t\t\t\n\t\t\tcss: {\n\t\t\t\n\t\t\t\t/**\n\t\t\t\t * The getAppliedStyle method returns the current value of a specific CSS style property on a particular element\n\t\t\t\t * \n\t\t\t\t * @param element { Element/Node } the element we wish to find the style value for\n\t\t\t\t * @param styleName { String } the specific style property we're interested in\n\t\t\t\t * @return style { String } the value of the style property found\n\t\t\t\t */\n\t\t\t \tgetAppliedStyle: function(element, styleName) {\n\t\t\t \t \n\t\t\t\t\tvar style = \"\";\n\t\t\t\t\t\n\t\t\t\t\tif (window.getComputedStyle) { \n\t\t\t\t\t\t//  W3C specific method. Expects a style property with hyphens \n\t\t\t\t\t\tstyle = element.ownerDocument.defaultView.getComputedStyle(element, null).getPropertyValue(__mylib.utilities.toHyphens(styleName)); \n\t\t\t\t\t} \n\t\t\t\t\t\n\t\t\t\t\telse if (element.currentStyle) { \n\t\t\t\t\t\t// Internet Explorer-specific method. Expects style property names in camel case \n\t\t\t\t\t\tstyle = element.currentStyle[__mylib.utilities.toCamelCase(styleName)]; \n\t\t\t\t\t}\n\t\t\t\t\t  \n\t\t\t\t\treturn style;\n\t\t\t\t\t\n\t\t\t\t},\n\t\t\t\t\n\t\t\t\t/**\n\t\t\t\t * The getArrayOfClassNames method is a utility method which returns an array of all the CSS class names assigned to a particular element.\n\t\t\t\t * Multiple class names are separated by a space character\n\t\t\t\t * \n\t\t\t\t * @param element { Element/Node } the element we wish to retrieve class names for\n\t\t\t\t * @return classNames { String } a list of class names separated with a space in-between\n\t\t\t\t */\n\t\t\t \tgetArrayOfClassNames: function(element) {\n\t\t\t \t\n\t\t\t\t\tvar classNames = []; \n\t\t\t\t\t\n\t\t\t\t\tif (element.className) { \n\t\t\t\t\t\t// If the element has a CSS class specified, create an array \n\t\t\t\t\t\tclassNames = element.className.split(' '); \n\t\t\t\t\t} \n\t\t\t\t\t\n\t\t\t\t\treturn classNames;\n\t\t\t\t\t\n\t\t\t\t},\n\t\t\t\t\n\t\t\t\t/**\n\t\t\t\t * The addClass method adds a new CSS class of a given name to a particular element\n\t\t\t\t * \n\t\t\t\t * @param element { Element/Node } the element we want to add a class name to\n\t\t\t\t * @param className { String } the class name we want to add\n\t\t\t\t * @return undefined {  } no explicitly returned value\n\t\t\t\t */\n\t\t\t \taddClass: function(element, className) {\n\t\t\t \t\n\t\t\t\t\t// Get a list of the current CSS class names applied to the element \n\t\t\t\t\tvar classNames = this.getArrayOfClassNames(element); \n\t\t\t\t\t\n\t\t\t\t\t// Add the new class name to the list \n\t\t\t\t\tclassNames.push(className);\n\t\t\t\t\t\n\t\t\t\t\t// Convert the list in space-separated string and assign to the element \n\t\t\t\t\telement.className = classNames.join(' '); \n\t\t\t\t\t\n\t\t\t\t},\n\t\t\t\t\n\t\t\t\t/**\n\t\t\t\t * The removeClass method removes a given CSS class name from a given element\n\t\t\t\t * \n\t\t\t\t * @param element { Element/Node } the element we want to remove a class name from\n\t\t\t\t * @param className { String } the class name we want to remove\n\t\t\t\t * @return undefined {  } no explicitly returned value\n\t\t\t\t */\n\t\t\t \tremoveClass: function(element, className) { \n\t\t\t \t\n\t\t\t\t\tvar classNames = this.getArrayOfClassNames(element),\n\t\t\t\t\t\t resultingClassNames = []; // Create a new array for storing all the final CSS class names in \n\t\t\t        \n\t\t\t\t\tfor (var index = 0, len = classNames.length; index \u003c len; index++) { \n\t\t\t\t\t\n\t\t\t\t\t\t// Loop through every class name in the list \n\t\t\t\t\t\tif (className != classNames[index]) { \n\t\t\t\t\t\t\n\t\t\t\t\t\t\t// Add the class name to the new list if it isn't the one specified \n\t\t\t\t\t\t\tresultingClassNames.push(classNames[index]); \n\t\t\t\t\t\t\t\n\t\t\t\t\t\t} \n\t\t\t\t\t\t\n\t\t\t\t\t}\n\t\t\t\t\t  \n\t\t\t\t\t// Convert the new list into a  space- separated string and assign it \n\t\t\t\t\telement.className = resultingClassNames.join(\" \"); \n\t\t\t\t\t\n\t\t\t\t},\n\t\t\t\t\n\t\t\t\t/**\n\t\t\t\t * The hasClass method returns true if a given class name exists on a specific element, false otherwise\n\t\t\t\t * \n\t\t\t\t * @param element { Element/Node } the element we want to check whether a class name exists on\n\t\t\t\t * @param className { String } the class name we want to check for\n\t\t\t\t * @return isClassNamePresent { Boolean } if class name was found or not\n\t\t\t\t */\n\t\t\t \thasClass: function(element, className) { \n\t\t\t \t\n\t\t\t\t\t// Assume by default that the class name is not applied to the element \n\t\t\t\t\tvar isClassNamePresent = false,\n\t\t\t\t\t\t classNames = this.getArrayOfClassNames(element); \n\t\t\t        \n\t\t\t\t\tfor (var index = 0, len = classNames.length; index \u003c len; index++) { \n\t\t\t\t\t\n\t\t\t\t\t\t// Loop through each CSS class name applied to this element \n\t\t\t\t\t\tif (className == classNames[index]) { \n\t\t\t\t\t\t\n\t\t\t\t\t\t\t// If the specific class name is found, set the return value to true \n\t\t\t\t\t\t\tisClassNamePresent = true; \n\t\t\t\t\t\t\t\n\t\t\t\t\t\t} \n\t\t\t\t\t\t\n\t\t\t\t\t} \n\t\t\t        \n\t\t\t\t\t// Return true or false, depending on if the specified class name was found \n\t\t\t\t\treturn isClassNamePresent; \n\t\t\t\t\t\n\t\t\t\t}\n\t\t\t\t\n\t\t\t}\n\t\t\t\n\t\t};\n\t\n\t\t// Return public API\n\t\treturn {\n\t\t\tload: __mylib.domready,\n\t\t\tajax: __mylib.ajax,\n\t\t\tevents: __mylib.events,\n\t\t\tcss: __mylib.css\n\t\t};\n\t\t\n\t}());\n\t\n\t// Expose st to the global object\n\twindow.st = mylib;\n\t\n}(this, this.document));\n","tags":"#js"},{"id":"1077593","title":"Cheap 'inArray' trick by @ded ","content":"/*\n * jsFiddle: http://jsfiddle.net/integralist/fL2Xv/\n * Original: http://twitter.com/#!/ded/status/90531502097575936\n */\n\nif (!Array.prototype.indexOf) {\n    Array.prototype.indexOf = function(item) {\n        return ( Math.abs( ~this.indexOf(item) ) )-1;\n    }\n}\n","tags":"#js"},{"id":"2782758","title":"Basic Form Validator","content":"```js\nrequire.config({ \n\tcatchError: {\n\t\tdefine: true\n\t}\n});\n\nrequire([\"../ErrorHandler/errors\"], function (handler) {\n\trequire.onError = handler;\n});\n\nrequire([\"validate\"], function (validate) {\n\tvalidate(document.forms[\"formname\"]);\n});\n\n```\n\n```js\ndefine(function(){\n\t\n\tfunction validate (form) {\n\t\tvar errors = [],\n\t\t\tform = form,\n\t\t\tfields = form.elements,\n\t\t\tformats = {\n\t\t\t\tnumber: function (field) {\n\t\t\t\t\tif (/^\\D+/.test(field.value) || !field.value.length) {\n\t\t\t\t\t\terrors.push(field);\n\t\t\t\t\t}\n\t\t\t\t},\n\t\t\t\tdate: function (field) {\n\t\t\t\t\t/*\n\t\t\t\t\t\tThe regex allows the following formats:\n\t\t\t\t\t\t\t00/00/0000\n\t\t\t\t\t\t\t00/00/00\n\t\t\t\t\t\t\t0/0/00\n\t\t\t\t\t */\n\t\t\t\t\tif (!/^\\d{1,2}\\/\\d{1,2}\\/\\d{2,4}$/.test(field.value) || !field.value.length) {\n    \t\t\t\t    errors.push(field);\n\t\t\t\t\t}\n\t\t\t\t},\n\t\t\t\temail: function (field) {\n\t\t\t\t\tif (field.value.indexOf(\"@\") === -1 || !field.value.length) {\n\t\t\t\t\t\terrors.push(field);\n\t\t\t\t\t}\n\t\t\t\t},\n\t\t\t\tmobile: function (field) {\n\t\t\t\t\t/*\n\t\t\t\t\t\tThe regex allows the following formats:\n\t\t\t\t\t\t\t+44 07000000000\n\t\t\t\t\t\t\t07000000000\n\t\t\t\t\t\t\t+4407000000000\n\t\t\t\t\t\t\n\t\t\t\t\t\tSo there is an optional +000 country code at the start (wrapped in a non-capturing group)\n\t\t\t\t\t\tWe then allow for an optional space after the optional country code\n\t\t\t\t\t\tFinally we allow for 11 digits (no spaces)\n\t\t\t\t\t */\n\t\t\t\t\tif (!/^(?:\\+\\d{1,3})?\\s?\\d{11}$/.test(field.value) || !field.value.length) {\n\t\t\t\t\t\terrors.push(field);\n\t\t\t\t\t}\n\t\t\t\t},\n\t\t\t\tpassword: function (field) {\n\t\t\t\t\t/*\n\t\t\t\t\t\tThe regex makes sure there is at least 8 alpha-numerical characters\n\t\t\t\t\t\tAnd that at least one of those values is a number\n\t\t\t\t\t\tAnd that at least one of those values is a text character\n\t\t\t\t\t\tWe use a positive lookahead (which checks to see if a sub pattern matches a specific position)\n\t\t\t\t\t\tThe lookahead checks for any character (zero or more times) is followed by a digit (e.g. making sure there is at least one digit)\n\t\t\t\t\t\tThe lookahead then checks for any character (zero or more times) is followed by a text character (e.g. making sure there is at least one text character)\n\t\t\t\t\t\tFinally after the two lookaheads we have the standard regex which makes sure there is at least 8 alpha-numerical characters\n\t\t\t\t\t */\n\t\t\t\t\tif (!/^(?=.*\\d)(?=.*[a-z])\\w{8,}/i.test(field.value)) {\n\t\t\t\t\t\terrors.push(field);\n\t\t\t\t\t}\n\t\t\t\t},\n\t\t\t\tincome: function (field) { \n\t\t\t\t\tif (!/^[\\d,.]+/.test(field.value) || !field.value.length) {\n\t\t\t\t\t\terrors.push(field);\n\t\t\t\t\t}\n\t\t\t\t},\n\t\t\t\taccountnumber: function (field) {\n\t\t\t\t\tif (!/^\\d{8}$/.test(field.value)) {\n\t\t\t\t\t\terrors.push(field);\n\t\t\t\t\t}\n\t\t\t\t},\n\t\t\t\tcardnumber: function (field) {\n\t\t\t\t\t/*\n\t\t\t\t\t\tThe following regex was actually borrowed from The Regular Expression Cookbook (co-written by the regex legend @stevenlevithan)\n\t\t\t\t\t */\n\t\t\t\t\tif (!/^(?:4[0-9]{12}(?:[0-9]{3})?|5[1-5][0-9]{14}|6(?:011|5[0-9][0-9])[0-9]{12}|3[47][0-9]{13}|3(?:0[0-5]|[68][0-9])[0-9]{11}|(?:2131|1800|35\\d{3})\\d{11})$/g.test(field.value)) {\n\t\t\t\t\t\terrors.push(field);\n\t\t\t\t\t}\n\t\t\t\t},\n\t\t\t\tshortdate: function (field) {\n\t\t\t\t\t/*\n\t\t\t\t\t\tThe regex allows the following formats:\n\t\t\t\t\t\t\t00/0000\n\t\t\t\t\t\t\t0/0000\n\t\t\t\t\t\t\t00/00\n\t\t\t\t\t\t\t0/00\n\t\t\t\t\t */\n\t\t\t\t\tif (!/^\\d{1,2}\\/\\d{2,4}$/.test(field.value) || !field.value.length) {\n    \t\t\t\t    errors.push(field);\n\t\t\t\t\t}\n\t\t\t\t},\n\t\t\t};\n\t\t\n\t\tform.onsubmit = function(){\n\t\t\tvar len = fields.length,\n\t\t\t\tfield,\n\t\t\t\tclassname,\n\t\t\t\ti;\n\t\t\t\n\t\t\terrors = [];\n\t\t\t\n\t\t\twhile(len--) {\n\t\t\t\tfield = fields[len];\n\t\t\t\tclassname = field.className;\n\t\t\t\ti = classname.indexOf(\"mandatory\");\n\t\t\t\t\n\t\t\t\tif (i \u003e= 0) {\n\t\t\t\t\t// For the validation script to work we need to ensure a specific format is used in the HTML.\n\t\t\t\t\t// The main principle is to make sure the last class on an input is either 'mandatory' or 'mandatory-xxxx' \n\t\t\t\t\t// e.g. 'mandatory-number', 'mandatory-dob', 'mandatory-email', 'mandatory-mobile', 'mandatory-password'\n\t\t\t\t\t\n\t\t\t\t\tif (classname.split(\"mandatory-\")[1]) {\n\t\t\t\t\t\t// If there is a second item then we know there is a specific type to validate against\n\t\t\t\t\t\tformats[classname.split(\"mandatory-\")[1]](field);\n\t\t\t\t\t} else {\n\t\t\t\t\t\t// Otherwise we validate by standard method\n\t\t\t\t\t\t// e.g. if the length is zero (meaning the field is empty) then zero will coerce to false\n\t\t\t\t\t\t// \t\tso we return the opposite of that using the ! operator (so the first part of the following condition is met)\n\t\t\t\t\t\t// \t\tand if the length is greater than zero then the regex checks to see if the content isn't just empty spaces\n\t\t\t\t\t\tif (/^\\s+$/.test(field.value) || !field.value.length) {\n\t\t\t\t\t\t\terrors.push(field);\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\t\n\t\t\t// Make sure there are no errors stored\n\t\t\t// If errors.length is zero then that means there are no errors\n\t\t\t// Zero will coerce to false and so we return the opposite of false using the ! operator\n\t\t\tif (!errors.length) {\n\t\t\t\treturn true;\n\t\t\t} \n\t\t\t\n\t\t\t// We return false to prevent the form from submitting\n\t\t\t// And we display the errors we found\n\t\t\telse {\t\t\t\t\n\t\t\t\tconsole.log(errors); // TODO: actually display the errors appropriately!\n\t\t\t\treturn false;\n\t\t\t}\n\t\t}\n\t}\n\t\n\treturn validate;\n\t\n});\n```\n","tags":""},{"id":"803331","title":"JavaScript CSS animation ","content":"// This script was written by @ded - I've just modified it slightly to take into account other browser vendor prefixes\n\n/**\n * @constructor Animate\n * @param {HTMLElement} el the element we want to animate\n * @param {String} prop the CSS property we will be animating\n * @param {Object} opts a configuration object\n * object properties include\n * from {Int}\n * to {Int}\n * time {Int} time in milliseconds\n * callback {Function}\n */\n\nfunction Animate(el, prop, opts) {\n    this.el = el;\n    this.prop = prop;\n    this.from = opts.from;\n    this.to = opts.to;\n    this.time = opts.time;\n    this.callback = opts.callback;\n    this.animDiff = this.to - this.from;\n}\n\n/**\n * @private\n * @param {String} val the CSS value we will set on the property\n */\nAnimate.prototype._setStyle = function(val) {\n\tif (this.prop == 'opacity') {\n    \tthis.el.style[this.prop] = val;\n\t\tthis.el.style.filter = 'alpha(opacity=' + val * 100 + ')';\n\t} else {\n    \tthis.el.style[this.prop] = val + 'px';\n\t}\n};\n\n/**\n * @private\n * this is the tweening function\n */\nAnimate.prototype._animate = function() {\n    var that = this;\n    this.now = new Date();\n    this.diff = this.now - this.startTime;\n\n    if (this.diff \u003e this.time) {\n        this._setStyle(this.to);\n\n        if (this.callback) {\n            this.callback.call(this);\n        }\n        clearInterval(this.timer);\n        return;\n    }\n\n    this.percentage = (Math.floor((this.diff / this.time) * 100) / 100);\n    this.val = (this.animDiff * this.percentage) + this.from;\n    this._setStyle(this.val);\n};\n\n/**\n * @public\n * begins the animation\n */\nAnimate.prototype.start = function() {\n    var that = this;\n    this.startTime = new Date();\n\n    this.timer = setInterval(function() {\n        that._animate.call(that);\n    }, 4);\n};\n\n/**\n * @static\n * @boolean\n * allows us to check if native CSS transitions are possible\n */\nAnimate.canTransition = (function() {\n\t/*\n\tvar el = document.createElement('foo');\n   el.style.cssText = '-webkit-transition: all .5s linear;';\n   return !!el.style.webkitTransitionProperty;\n   */\n   \n   // Modified check to match jQuery.support.transition (https://gist.github.com/373874)\n   var thisBody = document.body || document.documentElement,\n\t\t thisStyle = thisBody.style,\n    \t support = thisStyle.WebkitTransition !== undefined || thisStyle.MozTransition !== undefined || thisStyle.OTransition !== undefined || thisStyle.transition !== undefined;\n    \n\treturn support; \n}());\n\n/**\n * @static\n * @boolean\n * tells us whether CSS transitions are possible either natively or via a browser vendor prefixed\n */\nAnimate.whichTransition = (function() {\n\tvar thisBody = document.body || document.documentElement,\n\t\t thisStyle = thisBody.style,\n    \t obj = {\n    \t \t'webkit': thisStyle.WebkitTransition !== undefined,\n    \t \t'mozilla': thisStyle.MozTransition !== undefined,\n    \t \t'opera': thisStyle.OTransition !== undefined,\n    \t \t'default': thisStyle.transition !== undefined\n    \t };\n   \n   for (prop in obj) {\n   \tif (obj.hasOwnProperty(prop)) {\n   \t\tif (obj[prop]) {\n   \t\t\treturn prop;\n   \t\t}\n   \t}\n   }\n}());\nvar blocking = false;\n\nalert(Animate.whichTransition);\n\t\ndocument.getElementById('click').onclick = function(e) {\n\tif (blocking) {\n   \t\treturn false;\n \t}\n \t\n \tblocking = true;\n \t\n \tvar that = this,\n \t    el = document.getElementById('test'),\n\t    from = (this.className == 'animated') ? 1 : 0,\n \t    to = from == 1 ? 0 : 1;\n\t\t\n\t\t// relevant stuffs\n \tif (Animate.canTransition) {\n   \t\tswitch (Animate.whichTransition) {\n   \t\t\tcase 'webkit':\n   \t\t\t\tconsole.log('WebKit Vendor Prefix');\n   \t\t\t\tel.style.WebkitTransition = 'opacity 0.5s ease-out';\n\t   \t\t\tbreak;\n   \t\t\tcase 'mozilla':\n   \t\t\t\tconsole.log('Mozilla Vendor Prefix');\n   \t\t\t\tel.style.MozTransition = 'opacity 0.5s ease-out';\n   \t\t\t\tbreak;\n   \t\t\tcase 'opera':\n\t   \t\t\tconsole.log('Opera Vendor Prefix');\n   \t\t\t\tel.style.OTransition = 'opacity 0.5s ease-out';\n   \t\t\t\tbreak;\n   \t\t\tdefault:\n   \t\t\t\tconsole.log('W3C Standard Compliant Browser');\n\t   \t\t\tel.style.transition = 'opacity 0.5s ease-out';\n   \t\t\t\tbreak;\n   \t\t}\n   \t\t\n\t\tel.style.opacity = to;\n   \t\tblocking = false;\n   \t\tthat.className = (that.className == 'animated') ? '' : 'animated';\n \t} else {\n   \t\tnew Animate(el, 'opacity', {\n     \t\t\tfrom: from,\n\t     \t\tto: to,\n     \t\t\ttime: 500,\n     \t\t\tcallback: function() {\n\t       \t\t\tthat.className = (that.className == 'animated') ? '' : 'animated';\n       \t\t\t\tblocking = false;\n     \t\t\t}\n\t   \t}).start();\n \t}\n \t\n \treturn false;\n}};\n","tags":"#js"},{"id":"2700684","title":"Ordered Lists","content":"```css\nol {\n\tcounter-reset: section;\n\tlist-style-type: none;\n}\n\nol li:before {\n\tcounter-increment: section;\n\tcontent: counters(section, \".\") \" \";\n}\n```\n\n```html\n    \u003col\u003e  \n      \u003cli\u003eitem\u003c/li\u003e          \u003c!-- 1     --\u003e  \n      \u003cli\u003eitem               \u003c!-- 2     --\u003e  \n        \u003col\u003e  \n          \u003cli\u003eitem\u003c/li\u003e      \u003c!-- 2.1   --\u003e  \n          \u003cli\u003eitem\u003c/li\u003e      \u003c!-- 2.2   --\u003e  \n          \u003cli\u003eitem           \u003c!-- 2.3   --\u003e  \n            \u003col\u003e  \n              \u003cli\u003eitem\u003c/li\u003e  \u003c!-- 2.3.1 --\u003e  \n              \u003cli\u003eitem\u003c/li\u003e  \u003c!-- 2.3.2 --\u003e  \n            \u003c/ol\u003e  \n            \u003col\u003e  \n              \u003cli\u003eitem\u003c/li\u003e  \u003c!-- 2.3.1 --\u003e  \n              \u003cli\u003eitem\u003c/li\u003e  \u003c!-- 2.3.2 --\u003e  \n              \u003cli\u003eitem\u003c/li\u003e  \u003c!-- 2.3.3 --\u003e  \n            \u003c/ol\u003e  \n          \u003c/li\u003e  \n          \u003cli\u003eitem\u003c/li\u003e      \u003c!-- 2.4   --\u003e  \n        \u003c/ol\u003e  \n      \u003c/li\u003e  \n      \u003cli\u003eitem\u003c/li\u003e          \u003c!-- 3     --\u003e  \n      \u003cli\u003eitem\u003c/li\u003e          \u003c!-- 4     --\u003e  \n    \u003c/ol\u003e  \n    \u003col\u003e  \n      \u003cli\u003eitem\u003c/li\u003e          \u003c!-- 1     --\u003e  \n      \u003cli\u003eitem\u003c/li\u003e          \u003c!-- 2     --\u003e  \n    \u003c/ol\u003e\n```\n","tags":""},{"id":"2864041","title":"Create basic site using Ruby and Sinatra (and external templates)","content":"#!/usr/bin/env ruby\n\n=begin\n    install Sinatra: gem install sinatra\n    install Shotgun: gem install shotgun (this auto-reloads sinatra on every http request - which means every time you make a change in your code you don't have to stop then start sinatra)\n\n    To just run your code using Sinatra: ruby name-of-file.rb\n    To run your code using Shotgun (which is just Sinatra but with ability to auto-reload when changes are made to files): shotgun name-of-file.rb\n\n    The following examples are run using Shotgun and the URL is: http://127.0.0.1:9393/\n    Note: When you run 'shotgun' it might well give you a different URL port number.\n=end\n\nrequire \"sinatra\"\n\n=begin\n    The following line helps direct the requests for static resources (e.g. styles \u0026 scripts) \n    to the correct location by telling it what the 'public' folder should be. \n\n    e.g. if there is a request for 'Assets/Styles/test.css then the styles wont be found.\n    This is because the request is coming from a template file which is loaded from /views/\n    so we need to set the default route back to \"/\" so even though the template is within \n    /views/ the request will correct locate Assets/Styles/test.css\n=end\n\nset :public_folder, File.dirname(__FILE__)\n\n=begin\n    The following is an example of generating some HTML that submits the form data\n    back to the current page \"/\" and then uses a \"post\" check to display the posted\n    form data\n=end\n\nget \"/\" do\n    %q{\n        Hello World!\u003cbr\u003e\u003cf\u003e\u003ca href=\"http://www.google.com\"\u003eGoogle\u003c/a\u003e\n        \u003cform method=\"post\"\u003e\n        Enter your name: \u003cinput type=\"text\" name=\"name\" /\u003e\n        \u003cinput type=\"submit\" value=\"Go!\" /\u003e\n        \u003c/form\u003e\n    }\nend\n\npost \"/\" do\n    # When receiving post data from a form field we need to use a \"Named Parameter\"\n    \"Hello #{params[:name]}\"\nend\n\n=begin\n    The following examples show how to set-up code to run when accessing a specific\n    URL route like http://127.0.0.1:9393/add/5/1 \n=end\n\n# This example uses 'Named Parameters' (e.g. params[:name])\nget \"/add/:a/:b\" do\n    # http://127.0.0.1:9393/add/5/1 which should display 6 (5+1)\n    (params[:a].to_i + params[:b].to_i).to_s\nend\n\n# This example uses 'block parameters' (e.g. |x, y, z|)\nget \"/subtract/:a/:b\" do |a, b|\n    # Go to http://127.0.0.1:9393/subtract/5/1 which should display 4 (5-1)\n    (a.to_i - b.to_i).to_s\nend\n\n=begin\n    The following example shows how to use Templates and Layouts.\n    A Template is HTML code interpolated with dynamic content.\n    A Layout is a wrapper around the Template (e.g. \u003chtml\u003e\u003cbody\u003eTEMPLATE\u003c/body\u003e\u003c/html\u003e which means you don't have to include the same page content around your Template)\n\n    Templating is handled via Erb, but there are other template languages you can use\n    instead such as HAML or Builder\n=end\n\n# The \"before\" code block is executed before ALL requests\nbefore do\n    @people = [\n        { :name =\u003e \"Mark\", :age =\u003e 30 },\n        { :name =\u003e \"Brad\", :age =\u003e 21 },\n        { :name =\u003e \"Ash\", :age =\u003e 21 }\n    ] \nend\n\n# you must have a folder called 'views' with your template \u0026 layout files within it\n# e.g. /views/mylayout.erb and /views/mytemplate.erb (see additional files below for the content of these files)\nget \"/erb-template-external\" do\n    erb :mytemplate, :layout =\u003e :mylayout\nend\n\u003chtml lang=\"en\" dir=\"ltr\"\u003e\n    \u003chead\u003e\n        \u003cmeta charset=\"utf-8\"\u003e\n        \u003ctitle\u003eUsing Erb Templates\u003c/title\u003e\n        \u003clink rel=\"stylesheet\" href=\"Assets/Styles/test.css\"\u003e\n    \u003c/head\u003e\n    \u003cbody\u003e\n        \u003ch2\u003eErb Templates\u003c/h2\u003e\n        \u003c%= yield %\u003e\n        \u003cscript src=\"Assets/Scripts/test.js\"\u003e\u003c/script\u003e\n    \u003c/body\u003e\n\u003c/html\u003e\n\u003c% @people.each do |person| %\u003e\n   \u003cp\u003e\u003cstrong\u003e\u003c%= person[:name] %\u003e\u003c/strong\u003e is \u003c%= person[:age] %\u003e years old\u003c/p\u003e     \n\u003c% end %\u003e\nbody {\n    color: #CC0;\n    font-family: Helvetica, Arial, sans-serif;\n    font-size: 100%;\n    margin: 1em;\n    padding: 1em;\n}\nwindow.setTimeout(function(){\n    alert(\"This was delayed by five seconds\");\n}, 5000);\n","tags":""},{"id":"2862917","title":"Create basic Web Server in Ruby (using WEBrick)","content":"#!/usr/bin/env ruby\n\nrequire \"webrick\"\n\n=begin\n    WEBrick is a Ruby library that makes it easy to build an HTTP server with Ruby. \n    It comes with most installations of Ruby by default (it’s part of the standard library), \n    so you can usually create a basic web/HTTP server with only several lines of code.\n    \n    The following code creates a generic WEBrick server on the local machine on port 1234, \n    shuts the server down if the process is interrupted (often done with Ctrl+C).\n\n    This example lets you call the URL's: \"add\" and \"subtract\" and pass through arguments to them\n\n    Example usage: \n        http://localhost:1234/ (this will show the specified error message)\n        http://localhost:1234/add?a=10\u0026b=10 \n        http://localhost:1234/subtract?a=10\u0026b=9\n=end\n\nclass MyNormalClass\n    def self.add (a, b)\n        a.to_i + b.to_i\n    end\n    \n    def self.subtract (a, b)\n        a.to_i - b.to_i\n    end\nend\n\nclass MyServlet \u003c WEBrick::HTTPServlet::AbstractServlet\n    def do_GET (request, response)\n        if request.query[\"a\"] \u0026\u0026 request.query[\"b\"]\n            a = request.query[\"a\"]\n            b = request.query[\"b\"]\n            response.status = 200\n            response.content_type = \"text/plain\"\n            result = nil\n            \n            case request.path\n                when \"/add\"\n                    result = MyNormalClass.add(a, b)\n                when \"/subtract\"\n                    result = MyNormalClass.subtract(a, b)\n                else\n                    result = \"No such method\"\n            end\n            \n            response.body = result.to_s + \"\\n\"\n        else\n            response.status = 200\n            response.body = \"You did not provide the correct parameters\"\n        end\n    end\nend\n\nserver = WEBrick::HTTPServer.new(:Port =\u003e 1234)\n\nserver.mount \"/\", MyServlet\n\ntrap(\"INT\") {\n    server.shutdown\n}\n\nserver.start\n","tags":""}];</script>
<script src="assets/js/lunr.min.js"></script>
<script src="assets/js/search.js" defer></script>
<script src="assets/js/tags.js" defer></script>
</div>
</body>
</html>
<!DOCTYPE html>
<html>
<head>
<meta charset="utf-8">
<title>[Simple Fastly CDN Rate Limiting Logic using Vary behaviour for cacheable GET requests] #fastly #varnish #vcl #ratelimit #dos</title>
<style>
body { font-family: sans-serif; margin: 20px; line-height: 1.6; background-color: #f4f4f4; color: #333; }
.container { max-width: 800px; margin: auto; background: #fff; padding: 20px; border-radius: 8px; box-shadow: 0 0 10px rgba(0,0,0,0.1); }
pre { background: #f0f0f0; padding: 1em; border-radius: 5px; overflow-x: auto; border: 1px solid #ddd; }
code { font-family: 'SFMono-Regular', Consolas, 'Liberation Mono', Menlo, Courier, monospace; font-size: 0.9em;}
h1, h2 { border-bottom: 1px solid #eee; padding-bottom: 0.3em;}
a.back-link { display: inline-block; margin-bottom: 20px; color: #007bff; text-decoration: none; }
a.back-link:hover { text-decoration: underline; }
</style>
</head>
<body>
<div class="container">
<a href="../index.html" class="back-link">&laquo; Back to Index</a>
<h1 id="simple-fastly-cdn-rate-limiting-logic-using-vary-behaviour-for-cacheable-get-requests-fastly-varnish-vcl-ratelimit-dos">[Simple Fastly CDN Rate Limiting Logic using Vary behaviour for cacheable GET requests] #fastly #varnish #vcl #ratelimit #dos</h1>

<h2 id="1-readme">1. README</h2>

<pre><code class="language-text"># Example:
# https://fiddle.fastlydemo.net/fiddle/4ac44faf
#
# the principle of this design is that we want 
# requests to be cached using a key that varies
# on the &quot;Fastly-Client-IP&quot; and &quot;User-Agent&quot; headers
# but only for responses that indicate &quot;429 Too Many Requests&quot;
#
# whenever we get a &quot;429 Too Many Requests&quot; response, we'll
# we'll ensure it is cacheable, and that will result in the Vary headers
# being applied as part of the cache lookup process (because a different
# client request will provide a different value for the IP and User-Agent headers
# which are used for the varying logic. and so they'll have empty values and 
# this will result in (hopefully) a cached &quot;200 OK&quot;. or at the very least they'll 
# get a cache MISS and go to origin to fetch the content which will then be cached).
#
# caveat:
# this example doesn't work with POST requests.
# the solution to that is to `return(lookup)` in vcl_recv for POST|PUT|DELETE methods
# then skip caching for anything other than the 429 status code (e.g. if '200 OK' then don't cache)
# as we only want to cache a 429 with Vary behaviour
# 
# see this fiddle: https://fiddle.fastlydemo.net/fiddle/47871720
# which fixes the issue and implements the following changes 
# + additional changes to support otherwise uncacheable method types
#
# the code for that latter fiddle is also copied at the bottom of this gist
# just in case the fastly fiddle url is no longer available.
#
# one caveat to this approach (according to fastly)...
#
# &gt; As far as the caveat is considered, Fastly have told me…
# &gt; POST requests are also ineligible for clustering, ie transferring the request to a consistently-hashed storage node.  
# &gt; Since we don’t expect POSTs to be cached, this is an optimisation and we unfortunately don’t provide a way for you to override it.
# &gt; The effect of this is that even if you do enable POSTs to be cached, your cache hit ratio will be poor.
# &gt; This may be fine if your intention is just to use it for rate limiting.
#
# So yeah it’s not the end of the world, but the fact we lose fastly’s clustering behaviour isn’t ideal either.
</code></pre>

<h2 id="2-vcl-recv-vcl">2. vcl_recv.vcl</h2>

<pre><code class="language-vcl">if (req.restarts == 0) {
  # the User-Agent isn't provided by all clients (e.g. pentesting tools)
  # so we'll provide a genericized value if no header is found
  if (!req.http.User-Agent) {
    set req.http.UserAgent = &quot;Foo-Bar&quot;;
  }
}
</code></pre>

<h2 id="3-vcl-fetch-vcl">3. vcl_fetch.vcl</h2>

<pre><code class="language-vcl"># at this point we've gone to the origin and we've received a 429
# and so we set the 429 to be cacheable and we give it a TTL via Cache-Control header
# and we state this content needs to utilize Vary so that other clients don't get the cached 429
# if no caching directives are provided, then we'll set a default of one hour
if (beresp.status == 429) {
  # ensure all responses have the required Vary header values
  # for the sake of this test fiddle we simply hardcode the value
  # but in our real service we would check the Vary header and append to it
  if (!beresp.http.Vary) {
    set beresp.http.Vary = &quot;Fastly-Client-IP, User-Agent&quot;;
  }

  set beresp.cacheable = true;
  if (!beresp.http.Surrogate-Control &amp;&amp; !beresp.http.Cache-Control) {
    set beresp.ttl = 1h; # 1 hour
  }
}
</code></pre>

<h2 id="4-support-all-method-types-vcl">4. support all method types.vcl</h2>

<pre><code class="language-vcl">sub vcl_recv {
  if (req.restarts == 0) {
    if (!req.http.User-Agent) {
      set req.http.UserAgent = &quot;Fallback&quot;;
    }
  }

  // force caching for methods that are otherwise normally uncached
  // and mimic the standard behaviour of disabling 'request collapsing'
  if (req.method ~ &quot;(POST|PUT|DELETE)&quot;) {
    set req.http.X-PassMethod = &quot;true&quot;;
    set req.hash_ignore_busy = true;
    return(lookup);
  }
}
    
sub vcl_fetch {
  // this conditional is used for testing the logic
  // and isn't required for actual implementation
  if (req.http.X-429) {
    set beresp.status = 429;
  }

  declare local var.vary STRING;
  set var.vary = &quot;Fastly-Client-IP, User-Agent&quot;;

  if (beresp.status == 429) {
    if (!beresp.http.Vary) {
      set beresp.http.Vary = var.vary;
    } else {
      set beresp.http.Vary = beresp.http.Vary + &quot;, &quot; + var.vary;
    }

    set beresp.cacheable = true;
    if (!beresp.http.Surrogate-Control:max-age &amp;&amp; !beresp.http.Cache-Control:max-age) {
      set beresp.ttl = 1m; // 1 minute
    }
  }

  if (req.http.X-PassMethod) {
    if (beresp.status != 429) {
      set beresp.cacheable = false;
    }
  }
}
</code></pre>

</div>
</body>
</html>